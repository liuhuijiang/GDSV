{"project": "FFmpeg", "commit_id": "2aab7c2dfaca4386c38e5d565cd2bf73096bcc86", "target": 0, "func": "void ff_put_h264_qpel8_mc13_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_hv_qrt_8w_msa(src + stride - 2,\n\n                           src - (stride * 2), stride, dst, stride, 8);\n\n}\n", "idx": 24628}
{"project": "FFmpeg", "commit_id": "40ad05bab206c932a32171d45581080c914b06ec", "target": 0, "func": "int float_near_ulp(float a, float b, unsigned max_ulp)\n\n{\n\n    union av_intfloat32 x, y;\n\n\n\n    x.f = a;\n\n    y.f = b;\n\n\n\n    if (is_negative(x) != is_negative(y)) {\n\n        // handle -0.0 == +0.0\n\n        return a == b;\n\n    }\n\n\n\n    if (abs(x.i - y.i) <= max_ulp)\n\n        return 1;\n\n\n\n    return 0;\n\n}\n", "idx": 24629}
{"project": "FFmpeg", "commit_id": "a8bdf2405c6027f45a899eaaa6ba74e97c1c2701", "target": 1, "func": "static av_cold int roq_dpcm_encode_init(AVCodecContext *avctx)\n\n{\n\n    ROQDPCMContext *context = avctx->priv_data;\n\n\n\n    if (avctx->channels > 2) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Audio must be mono or stereo\\n\");\n\n        return -1;\n\n    }\n\n    if (avctx->sample_rate != 22050) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Audio must be 22050 Hz\\n\");\n\n        return -1;\n\n    }\n\n    if (avctx->sample_fmt != AV_SAMPLE_FMT_S16) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Audio must be signed 16-bit\\n\");\n\n        return -1;\n\n    }\n\n\n\n    avctx->frame_size = ROQ_FIRST_FRAME_SIZE;\n\n\n\n    context->lastSample[0] = context->lastSample[1] = 0;\n\n\n\n    avctx->coded_frame= avcodec_alloc_frame();\n\n\n\n\n\n    return 0;\n\n}", "idx": 24631}
{"project": "FFmpeg", "commit_id": "32baeafeee4f8446c2c3720b9223ad2166ca9d30", "target": 1, "func": "static void xvid_idct_add(uint8_t *dest, ptrdiff_t line_size, int16_t *block)\n\n{\n\n    ff_xvid_idct(block);\n\n    ff_add_pixels_clamped(block, dest, line_size);\n\n}\n", "idx": 24633}
{"project": "FFmpeg", "commit_id": "18d1d5886bb78e4d0e11a2a0193fda765e05805d", "target": 1, "func": "static int rv30_decode_mb_info(RV34DecContext *r)\n\n{\n\n    static const int rv30_p_types[6] = { RV34_MB_SKIP, RV34_MB_P_16x16, RV34_MB_P_8x8, -1, RV34_MB_TYPE_INTRA, RV34_MB_TYPE_INTRA16x16 };\n\n    static const int rv30_b_types[6] = { RV34_MB_SKIP, RV34_MB_B_DIRECT, RV34_MB_B_FORWARD, RV34_MB_B_BACKWARD, RV34_MB_TYPE_INTRA, RV34_MB_TYPE_INTRA16x16 };\n\n    MpegEncContext *s = &r->s;\n\n    GetBitContext *gb = &s->gb;\n\n    int code = svq3_get_ue_golomb(gb);\n\n\n\n    if(code > 11){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Incorrect MB type code\\n\");\n\n        return -1;\n\n    }\n\n    if(code > 5){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"dquant needed\\n\");\n\n        code -= 6;\n\n    }\n\n    if(s->pict_type != AV_PICTURE_TYPE_B)\n\n        return rv30_p_types[code];\n\n    else\n\n        return rv30_b_types[code];\n\n}\n", "idx": 24636}
{"project": "FFmpeg", "commit_id": "2580bae54a45d6aaf85ddc5e780389e7e90b2c86", "target": 1, "func": "static av_cold int j2kenc_init(AVCodecContext *avctx)\n\n{\n\n    int i, ret;\n\n    Jpeg2000EncoderContext *s = avctx->priv_data;\n\n    Jpeg2000CodingStyle *codsty = &s->codsty;\n\n    Jpeg2000QuantStyle  *qntsty = &s->qntsty;\n\n\n\n    s->avctx = avctx;\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"init\\n\");\n\n\n\n    // defaults:\n\n    // TODO: implement setting non-standard precinct size\n\n    memset(codsty->log2_prec_widths , 15, sizeof(codsty->log2_prec_widths ));\n\n    memset(codsty->log2_prec_heights, 15, sizeof(codsty->log2_prec_heights));\n\n    codsty->nreslevels2decode=\n\n    codsty->nreslevels       = 7;\n\n    codsty->log2_cblk_width  = 4;\n\n    codsty->log2_cblk_height = 4;\n\n    codsty->transform        = avctx->prediction_method ? FF_DWT53 : FF_DWT97_INT;\n\n\n\n    qntsty->nguardbits       = 1;\n\n\n\n    s->tile_width            = 256;\n\n    s->tile_height           = 256;\n\n\n\n    if (codsty->transform == FF_DWT53)\n\n        qntsty->quantsty = JPEG2000_QSTY_NONE;\n\n    else\n\n        qntsty->quantsty = JPEG2000_QSTY_SE;\n\n\n\n    s->width = avctx->width;\n\n    s->height = avctx->height;\n\n\n\n    for (i = 0; i < 3; i++)\n\n        s->cbps[i] = 8;\n\n\n\n    if (avctx->pix_fmt == AV_PIX_FMT_RGB24){\n\n        s->ncomponents = 3;\n\n    } else if (avctx->pix_fmt == AV_PIX_FMT_GRAY8){\n\n        s->ncomponents = 1;\n\n    } else{ // planar YUV\n\n        s->planar = 1;\n\n        s->ncomponents = 3;\n\n        avcodec_get_chroma_sub_sample(avctx->pix_fmt,\n\n                s->chroma_shift, s->chroma_shift + 1);\n\n    }\n\n\n\n    ff_jpeg2000_init_tier1_luts();\n\n    ff_mqc_init_context_tables();\n\n    init_luts();\n\n\n\n    init_quantization(s);\n\n    if (ret=init_tiles(s))\n\n        return ret;\n\n\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"after init\\n\");\n\n\n\n    return 0;\n\n}\n", "idx": 24638}
{"project": "FFmpeg", "commit_id": "0424e052f83adc422d8a746e3cdc5ab6bc28679e", "target": 1, "func": "void ff_release_unused_pictures(MpegEncContext *s, int remove_current)\n\n{\n\n    int i;\n\n\n\n    /* release non reference frames */\n\n    for(i=0; i<s->picture_count; i++){\n\n        if(s->picture[i].data[0] && !s->picture[i].reference\n\n           && s->picture[i].owner2 == s\n\n           && (remove_current || &s->picture[i] != s->current_picture_ptr)\n\n           /*&& s->picture[i].type!=FF_BUFFER_TYPE_SHARED*/){\n\n            free_frame_buffer(s, &s->picture[i]);\n\n        }\n\n    }\n\n}\n", "idx": 24641}
{"project": "FFmpeg", "commit_id": "568e18b15e2ddf494fd8926707d34ca08c8edce5", "target": 1, "func": "static int mov_read_stsc(MOVContext *c, ByteIOContext *pb, MOV_atom_t atom)\n\n{\n\n    AVStream *st = c->fc->streams[c->fc->nb_streams-1];\n\n    MOVStreamContext *sc = (MOVStreamContext *)st->priv_data;\n\n    int entries, i;\n\n\n\n    print_atom(\"stsc\", atom);\n\n\n\n    get_byte(pb); /* version */\n\n    get_byte(pb); get_byte(pb); get_byte(pb); /* flags */\n\n\n\n    entries = get_be32(pb);\n\n#ifdef DEBUG\n\nav_log(NULL, AV_LOG_DEBUG, \"track[%i].stsc.entries = %i\\n\", c->fc->nb_streams-1, entries);\n\n#endif\n\n    sc->sample_to_chunk_sz = entries;\n\n    sc->sample_to_chunk = (MOV_sample_to_chunk_tbl*) av_malloc(entries * sizeof(MOV_sample_to_chunk_tbl));\n\n    if (!sc->sample_to_chunk)\n\n        return -1;\n\n    for(i=0; i<entries; i++) {\n\n        sc->sample_to_chunk[i].first = get_be32(pb);\n\n        sc->sample_to_chunk[i].count = get_be32(pb);\n\n        sc->sample_to_chunk[i].id = get_be32(pb);\n\n#ifdef DEBUG\n\n/*        av_log(NULL, AV_LOG_DEBUG, \"sample_to_chunk first=%ld count=%ld, id=%ld\\n\", sc->sample_to_chunk[i].first, sc->sample_to_chunk[i].count, sc->sample_to_chunk[i].id); */\n\n#endif\n\n    }\n\n    return 0;\n\n}\n", "idx": 24646}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "av_cold int ff_MPV_common_init(MpegEncContext *s)\n\n{\n\n    int i;\n\n    int nb_slices = (HAVE_THREADS &&\n\n                     s->avctx->active_thread_type & FF_THREAD_SLICE) ?\n\n                    s->avctx->thread_count : 1;\n\n\n\n    if (s->encoding && s->avctx->slices)\n\n        nb_slices = s->avctx->slices;\n\n\n\n    if (s->codec_id == AV_CODEC_ID_MPEG2VIDEO && !s->progressive_sequence)\n\n        s->mb_height = (s->height + 31) / 32 * 2;\n\n    else\n\n        s->mb_height = (s->height + 15) / 16;\n\n\n\n    if (s->avctx->pix_fmt == AV_PIX_FMT_NONE) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"decoding to AV_PIX_FMT_NONE is not supported.\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (nb_slices > MAX_THREADS || (nb_slices > s->mb_height && s->mb_height)) {\n\n        int max_slices;\n\n        if (s->mb_height)\n\n            max_slices = FFMIN(MAX_THREADS, s->mb_height);\n\n        else\n\n            max_slices = MAX_THREADS;\n\n        av_log(s->avctx, AV_LOG_WARNING, \"too many threads/slices (%d),\"\n\n               \" reducing to %d\\n\", nb_slices, max_slices);\n\n        nb_slices = max_slices;\n\n    }\n\n\n\n    if ((s->width || s->height) &&\n\n        av_image_check_size(s->width, s->height, 0, s->avctx))\n\n        return -1;\n\n\n\n    ff_dct_common_init(s);\n\n\n\n    s->flags  = s->avctx->flags;\n\n    s->flags2 = s->avctx->flags2;\n\n\n\n    /* set chroma shifts */\n\n    av_pix_fmt_get_chroma_sub_sample(s->avctx->pix_fmt,\n\n                                     &s->chroma_x_shift,\n\n                                     &s->chroma_y_shift);\n\n\n\n    /* convert fourcc to upper case */\n\n    s->codec_tag          = avpriv_toupper4(s->avctx->codec_tag);\n\n\n\n    s->stream_codec_tag   = avpriv_toupper4(s->avctx->stream_codec_tag);\n\n\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->picture,\n\n                      MAX_PICTURE_COUNT * sizeof(Picture), fail);\n\n    for (i = 0; i < MAX_PICTURE_COUNT; i++) {\n\n        av_frame_unref(&s->picture[i].f);\n\n    }\n\n    memset(&s->next_picture, 0, sizeof(s->next_picture));\n\n    memset(&s->last_picture, 0, sizeof(s->last_picture));\n\n    memset(&s->current_picture, 0, sizeof(s->current_picture));\n\n    av_frame_unref(&s->next_picture.f);\n\n    av_frame_unref(&s->last_picture.f);\n\n    av_frame_unref(&s->current_picture.f);\n\n\n\n    if (s->width && s->height) {\n\n        if (init_context_frame(s))\n\n            goto fail;\n\n\n\n        s->parse_context.state = -1;\n\n    }\n\n\n\n    s->context_initialized = 1;\n\n    s->thread_context[0]   = s;\n\n\n\n    if (s->width && s->height) {\n\n        if (nb_slices > 1) {\n\n            for (i = 1; i < nb_slices; i++) {\n\n                s->thread_context[i] = av_malloc(sizeof(MpegEncContext));\n\n                memcpy(s->thread_context[i], s, sizeof(MpegEncContext));\n\n            }\n\n\n\n            for (i = 0; i < nb_slices; i++) {\n\n                if (init_duplicate_context(s->thread_context[i]) < 0)\n\n                    goto fail;\n\n                    s->thread_context[i]->start_mb_y =\n\n                        (s->mb_height * (i) + nb_slices / 2) / nb_slices;\n\n                    s->thread_context[i]->end_mb_y   =\n\n                        (s->mb_height * (i + 1) + nb_slices / 2) / nb_slices;\n\n            }\n\n        } else {\n\n            if (init_duplicate_context(s) < 0)\n\n                goto fail;\n\n            s->start_mb_y = 0;\n\n            s->end_mb_y   = s->mb_height;\n\n        }\n\n        s->slice_context_count = nb_slices;\n\n    }\n\n\n\n    return 0;\n\n fail:\n\n    ff_MPV_common_end(s);\n\n    return -1;\n\n}\n", "idx": 24647}
{"project": "FFmpeg", "commit_id": "6a69a175e7b5c5393528ed0f5753e41573fa0df2", "target": 1, "func": "static void clear_context(MpegEncContext *s)\n\n{\n\n    int i, j, k;\n\n\n\n    memset(&s->next_picture, 0, sizeof(s->next_picture));\n\n    memset(&s->last_picture, 0, sizeof(s->last_picture));\n\n    memset(&s->current_picture, 0, sizeof(s->current_picture));\n\n    memset(&s->new_picture, 0, sizeof(s->new_picture));\n\n\n\n    memset(s->thread_context, 0, sizeof(s->thread_context));\n\n\n\n    s->me.map = NULL;\n\n    s->me.score_map = NULL;\n\n    s->dct_error_sum = NULL;\n\n    s->block = NULL;\n\n    s->blocks = NULL;\n\n    memset(s->pblocks, 0, sizeof(s->pblocks));\n\n    s->ac_val_base = NULL;\n\n    s->ac_val[0] =\n\n    s->ac_val[1] =\n\n    s->ac_val[2] =NULL;\n\n    s->sc.edge_emu_buffer = NULL;\n\n    s->me.scratchpad = NULL;\n\n    s->me.temp =\n\n    s->sc.rd_scratchpad =\n\n    s->sc.b_scratchpad =\n\n    s->sc.obmc_scratchpad = NULL;\n\n\n\n    s->parse_context.buffer = NULL;\n\n    s->parse_context.buffer_size = 0;\n\n\n    s->bitstream_buffer = NULL;\n\n    s->allocated_bitstream_buffer_size = 0;\n\n    s->picture          = NULL;\n\n    s->mb_type          = NULL;\n\n    s->p_mv_table_base  = NULL;\n\n    s->b_forw_mv_table_base = NULL;\n\n    s->b_back_mv_table_base = NULL;\n\n    s->b_bidir_forw_mv_table_base = NULL;\n\n    s->b_bidir_back_mv_table_base = NULL;\n\n    s->b_direct_mv_table_base = NULL;\n\n    s->p_mv_table            = NULL;\n\n    s->b_forw_mv_table       = NULL;\n\n    s->b_back_mv_table       = NULL;\n\n    s->b_bidir_forw_mv_table = NULL;\n\n    s->b_bidir_back_mv_table = NULL;\n\n    s->b_direct_mv_table     = NULL;\n\n    for (i = 0; i < 2; i++) {\n\n        for (j = 0; j < 2; j++) {\n\n            for (k = 0; k < 2; k++) {\n\n                s->b_field_mv_table_base[i][j][k] = NULL;\n\n                s->b_field_mv_table[i][j][k] = NULL;\n\n            }\n\n            s->b_field_select_table[i][j] = NULL;\n\n            s->p_field_mv_table_base[i][j] = NULL;\n\n            s->p_field_mv_table[i][j] = NULL;\n\n        }\n\n        s->p_field_select_table[i] = NULL;\n\n    }\n\n\n\n    s->dc_val_base = NULL;\n\n    s->coded_block_base = NULL;\n\n    s->mbintra_table = NULL;\n\n    s->cbp_table = NULL;\n\n    s->pred_dir_table = NULL;\n\n\n\n    s->mbskip_table = NULL;\n\n\n\n    s->er.error_status_table = NULL;\n\n    s->er.er_temp_buffer = NULL;\n\n    s->mb_index2xy = NULL;\n\n    s->lambda_table = NULL;\n\n\n\n    s->cplx_tab = NULL;\n\n    s->bits_tab = NULL;\n\n}", "idx": 24651}
{"project": "FFmpeg", "commit_id": "2cbe6bac0337939f023bd1c37a9c455e6d535f3a", "target": 1, "func": "static int blend_frames(AVFilterContext *ctx, int interpolate)\n\n{\n\n    FrameRateContext *s = ctx->priv;\n\n    AVFilterLink *outlink = ctx->outputs[0];\n\n    double interpolate_scene_score = 0;\n\n\n\n    if ((s->flags & FRAMERATE_FLAG_SCD)) {\n\n        if (s->score >= 0.0)\n\n            interpolate_scene_score = s->score;\n\n        else\n\n            interpolate_scene_score = s->score = get_scene_score(ctx, s->f0, s->f1);\n\n        ff_dlog(ctx, \"blend_frames() interpolate scene score:%f\\n\", interpolate_scene_score);\n\n    }\n\n    // decide if the shot-change detection allows us to blend two frames\n\n    if (interpolate_scene_score < s->scene_score) {\n\n        ThreadData td;\n\n        td.copy_src1 = s->f0;\n\n        td.copy_src2 = s->f1;\n\n        td.src2_factor = interpolate;\n\n        td.src1_factor = s->max - td.src2_factor;\n\n\n\n        // get work-space for output frame\n\n        s->work = ff_get_video_buffer(outlink, outlink->w, outlink->h);\n\n        if (!s->work)\n\n            return AVERROR(ENOMEM);\n\n\n\n        av_frame_copy_props(s->work, s->f0);\n\n\n\n        ff_dlog(ctx, \"blend_frames() INTERPOLATE to create work frame\\n\");\n\n        ctx->internal->execute(ctx, filter_slice, &td, NULL, FFMIN(outlink->h, ff_filter_get_nb_threads(ctx)));\n\n        return 1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 24653}
{"project": "FFmpeg", "commit_id": "d05bdba2428dd0c1c5cd3426d69c712b127f996c", "target": 1, "func": "static int rac_get_model256_sym(RangeCoder *c, Model256 *m)\n\n{\n\n    int prob, prob2, helper, val;\n\n    int start, end;\n\n    int ssym;\n\n\n\n    prob2      = c->range;\n\n    c->range >>= MODEL_SCALE;\n\n\n\n    helper     = c->low / c->range;\n\n    ssym       = helper >> MODEL256_SEC_SCALE;\n\n    val        = m->secondary[ssym];\n\n\n\n    end = start = m->secondary[ssym + 1] + 1;\n\n    while (end > val + 1) {\n\n        ssym = (end + val) >> 1;\n\n        if (m->freqs[ssym] <= helper) {\n\n            end = start;\n\n            val = ssym;\n\n        } else {\n\n            end   = (end + val) >> 1;\n\n            start = ssym;\n\n        }\n\n    }\n\n    prob = m->freqs[val] * c->range;\n\n    if (val != 255)\n\n        prob2 = m->freqs[val + 1] * c->range;\n\n\n\n    c->low  -= prob;\n\n    c->range = prob2 - prob;\n\n    if (c->range < RAC_BOTTOM)\n\n        rac_normalise(c);\n\n\n\n    model256_update(m, val);\n\n\n\n    return val;\n\n}\n", "idx": 24654}
{"project": "FFmpeg", "commit_id": "1bfb4587a2e5b25ed15f742149e555efc8f305ae", "target": 1, "func": "static void test_function(const TestStruct test_sample)\n\n{\n\n    int ret, i;\n\n    void **output_data  = NULL;\n\n    AVAudioFifo *afifo  = av_audio_fifo_alloc(test_sample.format, test_sample.nb_ch,\n\n                                            test_sample.nb_samples_pch);\n\n    if (!afifo) {\n\n        ERROR(\"ERROR: av_audio_fifo_alloc returned NULL!\");\n\n    }\n\n    ret = write_samples_to_audio_fifo(afifo, test_sample, test_sample.nb_samples_pch, 0);\n\n    if (ret < 0){\n\n        ERROR(\"ERROR: av_audio_fifo_write failed!\");\n\n    }\n\n    printf(\"written: %d\\n\", ret);\n\n\n\n    ret = write_samples_to_audio_fifo(afifo, test_sample, test_sample.nb_samples_pch, 0);\n\n    if (ret < 0){\n\n        ERROR(\"ERROR: av_audio_fifo_write failed!\");\n\n    }\n\n    printf(\"written: %d\\n\", ret);\n\n    printf(\"remaining samples in audio_fifo: %d\\n\\n\", av_audio_fifo_size(afifo));\n\n\n\n    ret = read_samples_from_audio_fifo(afifo, &output_data, test_sample.nb_samples_pch);\n\n    if (ret < 0){\n\n        ERROR(\"ERROR: av_audio_fifo_read failed!\");\n\n    }\n\n    printf(\"read: %d\\n\", ret);\n\n    print_audio_bytes(&test_sample, output_data, ret);\n\n    printf(\"remaining samples in audio_fifo: %d\\n\\n\", av_audio_fifo_size(afifo));\n\n\n\n    /* test av_audio_fifo_peek */\n\n    ret = av_audio_fifo_peek(afifo, output_data, afifo->nb_samples);\n\n    if (ret < 0){\n\n        ERROR(\"ERROR: av_audio_fifo_peek failed!\");\n\n    }\n\n    printf(\"peek:\\n\");\n\n    print_audio_bytes(&test_sample, output_data, ret);\n\n    printf(\"\\n\");\n\n\n\n    /* test av_audio_fifo_peek_at */\n\n    printf(\"peek_at:\\n\");\n\n    for (i = 0; i < afifo->nb_samples; ++i){\n\n        ret = av_audio_fifo_peek_at(afifo, output_data, 1, i);\n\n        if (ret < 0){\n\n            ERROR(\"ERROR: av_audio_fifo_peek_at failed!\");\n\n        }\n\n        printf(\"%d:\\n\", i);\n\n        print_audio_bytes(&test_sample, output_data, ret);\n\n    }\n\n    printf(\"\\n\");\n\n\n\n    /* test av_audio_fifo_drain */\n\n    ret = av_audio_fifo_drain(afifo, afifo->nb_samples);\n\n    if (ret < 0){\n\n        ERROR(\"ERROR: av_audio_fifo_drain failed!\");\n\n    }\n\n    if (afifo->nb_samples){\n\n        ERROR(\"drain failed to flush all samples in audio_fifo!\");\n\n    }\n\n\n\n    /* deallocate */\n\n    for (i = 0; i < afifo->nb_buffers; ++i){\n\n        av_freep(&output_data[i]);\n\n    }\n\n    av_freep(&output_data);\n\n    av_audio_fifo_free(afifo);\n\n}\n", "idx": 24655}
{"project": "FFmpeg", "commit_id": "134aaa79f7f1ce1df64afc7d10d2b3de77df7b08", "target": 1, "func": "static int parse_bintree(Indeo3DecodeContext *ctx, AVCodecContext *avctx,\n\n                         Plane *plane, int code, Cell *ref_cell,\n\n                         const int depth, const int strip_width)\n\n{\n\n    Cell    curr_cell;\n\n    int     bytes_used;\n\n\n\n    if (depth <= 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Stack overflow (corrupted binary tree)!\\n\");\n\n        return AVERROR_INVALIDDATA; // unwind recursion\n\n    }\n\n\n\n    curr_cell = *ref_cell; // clone parent cell\n\n    if (code == H_SPLIT) {\n\n        SPLIT_CELL(ref_cell->height, curr_cell.height);\n\n        ref_cell->ypos   += curr_cell.height;\n\n        ref_cell->height -= curr_cell.height;\n\n    } else if (code == V_SPLIT) {\n\n        if (curr_cell.width > strip_width) {\n\n            /* split strip */\n\n            curr_cell.width = (curr_cell.width <= (strip_width << 1) ? 1 : 2) * strip_width;\n\n        } else\n\n            SPLIT_CELL(ref_cell->width, curr_cell.width);\n\n        ref_cell->xpos  += curr_cell.width;\n\n        ref_cell->width -= curr_cell.width;\n\n    }\n\n\n\n    while (get_bits_left(&ctx->gb) >= 2) { /* loop until return */\n\n        RESYNC_BITSTREAM;\n\n        switch (code = get_bits(&ctx->gb, 2)) {\n\n        case H_SPLIT:\n\n        case V_SPLIT:\n\n            if (parse_bintree(ctx, avctx, plane, code, &curr_cell, depth - 1, strip_width))\n\n                return AVERROR_INVALIDDATA;\n\n            break;\n\n        case INTRA_NULL:\n\n            if (!curr_cell.tree) { /* MC tree INTRA code */\n\n                curr_cell.mv_ptr = 0; /* mark the current strip as INTRA */\n\n                curr_cell.tree   = 1; /* enter the VQ tree */\n\n            } else { /* VQ tree NULL code */\n\n                RESYNC_BITSTREAM;\n\n                code = get_bits(&ctx->gb, 2);\n\n                if (code >= 2) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"Invalid VQ_NULL code: %d\\n\", code);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                if (code == 1)\n\n                    av_log(avctx, AV_LOG_ERROR, \"SkipCell procedure not implemented yet!\\n\");\n\n\n\n                CHECK_CELL\n\n                if (!curr_cell.mv_ptr)\n\n                    return AVERROR_INVALIDDATA;\n\n                copy_cell(ctx, plane, &curr_cell);\n\n                return 0;\n\n            }\n\n            break;\n\n        case INTER_DATA:\n\n            if (!curr_cell.tree) { /* MC tree INTER code */\n\n                /* get motion vector index and setup the pointer to the mv set */\n\n                if (!ctx->need_resync)\n\n                    ctx->next_cell_data = &ctx->gb.buffer[(get_bits_count(&ctx->gb) + 7) >> 3];\n\n                curr_cell.mv_ptr = &ctx->mc_vectors[*(ctx->next_cell_data++) << 1];\n\n                curr_cell.tree   = 1; /* enter the VQ tree */\n\n                UPDATE_BITPOS(8);\n\n            } else { /* VQ tree DATA code */\n\n                if (!ctx->need_resync)\n\n                    ctx->next_cell_data = &ctx->gb.buffer[(get_bits_count(&ctx->gb) + 7) >> 3];\n\n\n\n                CHECK_CELL\n\n                bytes_used = decode_cell(ctx, avctx, plane, &curr_cell,\n\n                                         ctx->next_cell_data, ctx->last_byte);\n\n                if (bytes_used < 0)\n\n                    return AVERROR_INVALIDDATA;\n\n\n\n                UPDATE_BITPOS(bytes_used << 3);\n\n                ctx->next_cell_data += bytes_used;\n\n                return 0;\n\n            }\n\n            break;\n\n        }\n\n    }//while\n\n\n\n    return AVERROR_INVALIDDATA;\n\n}\n", "idx": 24657}
{"project": "FFmpeg", "commit_id": "e4f85b849913794395bb03dfc09546cd41b10882", "target": 0, "func": "static int parse_chunks(AVFormatContext *s, int mode, int64_t seekts, int *len_ptr)\n\n{\n\n    WtvContext *wtv = s->priv_data;\n\n    ByteIOContext *pb = wtv->pb;\n\n    while (!url_feof(pb)) {\n\n        ff_asf_guid g;\n\n        int len, sid, consumed;\n\n\n\n        ff_get_guid(pb, &g);\n\n        len = get_le32(pb);\n\n        if (len < 32)\n\n            break;\n\n        sid = get_le32(pb) & 0x7FFF;\n\n        url_fskip(pb, 8);\n\n        consumed = 32;\n\n\n\n        if (!ff_guidcmp(g, stream_guid)) {\n\n            if (ff_find_stream_index(s, sid) < 0) {\n\n                ff_asf_guid mediatype, subtype, formattype;\n\n                int size;\n\n                consumed += 20;\n\n                url_fskip(pb, 16);\n\n                if (get_le32(pb)) {\n\n                    url_fskip(pb, 8);\n\n                    ff_get_guid(pb, &mediatype);\n\n                    ff_get_guid(pb, &subtype);\n\n                    url_fskip(pb, 12);\n\n                    ff_get_guid(pb, &formattype);\n\n                    size = get_le32(pb);\n\n                    parse_media_type(s, 0, sid, mediatype, subtype, formattype, size);\n\n                    consumed += 72 + size;\n\n                }\n\n            }\n\n        } else if (!ff_guidcmp(g, stream2_guid)) {\n\n            int stream_index = ff_find_stream_index(s, sid);\n\n            if (stream_index >= 0 && !((WtvStream*)s->streams[stream_index]->priv_data)->seen_data) {\n\n                ff_asf_guid mediatype, subtype, formattype;\n\n                int size;\n\n                url_fskip(pb, 12);\n\n                ff_get_guid(pb, &mediatype);\n\n                ff_get_guid(pb, &subtype);\n\n                url_fskip(pb, 12);\n\n                ff_get_guid(pb, &formattype);\n\n                size = get_le32(pb);\n\n                parse_media_type(s, s->streams[stream_index], sid, mediatype, subtype, formattype, size);\n\n                consumed += 76 + size;\n\n            }\n\n        } else if (!ff_guidcmp(g, EVENTID_AudioDescriptorSpanningEvent) ||\n\n                   !ff_guidcmp(g, EVENTID_CtxADescriptorSpanningEvent) ||\n\n                   !ff_guidcmp(g, EVENTID_CSDescriptorSpanningEvent) ||\n\n                   !ff_guidcmp(g, EVENTID_StreamIDSpanningEvent) ||\n\n                   !ff_guidcmp(g, EVENTID_SubtitleSpanningEvent) ||\n\n                   !ff_guidcmp(g, EVENTID_TeletextSpanningEvent)) {\n\n            int stream_index = ff_find_stream_index(s, sid);\n\n            if (stream_index >= 0) {\n\n                AVStream *st = s->streams[stream_index];\n\n                uint8_t buf[258];\n\n                const uint8_t *pbuf = buf;\n\n                int buf_size;\n\n\n\n                url_fskip(pb, 8);\n\n                consumed += 8;\n\n                if (!ff_guidcmp(g, EVENTID_CtxADescriptorSpanningEvent) ||\n\n                    !ff_guidcmp(g, EVENTID_CSDescriptorSpanningEvent)) {\n\n                    url_fskip(pb, 6);\n\n                    consumed += 6;\n\n                }\n\n\n\n                buf_size = FFMIN(len - consumed, sizeof(buf));\n\n                get_buffer(pb, buf, buf_size);\n\n                consumed += buf_size;\n\n                ff_parse_mpeg2_descriptor(s, st, 0, &pbuf, buf + buf_size, 0, 0, 0, 0);\n\n            }\n\n        } else if (!ff_guidcmp(g, EVENTID_DVBScramblingControlSpanningEvent)) {\n\n            int stream_index = ff_find_stream_index(s, sid);\n\n            if (stream_index >= 0) {\n\n                url_fskip(pb, 12);\n\n                if (get_le32(pb))\n\n                    av_log(s, AV_LOG_WARNING, \"DVB scrambled stream detected (st:%d), decoding will likely fail\\n\", stream_index);\n\n                consumed += 16;\n\n            }\n\n        } else if (!ff_guidcmp(g, EVENTID_LanguageSpanningEvent)) {\n\n            int stream_index = ff_find_stream_index(s, sid);\n\n            if (stream_index >= 0) {\n\n                AVStream *st = s->streams[stream_index];\n\n                uint8_t language[4];\n\n                url_fskip(pb, 12);\n\n                get_buffer(pb, language, 3);\n\n                if (language[0]) {\n\n                    language[3] = 0;\n\n                    av_metadata_set2(&st->metadata, \"language\", language, 0);\n\n                }\n\n                consumed += 15;\n\n            }\n\n        } else if (!ff_guidcmp(g, timestamp_guid)) {\n\n            int stream_index = ff_find_stream_index(s, sid);\n\n            if (stream_index >= 0) {\n\n                url_fskip(pb, 8);\n\n                wtv->pts = get_le64(pb);\n\n                consumed += 16;\n\n                if (wtv->pts == -1)\n\n                    wtv->pts = AV_NOPTS_VALUE;\n\n                else {\n\n                    wtv->last_valid_pts = wtv->pts;\n\n                    if (wtv->epoch == AV_NOPTS_VALUE || wtv->pts < wtv->epoch)\n\n                        wtv->epoch = wtv->pts;\n\n                if (mode == SEEK_TO_PTS && wtv->pts >= seekts) {\n\n#define WTV_PAD8(x) (((x) + 7) & ~7)\n\n                    url_fskip(pb, WTV_PAD8(len) - consumed);\n\n                    return 0;\n\n                }\n\n                }\n\n            }\n\n        } else if (!ff_guidcmp(g, data_guid)) {\n\n            int stream_index = ff_find_stream_index(s, sid);\n\n            if (mode == SEEK_TO_DATA && stream_index >= 0) {\n\n                WtvStream *wst = s->streams[stream_index]->priv_data;\n\n                wst->seen_data = 1;\n\n                if (len_ptr) {\n\n                    *len_ptr = len;\n\n                }\n\n                return stream_index;\n\n            }\n\n        } else if (\n\n            !ff_guidcmp(g, /* DSATTRIB_CAPTURE_STREAMTIME */ (const ff_asf_guid){0x14,0x56,0x1A,0x0C,0xCD,0x30,0x40,0x4F,0xBC,0xBF,0xD0,0x3E,0x52,0x30,0x62,0x07}) ||\n\n            !ff_guidcmp(g, /* DSATTRIB_PicSampleSeq */ (const ff_asf_guid){0x02,0xAE,0x5B,0x2F,0x8F,0x7B,0x60,0x4F,0x82,0xD6,0xE4,0xEA,0x2F,0x1F,0x4C,0x99}) ||\n\n            !ff_guidcmp(g, /* DSATTRIB_TRANSPORT_PROPERTIES */ (const ff_asf_guid){0x12,0xF6,0x22,0xB6,0xAD,0x47,0x71,0x46,0xAD,0x6C,0x05,0xA9,0x8E,0x65,0xDE,0x3A}) ||\n\n            !ff_guidcmp(g, /* dvr_ms_vid_frame_rep_data */ (const ff_asf_guid){0xCC,0x32,0x64,0xDD,0x29,0xE2,0xDB,0x40,0x80,0xF6,0xD2,0x63,0x28,0xD2,0x76,0x1F}) ||\n\n            !ff_guidcmp(g, /* EVENTID_AudioTypeSpanningEvent */ (const ff_asf_guid){0xBE,0xBF,0x1C,0x50,0x49,0xB8,0xCE,0x42,0x9B,0xE9,0x3D,0xB8,0x69,0xFB,0x82,0xB3}) ||\n\n            !ff_guidcmp(g, /* EVENTID_ChannelChangeSpanningEvent */ (const ff_asf_guid){0xE5,0xC5,0x67,0x90,0x5C,0x4C,0x05,0x42,0x86,0xC8,0x7A,0xFE,0x20,0xFE,0x1E,0xFA}) ||\n\n            !ff_guidcmp(g, /* EVENTID_ChannelInfoSpanningEvent */ (const ff_asf_guid){0x80,0x6D,0xF3,0x41,0x32,0x41,0xC2,0x4C,0xB1,0x21,0x01,0xA4,0x32,0x19,0xD8,0x1B}) ||\n\n            !ff_guidcmp(g, /* EVENTID_ChannelTypeSpanningEvent */ (const ff_asf_guid){0x51,0x1D,0xAB,0x72,0xD2,0x87,0x9B,0x48,0xBA,0x11,0x0E,0x08,0xDC,0x21,0x02,0x43}) ||\n\n            !ff_guidcmp(g, /* EVENTID_PIDListSpanningEvent */ (const ff_asf_guid){0x65,0x8F,0xFC,0x47,0xBB,0xE2,0x34,0x46,0x9C,0xEF,0xFD,0xBF,0xE6,0x26,0x1D,0x5C}) ||\n\n            !ff_guidcmp(g, /* EVENTID_SignalAndServiceStatusSpanningEvent */ (const ff_asf_guid){0xCB,0xC5,0x68,0x80,0x04,0x3C,0x2B,0x49,0xB4,0x7D,0x03,0x08,0x82,0x0D,0xCE,0x51}) ||\n\n            !ff_guidcmp(g, /* EVENTID_StreamTypeSpanningEvent */ (const ff_asf_guid){0xBC,0x2E,0xAF,0x82,0xA6,0x30,0x64,0x42,0xA8,0x0B,0xAD,0x2E,0x13,0x72,0xAC,0x60}) ||\n\n            !ff_guidcmp(g, (const ff_asf_guid){0x1E,0xBE,0xC3,0xC5,0x43,0x92,0xDC,0x11,0x85,0xE5,0x00,0x12,0x3F,0x6F,0x73,0xB9}) ||\n\n            !ff_guidcmp(g, (const ff_asf_guid){0x3B,0x86,0xA2,0xB1,0xEB,0x1E,0xC3,0x44,0x8C,0x88,0x1C,0xA3,0xFF,0xE3,0xE7,0x6A}) ||\n\n            !ff_guidcmp(g, (const ff_asf_guid){0x4E,0x7F,0x4C,0x5B,0xC4,0xD0,0x38,0x4B,0xA8,0x3E,0x21,0x7F,0x7B,0xBF,0x52,0xE7}) ||\n\n            !ff_guidcmp(g, (const ff_asf_guid){0x63,0x36,0xEB,0xFE,0xA1,0x7E,0xD9,0x11,0x83,0x08,0x00,0x07,0xE9,0x5E,0xAD,0x8D}) ||\n\n            !ff_guidcmp(g, (const ff_asf_guid){0x70,0xE9,0xF1,0xF8,0x89,0xA4,0x4C,0x4D,0x83,0x73,0xB8,0x12,0xE0,0xD5,0xF8,0x1E}) ||\n\n            !ff_guidcmp(g, (const ff_asf_guid){0x96,0xC3,0xD2,0xC2,0x7E,0x9A,0xDA,0x11,0x8B,0xF7,0x00,0x07,0xE9,0x5E,0xAD,0x8D}) ||\n\n            !ff_guidcmp(g, (const ff_asf_guid){0x97,0xC3,0xD2,0xC2,0x7E,0x9A,0xDA,0x11,0x8B,0xF7,0x00,0x07,0xE9,0x5E,0xAD,0x8D}) ||\n\n            !ff_guidcmp(g, (const ff_asf_guid){0xA1,0xC3,0xD2,0xC2,0x7E,0x9A,0xDA,0x11,0x8B,0xF7,0x00,0x07,0xE9,0x5E,0xAD,0x8D})) {\n\n            //ignore known guids\n\n        } else\n\n            av_log(s, AV_LOG_WARNING, \"unsupported chunk:\"PRI_GUID\"\\n\", ARG_GUID(g));\n\n\n\n        url_fskip(pb, WTV_PAD8(len) - consumed);\n\n    }\n\n    return AVERROR_EOF;\n\n}\n", "idx": 24658}
{"project": "FFmpeg", "commit_id": "ae43c10e36197000de2f3cc99ea35727ce98a796", "target": 0, "func": "int ff_replaygain_export(AVStream *st, AVDictionary *metadata)\n\n{\n\n    const AVDictionaryEntry *tg, *tp, *ag, *ap;\n\n\n\n    tg = av_dict_get(metadata, \"REPLAYGAIN_TRACK_GAIN\", NULL, 0);\n\n    tp = av_dict_get(metadata, \"REPLAYGAIN_TRACK_PEAK\", NULL, 0);\n\n    ag = av_dict_get(metadata, \"REPLAYGAIN_ALBUM_GAIN\", NULL, 0);\n\n    ap = av_dict_get(metadata, \"REPLAYGAIN_ALBUM_PEAK\", NULL, 0);\n\n\n\n    return replaygain_export(st,\n\n                             tg ? tg->value : NULL,\n\n                             tp ? tp->value : NULL,\n\n                             ag ? ag->value : NULL,\n\n                             ap ? ap->value : NULL);\n\n}\n", "idx": 24659}
{"project": "FFmpeg", "commit_id": "4782c4284fa3856a9b6910fe5ff6e4fb1c65b58c", "target": 1, "func": "static void ac3_decode_transform_coeffs_ch(AC3DecodeContext *s, int ch_index, mant_groups *m)\n\n{\n\n    int start_freq = s->start_freq[ch_index];\n\n    int end_freq   = s->end_freq[ch_index];\n\n    uint8_t *baps  = s->bap[ch_index];\n\n    int8_t *exps   = s->dexps[ch_index];\n\n    int32_t *coeffs = s->fixed_coeffs[ch_index];\n\n    int dither     = (ch_index == CPL_CH) || s->dither_flag[ch_index];\n\n    GetBitContext *gbc = &s->gbc;\n\n    int freq;\n\n\n\n    for (freq = start_freq; freq < end_freq; freq++) {\n\n        int bap = baps[freq];\n\n        int mantissa;\n\n        switch (bap) {\n\n        case 0:\n\n            /* random noise with approximate range of -0.707 to 0.707 */\n\n            if (dither)\n\n                mantissa = (((av_lfg_get(&s->dith_state)>>8)*181)>>8) - 5931008;\n\n            else\n\n                mantissa = 0;\n\n            break;\n\n        case 1:\n\n            if (m->b1) {\n\n                m->b1--;\n\n                mantissa = m->b1_mant[m->b1];\n\n            } else {\n\n                int bits      = get_bits(gbc, 5);\n\n                mantissa      = b1_mantissas[bits][0];\n\n                m->b1_mant[1] = b1_mantissas[bits][1];\n\n                m->b1_mant[0] = b1_mantissas[bits][2];\n\n                m->b1         = 2;\n\n\n            break;\n\n        case 2:\n\n            if (m->b2) {\n\n                m->b2--;\n\n                mantissa = m->b2_mant[m->b2];\n\n            } else {\n\n                int bits      = get_bits(gbc, 7);\n\n                mantissa      = b2_mantissas[bits][0];\n\n                m->b2_mant[1] = b2_mantissas[bits][1];\n\n                m->b2_mant[0] = b2_mantissas[bits][2];\n\n                m->b2         = 2;\n\n\n            break;\n\n        case 3:\n\n            mantissa = b3_mantissas[get_bits(gbc, 3)];\n\n            break;\n\n        case 4:\n\n            if (m->b4) {\n\n                m->b4 = 0;\n\n                mantissa = m->b4_mant;\n\n            } else {\n\n                int bits   = get_bits(gbc, 7);\n\n                mantissa   = b4_mantissas[bits][0];\n\n                m->b4_mant = b4_mantissas[bits][1];\n\n                m->b4      = 1;\n\n\n            break;\n\n        case 5:\n\n            mantissa = b5_mantissas[get_bits(gbc, 4)];\n\n            break;\n\n        default: /* 6 to 15 */\n\n            /* Shift mantissa and sign-extend it. */\n\n\n\n\n\n            mantissa = get_sbits(gbc, quantization_tab[bap]);\n\n            mantissa <<= 24 - quantization_tab[bap];\n\n            break;\n\n\n        coeffs[freq] = mantissa >> exps[freq];\n\n", "idx": 24660}
{"project": "FFmpeg", "commit_id": "7a7ca3cc2f43e7a7b61fdad8200b365ff0977bd2", "target": 1, "func": "static void draw_bar(TestSourceContext *test, const uint8_t color[4],\n\n                     unsigned x, unsigned y, unsigned w, unsigned h,\n\n                     AVFrame *frame)\n\n{\n\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(frame->format);\n\n    uint8_t *p, *p0;\n\n    int plane;\n\n\n\n    x = FFMIN(x, test->w - 1);\n\n    y = FFMIN(y, test->h - 1);\n\n    w = FFMIN(w, test->w - x);\n\n    h = FFMIN(h, test->h - y);\n\n\n\n    av_assert0(x + w <= test->w);\n\n    av_assert0(y + h <= test->h);\n\n\n\n    for (plane = 0; frame->data[plane]; plane++) {\n\n        const int c = color[plane];\n\n        const int linesize = frame->linesize[plane];\n\n        int i, px, py, pw, ph;\n\n\n\n        if (plane == 1 || plane == 2) {\n\n            px = x >> desc->log2_chroma_w;\n\n            pw = w >> desc->log2_chroma_w;\n\n            py = y >> desc->log2_chroma_h;\n\n            ph = h >> desc->log2_chroma_h;\n\n        } else {\n\n            px = x;\n\n            pw = w;\n\n            py = y;\n\n            ph = h;\n\n        }\n\n\n\n        p0 = p = frame->data[plane] + py * linesize + px;\n\n        memset(p, c, pw);\n\n        p += linesize;\n\n        for (i = 1; i < ph; i++, p += linesize)\n\n            memcpy(p, p0, pw);\n\n    }\n\n}\n", "idx": 24664}
{"project": "FFmpeg", "commit_id": "05e161952954acf247e0fd1fdef00559675c4d4d", "target": 1, "func": "static inline int64_t gb_get_v(GetBitContext *gb)\n\n{\n\n    int64_t v = 0;\n\n    int bits = 0;\n\n    while(get_bits1(gb) && bits < 64-7){\n\n        v <<= 7;\n\n        v |= get_bits(gb, 7);\n\n        bits += 7;\n\n    }\n\n    v <<= 7;\n\n    v |= get_bits(gb, 7);\n\n\n\n    return v;\n\n}\n", "idx": 24666}
{"project": "FFmpeg", "commit_id": "e6bc38fd49c94726b45d5d5cc2b756ad8ec49ee0", "target": 1, "func": "static void ff_wmv2_idct_put_c(uint8_t *dest, int line_size, DCTELEM *block)\n\n{\n\n    ff_wmv2_idct_c(block);\n\n    put_pixels_clamped_c(block, dest, line_size);\n\n}\n", "idx": 24668}
{"project": "FFmpeg", "commit_id": "8370e426e42f2e4b9d14a1fb8107ecfe5163ce7f", "target": 1, "func": "static int unpack_vlcs(Vp3DecodeContext *s, GetBitContext *gb,\n\n                        VLC *table, int coeff_index,\n\n                        int plane,\n\n                        int eob_run)\n\n{\n\n    int i, j = 0;\n\n    int token;\n\n    int zero_run = 0;\n\n    DCTELEM coeff = 0;\n\n    int bits_to_get;\n\n    int blocks_ended;\n\n    int coeff_i = 0;\n\n    int num_coeffs = s->num_coded_frags[plane][coeff_index];\n\n    int16_t *dct_tokens = s->dct_tokens[plane][coeff_index];\n\n\n\n    /* local references to structure members to avoid repeated deferences */\n\n    int *coded_fragment_list = s->coded_fragment_list[plane];\n\n    Vp3Fragment *all_fragments = s->all_fragments;\n\n    VLC_TYPE (*vlc_table)[2] = table->table;\n\n\n\n    if (num_coeffs < 0)\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid number of coefficents at level %d\\n\", coeff_index);\n\n\n\n    if (eob_run > num_coeffs) {\n\n        coeff_i = blocks_ended = num_coeffs;\n\n        eob_run -= num_coeffs;\n\n    } else {\n\n        coeff_i = blocks_ended = eob_run;\n\n        eob_run = 0;\n\n    }\n\n\n\n    // insert fake EOB token to cover the split between planes or zzi\n\n    if (blocks_ended)\n\n        dct_tokens[j++] = blocks_ended << 2;\n\n\n\n    while (coeff_i < num_coeffs && get_bits_left(gb) > 0) {\n\n            /* decode a VLC into a token */\n\n            token = get_vlc2(gb, vlc_table, 11, 3);\n\n            /* use the token to get a zero run, a coefficient, and an eob run */\n\n            if (token <= 6) {\n\n                eob_run = eob_run_base[token];\n\n                if (eob_run_get_bits[token])\n\n                    eob_run += get_bits(gb, eob_run_get_bits[token]);\n\n\n\n                // record only the number of blocks ended in this plane,\n\n                // any spill will be recorded in the next plane.\n\n                if (eob_run > num_coeffs - coeff_i) {\n\n                    dct_tokens[j++] = TOKEN_EOB(num_coeffs - coeff_i);\n\n                    blocks_ended   += num_coeffs - coeff_i;\n\n                    eob_run        -= num_coeffs - coeff_i;\n\n                    coeff_i         = num_coeffs;\n\n                } else {\n\n                    dct_tokens[j++] = TOKEN_EOB(eob_run);\n\n                    blocks_ended   += eob_run;\n\n                    coeff_i        += eob_run;\n\n                    eob_run = 0;\n\n                }\n\n            } else {\n\n                bits_to_get = coeff_get_bits[token];\n\n                if (bits_to_get)\n\n                    bits_to_get = get_bits(gb, bits_to_get);\n\n                coeff = coeff_tables[token][bits_to_get];\n\n\n\n                zero_run = zero_run_base[token];\n\n                if (zero_run_get_bits[token])\n\n                    zero_run += get_bits(gb, zero_run_get_bits[token]);\n\n\n\n                if (zero_run) {\n\n                    dct_tokens[j++] = TOKEN_ZERO_RUN(coeff, zero_run);\n\n                } else {\n\n                    // Save DC into the fragment structure. DC prediction is\n\n                    // done in raster order, so the actual DC can't be in with\n\n                    // other tokens. We still need the token in dct_tokens[]\n\n                    // however, or else the structure collapses on itself.\n\n                    if (!coeff_index)\n\n                        all_fragments[coded_fragment_list[coeff_i]].dc = coeff;\n\n\n\n                    dct_tokens[j++] = TOKEN_COEFF(coeff);\n\n                }\n\n\n\n                if (coeff_index + zero_run > 64) {\n\n                    av_log(s->avctx, AV_LOG_DEBUG, \"Invalid zero run of %d with\"\n\n                           \" %d coeffs left\\n\", zero_run, 64-coeff_index);\n\n                    zero_run = 64 - coeff_index;\n\n                }\n\n\n\n                // zero runs code multiple coefficients,\n\n                // so don't try to decode coeffs for those higher levels\n\n                for (i = coeff_index+1; i <= coeff_index+zero_run; i++)\n\n                    s->num_coded_frags[plane][i]--;\n\n                coeff_i++;\n\n            }\n\n    }\n\n\n\n    if (blocks_ended > s->num_coded_frags[plane][coeff_index])\n\n        av_log(s->avctx, AV_LOG_ERROR, \"More blocks ended than coded!\\n\");\n\n\n\n    // decrement the number of blocks that have higher coeffecients for each\n\n    // EOB run at this level\n\n    if (blocks_ended)\n\n        for (i = coeff_index+1; i < 64; i++)\n\n            s->num_coded_frags[plane][i] -= blocks_ended;\n\n\n\n    // setup the next buffer\n\n    if (plane < 2)\n\n        s->dct_tokens[plane+1][coeff_index] = dct_tokens + j;\n\n    else if (coeff_index < 63)\n\n        s->dct_tokens[0][coeff_index+1] = dct_tokens + j;\n\n\n\n    return eob_run;\n\n}\n", "idx": 24669}
{"project": "FFmpeg", "commit_id": "1dba8371d93cf1c83bcd5c432d921905206a60f3", "target": 0, "func": "int ff_copy_whitelists(AVFormatContext *dst, AVFormatContext *src)\n\n{\n\n    av_assert0(!dst->codec_whitelist && !dst->format_whitelist);\n\n    dst-> codec_whitelist = av_strdup(src->codec_whitelist);\n\n    dst->format_whitelist = av_strdup(src->format_whitelist);\n\n    if (   (src-> codec_whitelist && !dst-> codec_whitelist)\n\n        || (src->format_whitelist && !dst->format_whitelist)) {\n\n        av_log(dst, AV_LOG_ERROR, \"Failed to duplicate whitelist\\n\");\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    return 0;\n\n}\n", "idx": 24670}
{"project": "FFmpeg", "commit_id": "ca32f7f2083f9ededd1d9964ed065e0ad07a01e0", "target": 0, "func": "static void init_dequant4_coeff_table(H264Context *h){\n\n    int i,j,q,x;\n\n    const int transpose = (h->h264dsp.h264_idct_add != ff_h264_idct_add_c); //FIXME ugly\n\n    for(i=0; i<6; i++ ){\n\n        h->dequant4_coeff[i] = h->dequant4_buffer[i];\n\n        for(j=0; j<i; j++){\n\n            if(!memcmp(h->pps.scaling_matrix4[j], h->pps.scaling_matrix4[i], 16*sizeof(uint8_t))){\n\n                h->dequant4_coeff[i] = h->dequant4_buffer[j];\n\n                break;\n\n            }\n\n        }\n\n        if(j<i)\n\n            continue;\n\n\n\n        for(q=0; q<52; q++){\n\n            int shift = div6[q] + 2;\n\n            int idx = rem6[q];\n\n            for(x=0; x<16; x++)\n\n                h->dequant4_coeff[i][q][transpose ? (x>>2)|((x<<2)&0xF) : x] =\n\n                    ((uint32_t)dequant4_coeff_init[idx][(x&1) + ((x>>2)&1)] *\n\n                    h->pps.scaling_matrix4[i][x]) << shift;\n\n        }\n\n    }\n\n}\n", "idx": 24671}
{"project": "FFmpeg", "commit_id": "3c895fc098f7637f6d5ec3a9d6766e724a8b9e41", "target": 0, "func": "static int mpeg_mux_write_packet(AVFormatContext *ctx, AVPacket *pkt)\n\n{\n\n    MpegMuxContext *s = ctx->priv_data;\n\n    int stream_index= pkt->stream_index;\n\n    int size= pkt->size;\n\n    uint8_t *buf= pkt->data;\n\n    AVStream *st = ctx->streams[stream_index];\n\n    StreamInfo *stream = st->priv_data;\n\n    int64_t pts, dts, new_start_pts, new_start_dts;\n\n    int len, avail_size;\n\n    \n\n    //XXX/FIXME this is and always was broken\n\n//    compute_pts_dts(st, &pts, &dts, pkt->pts);\n\n\n\n    pts= pkt->pts;\n\n    dts= pkt->dts;\n\n\n\n    if(s->is_svcd) {\n\n        /* offset pts and dts slightly into the future to be able\n\n           to do the compatibility fix below.*/\n\n        pts = (pts + 2) & ((1LL << 33) - 1);\n\n        dts = (dts + 2) & ((1LL << 33) - 1);\n\n\n\n        if (stream->packet_number == 0 && dts == pts)\n\n            /* For the very first packet we want to force the DTS to be included.\n\n               This increases compatibility with lots of DVD players.\n\n               Since the MPEG-2 standard mandates that DTS is only written when\n\n               it is different from PTS we have to move it slightly into the past.*/\n\n            dts = (dts - 2) & ((1LL << 33) - 1);\n\n    }\n\n    if(s->is_vcd) {\n\n        /* We have to offset the PTS, so that it is consistent with the SCR.\n\n           SCR starts at 36000, but the first two packs contain only padding\n\n           and the first pack from the other stream, respectively, may also have\n\n           been written before.\n\n           So the real data starts at SCR 36000+3*1200. */\n\n        pts = (pts + 36000 + 3600) & ((1LL << 33) - 1);\n\n        dts = (dts + 36000 + 3600) & ((1LL << 33) - 1);\n\n    }\n\n    \n\n#if 0\n\n    update_scr(ctx,stream_index,pts);\n\n\n\n    printf(\"%d: pts=%0.3f dts=%0.3f scr=%0.3f\\n\", \n\n           stream_index, \n\n           pts / 90000.0, \n\n           dts / 90000.0, \n\n           s->last_scr / 90000.0);\n\n#endif\n\n    \n\n    /* we assume here that pts != AV_NOPTS_VALUE */\n\n    new_start_pts = stream->start_pts;\n\n    new_start_dts = stream->start_dts;\n\n    \n\n    if (stream->start_pts == AV_NOPTS_VALUE) {\n\n        new_start_pts = pts;\n\n        new_start_dts = dts;\n\n    }\n\n    avail_size = get_packet_payload_size(ctx, stream_index,\n\n                                         new_start_pts, \n\n                                         new_start_dts);\n\n    if (stream->buffer_ptr >= avail_size) {\n\n\n\n        update_scr(ctx,stream_index,stream->start_pts);\n\n\n\n        /* unlikely case: outputing the pts or dts increase the packet\n\n           size so that we cannot write the start of the next\n\n           packet. In this case, we must flush the current packet with\n\n           padding.\n\n           Note: this always happens for the first audio and video packet\n\n           in a VCD file, since they do not carry any data.*/\n\n        flush_packet(ctx, stream_index,\n\n                     stream->start_pts, stream->start_dts, s->last_scr);\n\n        stream->buffer_ptr = 0;\n\n    }\n\n    stream->start_pts = new_start_pts;\n\n    stream->start_dts = new_start_dts;\n\n    stream->nb_frames++;\n\n    if (stream->frame_start_offset == 0)\n\n        stream->frame_start_offset = stream->buffer_ptr;\n\n    while (size > 0) {\n\n        avail_size = get_packet_payload_size(ctx, stream_index,\n\n                                             stream->start_pts, \n\n                                             stream->start_dts);\n\n        len = avail_size - stream->buffer_ptr;\n\n        if (len > size)\n\n            len = size;\n\n        memcpy(stream->buffer + stream->buffer_ptr, buf, len);\n\n        stream->buffer_ptr += len;\n\n        buf += len;\n\n        size -= len;\n\n        if (stream->buffer_ptr >= avail_size) {\n\n\n\n            update_scr(ctx,stream_index,stream->start_pts);\n\n\n\n            /* if packet full, we send it now */\n\n            flush_packet(ctx, stream_index,\n\n                         stream->start_pts, stream->start_dts, s->last_scr);\n\n            stream->buffer_ptr = 0;\n\n\n\n            if (s->is_vcd) {\n\n                /* Write one or more padding sectors, if necessary, to reach\n\n                   the constant overall bitrate.*/\n\n                int vcd_pad_bytes;\n\n            \n\n                while((vcd_pad_bytes = get_vcd_padding_size(ctx,stream->start_pts) ) >= s->packet_size)\n\n                    put_vcd_padding_sector(ctx);\n\n            }\n\n\n\n            /* Make sure only the FIRST pes packet for this frame has\n\n               a timestamp */\n\n            stream->start_pts = AV_NOPTS_VALUE;\n\n            stream->start_dts = AV_NOPTS_VALUE;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24672}
{"project": "FFmpeg", "commit_id": "34a8dcd031d637273cdea021e5a79cf720c4c51c", "target": 0, "func": "static int decode_end(AVCodecContext * avctx)\n\n{\n\n    KmvcContext *const c = (KmvcContext *) avctx->priv_data;\n\n\n\n    if (c->frm0)\n\n        av_free(c->frm0);\n\n    if (c->frm1)\n\n        av_free(c->frm1);\n\n    if (c->pic.data[0])\n\n        avctx->release_buffer(avctx, &c->pic);\n\n\n\n    return 0;\n\n}\n", "idx": 24673}
{"project": "FFmpeg", "commit_id": "7ebb3022297aa00afda6800105684b8303f2608e", "target": 0, "func": "SwsFilter *sws_getDefaultFilter(float lumaGBlur, float chromaGBlur,\n\n                                float lumaSharpen, float chromaSharpen,\n\n                                float chromaHShift, float chromaVShift,\n\n                                int verbose)\n\n{\n\n    SwsFilter *filter = av_malloc(sizeof(SwsFilter));\n\n    if (!filter)\n\n        return NULL;\n\n\n\n    if (lumaGBlur != 0.0) {\n\n        filter->lumH = sws_getGaussianVec(lumaGBlur, 3.0);\n\n        filter->lumV = sws_getGaussianVec(lumaGBlur, 3.0);\n\n    } else {\n\n        filter->lumH = sws_getIdentityVec();\n\n        filter->lumV = sws_getIdentityVec();\n\n    }\n\n\n\n    if (chromaGBlur != 0.0) {\n\n        filter->chrH = sws_getGaussianVec(chromaGBlur, 3.0);\n\n        filter->chrV = sws_getGaussianVec(chromaGBlur, 3.0);\n\n    } else {\n\n        filter->chrH = sws_getIdentityVec();\n\n        filter->chrV = sws_getIdentityVec();\n\n    }\n\n\n\n    if (!filter->lumH || !filter->lumV || !filter->chrH || !filter->chrV) {\n\n        sws_freeVec(filter->lumH);\n\n        sws_freeVec(filter->lumV);\n\n        sws_freeVec(filter->chrH);\n\n        sws_freeVec(filter->chrV);\n\n        av_freep(&filter);\n\n        return NULL;\n\n    }\n\n\n\n    if (chromaSharpen != 0.0) {\n\n        SwsVector *id = sws_getIdentityVec();\n\n        sws_scaleVec(filter->chrH, -chromaSharpen);\n\n        sws_scaleVec(filter->chrV, -chromaSharpen);\n\n        sws_addVec(filter->chrH, id);\n\n        sws_addVec(filter->chrV, id);\n\n        sws_freeVec(id);\n\n    }\n\n\n\n    if (lumaSharpen != 0.0) {\n\n        SwsVector *id = sws_getIdentityVec();\n\n        sws_scaleVec(filter->lumH, -lumaSharpen);\n\n        sws_scaleVec(filter->lumV, -lumaSharpen);\n\n        sws_addVec(filter->lumH, id);\n\n        sws_addVec(filter->lumV, id);\n\n        sws_freeVec(id);\n\n    }\n\n\n\n    if (chromaHShift != 0.0)\n\n        sws_shiftVec(filter->chrH, (int)(chromaHShift + 0.5));\n\n\n\n    if (chromaVShift != 0.0)\n\n        sws_shiftVec(filter->chrV, (int)(chromaVShift + 0.5));\n\n\n\n    sws_normalizeVec(filter->chrH, 1.0);\n\n    sws_normalizeVec(filter->chrV, 1.0);\n\n    sws_normalizeVec(filter->lumH, 1.0);\n\n    sws_normalizeVec(filter->lumV, 1.0);\n\n\n\n    if (verbose)\n\n        sws_printVec2(filter->chrH, NULL, AV_LOG_DEBUG);\n\n    if (verbose)\n\n        sws_printVec2(filter->lumH, NULL, AV_LOG_DEBUG);\n\n\n\n    return filter;\n\n}\n", "idx": 24674}
{"project": "FFmpeg", "commit_id": "e2e6c8799b3c4a61b8be36c84c5e5e15c49a31cd", "target": 0, "func": "static int decode_frame(AVCodecContext * avctx, void *data, int *data_size,\n\n                        AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf  = avpkt->data;\n\n    int buf_size        = avpkt->size;\n\n    MPADecodeContext *s = avctx->priv_data;\n\n    uint32_t header;\n\n    int out_size;\n\n    OUT_INT *out_samples = data;\n\n\n\n    if (buf_size < HEADER_SIZE)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    header = AV_RB32(buf);\n\n    if (ff_mpa_check_header(header) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Header missing\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (avpriv_mpegaudio_decode_header((MPADecodeHeader *)s, header) == 1) {\n\n        /* free format: prepare to compute frame size */\n\n        s->frame_size = -1;\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    /* update codec info */\n\n    avctx->channels       = s->nb_channels;\n\n    avctx->channel_layout = s->nb_channels == 1 ? AV_CH_LAYOUT_MONO : AV_CH_LAYOUT_STEREO;\n\n    if (!avctx->bit_rate)\n\n        avctx->bit_rate = s->bit_rate;\n\n    avctx->sub_id = s->layer;\n\n\n\n    if (*data_size < 1152 * avctx->channels * sizeof(OUT_INT))\n\n        return AVERROR(EINVAL);\n\n    *data_size = 0;\n\n\n\n    if (s->frame_size <= 0 || s->frame_size > buf_size) {\n\n        av_log(avctx, AV_LOG_ERROR, \"incomplete frame\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    } else if (s->frame_size < buf_size) {\n\n        av_log(avctx, AV_LOG_ERROR, \"incorrect frame size\\n\");\n\n        buf_size= s->frame_size;\n\n    }\n\n\n\n    out_size = mp_decode_frame(s, out_samples, buf, buf_size);\n\n    if (out_size >= 0) {\n\n        *data_size         = out_size;\n\n        avctx->sample_rate = s->sample_rate;\n\n        //FIXME maybe move the other codec info stuff from above here too\n\n    } else {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error while decoding MPEG audio frame.\\n\");\n\n        /* Only return an error if the bad frame makes up the whole packet.\n\n           If there is more data in the packet, just consume the bad frame\n\n           instead of returning an error, which would discard the whole\n\n           packet. */\n\n        if (buf_size == avpkt->size)\n\n            return out_size;\n\n    }\n\n    s->frame_size = 0;\n\n    return buf_size;\n\n}\n", "idx": 24675}
{"project": "FFmpeg", "commit_id": "5a08ba5381cf8d46034440163e71cd95748beceb", "target": 0, "func": "static void decode_interframe_v4(AVCodecContext *avctx, uint8_t *src, uint32_t size)\n\n{\n\n    Hnm4VideoContext *hnm = avctx->priv_data;\n\n    GetByteContext gb;\n\n    uint32_t writeoffset = 0, count, left, offset;\n\n    uint8_t tag, previous, backline, backward, swap;\n\n\n\n    bytestream2_init(&gb, src, size);\n\n\n\n    while (bytestream2_tell(&gb) < size) {\n\n        count = bytestream2_peek_byte(&gb) & 0x1F;\n\n        if (count == 0) {\n\n            tag = bytestream2_get_byte(&gb) & 0xE0;\n\n            tag = tag >> 5;\n\n            if (tag == 0) {\n\n                hnm->current[writeoffset++] = bytestream2_get_byte(&gb);\n\n                hnm->current[writeoffset++] = bytestream2_get_byte(&gb);\n\n            } else if (tag == 1) {\n\n                writeoffset += bytestream2_get_byte(&gb) * 2;\n\n            } else if (tag == 2) {\n\n                count = bytestream2_get_le16(&gb);\n\n                count *= 2;\n\n                writeoffset += count;\n\n            } else if (tag == 3) {\n\n                count = bytestream2_get_byte(&gb) * 2;\n\n                while (count > 0) {\n\n                    hnm->current[writeoffset++] = bytestream2_peek_byte(&gb);\n\n                    count--;\n\n                }\n\n                bytestream2_skip(&gb, 1);\n\n            } else {\n\n                break;\n\n            }\n\n        } else {\n\n            previous = bytestream2_peek_byte(&gb) & 0x20;\n\n            backline = bytestream2_peek_byte(&gb) & 0x40;\n\n            backward = bytestream2_peek_byte(&gb) & 0x80;\n\n            bytestream2_skip(&gb, 1);\n\n            swap   = bytestream2_peek_byte(&gb) & 0x01;\n\n            offset = bytestream2_get_le16(&gb);\n\n            offset = (offset >> 1) & 0x7FFF;\n\n            offset = writeoffset + (offset * 2) - 0x8000;\n\n\n\n            left = count;\n\n\n\n            if (!backward && offset + count >= hnm->width * hnm->height) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Attempting to read out of bounds\");\n\n                break;\n\n            } else if (backward && offset >= hnm->width * hnm->height) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Attempting to read out of bounds\");\n\n                break;\n\n            } else if (writeoffset + count >= hnm->width * hnm->height) {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"Attempting to write out of bounds\");\n\n                break;\n\n            }\n\n\n\n            if (previous) {\n\n                while (left > 0) {\n\n                    if (backline) {\n\n                        hnm->current[writeoffset++] = hnm->previous[offset - (2 * hnm->width) + 1];\n\n                        hnm->current[writeoffset++] = hnm->previous[offset++];\n\n                        offset++;\n\n                    } else {\n\n                        hnm->current[writeoffset++] = hnm->previous[offset++];\n\n                        hnm->current[writeoffset++] = hnm->previous[offset++];\n\n                    }\n\n                    if (backward)\n\n                        offset -= 4;\n\n                    left--;\n\n                }\n\n            } else {\n\n                while (left > 0) {\n\n                    if (backline) {\n\n                        hnm->current[writeoffset++] = hnm->current[offset - (2 * hnm->width) + 1];\n\n                        hnm->current[writeoffset++] = hnm->current[offset++];\n\n                        offset++;\n\n                    } else {\n\n                        hnm->current[writeoffset++] = hnm->current[offset++];\n\n                        hnm->current[writeoffset++] = hnm->current[offset++];\n\n                    }\n\n                    if (backward)\n\n                        offset -= 4;\n\n                    left--;\n\n                }\n\n            }\n\n\n\n            if (swap) {\n\n                left         = count;\n\n                writeoffset -= count * 2;\n\n                while (left > 0) {\n\n                    swap = hnm->current[writeoffset];\n\n                    hnm->current[writeoffset] = hnm->current[writeoffset + 1];\n\n                    hnm->current[writeoffset + 1] = swap;\n\n                    left--;\n\n                    writeoffset += 2;\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 24677}
{"project": "FFmpeg", "commit_id": "1d16a1cf99488f16492b1bb48e023f4da8377e07", "target": 0, "func": "static void ff_h264_idct_add16_mmx2(uint8_t *dst, const int *block_offset, DCTELEM *block, int stride, const uint8_t nnzc[6*8]){\n\n    int i;\n\n    for(i=0; i<16; i++){\n\n        int nnz = nnzc[ scan8[i] ];\n\n        if(nnz){\n\n            if(nnz==1 && block[i*16]) ff_h264_idct_dc_add_mmx2(dst + block_offset[i], block + i*16, stride);\n\n            else                      ff_h264_idct_add_mmx    (dst + block_offset[i], block + i*16, stride);\n\n        }\n\n    }\n\n}\n", "idx": 24688}
{"project": "FFmpeg", "commit_id": "99982524f93a5fc5f8eadd3e8f9b4e3af446cdaa", "target": 0, "func": "static void check_cpu_flag(const char *name, int flag)\n\n{\n\n    int old_cpu_flag = state.cpu_flag;\n\n\n\n    flag |= old_cpu_flag;\n\n    av_set_cpu_flags_mask(flag);\n\n    state.cpu_flag = av_get_cpu_flags();\n\n\n\n    if (!flag || state.cpu_flag != old_cpu_flag) {\n\n        int i;\n\n\n\n        state.cpu_flag_name = name;\n\n        for (i = 0; tests[i].func; i++) {\n\n            state.current_test_name = tests[i].name;\n\n            tests[i].func();\n\n        }\n\n    }\n\n}\n", "idx": 24699}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int pcx_encode_close(AVCodecContext *avctx)\n\n{\n\n    av_frame_free(&avctx->coded_frame);\n\n    return 0;\n\n}\n", "idx": 24701}
{"project": "FFmpeg", "commit_id": "e53c9065ca08a9153ecc73a6a8940bcc6d667e58", "target": 0, "func": "static void fill_double_array(AVLFG *lfg, double *a, int len)\n\n{\n\n    int i;\n\n    double bmg[2], stddev = 10.0, mean = 0.0;\n\n\n\n    for (i = 0; i < len; i += 2) {\n\n        av_bmg_get(lfg, bmg);\n\n        a[i]     = bmg[0] * stddev + mean;\n\n        a[i + 1] = bmg[1] * stddev + mean;\n\n    }\n\n}\n", "idx": 24702}
{"project": "FFmpeg", "commit_id": "602abe77b02f9702c18c2787d208fcfc9d94b70f", "target": 0, "func": "static void init_input_filter(FilterGraph *fg, AVFilterInOut *in)\n\n{\n\n    InputStream *ist = NULL;\n\n    enum AVMediaType type = avfilter_pad_get_type(in->filter_ctx->input_pads, in->pad_idx);\n\n    int i;\n\n\n\n    // TODO: support other filter types\n\n    if (type != AVMEDIA_TYPE_VIDEO && type != AVMEDIA_TYPE_AUDIO) {\n\n        av_log(NULL, AV_LOG_FATAL, \"Only video and audio filters supported \"\n\n               \"currently.\\n\");\n\n        exit(1);\n\n    }\n\n\n\n    if (in->name) {\n\n        AVFormatContext *s;\n\n        AVStream       *st = NULL;\n\n        char *p;\n\n        int file_idx = strtol(in->name, &p, 0);\n\n\n\n        if (file_idx < 0 || file_idx >= nb_input_files) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Invalid file index %d in filtegraph description %s.\\n\",\n\n                   file_idx, fg->graph_desc);\n\n            exit(1);\n\n        }\n\n        s = input_files[file_idx]->ctx;\n\n\n\n        for (i = 0; i < s->nb_streams; i++) {\n\n            if (s->streams[i]->codecpar->codec_type != type)\n\n                continue;\n\n            if (check_stream_specifier(s, s->streams[i], *p == ':' ? p + 1 : p) == 1) {\n\n                st = s->streams[i];\n\n                break;\n\n            }\n\n        }\n\n        if (!st) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Stream specifier '%s' in filtergraph description %s \"\n\n                   \"matches no streams.\\n\", p, fg->graph_desc);\n\n            exit(1);\n\n        }\n\n        ist = input_streams[input_files[file_idx]->ist_index + st->index];\n\n    } else {\n\n        /* find the first unused stream of corresponding type */\n\n        for (i = 0; i < nb_input_streams; i++) {\n\n            ist = input_streams[i];\n\n            if (ist->dec_ctx->codec_type == type && ist->discard)\n\n                break;\n\n        }\n\n        if (i == nb_input_streams) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Cannot find a matching stream for \"\n\n                   \"unlabeled input pad %d on filter %s\\n\", in->pad_idx,\n\n                   in->filter_ctx->name);\n\n            exit(1);\n\n        }\n\n    }\n\n    av_assert0(ist);\n\n\n\n    ist->discard         = 0;\n\n    ist->decoding_needed = 1;\n\n    ist->st->discard = AVDISCARD_NONE;\n\n\n\n    GROW_ARRAY(fg->inputs, fg->nb_inputs);\n\n    if (!(fg->inputs[fg->nb_inputs - 1] = av_mallocz(sizeof(*fg->inputs[0]))))\n\n        exit(1);\n\n    fg->inputs[fg->nb_inputs - 1]->ist   = ist;\n\n    fg->inputs[fg->nb_inputs - 1]->graph = fg;\n\n    fg->inputs[fg->nb_inputs - 1]->format = -1;\n\n\n\n    fg->inputs[fg->nb_inputs - 1]->frame_queue = av_fifo_alloc(8 * sizeof(AVFrame*));\n\n    if (!fg->inputs[fg->nb_inputs - 1])\n\n        exit_program(1);\n\n\n\n    GROW_ARRAY(ist->filters, ist->nb_filters);\n\n    ist->filters[ist->nb_filters - 1] = fg->inputs[fg->nb_inputs - 1];\n\n}\n", "idx": 24703}
{"project": "FFmpeg", "commit_id": "9e9be5a20c0b36dce1cae11f5f5957886231a764", "target": 0, "func": "static void derive_spatial_merge_candidates(HEVCContext *s, int x0, int y0,\n\n                                            int nPbW, int nPbH,\n\n                                            int log2_cb_size,\n\n                                            int singleMCLFlag, int part_idx,\n\n                                            int merge_idx,\n\n                                            struct MvField mergecandlist[])\n\n{\n\n    HEVCLocalContext *lc   = &s->HEVClc;\n\n    RefPicList *refPicList = s->ref->refPicList;\n\n    MvField *tab_mvf       = s->ref->tab_mvf;\n\n\n\n    const int min_pu_width = s->sps->min_pu_width;\n\n\n\n    const int cand_bottom_left = lc->na.cand_bottom_left;\n\n    const int cand_left        = lc->na.cand_left;\n\n    const int cand_up_left     = lc->na.cand_up_left;\n\n    const int cand_up          = lc->na.cand_up;\n\n    const int cand_up_right    = lc->na.cand_up_right_sap;\n\n\n\n    const int xA1    = x0 - 1;\n\n    const int yA1    = y0 + nPbH - 1;\n\n    const int xA1_pu = xA1 >> s->sps->log2_min_pu_size;\n\n    const int yA1_pu = yA1 >> s->sps->log2_min_pu_size;\n\n\n\n    const int xB1    = x0 + nPbW - 1;\n\n    const int yB1    = y0 - 1;\n\n    const int xB1_pu = xB1 >> s->sps->log2_min_pu_size;\n\n    const int yB1_pu = yB1 >> s->sps->log2_min_pu_size;\n\n\n\n    const int xB0    = x0 + nPbW;\n\n    const int yB0    = y0 - 1;\n\n    const int xB0_pu = xB0 >> s->sps->log2_min_pu_size;\n\n    const int yB0_pu = yB0 >> s->sps->log2_min_pu_size;\n\n\n\n    const int xA0    = x0 - 1;\n\n    const int yA0    = y0 + nPbH;\n\n    const int xA0_pu = xA0 >> s->sps->log2_min_pu_size;\n\n    const int yA0_pu = yA0 >> s->sps->log2_min_pu_size;\n\n\n\n    const int xB2    = x0 - 1;\n\n    const int yB2    = y0 - 1;\n\n    const int xB2_pu = xB2 >> s->sps->log2_min_pu_size;\n\n    const int yB2_pu = yB2 >> s->sps->log2_min_pu_size;\n\n\n\n    const int nb_refs = (s->sh.slice_type == P_SLICE) ?\n\n                        s->sh.nb_refs[0] : FFMIN(s->sh.nb_refs[0], s->sh.nb_refs[1]);\n\n    int check_MER   = 1;\n\n    int check_MER_1 = 1;\n\n\n\n    int zero_idx = 0;\n\n\n\n    int nb_merge_cand = 0;\n\n    int nb_orig_merge_cand = 0;\n\n\n\n    int is_available_a0;\n\n    int is_available_a1;\n\n    int is_available_b0;\n\n    int is_available_b1;\n\n    int is_available_b2;\n\n    int check_B0;\n\n    int check_A0;\n\n\n\n    //first left spatial merge candidate\n\n    is_available_a1 = AVAILABLE(cand_left, A1);\n\n\n\n    if (!singleMCLFlag && part_idx == 1 &&\n\n        (lc->cu.part_mode == PART_Nx2N ||\n\n         lc->cu.part_mode == PART_nLx2N ||\n\n         lc->cu.part_mode == PART_nRx2N) ||\n\n        isDiffMER(s, xA1, yA1, x0, y0)) {\n\n        is_available_a1 = 0;\n\n    }\n\n\n\n    if (is_available_a1) {\n\n        mergecandlist[0] = TAB_MVF_PU(A1);\n\n        if (merge_idx == 0)\n\n            return;\n\n        nb_merge_cand++;\n\n    }\n\n\n\n    // above spatial merge candidate\n\n    is_available_b1 = AVAILABLE(cand_up, B1);\n\n\n\n    if (!singleMCLFlag && part_idx == 1 &&\n\n        (lc->cu.part_mode == PART_2NxN ||\n\n         lc->cu.part_mode == PART_2NxnU ||\n\n         lc->cu.part_mode == PART_2NxnD) ||\n\n        isDiffMER(s, xB1, yB1, x0, y0)) {\n\n        is_available_b1 = 0;\n\n    }\n\n\n\n    if (is_available_a1 && is_available_b1)\n\n        check_MER = !COMPARE_MV_REFIDX(B1, A1);\n\n\n\n    if (is_available_b1 && check_MER)\n\n        mergecandlist[nb_merge_cand++] = TAB_MVF_PU(B1);\n\n\n\n    // above right spatial merge candidate\n\n    check_MER = 1;\n\n    check_B0  = PRED_BLOCK_AVAILABLE(B0);\n\n\n\n    is_available_b0 = check_B0 && AVAILABLE(cand_up_right, B0);\n\n\n\n    if (isDiffMER(s, xB0, yB0, x0, y0))\n\n        is_available_b0 = 0;\n\n\n\n    if (is_available_b1 && is_available_b0)\n\n        check_MER = !COMPARE_MV_REFIDX(B0, B1);\n\n\n\n    if (is_available_b0 && check_MER) {\n\n        mergecandlist[nb_merge_cand] = TAB_MVF_PU(B0);\n\n        if (merge_idx == nb_merge_cand)\n\n            return;\n\n        nb_merge_cand++;\n\n    }\n\n\n\n    // left bottom spatial merge candidate\n\n    check_MER = 1;\n\n    check_A0  = PRED_BLOCK_AVAILABLE(A0);\n\n\n\n    is_available_a0 = check_A0 && AVAILABLE(cand_bottom_left, A0);\n\n\n\n    if (isDiffMER(s, xA0, yA0, x0, y0))\n\n        is_available_a0 = 0;\n\n\n\n    if (is_available_a1 && is_available_a0)\n\n        check_MER = !COMPARE_MV_REFIDX(A0, A1);\n\n\n\n    if (is_available_a0 && check_MER) {\n\n        mergecandlist[nb_merge_cand] = TAB_MVF_PU(A0);\n\n        if (merge_idx == nb_merge_cand)\n\n            return;\n\n        nb_merge_cand++;\n\n    }\n\n\n\n    // above left spatial merge candidate\n\n    check_MER = 1;\n\n\n\n    is_available_b2 = AVAILABLE(cand_up_left, B2);\n\n\n\n    if (isDiffMER(s, xB2, yB2, x0, y0))\n\n        is_available_b2 = 0;\n\n\n\n    if (is_available_a1 && is_available_b2)\n\n        check_MER = !COMPARE_MV_REFIDX(B2, A1);\n\n\n\n    if (is_available_b1 && is_available_b2)\n\n        check_MER_1 = !COMPARE_MV_REFIDX(B2, B1);\n\n\n\n    if (is_available_b2 && check_MER && check_MER_1 && nb_merge_cand != 4) {\n\n        mergecandlist[nb_merge_cand] = TAB_MVF_PU(B2);\n\n        if (merge_idx == nb_merge_cand)\n\n            return;\n\n        nb_merge_cand++;\n\n    }\n\n\n\n    // temporal motion vector candidate\n\n    if (s->sh.slice_temporal_mvp_enabled_flag &&\n\n        nb_merge_cand < s->sh.max_num_merge_cand) {\n\n        Mv mv_l0_col, mv_l1_col;\n\n        int available_l0 = temporal_luma_motion_vector(s, x0, y0, nPbW, nPbH,\n\n                                                       0, &mv_l0_col, 0);\n\n        int available_l1 = (s->sh.slice_type == B_SLICE) ?\n\n                           temporal_luma_motion_vector(s, x0, y0, nPbW, nPbH,\n\n                                                       0, &mv_l1_col, 1) : 0;\n\n\n\n        if (available_l0 || available_l1) {\n\n            mergecandlist[nb_merge_cand].is_intra     = 0;\n\n            mergecandlist[nb_merge_cand].pred_flag[0] = available_l0;\n\n            mergecandlist[nb_merge_cand].pred_flag[1] = available_l1;\n\n            AV_ZERO16(mergecandlist[nb_merge_cand].ref_idx);\n\n            mergecandlist[nb_merge_cand].mv[0]      = mv_l0_col;\n\n            mergecandlist[nb_merge_cand].mv[1]      = mv_l1_col;\n\n\n\n            if (merge_idx == nb_merge_cand)\n\n                return;\n\n            nb_merge_cand++;\n\n        }\n\n    }\n\n\n\n    nb_orig_merge_cand = nb_merge_cand;\n\n\n\n    // combined bi-predictive merge candidates  (applies for B slices)\n\n    if (s->sh.slice_type == B_SLICE && nb_orig_merge_cand > 1 &&\n\n        nb_orig_merge_cand < s->sh.max_num_merge_cand) {\n\n        int comb_idx;\n\n\n\n        for (comb_idx = 0; nb_merge_cand < s->sh.max_num_merge_cand &&\n\n                           comb_idx < nb_orig_merge_cand * (nb_orig_merge_cand - 1); comb_idx++) {\n\n            int l0_cand_idx = l0_l1_cand_idx[comb_idx][0];\n\n            int l1_cand_idx = l0_l1_cand_idx[comb_idx][1];\n\n            MvField l0_cand = mergecandlist[l0_cand_idx];\n\n            MvField l1_cand = mergecandlist[l1_cand_idx];\n\n\n\n            if (l0_cand.pred_flag[0] && l1_cand.pred_flag[1] &&\n\n                (refPicList[0].list[l0_cand.ref_idx[0]] !=\n\n                 refPicList[1].list[l1_cand.ref_idx[1]] ||\n\n                 AV_RN32A(&l0_cand.mv[0]) != AV_RN32A(&l1_cand.mv[1]))) {\n\n                mergecandlist[nb_merge_cand].ref_idx[0]   = l0_cand.ref_idx[0];\n\n                mergecandlist[nb_merge_cand].ref_idx[1]   = l1_cand.ref_idx[1];\n\n                mergecandlist[nb_merge_cand].pred_flag[0] = 1;\n\n                mergecandlist[nb_merge_cand].pred_flag[1] = 1;\n\n                AV_COPY32(&mergecandlist[nb_merge_cand].mv[0], &l0_cand.mv[0]);\n\n                AV_COPY32(&mergecandlist[nb_merge_cand].mv[1], &l1_cand.mv[1]);\n\n                mergecandlist[nb_merge_cand].is_intra     = 0;\n\n                if (merge_idx == nb_merge_cand)\n\n                    return;\n\n                nb_merge_cand++;\n\n            }\n\n        }\n\n    }\n\n\n\n    // append Zero motion vector candidates\n\n    while (nb_merge_cand < s->sh.max_num_merge_cand) {\n\n        mergecandlist[nb_merge_cand].pred_flag[0] = 1;\n\n        mergecandlist[nb_merge_cand].pred_flag[1] = s->sh.slice_type == B_SLICE;\n\n        AV_ZERO32(mergecandlist[nb_merge_cand].mv + 0);\n\n        AV_ZERO32(mergecandlist[nb_merge_cand].mv + 1);\n\n        mergecandlist[nb_merge_cand].is_intra     = 0;\n\n        mergecandlist[nb_merge_cand].ref_idx[0]   = zero_idx < nb_refs ? zero_idx : 0;\n\n        mergecandlist[nb_merge_cand].ref_idx[1]   = zero_idx < nb_refs ? zero_idx : 0;\n\n\n\n        if (merge_idx == nb_merge_cand)\n\n            return;\n\n        nb_merge_cand++;\n\n        zero_idx++;\n\n    }\n\n}\n", "idx": 24706}
{"project": "FFmpeg", "commit_id": "72dbc610be3272ba36603f78a39cc2d2d8fe0cc3", "target": 0, "func": "void ff_avg_h264_qpel4_mc12_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_midh_qrt_and_aver_dst_4w_msa(src - (2 * stride) - 2,\n\n                                          stride, dst, stride, 4, 0);\n\n}\n", "idx": 24707}
{"project": "FFmpeg", "commit_id": "99c554efc8b09c3f1bb2fb41c3da5431085f7470", "target": 0, "func": "static void decode_postinit(H264Context *h, int setup_finished)\n\n{\n\n    const SPS *sps = h->ps.sps;\n\n    H264Picture *out = h->cur_pic_ptr;\n\n    H264Picture *cur = h->cur_pic_ptr;\n\n    int i, pics, out_of_order, out_idx;\n\n    int invalid = 0, cnt = 0;\n\n\n\n    h->cur_pic_ptr->f->pict_type = h->pict_type;\n\n\n\n    if (h->next_output_pic)\n\n        return;\n\n\n\n    if (cur->field_poc[0] == INT_MAX || cur->field_poc[1] == INT_MAX) {\n\n        /* FIXME: if we have two PAFF fields in one packet, we can't start\n\n         * the next thread here. If we have one field per packet, we can.\n\n         * The check in decode_nal_units() is not good enough to find this\n\n         * yet, so we assume the worst for now. */\n\n        // if (setup_finished)\n\n        //    ff_thread_finish_setup(h->avctx);\n\n        return;\n\n    }\n\n\n\n    cur->f->interlaced_frame = 0;\n\n    cur->f->repeat_pict      = 0;\n\n\n\n    /* Signal interlacing information externally. */\n\n    /* Prioritize picture timing SEI information over used\n\n     * decoding process if it exists. */\n\n\n\n    if (sps->pic_struct_present_flag) {\n\n        H264SEIPictureTiming *pt = &h->sei.picture_timing;\n\n        switch (pt->pic_struct) {\n\n        case SEI_PIC_STRUCT_FRAME:\n\n            break;\n\n        case SEI_PIC_STRUCT_TOP_FIELD:\n\n        case SEI_PIC_STRUCT_BOTTOM_FIELD:\n\n            cur->f->interlaced_frame = 1;\n\n            break;\n\n        case SEI_PIC_STRUCT_TOP_BOTTOM:\n\n        case SEI_PIC_STRUCT_BOTTOM_TOP:\n\n            if (FIELD_OR_MBAFF_PICTURE(h))\n\n                cur->f->interlaced_frame = 1;\n\n            else\n\n                // try to flag soft telecine progressive\n\n                cur->f->interlaced_frame = h->prev_interlaced_frame;\n\n            break;\n\n        case SEI_PIC_STRUCT_TOP_BOTTOM_TOP:\n\n        case SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM:\n\n            /* Signal the possibility of telecined film externally\n\n             * (pic_struct 5,6). From these hints, let the applications\n\n             * decide if they apply deinterlacing. */\n\n            cur->f->repeat_pict = 1;\n\n            break;\n\n        case SEI_PIC_STRUCT_FRAME_DOUBLING:\n\n            cur->f->repeat_pict = 2;\n\n            break;\n\n        case SEI_PIC_STRUCT_FRAME_TRIPLING:\n\n            cur->f->repeat_pict = 4;\n\n            break;\n\n        }\n\n\n\n        if ((pt->ct_type & 3) &&\n\n            pt->pic_struct <= SEI_PIC_STRUCT_BOTTOM_TOP)\n\n            cur->f->interlaced_frame = (pt->ct_type & (1 << 1)) != 0;\n\n    } else {\n\n        /* Derive interlacing flag from used decoding process. */\n\n        cur->f->interlaced_frame = FIELD_OR_MBAFF_PICTURE(h);\n\n    }\n\n    h->prev_interlaced_frame = cur->f->interlaced_frame;\n\n\n\n    if (cur->field_poc[0] != cur->field_poc[1]) {\n\n        /* Derive top_field_first from field pocs. */\n\n        cur->f->top_field_first = cur->field_poc[0] < cur->field_poc[1];\n\n    } else {\n\n        if (cur->f->interlaced_frame || sps->pic_struct_present_flag) {\n\n            /* Use picture timing SEI information. Even if it is a\n\n             * information of a past frame, better than nothing. */\n\n            if (h->sei.picture_timing.pic_struct == SEI_PIC_STRUCT_TOP_BOTTOM ||\n\n                h->sei.picture_timing.pic_struct == SEI_PIC_STRUCT_TOP_BOTTOM_TOP)\n\n                cur->f->top_field_first = 1;\n\n            else\n\n                cur->f->top_field_first = 0;\n\n        } else {\n\n            /* Most likely progressive */\n\n            cur->f->top_field_first = 0;\n\n        }\n\n    }\n\n\n\n    if (h->sei.frame_packing.present &&\n\n        h->sei.frame_packing.arrangement_type >= 0 &&\n\n        h->sei.frame_packing.arrangement_type <= 6 &&\n\n        h->sei.frame_packing.content_interpretation_type > 0 &&\n\n        h->sei.frame_packing.content_interpretation_type < 3) {\n\n        H264SEIFramePacking *fp = &h->sei.frame_packing;\n\n        AVStereo3D *stereo = av_stereo3d_create_side_data(cur->f);\n\n        if (!stereo)\n\n            return;\n\n\n\n        switch (fp->arrangement_type) {\n\n        case 0:\n\n            stereo->type = AV_STEREO3D_CHECKERBOARD;\n\n            break;\n\n        case 1:\n\n            stereo->type = AV_STEREO3D_COLUMNS;\n\n            break;\n\n        case 2:\n\n            stereo->type = AV_STEREO3D_LINES;\n\n            break;\n\n        case 3:\n\n            if (fp->quincunx_subsampling)\n\n                stereo->type = AV_STEREO3D_SIDEBYSIDE_QUINCUNX;\n\n            else\n\n                stereo->type = AV_STEREO3D_SIDEBYSIDE;\n\n            break;\n\n        case 4:\n\n            stereo->type = AV_STEREO3D_TOPBOTTOM;\n\n            break;\n\n        case 5:\n\n            stereo->type = AV_STEREO3D_FRAMESEQUENCE;\n\n            break;\n\n        case 6:\n\n            stereo->type = AV_STEREO3D_2D;\n\n            break;\n\n        }\n\n\n\n        if (fp->content_interpretation_type == 2)\n\n            stereo->flags = AV_STEREO3D_FLAG_INVERT;\n\n    }\n\n\n\n    if (h->sei.display_orientation.present &&\n\n        (h->sei.display_orientation.anticlockwise_rotation ||\n\n         h->sei.display_orientation.hflip ||\n\n         h->sei.display_orientation.vflip)) {\n\n        H264SEIDisplayOrientation *o = &h->sei.display_orientation;\n\n        double angle = o->anticlockwise_rotation * 360 / (double) (1 << 16);\n\n        AVFrameSideData *rotation = av_frame_new_side_data(cur->f,\n\n                                                           AV_FRAME_DATA_DISPLAYMATRIX,\n\n                                                           sizeof(int32_t) * 9);\n\n        if (!rotation)\n\n            return;\n\n\n\n        av_display_rotation_set((int32_t *)rotation->data, angle);\n\n        av_display_matrix_flip((int32_t *)rotation->data,\n\n                               o->hflip, o->vflip);\n\n    }\n\n\n\n    if (h->sei.afd.present) {\n\n        AVFrameSideData *sd = av_frame_new_side_data(cur->f, AV_FRAME_DATA_AFD,\n\n                                                     sizeof(uint8_t));\n\n        if (!sd)\n\n            return;\n\n\n\n        *sd->data = h->sei.afd.active_format_description;\n\n        h->sei.afd.present = 0;\n\n    }\n\n\n\n    if (h->sei.a53_caption.a53_caption) {\n\n        H264SEIA53Caption *a53 = &h->sei.a53_caption;\n\n        AVFrameSideData *sd = av_frame_new_side_data(cur->f,\n\n                                                     AV_FRAME_DATA_A53_CC,\n\n                                                     a53->a53_caption_size);\n\n        if (!sd)\n\n            return;\n\n\n\n        memcpy(sd->data, a53->a53_caption, a53->a53_caption_size);\n\n        av_freep(&a53->a53_caption);\n\n        a53->a53_caption_size = 0;\n\n    }\n\n\n\n    // FIXME do something with unavailable reference frames\n\n\n\n    /* Sort B-frames into display order */\n\n    if (sps->bitstream_restriction_flag ||\n\n        h->avctx->strict_std_compliance >= FF_COMPLIANCE_NORMAL) {\n\n        h->avctx->has_b_frames = FFMAX(h->avctx->has_b_frames, sps->num_reorder_frames);\n\n    }\n\n    h->low_delay = !h->avctx->has_b_frames;\n\n\n\n    pics = 0;\n\n    while (h->delayed_pic[pics])\n\n        pics++;\n\n\n\n    assert(pics <= MAX_DELAYED_PIC_COUNT);\n\n\n\n    h->delayed_pic[pics++] = cur;\n\n    if (cur->reference == 0)\n\n        cur->reference = DELAYED_PIC_REF;\n\n\n\n    /* Frame reordering. This code takes pictures from coding order and sorts\n\n     * them by their incremental POC value into display order. It supports POC\n\n     * gaps, MMCO reset codes and random resets.\n\n     * A \"display group\" can start either with a IDR frame (f.key_frame = 1),\n\n     * and/or can be closed down with a MMCO reset code. In sequences where\n\n     * there is no delay, we can't detect that (since the frame was already\n\n     * output to the user), so we also set h->mmco_reset to detect the MMCO\n\n     * reset code.\n\n     * FIXME: if we detect insufficient delays (as per h->avctx->has_b_frames),\n\n     * we increase the delay between input and output. All frames affected by\n\n     * the lag (e.g. those that should have been output before another frame\n\n     * that we already returned to the user) will be dropped. This is a bug\n\n     * that we will fix later. */\n\n    for (i = 0; i < MAX_DELAYED_PIC_COUNT; i++) {\n\n        cnt     += out->poc < h->last_pocs[i];\n\n        invalid += out->poc == INT_MIN;\n\n    }\n\n    if (!h->mmco_reset && !cur->f->key_frame &&\n\n        cnt + invalid == MAX_DELAYED_PIC_COUNT && cnt > 0) {\n\n        h->mmco_reset = 2;\n\n        if (pics > 1)\n\n            h->delayed_pic[pics - 2]->mmco_reset = 2;\n\n    }\n\n    if (h->mmco_reset || cur->f->key_frame) {\n\n        for (i = 0; i < MAX_DELAYED_PIC_COUNT; i++)\n\n            h->last_pocs[i] = INT_MIN;\n\n        cnt     = 0;\n\n        invalid = MAX_DELAYED_PIC_COUNT;\n\n    }\n\n    out     = h->delayed_pic[0];\n\n    out_idx = 0;\n\n    for (i = 1; i < MAX_DELAYED_PIC_COUNT &&\n\n                h->delayed_pic[i] &&\n\n                !h->delayed_pic[i - 1]->mmco_reset &&\n\n                !h->delayed_pic[i]->f->key_frame;\n\n         i++)\n\n        if (h->delayed_pic[i]->poc < out->poc) {\n\n            out     = h->delayed_pic[i];\n\n            out_idx = i;\n\n        }\n\n    if (h->avctx->has_b_frames == 0 &&\n\n        (h->delayed_pic[0]->f->key_frame || h->mmco_reset))\n\n        h->next_outputed_poc = INT_MIN;\n\n    out_of_order = !out->f->key_frame && !h->mmco_reset &&\n\n                   (out->poc < h->next_outputed_poc);\n\n\n\n    if (sps->bitstream_restriction_flag &&\n\n        h->avctx->has_b_frames >= sps->num_reorder_frames) {\n\n    } else if (out_of_order && pics - 1 == h->avctx->has_b_frames &&\n\n               h->avctx->has_b_frames < MAX_DELAYED_PIC_COUNT) {\n\n        if (invalid + cnt < MAX_DELAYED_PIC_COUNT) {\n\n            h->avctx->has_b_frames = FFMAX(h->avctx->has_b_frames, cnt);\n\n        }\n\n        h->low_delay = 0;\n\n    } else if (h->low_delay &&\n\n               ((h->next_outputed_poc != INT_MIN &&\n\n                 out->poc > h->next_outputed_poc + 2) ||\n\n                cur->f->pict_type == AV_PICTURE_TYPE_B)) {\n\n        h->low_delay = 0;\n\n        h->avctx->has_b_frames++;\n\n    }\n\n\n\n    if (pics > h->avctx->has_b_frames) {\n\n        out->reference &= ~DELAYED_PIC_REF;\n\n        for (i = out_idx; h->delayed_pic[i]; i++)\n\n            h->delayed_pic[i] = h->delayed_pic[i + 1];\n\n    }\n\n    memmove(h->last_pocs, &h->last_pocs[1],\n\n            sizeof(*h->last_pocs) * (MAX_DELAYED_PIC_COUNT - 1));\n\n    h->last_pocs[MAX_DELAYED_PIC_COUNT - 1] = cur->poc;\n\n    if (!out_of_order && pics > h->avctx->has_b_frames) {\n\n        h->next_output_pic = out;\n\n        if (out->mmco_reset) {\n\n            if (out_idx > 0) {\n\n                h->next_outputed_poc                    = out->poc;\n\n                h->delayed_pic[out_idx - 1]->mmco_reset = out->mmco_reset;\n\n            } else {\n\n                h->next_outputed_poc = INT_MIN;\n\n            }\n\n        } else {\n\n            if (out_idx == 0 && pics > 1 && h->delayed_pic[0]->f->key_frame) {\n\n                h->next_outputed_poc = INT_MIN;\n\n            } else {\n\n                h->next_outputed_poc = out->poc;\n\n            }\n\n        }\n\n        h->mmco_reset = 0;\n\n    } else {\n\n        av_log(h->avctx, AV_LOG_DEBUG, \"no picture\\n\");\n\n    }\n\n\n\n    if (h->next_output_pic) {\n\n        if (h->next_output_pic->recovered) {\n\n            // We have reached an recovery point and all frames after it in\n\n            // display order are \"recovered\".\n\n            h->frame_recovered |= FRAME_RECOVERED_SEI;\n\n        }\n\n        h->next_output_pic->recovered |= !!(h->frame_recovered & FRAME_RECOVERED_SEI);\n\n    }\n\n\n\n    if (setup_finished && !h->avctx->hwaccel) {\n\n        ff_thread_finish_setup(h->avctx);\n\n\n\n        if (h->avctx->active_thread_type & FF_THREAD_FRAME)\n\n            h->setup_finished = 1;\n\n    }\n\n}\n", "idx": 24708}
{"project": "FFmpeg", "commit_id": "83f7bd6dcf00875725c5f3b7e1bedac5a6b3c77d", "target": 0, "func": "static int g2m_load_cursor(AVCodecContext *avctx, G2MContext *c,\n\n                           GetByteContext *gb)\n\n{\n\n    int i, j, k;\n\n    uint8_t *dst;\n\n    uint32_t bits;\n\n    uint32_t cur_size, cursor_w, cursor_h, cursor_stride;\n\n    uint32_t cursor_hot_x, cursor_hot_y;\n\n    int cursor_fmt;\n\n    uint8_t *tmp;\n\n\n\n    cur_size      = bytestream2_get_be32(gb);\n\n    cursor_w      = bytestream2_get_byte(gb);\n\n    cursor_h      = bytestream2_get_byte(gb);\n\n    cursor_hot_x  = bytestream2_get_byte(gb);\n\n    cursor_hot_y  = bytestream2_get_byte(gb);\n\n    cursor_fmt    = bytestream2_get_byte(gb);\n\n\n\n    cursor_stride = FFALIGN(cursor_w, c->cursor_fmt==1 ? 32 : 1) * 4;\n\n\n\n    if (cursor_w < 1 || cursor_w > 256 ||\n\n        cursor_h < 1 || cursor_h > 256) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid cursor dimensions %dx%d\\n\",\n\n               cursor_w, cursor_h);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (cursor_hot_x > cursor_w || cursor_hot_y > cursor_h) {\n\n        av_log(avctx, AV_LOG_WARNING, \"Invalid hotspot position %d,%d\\n\",\n\n               cursor_hot_x, cursor_hot_y);\n\n        cursor_hot_x = FFMIN(cursor_hot_x, cursor_w - 1);\n\n        cursor_hot_y = FFMIN(cursor_hot_y, cursor_h - 1);\n\n    }\n\n    if (cur_size - 9 > bytestream2_get_bytes_left(gb) ||\n\n        c->cursor_w * c->cursor_h / 4 > cur_size) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid cursor data size %d/%d\\n\",\n\n               cur_size, bytestream2_get_bytes_left(gb));\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (cursor_fmt != 1 && cursor_fmt != 32) {\n\n        avpriv_report_missing_feature(avctx, \"Cursor format %d\",\n\n                                      cursor_fmt);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    tmp = av_realloc(c->cursor, cursor_stride * cursor_h);\n\n    if (!tmp) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Cannot allocate cursor buffer\\n\");\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    c->cursor        = tmp;\n\n    c->cursor_w      = cursor_w;\n\n    c->cursor_h      = cursor_h;\n\n    c->cursor_hot_x  = cursor_hot_x;\n\n    c->cursor_hot_y  = cursor_hot_y;\n\n    c->cursor_fmt    = cursor_fmt;\n\n    c->cursor_stride = cursor_stride;\n\n\n\n    dst = c->cursor;\n\n    switch (c->cursor_fmt) {\n\n    case 1: // old monochrome\n\n        for (j = 0; j < c->cursor_h; j++) {\n\n            for (i = 0; i < c->cursor_w; i += 32) {\n\n                bits = bytestream2_get_be32(gb);\n\n                for (k = 0; k < 32; k++) {\n\n                    dst[0] = !!(bits & 0x80000000);\n\n                    dst += 4;\n\n                    bits <<= 1;\n\n                }\n\n            }\n\n        }\n\n\n\n        dst = c->cursor;\n\n        for (j = 0; j < c->cursor_h; j++) {\n\n            for (i = 0; i < c->cursor_w; i += 32) {\n\n                bits = bytestream2_get_be32(gb);\n\n                for (k = 0; k < 32; k++) {\n\n                    int mask_bit = !!(bits & 0x80000000);\n\n                    switch (dst[0] * 2 + mask_bit) {\n\n                    case 0:\n\n                        dst[0] = 0xFF; dst[1] = 0x00;\n\n                        dst[2] = 0x00; dst[3] = 0x00;\n\n                        break;\n\n                    case 1:\n\n                        dst[0] = 0xFF; dst[1] = 0xFF;\n\n                        dst[2] = 0xFF; dst[3] = 0xFF;\n\n                        break;\n\n                    default:\n\n                        dst[0] = 0x00; dst[1] = 0x00;\n\n                        dst[2] = 0x00; dst[3] = 0x00;\n\n                    }\n\n                    dst += 4;\n\n                    bits <<= 1;\n\n                }\n\n            }\n\n        }\n\n        break;\n\n    case 32: // full colour\n\n        /* skip monochrome version of the cursor and decode RGBA instead */\n\n        bytestream2_skip(gb, c->cursor_h * (FFALIGN(c->cursor_w, 32) >> 3));\n\n        for (j = 0; j < c->cursor_h; j++) {\n\n            for (i = 0; i < c->cursor_w; i++) {\n\n                int val = bytestream2_get_be32(gb);\n\n                *dst++ = val >>  0;\n\n                *dst++ = val >>  8;\n\n                *dst++ = val >> 16;\n\n                *dst++ = val >> 24;\n\n            }\n\n        }\n\n        break;\n\n    default:\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n    return 0;\n\n}\n", "idx": 24709}
{"project": "FFmpeg", "commit_id": "8b97ae64841ed29db9c77db322890656cdc0d354", "target": 0, "func": "static int has_duration(AVFormatContext *ic)\n\n{\n\n    int i;\n\n    AVStream *st;\n\n\n\n    for(i = 0;i < ic->nb_streams; i++) {\n\n        st = ic->streams[i];\n\n        if (st->duration != AV_NOPTS_VALUE)\n\n            return 1;\n\n    }\n\n    if (ic->duration)\n\n        return 1;\n\n    return 0;\n\n}\n", "idx": 24710}
{"project": "FFmpeg", "commit_id": "e6923f683c506cbb581eb7f31288801f1a065fb0", "target": 0, "func": "static int tta_decode_frame(AVCodecContext *avctx,\n\n        void *data, int *data_size,\n\n        AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    TTAContext *s = avctx->priv_data;\n\n    int i;\n\n\n\n    init_get_bits(&s->gb, buf, buf_size*8);\n\n    {\n\n        int cur_chan = 0, framelen = s->frame_length;\n\n        int32_t *p;\n\n\n\n        if (*data_size < (framelen * s->channels * 2)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Output buffer size is too small.\\n\");\n\n            return -1;\n\n        }\n\n        // FIXME: seeking\n\n        s->total_frames--;\n\n        if (!s->total_frames && s->last_frame_length)\n\n            framelen = s->last_frame_length;\n\n\n\n        // init per channel states\n\n        for (i = 0; i < s->channels; i++) {\n\n            s->ch_ctx[i].predictor = 0;\n\n            ttafilter_init(&s->ch_ctx[i].filter, ttafilter_configs[s->bps-1][0], ttafilter_configs[s->bps-1][1]);\n\n            rice_init(&s->ch_ctx[i].rice, 10, 10);\n\n        }\n\n\n\n        for (p = s->decode_buffer; p < s->decode_buffer + (framelen * s->channels); p++) {\n\n            int32_t *predictor = &s->ch_ctx[cur_chan].predictor;\n\n            TTAFilter *filter = &s->ch_ctx[cur_chan].filter;\n\n            TTARice *rice = &s->ch_ctx[cur_chan].rice;\n\n            uint32_t unary, depth, k;\n\n            int32_t value;\n\n\n\n            unary = tta_get_unary(&s->gb);\n\n\n\n            if (unary == 0) {\n\n                depth = 0;\n\n                k = rice->k0;\n\n            } else {\n\n                depth = 1;\n\n                k = rice->k1;\n\n                unary--;\n\n            }\n\n\n\n            if (get_bits_left(&s->gb) < k)\n\n                return -1;\n\n\n\n            if (k) {\n\n                if (k > MIN_CACHE_BITS)\n\n                    return -1;\n\n                value = (unary << k) + get_bits(&s->gb, k);\n\n            } else\n\n                value = unary;\n\n\n\n            // FIXME: copy paste from original\n\n            switch (depth) {\n\n            case 1:\n\n                rice->sum1 += value - (rice->sum1 >> 4);\n\n                if (rice->k1 > 0 && rice->sum1 < shift_16[rice->k1])\n\n                    rice->k1--;\n\n                else if(rice->sum1 > shift_16[rice->k1 + 1])\n\n                    rice->k1++;\n\n                value += shift_1[rice->k0];\n\n            default:\n\n                rice->sum0 += value - (rice->sum0 >> 4);\n\n                if (rice->k0 > 0 && rice->sum0 < shift_16[rice->k0])\n\n                    rice->k0--;\n\n                else if(rice->sum0 > shift_16[rice->k0 + 1])\n\n                    rice->k0++;\n\n            }\n\n\n\n            // extract coded value\n\n#define UNFOLD(x) (((x)&1) ? (++(x)>>1) : (-(x)>>1))\n\n            *p = UNFOLD(value);\n\n\n\n            // run hybrid filter\n\n            ttafilter_process(filter, p, 0);\n\n\n\n            // fixed order prediction\n\n#define PRED(x, k) (int32_t)((((uint64_t)x << k) - x) >> k)\n\n            switch (s->bps) {\n\n                case 1: *p += PRED(*predictor, 4); break;\n\n                case 2:\n\n                case 3: *p += PRED(*predictor, 5); break;\n\n                case 4: *p += *predictor; break;\n\n            }\n\n            *predictor = *p;\n\n\n\n            // flip channels\n\n            if (cur_chan < (s->channels-1))\n\n                cur_chan++;\n\n            else {\n\n                // decorrelate in case of stereo integer\n\n                if (s->channels > 1) {\n\n                    int32_t *r = p - 1;\n\n                    for (*p += *r / 2; r > p - s->channels; r--)\n\n                        *r = *(r + 1) - *r;\n\n                }\n\n                cur_chan = 0;\n\n            }\n\n        }\n\n\n\n        if (get_bits_left(&s->gb) < 32)\n\n            return -1;\n\n        skip_bits(&s->gb, 32); // frame crc\n\n\n\n        // convert to output buffer\n\n        switch(s->bps) {\n\n            case 2: {\n\n                uint16_t *samples = data;\n\n                for (p = s->decode_buffer; p < s->decode_buffer + (framelen * s->channels); p++) {\n\n                    *samples++ = *p;\n\n                }\n\n                *data_size = (uint8_t *)samples - (uint8_t *)data;\n\n                break;\n\n            }\n\n            default:\n\n                av_log(s->avctx, AV_LOG_ERROR, \"Error, only 16bit samples supported!\\n\");\n\n        }\n\n    }\n\n\n\n    return buf_size;\n\n}\n", "idx": 24721}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(rgb16to15)(const uint8_t *src,uint8_t *dst,unsigned src_size)\n\n{\n\n  register const uint8_t* s=src;\n\n  register uint8_t* d=dst;\n\n  register const uint8_t *end;\n\n  const uint8_t *mm_end;\n\n  end = s + src_size;\n\n#ifdef HAVE_MMX\n\n  __asm __volatile(PREFETCH\"\t%0\"::\"m\"(*s));\n\n  __asm __volatile(\"movq\t%0, %%mm7\"::\"m\"(mask15rg));\n\n  __asm __volatile(\"movq\t%0, %%mm6\"::\"m\"(mask15b));\n\n  mm_end = end - 15;\n\n  while(s<mm_end)\n\n  {\n\n\t__asm __volatile(\n\n\t\tPREFETCH\"\t32%1\\n\\t\"\n\n\t\t\"movq\t%1, %%mm0\\n\\t\"\n\n\t\t\"movq\t8%1, %%mm2\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm1\\n\\t\"\n\n\t\t\"movq\t%%mm2, %%mm3\\n\\t\"\n\n\t\t\"psrlq\t$1, %%mm0\\n\\t\"\n\n\t\t\"psrlq\t$1, %%mm2\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm0\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm2\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm1\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm1, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm3, %%mm2\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm2, 8%0\"\n\n\t\t:\"=m\"(*d)\n\n\t\t:\"m\"(*s)\n\n\t\t);\n\n\td+=16;\n\n\ts+=16;\n\n  }\n\n  __asm __volatile(SFENCE:::\"memory\");\n\n  __asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n    mm_end = end - 3;\n\n    while(s < mm_end)\n\n    {\n\n\tregister uint32_t x= *((uint32_t *)s);\n\n\t*((uint32_t *)d) = ((x>>1)&0x7FE07FE0) | (x&0x001F001F);\n\n\ts+=4;\n\n\td+=4;\n\n    }\n\n    if(s < end)\n\n    {\n\n\tregister uint16_t x= *((uint16_t *)s);\n\n\t*((uint16_t *)d) = ((x>>1)&0x7FE0) | (x&0x001F);\n\n\ts+=2;\n\n\td+=2;\n\n    }\n\n}\n", "idx": 24731}
{"project": "FFmpeg", "commit_id": "93c39db5f1544d1220488cfeb93bfe812a52f374", "target": 1, "func": "static int aiff_read_packet(AVFormatContext *s,\n                            AVPacket *pkt)\n{\n    AVStream *st = s->streams[0];\n    AIFFInputContext *aiff = s->priv_data;\n    int64_t max_size;\n    int res, size;\n    /* calculate size of remaining data */\n    max_size = aiff->data_end - avio_tell(s->pb);\n    if (max_size <= 0)\n        return AVERROR_EOF;\n    /* Now for that packet */\n    switch (st->codecpar->codec_id) {\n    case AV_CODEC_ID_ADPCM_IMA_QT:\n    case AV_CODEC_ID_GSM:\n    case AV_CODEC_ID_QDM2:\n    case AV_CODEC_ID_QCELP:\n        size = st->codecpar->block_align;\n        break;\n    default:\n        size = st->codecpar->block_align ? (MAX_SIZE / st->codecpar->block_align) * st->codecpar->block_align : MAX_SIZE;\n    size = FFMIN(max_size, size);\n    res = av_get_packet(s->pb, pkt, size);\n    if (res < 0)\n        return res;\n    if (size >= st->codecpar->block_align)\n        pkt->flags &= ~AV_PKT_FLAG_CORRUPT;\n    /* Only one stream in an AIFF file */\n    pkt->stream_index = 0;\n    pkt->duration     = (res / st->codecpar->block_align) * aiff->block_duration;\n    return 0;", "idx": 24732}
{"project": "FFmpeg", "commit_id": "e70fcf075b8f92c4e410b80c703fbdc1d531d42d", "target": 1, "func": "void write_video_frame(AVFormatContext *oc, AVStream *st)\n\n{\n\n    int x, y, i, out_size;\n\n    AVCodecContext *c;\n\n\n\n    c = &st->codec;\n\n    \n\n    /* prepare a dummy image */\n\n    /* Y */\n\n    i = frame_count++;\n\n    for(y=0;y<c->height;y++) {\n\n        for(x=0;x<c->width;x++) {\n\n            picture->data[0][y * picture->linesize[0] + x] = x + y + i * 3;\n\n        }\n\n    }\n\n    \n\n    /* Cb and Cr */\n\n    for(y=0;y<c->height/2;y++) {\n\n        for(x=0;x<c->width/2;x++) {\n\n            picture->data[1][y * picture->linesize[1] + x] = 128 + y + i * 2;\n\n            picture->data[2][y * picture->linesize[2] + x] = 64 + x + i * 5;\n\n        }\n\n    }\n\n\n\n    /* encode the image */\n\n    out_size = avcodec_encode_video(c, video_outbuf, video_outbuf_size, picture);\n\n\n\n    /* write the compressed frame in the media file */\n\n    if (av_write_frame(oc, st->index, video_outbuf, out_size) != 0) {\n\n        fprintf(stderr, \"Error while writing video frame\\n\");\n\n        exit(1);\n\n    }\n\n}\n", "idx": 24735}
{"project": "FFmpeg", "commit_id": "db61329607c858f95cd7e4c165897dcd39f82977", "target": 1, "func": "av_cold int MPV_encode_init(AVCodecContext *avctx)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int i;\n\n    int chroma_h_shift, chroma_v_shift;\n\n\n\n    MPV_encode_defaults(s);\n\n\n\n    switch (avctx->codec_id) {\n\n    case CODEC_ID_MPEG2VIDEO:\n\n        if(avctx->pix_fmt != PIX_FMT_YUV420P && avctx->pix_fmt != PIX_FMT_YUV422P){\n\n            av_log(avctx, AV_LOG_ERROR, \"only YUV420 and YUV422 are supported\\n\");\n\n            return -1;\n\n        }\n\n        break;\n\n    case CODEC_ID_LJPEG:\n\n        if(avctx->pix_fmt != PIX_FMT_YUVJ420P && avctx->pix_fmt != PIX_FMT_YUVJ422P && avctx->pix_fmt != PIX_FMT_YUVJ444P && avctx->pix_fmt != PIX_FMT_RGB32 &&\n\n           ((avctx->pix_fmt != PIX_FMT_YUV420P && avctx->pix_fmt != PIX_FMT_YUV422P && avctx->pix_fmt != PIX_FMT_YUV444P) || avctx->strict_std_compliance>FF_COMPLIANCE_UNOFFICIAL)){\n\n            av_log(avctx, AV_LOG_ERROR, \"colorspace not supported in LJPEG\\n\");\n\n            return -1;\n\n        }\n\n        break;\n\n    case CODEC_ID_MJPEG:\n\n        if(avctx->pix_fmt != PIX_FMT_YUVJ420P && avctx->pix_fmt != PIX_FMT_YUVJ422P &&\n\n           ((avctx->pix_fmt != PIX_FMT_YUV420P && avctx->pix_fmt != PIX_FMT_YUV422P) || avctx->strict_std_compliance>FF_COMPLIANCE_UNOFFICIAL)){\n\n            av_log(avctx, AV_LOG_ERROR, \"colorspace not supported in jpeg\\n\");\n\n            return -1;\n\n        }\n\n        break;\n\n    default:\n\n        if(avctx->pix_fmt != PIX_FMT_YUV420P){\n\n            av_log(avctx, AV_LOG_ERROR, \"only YUV420 is supported\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    switch (avctx->pix_fmt) {\n\n    case PIX_FMT_YUVJ422P:\n\n    case PIX_FMT_YUV422P:\n\n        s->chroma_format = CHROMA_422;\n\n        break;\n\n    case PIX_FMT_YUVJ420P:\n\n    case PIX_FMT_YUV420P:\n\n    default:\n\n        s->chroma_format = CHROMA_420;\n\n        break;\n\n    }\n\n\n\n    s->bit_rate = avctx->bit_rate;\n\n    s->width = avctx->width;\n\n    s->height = avctx->height;\n\n    if(avctx->gop_size > 600 && avctx->strict_std_compliance>FF_COMPLIANCE_EXPERIMENTAL){\n\n        av_log(avctx, AV_LOG_ERROR, \"Warning keyframe interval too large! reducing it ...\\n\");\n\n        avctx->gop_size=600;\n\n    }\n\n    s->gop_size = avctx->gop_size;\n\n    s->avctx = avctx;\n\n    s->flags= avctx->flags;\n\n    s->flags2= avctx->flags2;\n\n    s->max_b_frames= avctx->max_b_frames;\n\n    s->codec_id= avctx->codec->id;\n\n    s->luma_elim_threshold  = avctx->luma_elim_threshold;\n\n    s->chroma_elim_threshold= avctx->chroma_elim_threshold;\n\n    s->strict_std_compliance= avctx->strict_std_compliance;\n\n    s->data_partitioning= avctx->flags & CODEC_FLAG_PART;\n\n    s->quarter_sample= (avctx->flags & CODEC_FLAG_QPEL)!=0;\n\n    s->mpeg_quant= avctx->mpeg_quant;\n\n    s->rtp_mode= !!avctx->rtp_payload_size;\n\n    s->intra_dc_precision= avctx->intra_dc_precision;\n\n    s->user_specified_pts = AV_NOPTS_VALUE;\n\n\n\n    if (s->gop_size <= 1) {\n\n        s->intra_only = 1;\n\n        s->gop_size = 12;\n\n    } else {\n\n        s->intra_only = 0;\n\n    }\n\n\n\n    s->me_method = avctx->me_method;\n\n\n\n    /* Fixed QSCALE */\n\n    s->fixed_qscale = !!(avctx->flags & CODEC_FLAG_QSCALE);\n\n\n\n    s->adaptive_quant= (   s->avctx->lumi_masking\n\n                        || s->avctx->dark_masking\n\n                        || s->avctx->temporal_cplx_masking\n\n                        || s->avctx->spatial_cplx_masking\n\n                        || s->avctx->p_masking\n\n                        || s->avctx->border_masking\n\n                        || (s->flags&CODEC_FLAG_QP_RD))\n\n                       && !s->fixed_qscale;\n\n\n\n    s->obmc= !!(s->flags & CODEC_FLAG_OBMC);\n\n    s->loop_filter= !!(s->flags & CODEC_FLAG_LOOP_FILTER);\n\n    s->alternate_scan= !!(s->flags & CODEC_FLAG_ALT_SCAN);\n\n    s->intra_vlc_format= !!(s->flags2 & CODEC_FLAG2_INTRA_VLC);\n\n    s->q_scale_type= !!(s->flags2 & CODEC_FLAG2_NON_LINEAR_QUANT);\n\n\n\n    if(avctx->rc_max_rate && !avctx->rc_buffer_size){\n\n        av_log(avctx, AV_LOG_ERROR, \"a vbv buffer size is needed, for encoding with a maximum bitrate\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(avctx->rc_min_rate && avctx->rc_max_rate != avctx->rc_min_rate){\n\n        av_log(avctx, AV_LOG_INFO, \"Warning min_rate > 0 but min_rate != max_rate isn't recommended!\\n\");\n\n    }\n\n\n\n    if(avctx->rc_min_rate && avctx->rc_min_rate > avctx->bit_rate){\n\n        av_log(avctx, AV_LOG_ERROR, \"bitrate below min bitrate\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(avctx->rc_max_rate && avctx->rc_max_rate < avctx->bit_rate){\n\n        av_log(avctx, AV_LOG_INFO, \"bitrate above max bitrate\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(avctx->rc_max_rate && avctx->rc_max_rate == avctx->bit_rate && avctx->rc_max_rate != avctx->rc_min_rate){\n\n        av_log(avctx, AV_LOG_INFO, \"impossible bitrate constraints, this will fail\\n\");\n\n    }\n\n\n\n    if(avctx->rc_buffer_size && avctx->bit_rate*(int64_t)avctx->time_base.num > avctx->rc_buffer_size * (int64_t)avctx->time_base.den){\n\n        av_log(avctx, AV_LOG_ERROR, \"VBV buffer too small for bitrate\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(!s->fixed_qscale && avctx->bit_rate*av_q2d(avctx->time_base) > avctx->bit_rate_tolerance){\n\n        av_log(avctx, AV_LOG_ERROR, \"bitrate tolerance too small for bitrate\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(   s->avctx->rc_max_rate && s->avctx->rc_min_rate == s->avctx->rc_max_rate\n\n       && (s->codec_id == CODEC_ID_MPEG1VIDEO || s->codec_id == CODEC_ID_MPEG2VIDEO)\n\n       && 90000LL * (avctx->rc_buffer_size-1) > s->avctx->rc_max_rate*0xFFFFLL){\n\n\n\n        av_log(avctx, AV_LOG_INFO, \"Warning vbv_delay will be set to 0xFFFF (=VBR) as the specified vbv buffer is too large for the given bitrate!\\n\");\n\n    }\n\n\n\n    if((s->flags & CODEC_FLAG_4MV) && s->codec_id != CODEC_ID_MPEG4\n\n       && s->codec_id != CODEC_ID_H263 && s->codec_id != CODEC_ID_H263P && s->codec_id != CODEC_ID_FLV1){\n\n        av_log(avctx, AV_LOG_ERROR, \"4MV not supported by codec\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(s->obmc && s->avctx->mb_decision != FF_MB_DECISION_SIMPLE){\n\n        av_log(avctx, AV_LOG_ERROR, \"OBMC is only supported with simple mb decision\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(s->obmc && s->codec_id != CODEC_ID_H263 && s->codec_id != CODEC_ID_H263P){\n\n        av_log(avctx, AV_LOG_ERROR, \"OBMC is only supported with H263(+)\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(s->quarter_sample && s->codec_id != CODEC_ID_MPEG4){\n\n        av_log(avctx, AV_LOG_ERROR, \"qpel not supported by codec\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(s->data_partitioning && s->codec_id != CODEC_ID_MPEG4){\n\n        av_log(avctx, AV_LOG_ERROR, \"data partitioning not supported by codec\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(s->max_b_frames && s->codec_id != CODEC_ID_MPEG4 && s->codec_id != CODEC_ID_MPEG1VIDEO && s->codec_id != CODEC_ID_MPEG2VIDEO){\n\n        av_log(avctx, AV_LOG_ERROR, \"b frames not supported by codec\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if ((s->codec_id == CODEC_ID_MPEG4 || s->codec_id == CODEC_ID_H263 ||\n\n         s->codec_id == CODEC_ID_H263P) &&\n\n        (avctx->sample_aspect_ratio.num > 255 || avctx->sample_aspect_ratio.den > 255)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid pixel aspect ratio %i/%i, limit is 255/255\\n\",\n\n               avctx->sample_aspect_ratio.num, avctx->sample_aspect_ratio.den);\n\n        return -1;\n\n    }\n\n\n\n    if((s->flags & (CODEC_FLAG_INTERLACED_DCT|CODEC_FLAG_INTERLACED_ME|CODEC_FLAG_ALT_SCAN))\n\n       && s->codec_id != CODEC_ID_MPEG4 && s->codec_id != CODEC_ID_MPEG2VIDEO){\n\n        av_log(avctx, AV_LOG_ERROR, \"interlacing not supported by codec\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(s->mpeg_quant && s->codec_id != CODEC_ID_MPEG4){ //FIXME mpeg2 uses that too\n\n        av_log(avctx, AV_LOG_ERROR, \"mpeg2 style quantization not supported by codec\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if((s->flags & CODEC_FLAG_CBP_RD) && !avctx->trellis){\n\n        av_log(avctx, AV_LOG_ERROR, \"CBP RD needs trellis quant\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if((s->flags & CODEC_FLAG_QP_RD) && s->avctx->mb_decision != FF_MB_DECISION_RD){\n\n        av_log(avctx, AV_LOG_ERROR, \"QP RD needs mbd=2\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(s->avctx->scenechange_threshold < 1000000000 && (s->flags & CODEC_FLAG_CLOSED_GOP)){\n\n        av_log(avctx, AV_LOG_ERROR, \"closed gop with scene change detection are not supported yet, set threshold to 1000000000\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if((s->flags2 & CODEC_FLAG2_INTRA_VLC) && s->codec_id != CODEC_ID_MPEG2VIDEO){\n\n        av_log(avctx, AV_LOG_ERROR, \"intra vlc table not supported by codec\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(s->flags & CODEC_FLAG_LOW_DELAY){\n\n        if (s->codec_id != CODEC_ID_MPEG2VIDEO){\n\n            av_log(avctx, AV_LOG_ERROR, \"low delay forcing is only available for mpeg2\\n\");\n\n            return -1;\n\n        }\n\n        if (s->max_b_frames != 0){\n\n            av_log(avctx, AV_LOG_ERROR, \"b frames cannot be used with low delay\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    if(s->q_scale_type == 1){\n\n        if(s->codec_id != CODEC_ID_MPEG2VIDEO){\n\n            av_log(avctx, AV_LOG_ERROR, \"non linear quant is only available for mpeg2\\n\");\n\n            return -1;\n\n        }\n\n        if(avctx->qmax > 12){\n\n            av_log(avctx, AV_LOG_ERROR, \"non linear quant only supports qmax <= 12 currently\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    if(s->avctx->thread_count > 1 && s->codec_id != CODEC_ID_MPEG4\n\n       && s->codec_id != CODEC_ID_MPEG1VIDEO && s->codec_id != CODEC_ID_MPEG2VIDEO\n\n       && (s->codec_id != CODEC_ID_H263P || !(s->flags & CODEC_FLAG_H263P_SLICE_STRUCT))){\n\n        av_log(avctx, AV_LOG_ERROR, \"multi threaded encoding not supported by codec\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(s->avctx->thread_count < 1){\n\n        av_log(avctx, AV_LOG_ERROR, \"automatic thread number detection not supported by codec, patch welcome\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(s->avctx->thread_count > 1)\n\n        s->rtp_mode= 1;\n\n\n\n    if(!avctx->time_base.den || !avctx->time_base.num){\n\n        av_log(avctx, AV_LOG_ERROR, \"framerate not set\\n\");\n\n        return -1;\n\n    }\n\n\n\n    i= (INT_MAX/2+128)>>8;\n\n    if(avctx->me_threshold >= i){\n\n        av_log(avctx, AV_LOG_ERROR, \"me_threshold too large, max is %d\\n\", i - 1);\n\n        return -1;\n\n    }\n\n    if(avctx->mb_threshold >= i){\n\n        av_log(avctx, AV_LOG_ERROR, \"mb_threshold too large, max is %d\\n\", i - 1);\n\n        return -1;\n\n    }\n\n\n\n    if(avctx->b_frame_strategy && (avctx->flags&CODEC_FLAG_PASS2)){\n\n        av_log(avctx, AV_LOG_INFO, \"notice: b_frame_strategy only affects the first pass\\n\");\n\n        avctx->b_frame_strategy = 0;\n\n    }\n\n\n\n    i= av_gcd(avctx->time_base.den, avctx->time_base.num);\n\n    if(i > 1){\n\n        av_log(avctx, AV_LOG_INFO, \"removing common factors from framerate\\n\");\n\n        avctx->time_base.den /= i;\n\n        avctx->time_base.num /= i;\n\n//        return -1;\n\n    }\n\n\n\n    if(s->mpeg_quant || s->codec_id==CODEC_ID_MPEG1VIDEO || s->codec_id==CODEC_ID_MPEG2VIDEO || s->codec_id==CODEC_ID_MJPEG){\n\n        s->intra_quant_bias= 3<<(QUANT_BIAS_SHIFT-3); //(a + x*3/8)/x\n\n        s->inter_quant_bias= 0;\n\n    }else{\n\n        s->intra_quant_bias=0;\n\n        s->inter_quant_bias=-(1<<(QUANT_BIAS_SHIFT-2)); //(a - x/4)/x\n\n    }\n\n\n\n    if(avctx->intra_quant_bias != FF_DEFAULT_QUANT_BIAS)\n\n        s->intra_quant_bias= avctx->intra_quant_bias;\n\n    if(avctx->inter_quant_bias != FF_DEFAULT_QUANT_BIAS)\n\n        s->inter_quant_bias= avctx->inter_quant_bias;\n\n\n\n    avcodec_get_chroma_sub_sample(avctx->pix_fmt, &chroma_h_shift, &chroma_v_shift);\n\n\n\n    if(avctx->codec_id == CODEC_ID_MPEG4 && s->avctx->time_base.den > (1<<16)-1){\n\n        av_log(avctx, AV_LOG_ERROR, \"timebase not supported by mpeg 4 standard\\n\");\n\n        return -1;\n\n    }\n\n    s->time_increment_bits = av_log2(s->avctx->time_base.den - 1) + 1;\n\n\n\n    switch(avctx->codec->id) {\n\n    case CODEC_ID_MPEG1VIDEO:\n\n        s->out_format = FMT_MPEG1;\n\n        s->low_delay= !!(s->flags & CODEC_FLAG_LOW_DELAY);\n\n        avctx->delay= s->low_delay ? 0 : (s->max_b_frames + 1);\n\n        break;\n\n    case CODEC_ID_MPEG2VIDEO:\n\n        s->out_format = FMT_MPEG1;\n\n        s->low_delay= !!(s->flags & CODEC_FLAG_LOW_DELAY);\n\n        avctx->delay= s->low_delay ? 0 : (s->max_b_frames + 1);\n\n        s->rtp_mode= 1;\n\n        break;\n\n    case CODEC_ID_LJPEG:\n\n    case CODEC_ID_MJPEG:\n\n        s->out_format = FMT_MJPEG;\n\n        s->intra_only = 1; /* force intra only for jpeg */\n\n        if(avctx->codec->id == CODEC_ID_LJPEG && avctx->pix_fmt == PIX_FMT_BGRA){\n\n            s->mjpeg_vsample[0] = s->mjpeg_hsample[0] =\n\n            s->mjpeg_vsample[1] = s->mjpeg_hsample[1] =\n\n            s->mjpeg_vsample[2] = s->mjpeg_hsample[2] = 1;\n\n        }else{\n\n            s->mjpeg_vsample[0] = 2;\n\n            s->mjpeg_vsample[1] = 2>>chroma_v_shift;\n\n            s->mjpeg_vsample[2] = 2>>chroma_v_shift;\n\n            s->mjpeg_hsample[0] = 2;\n\n            s->mjpeg_hsample[1] = 2>>chroma_h_shift;\n\n            s->mjpeg_hsample[2] = 2>>chroma_h_shift;\n\n        }\n\n        if (!(CONFIG_MJPEG_ENCODER || CONFIG_LJPEG_ENCODER)\n\n            || ff_mjpeg_encode_init(s) < 0)\n\n            return -1;\n\n        avctx->delay=0;\n\n        s->low_delay=1;\n\n        break;\n\n    case CODEC_ID_H261:\n\n        if (!CONFIG_H261_ENCODER)  return -1;\n\n        if (ff_h261_get_picture_format(s->width, s->height) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"The specified picture size of %dx%d is not valid for the H.261 codec.\\nValid sizes are 176x144, 352x288\\n\", s->width, s->height);\n\n            return -1;\n\n        }\n\n        s->out_format = FMT_H261;\n\n        avctx->delay=0;\n\n        s->low_delay=1;\n\n        break;\n\n    case CODEC_ID_H263:\n\n        if (!CONFIG_H263_ENCODER)  return -1;\n\n        if (ff_match_2uint16(h263_format, FF_ARRAY_ELEMS(h263_format), s->width, s->height) == 8) {\n\n            av_log(avctx, AV_LOG_INFO, \"The specified picture size of %dx%d is not valid for the H.263 codec.\\nValid sizes are 128x96, 176x144, 352x288, 704x576, and 1408x1152. Try H.263+.\\n\", s->width, s->height);\n\n            return -1;\n\n        }\n\n        s->out_format = FMT_H263;\n\n        s->obmc= (avctx->flags & CODEC_FLAG_OBMC) ? 1:0;\n\n        avctx->delay=0;\n\n        s->low_delay=1;\n\n        break;\n\n    case CODEC_ID_H263P:\n\n        s->out_format = FMT_H263;\n\n        s->h263_plus = 1;\n\n        /* Fx */\n\n        s->umvplus = (avctx->flags & CODEC_FLAG_H263P_UMV) ? 1:0;\n\n        s->h263_aic= (avctx->flags & CODEC_FLAG_AC_PRED) ? 1:0;\n\n        s->modified_quant= s->h263_aic;\n\n        s->alt_inter_vlc= (avctx->flags & CODEC_FLAG_H263P_AIV) ? 1:0;\n\n        s->obmc= (avctx->flags & CODEC_FLAG_OBMC) ? 1:0;\n\n        s->loop_filter= (avctx->flags & CODEC_FLAG_LOOP_FILTER) ? 1:0;\n\n        s->unrestricted_mv= s->obmc || s->loop_filter || s->umvplus;\n\n        s->h263_slice_structured= (s->flags & CODEC_FLAG_H263P_SLICE_STRUCT) ? 1:0;\n\n\n\n        /* /Fx */\n\n        /* These are just to be sure */\n\n        avctx->delay=0;\n\n        s->low_delay=1;\n\n        break;\n\n    case CODEC_ID_FLV1:\n\n        s->out_format = FMT_H263;\n\n        s->h263_flv = 2; /* format = 1; 11-bit codes */\n\n        s->unrestricted_mv = 1;\n\n        s->rtp_mode=0; /* don't allow GOB */\n\n        avctx->delay=0;\n\n        s->low_delay=1;\n\n        break;\n\n    case CODEC_ID_RV10:\n\n        s->out_format = FMT_H263;\n\n        avctx->delay=0;\n\n        s->low_delay=1;\n\n        break;\n\n    case CODEC_ID_RV20:\n\n        s->out_format = FMT_H263;\n\n        avctx->delay=0;\n\n        s->low_delay=1;\n\n        s->modified_quant=1;\n\n        s->h263_aic=1;\n\n        s->h263_plus=1;\n\n        s->loop_filter=1;\n\n        s->unrestricted_mv= 0;\n\n        break;\n\n    case CODEC_ID_MPEG4:\n\n        s->out_format = FMT_H263;\n\n        s->h263_pred = 1;\n\n        s->unrestricted_mv = 1;\n\n        s->low_delay= s->max_b_frames ? 0 : 1;\n\n        avctx->delay= s->low_delay ? 0 : (s->max_b_frames + 1);\n\n        break;\n\n    case CODEC_ID_MSMPEG4V1:\n\n        s->out_format = FMT_H263;\n\n        s->h263_msmpeg4 = 1;\n\n        s->h263_pred = 1;\n\n        s->unrestricted_mv = 1;\n\n        s->msmpeg4_version= 1;\n\n        avctx->delay=0;\n\n        s->low_delay=1;\n\n        break;\n\n    case CODEC_ID_MSMPEG4V2:\n\n        s->out_format = FMT_H263;\n\n        s->h263_msmpeg4 = 1;\n\n        s->h263_pred = 1;\n\n        s->unrestricted_mv = 1;\n\n        s->msmpeg4_version= 2;\n\n        avctx->delay=0;\n\n        s->low_delay=1;\n\n        break;\n\n    case CODEC_ID_MSMPEG4V3:\n\n        s->out_format = FMT_H263;\n\n        s->h263_msmpeg4 = 1;\n\n        s->h263_pred = 1;\n\n        s->unrestricted_mv = 1;\n\n        s->msmpeg4_version= 3;\n\n        s->flipflop_rounding=1;\n\n        avctx->delay=0;\n\n        s->low_delay=1;\n\n        break;\n\n    case CODEC_ID_WMV1:\n\n        s->out_format = FMT_H263;\n\n        s->h263_msmpeg4 = 1;\n\n        s->h263_pred = 1;\n\n        s->unrestricted_mv = 1;\n\n        s->msmpeg4_version= 4;\n\n        s->flipflop_rounding=1;\n\n        avctx->delay=0;\n\n        s->low_delay=1;\n\n        break;\n\n    case CODEC_ID_WMV2:\n\n        s->out_format = FMT_H263;\n\n        s->h263_msmpeg4 = 1;\n\n        s->h263_pred = 1;\n\n        s->unrestricted_mv = 1;\n\n        s->msmpeg4_version= 5;\n\n        s->flipflop_rounding=1;\n\n        avctx->delay=0;\n\n        s->low_delay=1;\n\n        break;\n\n    default:\n\n        return -1;\n\n    }\n\n\n\n    avctx->has_b_frames= !s->low_delay;\n\n\n\n    s->encoding = 1;\n\n\n\n    s->progressive_frame=\n\n    s->progressive_sequence= !(avctx->flags & (CODEC_FLAG_INTERLACED_DCT|CODEC_FLAG_INTERLACED_ME|CODEC_FLAG_ALT_SCAN));\n\n\n\n    /* init */\n\n    if (MPV_common_init(s) < 0)\n\n        return -1;\n\n\n\n    if(!s->dct_quantize)\n\n        s->dct_quantize = dct_quantize_c;\n\n    if(!s->denoise_dct)\n\n        s->denoise_dct = denoise_dct_c;\n\n    s->fast_dct_quantize = s->dct_quantize;\n\n    if(avctx->trellis)\n\n        s->dct_quantize = dct_quantize_trellis_c;\n\n\n\n    if((CONFIG_H263P_ENCODER || CONFIG_RV20_ENCODER) && s->modified_quant)\n\n        s->chroma_qscale_table= ff_h263_chroma_qscale_table;\n\n\n\n    s->quant_precision=5;\n\n\n\n    ff_set_cmp(&s->dsp, s->dsp.ildct_cmp, s->avctx->ildct_cmp);\n\n    ff_set_cmp(&s->dsp, s->dsp.frame_skip_cmp, s->avctx->frame_skip_cmp);\n\n\n\n    if (CONFIG_H261_ENCODER && s->out_format == FMT_H261)\n\n        ff_h261_encode_init(s);\n\n    if (CONFIG_H263_ENCODER && s->out_format == FMT_H263)\n\n        h263_encode_init(s);\n\n    if (CONFIG_MSMPEG4_ENCODER && s->msmpeg4_version)\n\n        ff_msmpeg4_encode_init(s);\n\n    if ((CONFIG_MPEG1VIDEO_ENCODER || CONFIG_MPEG2VIDEO_ENCODER)\n\n        && s->out_format == FMT_MPEG1)\n\n        ff_mpeg1_encode_init(s);\n\n\n\n    /* init q matrix */\n\n    for(i=0;i<64;i++) {\n\n        int j= s->dsp.idct_permutation[i];\n\n        if(CONFIG_MPEG4_ENCODER && s->codec_id==CODEC_ID_MPEG4 && s->mpeg_quant){\n\n            s->intra_matrix[j] = ff_mpeg4_default_intra_matrix[i];\n\n            s->inter_matrix[j] = ff_mpeg4_default_non_intra_matrix[i];\n\n        }else if(s->out_format == FMT_H263 || s->out_format == FMT_H261){\n\n            s->intra_matrix[j] =\n\n            s->inter_matrix[j] = ff_mpeg1_default_non_intra_matrix[i];\n\n        }else\n\n        { /* mpeg1/2 */\n\n            s->intra_matrix[j] = ff_mpeg1_default_intra_matrix[i];\n\n            s->inter_matrix[j] = ff_mpeg1_default_non_intra_matrix[i];\n\n        }\n\n        if(s->avctx->intra_matrix)\n\n            s->intra_matrix[j] = s->avctx->intra_matrix[i];\n\n        if(s->avctx->inter_matrix)\n\n            s->inter_matrix[j] = s->avctx->inter_matrix[i];\n\n    }\n\n\n\n    /* precompute matrix */\n\n    /* for mjpeg, we do include qscale in the matrix */\n\n    if (s->out_format != FMT_MJPEG) {\n\n        ff_convert_matrix(&s->dsp, s->q_intra_matrix, s->q_intra_matrix16,\n\n                       s->intra_matrix, s->intra_quant_bias, avctx->qmin, 31, 1);\n\n        ff_convert_matrix(&s->dsp, s->q_inter_matrix, s->q_inter_matrix16,\n\n                       s->inter_matrix, s->inter_quant_bias, avctx->qmin, 31, 0);\n\n    }\n\n\n\n    if(ff_rate_control_init(s) < 0)\n\n        return -1;\n\n\n\n    return 0;\n\n}\n", "idx": 24738}
{"project": "FFmpeg", "commit_id": "155ec6edf82692bcf3a5f87d2bc697404f4e5aaf", "target": 0, "func": "static int inline get_mb_score(MpegEncContext * s, int mx, int my, int src_index,\n\n                               int ref_index)\n\n{\n\n//    const int check_luma= s->dsp.me_sub_cmp != s->dsp.mb_cmp;\n\n    MotionEstContext * const c= &s->me;\n\n    const int size= 0;\n\n    const int h= 16;\n\n    const int penalty_factor= c->mb_penalty_factor;\n\n    const int flags= c->mb_flags;\n\n    const int qpel= flags & FLAG_QPEL;\n\n    const int mask= 1+2*qpel;\n\n    me_cmp_func cmp_sub, chroma_cmp_sub;\n\n    int d;\n\n\n\n    LOAD_COMMON\n\n    \n\n //FIXME factorize\n\n\n\n    cmp_sub= s->dsp.mb_cmp[size];\n\n    chroma_cmp_sub= s->dsp.mb_cmp[size+1];\n\n    \n\n    assert(!c->skip);\n\n    assert(c->avctx->me_sub_cmp != c->avctx->mb_cmp);\n\n\n\n    d= cmp(s, mx>>(qpel+1), my>>(qpel+1), mx&mask, my&mask, size, h, ref_index, src_index, cmp_sub, chroma_cmp_sub, flags);\n\n    //FIXME check cbp before adding penalty for (0,0) vector\n\n    if(mx || my || size>0)\n\n        d += (mv_penalty[mx - pred_x] + mv_penalty[my - pred_y])*penalty_factor;\n\n        \n\n    return d;\n\n}\n", "idx": 24745}
{"project": "FFmpeg", "commit_id": "4cb6964244fd6c099383d8b7e99731e72cc844b9", "target": 0, "func": "av_cold void ff_dcadsp_init(DCADSPContext *s)\n\n{\n\n    s->lfe_fir[0] = dca_lfe_fir0_c;\n\n    s->lfe_fir[1] = dca_lfe_fir1_c;\n\n    s->qmf_32_subbands = dca_qmf_32_subbands;\n\n    s->int8x8_fmul_int32 = int8x8_fmul_int32_c;\n\n    if (ARCH_ARM) ff_dcadsp_init_arm(s);\n\n    if (ARCH_X86) ff_dcadsp_init_x86(s);\n\n}\n", "idx": 24746}
{"project": "FFmpeg", "commit_id": "4c0080b7e7d501e2720d2a61f5186a18377f9d63", "target": 0, "func": "static int decode_packet(AVCodecContext *avctx, void *data,\n\n                         int *got_frame_ptr, AVPacket* avpkt)\n\n{\n\n    WMAProDecodeCtx *s = avctx->priv_data;\n\n    GetBitContext* gb  = &s->pgb;\n\n    const uint8_t* buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    int num_bits_prev_frame;\n\n    int packet_sequence_number;\n\n\n\n    *got_frame_ptr = 0;\n\n\n\n    if (s->packet_done || s->packet_loss) {\n\n        s->packet_done = 0;\n\n\n\n        /** sanity check for the buffer length */\n\n        if (buf_size < avctx->block_align)\n\n            return 0;\n\n\n\n        s->next_packet_start = buf_size - avctx->block_align;\n\n        buf_size = avctx->block_align;\n\n        s->buf_bit_size = buf_size << 3;\n\n\n\n        /** parse packet header */\n\n        init_get_bits(gb, buf, s->buf_bit_size);\n\n        packet_sequence_number = get_bits(gb, 4);\n\n        skip_bits(gb, 2);\n\n\n\n        /** get number of bits that need to be added to the previous frame */\n\n        num_bits_prev_frame = get_bits(gb, s->log2_frame_size);\n\n        av_dlog(avctx, \"packet[%d]: nbpf %x\\n\", avctx->frame_number,\n\n                num_bits_prev_frame);\n\n\n\n        /** check for packet loss */\n\n        if (!s->packet_loss &&\n\n            ((s->packet_sequence_number + 1) & 0xF) != packet_sequence_number) {\n\n            s->packet_loss = 1;\n\n            av_log(avctx, AV_LOG_ERROR, \"Packet loss detected! seq %x vs %x\\n\",\n\n                   s->packet_sequence_number, packet_sequence_number);\n\n        }\n\n        s->packet_sequence_number = packet_sequence_number;\n\n\n\n        if (num_bits_prev_frame > 0) {\n\n            int remaining_packet_bits = s->buf_bit_size - get_bits_count(gb);\n\n            if (num_bits_prev_frame >= remaining_packet_bits) {\n\n                num_bits_prev_frame = remaining_packet_bits;\n\n                s->packet_done = 1;\n\n            }\n\n\n\n            /** append the previous frame data to the remaining data from the\n\n                previous packet to create a full frame */\n\n            save_bits(s, gb, num_bits_prev_frame, 1);\n\n            av_dlog(avctx, \"accumulated %x bits of frame data\\n\",\n\n                    s->num_saved_bits - s->frame_offset);\n\n\n\n            /** decode the cross packet frame if it is valid */\n\n            if (!s->packet_loss)\n\n                decode_frame(s, data, got_frame_ptr);\n\n        } else if (s->num_saved_bits - s->frame_offset) {\n\n            av_dlog(avctx, \"ignoring %x previously saved bits\\n\",\n\n                    s->num_saved_bits - s->frame_offset);\n\n        }\n\n\n\n        if (s->packet_loss) {\n\n            /** reset number of saved bits so that the decoder\n\n                does not start to decode incomplete frames in the\n\n                s->len_prefix == 0 case */\n\n            s->num_saved_bits = 0;\n\n            s->packet_loss = 0;\n\n        }\n\n\n\n    } else {\n\n        int frame_size;\n\n        s->buf_bit_size = (avpkt->size - s->next_packet_start) << 3;\n\n        init_get_bits(gb, avpkt->data, s->buf_bit_size);\n\n        skip_bits(gb, s->packet_offset);\n\n        if (s->len_prefix && remaining_bits(s, gb) > s->log2_frame_size &&\n\n            (frame_size = show_bits(gb, s->log2_frame_size)) &&\n\n            frame_size <= remaining_bits(s, gb)) {\n\n            save_bits(s, gb, frame_size, 0);\n\n            s->packet_done = !decode_frame(s, data, got_frame_ptr);\n\n        } else if (!s->len_prefix\n\n                   && s->num_saved_bits > get_bits_count(&s->gb)) {\n\n            /** when the frames do not have a length prefix, we don't know\n\n                the compressed length of the individual frames\n\n                however, we know what part of a new packet belongs to the\n\n                previous frame\n\n                therefore we save the incoming packet first, then we append\n\n                the \"previous frame\" data from the next packet so that\n\n                we get a buffer that only contains full frames */\n\n            s->packet_done = !decode_frame(s, data, got_frame_ptr);\n\n        } else\n\n            s->packet_done = 1;\n\n    }\n\n\n\n    if (s->packet_done && !s->packet_loss &&\n\n        remaining_bits(s, gb) > 0) {\n\n        /** save the rest of the data so that it can be decoded\n\n            with the next packet */\n\n        save_bits(s, gb, remaining_bits(s, gb), 0);\n\n    }\n\n\n\n    s->packet_offset = get_bits_count(gb) & 7;\n\n    if (s->packet_loss)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    return get_bits_count(gb) >> 3;\n\n}\n", "idx": 24757}
{"project": "FFmpeg", "commit_id": "13a099799e89a76eb921ca452e1b04a7a28a9855", "target": 0, "func": "yuv2mono_1_c_template(SwsContext *c, const uint16_t *buf0,\n\n                      const uint16_t *ubuf0, const uint16_t *ubuf1,\n\n                      const uint16_t *vbuf0, const uint16_t *vbuf1,\n\n                      const uint16_t *abuf0, uint8_t *dest, int dstW,\n\n                      int uvalpha, enum PixelFormat dstFormat,\n\n                      int flags, int y, enum PixelFormat target)\n\n{\n\n    const uint8_t * const d128 = dither_8x8_220[y & 7];\n\n    uint8_t *g = c->table_gU[128] + c->table_gV[128];\n\n    int i;\n\n\n\n    for (i = 0; i < dstW - 7; i += 8) {\n\n        int acc =    g[(buf0[i    ] >> 7) + d128[0]];\n\n        acc += acc + g[(buf0[i + 1] >> 7) + d128[1]];\n\n        acc += acc + g[(buf0[i + 2] >> 7) + d128[2]];\n\n        acc += acc + g[(buf0[i + 3] >> 7) + d128[3]];\n\n        acc += acc + g[(buf0[i + 4] >> 7) + d128[4]];\n\n        acc += acc + g[(buf0[i + 5] >> 7) + d128[5]];\n\n        acc += acc + g[(buf0[i + 6] >> 7) + d128[6]];\n\n        acc += acc + g[(buf0[i + 7] >> 7) + d128[7]];\n\n        output_pixel(*dest++, acc);\n\n    }\n\n}\n", "idx": 24760}
{"project": "FFmpeg", "commit_id": "f20b67173ca6a05b8c3dee02dad3b7243b96292b", "target": 0, "func": "static void apply_tns_filter(float *out, float *in, int order, int direction,\n\n                             float *tns_coefs, int ltp_used, int w, int filt,\n\n                             int start_i, int len)\n\n{\n\n    int i, j, inc, start = start_i;\n\n    float tmp[TNS_MAX_ORDER+1];\n\n    if (direction) {\n\n        inc = -1;\n\n        start = (start + len) - 1;\n\n    } else {\n\n        inc = 1;\n\n    }\n\n    if (!ltp_used) {    /* AR filter */\n\n        for (i = 0; i < len; i++, start += inc)\n\n            out[i] = in[start];\n\n            for (j = 1; j <= FFMIN(i, order); j++)\n\n                out[i] += tns_coefs[j]*in[start - j*inc];\n\n    } else {            /* MA filter */\n\n        for (i = 0; i < len; i++, start += inc) {\n\n            tmp[0] = out[i] = in[start];\n\n            for (j = 1; j <= FFMIN(i, order); j++)\n\n                out[i] += tmp[j]*tns_coefs[j];\n\n            for (j = order; j > 0; j--)\n\n                tmp[j] = tmp[j - 1];\n\n        }\n\n    }\n\n}\n", "idx": 24761}
{"project": "FFmpeg", "commit_id": "851ded8918c977d8160c6617b69604f758cabf50", "target": 0, "func": "static int decode_cabac_mb_dqp( H264Context *h) {\n\n    MpegEncContext * const s = &h->s;\n\n    int mbn_xy;\n\n    int   ctx = 0;\n\n    int   val = 0;\n\n\n\n    if( s->mb_x > 0 )\n\n        mbn_xy = s->mb_x + s->mb_y*s->mb_stride - 1;\n\n    else\n\n        mbn_xy = s->mb_width - 1 + (s->mb_y-1)*s->mb_stride;\n\n\n\n    if( h->last_qscale_diff != 0 )\n\n        ctx++;\n\n\n\n    while( get_cabac( &h->cabac, &h->cabac_state[60 + ctx] ) ) {\n\n        if( ctx < 2 )\n\n            ctx = 2;\n\n        else\n\n            ctx = 3;\n\n        val++;\n\n        if(val > 102) //prevent infinite loop\n\n            return INT_MIN;\n\n    }\n\n\n\n    if( val&0x01 )\n\n        return (val + 1)/2;\n\n    else\n\n        return -(val + 1)/2;\n\n}\n", "idx": 24762}
{"project": "FFmpeg", "commit_id": "69c1fe7c9c9bc85eebfc02c6a19caf7e88cd74ff", "target": 0, "func": "static int mkv_write_ass_blocks(AVFormatContext *s, AVIOContext *pb,\n\n                                AVPacket *pkt)\n\n{\n\n    MatroskaMuxContext *mkv = s->priv_data;\n\n    int i, layer = 0, max_duration = 0, size, line_size, data_size = pkt->size;\n\n    uint8_t *start, *end, *data = pkt->data;\n\n    ebml_master blockgroup;\n\n    char buffer[2048];\n\n\n\n    while (data_size) {\n\n        int duration = ass_get_duration(data);\n\n        max_duration = FFMAX(duration, max_duration);\n\n        end          = memchr(data, '\\n', data_size);\n\n        size         = line_size = end ? end - data + 1 : data_size;\n\n        size        -= end ? (end[-1] == '\\r') + 1 : 0;\n\n        start        = data;\n\n        for (i = 0; i < 3; i++, start++)\n\n            if (!(start = memchr(start, ',', size - (start - data))))\n\n                return max_duration;\n\n        size -= start - data;\n\n        sscanf(data, \"Dialogue: %d,\", &layer);\n\n        i = snprintf(buffer, sizeof(buffer), \"%\" PRId64 \",%d,\",\n\n                     s->streams[pkt->stream_index]->nb_frames, layer);\n\n        size = FFMIN(i + size, sizeof(buffer));\n\n        memcpy(buffer + i, start, size - i);\n\n\n\n        av_log(s, AV_LOG_DEBUG,\n\n               \"Writing block at offset %\" PRIu64 \", size %d, \"\n\n               \"pts %\" PRId64 \", duration %d\\n\",\n\n               avio_tell(pb), size, pkt->pts, duration);\n\n        blockgroup = start_ebml_master(pb, MATROSKA_ID_BLOCKGROUP,\n\n                                       mkv_blockgroup_size(size));\n\n        put_ebml_id(pb, MATROSKA_ID_BLOCK);\n\n        put_ebml_num(pb, size + 4, 0);\n\n        // this assumes stream_index is less than 126\n\n        avio_w8(pb, 0x80 | (pkt->stream_index + 1));\n\n        avio_wb16(pb, pkt->pts - mkv->cluster_pts);\n\n        avio_w8(pb, 0);\n\n        avio_write(pb, buffer, size);\n\n        put_ebml_uint(pb, MATROSKA_ID_BLOCKDURATION, duration);\n\n        end_ebml_master(pb, blockgroup);\n\n\n\n        data      += line_size;\n\n        data_size -= line_size;\n\n    }\n\n\n\n    return max_duration;\n\n}\n", "idx": 24768}
{"project": "FFmpeg", "commit_id": "0b42631641d998e509cde6fa344edc6ab5cb4ac8", "target": 0, "func": "static uint8_t get_sot(Jpeg2000DecoderContext *s, int n)\n\n{\n\n    Jpeg2000TilePart *tp;\n\n    uint16_t Isot;\n\n    uint32_t Psot;\n\n    uint8_t TPsot;\n\n\n\n    if (s->buf_end - s->buf < 4)\n\n        return AVERROR(EINVAL);\n\n\n\n    Isot = bytestream_get_be16(&s->buf);        // Isot\n\n    if (Isot) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"Not a DCINEMA JP2K file: more than one tile\\n\");\n\n        return -1;\n\n    }\n\n    Psot  = bytestream_get_be32(&s->buf);       // Psot\n\n    TPsot = bytestream_get_byte(&s->buf);       // TPsot\n\n\n\n    /* Read TNSot but not used */\n\n    bytestream_get_byte(&s->buf);               // TNsot\n\n\n\n    tp             = s->tile[s->curtileno].tile_part + TPsot;\n\n    tp->tile_index = Isot;\n\n    tp->tp_len     = Psot;\n\n    tp->tp_idx     = TPsot;\n\n\n\n    /* Start of bit stream. Pointer to SOD marker\n\n     * Check SOD marker is present. */\n\n    if (JPEG2000_SOD == bytestream_get_be16(&s->buf))\n\n        tp->tp_start_bstrm = s->buf;\n\n    else {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"SOD marker not found \\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* End address of bit stream =\n\n     *     start address + (Psot - size of SOT HEADER(n)\n\n     *     - size of SOT MARKER(2)  - size of SOD marker(2) */\n\n    tp->tp_end_bstrm = s->buf + (tp->tp_len - n - 4);\n\n\n\n    // set buffer pointer to end of tile part header\n\n    s->buf = tp->tp_end_bstrm;\n\n\n\n    return 0;\n\n}\n", "idx": 24769}
{"project": "FFmpeg", "commit_id": "ddbb7c9be2f8a006325ec64cd5b90e1ade5bc476", "target": 1, "func": "static int xa_probe(AVProbeData *p)\n\n{\n\n    switch(AV_RL32(p->buf)) {\n\n    case XA00_TAG:\n\n    case XAI0_TAG:\n\n    case XAJ0_TAG:\n\n        return AVPROBE_SCORE_MAX;\n\n    }\n\n    return 0;\n\n}\n", "idx": 24770}
{"project": "FFmpeg", "commit_id": "3ed65d98c616d52e2544c8b81aa3997f28bb88f5", "target": 1, "func": "void av_vlog(void* avcl, int level, const char *fmt, va_list vl)\n\n{\n\n    if(av_log_callback)\n\n        av_log_callback(avcl, level, fmt, vl);\n\n}\n", "idx": 24773}
{"project": "FFmpeg", "commit_id": "e9ba3098319f78c91470c05da988d865491852c5", "target": 0, "func": "static int read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    ASSContext *ass = s->priv_data;\n\n    uint8_t *p, *end;\n\n\n\n    if (ass->event_index >= ass->event_count)\n\n        return AVERROR(EIO);\n\n\n\n    p = ass->event[ass->event_index];\n\n\n\n    end = strchr(p, '\\n');\n\n    av_new_packet(pkt, end ? end - p + 1 : strlen(p));\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n\n    pkt->pos    = p - ass->event_buffer + s->streams[0]->codec->extradata_size;\n\n    pkt->pts    = pkt->dts = get_pts(p);\n\n    memcpy(pkt->data, p, pkt->size);\n\n\n\n    ass->event_index++;\n\n\n\n    return 0;\n\n}\n", "idx": 24775}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int xwd_encode_close(AVCodecContext *avctx)\n\n{\n\n    av_freep(&avctx->coded_frame);\n\n\n\n    return 0;\n\n}\n", "idx": 24776}
{"project": "FFmpeg", "commit_id": "7ece8b50b19e140ace13eda6f1a9f45f868c2528", "target": 1, "func": "av_cold void ff_idctdsp_init_x86(IDCTDSPContext *c, AVCodecContext *avctx,\n\n                                 unsigned high_bit_depth)\n\n{\n\n    int cpu_flags = av_get_cpu_flags();\n\n\n\n    if (INLINE_MMX(cpu_flags)) {\n\n        if (!high_bit_depth &&\n\n            avctx->lowres == 0 &&\n\n            (avctx->idct_algo == FF_IDCT_AUTO ||\n\n             avctx->idct_algo == FF_IDCT_SIMPLEAUTO ||\n\n             avctx->idct_algo == FF_IDCT_SIMPLEMMX)) {\n\n                c->idct_put  = ff_simple_idct_put_mmx;\n\n                c->idct_add  = ff_simple_idct_add_mmx;\n\n                c->idct      = ff_simple_idct_mmx;\n\n                c->perm_type = FF_IDCT_PERM_SIMPLE;\n\n        }\n\n    }\n\n    if (EXTERNAL_MMX(cpu_flags)) {\n\n        c->put_signed_pixels_clamped = ff_put_signed_pixels_clamped_mmx;\n\n        c->put_pixels_clamped        = ff_put_pixels_clamped_mmx;\n\n        c->add_pixels_clamped        = ff_add_pixels_clamped_mmx;\n\n    }\n\n    if (EXTERNAL_SSE2(cpu_flags)) {\n\n        c->put_signed_pixels_clamped = ff_put_signed_pixels_clamped_sse2;\n\n        c->put_pixels_clamped        = ff_put_pixels_clamped_sse2;\n\n        c->add_pixels_clamped        = ff_add_pixels_clamped_sse2;\n\n    }\n\n\n\n    if (ARCH_X86_64 &&\n\n        avctx->bits_per_raw_sample == 10 && avctx->lowres == 0 &&\n\n        (avctx->idct_algo == FF_IDCT_AUTO ||\n\n         avctx->idct_algo == FF_IDCT_SIMPLEAUTO ||\n\n         avctx->idct_algo == FF_IDCT_SIMPLE)) {\n\n        if (EXTERNAL_SSE2(cpu_flags)) {\n\n            c->idct_put  = ff_simple_idct10_put_sse2;\n\n            c->idct_add  = NULL;\n\n            c->idct      = ff_simple_idct10_sse2;\n\n            c->perm_type = FF_IDCT_PERM_TRANSPOSE;\n\n\n\n        }\n\n        if (EXTERNAL_AVX(cpu_flags)) {\n\n            c->idct_put  = ff_simple_idct10_put_avx;\n\n            c->idct_add  = NULL;\n\n            c->idct      = ff_simple_idct10_avx;\n\n            c->perm_type = FF_IDCT_PERM_TRANSPOSE;\n\n        }\n\n    }\n\n}\n", "idx": 24777}
{"project": "FFmpeg", "commit_id": "a2a12e3358c3bbdc0246ffc94973e58eba50ee30", "target": 1, "func": "static void render_slice(Vp3DecodeContext *s, int slice)\n\n{\n\n    int x, y, i, j, fragment;\n\n    LOCAL_ALIGNED_16(DCTELEM, block, [64]);\n\n    int motion_x = 0xdeadbeef, motion_y = 0xdeadbeef;\n\n    int motion_halfpel_index;\n\n    uint8_t *motion_source;\n\n    int plane, first_pixel;\n\n\n\n    if (slice >= s->c_superblock_height)\n\n        return;\n\n\n\n    for (plane = 0; plane < 3; plane++) {\n\n        uint8_t *output_plane = s->current_frame.data    [plane] + s->data_offset[plane];\n\n        uint8_t *  last_plane = s->   last_frame.data    [plane] + s->data_offset[plane];\n\n        uint8_t *golden_plane = s-> golden_frame.data    [plane] + s->data_offset[plane];\n\n        int stride            = s->current_frame.linesize[plane];\n\n        int plane_width       = s->width  >> (plane && s->chroma_x_shift);\n\n        int plane_height      = s->height >> (plane && s->chroma_y_shift);\n\n        int8_t (*motion_val)[2] = s->motion_val[!!plane];\n\n\n\n        int sb_x, sb_y        = slice << (!plane && s->chroma_y_shift);\n\n        int slice_height      = sb_y + 1 + (!plane && s->chroma_y_shift);\n\n        int slice_width       = plane ? s->c_superblock_width : s->y_superblock_width;\n\n\n\n        int fragment_width    = s->fragment_width[!!plane];\n\n        int fragment_height   = s->fragment_height[!!plane];\n\n        int fragment_start    = s->fragment_start[plane];\n\n        int do_await          = !plane && HAVE_THREADS && (s->avctx->active_thread_type&FF_THREAD_FRAME);\n\n\n\n        if (!s->flipped_image) stride = -stride;\n\n        if (CONFIG_GRAY && plane && (s->avctx->flags & CODEC_FLAG_GRAY))\n\n            continue;\n\n\n\n        /* for each superblock row in the slice (both of them)... */\n\n        for (; sb_y < slice_height; sb_y++) {\n\n\n\n            /* for each superblock in a row... */\n\n            for (sb_x = 0; sb_x < slice_width; sb_x++) {\n\n\n\n                /* for each block in a superblock... */\n\n                for (j = 0; j < 16; j++) {\n\n                    x = 4*sb_x + hilbert_offset[j][0];\n\n                    y = 4*sb_y + hilbert_offset[j][1];\n\n                    fragment = y*fragment_width + x;\n\n\n\n                    i = fragment_start + fragment;\n\n\n\n                    // bounds check\n\n                    if (x >= fragment_width || y >= fragment_height)\n\n                        continue;\n\n\n\n                first_pixel = 8*y*stride + 8*x;\n\n\n\n                if (do_await && s->all_fragments[i].coding_method != MODE_INTRA)\n\n                    await_reference_row(s, &s->all_fragments[i], motion_val[fragment][1], (16*y) >> s->chroma_y_shift);\n\n\n\n                /* transform if this block was coded */\n\n                if (s->all_fragments[i].coding_method != MODE_COPY) {\n\n                    if ((s->all_fragments[i].coding_method == MODE_USING_GOLDEN) ||\n\n                        (s->all_fragments[i].coding_method == MODE_GOLDEN_MV))\n\n                        motion_source= golden_plane;\n\n                    else\n\n                        motion_source= last_plane;\n\n\n\n                    motion_source += first_pixel;\n\n                    motion_halfpel_index = 0;\n\n\n\n                    /* sort out the motion vector if this fragment is coded\n\n                     * using a motion vector method */\n\n                    if ((s->all_fragments[i].coding_method > MODE_INTRA) &&\n\n                        (s->all_fragments[i].coding_method != MODE_USING_GOLDEN)) {\n\n                        int src_x, src_y;\n\n                        motion_x = motion_val[fragment][0];\n\n                        motion_y = motion_val[fragment][1];\n\n\n\n                        src_x= (motion_x>>1) + 8*x;\n\n                        src_y= (motion_y>>1) + 8*y;\n\n\n\n                        motion_halfpel_index = motion_x & 0x01;\n\n                        motion_source += (motion_x >> 1);\n\n\n\n                        motion_halfpel_index |= (motion_y & 0x01) << 1;\n\n                        motion_source += ((motion_y >> 1) * stride);\n\n\n\n                        if(src_x<0 || src_y<0 || src_x + 9 >= plane_width || src_y + 9 >= plane_height){\n\n                            uint8_t *temp= s->edge_emu_buffer;\n\n                            if(stride<0) temp -= 8*stride;\n\n\n\n                            s->dsp.emulated_edge_mc(temp, motion_source, stride, 9, 9, src_x, src_y, plane_width, plane_height);\n\n                            motion_source= temp;\n\n                        }\n\n                    }\n\n\n\n\n\n                    /* first, take care of copying a block from either the\n\n                     * previous or the golden frame */\n\n                    if (s->all_fragments[i].coding_method != MODE_INTRA) {\n\n                        /* Note, it is possible to implement all MC cases with\n\n                           put_no_rnd_pixels_l2 which would look more like the\n\n                           VP3 source but this would be slower as\n\n                           put_no_rnd_pixels_tab is better optimzed */\n\n                        if(motion_halfpel_index != 3){\n\n                            s->dsp.put_no_rnd_pixels_tab[1][motion_halfpel_index](\n\n                                output_plane + first_pixel,\n\n                                motion_source, stride, 8);\n\n                        }else{\n\n                            int d= (motion_x ^ motion_y)>>31; // d is 0 if motion_x and _y have the same sign, else -1\n\n                            s->dsp.put_no_rnd_pixels_l2[1](\n\n                                output_plane + first_pixel,\n\n                                motion_source - d,\n\n                                motion_source + stride + 1 + d,\n\n                                stride, 8);\n\n                        }\n\n                    }\n\n\n\n                        s->dsp.clear_block(block);\n\n\n\n                    /* invert DCT and place (or add) in final output */\n\n\n\n                    if (s->all_fragments[i].coding_method == MODE_INTRA) {\n\n                        int index;\n\n                        index = vp3_dequant(s, s->all_fragments + i, plane, 0, block);\n\n                        if (index > 63)\n\n                            continue;\n\n                        if(s->avctx->idct_algo!=FF_IDCT_VP3)\n\n                            block[0] += 128<<3;\n\n                        s->dsp.idct_put(\n\n                            output_plane + first_pixel,\n\n                            stride,\n\n                            block);\n\n                    } else {\n\n                        int index = vp3_dequant(s, s->all_fragments + i, plane, 1, block);\n\n                        if (index > 63)\n\n                            continue;\n\n                        if (index > 0) {\n\n                        s->dsp.idct_add(\n\n                            output_plane + first_pixel,\n\n                            stride,\n\n                            block);\n\n                        } else {\n\n                            s->dsp.vp3_idct_dc_add(output_plane + first_pixel, stride, block);\n\n                        }\n\n                    }\n\n                } else {\n\n\n\n                    /* copy directly from the previous frame */\n\n                    s->dsp.put_pixels_tab[1][0](\n\n                        output_plane + first_pixel,\n\n                        last_plane + first_pixel,\n\n                        stride, 8);\n\n\n\n                }\n\n                }\n\n            }\n\n\n\n            // Filter up to the last row in the superblock row\n\n            if (!s->skip_loop_filter)\n\n                apply_loop_filter(s, plane, 4*sb_y - !!sb_y, FFMIN(4*sb_y+3, fragment_height-1));\n\n        }\n\n    }\n\n\n\n     /* this looks like a good place for slice dispatch... */\n\n     /* algorithm:\n\n      *   if (slice == s->macroblock_height - 1)\n\n      *     dispatch (both last slice & 2nd-to-last slice);\n\n      *   else if (slice > 0)\n\n      *     dispatch (slice - 1);\n\n      */\n\n\n\n    vp3_draw_horiz_band(s, FFMIN((32 << s->chroma_y_shift) * (slice + 1) -16, s->height-16));\n\n}\n", "idx": 24779}
{"project": "FFmpeg", "commit_id": "79db7ac6ef235a06c3049d7792eda39da28ee3fd", "target": 1, "func": "static int context_init(H264Context *h){\n\n    MpegEncContext * const s = &h->s;\n\n\n\n    CHECKED_ALLOCZ(h->top_borders[0], h->s.mb_width * (16+8+8) * sizeof(uint8_t))\n\n    CHECKED_ALLOCZ(h->top_borders[1], h->s.mb_width * (16+8+8) * sizeof(uint8_t))\n\n\n\n    // edge emu needs blocksize + filter length - 1 (=17x17 for halfpel / 21x21 for h264)\n\n    CHECKED_ALLOCZ(s->allocated_edge_emu_buffer,\n\n                   (s->width+64)*2*21*2); //(width + edge + align)*interlaced*MBsize*tolerance\n\n    s->edge_emu_buffer= s->allocated_edge_emu_buffer + (s->width+64)*2*21;\n\n    return 0;\n\nfail:\n\n    return -1; // free_tables will clean up for us\n\n}\n", "idx": 24782}
{"project": "FFmpeg", "commit_id": "f72e0d9a9f516be77d20c6a37dcd34add8f932e3", "target": 1, "func": "int ff_MPV_encode_picture(AVCodecContext *avctx, AVPacket *pkt,\n\n                          AVFrame *pic_arg, int *got_packet)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int i, stuffing_count, ret;\n\n    int context_count = s->slice_context_count;\n\n\n\n    s->picture_in_gop_number++;\n\n\n\n    if (load_input_picture(s, pic_arg) < 0)\n\n        return -1;\n\n\n\n    if (select_input_picture(s) < 0) {\n\n        return -1;\n\n    }\n\n\n\n    /* output? */\n\n    if (s->new_picture.f.data[0]) {\n\n        if ((ret = ff_alloc_packet2(avctx, pkt, s->mb_width*s->mb_height*(MAX_MB_BYTES+100)+10000)) < 0)\n\n            return ret;\n\n        if (s->mb_info) {\n\n            s->mb_info_ptr = av_packet_new_side_data(pkt,\n\n                                 AV_PKT_DATA_H263_MB_INFO,\n\n                                 s->mb_width*s->mb_height*12);\n\n            s->prev_mb_info = s->last_mb_info = s->mb_info_size = 0;\n\n        }\n\n\n\n        for (i = 0; i < context_count; i++) {\n\n            int start_y = s->thread_context[i]->start_mb_y;\n\n            int   end_y = s->thread_context[i]->  end_mb_y;\n\n            int h       = s->mb_height;\n\n            uint8_t *start = pkt->data + (size_t)(((int64_t) pkt->size) * start_y / h);\n\n            uint8_t *end   = pkt->data + (size_t)(((int64_t) pkt->size) *   end_y / h);\n\n\n\n            init_put_bits(&s->thread_context[i]->pb, start, end - start);\n\n        }\n\n\n\n        s->pict_type = s->new_picture.f.pict_type;\n\n        //emms_c();\n\n        //printf(\"qs:%f %f %d\\n\", s->new_picture.quality,\n\n        //       s->current_picture.quality, s->qscale);\n\n        ff_MPV_frame_start(s, avctx);\n\nvbv_retry:\n\n        if (encode_picture(s, s->picture_number) < 0)\n\n            return -1;\n\n\n\n        avctx->header_bits = s->header_bits;\n\n        avctx->mv_bits     = s->mv_bits;\n\n        avctx->misc_bits   = s->misc_bits;\n\n        avctx->i_tex_bits  = s->i_tex_bits;\n\n        avctx->p_tex_bits  = s->p_tex_bits;\n\n        avctx->i_count     = s->i_count;\n\n        // FIXME f/b_count in avctx\n\n        avctx->p_count     = s->mb_num - s->i_count - s->skip_count;\n\n        avctx->skip_count  = s->skip_count;\n\n\n\n        ff_MPV_frame_end(s);\n\n\n\n        if (CONFIG_MJPEG_ENCODER && s->out_format == FMT_MJPEG)\n\n            ff_mjpeg_encode_picture_trailer(s);\n\n\n\n        if (avctx->rc_buffer_size) {\n\n            RateControlContext *rcc = &s->rc_context;\n\n            int max_size = rcc->buffer_index * avctx->rc_max_available_vbv_use;\n\n\n\n            if (put_bits_count(&s->pb) > max_size &&\n\n                s->lambda < s->avctx->lmax) {\n\n                s->next_lambda = FFMAX(s->lambda + 1, s->lambda *\n\n                                       (s->qscale + 1) / s->qscale);\n\n                if (s->adaptive_quant) {\n\n                    int i;\n\n                    for (i = 0; i < s->mb_height * s->mb_stride; i++)\n\n                        s->lambda_table[i] =\n\n                            FFMAX(s->lambda_table[i] + 1,\n\n                                  s->lambda_table[i] * (s->qscale + 1) /\n\n                                  s->qscale);\n\n                }\n\n                s->mb_skipped = 0;        // done in MPV_frame_start()\n\n                // done in encode_picture() so we must undo it\n\n                if (s->pict_type == AV_PICTURE_TYPE_P) {\n\n                    if (s->flipflop_rounding          ||\n\n                        s->codec_id == CODEC_ID_H263P ||\n\n                        s->codec_id == CODEC_ID_MPEG4)\n\n                        s->no_rounding ^= 1;\n\n                }\n\n                if (s->pict_type != AV_PICTURE_TYPE_B) {\n\n                    s->time_base       = s->last_time_base;\n\n                    s->last_non_b_time = s->time - s->pp_time;\n\n                }\n\n                //av_log(NULL, AV_LOG_ERROR, \"R:%d \", s->next_lambda);\n\n                for (i = 0; i < context_count; i++) {\n\n                    PutBitContext *pb = &s->thread_context[i]->pb;\n\n                    init_put_bits(pb, pb->buf, pb->buf_end - pb->buf);\n\n                }\n\n                goto vbv_retry;\n\n            }\n\n\n\n            assert(s->avctx->rc_max_rate);\n\n        }\n\n\n\n        if (s->flags & CODEC_FLAG_PASS1)\n\n            ff_write_pass1_stats(s);\n\n\n\n        for (i = 0; i < 4; i++) {\n\n            s->current_picture_ptr->f.error[i] = s->current_picture.f.error[i];\n\n            avctx->error[i] += s->current_picture_ptr->f.error[i];\n\n        }\n\n\n\n        if (s->flags & CODEC_FLAG_PASS1)\n\n            assert(avctx->header_bits + avctx->mv_bits + avctx->misc_bits +\n\n                   avctx->i_tex_bits + avctx->p_tex_bits ==\n\n                       put_bits_count(&s->pb));\n\n        flush_put_bits(&s->pb);\n\n        s->frame_bits  = put_bits_count(&s->pb);\n\n\n\n        stuffing_count = ff_vbv_update(s, s->frame_bits);\n\n        if (stuffing_count) {\n\n            if (s->pb.buf_end - s->pb.buf - (put_bits_count(&s->pb) >> 3) <\n\n                    stuffing_count + 50) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"stuffing too large\\n\");\n\n                return -1;\n\n            }\n\n\n\n            switch (s->codec_id) {\n\n            case CODEC_ID_MPEG1VIDEO:\n\n            case CODEC_ID_MPEG2VIDEO:\n\n                while (stuffing_count--) {\n\n                    put_bits(&s->pb, 8, 0);\n\n                }\n\n            break;\n\n            case CODEC_ID_MPEG4:\n\n                put_bits(&s->pb, 16, 0);\n\n                put_bits(&s->pb, 16, 0x1C3);\n\n                stuffing_count -= 4;\n\n                while (stuffing_count--) {\n\n                    put_bits(&s->pb, 8, 0xFF);\n\n                }\n\n            break;\n\n            default:\n\n                av_log(s->avctx, AV_LOG_ERROR, \"vbv buffer overflow\\n\");\n\n            }\n\n            flush_put_bits(&s->pb);\n\n            s->frame_bits  = put_bits_count(&s->pb);\n\n        }\n\n\n\n        /* update mpeg1/2 vbv_delay for CBR */\n\n        if (s->avctx->rc_max_rate                          &&\n\n            s->avctx->rc_min_rate == s->avctx->rc_max_rate &&\n\n            s->out_format == FMT_MPEG1                     &&\n\n            90000LL * (avctx->rc_buffer_size - 1) <=\n\n                s->avctx->rc_max_rate * 0xFFFFLL) {\n\n            int vbv_delay, min_delay;\n\n            double inbits  = s->avctx->rc_max_rate *\n\n                             av_q2d(s->avctx->time_base);\n\n            int    minbits = s->frame_bits - 8 *\n\n                             (s->vbv_delay_ptr - s->pb.buf - 1);\n\n            double bits    = s->rc_context.buffer_index + minbits - inbits;\n\n\n\n            if (bits < 0)\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"Internal error, negative bits\\n\");\n\n\n\n            assert(s->repeat_first_field == 0);\n\n\n\n            vbv_delay = bits * 90000 / s->avctx->rc_max_rate;\n\n            min_delay = (minbits * 90000LL + s->avctx->rc_max_rate - 1) /\n\n                        s->avctx->rc_max_rate;\n\n\n\n            vbv_delay = FFMAX(vbv_delay, min_delay);\n\n\n\n            assert(vbv_delay < 0xFFFF);\n\n\n\n            s->vbv_delay_ptr[0] &= 0xF8;\n\n            s->vbv_delay_ptr[0] |= vbv_delay >> 13;\n\n            s->vbv_delay_ptr[1]  = vbv_delay >> 5;\n\n            s->vbv_delay_ptr[2] &= 0x07;\n\n            s->vbv_delay_ptr[2] |= vbv_delay << 3;\n\n            avctx->vbv_delay     = vbv_delay * 300;\n\n        }\n\n        s->total_bits     += s->frame_bits;\n\n        avctx->frame_bits  = s->frame_bits;\n\n\n\n        pkt->pts = s->current_picture.f.pts;\n\n        if (!s->low_delay && s->pict_type != AV_PICTURE_TYPE_B) {\n\n            if (!s->current_picture.f.coded_picture_number)\n\n                pkt->dts = pkt->pts - s->dts_delta;\n\n            else\n\n                pkt->dts = s->reordered_pts;\n\n            s->reordered_pts = pkt->pts;\n\n        } else\n\n            pkt->dts = pkt->pts;\n\n        if (s->current_picture.f.key_frame)\n\n            pkt->flags |= AV_PKT_FLAG_KEY;\n\n        if (s->mb_info)\n\n            av_packet_shrink_side_data(pkt, AV_PKT_DATA_H263_MB_INFO, s->mb_info_size);\n\n    } else {\n\n        assert((put_bits_ptr(&s->pb) == s->pb.buf));\n\n        s->frame_bits = 0;\n\n    }\n\n    assert((s->frame_bits & 7) == 0);\n\n\n\n    pkt->size = s->frame_bits / 8;\n\n    *got_packet = !!pkt->size;\n\n    return 0;\n\n}\n", "idx": 24783}
{"project": "FFmpeg", "commit_id": "2d0b4bc4cf92dd961dbafbff3f1f4a9e08a9565b", "target": 0, "func": "static int check_slice_end(RV34DecContext *r, MpegEncContext *s)\n\n{\n\n    int bits;\n\n    if(s->mb_y >= s->mb_height)\n\n        return 1;\n\n    if(!s->mb_num_left)\n\n        return 1;\n\n    if(r->s.mb_skip_run > 1)\n\n        return 0;\n\n    bits = get_bits_left(&s->gb);\n\n    if(bits < 0 || (bits < 8 && !show_bits(&s->gb, bits)))\n\n        return 1;\n\n    return 0;\n\n}\n", "idx": 24784}
{"project": "FFmpeg", "commit_id": "bb4c9d0a8ead02f7d943c2bae3e36b30e605b30b", "target": 0, "func": "static int alloc_frame_buffer(AVCodecContext *avctx,  Picture *pic,\n\n                              MotionEstContext *me, ScratchpadContext *sc,\n\n                              int chroma_x_shift, int chroma_y_shift,\n\n                              int linesize, int uvlinesize)\n\n{\n\n    int edges_needed = av_codec_is_encoder(avctx->codec);\n\n    int r, ret;\n\n\n\n    pic->tf.f = pic->f;\n\n    if (avctx->codec_id != AV_CODEC_ID_WMV3IMAGE &&\n\n        avctx->codec_id != AV_CODEC_ID_VC1IMAGE  &&\n\n        avctx->codec_id != AV_CODEC_ID_MSS2) {\n\n        if (edges_needed) {\n\n            pic->f->width  = avctx->width  + 2 * EDGE_WIDTH;\n\n            pic->f->height = avctx->height + 2 * EDGE_WIDTH;\n\n        }\n\n\n\n        r = ff_thread_get_buffer(avctx, &pic->tf,\n\n                                 pic->reference ? AV_GET_BUFFER_FLAG_REF : 0);\n\n    } else {\n\n        pic->f->width  = avctx->width;\n\n        pic->f->height = avctx->height;\n\n        pic->f->format = avctx->pix_fmt;\n\n        r = avcodec_default_get_buffer2(avctx, pic->f, 0);\n\n    }\n\n\n\n    if (r < 0 || !pic->f->buf[0]) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed (%d %p)\\n\",\n\n               r, pic->f->data[0]);\n\n        return -1;\n\n    }\n\n\n\n    if (edges_needed) {\n\n        int i;\n\n        for (i = 0; pic->f->data[i]; i++) {\n\n            int offset = (EDGE_WIDTH >> (i ? chroma_y_shift : 0)) *\n\n                         pic->f->linesize[i] +\n\n                         (EDGE_WIDTH >> (i ? chroma_x_shift : 0));\n\n            pic->f->data[i] += offset;\n\n        }\n\n        pic->f->width  = avctx->width;\n\n        pic->f->height = avctx->height;\n\n    }\n\n\n\n    if (avctx->hwaccel) {\n\n        assert(!pic->hwaccel_picture_private);\n\n        if (avctx->hwaccel->frame_priv_data_size) {\n\n            pic->hwaccel_priv_buf = av_buffer_allocz(avctx->hwaccel->frame_priv_data_size);\n\n            if (!pic->hwaccel_priv_buf) {\n\n                av_log(avctx, AV_LOG_ERROR, \"alloc_frame_buffer() failed (hwaccel private data allocation)\\n\");\n\n                return -1;\n\n            }\n\n            pic->hwaccel_picture_private = pic->hwaccel_priv_buf->data;\n\n        }\n\n    }\n\n\n\n    if (linesize && (linesize   != pic->f->linesize[0] ||\n\n                     uvlinesize != pic->f->linesize[1])) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"get_buffer() failed (stride changed)\\n\");\n\n        ff_mpeg_unref_picture(avctx, pic);\n\n        return -1;\n\n    }\n\n\n\n    if (pic->f->linesize[1] != pic->f->linesize[2]) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"get_buffer() failed (uv stride mismatch)\\n\");\n\n        ff_mpeg_unref_picture(avctx, pic);\n\n        return -1;\n\n    }\n\n\n\n    if (!sc->edge_emu_buffer &&\n\n        (ret = ff_mpeg_framesize_alloc(avctx, me, sc,\n\n                                       pic->f->linesize[0])) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"get_buffer() failed to allocate context scratch buffers.\\n\");\n\n        ff_mpeg_unref_picture(avctx, pic);\n\n        return ret;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24785}
{"project": "FFmpeg", "commit_id": "72dbc610be3272ba36603f78a39cc2d2d8fe0cc3", "target": 0, "func": "void ff_avg_h264_qpel4_mc32_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_midh_qrt_and_aver_dst_4w_msa(src - (2 * stride) - 2,\n\n                                          stride, dst, stride, 4, 1);\n\n}\n", "idx": 24786}
{"project": "FFmpeg", "commit_id": "6df2c94130b026930d1f7148699925dcaa08759c", "target": 0, "func": "static void draw_bar_yuv(AVFrame *out, const float *h, const float *rcp_h,\n\n                         const ColorFloat *c, int bar_h)\n\n{\n\n    int x, y, yh, w = out->width;\n\n    float mul, ht, rcp_bar_h = 1.0f / bar_h;\n\n    uint8_t *vy = out->data[0], *vu = out->data[1], *vv = out->data[2];\n\n    uint8_t *lpy, *lpu, *lpv;\n\n    int lsy = out->linesize[0], lsu = out->linesize[1], lsv = out->linesize[2];\n\n    int fmt = out->format;\n\n\n\n    for (y = 0; y < bar_h; y += 2) {\n\n        yh = (fmt == AV_PIX_FMT_YUV420P) ? y / 2 : y;\n\n        ht = (bar_h - y) * rcp_bar_h;\n\n        lpy = vy + y * lsy;\n\n        lpu = vu + yh * lsu;\n\n        lpv = vv + yh * lsv;\n\n        for (x = 0; x < w; x += 2) {\n\n            if (h[x] <= ht) {\n\n                *lpy++ = 16;\n\n                *lpu++ = 128;\n\n                *lpv++ = 128;\n\n            } else {\n\n                mul = (h[x] - ht) * rcp_h[x];\n\n                *lpy++ = mul * c[x].yuv.y + (1.0f - mul) * 16.0f + 0.5f;\n\n                *lpu++ = mul * c[x].yuv.u + (1.0f - mul) * 128.0f + 0.5f;\n\n                *lpv++ = mul * c[x].yuv.v + (1.0f - mul) * 128.0f + 0.5f;\n\n            }\n\n            /* u and v are skipped on yuv422p and yuv420p */\n\n            if (fmt == AV_PIX_FMT_YUV444P) {\n\n                if (h[x+1] <= ht) {\n\n                    *lpy++ = 16;\n\n                    *lpu++ = 128;\n\n                    *lpv++ = 128;\n\n                } else {\n\n                    mul = (h[x+1] - ht) * rcp_h[x+1];\n\n                    *lpy++ = mul * c[x+1].yuv.y + (1.0f - mul) * 16.0f + 0.5f;\n\n                    *lpu++ = mul * c[x+1].yuv.u + (1.0f - mul) * 128.0f + 0.5f;\n\n                    *lpv++ = mul * c[x+1].yuv.v + (1.0f - mul) * 128.0f + 0.5f;\n\n                }\n\n            } else {\n\n                if (h[x+1] <= ht) {\n\n                    *lpy++ = 16;\n\n                } else {\n\n                    mul = (h[x+1] - ht) * rcp_h[x+1];\n\n                    *lpy++ = mul * c[x+1].yuv.y + (1.0f - mul) * 16.0f + 0.5f;\n\n                }\n\n            }\n\n        }\n\n\n\n        ht = (bar_h - (y+1)) * rcp_bar_h;\n\n        lpy = vy + (y+1) * lsy;\n\n        lpu = vu + (y+1) * lsu;\n\n        lpv = vv + (y+1) * lsv;\n\n        for (x = 0; x < w; x += 2) {\n\n            /* u and v are skipped on yuv420p */\n\n            if (fmt != AV_PIX_FMT_YUV420P) {\n\n                if (h[x] <= ht) {\n\n                    *lpy++ = 16;\n\n                    *lpu++ = 128;\n\n                    *lpv++ = 128;\n\n                } else {\n\n                    mul = (h[x] - ht) * rcp_h[x];\n\n                    *lpy++ = mul * c[x].yuv.y + (1.0f - mul) * 16.0f + 0.5f;\n\n                    *lpu++ = mul * c[x].yuv.u + (1.0f - mul) * 128.0f + 0.5f;\n\n                    *lpv++ = mul * c[x].yuv.v + (1.0f - mul) * 128.0f + 0.5f;\n\n                }\n\n            } else {\n\n                if (h[x] <= ht) {\n\n                    *lpy++ = 16;\n\n                } else {\n\n                    mul = (h[x] - ht) * rcp_h[x];\n\n                    *lpy++ = mul * c[x].yuv.y + (1.0f - mul) * 16.0f + 0.5f;\n\n                }\n\n            }\n\n            /* u and v are skipped on yuv422p and yuv420p */\n\n            if (out->format == AV_PIX_FMT_YUV444P) {\n\n                if (h[x+1] <= ht) {\n\n                    *lpy++ = 16;\n\n                    *lpu++ = 128;\n\n                    *lpv++ = 128;\n\n                } else {\n\n                    mul = (h[x+1] - ht) * rcp_h[x+1];\n\n                    *lpy++ = mul * c[x+1].yuv.y + (1.0f - mul) * 16.0f + 0.5f;\n\n                    *lpu++ = mul * c[x+1].yuv.u + (1.0f - mul) * 128.0f + 0.5f;\n\n                    *lpv++ = mul * c[x+1].yuv.v + (1.0f - mul) * 128.0f + 0.5f;\n\n                }\n\n            } else {\n\n                if (h[x+1] <= ht) {\n\n                    *lpy++ = 16;\n\n                } else {\n\n                    mul = (h[x+1] - ht) * rcp_h[x+1];\n\n                    *lpy++ = mul * c[x+1].yuv.y + (1.0f - mul) * 16.0f + 0.5f;\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 24787}
{"project": "FFmpeg", "commit_id": "e87190f5d20d380608f792ceb14d0def1d80e24b", "target": 0, "func": "static void show_programs(WriterContext *w, AVFormatContext *fmt_ctx)\n\n{\n\n    int i;\n\n\n\n    writer_print_section_header(w, SECTION_ID_PROGRAMS);\n\n    for (i = 0; i < fmt_ctx->nb_programs; i++) {\n\n        AVProgram *program = fmt_ctx->programs[i];\n\n        if (!program)\n\n            continue;\n\n        show_program(w, fmt_ctx, program);\n\n    }\n\n    writer_print_section_footer(w);\n\n}\n", "idx": 24788}
{"project": "FFmpeg", "commit_id": "66f26b3e8ec075298e7ba329a55893d085bafe96", "target": 0, "func": "static int put_flac_codecpriv(AVFormatContext *s,\n\n                              AVIOContext *pb, AVCodecContext *codec)\n\n{\n\n    int write_comment = (codec->channel_layout &&\n\n                         !(codec->channel_layout & ~0x3ffffULL) &&\n\n                         !ff_flac_is_native_layout(codec->channel_layout));\n\n    int ret = ff_flac_write_header(pb, codec->extradata, codec->extradata_size,\n\n                                   !write_comment);\n\n\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (write_comment) {\n\n        const char *vendor = (s->flags & AVFMT_FLAG_BITEXACT) ?\n\n                             \"Lavf\" : LIBAVFORMAT_IDENT;\n\n        AVDictionary *dict = NULL;\n\n        uint8_t buf[32], *data, *p;\n\n        int len;\n\n\n\n        snprintf(buf, sizeof(buf), \"0x%\"PRIx64, codec->channel_layout);\n\n        av_dict_set(&dict, \"WAVEFORMATEXTENSIBLE_CHANNEL_MASK\", buf, 0);\n\n\n\n        len = ff_vorbiscomment_length(dict, vendor);\n\n        data = av_malloc(len + 4);\n\n        if (!data) {\n\n            av_dict_free(&dict);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n\n\n        data[0] = 0x84;\n\n        AV_WB24(data + 1, len);\n\n\n\n        p = data + 4;\n\n        ff_vorbiscomment_write(&p, &dict, vendor);\n\n\n\n        avio_write(pb, data, len + 4);\n\n\n\n        av_freep(&data);\n\n        av_dict_free(&dict);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24789}
{"project": "FFmpeg", "commit_id": "d2c5f0a4bf23758abd49ec2d0e1f7c3d17eea466", "target": 0, "func": "static int avi_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    AVIContext *avi = s->priv_data;\n\n    ByteIOContext *pb = &s->pb;\n\n    int n, d[8], size;\n\n    offset_t i;\n\n    void* dstr;\n\n\n\n    memset(d, -1, sizeof(int)*8);\n\n   \n\n    if (avi->dv_demux) {\n\n        size = dv_get_packet(avi->dv_demux, pkt);\n\n\tif (size >= 0)\n\n\t    return size;\n\n    }\n\n        \n\n    for(i=url_ftell(pb); !url_feof(pb); i++) {\n\n        int j;\n\n\n\n\tif (i >= avi->movi_end) {\n\n\t    if (avi->is_odml) {\n\n\t\turl_fskip(pb, avi->riff_end - i);\n\n\t        avi->riff_end = avi->movi_end = url_filesize(url_fileno(pb));\n\n\t    } else\n\n\t        break;\n\n\t}\n\n\n\n        for(j=0; j<7; j++)\n\n            d[j]= d[j+1];\n\n        d[7]= get_byte(pb);\n\n        \n\n        size= d[4] + (d[5]<<8) + (d[6]<<16) + (d[7]<<24);\n\n        \n\n        //parse ix##\n\n        n= (d[2] - '0') * 10 + (d[3] - '0');\n\n        if(    d[2] >= '0' && d[2] <= '9'\n\n            && d[3] >= '0' && d[3] <= '9'\n\n            && d[0] == 'i' && d[1] == 'x'\n\n            && n < s->nb_streams\n\n            && i + size <= avi->movi_end){\n\n            \n\n            url_fskip(pb, size);\n\n        }\n\n\n\n\t//parse JUNK\n\n        if(d[0] == 'J' && d[1] == 'U' && d[2] == 'N' && d[3] == 'K' &&\n\n           i + size <= avi->movi_end) {\n\n            \n\n            url_fskip(pb, size);\n\n        }\n\n        \n\n        //parse ##dc/##wb\n\n        n= (d[0] - '0') * 10 + (d[1] - '0');\n\n        if(    d[0] >= '0' && d[0] <= '9'\n\n            && d[1] >= '0' && d[1] <= '9'\n\n            && ((d[2] == 'd' && d[3] == 'c') || \n\n\t        (d[2] == 'w' && d[3] == 'b') || \n\n\t\t(d[2] == 'd' && d[3] == 'b') ||\n\n\t\t(d[2] == '_' && d[3] == '_'))\n\n            && n < s->nb_streams\n\n            && i + size <= avi->movi_end) {\n\n        \n\n            av_new_packet(pkt, size);\n\n            get_buffer(pb, pkt->data, size);\n\n            if (size & 1) {\n\n                get_byte(pb);\n\n\t\tsize++;\n\n\t    }\n\n\t\n\n\t    if (avi->dv_demux) {\n\n\t        dstr = pkt->destruct;\n\n\t        size = dv_produce_packet(avi->dv_demux, pkt,\n\n\t\t                         pkt->data, pkt->size);\n\n\t\tpkt->destruct = dstr;\n\n                pkt->flags |= PKT_FLAG_KEY;\n\n\t    } else {\n\n                AVStream *st;\n\n                AVIStream *ast;\n\n                st = s->streams[n];\n\n                ast = st->priv_data;\n\n                \n\n                /* XXX: how to handle B frames in avi ? */\n\n                pkt->dts = ast->frame_offset;\n\n//                pkt->dts += ast->start;\n\n                if(ast->sample_size)\n\n                    pkt->dts /= ast->sample_size;\n\n//av_log(NULL, AV_LOG_DEBUG, \"dts:%Ld offset:%d %d/%d smpl_siz:%d base:%d st:%d size:%d\\n\", pkt->dts, ast->frame_offset, ast->scale, ast->rate, ast->sample_size, AV_TIME_BASE, n, size);\n\n                pkt->stream_index = n;\n\n                /* FIXME: We really should read index for that */\n\n                if (st->codec.codec_type == CODEC_TYPE_VIDEO) {\n\n                    if (ast->frame_offset < ast->nb_index_entries) {\n\n                        if (ast->index_entries[ast->frame_offset].flags & AVIIF_INDEX)\n\n                            pkt->flags |= PKT_FLAG_KEY; \n\n                    } else {\n\n                        /* if no index, better to say that all frames\n\n                           are key frames */\n\n                        pkt->flags |= PKT_FLAG_KEY;\n\n                    }\n\n                } else {\n\n                    pkt->flags |= PKT_FLAG_KEY; \n\n                }\n\n                if(ast->sample_size)\n\n                    ast->frame_offset += pkt->size;\n\n                else\n\n                    ast->frame_offset++;\n\n\t    }\n\n            return size;\n\n        }\n\n    }\n\n    return -1;\n\n}\n", "idx": 24790}
{"project": "FFmpeg", "commit_id": "b2244fa0a624f7e38893d58265e9c039bed2e4de", "target": 1, "func": "static int rscc_decode_frame(AVCodecContext *avctx, void *data,\n\n                                     int *got_frame, AVPacket *avpkt)\n\n{\n\n    RsccContext *ctx = avctx->priv_data;\n\n    GetByteContext *gbc = &ctx->gbc;\n\n    GetByteContext tiles_gbc;\n\n    AVFrame *frame = data;\n\n    const uint8_t *pixels, *raw;\n\n    uint8_t *inflated_tiles = NULL;\n\n    int tiles_nb, packed_size, pixel_size = 0;\n\n    int i, ret = 0;\n\n\n\n    bytestream2_init(gbc, avpkt->data, avpkt->size);\n\n\n\n    /* Size check */\n\n    if (bytestream2_get_bytes_left(gbc) < 12) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Packet too small (%d)\\n\", avpkt->size);\n\n        return AVERROR_INVALIDDATA;\n\n\n\n\n    /* Read number of tiles, and allocate the array */\n\n    tiles_nb = bytestream2_get_le16(gbc);\n\n    av_fast_malloc(&ctx->tiles, &ctx->tiles_size,\n\n                   tiles_nb * sizeof(*ctx->tiles));\n\n    if (!ctx->tiles) {\n\n        ret = AVERROR(ENOMEM);\n\n\n\n\n\n    av_log(avctx, AV_LOG_DEBUG, \"Frame with %d tiles.\\n\", tiles_nb);\n\n\n\n    /* When there are more than 5 tiles, they are packed together with\n\n     * a size header. When that size does not match the number of tiles\n\n     * times the tile size, it means it needs to be inflated as well */\n\n    if (tiles_nb > 5) {\n\n        uLongf packed_tiles_size;\n\n\n\n        if (tiles_nb < 32)\n\n            packed_tiles_size = bytestream2_get_byte(gbc);\n\n        else\n\n            packed_tiles_size = bytestream2_get_le16(gbc);\n\n\n\n        ff_dlog(avctx, \"packed tiles of size %lu.\\n\", packed_tiles_size);\n\n\n\n        /* If necessary, uncompress tiles, and hijack the bytestream reader */\n\n        if (packed_tiles_size != tiles_nb * TILE_SIZE) {\n\n            uLongf length = tiles_nb * TILE_SIZE;\n\n            inflated_tiles = av_malloc(length);\n\n            if (!inflated_tiles) {\n\n                ret = AVERROR(ENOMEM);\n\n\n\n\n\n            ret = uncompress(inflated_tiles, &length,\n\n                             gbc->buffer, packed_tiles_size);\n\n            if (ret) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Tile deflate error %d.\\n\", ret);\n\n                ret = AVERROR_UNKNOWN;\n\n\n\n\n\n            /* Skip the compressed tile section in the main byte reader,\n\n             * and point it to read the newly uncompressed data */\n\n            bytestream2_skip(gbc, packed_tiles_size);\n\n            bytestream2_init(&tiles_gbc, inflated_tiles, length);\n\n            gbc = &tiles_gbc;\n\n\n\n\n\n    /* Fill in array of tiles, keeping track of how many pixels are updated */\n\n    for (i = 0; i < tiles_nb; i++) {\n\n        ctx->tiles[i].x = bytestream2_get_le16(gbc);\n\n        ctx->tiles[i].w = bytestream2_get_le16(gbc);\n\n        ctx->tiles[i].y = bytestream2_get_le16(gbc);\n\n        ctx->tiles[i].h = bytestream2_get_le16(gbc);\n\n\n\n        pixel_size += ctx->tiles[i].w * ctx->tiles[i].h * ctx->component_size;\n\n\n\n        ff_dlog(avctx, \"tile %d orig(%d,%d) %dx%d.\\n\", i,\n\n                ctx->tiles[i].x, ctx->tiles[i].y,\n\n                ctx->tiles[i].w, ctx->tiles[i].h);\n\n\n\n        if (ctx->tiles[i].w == 0 || ctx->tiles[i].h == 0) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"invalid tile %d at (%d.%d) with size %dx%d.\\n\", i,\n\n                   ctx->tiles[i].x, ctx->tiles[i].y,\n\n                   ctx->tiles[i].w, ctx->tiles[i].h);\n\n\n\n        } else if (ctx->tiles[i].x + ctx->tiles[i].w > avctx->width ||\n\n                   ctx->tiles[i].y + ctx->tiles[i].h > avctx->height) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"out of bounds tile %d at (%d.%d) with size %dx%d.\\n\", i,\n\n                   ctx->tiles[i].x, ctx->tiles[i].y,\n\n                   ctx->tiles[i].w, ctx->tiles[i].h);\n\n\n\n\n\n\n\n    /* Reset the reader in case it had been modified before */\n\n    gbc = &ctx->gbc;\n\n\n\n    /* Extract how much pixel data the tiles contain */\n\n    if (pixel_size < 0x100)\n\n        packed_size = bytestream2_get_byte(gbc);\n\n    else if (pixel_size < 0x10000)\n\n        packed_size = bytestream2_get_le16(gbc);\n\n    else if (pixel_size < 0x1000000)\n\n        packed_size = bytestream2_get_le24(gbc);\n\n    else\n\n        packed_size = bytestream2_get_le32(gbc);\n\n\n\n    ff_dlog(avctx, \"pixel_size %d packed_size %d.\\n\", pixel_size, packed_size);\n\n\n\n    if (packed_size < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid tile size %d\\n\", packed_size);\n\n\n\n\n\n\n    /* Get pixels buffer, it may be deflated or just raw */\n\n    if (pixel_size == packed_size) {\n\n        if (bytestream2_get_bytes_left(gbc) < pixel_size) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Insufficient input for %d\\n\", pixel_size);\n\n\n\n\n        pixels = gbc->buffer;\n\n    } else {\n\n        uLongf len = ctx->inflated_size;\n\n\n\n\n\n\n        ret = uncompress(ctx->inflated_buf, &len, gbc->buffer, packed_size);\n\n        if (ret) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Pixel deflate error %d.\\n\", ret);\n\n            ret = AVERROR_UNKNOWN;\n\n\n\n        pixels = ctx->inflated_buf;\n\n\n\n\n    /* Allocate when needed */\n\n    ret = ff_reget_buffer(avctx, ctx->reference);\n\n    if (ret < 0)\n\n\n\n\n    /* Pointer to actual pixels, will be updated when data is consumed */\n\n    raw = pixels;\n\n    for (i = 0; i < tiles_nb; i++) {\n\n        uint8_t *dst = ctx->reference->data[0] + ctx->reference->linesize[0] *\n\n                       (avctx->height - ctx->tiles[i].y - 1) +\n\n                       ctx->tiles[i].x * ctx->component_size;\n\n        av_image_copy_plane(dst, -1 * ctx->reference->linesize[0],\n\n                            raw, ctx->tiles[i].w * ctx->component_size,\n\n                            ctx->tiles[i].w * ctx->component_size,\n\n                            ctx->tiles[i].h);\n\n        raw += ctx->tiles[i].w * ctx->component_size * ctx->tiles[i].h;\n\n\n\n\n    /* Frame is ready to be output */\n\n    ret = av_frame_ref(frame, ctx->reference);\n\n    if (ret < 0)\n\n\n\n\n    /* Keyframe when the number of pixels updated matches the whole surface */\n\n    if (pixel_size == ctx->inflated_size) {\n\n        frame->pict_type = AV_PICTURE_TYPE_I;\n\n        frame->key_frame = 1;\n\n    } else {\n\n        frame->pict_type = AV_PICTURE_TYPE_P;\n\n\n    *got_frame = 1;\n\n\n\nend:\n\n    av_free(inflated_tiles);\n\n    return ret;\n", "idx": 24792}
{"project": "FFmpeg", "commit_id": "1662bd350a470f1cbd5c2cc9a0e1bfaa8543033f", "target": 1, "func": "static int64_t wrap_timestamp(AVStream *st, int64_t timestamp)\n\n{\n\n    if (st->pts_wrap_behavior != AV_PTS_WRAP_IGNORE && st->pts_wrap_bits < 64 &&\n\n        st->pts_wrap_reference != AV_NOPTS_VALUE && timestamp != AV_NOPTS_VALUE) {\n\n        if (st->pts_wrap_behavior == AV_PTS_WRAP_ADD_OFFSET &&\n\n            timestamp < st->pts_wrap_reference)\n\n            return timestamp + (1LL<<st->pts_wrap_bits);\n\n        else if (st->pts_wrap_behavior == AV_PTS_WRAP_SUB_OFFSET &&\n\n            timestamp >= st->pts_wrap_reference)\n\n            return timestamp - (1LL<<st->pts_wrap_bits);\n\n    }\n\n    return timestamp;\n\n}\n", "idx": 24793}
{"project": "FFmpeg", "commit_id": "8635954335061ea4c03d3f492b7bc803ea740d9c", "target": 1, "func": "static void write_section_data(AVFormatContext *s, MpegTSFilter *tss1,\n\n                               const uint8_t *buf, int buf_size, int is_start)\n\n{\n\n    MpegTSContext *ts = s->priv_data;\n\n    MpegTSSectionFilter *tss = &tss1->u.section_filter;\n\n    int len;\n\n\n\n    if (is_start) {\n\n        memcpy(tss->section_buf, buf, buf_size);\n\n        tss->section_index = buf_size;\n\n        tss->section_h_size = -1;\n\n        tss->end_of_section_reached = 0;\n\n    } else {\n\n        if (tss->end_of_section_reached)\n\n            return;\n\n        len = 4096 - tss->section_index;\n\n        if (buf_size < len)\n\n            len = buf_size;\n\n        memcpy(tss->section_buf + tss->section_index, buf, len);\n\n        tss->section_index += len;\n\n    }\n\n\n\n    /* compute section length if possible */\n\n    if (tss->section_h_size == -1 && tss->section_index >= 3) {\n\n        len = (AV_RB16(tss->section_buf + 1) & 0xfff) + 3;\n\n        if (len > 4096)\n\n            return;\n\n        tss->section_h_size = len;\n\n    }\n\n\n\n    if (tss->section_h_size != -1 &&\n\n        tss->section_index >= tss->section_h_size) {\n\n        int crc_valid = 1;\n\n        tss->end_of_section_reached = 1;\n\n\n\n        if (tss->check_crc) {\n\n            crc_valid = !av_crc(av_crc_get_table(AV_CRC_32_IEEE), -1, tss->section_buf, tss->section_h_size);\n\n            if (crc_valid) {\n\n                ts->crc_validity[ tss1->pid ] = 100;\n\n            }else if (ts->crc_validity[ tss1->pid ] > -10) {\n\n                ts->crc_validity[ tss1->pid ]--;\n\n            }else\n\n                crc_valid = 2;\n\n        }\n\n        if (crc_valid)\n\n            tss->section_cb(tss1, tss->section_buf, tss->section_h_size);\n\n    }\n\n}\n", "idx": 24795}
{"project": "FFmpeg", "commit_id": "529a25d6e5c3ff889257a57042872d84dc2312d5", "target": 1, "func": "static int dpcm_decode_frame(AVCodecContext *avctx, void *data,\n\n                             int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    const uint8_t *buf_end = buf + buf_size;\n\n    DPCMContext *s = avctx->priv_data;\n\n    int out = 0, ret;\n\n    int predictor[2];\n\n    int ch = 0;\n\n    int stereo = s->channels - 1;\n\n    int16_t *output_samples;\n\n\n\n    /* calculate output size */\n\n    switch(avctx->codec->id) {\n\n    case CODEC_ID_ROQ_DPCM:\n\n        out = buf_size - 8;\n\n        break;\n\n    case CODEC_ID_INTERPLAY_DPCM:\n\n        out = buf_size - 6 - s->channels;\n\n        break;\n\n    case CODEC_ID_XAN_DPCM:\n\n        out = buf_size - 2 * s->channels;\n\n        break;\n\n    case CODEC_ID_SOL_DPCM:\n\n        if (avctx->codec_tag != 3)\n\n            out = buf_size * 2;\n\n        else\n\n            out = buf_size;\n\n        break;\n\n    }\n\n    if (out <= 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"packet is too small\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    /* get output buffer */\n\n    s->frame.nb_samples = out / s->channels;\n\n    if ((ret = avctx->get_buffer(avctx, &s->frame)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n    output_samples = (int16_t *)s->frame.data[0];\n\n\n\n    switch(avctx->codec->id) {\n\n\n\n    case CODEC_ID_ROQ_DPCM:\n\n        buf += 6;\n\n\n\n        if (stereo) {\n\n            predictor[1] = (int16_t)(bytestream_get_byte(&buf) << 8);\n\n            predictor[0] = (int16_t)(bytestream_get_byte(&buf) << 8);\n\n        } else {\n\n            predictor[0] = (int16_t)bytestream_get_le16(&buf);\n\n        }\n\n\n\n        /* decode the samples */\n\n        while (buf < buf_end) {\n\n            predictor[ch] += s->roq_square_array[*buf++];\n\n            predictor[ch]  = av_clip_int16(predictor[ch]);\n\n            *output_samples++ = predictor[ch];\n\n\n\n            /* toggle channel */\n\n            ch ^= stereo;\n\n        }\n\n        break;\n\n\n\n    case CODEC_ID_INTERPLAY_DPCM:\n\n        buf += 6;  /* skip over the stream mask and stream length */\n\n\n\n        for (ch = 0; ch < s->channels; ch++) {\n\n            predictor[ch] = (int16_t)bytestream_get_le16(&buf);\n\n            *output_samples++ = predictor[ch];\n\n        }\n\n\n\n        ch = 0;\n\n        while (buf < buf_end) {\n\n            predictor[ch] += interplay_delta_table[*buf++];\n\n            predictor[ch]  = av_clip_int16(predictor[ch]);\n\n            *output_samples++ = predictor[ch];\n\n\n\n            /* toggle channel */\n\n            ch ^= stereo;\n\n        }\n\n        break;\n\n\n\n    case CODEC_ID_XAN_DPCM:\n\n    {\n\n        int shift[2] = { 4, 4 };\n\n\n\n        for (ch = 0; ch < s->channels; ch++)\n\n            predictor[ch] = (int16_t)bytestream_get_le16(&buf);\n\n\n\n        ch = 0;\n\n        while (buf < buf_end) {\n\n            uint8_t n = *buf++;\n\n            int16_t diff = (n & 0xFC) << 8;\n\n            if ((n & 0x03) == 3)\n\n                shift[ch]++;\n\n            else\n\n                shift[ch] -= (2 * (n & 3));\n\n            /* saturate the shifter to a lower limit of 0 */\n\n            if (shift[ch] < 0)\n\n                shift[ch] = 0;\n\n\n\n            diff >>= shift[ch];\n\n            predictor[ch] += diff;\n\n\n\n            predictor[ch] = av_clip_int16(predictor[ch]);\n\n            *output_samples++ = predictor[ch];\n\n\n\n            /* toggle channel */\n\n            ch ^= stereo;\n\n        }\n\n        break;\n\n    }\n\n    case CODEC_ID_SOL_DPCM:\n\n        if (avctx->codec_tag != 3) {\n\n            uint8_t *output_samples_u8 = data;\n\n            while (buf < buf_end) {\n\n                uint8_t n = *buf++;\n\n\n\n                s->sample[0] += s->sol_table[n >> 4];\n\n                s->sample[0]  = av_clip_uint8(s->sample[0]);\n\n                *output_samples_u8++ = s->sample[0];\n\n\n\n                s->sample[stereo] += s->sol_table[n & 0x0F];\n\n                s->sample[stereo]  = av_clip_uint8(s->sample[stereo]);\n\n                *output_samples_u8++ = s->sample[stereo];\n\n            }\n\n        } else {\n\n            while (buf < buf_end) {\n\n                uint8_t n = *buf++;\n\n                if (n & 0x80) s->sample[ch] -= sol_table_16[n & 0x7F];\n\n                else          s->sample[ch] += sol_table_16[n & 0x7F];\n\n                s->sample[ch] = av_clip_int16(s->sample[ch]);\n\n                *output_samples++ = s->sample[ch];\n\n                /* toggle channel */\n\n                ch ^= stereo;\n\n            }\n\n        }\n\n        break;\n\n    }\n\n\n\n    *got_frame_ptr   = 1;\n\n    *(AVFrame *)data = s->frame;\n\n\n\n    return buf_size;\n\n}\n", "idx": 24797}
{"project": "FFmpeg", "commit_id": "f52fbf4f3ed02a7d872d8a102006f29b4421f360", "target": 1, "func": "static int decode_dds1(GetByteContext *gb, uint8_t *frame, int width, int height)\n\n{\n\n    const uint8_t *frame_start = frame;\n\n    const uint8_t *frame_end   = frame + width * height;\n\n    int mask = 0x10000, bitbuf = 0;\n\n    int i, v, offset, count, segments;\n\n\n\n    segments = bytestream2_get_le16(gb);\n\n    while (segments--) {\n\n        if (bytestream2_get_bytes_left(gb) < 2)\n\n            return AVERROR_INVALIDDATA;\n\n        if (mask == 0x10000) {\n\n            bitbuf = bytestream2_get_le16u(gb);\n\n            mask = 1;\n\n        }\n\n\n\n        if (bitbuf & mask) {\n\n            v = bytestream2_get_le16(gb);\n\n            offset = (v & 0x1FFF) << 2;\n\n            count = ((v >> 13) + 2) << 1;\n\n            if (frame - frame_start < offset || frame_end - frame < count*2 + width)\n\n                return AVERROR_INVALIDDATA;\n\n            for (i = 0; i < count; i++) {\n\n                frame[0] = frame[1] =\n\n                frame[width] = frame[width + 1] = frame[-offset];\n\n\n\n                frame += 2;\n\n            }\n\n        } else if (bitbuf & (mask << 1)) {\n\n            v = bytestream2_get_le16(gb)*2;\n\n            if (frame - frame_end < v)\n\n                return AVERROR_INVALIDDATA;\n\n            frame += v;\n\n        } else {\n\n            if (frame_end - frame < width + 3)\n\n                return AVERROR_INVALIDDATA;\n\n            frame[0] = frame[1] =\n\n            frame[width] = frame[width + 1] =  bytestream2_get_byte(gb);\n\n            frame += 2;\n\n            frame[0] = frame[1] =\n\n            frame[width] = frame[width + 1] =  bytestream2_get_byte(gb);\n\n            frame += 2;\n\n        }\n\n        mask <<= 2;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24799}
{"project": "FFmpeg", "commit_id": "2b44dcbc44e99daf9515753e9fd4c2e1ea53a2fa", "target": 1, "func": "int ff_hevc_decode_short_term_rps(GetBitContext *gb, AVCodecContext *avctx,\n\n                                  ShortTermRPS *rps, const HEVCSPS *sps, int is_slice_header)\n\n{\n\n    uint8_t rps_predict = 0;\n\n    int delta_poc;\n\n    int k0 = 0;\n\n    int k1 = 0;\n\n    int k  = 0;\n\n    int i;\n\n\n\n    if (rps != sps->st_rps && sps->nb_st_rps)\n\n        rps_predict = get_bits1(gb);\n\n\n\n    if (rps_predict) {\n\n        const ShortTermRPS *rps_ridx;\n\n        int delta_rps;\n\n        unsigned abs_delta_rps;\n\n        uint8_t use_delta_flag = 0;\n\n        uint8_t delta_rps_sign;\n\n\n\n        if (is_slice_header) {\n\n            unsigned int delta_idx = get_ue_golomb_long(gb) + 1;\n\n            if (delta_idx > sps->nb_st_rps) {\n\n\n                       \"Invalid value of delta_idx in slice header RPS: %d > %d.\\n\",\n\n                       delta_idx, sps->nb_st_rps);\n\n\n\n            rps_ridx = &sps->st_rps[sps->nb_st_rps - delta_idx];\n\n            rps->rps_idx_num_delta_pocs = rps_ridx->num_delta_pocs;\n\n        } else\n\n            rps_ridx = &sps->st_rps[rps - sps->st_rps - 1];\n\n\n\n        delta_rps_sign = get_bits1(gb);\n\n        abs_delta_rps  = get_ue_golomb_long(gb) + 1;\n\n        if (abs_delta_rps < 1 || abs_delta_rps > 32768) {\n\n\n                   \"Invalid value of abs_delta_rps: %d\\n\",\n\n                   abs_delta_rps);\n\n\n\n        delta_rps      = (1 - (delta_rps_sign << 1)) * abs_delta_rps;\n\n        for (i = 0; i <= rps_ridx->num_delta_pocs; i++) {\n\n            int used = rps->used[k] = get_bits1(gb);\n\n\n\n            if (!used)\n\n                use_delta_flag = get_bits1(gb);\n\n\n\n            if (used || use_delta_flag) {\n\n                if (i < rps_ridx->num_delta_pocs)\n\n                    delta_poc = delta_rps + rps_ridx->delta_poc[i];\n\n                else\n\n                    delta_poc = delta_rps;\n\n                rps->delta_poc[k] = delta_poc;\n\n                if (delta_poc < 0)\n\n                    k0++;\n\n                else\n\n                    k1++;\n\n                k++;\n\n\n\n\n\n        if (k >= FF_ARRAY_ELEMS(rps->used)) {\n\n\n                   \"Invalid num_delta_pocs: %d\\n\", k);\n\n\n\n\n\n        rps->num_delta_pocs    = k;\n\n        rps->num_negative_pics = k0;\n\n        // sort in increasing order (smallest first)\n\n        if (rps->num_delta_pocs != 0) {\n\n            int used, tmp;\n\n            for (i = 1; i < rps->num_delta_pocs; i++) {\n\n                delta_poc = rps->delta_poc[i];\n\n                used      = rps->used[i];\n\n                for (k = i - 1; k >= 0; k--) {\n\n                    tmp = rps->delta_poc[k];\n\n                    if (delta_poc < tmp) {\n\n                        rps->delta_poc[k + 1] = tmp;\n\n                        rps->used[k + 1]      = rps->used[k];\n\n                        rps->delta_poc[k]     = delta_poc;\n\n                        rps->used[k]          = used;\n\n\n\n\n\n        if ((rps->num_negative_pics >> 1) != 0) {\n\n            int used;\n\n            k = rps->num_negative_pics - 1;\n\n            // flip the negative values to largest first\n\n            for (i = 0; i < rps->num_negative_pics >> 1; i++) {\n\n                delta_poc         = rps->delta_poc[i];\n\n                used              = rps->used[i];\n\n                rps->delta_poc[i] = rps->delta_poc[k];\n\n                rps->used[i]      = rps->used[k];\n\n                rps->delta_poc[k] = delta_poc;\n\n                rps->used[k]      = used;\n\n                k--;\n\n\n\n    } else {\n\n        unsigned int prev, nb_positive_pics;\n\n        rps->num_negative_pics = get_ue_golomb_long(gb);\n\n        nb_positive_pics       = get_ue_golomb_long(gb);\n\n\n\n        if (rps->num_negative_pics >= HEVC_MAX_REFS ||\n\n            nb_positive_pics >= HEVC_MAX_REFS) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Too many refs in a short term RPS.\\n\");\n\n\n\n\n\n        rps->num_delta_pocs = rps->num_negative_pics + nb_positive_pics;\n\n        if (rps->num_delta_pocs) {\n\n            prev = 0;\n\n            for (i = 0; i < rps->num_negative_pics; i++) {\n\n                delta_poc = get_ue_golomb_long(gb) + 1;\n\n\n\n\n\n\n\n                prev -= delta_poc;\n\n                rps->delta_poc[i] = prev;\n\n                rps->used[i]      = get_bits1(gb);\n\n\n            prev = 0;\n\n            for (i = 0; i < nb_positive_pics; i++) {\n\n                delta_poc = get_ue_golomb_long(gb) + 1;\n\n\n\n\n\n\n\n                prev += delta_poc;\n\n                rps->delta_poc[rps->num_negative_pics + i] = prev;\n\n                rps->used[rps->num_negative_pics + i]      = get_bits1(gb);\n\n\n\n\n    return 0;\n", "idx": 24800}
{"project": "FFmpeg", "commit_id": "09f20d37867baaa0122ffdd75f0481b2b3a08079", "target": 1, "func": "static int flac_decode_frame(AVCodecContext *avctx,\n\n                            void *data, int *data_size,\n\n                            uint8_t *buf, int buf_size)\n\n{\n\n    FLACContext *s = avctx->priv_data;\n\n    int metadata_last, metadata_type, metadata_size;\n\n    int tmp = 0, i, j = 0, input_buf_size = 0;\n\n    int16_t *samples = data;\n\n\n\n    if(s->max_framesize == 0){\n\n        s->max_framesize= 8192; // should hopefully be enough for the first header\n\n        s->bitstream= av_fast_realloc(s->bitstream, &s->allocated_bitstream_size, s->max_framesize);\n\n    }\n\n\n\n    if(1 && s->max_framesize){//FIXME truncated\n\n            buf_size= FFMIN(buf_size, s->max_framesize - s->bitstream_size);\n\n            input_buf_size= buf_size;\n\n\n\n            if(s->bitstream_index + s->bitstream_size + buf_size > s->allocated_bitstream_size){\n\n//                printf(\"memmove\\n\");\n\n                memmove(s->bitstream, &s->bitstream[s->bitstream_index], s->bitstream_size);\n\n                s->bitstream_index=0;\n\n            }\n\n            memcpy(&s->bitstream[s->bitstream_index + s->bitstream_size], buf, buf_size);\n\n            buf= &s->bitstream[s->bitstream_index];\n\n            buf_size += s->bitstream_size;\n\n            s->bitstream_size= buf_size;\n\n            \n\n            if(buf_size < s->max_framesize){\n\n//                printf(\"wanna more data ...\\n\");\n\n                return input_buf_size;\n\n            }\n\n    }\n\n\n\n    init_get_bits(&s->gb, buf, buf_size*8);\n\n    \n\n    /* fLaC signature (be) */\n\n    if (show_bits_long(&s->gb, 32) == bswap_32(ff_get_fourcc(\"fLaC\")))\n\n    {\n\n        skip_bits(&s->gb, 32);\n\n\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"STREAM HEADER\\n\");\n\n        do {\n\n            metadata_last = get_bits(&s->gb, 1);\n\n            metadata_type = get_bits(&s->gb, 7);\n\n            metadata_size = get_bits_long(&s->gb, 24);\n\n            \n\n            av_log(s->avctx, AV_LOG_DEBUG, \" metadata block: flag = %d, type = %d, size = %d\\n\",\n\n                metadata_last, metadata_type,\n\n                metadata_size);\n\n            if(metadata_size){\n\n                switch(metadata_type)\n\n                {\n\n                case METADATA_TYPE_STREAMINFO:{\n\n                    int bits_count= get_bits_count(&s->gb);\n\n\n\n                    metadata_streaminfo(s);\n\n                    buf= &s->bitstream[s->bitstream_index];\n\n                    init_get_bits(&s->gb, buf, buf_size*8);\n\n                    skip_bits(&s->gb, bits_count);\n\n\n\n                    dump_headers(s);\n\n                    break;}\n\n                default:\n\n                    for(i=0; i<metadata_size; i++)\n\n                        skip_bits(&s->gb, 8);\n\n                }\n\n            }\n\n        } while(!metadata_last);\n\n    }\n\n    else\n\n    {\n\n        \n\n        tmp = show_bits(&s->gb, 16);\n\n        if(tmp != 0xFFF8){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"FRAME HEADER not here\\n\");\n\n            while(get_bits_count(&s->gb)/8+2 < buf_size && show_bits(&s->gb, 16) != 0xFFF8)\n\n                skip_bits(&s->gb, 8);\n\n            goto end; // we may not have enough bits left to decode a frame, so try next time\n\n        }\n\n        skip_bits(&s->gb, 16);\n\n        if (decode_frame(s) < 0){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"decode_frame() failed\\n\");\n\n            s->bitstream_size=0;\n\n            s->bitstream_index=0;\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    \n\n#if 0\n\n    /* fix the channel order here */\n\n    if (s->order == MID_SIDE)\n\n    {\n\n        short *left = samples;\n\n        short *right = samples + s->blocksize;\n\n        for (i = 0; i < s->blocksize; i += 2)\n\n        {\n\n            uint32_t x = s->decoded[0][i];\n\n            uint32_t y = s->decoded[0][i+1];\n\n\n\n            right[i] = x - (y / 2);\n\n            left[i] = right[i] + y;\n\n        }\n\n        *data_size = 2 * s->blocksize;\n\n    }\n\n    else\n\n    {\n\n    for (i = 0; i < s->channels; i++)\n\n    {\n\n        switch(s->order)\n\n        {\n\n            case INDEPENDENT:\n\n                for (j = 0; j < s->blocksize; j++)\n\n                    samples[(s->blocksize*i)+j] = s->decoded[i][j];\n\n                break;\n\n            case LEFT_SIDE:\n\n            case RIGHT_SIDE:\n\n                if (i == 0)\n\n                    for (j = 0; j < s->blocksize; j++)\n\n                        samples[(s->blocksize*i)+j] = s->decoded[0][j];\n\n                else\n\n                    for (j = 0; j < s->blocksize; j++)\n\n                        samples[(s->blocksize*i)+j] = s->decoded[0][j] - s->decoded[i][j];\n\n                break;\n\n//            case MID_SIDE:\n\n//                av_log(s->avctx, AV_LOG_DEBUG, \"mid-side unsupported\\n\");\n\n        }\n\n        *data_size += s->blocksize;\n\n    }\n\n    }\n\n#else\n\n    switch(s->decorrelation)\n\n    {\n\n        case INDEPENDENT:\n\n            for (j = 0; j < s->blocksize; j++)\n\n            {\n\n                for (i = 0; i < s->channels; i++)\n\n                    *(samples++) = s->decoded[i][j];\n\n            }\n\n            break;\n\n        case LEFT_SIDE:\n\n            assert(s->channels == 2);\n\n            for (i = 0; i < s->blocksize; i++)\n\n            {\n\n                *(samples++) = s->decoded[0][i];\n\n                *(samples++) = s->decoded[0][i] - s->decoded[1][i];\n\n            }\n\n            break;\n\n        case RIGHT_SIDE:\n\n            assert(s->channels == 2);\n\n            for (i = 0; i < s->blocksize; i++)\n\n            {\n\n                *(samples++) = s->decoded[0][i] + s->decoded[1][i];\n\n                *(samples++) = s->decoded[1][i];\n\n            }\n\n            break;\n\n        case MID_SIDE:\n\n            assert(s->channels == 2);\n\n            for (i = 0; i < s->blocksize; i++)\n\n            {\n\n                int mid, side;\n\n                mid = s->decoded[0][i];\n\n                side = s->decoded[1][i];\n\n\n\n#if 1 //needs to be checked but IMHO it should be binary identical\n\n                mid -= side>>1;\n\n                *(samples++) = mid + side;\n\n                *(samples++) = mid;\n\n#else\n\n                \n\n                mid <<= 1;\n\n                if (side & 1)\n\n                    mid++;\n\n                *(samples++) = (mid + side) >> 1;\n\n                *(samples++) = (mid - side) >> 1;\n\n#endif\n\n            }\n\n            break;\n\n    }\n\n#endif\n\n\n\n    *data_size = (int8_t *)samples - (int8_t *)data;\n\n//    av_log(s->avctx, AV_LOG_DEBUG, \"data size: %d\\n\", *data_size);\n\n\n\n//    s->last_blocksize = s->blocksize;\n\nend:\n\n    i= (get_bits_count(&s->gb)+7)/8;;\n\n    if(i > buf_size){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"overread: %d\\n\", i - buf_size);\n\n        s->bitstream_size=0;\n\n        s->bitstream_index=0;\n\n        return -1;\n\n    }\n\n\n\n    if(s->bitstream_size){\n\n        s->bitstream_index += i;\n\n        s->bitstream_size  -= i;\n\n        return input_buf_size;\n\n    }else \n\n        return i;\n\n}\n", "idx": 24803}
{"project": "FFmpeg", "commit_id": "fc4c27c4edfc6a5f9bc7c696e823652474a65ce8", "target": 0, "func": "static void dump_video_param(AVCodecContext *avctx, QSVEncContext *q,\n\n                             mfxExtBuffer **coding_opts)\n\n{\n\n    mfxInfoMFX *info = &q->param.mfx;\n\n\n\n    mfxExtCodingOption   *co = (mfxExtCodingOption*)coding_opts[0];\n\n#if QSV_HAVE_CO2\n\n    mfxExtCodingOption2 *co2 = (mfxExtCodingOption2*)coding_opts[1];\n\n#endif\n\n#if QSV_HAVE_CO3\n\n    mfxExtCodingOption3 *co3 = (mfxExtCodingOption3*)coding_opts[2];\n\n#endif\n\n\n\n    av_log(avctx, AV_LOG_VERBOSE, \"profile: %s; level: %\"PRIu16\"\\n\",\n\n           print_profile(info->CodecProfile), info->CodecLevel);\n\n\n\n    av_log(avctx, AV_LOG_VERBOSE, \"GopPicSize: %\"PRIu16\"; GopRefDist: %\"PRIu16\"; GopOptFlag: \",\n\n           info->GopPicSize, info->GopRefDist);\n\n    if (info->GopOptFlag & MFX_GOP_CLOSED)\n\n        av_log(avctx, AV_LOG_VERBOSE, \"closed \");\n\n    if (info->GopOptFlag & MFX_GOP_STRICT)\n\n        av_log(avctx, AV_LOG_VERBOSE, \"strict \");\n\n    av_log(avctx, AV_LOG_VERBOSE, \"; IdrInterval: %\"PRIu16\"\\n\", info->IdrInterval);\n\n\n\n    av_log(avctx, AV_LOG_VERBOSE, \"TargetUsage: %\"PRIu16\"; RateControlMethod: %s\\n\",\n\n           info->TargetUsage, print_ratecontrol(info->RateControlMethod));\n\n\n\n    if (info->RateControlMethod == MFX_RATECONTROL_CBR ||\n\n        info->RateControlMethod == MFX_RATECONTROL_VBR\n\n#if QSV_HAVE_VCM\n\n        || info->RateControlMethod == MFX_RATECONTROL_VCM\n\n#endif\n\n        ) {\n\n        av_log(avctx, AV_LOG_VERBOSE,\n\n               \"InitialDelayInKB: %\"PRIu16\"; TargetKbps: %\"PRIu16\"; MaxKbps: %\"PRIu16\"\\n\",\n\n               info->InitialDelayInKB, info->TargetKbps, info->MaxKbps);\n\n    } else if (info->RateControlMethod == MFX_RATECONTROL_CQP) {\n\n        av_log(avctx, AV_LOG_VERBOSE, \"QPI: %\"PRIu16\"; QPP: %\"PRIu16\"; QPB: %\"PRIu16\"\\n\",\n\n               info->QPI, info->QPP, info->QPB);\n\n    } else if (info->RateControlMethod == MFX_RATECONTROL_AVBR) {\n\n        av_log(avctx, AV_LOG_VERBOSE,\n\n               \"TargetKbps: %\"PRIu16\"; Accuracy: %\"PRIu16\"; Convergence: %\"PRIu16\"\\n\",\n\n               info->TargetKbps, info->Accuracy, info->Convergence);\n\n    }\n\n#if QSV_HAVE_LA\n\n    else if (info->RateControlMethod == MFX_RATECONTROL_LA\n\n#if QSV_HAVE_LA_HRD\n\n             || info->RateControlMethod == MFX_RATECONTROL_LA_HRD\n\n#endif\n\n             ) {\n\n        av_log(avctx, AV_LOG_VERBOSE,\n\n               \"TargetKbps: %\"PRIu16\"; LookAheadDepth: %\"PRIu16\"\\n\",\n\n               info->TargetKbps, co2->LookAheadDepth);\n\n    }\n\n#endif\n\n#if QSV_HAVE_ICQ\n\n    else if (info->RateControlMethod == MFX_RATECONTROL_ICQ) {\n\n        av_log(avctx, AV_LOG_VERBOSE, \"ICQQuality: %\"PRIu16\"\\n\", info->ICQQuality);\n\n    } else if (info->RateControlMethod == MFX_RATECONTROL_LA_ICQ) {\n\n        av_log(avctx, AV_LOG_VERBOSE, \"ICQQuality: %\"PRIu16\"; LookAheadDepth: %\"PRIu16\"\\n\",\n\n               info->ICQQuality, co2->LookAheadDepth);\n\n    }\n\n#endif\n\n#if QSV_HAVE_QVBR\n\n    else if (info->RateControlMethod == MFX_RATECONTROL_QVBR) {\n\n        av_log(avctx, AV_LOG_VERBOSE, \"QVBRQuality: %\"PRIu16\"\\n\",\n\n               co3->QVBRQuality);\n\n    }\n\n#endif\n\n\n\n    av_log(avctx, AV_LOG_VERBOSE, \"NumSlice: %\"PRIu16\"; NumRefFrame: %\"PRIu16\"\\n\",\n\n           info->NumSlice, info->NumRefFrame);\n\n    av_log(avctx, AV_LOG_VERBOSE, \"RateDistortionOpt: %s\\n\",\n\n           print_threestate(co->RateDistortionOpt));\n\n\n\n#if QSV_HAVE_CO2\n\n    av_log(avctx, AV_LOG_VERBOSE,\n\n           \"RecoveryPointSEI: %s IntRefType: %\"PRIu16\"; IntRefCycleSize: %\"PRIu16\"; IntRefQPDelta: %\"PRId16\"\\n\",\n\n           print_threestate(co->RecoveryPointSEI), co2->IntRefType, co2->IntRefCycleSize, co2->IntRefQPDelta);\n\n\n\n    av_log(avctx, AV_LOG_VERBOSE, \"MaxFrameSize: %\"PRIu16\"; \", co2->MaxFrameSize);\n\n#if QSV_VERSION_ATLEAST(1, 9)\n\n    av_log(avctx, AV_LOG_VERBOSE, \"MaxSliceSize: %\"PRIu16\"; \", co2->MaxSliceSize);\n\n#endif\n\n    av_log(avctx, AV_LOG_VERBOSE, \"\\n\");\n\n\n\n    av_log(avctx, AV_LOG_VERBOSE,\n\n           \"BitrateLimit: %s; MBBRC: %s; ExtBRC: %s\\n\",\n\n           print_threestate(co2->BitrateLimit), print_threestate(co2->MBBRC),\n\n           print_threestate(co2->ExtBRC));\n\n\n\n#if QSV_HAVE_TRELLIS\n\n    av_log(avctx, AV_LOG_VERBOSE, \"Trellis: \");\n\n    if (co2->Trellis & MFX_TRELLIS_OFF) {\n\n        av_log(avctx, AV_LOG_VERBOSE, \"off\");\n\n    } else if (!co2->Trellis) {\n\n        av_log(avctx, AV_LOG_VERBOSE, \"auto\");\n\n    } else {\n\n        if (co2->Trellis & MFX_TRELLIS_I) av_log(avctx, AV_LOG_VERBOSE, \"I\");\n\n        if (co2->Trellis & MFX_TRELLIS_P) av_log(avctx, AV_LOG_VERBOSE, \"P\");\n\n        if (co2->Trellis & MFX_TRELLIS_B) av_log(avctx, AV_LOG_VERBOSE, \"B\");\n\n    }\n\n    av_log(avctx, AV_LOG_VERBOSE, \"\\n\");\n\n#endif\n\n\n\n#if QSV_VERSION_ATLEAST(1, 8)\n\n    av_log(avctx, AV_LOG_VERBOSE,\n\n           \"RepeatPPS: %s; NumMbPerSlice: %\"PRIu16\"; LookAheadDS: \",\n\n           print_threestate(co2->RepeatPPS), co2->NumMbPerSlice);\n\n    switch (co2->LookAheadDS) {\n\n    case MFX_LOOKAHEAD_DS_OFF: av_log(avctx, AV_LOG_VERBOSE, \"off\");     break;\n\n    case MFX_LOOKAHEAD_DS_2x:  av_log(avctx, AV_LOG_VERBOSE, \"2x\");      break;\n\n    case MFX_LOOKAHEAD_DS_4x:  av_log(avctx, AV_LOG_VERBOSE, \"4x\");      break;\n\n    default:                   av_log(avctx, AV_LOG_VERBOSE, \"unknown\"); break;\n\n    }\n\n    av_log(avctx, AV_LOG_VERBOSE, \"\\n\");\n\n\n\n    av_log(avctx, AV_LOG_VERBOSE, \"AdaptiveI: %s; AdaptiveB: %s; BRefType: \",\n\n           print_threestate(co2->AdaptiveI), print_threestate(co2->AdaptiveB));\n\n    switch (co2->BRefType) {\n\n    case MFX_B_REF_OFF:     av_log(avctx, AV_LOG_VERBOSE, \"off\");       break;\n\n    case MFX_B_REF_PYRAMID: av_log(avctx, AV_LOG_VERBOSE, \"pyramid\");   break;\n\n    default:                av_log(avctx, AV_LOG_VERBOSE, \"auto\");      break;\n\n    }\n\n    av_log(avctx, AV_LOG_VERBOSE, \"\\n\");\n\n#endif\n\n\n\n#if QSV_VERSION_ATLEAST(1, 9)\n\n    av_log(avctx, AV_LOG_VERBOSE,\n\n           \"MinQPI: %\"PRIu8\"; MaxQPI: %\"PRIu8\"; MinQPP: %\"PRIu8\"; MaxQPP: %\"PRIu8\"; MinQPB: %\"PRIu8\"; MaxQPB: %\"PRIu8\"\\n\",\n\n           co2->MinQPI, co2->MaxQPI, co2->MinQPP, co2->MaxQPP, co2->MinQPB, co2->MaxQPB);\n\n#endif\n\n#endif\n\n\n\n    if (avctx->codec_id == AV_CODEC_ID_H264) {\n\n        av_log(avctx, AV_LOG_VERBOSE, \"Entropy coding: %s; MaxDecFrameBuffering: %\"PRIu16\"\\n\",\n\n               co->CAVLC == MFX_CODINGOPTION_ON ? \"CAVLC\" : \"CABAC\", co->MaxDecFrameBuffering);\n\n        av_log(avctx, AV_LOG_VERBOSE,\n\n               \"NalHrdConformance: %s; SingleSeiNalUnit: %s; VuiVclHrdParameters: %s VuiNalHrdParameters: %s\\n\",\n\n               print_threestate(co->NalHrdConformance), print_threestate(co->SingleSeiNalUnit),\n\n               print_threestate(co->VuiVclHrdParameters), print_threestate(co->VuiNalHrdParameters));\n\n    }\n\n}\n", "idx": 24804}
{"project": "FFmpeg", "commit_id": "8813d55fa5978660d9f4e7dbe1f50da9922be08d", "target": 0, "func": "static void *alloc_buffer(FFVAContext *vactx, int type, unsigned int size, uint32_t *buf_id)\n\n{\n\n    void *data = NULL;\n\n\n\n    *buf_id = 0;\n\n    if (vaCreateBuffer(vactx->display, vactx->context_id,\n\n                       type, size, 1, NULL, buf_id) == VA_STATUS_SUCCESS)\n\n        vaMapBuffer(vactx->display, *buf_id, &data);\n\n\n\n    return data;\n\n}\n", "idx": 24805}
{"project": "FFmpeg", "commit_id": "add41decd94b2d3581a3715ba10f27168b8cdb1b", "target": 0, "func": "static int decode_slice(struct AVCodecContext *avctx, void *arg){\n\n    H264Context *h = *(void**)arg;\n\n    MpegEncContext * const s = &h->s;\n\n    const int part_mask= s->partitioned_frame ? (AC_END|AC_ERROR) : 0x7F;\n\n    int lf_x_start = s->mb_x;\n\n\n\n    s->mb_skip_run= -1;\n\n\n\n    h->is_complex = FRAME_MBAFF || s->picture_structure != PICT_FRAME || s->codec_id != CODEC_ID_H264 ||\n\n                    (CONFIG_GRAY && (s->flags&CODEC_FLAG_GRAY));\n\n\n\n    if( h->pps.cabac ) {\n\n        /* realign */\n\n        align_get_bits( &s->gb );\n\n\n\n        /* init cabac */\n\n        ff_init_cabac_states( &h->cabac);\n\n        ff_init_cabac_decoder( &h->cabac,\n\n                               s->gb.buffer + get_bits_count(&s->gb)/8,\n\n                               (get_bits_left(&s->gb) + 7)/8);\n\n\n\n        ff_h264_init_cabac_states(h);\n\n\n\n        for(;;){\n\n//START_TIMER\n\n            int ret = ff_h264_decode_mb_cabac(h);\n\n            int eos;\n\n//STOP_TIMER(\"decode_mb_cabac\")\n\n\n\n            if(ret>=0) ff_h264_hl_decode_mb(h);\n\n\n\n            if( ret >= 0 && FRAME_MBAFF ) { //FIXME optimal? or let mb_decode decode 16x32 ?\n\n                s->mb_y++;\n\n\n\n                ret = ff_h264_decode_mb_cabac(h);\n\n\n\n                if(ret>=0) ff_h264_hl_decode_mb(h);\n\n                s->mb_y--;\n\n            }\n\n            eos = get_cabac_terminate( &h->cabac );\n\n\n\n            if((s->workaround_bugs & FF_BUG_TRUNCATED) && h->cabac.bytestream > h->cabac.bytestream_end + 2){\n\n                ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n                if (s->mb_x >= lf_x_start) loop_filter(h, lf_x_start, s->mb_x + 1);\n\n                return 0;\n\n            }\n\n            if( ret < 0 || h->cabac.bytestream > h->cabac.bytestream_end + 2) {\n\n                av_log(h->s.avctx, AV_LOG_ERROR, \"error while decoding MB %d %d, bytestream (%td)\\n\", s->mb_x, s->mb_y, h->cabac.bytestream_end - h->cabac.bytestream);\n\n                ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, (AC_ERROR|DC_ERROR|MV_ERROR)&part_mask);\n\n                return -1;\n\n            }\n\n\n\n            if( ++s->mb_x >= s->mb_width ) {\n\n                loop_filter(h, lf_x_start, s->mb_x);\n\n                s->mb_x = lf_x_start = 0;\n\n                decode_finish_row(h);\n\n                ++s->mb_y;\n\n                if(FIELD_OR_MBAFF_PICTURE) {\n\n                    ++s->mb_y;\n\n                    if(FRAME_MBAFF && s->mb_y < s->mb_height)\n\n                        predict_field_decoding_flag(h);\n\n                }\n\n            }\n\n\n\n            if( eos || s->mb_y >= s->mb_height ) {\n\n                tprintf(s->avctx, \"slice end %d %d\\n\", get_bits_count(&s->gb), s->gb.size_in_bits);\n\n                ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n                if (s->mb_x > lf_x_start) loop_filter(h, lf_x_start, s->mb_x);\n\n                return 0;\n\n            }\n\n        }\n\n\n\n    } else {\n\n        for(;;){\n\n            int ret = ff_h264_decode_mb_cavlc(h);\n\n\n\n            if(ret>=0) ff_h264_hl_decode_mb(h);\n\n\n\n            if(ret>=0 && FRAME_MBAFF){ //FIXME optimal? or let mb_decode decode 16x32 ?\n\n                s->mb_y++;\n\n                ret = ff_h264_decode_mb_cavlc(h);\n\n\n\n                if(ret>=0) ff_h264_hl_decode_mb(h);\n\n                s->mb_y--;\n\n            }\n\n\n\n            if(ret<0){\n\n                av_log(h->s.avctx, AV_LOG_ERROR, \"error while decoding MB %d %d\\n\", s->mb_x, s->mb_y);\n\n                ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, (AC_ERROR|DC_ERROR|MV_ERROR)&part_mask);\n\n                return -1;\n\n            }\n\n\n\n            if(++s->mb_x >= s->mb_width){\n\n                loop_filter(h, lf_x_start, s->mb_x);\n\n                s->mb_x = lf_x_start = 0;\n\n                decode_finish_row(h);\n\n                ++s->mb_y;\n\n                if(FIELD_OR_MBAFF_PICTURE) {\n\n                    ++s->mb_y;\n\n                    if(FRAME_MBAFF && s->mb_y < s->mb_height)\n\n                        predict_field_decoding_flag(h);\n\n                }\n\n                if(s->mb_y >= s->mb_height){\n\n                    tprintf(s->avctx, \"slice end %d %d\\n\", get_bits_count(&s->gb), s->gb.size_in_bits);\n\n\n\n                    if(get_bits_count(&s->gb) == s->gb.size_in_bits ) {\n\n                        ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n\n\n                        return 0;\n\n                    }else{\n\n                        ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n\n\n                        return -1;\n\n                    }\n\n                }\n\n            }\n\n\n\n            if(get_bits_count(&s->gb) >= s->gb.size_in_bits && s->mb_skip_run<=0){\n\n                tprintf(s->avctx, \"slice end %d %d\\n\", get_bits_count(&s->gb), s->gb.size_in_bits);\n\n                if(get_bits_count(&s->gb) == s->gb.size_in_bits ){\n\n                    ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n                    if (s->mb_x > lf_x_start) loop_filter(h, lf_x_start, s->mb_x);\n\n\n\n                    return 0;\n\n                }else{\n\n                    ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, (AC_ERROR|DC_ERROR|MV_ERROR)&part_mask);\n\n\n\n                    return -1;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n#if 0\n\n    for(;s->mb_y < s->mb_height; s->mb_y++){\n\n        for(;s->mb_x < s->mb_width; s->mb_x++){\n\n            int ret= decode_mb(h);\n\n\n\n            ff_h264_hl_decode_mb(h);\n\n\n\n            if(ret<0){\n\n                av_log(s->avctx, AV_LOG_ERROR, \"error while decoding MB %d %d\\n\", s->mb_x, s->mb_y);\n\n                ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, (AC_ERROR|DC_ERROR|MV_ERROR)&part_mask);\n\n\n\n                return -1;\n\n            }\n\n\n\n            if(++s->mb_x >= s->mb_width){\n\n                s->mb_x=0;\n\n                if(++s->mb_y >= s->mb_height){\n\n                    if(get_bits_count(s->gb) == s->gb.size_in_bits){\n\n                        ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n\n\n                        return 0;\n\n                    }else{\n\n                        ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n\n\n                        return -1;\n\n                    }\n\n                }\n\n            }\n\n\n\n            if(get_bits_count(s->?gb) >= s->gb?.size_in_bits){\n\n                if(get_bits_count(s->gb) == s->gb.size_in_bits){\n\n                    ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n\n\n                    return 0;\n\n                }else{\n\n                    ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, (AC_ERROR|DC_ERROR|MV_ERROR)&part_mask);\n\n\n\n                    return -1;\n\n                }\n\n            }\n\n        }\n\n        s->mb_x=0;\n\n        ff_draw_horiz_band(s, 16*s->mb_y, 16);\n\n    }\n\n#endif\n\n    return -1; //not reached\n\n}\n", "idx": 24806}
{"project": "FFmpeg", "commit_id": "8f0bd1d9bad5b8aa42b5b4cec103cc4afed5eab6", "target": 0, "func": "void ff_http_auth_handle_header(HTTPAuthState *state, const char *key,\n\n                                const char *value)\n\n{\n\n    if (!strcmp(key, \"WWW-Authenticate\") || !strcmp(key, \"Proxy-Authenticate\")) {\n\n        const char *p;\n\n        if (av_stristart(value, \"Basic \", &p) &&\n\n            state->auth_type <= HTTP_AUTH_BASIC) {\n\n            state->auth_type = HTTP_AUTH_BASIC;\n\n            state->realm[0] = 0;\n\n            state->stale = 0;\n\n            ff_parse_key_value(p, (ff_parse_key_val_cb) handle_basic_params,\n\n                               state);\n\n        } else if (av_stristart(value, \"Digest \", &p) &&\n\n                   state->auth_type <= HTTP_AUTH_DIGEST) {\n\n            state->auth_type = HTTP_AUTH_DIGEST;\n\n            memset(&state->digest_params, 0, sizeof(DigestParams));\n\n            state->realm[0] = 0;\n\n            state->stale = 0;\n\n            ff_parse_key_value(p, (ff_parse_key_val_cb) handle_digest_params,\n\n                               state);\n\n            choose_qop(state->digest_params.qop,\n\n                       sizeof(state->digest_params.qop));\n\n            if (!av_strcasecmp(state->digest_params.stale, \"true\"))\n\n                state->stale = 1;\n\n        }\n\n    } else if (!strcmp(key, \"Authentication-Info\")) {\n\n        ff_parse_key_value(value, (ff_parse_key_val_cb) handle_digest_update,\n\n                           state);\n\n    }\n\n}\n", "idx": 24807}
{"project": "FFmpeg", "commit_id": "343e2833994655c252d5236a3394bf6db7a4d8b1", "target": 0, "func": "void ff_thread_report_progress(ThreadFrame *f, int n, int field)\n\n{\n\n    PerThreadContext *p;\n\n    atomic_int *progress = f->progress ? (atomic_int*)f->progress->data : NULL;\n\n\n\n    if (!progress ||\n\n        atomic_load_explicit(&progress[field], memory_order_acquire) >= n)\n\n        return;\n\n\n\n    p = f->owner->internal->thread_ctx;\n\n\n\n    if (f->owner->debug&FF_DEBUG_THREADS)\n\n        av_log(f->owner, AV_LOG_DEBUG, \"%p finished %d field %d\\n\", progress, n, field);\n\n\n\n    pthread_mutex_lock(&p->progress_mutex);\n\n\n\n    atomic_store(&progress[field], n);\n\n\n\n    pthread_cond_broadcast(&p->progress_cond);\n\n    pthread_mutex_unlock(&p->progress_mutex);\n\n}\n", "idx": 24808}
{"project": "FFmpeg", "commit_id": "3896cd11a107f241f06b06a336322aef2f372fdd", "target": 1, "func": "static void mxf_write_system_item(AVFormatContext *s)\n\n{\n\n    MXFContext *mxf = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    unsigned frame;\n\n    uint32_t time_code;\n\n\n\n    frame = mxf->last_indexed_edit_unit + mxf->edit_units_count;\n\n\n\n    // write system metadata pack\n\n    avio_write(pb, system_metadata_pack_key, 16);\n\n    klv_encode_ber4_length(pb, 57);\n\n    avio_w8(pb, 0x5c); // UL, user date/time stamp, picture and sound item present\n\n    avio_w8(pb, 0x04); // content package rate\n\n    avio_w8(pb, 0x00); // content package type\n\n    avio_wb16(pb, 0x00); // channel handle\n\n    avio_wb16(pb, mxf->tc.start + frame); // continuity count\n\n    if (mxf->essence_container_count > 1)\n\n        avio_write(pb, multiple_desc_ul, 16);\n\n    else {\n\n        MXFStreamContext *sc = s->streams[0]->priv_data;\n\n        avio_write(pb, mxf_essence_container_uls[sc->index].container_ul, 16);\n\n    }\n\n    avio_w8(pb, 0);\n\n    avio_wb64(pb, 0);\n\n    avio_wb64(pb, 0); // creation date/time stamp\n\n\n\n    avio_w8(pb, 0x81); // SMPTE 12M time code\n\n    time_code = av_timecode_get_smpte_from_framenum(&mxf->tc, frame);\n\n    avio_wb32(pb, time_code);\n\n    avio_wb32(pb, 0); // binary group data\n\n    avio_wb64(pb, 0);\n\n\n\n    // write system metadata package set\n\n    avio_write(pb, system_metadata_package_set_key, 16);\n\n    klv_encode_ber4_length(pb, 35);\n\n    avio_w8(pb, 0x83); // UMID\n\n    avio_wb16(pb, 0x20);\n\n    mxf_write_umid(s, 1);\n\n}\n", "idx": 24809}
{"project": "FFmpeg", "commit_id": "17ae608127324cabd083202a32a8dc210d30c3a1", "target": 1, "func": "static av_cold int aac_encode_end(AVCodecContext *avctx)\n\n{\n\n    AACEncContext *s = avctx->priv_data;\n\n\n\n    ff_mdct_end(&s->mdct1024);\n\n    ff_mdct_end(&s->mdct128);\n\n    ff_psy_end(&s->psy);\n\n    ff_psy_preprocess_end(s->psypp);\n\n    av_freep(&s->samples);\n\n    av_freep(&s->cpe);\n\n    return 0;\n\n}\n", "idx": 24814}
{"project": "FFmpeg", "commit_id": "1d8c4af396b6ed84c84b5ebf0bf1163c4a7a3017", "target": 1, "func": "void updateMMXDitherTables(SwsContext *c, int dstY, int lumBufIndex, int chrBufIndex,\n                           int lastInLumBuf, int lastInChrBuf)\n{\n    const int dstH= c->dstH;\n    const int flags= c->flags;\n    int16_t **lumPixBuf= c->lumPixBuf;\n    int16_t **chrUPixBuf= c->chrUPixBuf;\n    int16_t **alpPixBuf= c->alpPixBuf;\n    const int vLumBufSize= c->vLumBufSize;\n    const int vChrBufSize= c->vChrBufSize;\n    int16_t *vLumFilterPos= c->vLumFilterPos;\n    int16_t *vChrFilterPos= c->vChrFilterPos;\n    int16_t *vLumFilter= c->vLumFilter;\n    int16_t *vChrFilter= c->vChrFilter;\n    int32_t *lumMmxFilter= c->lumMmxFilter;\n    int32_t *chrMmxFilter= c->chrMmxFilter;\n    int32_t av_unused *alpMmxFilter= c->alpMmxFilter;\n    const int vLumFilterSize= c->vLumFilterSize;\n    const int vChrFilterSize= c->vChrFilterSize;\n    const int chrDstY= dstY>>c->chrDstVSubSample;\n    const int firstLumSrcY= vLumFilterPos[dstY]; //First line needed as input\n    const int firstChrSrcY= vChrFilterPos[chrDstY]; //First line needed as input\n    c->blueDither= ff_dither8[dstY&1];\n    if (c->dstFormat == PIX_FMT_RGB555 || c->dstFormat == PIX_FMT_BGR555)\n        c->greenDither= ff_dither8[dstY&1];\n    else\n        c->greenDither= ff_dither4[dstY&1];\n    c->redDither= ff_dither8[(dstY+1)&1];\n    if (dstY < dstH - 2) {\n        const int16_t **lumSrcPtr= (const int16_t **) lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n        const int16_t **chrUSrcPtr= (const int16_t **) chrUPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n        const int16_t **alpSrcPtr= (CONFIG_SWSCALE_ALPHA && alpPixBuf) ? (const int16_t **) alpPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize : NULL;\n        int i;\n        if (flags & SWS_ACCURATE_RND) {\n            int s= APCK_SIZE / 8;\n            for (i=0; i<vLumFilterSize; i+=2) {\n                *(const void**)&lumMmxFilter[s*i              ]= lumSrcPtr[i  ];\n                *(const void**)&lumMmxFilter[s*i+APCK_PTR2/4  ]= lumSrcPtr[i+(vLumFilterSize>1)];\n                lumMmxFilter[s*i+APCK_COEF/4  ]=\n                lumMmxFilter[s*i+APCK_COEF/4+1]= vLumFilter[dstY*vLumFilterSize + i    ]\n                + (vLumFilterSize>1 ? vLumFilter[dstY*vLumFilterSize + i + 1]<<16 : 0);\n                if (CONFIG_SWSCALE_ALPHA && alpPixBuf) {\n                    *(const void**)&alpMmxFilter[s*i              ]= alpSrcPtr[i  ];\n                    *(const void**)&alpMmxFilter[s*i+APCK_PTR2/4  ]= alpSrcPtr[i+(vLumFilterSize>1)];\n                    alpMmxFilter[s*i+APCK_COEF/4  ]=\n                    alpMmxFilter[s*i+APCK_COEF/4+1]= lumMmxFilter[s*i+APCK_COEF/4  ];\n            for (i=0; i<vChrFilterSize; i+=2) {\n                *(const void**)&chrMmxFilter[s*i              ]= chrUSrcPtr[i  ];\n                *(const void**)&chrMmxFilter[s*i+APCK_PTR2/4  ]= chrUSrcPtr[i+(vChrFilterSize>1)];\n                chrMmxFilter[s*i+APCK_COEF/4  ]=\n                chrMmxFilter[s*i+APCK_COEF/4+1]= vChrFilter[chrDstY*vChrFilterSize + i    ]\n                + (vChrFilterSize>1 ? vChrFilter[chrDstY*vChrFilterSize + i + 1]<<16 : 0);\n        } else {\n            for (i=0; i<vLumFilterSize; i++) {\n                *(const void**)&lumMmxFilter[4*i+0]= lumSrcPtr[i];\n                lumMmxFilter[4*i+2]=\n                lumMmxFilter[4*i+3]=\n                ((uint16_t)vLumFilter[dstY*vLumFilterSize + i])*0x10001;\n                if (CONFIG_SWSCALE_ALPHA && alpPixBuf) {\n                    *(const void**)&alpMmxFilter[4*i+0]= alpSrcPtr[i];\n                    alpMmxFilter[4*i+2]=\n                    alpMmxFilter[4*i+3]= lumMmxFilter[4*i+2];\n            for (i=0; i<vChrFilterSize; i++) {\n                *(const void**)&chrMmxFilter[4*i+0]= chrUSrcPtr[i];\n                chrMmxFilter[4*i+2]=\n                chrMmxFilter[4*i+3]=\n                ((uint16_t)vChrFilter[chrDstY*vChrFilterSize + i])*0x10001;", "idx": 24815}
{"project": "FFmpeg", "commit_id": "5ff998a233d759d0de83ea6f95c383d03d25d88e", "target": 1, "func": "static int rice_count_exact(int32_t *res, int n, int k)\n\n{\n\n    int i;\n\n    int count = 0;\n\n\n\n    for (i = 0; i < n; i++) {\n\n        int32_t v = -2 * res[i] - 1;\n\n        v ^= v >> 31;\n\n        count += (v >> k) + 1 + k;\n\n    }\n\n    return count;\n\n}\n", "idx": 24816}
{"project": "FFmpeg", "commit_id": "a38758a97efe9c2de48b5429fd2fdebd55ba6a64", "target": 1, "func": "int ff_h264_fill_default_ref_list(H264Context *h, H264SliceContext *sl)\n\n{\n\n    int i, len;\n\n\n\n    if (sl->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n        H264Picture *sorted[32];\n\n        int cur_poc, list;\n\n        int lens[2];\n\n\n\n        if (FIELD_PICTURE(h))\n\n            cur_poc = h->cur_pic_ptr->field_poc[h->picture_structure == PICT_BOTTOM_FIELD];\n\n        else\n\n            cur_poc = h->cur_pic_ptr->poc;\n\n\n\n        for (list = 0; list < 2; list++) {\n\n            len  = add_sorted(sorted,       h->short_ref, h->short_ref_count, cur_poc, 1 ^ list);\n\n            len += add_sorted(sorted + len, h->short_ref, h->short_ref_count, cur_poc, 0 ^ list);\n\n            av_assert0(len <= 32);\n\n\n\n            len  = build_def_list(h->default_ref_list[list], FF_ARRAY_ELEMS(h->default_ref_list[0]),\n\n                                  sorted, len, 0, h->picture_structure);\n\n            len += build_def_list(h->default_ref_list[list] + len,\n\n                                  FF_ARRAY_ELEMS(h->default_ref_list[0]) - len,\n\n                                  h->long_ref, 16, 1, h->picture_structure);\n\n            av_assert0(len <= 32);\n\n\n\n            if (len < sl->ref_count[list])\n\n                memset(&h->default_ref_list[list][len], 0, sizeof(H264Ref) * (sl->ref_count[list] - len));\n\n            lens[list] = len;\n\n        }\n\n\n\n        if (lens[0] == lens[1] && lens[1] > 1) {\n\n            for (i = 0; i < lens[0] &&\n\n                        h->default_ref_list[0][i].parent->f.buf[0]->buffer ==\n\n                        h->default_ref_list[1][i].parent->f.buf[0]->buffer; i++);\n\n            if (i == lens[0]) {\n\n                FFSWAP(H264Ref, h->default_ref_list[1][0], h->default_ref_list[1][1]);\n\n            }\n\n        }\n\n    } else {\n\n        len  = build_def_list(h->default_ref_list[0], FF_ARRAY_ELEMS(h->default_ref_list[0]),\n\n                              h->short_ref, h->short_ref_count, 0, h->picture_structure);\n\n        len += build_def_list(h->default_ref_list[0] + len,\n\n                              FF_ARRAY_ELEMS(h->default_ref_list[0]) - len,\n\n                              h-> long_ref, 16, 1, h->picture_structure);\n\n        av_assert0(len <= 32);\n\n\n\n        if (len < sl->ref_count[0])\n\n            memset(&h->default_ref_list[0][len], 0, sizeof(H264Ref) * (sl->ref_count[0] - len));\n\n    }\n\n#ifdef TRACE\n\n    for (i = 0; i < sl->ref_count[0]; i++) {\n\n        tprintf(h->avctx, \"List0: %s fn:%d 0x%p\\n\",\n\n                (h->default_ref_list[0][i].parent->long_ref ? \"LT\" : \"ST\"),\n\n                h->default_ref_list[0][i].pic_id,\n\n                h->default_ref_list[0][i].parent->f.data[0]);\n\n    }\n\n    if (sl->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n        for (i = 0; i < sl->ref_count[1]; i++) {\n\n            tprintf(h->avctx, \"List1: %s fn:%d 0x%p\\n\",\n\n                    (h->default_ref_list[1][i].parent->long_ref ? \"LT\" : \"ST\"),\n\n                    h->default_ref_list[1][i].pic_id,\n\n                    h->default_ref_list[1][i].parent->f.data[0]);\n\n        }\n\n    }\n\n#endif\n\n    return 0;\n\n}\n", "idx": 24818}
{"project": "FFmpeg", "commit_id": "5d20f19be25c973fe10d0d17db9245002585710d", "target": 1, "func": "static inline int mix_core(uint32_t multbl[][256], int a, int b, int c, int d){\n\n#if CONFIG_SMALL\n\n#define ROT(x,s) ((x<<s)|(x>>(32-s)))\n\n    return multbl[0][a] ^ ROT(multbl[0][b], 8) ^ ROT(multbl[0][c], 16) ^ ROT(multbl[0][d], 24);\n\n#else\n\n    return multbl[0][a] ^ multbl[1][b] ^ multbl[2][c] ^ multbl[3][d];\n\n#endif\n\n}\n", "idx": 24819}
{"project": "FFmpeg", "commit_id": "bad446e251405dc250c3cbee199072e083a1e4b9", "target": 1, "func": "void ff_generate_sliding_window_mmcos(H264Context *h) {\n\n    MpegEncContext * const s = &h->s;\n\n    assert(h->long_ref_count + h->short_ref_count <= h->sps.ref_frame_count);\n\n\n\n    h->mmco_index= 0;\n\n    if(h->short_ref_count && h->long_ref_count + h->short_ref_count == h->sps.ref_frame_count &&\n\n            !(FIELD_PICTURE && !s->first_field && s->current_picture_ptr->f.reference)) {\n\n        h->mmco[0].opcode= MMCO_SHORT2UNUSED;\n\n        h->mmco[0].short_pic_num= h->short_ref[ h->short_ref_count - 1 ]->frame_num;\n\n        h->mmco_index= 1;\n\n        if (FIELD_PICTURE) {\n\n            h->mmco[0].short_pic_num *= 2;\n\n            h->mmco[1].opcode= MMCO_SHORT2UNUSED;\n\n            h->mmco[1].short_pic_num= h->mmco[0].short_pic_num + 1;\n\n            h->mmco_index= 2;\n\n        }\n\n    }\n\n}\n", "idx": 24820}
{"project": "FFmpeg", "commit_id": "b737a2c52857b214be246ff615c6293730033cfa", "target": 1, "func": "static int mpc8_probe(AVProbeData *p)\n\n{\n\n    const uint8_t *bs = p->buf + 4;\n\n    const uint8_t *bs_end = bs + p->buf_size;\n\n    int64_t size;\n\n\n\n    if (p->buf_size < 16)\n\n        return 0;\n\n    if (AV_RL32(p->buf) != TAG_MPCK)\n\n        return 0;\n\n    while (bs < bs_end + 3) {\n\n        int header_found = (bs[0] == 'S' && bs[1] == 'H');\n\n        if (bs[0] < 'A' || bs[0] > 'Z' || bs[1] < 'A' || bs[1] > 'Z')\n\n            return 0;\n\n        bs += 2;\n\n        size = bs_get_v(&bs);\n\n        if (size < 2)\n\n            return 0;\n\n        if (bs + size - 2 >= bs_end)\n\n            return AVPROBE_SCORE_EXTENSION - 1; // seems to be valid MPC but no header yet\n\n        if (header_found) {\n\n            if (size < 11 || size > 28)\n\n                return 0;\n\n            if (!AV_RL32(bs)) //zero CRC is invalid\n\n                return 0;\n\n            return AVPROBE_SCORE_MAX;\n\n        } else {\n\n            bs += size - 2;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 24823}
{"project": "FFmpeg", "commit_id": "002a7414b5852418f9a66245fc414c0416c4b4c1", "target": 0, "func": "static int decode_block(MJpegDecodeContext *s, DCTELEM *block,\n\n                        int component, int dc_index, int ac_index, int16_t *quant_matrix)\n\n{\n\n    int code, i, j, level, val;\n\n    VLC *ac_vlc;\n\n\n\n    /* DC coef */\n\n    val = mjpeg_decode_dc(s, dc_index);\n\n    if (val == 0xffff) {\n\n        dprintf(\"error dc\\n\");\n\n        return -1;\n\n    }\n\n    val = val * quant_matrix[0] + s->last_dc[component];\n\n    s->last_dc[component] = val;\n\n    block[0] = val;\n\n    /* AC coefs */\n\n    ac_vlc = &s->vlcs[1][ac_index];\n\n    i = 0;\n\n    {OPEN_READER(re, &s->gb)\n\n    for(;;) {\n\n        UPDATE_CACHE(re, &s->gb);\n\n        GET_VLC(code, re, &s->gb, s->vlcs[1][ac_index].table, 9, 2)\n\n\n\n        /* EOB */\n\n        if (code == 0x10)\n\n            break;\n\n        if (code == 0x100) {\n\n            i += 16;\n\n        } else {\n\n            i += ((unsigned)code) >> 4;\n\n            code &= 0xf;\n\n            if(code > MIN_CACHE_BITS - 16){\n\n                UPDATE_CACHE(re, &s->gb)\n\n            }\n\n            {\n\n                int cache=GET_CACHE(re,gb);\n\n                int sign=(~cache)>>31;\n\n                level = (NEG_USR32(sign ^ cache,code) ^ sign) - sign;\n\n            }\n\n\n\n            LAST_SKIP_BITS(re, &s->gb, code)\n\n\n\n            if (i >= 63) {\n\n                if(i == 63){\n\n                    j = s->scantable.permutated[63];\n\n                    block[j] = level * quant_matrix[j];\n\n                    break;\n\n                }\n\n                dprintf(\"error count: %d\\n\", i);\n\n                return -1;\n\n            }\n\n            j = s->scantable.permutated[i];\n\n            block[j] = level * quant_matrix[j];\n\n        }\n\n    }\n\n    CLOSE_READER(re, &s->gb)}\n\n\n\n    return 0;\n\n}\n", "idx": 24826}
{"project": "FFmpeg", "commit_id": "853a97530e0aabfd1474b1679e3dc8be978e5ef8", "target": 0, "func": "static void mp3_parse_vbr_tags(AVFormatContext *s, AVStream *st, int64_t base)\n\n{\n\n    uint32_t v, spf;\n\n    int frames = -1; /* Total number of frames in file */\n\n    const int64_t xing_offtbl[2][2] = {{32, 17}, {17,9}};\n\n    MPADecodeContext c;\n\n\n\n    v = get_be32(s->pb);\n\n    if(ff_mpa_check_header(v) < 0)\n\n      return;\n\n\n\n    ff_mpegaudio_decode_header(&c, v);\n\n    if(c.layer != 3)\n\n        return;\n\n\n\n    /* Check for Xing / Info tag */\n\n    url_fseek(s->pb, xing_offtbl[c.lsf == 1][c.nb_channels == 1], SEEK_CUR);\n\n    v = get_be32(s->pb);\n\n    if(v == MKBETAG('X', 'i', 'n', 'g') || v == MKBETAG('I', 'n', 'f', 'o')) {\n\n        v = get_be32(s->pb);\n\n        if(v & 0x1)\n\n            frames = get_be32(s->pb);\n\n    }\n\n\n\n    /* Check for VBRI tag (always 32 bytes after end of mpegaudio header) */\n\n    url_fseek(s->pb, base + 4 + 32, SEEK_SET);\n\n    v = get_be32(s->pb);\n\n    if(v == MKBETAG('V', 'B', 'R', 'I')) {\n\n        /* Check tag version */\n\n        if(get_be16(s->pb) == 1) {\n\n            /* skip delay, quality and total bytes */\n\n            url_fseek(s->pb, 8, SEEK_CUR);\n\n            frames = get_be32(s->pb);\n\n        }\n\n    }\n\n\n\n    if(frames < 0)\n\n        return;\n\n\n\n    spf = c.lsf ? 576 : 1152; /* Samples per frame, layer 3 */\n\n    st->duration = av_rescale_q(frames, (AVRational){spf, c.sample_rate},\n\n                                st->time_base);\n\n}\n", "idx": 24827}
{"project": "FFmpeg", "commit_id": "c453723ad7d14abc5e82677eebaa6025fa598f08", "target": 0, "func": "static int gif_read_image(GifState *s, AVFrame *frame)\n\n{\n\n    int left, top, width, height, bits_per_pixel, code_size, flags;\n\n    int is_interleaved, has_local_palette, y, pass, y1, linesize, n, i;\n\n    uint8_t *ptr, *spal, *palette, *ptr1;\n\n\n\n    left = bytestream_get_le16(&s->bytestream);\n\n    top = bytestream_get_le16(&s->bytestream);\n\n    width = bytestream_get_le16(&s->bytestream);\n\n    height = bytestream_get_le16(&s->bytestream);\n\n    flags = bytestream_get_byte(&s->bytestream);\n\n    is_interleaved = flags & 0x40;\n\n    has_local_palette = flags & 0x80;\n\n    bits_per_pixel = (flags & 0x07) + 1;\n\n\n\n    av_dlog(s->avctx, \"gif: image x=%d y=%d w=%d h=%d\\n\", left, top, width, height);\n\n\n\n    if (has_local_palette) {\n\n        bytestream_get_buffer(&s->bytestream, s->local_palette, 3 * (1 << bits_per_pixel));\n\n        palette = s->local_palette;\n\n    } else {\n\n        palette = s->global_palette;\n\n        bits_per_pixel = s->bits_per_pixel;\n\n    }\n\n\n\n    /* verify that all the image is inside the screen dimensions */\n\n    if (left + width > s->screen_width ||\n\n        top + height > s->screen_height)\n\n        return AVERROR(EINVAL);\n\n\n\n    /* build the palette */\n\n    n = (1 << bits_per_pixel);\n\n    spal = palette;\n\n    for(i = 0; i < n; i++) {\n\n        s->image_palette[i] = (0xffu << 24) | AV_RB24(spal);\n\n        spal += 3;\n\n    }\n\n    for(; i < 256; i++)\n\n        s->image_palette[i] = (0xffu << 24);\n\n    /* handle transparency */\n\n    if (s->transparent_color_index >= 0)\n\n        s->image_palette[s->transparent_color_index] = 0;\n\n\n\n    /* now get the image data */\n\n    code_size = bytestream_get_byte(&s->bytestream);\n\n    ff_lzw_decode_init(s->lzw, code_size, s->bytestream,\n\n                       s->bytestream_end - s->bytestream, FF_LZW_GIF);\n\n\n\n    /* read all the image */\n\n    linesize = frame->linesize[0];\n\n    ptr1 = frame->data[0] + top * linesize + left;\n\n    ptr = ptr1;\n\n    pass = 0;\n\n    y1 = 0;\n\n    for (y = 0; y < height; y++) {\n\n        ff_lzw_decode(s->lzw, ptr, width);\n\n        if (is_interleaved) {\n\n            switch(pass) {\n\n            default:\n\n            case 0:\n\n            case 1:\n\n                y1 += 8;\n\n                ptr += linesize * 8;\n\n                if (y1 >= height) {\n\n                    y1 = pass ? 2 : 4;\n\n                    ptr = ptr1 + linesize * y1;\n\n                    pass++;\n\n                }\n\n                break;\n\n            case 2:\n\n                y1 += 4;\n\n                ptr += linesize * 4;\n\n                if (y1 >= height) {\n\n                    y1 = 1;\n\n                    ptr = ptr1 + linesize;\n\n                    pass++;\n\n                }\n\n                break;\n\n            case 3:\n\n                y1 += 2;\n\n                ptr += linesize * 2;\n\n                break;\n\n            }\n\n        } else {\n\n            ptr += linesize;\n\n        }\n\n    }\n\n    /* read the garbage data until end marker is found */\n\n    ff_lzw_decode_tail(s->lzw);\n\n    s->bytestream = ff_lzw_cur_ptr(s->lzw);\n\n    return 0;\n\n}\n", "idx": 24828}
{"project": "FFmpeg", "commit_id": "ce19aec15b4291dc48e791d89a1f940babc22cdc", "target": 0, "func": "const uint8_t *ff_h263_find_resync_marker(const uint8_t *av_restrict p, const uint8_t *av_restrict end)\n\n{\n\n    av_assert2(p < end);\n\n\n\n    end-=2;\n\n    p++;\n\n    for(;p<end; p+=2){\n\n        if(!*p){\n\n            if     (!p[-1] && p[1]) return p - 1;\n\n            else if(!p[ 1] && p[2]) return p;\n\n        }\n\n    }\n\n    return end+2;\n\n}\n", "idx": 24829}
{"project": "FFmpeg", "commit_id": "e9b8523d52ca84d5012168db24fec2d50e73cf22", "target": 1, "func": "static int parse_fade(struct sbg_parser *p, struct sbg_fade *fr)\n\n{\n\n    struct sbg_fade f;\n\n\n\n    if (lex_char(p, '<'))\n\n        f.in = SBG_FADE_SILENCE;\n\n    else if (lex_char(p, '-'))\n\n        f.in = SBG_FADE_SAME;\n\n    else if (lex_char(p, '='))\n\n        f.in = SBG_FADE_ADAPT;\n\n    else\n\n        return 0;\n\n    if (lex_char(p, '>'))\n\n        f.out = SBG_FADE_SILENCE;\n\n    else if (lex_char(p, '-'))\n\n        f.out = SBG_FADE_SAME;\n\n    else if (lex_char(p, '='))\n\n        f.out = SBG_FADE_ADAPT;\n\n    else\n\n        return AVERROR_INVALIDDATA;\n\n    *fr = f;\n\n    return 1;\n\n}\n", "idx": 24832}
{"project": "FFmpeg", "commit_id": "d13a731fc149d3fdbe679078479ec1950674e762", "target": 1, "func": "int ff_hevc_decode_short_term_rps(HEVCContext *s, ShortTermRPS *rps,\n\n                                  const HEVCSPS *sps, int is_slice_header)\n\n{\n\n    HEVCLocalContext *lc = s->HEVClc;\n\n    uint8_t rps_predict = 0;\n\n    int delta_poc;\n\n    int k0 = 0;\n\n    int k1 = 0;\n\n    int k  = 0;\n\n    int i;\n\n\n\n    GetBitContext *gb = &lc->gb;\n\n\n\n    if (rps != sps->st_rps && sps->nb_st_rps)\n\n        rps_predict = get_bits1(gb);\n\n\n\n    if (rps_predict) {\n\n        const ShortTermRPS *rps_ridx;\n\n        int delta_rps, abs_delta_rps;\n\n        uint8_t use_delta_flag = 0;\n\n        uint8_t delta_rps_sign;\n\n\n\n        if (is_slice_header) {\n\n            unsigned int delta_idx = get_ue_golomb_long(gb) + 1;\n\n            if (delta_idx > sps->nb_st_rps) {\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"Invalid value of delta_idx in slice header RPS: %d > %d.\\n\",\n\n                       delta_idx, sps->nb_st_rps);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            rps_ridx = &sps->st_rps[sps->nb_st_rps - delta_idx];\n\n        } else\n\n            rps_ridx = &sps->st_rps[rps - sps->st_rps - 1];\n\n\n\n        delta_rps_sign = get_bits1(gb);\n\n        abs_delta_rps  = get_ue_golomb_long(gb) + 1;\n\n        delta_rps      = (1 - (delta_rps_sign << 1)) * abs_delta_rps;\n\n        for (i = 0; i <= rps_ridx->num_delta_pocs; i++) {\n\n            int used = rps->used[k] = get_bits1(gb);\n\n\n\n            if (!used)\n\n                use_delta_flag = get_bits1(gb);\n\n\n\n            if (used || use_delta_flag) {\n\n                if (i < rps_ridx->num_delta_pocs)\n\n                    delta_poc = delta_rps + rps_ridx->delta_poc[i];\n\n                else\n\n                    delta_poc = delta_rps;\n\n                rps->delta_poc[k] = delta_poc;\n\n                if (delta_poc < 0)\n\n                    k0++;\n\n                else\n\n                    k1++;\n\n                k++;\n\n            }\n\n        }\n\n\n\n        rps->num_delta_pocs    = k;\n\n        rps->num_negative_pics = k0;\n\n        // sort in increasing order (smallest first)\n\n        if (rps->num_delta_pocs != 0) {\n\n            int used, tmp;\n\n            for (i = 1; i < rps->num_delta_pocs; i++) {\n\n                delta_poc = rps->delta_poc[i];\n\n                used      = rps->used[i];\n\n                for (k = i - 1; k >= 0; k--) {\n\n                    tmp = rps->delta_poc[k];\n\n                    if (delta_poc < tmp) {\n\n                        rps->delta_poc[k + 1] = tmp;\n\n                        rps->used[k + 1]      = rps->used[k];\n\n                        rps->delta_poc[k]     = delta_poc;\n\n                        rps->used[k]          = used;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        if ((rps->num_negative_pics >> 1) != 0) {\n\n            int used;\n\n            k = rps->num_negative_pics - 1;\n\n            // flip the negative values to largest first\n\n            for (i = 0; i < rps->num_negative_pics >> 1; i++) {\n\n                delta_poc         = rps->delta_poc[i];\n\n                used              = rps->used[i];\n\n                rps->delta_poc[i] = rps->delta_poc[k];\n\n                rps->used[i]      = rps->used[k];\n\n                rps->delta_poc[k] = delta_poc;\n\n                rps->used[k]      = used;\n\n                k--;\n\n            }\n\n        }\n\n    } else {\n\n        unsigned int prev, nb_positive_pics;\n\n        rps->num_negative_pics = get_ue_golomb_long(gb);\n\n        nb_positive_pics       = get_ue_golomb_long(gb);\n\n\n\n        if (rps->num_negative_pics >= MAX_REFS ||\n\n            nb_positive_pics >= MAX_REFS) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Too many refs in a short term RPS.\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        rps->num_delta_pocs = rps->num_negative_pics + nb_positive_pics;\n\n        if (rps->num_delta_pocs) {\n\n            prev = 0;\n\n            for (i = 0; i < rps->num_negative_pics; i++) {\n\n                delta_poc = get_ue_golomb_long(gb) + 1;\n\n                prev -= delta_poc;\n\n                rps->delta_poc[i] = prev;\n\n                rps->used[i]      = get_bits1(gb);\n\n            }\n\n            prev = 0;\n\n            for (i = 0; i < nb_positive_pics; i++) {\n\n                delta_poc = get_ue_golomb_long(gb) + 1;\n\n                prev += delta_poc;\n\n                rps->delta_poc[rps->num_negative_pics + i] = prev;\n\n                rps->used[rps->num_negative_pics + i]      = get_bits1(gb);\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 24834}
{"project": "FFmpeg", "commit_id": "6dd5371e34c6602591766f73aa647b369d77853b", "target": 1, "func": "int ff_tls_open_underlying(TLSShared *c, URLContext *parent, const char *uri, AVDictionary **options)\n\n{\n\n    int port;\n\n    const char *p;\n\n    char buf[200], opts[50] = \"\";\n\n    struct addrinfo hints = { 0 }, *ai = NULL;\n\n    const char *proxy_path;\n\n    int use_proxy;\n\n\n\n    set_options(c, uri);\n\n\n\n    if (c->listen)\n\n        snprintf(opts, sizeof(opts), \"?listen=1\");\n\n\n\n    av_url_split(NULL, 0, NULL, 0, c->host, sizeof(c->host), &port, NULL, 0, uri);\n\n\n\n    p = strchr(uri, '?');\n\n\n\n    if (!p) {\n\n        p = opts;\n\n    } else {\n\n        if (av_find_info_tag(opts, sizeof(opts), \"listen\", p))\n\n            c->listen = 1;\n\n    }\n\n\n\n    ff_url_join(buf, sizeof(buf), \"tcp\", NULL, c->host, port, \"%s\", p);\n\n\n\n    hints.ai_flags = AI_NUMERICHOST;\n\n    if (!getaddrinfo(c->host, NULL, &hints, &ai)) {\n\n        c->numerichost = 1;\n\n        freeaddrinfo(ai);\n\n    }\n\n\n\n    proxy_path = getenv(\"http_proxy\");\n\n    use_proxy = !ff_http_match_no_proxy(getenv(\"no_proxy\"), c->host) &&\n\n                proxy_path && av_strstart(proxy_path, \"http://\", NULL);\n\n\n\n    if (use_proxy) {\n\n        char proxy_host[200], proxy_auth[200], dest[200];\n\n        int proxy_port;\n\n        av_url_split(NULL, 0, proxy_auth, sizeof(proxy_auth),\n\n                     proxy_host, sizeof(proxy_host), &proxy_port, NULL, 0,\n\n                     proxy_path);\n\n        ff_url_join(dest, sizeof(dest), NULL, NULL, c->host, port, NULL);\n\n        ff_url_join(buf, sizeof(buf), \"httpproxy\", proxy_auth, proxy_host,\n\n                    proxy_port, \"/%s\", dest);\n\n    }\n\n\n\n    return ffurl_open(&c->tcp, buf, AVIO_FLAG_READ_WRITE,\n\n                      &parent->interrupt_callback, options);\n\n}\n", "idx": 24837}
{"project": "FFmpeg", "commit_id": "eb5b0422b595d488f5c2f2a37a62cd46dfbb6aa7", "target": 0, "func": "static inline int clamp(int value, int min, int max)\n\n{\n\n   if (value < min)\n\n       return min;\n\n   else if (value > max)\n\n       return max;\n\n   else \n\n       return value;\n\n}\n", "idx": 24839}
{"project": "FFmpeg", "commit_id": "980bbb13d653561d83619350db32ccb5e5248f95", "target": 0, "func": "static int faac_decode_frame(AVCodecContext *avctx,\n\n                             void *data, int *data_size,\n\n                             uint8_t *buf, int buf_size)\n\n{\n\n    FAACContext *s = (FAACContext *) avctx->priv_data;\n\n#ifndef FAAD2_VERSION\n\n    unsigned long bytesconsumed;\n\n    short *sample_buffer = NULL;\n\n    unsigned long samples;\n\n    int out;\n\n#else\n\n    faacDecFrameInfo frame_info;\n\n    void *out;\n\n#endif\n\n    if(buf_size == 0)\n\n        return 0;\n\n#ifndef FAAD2_VERSION\n\n    out = s->faacDecDecode(s->faac_handle,\n\n                           (unsigned char*)buf,\n\n                           &bytesconsumed,\n\n                           data,\n\n                           &samples);\n\n    samples *= s->sample_size;\n\n    if (data_size)\n\n        *data_size = samples;\n\n    return (buf_size < (int)bytesconsumed)\n\n        ? buf_size : (int)bytesconsumed;\n\n#else\n\n\n\n    if(!s->init){\n\n        unsigned long srate;\n\n        unsigned char channels;\n\n        int r = s->faacDecInit(s->faac_handle, buf, buf_size, &srate, &channels);\n\n        if(r < 0){\n\n            av_log(avctx, AV_LOG_ERROR, \"faac: codec init failed: %s\\n\",\n\n                   s->faacDecGetErrorMessage(frame_info.error));\n\n            return 0;\n\n        }\n\n        avctx->sample_rate = srate;\n\n        avctx->channels = channels;\n\n        s->init = 1;\n\n    }\n\n\n\n    out = s->faacDecDecode(s->faac_handle, &frame_info, (unsigned char*)buf, (unsigned long)buf_size);\n\n\n\n    if (frame_info.error > 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"faac: frame decoding failed: %s\\n\",\n\n                s->faacDecGetErrorMessage(frame_info.error));\n\n        return 0;\n\n    }\n\n\n\n    frame_info.samples *= s->sample_size;\n\n    memcpy(data, out, frame_info.samples); // CHECKME - can we cheat this one\n\n\n\n    if (data_size)\n\n        *data_size = frame_info.samples;\n\n\n\n    return (buf_size < (int)frame_info.bytesconsumed)\n\n        ? buf_size : (int)frame_info.bytesconsumed;\n\n#endif\n\n}\n", "idx": 24848}
{"project": "FFmpeg", "commit_id": "9d8533368f55e1f6a0ea30d6492b26399b030066", "target": 0, "func": "static void mdct512(int32_t *out, int16_t *in)\n\n{\n\n    int i, re, im, re1, im1;\n\n    int16_t rot[MDCT_SAMPLES];\n\n    IComplex x[MDCT_SAMPLES/4];\n\n\n\n    /* shift to simplify computations */\n\n    for (i = 0; i < MDCT_SAMPLES/4; i++)\n\n        rot[i] = -in[i + 3*MDCT_SAMPLES/4];\n\n    for (;i < MDCT_SAMPLES; i++)\n\n        rot[i] =  in[i -   MDCT_SAMPLES/4];\n\n\n\n    /* pre rotation */\n\n    for (i = 0; i < MDCT_SAMPLES/4; i++) {\n\n        re =  ((int)rot[               2*i] - (int)rot[MDCT_SAMPLES  -1-2*i]) >> 1;\n\n        im = -((int)rot[MDCT_SAMPLES/2+2*i] - (int)rot[MDCT_SAMPLES/2-1-2*i]) >> 1;\n\n        CMUL(x[i].re, x[i].im, re, im, -xcos1[i], xsin1[i]);\n\n    }\n\n\n\n    fft(x, MDCT_NBITS - 2);\n\n\n\n    /* post rotation */\n\n    for (i = 0; i < MDCT_SAMPLES/4; i++) {\n\n        re = x[i].re;\n\n        im = x[i].im;\n\n        CMUL(re1, im1, re, im, xsin1[i], xcos1[i]);\n\n        out[                 2*i] = im1;\n\n        out[MDCT_SAMPLES/2-1-2*i] = re1;\n\n    }\n\n}\n", "idx": 24859}
{"project": "FFmpeg", "commit_id": "3df18b3ed1177037892ce5b3db113d52dcdcdbf3", "target": 0, "func": "av_cold int ff_rv34_decode_init(AVCodecContext *avctx)\n\n{\n\n    RV34DecContext *r = avctx->priv_data;\n\n    MpegEncContext *s = &r->s;\n\n\n\n    MPV_decode_defaults(s);\n\n    s->avctx= avctx;\n\n    s->out_format = FMT_H263;\n\n    s->codec_id= avctx->codec_id;\n\n\n\n    s->width = avctx->width;\n\n    s->height = avctx->height;\n\n\n\n    r->s.avctx = avctx;\n\n    avctx->flags |= CODEC_FLAG_EMU_EDGE;\n\n    r->s.flags |= CODEC_FLAG_EMU_EDGE;\n\n    avctx->pix_fmt = PIX_FMT_YUV420P;\n\n    avctx->has_b_frames = 1;\n\n    s->low_delay = 0;\n\n\n\n    if (MPV_common_init(s) < 0)\n\n        return -1;\n\n\n\n    ff_h264_pred_init(&r->h, CODEC_ID_RV40);\n\n\n\n    r->intra_types_hist = av_malloc(s->b4_stride * 4 * 2 * sizeof(*r->intra_types_hist));\n\n    r->intra_types = r->intra_types_hist + s->b4_stride * 4;\n\n\n\n    r->mb_type = av_mallocz(r->s.mb_stride * r->s.mb_height * sizeof(*r->mb_type));\n\n\n\n    r->cbp_luma   = av_malloc(r->s.mb_stride * r->s.mb_height * sizeof(*r->cbp_luma));\n\n    r->cbp_chroma = av_malloc(r->s.mb_stride * r->s.mb_height * sizeof(*r->cbp_chroma));\n\n    r->deblock_coefs = av_malloc(r->s.mb_stride * r->s.mb_height * sizeof(*r->deblock_coefs));\n\n\n\n    if(!intra_vlcs[0].cbppattern[0].bits)\n\n        rv34_init_tables();\n\n\n\n    return 0;\n\n}\n", "idx": 24860}
{"project": "FFmpeg", "commit_id": "486637af8ef29ec215e0e0b7ecd3b5470f0e04e5", "target": 0, "func": "static inline void mix_2f_2r_to_stereo(AC3DecodeContext *ctx)\n\n{\n\n    int i;\n\n    float (*output)[256] = ctx->audio_block.block_output;\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        output[1][i] += output[3][i];\n\n        output[2][i] += output[4][i];\n\n    }\n\n    memset(output[3], 0, sizeof(output[3]));\n\n    memset(output[4], 0, sizeof(output[4]));\n\n}\n", "idx": 24861}
{"project": "FFmpeg", "commit_id": "d8013f38ab73b15c5041f2489fc0b8bb45512e24", "target": 0, "func": "static int segment_start(AVFormatContext *s)\n\n{\n\n    SegmentContext *seg = s->priv_data;\n\n    AVFormatContext *oc = seg->avf;\n\n    int err = 0;\n\n\n\n    if (seg->wrap)\n\n        seg->number %= seg->wrap;\n\n\n\n    if (av_get_frame_filename(oc->filename, sizeof(oc->filename),\n\n                              s->filename, seg->number++) < 0)\n\n        return AVERROR(EINVAL);\n\n\n\n    if ((err = avio_open2(&oc->pb, oc->filename, AVIO_FLAG_WRITE,\n\n                          &s->interrupt_callback, NULL)) < 0)\n\n        return err;\n\n\n\n    if (!oc->priv_data && oc->oformat->priv_data_size > 0) {\n\n        oc->priv_data = av_mallocz(oc->oformat->priv_data_size);\n\n        if (!oc->priv_data) {\n\n            avio_close(oc->pb);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        if (oc->oformat->priv_class) {\n\n            *(const AVClass**)oc->priv_data = oc->oformat->priv_class;\n\n            av_opt_set_defaults(oc->priv_data);\n\n        }\n\n    }\n\n\n\n    if ((err = oc->oformat->write_header(oc)) < 0) {\n\n        goto fail;\n\n    }\n\n\n\n    return 0;\n\n\n\nfail:\n\n    av_log(oc, AV_LOG_ERROR, \"Failure occurred when starting segment '%s'\\n\",\n\n           oc->filename);\n\n    avio_close(oc->pb);\n\n    av_freep(&oc->priv_data);\n\n\n\n    return err;\n\n}\n", "idx": 24869}
{"project": "FFmpeg", "commit_id": "708ed15d8ccd5ae3d073cbd4dc69dafccec3fcc7", "target": 0, "func": "static int put_image(struct vf_instance *vf, mp_image_t *mpi, double pts)\n\n{\n\n    mp_image_t *dmpi;\n\n    if (vf->priv->in.fmt == vf->priv->out.fmt) { //nothing to do\n\n        dmpi = mpi;\n\n    } else {\n\n        int out_off_left, out_off_right;\n\n        int in_off_left  = vf->priv->in.row_left   * mpi->stride[0]  +\n\n                           vf->priv->in.off_left;\n\n        int in_off_right = vf->priv->in.row_right  * mpi->stride[0]  +\n\n                           vf->priv->in.off_right;\n\n\n\n        dmpi = ff_vf_get_image(vf->next, IMGFMT_RGB24, MP_IMGTYPE_TEMP,\n\n                            MP_IMGFLAG_ACCEPT_STRIDE,\n\n                            vf->priv->out.width, vf->priv->out.height);\n\n        out_off_left   = vf->priv->out.row_left  * dmpi->stride[0] +\n\n                         vf->priv->out.off_left;\n\n        out_off_right  = vf->priv->out.row_right * dmpi->stride[0] +\n\n                         vf->priv->out.off_right;\n\n\n\n        switch (vf->priv->out.fmt) {\n\n        case SIDE_BY_SIDE_LR:\n\n        case SIDE_BY_SIDE_RL:\n\n        case SIDE_BY_SIDE_2_LR:\n\n        case SIDE_BY_SIDE_2_RL:\n\n        case ABOVE_BELOW_LR:\n\n        case ABOVE_BELOW_RL:\n\n        case ABOVE_BELOW_2_LR:\n\n        case ABOVE_BELOW_2_RL:\n\n        case INTERLEAVE_ROWS_LR:\n\n        case INTERLEAVE_ROWS_RL:\n\n            memcpy_pic2(dmpi->planes[0] + out_off_left,\n\n                       mpi->planes[0] + in_off_left,\n\n                       3 * vf->priv->width,\n\n                       vf->priv->height,\n\n                       dmpi->stride[0] * vf->priv->row_step,\n\n                       mpi->stride[0] * vf->priv->row_step,\n\n                       vf->priv->row_step != 1);\n\n            memcpy_pic2(dmpi->planes[0] + out_off_right,\n\n                       mpi->planes[0] + in_off_right,\n\n                       3 * vf->priv->width,\n\n                       vf->priv->height,\n\n                       dmpi->stride[0] * vf->priv->row_step,\n\n                       mpi->stride[0] * vf->priv->row_step,\n\n                       vf->priv->row_step != 1);\n\n            break;\n\n        case MONO_L:\n\n        case MONO_R:\n\n            memcpy_pic(dmpi->planes[0],\n\n                       mpi->planes[0] + in_off_left,\n\n                       3 * vf->priv->width,\n\n                       vf->priv->height,\n\n                       dmpi->stride[0],\n\n                       mpi->stride[0]);\n\n            break;\n\n        case ANAGLYPH_RC_GRAY:\n\n        case ANAGLYPH_RC_HALF:\n\n        case ANAGLYPH_RC_COLOR:\n\n        case ANAGLYPH_RC_DUBOIS:\n\n        case ANAGLYPH_GM_GRAY:\n\n        case ANAGLYPH_GM_HALF:\n\n        case ANAGLYPH_GM_COLOR:\n\n        case ANAGLYPH_YB_GRAY:\n\n        case ANAGLYPH_YB_HALF:\n\n        case ANAGLYPH_YB_COLOR: {\n\n            int i,x,y,il,ir,o;\n\n            unsigned char *source     = mpi->planes[0];\n\n            unsigned char *dest       = dmpi->planes[0];\n\n            unsigned int   out_width  = vf->priv->out.width;\n\n            int           *ana_matrix[3];\n\n\n\n            for(i = 0; i < 3; i++)\n\n                ana_matrix[i] = vf->priv->ana_matrix[i];\n\n\n\n            for (y = 0; y < vf->priv->out.height; y++) {\n\n                o   = dmpi->stride[0] * y;\n\n                il  = in_off_left  + y * mpi->stride[0];\n\n                ir  = in_off_right + y * mpi->stride[0];\n\n                for (x = 0; x < out_width; x++) {\n\n                    dest[o    ]  = ana_convert(\n\n                                   ana_matrix[0], source + il, source + ir); //red out\n\n                    dest[o + 1]  = ana_convert(\n\n                                   ana_matrix[1], source + il, source + ir); //green out\n\n                    dest[o + 2]  = ana_convert(\n\n                                   ana_matrix[2], source + il, source + ir); //blue out\n\n                    il += 3;\n\n                    ir += 3;\n\n                    o  += 3;\n\n                }\n\n            }\n\n            break;\n\n        }\n\n        default:\n\n            ff_mp_msg(MSGT_VFILTER, MSGL_WARN,\n\n                   \"[stereo3d] stereo format of output is not supported\\n\");\n\n            return 0;\n\n            break;\n\n        }\n\n    }\n\n    return ff_vf_next_put_image(vf, dmpi, pts);\n\n}\n", "idx": 24870}
{"project": "FFmpeg", "commit_id": "42361bdf51c4495ca71a532efbb7769475c1822c", "target": 0, "func": "int ff_MPV_frame_start(MpegEncContext *s, AVCodecContext *avctx)\n\n{\n\n    int i, ret;\n\n    Picture *pic;\n\n    s->mb_skipped = 0;\n\n\n\n    if (!ff_thread_can_start_frame(avctx)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Attempt to start a frame outside SETUP state\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* mark & release old frames */\n\n    if (s->pict_type != AV_PICTURE_TYPE_B && s->last_picture_ptr &&\n\n        s->last_picture_ptr != s->next_picture_ptr &&\n\n        s->last_picture_ptr->f.buf[0]) {\n\n        ff_mpeg_unref_picture(s, s->last_picture_ptr);\n\n    }\n\n\n\n    /* release forgotten pictures */\n\n    /* if (mpeg124/h263) */\n\n    for (i = 0; i < MAX_PICTURE_COUNT; i++) {\n\n        if (&s->picture[i] != s->last_picture_ptr &&\n\n            &s->picture[i] != s->next_picture_ptr &&\n\n            s->picture[i].reference && !s->picture[i].needs_realloc) {\n\n            if (!(avctx->active_thread_type & FF_THREAD_FRAME))\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"releasing zombie picture\\n\");\n\n            ff_mpeg_unref_picture(s, &s->picture[i]);\n\n        }\n\n    }\n\n\n\n    ff_mpeg_unref_picture(s, &s->current_picture);\n\n\n\n    release_unused_pictures(s);\n\n\n\n    if (s->current_picture_ptr &&\n\n        s->current_picture_ptr->f.buf[0] == NULL) {\n\n        // we already have a unused image\n\n        // (maybe it was set before reading the header)\n\n        pic = s->current_picture_ptr;\n\n    } else {\n\n        i   = ff_find_unused_picture(s, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        pic = &s->picture[i];\n\n    }\n\n\n\n    pic->reference = 0;\n\n    if (!s->droppable) {\n\n        if (s->pict_type != AV_PICTURE_TYPE_B)\n\n            pic->reference = 3;\n\n    }\n\n\n\n    pic->f.coded_picture_number = s->coded_picture_number++;\n\n\n\n    if (ff_alloc_picture(s, pic, 0) < 0)\n\n        return -1;\n\n\n\n    s->current_picture_ptr = pic;\n\n    // FIXME use only the vars from current_pic\n\n    s->current_picture_ptr->f.top_field_first = s->top_field_first;\n\n    if (s->codec_id == AV_CODEC_ID_MPEG1VIDEO ||\n\n        s->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n        if (s->picture_structure != PICT_FRAME)\n\n            s->current_picture_ptr->f.top_field_first =\n\n                (s->picture_structure == PICT_TOP_FIELD) == s->first_field;\n\n    }\n\n    s->current_picture_ptr->f.interlaced_frame = !s->progressive_frame &&\n\n                                                 !s->progressive_sequence;\n\n    s->current_picture_ptr->field_picture      =  s->picture_structure != PICT_FRAME;\n\n\n\n    s->current_picture_ptr->f.pict_type = s->pict_type;\n\n    // if (s->flags && CODEC_FLAG_QSCALE)\n\n    //     s->current_picture_ptr->quality = s->new_picture_ptr->quality;\n\n    s->current_picture_ptr->f.key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n\n\n    if ((ret = ff_mpeg_ref_picture(s, &s->current_picture,\n\n                                   s->current_picture_ptr)) < 0)\n\n        return ret;\n\n\n\n    if (s->pict_type != AV_PICTURE_TYPE_B) {\n\n        s->last_picture_ptr = s->next_picture_ptr;\n\n        if (!s->droppable)\n\n            s->next_picture_ptr = s->current_picture_ptr;\n\n    }\n\n    av_dlog(s->avctx, \"L%p N%p C%p L%p N%p C%p type:%d drop:%d\\n\",\n\n            s->last_picture_ptr, s->next_picture_ptr,s->current_picture_ptr,\n\n            s->last_picture_ptr    ? s->last_picture_ptr->f.data[0]    : NULL,\n\n            s->next_picture_ptr    ? s->next_picture_ptr->f.data[0]    : NULL,\n\n            s->current_picture_ptr ? s->current_picture_ptr->f.data[0] : NULL,\n\n            s->pict_type, s->droppable);\n\n\n\n    if ((s->last_picture_ptr == NULL ||\n\n         s->last_picture_ptr->f.buf[0] == NULL) &&\n\n        (s->pict_type != AV_PICTURE_TYPE_I ||\n\n         s->picture_structure != PICT_FRAME)) {\n\n        int h_chroma_shift, v_chroma_shift;\n\n        av_pix_fmt_get_chroma_sub_sample(s->avctx->pix_fmt,\n\n                                         &h_chroma_shift, &v_chroma_shift);\n\n        if (s->pict_type == AV_PICTURE_TYPE_B && s->next_picture_ptr && s->next_picture_ptr->f.buf[0])\n\n            av_log(avctx, AV_LOG_DEBUG,\n\n                   \"allocating dummy last picture for B frame\\n\");\n\n        else if (s->pict_type != AV_PICTURE_TYPE_I)\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"warning: first frame is no keyframe\\n\");\n\n        else if (s->picture_structure != PICT_FRAME)\n\n            av_log(avctx, AV_LOG_DEBUG,\n\n                   \"allocate dummy last picture for field based first keyframe\\n\");\n\n\n\n        /* Allocate a dummy frame */\n\n        i = ff_find_unused_picture(s, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        s->last_picture_ptr = &s->picture[i];\n\n\n\n        s->last_picture_ptr->reference   = 3;\n\n        s->last_picture_ptr->f.key_frame = 0;\n\n        s->last_picture_ptr->f.pict_type = AV_PICTURE_TYPE_P;\n\n\n\n        if (ff_alloc_picture(s, s->last_picture_ptr, 0) < 0) {\n\n            s->last_picture_ptr = NULL;\n\n            return -1;\n\n        }\n\n\n\n        memset(s->last_picture_ptr->f.data[0], 0x80,\n\n               avctx->height * s->last_picture_ptr->f.linesize[0]);\n\n        memset(s->last_picture_ptr->f.data[1], 0x80,\n\n               (avctx->height >> v_chroma_shift) *\n\n               s->last_picture_ptr->f.linesize[1]);\n\n        memset(s->last_picture_ptr->f.data[2], 0x80,\n\n               (avctx->height >> v_chroma_shift) *\n\n               s->last_picture_ptr->f.linesize[2]);\n\n\n\n        if(s->codec_id == AV_CODEC_ID_FLV1 || s->codec_id == AV_CODEC_ID_H263){\n\n            for(i=0; i<avctx->height; i++)\n\n            memset(s->last_picture_ptr->f.data[0] + s->last_picture_ptr->f.linesize[0]*i, 16, avctx->width);\n\n        }\n\n\n\n        ff_thread_report_progress(&s->last_picture_ptr->tf, INT_MAX, 0);\n\n        ff_thread_report_progress(&s->last_picture_ptr->tf, INT_MAX, 1);\n\n    }\n\n    if ((s->next_picture_ptr == NULL ||\n\n         s->next_picture_ptr->f.buf[0] == NULL) &&\n\n        s->pict_type == AV_PICTURE_TYPE_B) {\n\n        /* Allocate a dummy frame */\n\n        i = ff_find_unused_picture(s, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        s->next_picture_ptr = &s->picture[i];\n\n\n\n        s->next_picture_ptr->reference   = 3;\n\n        s->next_picture_ptr->f.key_frame = 0;\n\n        s->next_picture_ptr->f.pict_type = AV_PICTURE_TYPE_P;\n\n\n\n        if (ff_alloc_picture(s, s->next_picture_ptr, 0) < 0) {\n\n            s->next_picture_ptr = NULL;\n\n            return -1;\n\n        }\n\n        ff_thread_report_progress(&s->next_picture_ptr->tf, INT_MAX, 0);\n\n        ff_thread_report_progress(&s->next_picture_ptr->tf, INT_MAX, 1);\n\n    }\n\n\n\n#if 0 // BUFREF-FIXME\n\n    memset(s->last_picture.f.data, 0, sizeof(s->last_picture.f.data));\n\n    memset(s->next_picture.f.data, 0, sizeof(s->next_picture.f.data));\n\n#endif\n\n    if (s->last_picture_ptr) {\n\n        ff_mpeg_unref_picture(s, &s->last_picture);\n\n        if (s->last_picture_ptr->f.buf[0] &&\n\n            (ret = ff_mpeg_ref_picture(s, &s->last_picture,\n\n                                       s->last_picture_ptr)) < 0)\n\n            return ret;\n\n    }\n\n    if (s->next_picture_ptr) {\n\n        ff_mpeg_unref_picture(s, &s->next_picture);\n\n        if (s->next_picture_ptr->f.buf[0] &&\n\n            (ret = ff_mpeg_ref_picture(s, &s->next_picture,\n\n                                       s->next_picture_ptr)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    av_assert0(s->pict_type == AV_PICTURE_TYPE_I || (s->last_picture_ptr &&\n\n                                                 s->last_picture_ptr->f.buf[0]));\n\n\n\n    if (s->picture_structure!= PICT_FRAME) {\n\n        int i;\n\n        for (i = 0; i < 4; i++) {\n\n            if (s->picture_structure == PICT_BOTTOM_FIELD) {\n\n                s->current_picture.f.data[i] +=\n\n                    s->current_picture.f.linesize[i];\n\n            }\n\n            s->current_picture.f.linesize[i] *= 2;\n\n            s->last_picture.f.linesize[i]    *= 2;\n\n            s->next_picture.f.linesize[i]    *= 2;\n\n        }\n\n    }\n\n\n\n    s->err_recognition = avctx->err_recognition;\n\n\n\n    /* set dequantizer, we can't do it during init as\n\n     * it might change for mpeg4 and we can't do it in the header\n\n     * decode as init is not called for mpeg4 there yet */\n\n    if (s->mpeg_quant || s->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n        s->dct_unquantize_intra = s->dct_unquantize_mpeg2_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_mpeg2_inter;\n\n    } else if (s->out_format == FMT_H263 || s->out_format == FMT_H261) {\n\n        s->dct_unquantize_intra = s->dct_unquantize_h263_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_h263_inter;\n\n    } else {\n\n        s->dct_unquantize_intra = s->dct_unquantize_mpeg1_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_mpeg1_inter;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24881}
{"project": "FFmpeg", "commit_id": "a8d8e868c6154f63a9229f913434aaa21833e488", "target": 1, "func": "static int udp_open(URLContext *h, const char *uri, int flags)\n\n{\n\n    char hostname[1024], localaddr[1024] = \"\";\n\n    int port, udp_fd = -1, tmp, bind_ret = -1;\n\n    UDPContext *s = h->priv_data;\n\n    int is_output;\n\n    const char *p;\n\n    char buf[256];\n\n    struct sockaddr_storage my_addr;\n\n    int len;\n\n    int reuse_specified = 0;\n\n    int i, include = 0, num_sources = 0;\n\n    char *sources[32];\n\n\n\n    h->is_streamed = 1;\n\n    h->max_packet_size = 1472;\n\n\n\n    is_output = !(flags & AVIO_FLAG_READ);\n\n\n\n    s->ttl = 16;\n\n    s->buffer_size = is_output ? UDP_TX_BUF_SIZE : UDP_MAX_PKT_SIZE;\n\n\n\n    s->circular_buffer_size = 7*188*4096;\n\n\n\n    p = strchr(uri, '?');\n\n    if (p) {\n\n        if (av_find_info_tag(buf, sizeof(buf), \"reuse\", p)) {\n\n            char *endptr = NULL;\n\n            s->reuse_socket = strtol(buf, &endptr, 10);\n\n            /* assume if no digits were found it is a request to enable it */\n\n            if (buf == endptr)\n\n                s->reuse_socket = 1;\n\n            reuse_specified = 1;\n\n        }\n\n        if (av_find_info_tag(buf, sizeof(buf), \"overrun_nonfatal\", p)) {\n\n            char *endptr = NULL;\n\n            s->overrun_nonfatal = strtol(buf, &endptr, 10);\n\n            /* assume if no digits were found it is a request to enable it */\n\n            if (buf == endptr)\n\n                s->overrun_nonfatal = 1;\n\n\n\n\n\n        }\n\n        if (av_find_info_tag(buf, sizeof(buf), \"ttl\", p)) {\n\n            s->ttl = strtol(buf, NULL, 10);\n\n        }\n\n        if (av_find_info_tag(buf, sizeof(buf), \"localport\", p)) {\n\n            s->local_port = strtol(buf, NULL, 10);\n\n        }\n\n        if (av_find_info_tag(buf, sizeof(buf), \"pkt_size\", p)) {\n\n            h->max_packet_size = strtol(buf, NULL, 10);\n\n        }\n\n        if (av_find_info_tag(buf, sizeof(buf), \"buffer_size\", p)) {\n\n            s->buffer_size = strtol(buf, NULL, 10);\n\n        }\n\n        if (av_find_info_tag(buf, sizeof(buf), \"connect\", p)) {\n\n            s->is_connected = strtol(buf, NULL, 10);\n\n        }\n\n        if (av_find_info_tag(buf, sizeof(buf), \"fifo_size\", p)) {\n\n            s->circular_buffer_size = strtol(buf, NULL, 10)*188;\n\n\n\n                       \"'circular_buffer_size' option was set but it is not supported \"\n\n\n        }\n\n        if (av_find_info_tag(buf, sizeof(buf), \"localaddr\", p)) {\n\n            av_strlcpy(localaddr, buf, sizeof(localaddr));\n\n        }\n\n        if (av_find_info_tag(buf, sizeof(buf), \"sources\", p))\n\n            include = 1;\n\n        if (include || av_find_info_tag(buf, sizeof(buf), \"block\", p)) {\n\n            char *source_start;\n\n\n\n            source_start = buf;\n\n            while (1) {\n\n                char *next = strchr(source_start, ',');\n\n                if (next)\n\n                    *next = '\\0';\n\n                sources[num_sources] = av_strdup(source_start);\n\n                if (!sources[num_sources])\n\n                    goto fail;\n\n                source_start = next + 1;\n\n                num_sources++;\n\n                if (num_sources >= FF_ARRAY_ELEMS(sources) || !next)\n\n                    break;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* fill the dest addr */\n\n    av_url_split(NULL, 0, NULL, 0, hostname, sizeof(hostname), &port, NULL, 0, uri);\n\n\n\n    /* XXX: fix av_url_split */\n\n    if (hostname[0] == '\\0' || hostname[0] == '?') {\n\n        /* only accepts null hostname if input */\n\n        if (!(flags & AVIO_FLAG_READ))\n\n            goto fail;\n\n    } else {\n\n        if (ff_udp_set_remote_url(h, uri) < 0)\n\n            goto fail;\n\n    }\n\n\n\n    if ((s->is_multicast || !s->local_port) && (h->flags & AVIO_FLAG_READ))\n\n        s->local_port = port;\n\n    udp_fd = udp_socket_create(s, &my_addr, &len, localaddr);\n\n    if (udp_fd < 0)\n\n        goto fail;\n\n\n\n    /* Follow the requested reuse option, unless it's multicast in which\n\n     * case enable reuse unless explicitly disabled.\n\n     */\n\n    if (s->reuse_socket || (s->is_multicast && !reuse_specified)) {\n\n        s->reuse_socket = 1;\n\n        if (setsockopt (udp_fd, SOL_SOCKET, SO_REUSEADDR, &(s->reuse_socket), sizeof(s->reuse_socket)) != 0)\n\n            goto fail;\n\n    }\n\n\n\n    /* If multicast, try binding the multicast address first, to avoid\n\n     * receiving UDP packets from other sources aimed at the same UDP\n\n     * port. This fails on windows. This makes sending to the same address\n\n     * using sendto() fail, so only do it if we're opened in read-only mode. */\n\n    if (s->is_multicast && !(h->flags & AVIO_FLAG_WRITE)) {\n\n        bind_ret = bind(udp_fd,(struct sockaddr *)&s->dest_addr, len);\n\n    }\n\n    /* bind to the local address if not multicast or if the multicast\n\n     * bind failed */\n\n    /* the bind is needed to give a port to the socket now */\n\n    if (bind_ret < 0 && bind(udp_fd,(struct sockaddr *)&my_addr, len) < 0) {\n\n        log_net_error(h, AV_LOG_ERROR, \"bind failed\");\n\n        goto fail;\n\n    }\n\n\n\n    len = sizeof(my_addr);\n\n    getsockname(udp_fd, (struct sockaddr *)&my_addr, &len);\n\n    s->local_port = udp_port(&my_addr, len);\n\n\n\n    if (s->is_multicast) {\n\n        if (h->flags & AVIO_FLAG_WRITE) {\n\n            /* output */\n\n            if (udp_set_multicast_ttl(udp_fd, s->ttl, (struct sockaddr *)&s->dest_addr) < 0)\n\n                goto fail;\n\n        }\n\n        if (h->flags & AVIO_FLAG_READ) {\n\n            /* input */\n\n            if (num_sources == 0 || !include) {\n\n                if (udp_join_multicast_group(udp_fd, (struct sockaddr *)&s->dest_addr) < 0)\n\n                    goto fail;\n\n\n\n                if (num_sources) {\n\n                    if (udp_set_multicast_sources(udp_fd, (struct sockaddr *)&s->dest_addr, s->dest_addr_len, sources, num_sources, 0) < 0)\n\n                        goto fail;\n\n                }\n\n            } else if (include && num_sources) {\n\n                if (udp_set_multicast_sources(udp_fd, (struct sockaddr *)&s->dest_addr, s->dest_addr_len, sources, num_sources, 1) < 0)\n\n                    goto fail;\n\n            } else {\n\n                av_log(NULL, AV_LOG_ERROR, \"invalid udp settings: inclusive multicast but no sources given\\n\");\n\n                goto fail;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (is_output) {\n\n        /* limit the tx buf size to limit latency */\n\n        tmp = s->buffer_size;\n\n        if (setsockopt(udp_fd, SOL_SOCKET, SO_SNDBUF, &tmp, sizeof(tmp)) < 0) {\n\n            log_net_error(h, AV_LOG_ERROR, \"setsockopt(SO_SNDBUF)\");\n\n            goto fail;\n\n        }\n\n    } else {\n\n        /* set udp recv buffer size to the largest possible udp packet size to\n\n         * avoid losing data on OSes that set this too low by default. */\n\n        tmp = s->buffer_size;\n\n        if (setsockopt(udp_fd, SOL_SOCKET, SO_RCVBUF, &tmp, sizeof(tmp)) < 0) {\n\n            log_net_error(h, AV_LOG_WARNING, \"setsockopt(SO_RECVBUF)\");\n\n        }\n\n        /* make the socket non-blocking */\n\n        ff_socket_nonblock(udp_fd, 1);\n\n    }\n\n    if (s->is_connected) {\n\n        if (connect(udp_fd, (struct sockaddr *) &s->dest_addr, s->dest_addr_len)) {\n\n            log_net_error(h, AV_LOG_ERROR, \"connect\");\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < num_sources; i++)\n\n        av_freep(&sources[i]);\n\n\n\n    s->udp_fd = udp_fd;\n\n\n\n#if HAVE_PTHREAD_CANCEL\n\n    if (!is_output && s->circular_buffer_size) {\n\n        int ret;\n\n\n\n        /* start the task going */\n\n        s->fifo = av_fifo_alloc(s->circular_buffer_size);\n\n        ret = pthread_mutex_init(&s->mutex, NULL);\n\n        if (ret != 0) {\n\n            av_log(h, AV_LOG_ERROR, \"pthread_mutex_init failed : %s\\n\", strerror(ret));\n\n            goto fail;\n\n        }\n\n        ret = pthread_cond_init(&s->cond, NULL);\n\n        if (ret != 0) {\n\n            av_log(h, AV_LOG_ERROR, \"pthread_cond_init failed : %s\\n\", strerror(ret));\n\n            goto cond_fail;\n\n        }\n\n        ret = pthread_create(&s->circular_buffer_thread, NULL, circular_buffer_task, h);\n\n        if (ret != 0) {\n\n            av_log(h, AV_LOG_ERROR, \"pthread_create failed : %s\\n\", strerror(ret));\n\n            goto thread_fail;\n\n        }\n\n        s->thread_started = 1;\n\n    }\n\n#endif\n\n\n\n    return 0;\n\n#if HAVE_PTHREAD_CANCEL\n\n thread_fail:\n\n    pthread_cond_destroy(&s->cond);\n\n cond_fail:\n\n    pthread_mutex_destroy(&s->mutex);\n\n#endif\n\n fail:\n\n    if (udp_fd >= 0)\n\n        closesocket(udp_fd);\n\n    av_fifo_free(s->fifo);\n\n    for (i = 0; i < num_sources; i++)\n\n        av_freep(&sources[i]);\n\n    return AVERROR(EIO);\n\n}", "idx": 24887}
{"project": "FFmpeg", "commit_id": "6f8ef5320f4d435803482ed322f3de45e6ea125c", "target": 1, "func": "static int vc1_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *data_size, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size, n_slices = 0, i;\n\n    VC1Context *v = avctx->priv_data;\n\n    MpegEncContext *s = &v->s;\n\n    AVFrame *pict = data;\n\n    uint8_t *buf2 = NULL;\n\n    const uint8_t *buf_start = buf;\n\n    int mb_height, n_slices1;\n\n    struct {\n\n        uint8_t *buf;\n\n        GetBitContext gb;\n\n        int mby_start;\n\n    } *slices = NULL, *tmp;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == VC1_CODE_ENDOFSEQ)) {\n\n        /* special case for last picture */\n\n        if (s->low_delay == 0 && s->next_picture_ptr) {\n\n            *pict = s->next_picture_ptr->f;\n\n            s->next_picture_ptr = NULL;\n\n\n\n            *data_size = sizeof(AVFrame);\n\n        }\n\n\n\n        return 0;\n\n    }\n\n\n\n    if (s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU) {\n\n        if (v->profile < PROFILE_ADVANCED)\n\n            avctx->pix_fmt = AV_PIX_FMT_VDPAU_WMV3;\n\n        else\n\n            avctx->pix_fmt = AV_PIX_FMT_VDPAU_VC1;\n\n    }\n\n\n\n    //for advanced profile we may need to parse and unescape data\n\n    if (avctx->codec_id == AV_CODEC_ID_VC1 || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n\n        int buf_size2 = 0;\n\n        buf2 = av_mallocz(buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n        if (IS_MARKER(AV_RB32(buf))) { /* frame starts with marker and needs to be parsed */\n\n            const uint8_t *start, *end, *next;\n\n            int size;\n\n\n\n            next = buf;\n\n            for (start = buf, end = buf + buf_size; next < end; start = next) {\n\n                next = find_next_marker(start + 4, end);\n\n                size = next - start - 4;\n\n                if (size <= 0) continue;\n\n                switch (AV_RB32(start)) {\n\n                case VC1_CODE_FRAME:\n\n                    if (avctx->hwaccel ||\n\n                        s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)\n\n                        buf_start = start;\n\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n\n                    break;\n\n                case VC1_CODE_FIELD: {\n\n                    int buf_size3;\n\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n\n                    if (!tmp)\n\n                        goto err;\n\n                    slices = tmp;\n\n                    slices[n_slices].buf = av_mallocz(buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                    if (!slices[n_slices].buf)\n\n                        goto err;\n\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n\n                                                    slices[n_slices].buf);\n\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n\n                                  buf_size3 << 3);\n\n                    /* assuming that the field marker is at the exact middle,\n\n                       hope it's correct */\n\n                    slices[n_slices].mby_start = s->mb_height >> 1;\n\n                    n_slices1 = n_slices - 1; // index of the last slice of the first field\n\n                    n_slices++;\n\n                    break;\n\n                }\n\n                case VC1_CODE_ENTRYPOINT: /* it should be before frame data */\n\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n\n                    init_get_bits(&s->gb, buf2, buf_size2 * 8);\n\n                    ff_vc1_decode_entry_point(avctx, v, &s->gb);\n\n                    break;\n\n                case VC1_CODE_SLICE: {\n\n                    int buf_size3;\n\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n\n                    if (!tmp)\n\n                        goto err;\n\n                    slices = tmp;\n\n                    slices[n_slices].buf = av_mallocz(buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                    if (!slices[n_slices].buf)\n\n                        goto err;\n\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n\n                                                    slices[n_slices].buf);\n\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n\n                                  buf_size3 << 3);\n\n                    slices[n_slices].mby_start = get_bits(&slices[n_slices].gb, 9);\n\n                    n_slices++;\n\n                    break;\n\n                }\n\n                }\n\n            }\n\n        } else if (v->interlace && ((buf[0] & 0xC0) == 0xC0)) { /* WVC1 interlaced stores both fields divided by marker */\n\n            const uint8_t *divider;\n\n            int buf_size3;\n\n\n\n            divider = find_next_marker(buf, buf + buf_size);\n\n            if ((divider == (buf + buf_size)) || AV_RB32(divider) != VC1_CODE_FIELD) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Error in WVC1 interlaced frame\\n\");\n\n                goto err;\n\n            } else { // found field marker, unescape second field\n\n                tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n\n                if (!tmp)\n\n                    goto err;\n\n                slices = tmp;\n\n                slices[n_slices].buf = av_mallocz(buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                if (!slices[n_slices].buf)\n\n                    goto err;\n\n                buf_size3 = vc1_unescape_buffer(divider + 4, buf + buf_size - divider - 4, slices[n_slices].buf);\n\n                init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n\n                              buf_size3 << 3);\n\n                slices[n_slices].mby_start = s->mb_height >> 1;\n\n                n_slices1 = n_slices - 1;\n\n                n_slices++;\n\n            }\n\n            buf_size2 = vc1_unescape_buffer(buf, divider - buf, buf2);\n\n        } else {\n\n            buf_size2 = vc1_unescape_buffer(buf, buf_size, buf2);\n\n        }\n\n        init_get_bits(&s->gb, buf2, buf_size2*8);\n\n    } else\n\n        init_get_bits(&s->gb, buf, buf_size*8);\n\n\n\n    if (v->res_sprite) {\n\n        v->new_sprite  = !get_bits1(&s->gb);\n\n        v->two_sprites =  get_bits1(&s->gb);\n\n        /* res_sprite means a Windows Media Image stream, AV_CODEC_ID_*IMAGE means\n\n           we're using the sprite compositor. These are intentionally kept separate\n\n           so you can get the raw sprites by using the wmv3 decoder for WMVP or\n\n           the vc1 one for WVP2 */\n\n        if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n\n            if (v->new_sprite) {\n\n                // switch AVCodecContext parameters to those of the sprites\n\n                avctx->width  = avctx->coded_width  = v->sprite_width;\n\n                avctx->height = avctx->coded_height = v->sprite_height;\n\n            } else {\n\n                goto image;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (s->context_initialized &&\n\n        (s->width  != avctx->coded_width ||\n\n         s->height != avctx->coded_height)) {\n\n        ff_vc1_decode_end(avctx);\n\n    }\n\n\n\n    if (!s->context_initialized) {\n\n        if (ff_msmpeg4_decode_init(avctx) < 0 || ff_vc1_decode_init_alloc_tables(v) < 0)\n\n            return -1;\n\n\n\n        s->low_delay = !avctx->has_b_frames || v->res_sprite;\n\n\n\n        if (v->profile == PROFILE_ADVANCED) {\n\n            s->h_edge_pos = avctx->coded_width;\n\n            s->v_edge_pos = avctx->coded_height;\n\n        }\n\n    }\n\n\n\n    /* We need to set current_picture_ptr before reading the header,\n\n     * otherwise we cannot store anything in there. */\n\n    if (s->current_picture_ptr == NULL || s->current_picture_ptr->f.data[0]) {\n\n        int i = ff_find_unused_picture(s, 0);\n\n        if (i < 0)\n\n            goto err;\n\n        s->current_picture_ptr = &s->picture[i];\n\n    }\n\n\n\n    // do parse frame header\n\n    v->pic_header_flag = 0;\n\n    if (v->profile < PROFILE_ADVANCED) {\n\n        if (ff_vc1_parse_frame_header(v, &s->gb) == -1) {\n\n            goto err;\n\n        }\n\n    } else {\n\n        if (ff_vc1_parse_frame_header_adv(v, &s->gb) == -1) {\n\n            goto err;\n\n        }\n\n    }\n\n\n\n    if ((avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE)\n\n        && s->pict_type != AV_PICTURE_TYPE_I) {\n\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Sprite decoder: expected I-frame\\n\");\n\n        goto err;\n\n    }\n\n\n\n    // process pulldown flags\n\n    s->current_picture_ptr->f.repeat_pict = 0;\n\n    // Pulldown flags are only valid when 'broadcast' has been set.\n\n    // So ticks_per_frame will be 2\n\n    if (v->rff) {\n\n        // repeat field\n\n        s->current_picture_ptr->f.repeat_pict = 1;\n\n    } else if (v->rptfrm) {\n\n        // repeat frames\n\n        s->current_picture_ptr->f.repeat_pict = v->rptfrm * 2;\n\n    }\n\n\n\n    // for skipping the frame\n\n    s->current_picture.f.pict_type = s->pict_type;\n\n    s->current_picture.f.key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n\n\n    /* skip B-frames if we don't have reference frames */\n\n    if (s->last_picture_ptr == NULL && (s->pict_type == AV_PICTURE_TYPE_B || s->dropable)) {\n\n        goto err;\n\n    }\n\n    if ((avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type == AV_PICTURE_TYPE_B) ||\n\n        (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type != AV_PICTURE_TYPE_I) ||\n\n         avctx->skip_frame >= AVDISCARD_ALL) {\n\n        goto end;\n\n    }\n\n\n\n    if (s->next_p_frame_damaged) {\n\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n\n            goto end;\n\n        else\n\n            s->next_p_frame_damaged = 0;\n\n    }\n\n\n\n    if (ff_MPV_frame_start(s, avctx) < 0) {\n\n        goto err;\n\n    }\n\n\n\n    s->me.qpel_put = s->dsp.put_qpel_pixels_tab;\n\n    s->me.qpel_avg = s->dsp.avg_qpel_pixels_tab;\n\n\n\n    if ((CONFIG_VC1_VDPAU_DECODER)\n\n        &&s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)\n\n        ff_vdpau_vc1_decode_picture(s, buf_start, (buf + buf_size) - buf_start);\n\n    else if (avctx->hwaccel) {\n\n        if (avctx->hwaccel->start_frame(avctx, buf, buf_size) < 0)\n\n            goto err;\n\n        if (avctx->hwaccel->decode_slice(avctx, buf_start, (buf + buf_size) - buf_start) < 0)\n\n            goto err;\n\n        if (avctx->hwaccel->end_frame(avctx) < 0)\n\n            goto err;\n\n    } else {\n\n        ff_er_frame_start(s);\n\n\n\n        v->bits = buf_size * 8;\n\n        v->end_mb_x = s->mb_width;\n\n        if (v->field_mode) {\n\n            uint8_t *tmp[2];\n\n            s->current_picture.f.linesize[0] <<= 1;\n\n            s->current_picture.f.linesize[1] <<= 1;\n\n            s->current_picture.f.linesize[2] <<= 1;\n\n            s->linesize                      <<= 1;\n\n            s->uvlinesize                    <<= 1;\n\n            tmp[0]          = v->mv_f_last[0];\n\n            tmp[1]          = v->mv_f_last[1];\n\n            v->mv_f_last[0] = v->mv_f_next[0];\n\n            v->mv_f_last[1] = v->mv_f_next[1];\n\n            v->mv_f_next[0] = v->mv_f[0];\n\n            v->mv_f_next[1] = v->mv_f[1];\n\n            v->mv_f[0] = tmp[0];\n\n            v->mv_f[1] = tmp[1];\n\n        }\n\n        mb_height = s->mb_height >> v->field_mode;\n\n        for (i = 0; i <= n_slices; i++) {\n\n            if (i > 0 &&  slices[i - 1].mby_start >= mb_height) {\n\n                if (v->field_mode <= 0) {\n\n                    av_log(v->s.avctx, AV_LOG_ERROR, \"Slice %d starts beyond \"\n\n                           \"picture boundary (%d >= %d)\\n\", i,\n\n                           slices[i - 1].mby_start, mb_height);\n\n                    continue;\n\n                }\n\n                v->second_field = 1;\n\n                v->blocks_off   = s->mb_width  * s->mb_height << 1;\n\n                v->mb_off       = s->mb_stride * s->mb_height >> 1;\n\n            } else {\n\n                v->second_field = 0;\n\n                v->blocks_off   = 0;\n\n                v->mb_off       = 0;\n\n            }\n\n            if (i) {\n\n                v->pic_header_flag = 0;\n\n                if (v->field_mode && i == n_slices1 + 2) {\n\n                    if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Field header damaged\\n\");\n\n                        continue;\n\n                    }\n\n                } else if (get_bits1(&s->gb)) {\n\n                    v->pic_header_flag = 1;\n\n                    if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Slice header damaged\\n\");\n\n                        continue;\n\n                    }\n\n                }\n\n            }\n\n            s->start_mb_y = (i == 0) ? 0 : FFMAX(0, slices[i-1].mby_start % mb_height);\n\n            if (!v->field_mode || v->second_field)\n\n                s->end_mb_y = (i == n_slices     ) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n\n            else\n\n                s->end_mb_y = (i <= n_slices1 + 1) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n\n            ff_vc1_decode_blocks(v);\n\n            if (i != n_slices)\n\n                s->gb = slices[i].gb;\n\n        }\n\n        if (v->field_mode) {\n\n            v->second_field = 0;\n\n            if (s->pict_type == AV_PICTURE_TYPE_B) {\n\n                memcpy(v->mv_f_base, v->mv_f_next_base,\n\n                       2 * (s->b8_stride * (s->mb_height * 2 + 1) + s->mb_stride * (s->mb_height + 1) * 2));\n\n            }\n\n            s->current_picture.f.linesize[0] >>= 1;\n\n            s->current_picture.f.linesize[1] >>= 1;\n\n            s->current_picture.f.linesize[2] >>= 1;\n\n            s->linesize                      >>= 1;\n\n            s->uvlinesize                    >>= 1;\n\n        }\n\n        av_dlog(s->avctx, \"Consumed %i/%i bits\\n\",\n\n                get_bits_count(&s->gb), s->gb.size_in_bits);\n\n//  if (get_bits_count(&s->gb) > buf_size * 8)\n\n//      return -1;\n\n        ff_er_frame_end(s);\n\n    }\n\n\n\n    ff_MPV_frame_end(s);\n\n\n\n    if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n\nimage:\n\n        avctx->width  = avctx->coded_width  = v->output_width;\n\n        avctx->height = avctx->coded_height = v->output_height;\n\n        if (avctx->skip_frame >= AVDISCARD_NONREF)\n\n            goto end;\n\n#if CONFIG_WMV3IMAGE_DECODER || CONFIG_VC1IMAGE_DECODER\n\n        if (vc1_decode_sprites(v, &s->gb))\n\n            goto err;\n\n#endif\n\n        *pict      = v->sprite_output_frame;\n\n        *data_size = sizeof(AVFrame);\n\n    } else {\n\n        if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n\n            *pict = s->current_picture_ptr->f;\n\n        } else if (s->last_picture_ptr != NULL) {\n\n            *pict = s->last_picture_ptr->f;\n\n        }\n\n        if (s->last_picture_ptr || s->low_delay) {\n\n            *data_size = sizeof(AVFrame);\n\n            ff_print_debug_info(s, pict);\n\n        }\n\n    }\n\n\n\nend:\n\n    av_free(buf2);\n\n    for (i = 0; i < n_slices; i++)\n\n        av_free(slices[i].buf);\n\n    av_free(slices);\n\n    return buf_size;\n\n\n\nerr:\n\n    av_free(buf2);\n\n    for (i = 0; i < n_slices; i++)\n\n        av_free(slices[i].buf);\n\n    av_free(slices);\n\n    return -1;\n\n}\n", "idx": 24888}
{"project": "FFmpeg", "commit_id": "d47e14b53a3908e5bad82e22129bbd175b49e89b", "target": 1, "func": "int ff_h263_decode_frame(AVCodecContext *avctx,\n\n                             void *data, int *got_frame,\n\n                             AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int ret;\n\n    AVFrame *pict = data;\n\n\n\n    s->flags= avctx->flags;\n\n    s->flags2= avctx->flags2;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0) {\n\n        /* special case for last picture */\n\n        if (s->low_delay==0 && s->next_picture_ptr) {\n\n            if ((ret = av_frame_ref(pict, &s->next_picture_ptr->f)) < 0)\n\n                return ret;\n\n            s->next_picture_ptr= NULL;\n\n\n\n            *got_frame = 1;\n\n        }\n\n\n\n        return 0;\n\n    }\n\n\n\n    if(s->flags&CODEC_FLAG_TRUNCATED){\n\n        int next;\n\n\n\n        if(CONFIG_MPEG4_DECODER && s->codec_id==AV_CODEC_ID_MPEG4){\n\n            next= ff_mpeg4_find_frame_end(&s->parse_context, buf, buf_size);\n\n        }else if(CONFIG_H263_DECODER && s->codec_id==AV_CODEC_ID_H263){\n\n            next= ff_h263_find_frame_end(&s->parse_context, buf, buf_size);\n\n        }else if(CONFIG_H263P_DECODER && s->codec_id==AV_CODEC_ID_H263P){\n\n            next= ff_h263_find_frame_end(&s->parse_context, buf, buf_size);\n\n        }else{\n\n            av_log(s->avctx, AV_LOG_ERROR, \"this codec does not support truncated bitstreams\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n\n\n        if( ff_combine_frame(&s->parse_context, next, (const uint8_t **)&buf, &buf_size) < 0 )\n\n            return buf_size;\n\n    }\n\n\n\n\n\nretry:\n\n    if(s->divx_packed && s->bitstream_buffer_size){\n\n        int i;\n\n        for(i=0; i<buf_size-3; i++){\n\n            if(buf[i]==0 && buf[i+1]==0 && buf[i+2]==1){\n\n                if(buf[i+3]==0xB0){\n\n                    av_log(s->avctx, AV_LOG_WARNING, \"Discarding excessive bitstream in packed xvid\\n\");\n\n                    s->bitstream_buffer_size=0;\n\n                }\n\n                break;\n\n            }\n\n        }\n\n    }\n\n\n\n    if(s->bitstream_buffer_size && (s->divx_packed || buf_size<20)){ //divx 5.01+/xvid frame reorder\n\n        init_get_bits(&s->gb, s->bitstream_buffer, s->bitstream_buffer_size*8);\n\n    }else\n\n        init_get_bits(&s->gb, buf, buf_size*8);\n\n    s->bitstream_buffer_size=0;\n\n\n\n    if (!s->context_initialized) {\n\n        if ((ret = ff_MPV_common_init(s)) < 0) //we need the idct permutaton for reading a custom matrix\n\n            return ret;\n\n    }\n\n\n\n    /* We need to set current_picture_ptr before reading the header,\n\n     * otherwise we cannot store anyting in there */\n\n    if (s->current_picture_ptr == NULL || s->current_picture_ptr->f.data[0]) {\n\n        int i= ff_find_unused_picture(s, 0);\n\n        if (i < 0)\n\n            return i;\n\n        s->current_picture_ptr= &s->picture[i];\n\n    }\n\n\n\n    /* let's go :-) */\n\n    if (CONFIG_WMV2_DECODER && s->msmpeg4_version==5) {\n\n        ret= ff_wmv2_decode_picture_header(s);\n\n    } else if (CONFIG_MSMPEG4_DECODER && s->msmpeg4_version) {\n\n        ret = ff_msmpeg4_decode_picture_header(s);\n\n    } else if (CONFIG_MPEG4_DECODER && s->h263_pred) {\n\n        if(s->avctx->extradata_size && s->picture_number==0){\n\n            GetBitContext gb;\n\n\n\n            init_get_bits(&gb, s->avctx->extradata, s->avctx->extradata_size*8);\n\n            ret = ff_mpeg4_decode_picture_header(s, &gb);\n\n        }\n\n        ret = ff_mpeg4_decode_picture_header(s, &s->gb);\n\n    } else if (CONFIG_H263I_DECODER && s->codec_id == AV_CODEC_ID_H263I) {\n\n        ret = ff_intel_h263_decode_picture_header(s);\n\n    } else if (CONFIG_FLV_DECODER && s->h263_flv) {\n\n        ret = ff_flv_decode_picture_header(s);\n\n    } else {\n\n        ret = ff_h263_decode_picture_header(s);\n\n    }\n\n\n\n    if (ret < 0 || ret==FRAME_SKIPPED) {\n\n        if (   s->width  != avctx->coded_width\n\n            || s->height != avctx->coded_height) {\n\n                av_log(s->avctx, AV_LOG_WARNING, \"Reverting picture dimensions change due to header decoding failure\\n\");\n\n                s->width = avctx->coded_width;\n\n                s->height= avctx->coded_height;\n\n        }\n\n    }\n\n    if(ret==FRAME_SKIPPED) return get_consumed_bytes(s, buf_size);\n\n\n\n    /* skip if the header was thrashed */\n\n    if (ret < 0){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"header damaged\\n\");\n\n        return ret;\n\n    }\n\n\n\n    avctx->has_b_frames= !s->low_delay;\n\n\n\n    if(s->xvid_build==-1 && s->divx_version==-1 && s->lavc_build==-1){\n\n        if(s->stream_codec_tag == AV_RL32(\"XVID\") ||\n\n           s->codec_tag == AV_RL32(\"XVID\") || s->codec_tag == AV_RL32(\"XVIX\") ||\n\n           s->codec_tag == AV_RL32(\"RMP4\") || s->codec_tag == AV_RL32(\"ZMP4\") ||\n\n           s->codec_tag == AV_RL32(\"SIPP\")\n\n           )\n\n            s->xvid_build= 0;\n\n#if 0\n\n        if(s->codec_tag == AV_RL32(\"DIVX\") && s->vo_type==0 && s->vol_control_parameters==1\n\n           && s->padding_bug_score > 0 && s->low_delay) // XVID with modified fourcc\n\n            s->xvid_build= 0;\n\n#endif\n\n    }\n\n\n\n    if(s->xvid_build==-1 && s->divx_version==-1 && s->lavc_build==-1){\n\n        if(s->codec_tag == AV_RL32(\"DIVX\") && s->vo_type==0 && s->vol_control_parameters==0)\n\n            s->divx_version= 400; //divx 4\n\n    }\n\n\n\n    if(s->xvid_build>=0 && s->divx_version>=0){\n\n        s->divx_version=\n\n        s->divx_build= -1;\n\n    }\n\n\n\n    if(s->workaround_bugs&FF_BUG_AUTODETECT){\n\n        if(s->codec_tag == AV_RL32(\"XVIX\"))\n\n            s->workaround_bugs|= FF_BUG_XVID_ILACE;\n\n\n\n        if(s->codec_tag == AV_RL32(\"UMP4\")){\n\n            s->workaround_bugs|= FF_BUG_UMP4;\n\n        }\n\n\n\n        if(s->divx_version>=500 && s->divx_build<1814){\n\n            s->workaround_bugs|= FF_BUG_QPEL_CHROMA;\n\n        }\n\n\n\n        if(s->divx_version>502 && s->divx_build<1814){\n\n            s->workaround_bugs|= FF_BUG_QPEL_CHROMA2;\n\n        }\n\n\n\n        if(s->xvid_build<=3U)\n\n            s->padding_bug_score= 256*256*256*64;\n\n\n\n        if(s->xvid_build<=1U)\n\n            s->workaround_bugs|= FF_BUG_QPEL_CHROMA;\n\n\n\n        if(s->xvid_build<=12U)\n\n            s->workaround_bugs|= FF_BUG_EDGE;\n\n\n\n        if(s->xvid_build<=32U)\n\n            s->workaround_bugs|= FF_BUG_DC_CLIP;\n\n\n\n#define SET_QPEL_FUNC(postfix1, postfix2) \\\n\n    s->dsp.put_ ## postfix1 = ff_put_ ## postfix2;\\\n\n    s->dsp.put_no_rnd_ ## postfix1 = ff_put_no_rnd_ ## postfix2;\\\n\n    s->dsp.avg_ ## postfix1 = ff_avg_ ## postfix2;\n\n\n\n        if(s->lavc_build<4653U)\n\n            s->workaround_bugs|= FF_BUG_STD_QPEL;\n\n\n\n        if(s->lavc_build<4655U)\n\n            s->workaround_bugs|= FF_BUG_DIRECT_BLOCKSIZE;\n\n\n\n        if(s->lavc_build<4670U){\n\n            s->workaround_bugs|= FF_BUG_EDGE;\n\n        }\n\n\n\n        if(s->lavc_build<=4712U)\n\n            s->workaround_bugs|= FF_BUG_DC_CLIP;\n\n\n\n        if(s->divx_version>=0)\n\n            s->workaround_bugs|= FF_BUG_DIRECT_BLOCKSIZE;\n\n        if(s->divx_version==501 && s->divx_build==20020416)\n\n            s->padding_bug_score= 256*256*256*64;\n\n\n\n        if(s->divx_version<500U){\n\n            s->workaround_bugs|= FF_BUG_EDGE;\n\n        }\n\n\n\n        if(s->divx_version>=0)\n\n            s->workaround_bugs|= FF_BUG_HPEL_CHROMA;\n\n#if 0\n\n        if(s->divx_version==500)\n\n            s->padding_bug_score= 256*256*256*64;\n\n\n\n        /* very ugly XVID padding bug detection FIXME/XXX solve this differently\n\n         * Let us hope this at least works.\n\n         */\n\n        if(   s->resync_marker==0 && s->data_partitioning==0 && s->divx_version==-1\n\n           && s->codec_id==AV_CODEC_ID_MPEG4 && s->vo_type==0)\n\n            s->workaround_bugs|= FF_BUG_NO_PADDING;\n\n\n\n        if(s->lavc_build<4609U) //FIXME not sure about the version num but a 4609 file seems ok\n\n            s->workaround_bugs|= FF_BUG_NO_PADDING;\n\n#endif\n\n    }\n\n\n\n    if(s->workaround_bugs& FF_BUG_STD_QPEL){\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][ 5], qpel16_mc11_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][ 7], qpel16_mc31_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][ 9], qpel16_mc12_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][11], qpel16_mc32_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][13], qpel16_mc13_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][15], qpel16_mc33_old_c)\n\n\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][ 5], qpel8_mc11_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][ 7], qpel8_mc31_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][ 9], qpel8_mc12_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][11], qpel8_mc32_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][13], qpel8_mc13_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][15], qpel8_mc33_old_c)\n\n    }\n\n\n\n    if(avctx->debug & FF_DEBUG_BUGS)\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"bugs: %X lavc_build:%d xvid_build:%d divx_version:%d divx_build:%d %s\\n\",\n\n               s->workaround_bugs, s->lavc_build, s->xvid_build, s->divx_version, s->divx_build,\n\n               s->divx_packed ? \"p\" : \"\");\n\n\n\n#if HAVE_MMX\n\n    if (s->codec_id == AV_CODEC_ID_MPEG4 && s->xvid_build>=0 && avctx->idct_algo == FF_IDCT_AUTO && (av_get_cpu_flags() & AV_CPU_FLAG_MMX)) {\n\n        avctx->idct_algo= FF_IDCT_XVIDMMX;\n\n        ff_dct_common_init(s);\n\n        goto retry;\n\n    }\n\n#endif\n\n\n\n        /* After H263 & mpeg4 header decode we have the height, width,*/\n\n        /* and other parameters. So then we could init the picture   */\n\n        /* FIXME: By the way H263 decoder is evolving it should have */\n\n        /* an H263EncContext                                         */\n\n\n\n    if (s->width  != avctx->coded_width  ||\n\n        s->height != avctx->coded_height ||\n\n        s->context_reinit) {\n\n        /* H.263 could change picture size any time */\n\n        s->context_reinit = 0;\n\n\n\n        avcodec_set_dimensions(avctx, s->width, s->height);\n\n\n\n        if ((ret = ff_MPV_common_frame_size_change(s)))\n\n            return ret;\n\n    }\n\n\n\n    if((s->codec_id==AV_CODEC_ID_H263 || s->codec_id==AV_CODEC_ID_H263P || s->codec_id == AV_CODEC_ID_H263I))\n\n        s->gob_index = ff_h263_get_gob_height(s);\n\n\n\n    // for skipping the frame\n\n    s->current_picture.f.pict_type = s->pict_type;\n\n    s->current_picture.f.key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n\n\n    /* skip B-frames if we don't have reference frames */\n\n    if (s->last_picture_ptr == NULL &&\n\n        (s->pict_type == AV_PICTURE_TYPE_B || s->droppable))\n\n        return get_consumed_bytes(s, buf_size);\n\n    if(   (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type==AV_PICTURE_TYPE_B)\n\n       || (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type!=AV_PICTURE_TYPE_I)\n\n       ||  avctx->skip_frame >= AVDISCARD_ALL)\n\n        return get_consumed_bytes(s, buf_size);\n\n\n\n    if(s->next_p_frame_damaged){\n\n        if(s->pict_type==AV_PICTURE_TYPE_B)\n\n            return get_consumed_bytes(s, buf_size);\n\n        else\n\n            s->next_p_frame_damaged=0;\n\n    }\n\n\n\n    if((!s->no_rounding) || s->pict_type==AV_PICTURE_TYPE_B){\n\n        s->me.qpel_put= s->dsp.put_qpel_pixels_tab;\n\n        s->me.qpel_avg= s->dsp.avg_qpel_pixels_tab;\n\n    }else{\n\n        s->me.qpel_put= s->dsp.put_no_rnd_qpel_pixels_tab;\n\n        s->me.qpel_avg= s->dsp.avg_qpel_pixels_tab;\n\n    }\n\n\n\n    if ((ret = ff_MPV_frame_start(s, avctx)) < 0)\n\n        return ret;\n\n\n\n    if (!s->divx_packed && !avctx->hwaccel)\n\n        ff_thread_finish_setup(avctx);\n\n\n\n    if (CONFIG_MPEG4_VDPAU_DECODER && (s->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU)) {\n\n        ff_vdpau_mpeg4_decode_picture(s, s->gb.buffer, s->gb.buffer_end - s->gb.buffer);\n\n        goto frame_end;\n\n    }\n\n\n\n    if (avctx->hwaccel) {\n\n        if ((ret = avctx->hwaccel->start_frame(avctx, s->gb.buffer, s->gb.buffer_end - s->gb.buffer)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    ff_mpeg_er_frame_start(s);\n\n\n\n    //the second part of the wmv2 header contains the MB skip bits which are stored in current_picture->mb_type\n\n    //which is not available before ff_MPV_frame_start()\n\n    if (CONFIG_WMV2_DECODER && s->msmpeg4_version==5){\n\n        ret = ff_wmv2_decode_secondary_picture_header(s);\n\n        if(ret<0) return ret;\n\n        if(ret==1) goto frame_end;\n\n    }\n\n\n\n    /* decode each macroblock */\n\n    s->mb_x=0;\n\n    s->mb_y=0;\n\n\n\n    ret = decode_slice(s);\n\n    while(s->mb_y<s->mb_height){\n\n        if(s->msmpeg4_version){\n\n            if(s->slice_height==0 || s->mb_x!=0 || (s->mb_y%s->slice_height)!=0 || get_bits_left(&s->gb)<0)\n\n                break;\n\n        }else{\n\n            int prev_x=s->mb_x, prev_y=s->mb_y;\n\n            if(ff_h263_resync(s)<0)\n\n                break;\n\n            if (prev_y * s->mb_width + prev_x < s->mb_y * s->mb_width + s->mb_x)\n\n                s->er.error_occurred = 1;\n\n        }\n\n\n\n        if(s->msmpeg4_version<4 && s->h263_pred)\n\n            ff_mpeg4_clean_buffers(s);\n\n\n\n        if (decode_slice(s) < 0) ret = AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->msmpeg4_version && s->msmpeg4_version<4 && s->pict_type==AV_PICTURE_TYPE_I)\n\n        if(!CONFIG_MSMPEG4_DECODER || ff_msmpeg4_decode_ext_header(s, buf_size) < 0){\n\n            s->er.error_status_table[s->mb_num - 1] = ER_MB_ERROR;\n\n        }\n\n\n\n    av_assert1(s->bitstream_buffer_size==0);\n\nframe_end:\n\n    ff_er_frame_end(&s->er);\n\n\n\n    if (avctx->hwaccel) {\n\n        if ((ret = avctx->hwaccel->end_frame(avctx)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    ff_MPV_frame_end(s);\n\n\n\n    /* divx 5.01+ bitstream reorder stuff */\n\n    /* Since this clobbers the input buffer and hwaccel codecs still need the\n\n     * data during hwaccel->end_frame we should not do this any earlier */\n\n    if(s->codec_id==AV_CODEC_ID_MPEG4 && s->divx_packed){\n\n        int current_pos= s->gb.buffer == s->bitstream_buffer ? 0 : (get_bits_count(&s->gb)>>3);\n\n        int startcode_found=0;\n\n\n\n        if(buf_size - current_pos > 7){\n\n            int i;\n\n            for(i=current_pos; i<buf_size-4; i++){\n\n                if(buf[i]==0 && buf[i+1]==0 && buf[i+2]==1 && buf[i+3]==0xB6){\n\n                    startcode_found=!(buf[i+4]&0x40);\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n\n\n        if(startcode_found){\n\n            av_fast_malloc(\n\n                &s->bitstream_buffer,\n\n                &s->allocated_bitstream_buffer_size,\n\n                buf_size - current_pos + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (!s->bitstream_buffer)\n\n                return AVERROR(ENOMEM);\n\n            memcpy(s->bitstream_buffer, buf + current_pos, buf_size - current_pos);\n\n            s->bitstream_buffer_size= buf_size - current_pos;\n\n        }\n\n    }\n\n\n\n    if (!s->divx_packed && avctx->hwaccel)\n\n        ff_thread_finish_setup(avctx);\n\n\n\n    av_assert1(s->current_picture.f.pict_type == s->current_picture_ptr->f.pict_type);\n\n    av_assert1(s->current_picture.f.pict_type == s->pict_type);\n\n    if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n\n        if ((ret = av_frame_ref(pict, &s->current_picture_ptr->f)) < 0)\n\n            return ret;\n\n        ff_print_debug_info(s, s->current_picture_ptr, pict);\n\n        ff_mpv_export_qp_table(s, pict, s->current_picture_ptr, FF_QSCALE_TYPE_MPEG1);\n\n    } else if (s->last_picture_ptr != NULL) {\n\n        if ((ret = av_frame_ref(pict, &s->last_picture_ptr->f)) < 0)\n\n            return ret;\n\n        ff_print_debug_info(s, s->last_picture_ptr, pict);\n\n        ff_mpv_export_qp_table(s, pict, s->last_picture_ptr, FF_QSCALE_TYPE_MPEG1);\n\n    }\n\n\n\n    if(s->last_picture_ptr || s->low_delay){\n\n        if (   pict->format == AV_PIX_FMT_YUV420P\n\n            && (s->codec_tag == AV_RL32(\"GEOV\") || s->codec_tag == AV_RL32(\"GEOX\"))) {\n\n            int x, y, p;\n\n            av_frame_make_writable(pict);\n\n            for (p=0; p<3; p++) {\n\n                int w = FF_CEIL_RSHIFT(pict-> width, !!p);\n\n                int h = FF_CEIL_RSHIFT(pict->height, !!p);\n\n                int linesize = pict->linesize[p];\n\n                for (y=0; y<(h>>1); y++)\n\n                    for (x=0; x<w; x++)\n\n                        FFSWAP(int,\n\n                               pict->data[p][x + y*linesize],\n\n                               pict->data[p][x + (h-1-y)*linesize]);\n\n            }\n\n        }\n\n        *got_frame = 1;\n\n    }\n\n\n\n    return (ret && (avctx->err_recognition & AV_EF_EXPLODE))?ret:get_consumed_bytes(s, buf_size);\n\n}\n", "idx": 24889}
{"project": "FFmpeg", "commit_id": "345cfd04d093d9fdec81ea3531e73b1f5c1b6a6c", "target": 1, "func": "void avcodec_free_context(AVCodecContext **pavctx)\n\n{\n\n    AVCodecContext *avctx = *pavctx;\n\n\n\n    if (!avctx)\n\n        return;\n\n\n\n    avcodec_close(avctx);\n\n\n\n    av_freep(&avctx->extradata);\n\n    av_freep(&avctx->subtitle_header);\n\n\n\n\n\n\n    av_freep(pavctx);\n\n}", "idx": 24890}
{"project": "FFmpeg", "commit_id": "2d0bcfb412a618e8130fbfea15df76eb0f7dac45", "target": 1, "func": "void ff_mpeg_flush(AVCodecContext *avctx){\n\n    int i;\n\n    MpegEncContext *s = avctx->priv_data;\n\n\n\n    if(s==NULL || s->picture==NULL)\n\n        return;\n\n\n\n    for(i=0; i<MAX_PICTURE_COUNT; i++){\n\n       if(s->picture[i].data[0] && (   s->picture[i].type == FF_BUFFER_TYPE_INTERNAL\n\n                                    || s->picture[i].type == FF_BUFFER_TYPE_USER))\n\n        avctx->release_buffer(avctx, (AVFrame*)&s->picture[i]);\n\n    }\n\n    s->current_picture_ptr = s->last_picture_ptr = s->next_picture_ptr = NULL;\n\n\n\n    s->mb_x= s->mb_y= 0;\n\n\n\n    s->parse_context.state= -1;\n\n    s->parse_context.frame_start_found= 0;\n\n    s->parse_context.overread= 0;\n\n    s->parse_context.overread_index= 0;\n\n    s->parse_context.index= 0;\n\n    s->parse_context.last_index= 0;\n\n    s->bitstream_buffer_size=0;\n\n\n}", "idx": 24891}
{"project": "FFmpeg", "commit_id": "41abc9da50ba7a7b68bbbf6622475ce7a3c72e3f", "target": 1, "func": "static int decode_frame_ilbm(AVCodecContext *avctx,\n\n                            void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    IffContext *s = avctx->priv_data;\n\n    const uint8_t *buf = avpkt->size >= 2 ? avpkt->data + AV_RB16(avpkt->data) : NULL;\n\n    const int buf_size = avpkt->size >= 2 ? avpkt->size - AV_RB16(avpkt->data) : 0;\n\n    const uint8_t *buf_end = buf+buf_size;\n\n    int y, plane, res;\n\n\n\n    if ((res = extract_header(avctx, avpkt)) < 0)\n\n        return res;\n\n\n\n    if (s->init) {\n\n        if ((res = avctx->reget_buffer(avctx, &s->frame)) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n            return res;\n\n        }\n\n    } else if ((res = avctx->get_buffer(avctx, &s->frame)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return res;\n\n    } else if (avctx->bits_per_coded_sample <= 8 && avctx->pix_fmt != PIX_FMT_GRAY8) {\n\n        if ((res = ff_cmap_read_palette(avctx, (uint32_t*)s->frame.data[1])) < 0)\n\n            return res;\n\n    }\n\n    s->init = 1;\n\n\n\n    if (avctx->codec_tag == MKTAG('A','C','B','M')) {\n\n        if (avctx->pix_fmt == PIX_FMT_PAL8 || avctx->pix_fmt == PIX_FMT_GRAY8) {\n\n            memset(s->frame.data[0], 0, avctx->height * s->frame.linesize[0]);\n\n            for (plane = 0; plane < s->bpp; plane++) {\n\n                for(y = 0; y < avctx->height && buf < buf_end; y++ ) {\n\n                    uint8_t *row = &s->frame.data[0][ y*s->frame.linesize[0] ];\n\n                    decodeplane8(row, buf, FFMIN(s->planesize, buf_end - buf), plane);\n\n                    buf += s->planesize;\n\n                }\n\n            }\n\n        } else if (s->ham) { // HAM to PIX_FMT_BGR32\n\n            memset(s->frame.data[0], 0, avctx->height * s->frame.linesize[0]);\n\n            for(y = 0; y < avctx->height; y++) {\n\n                uint8_t *row = &s->frame.data[0][y * s->frame.linesize[0]];\n\n                memset(s->ham_buf, 0, s->planesize * 8);\n\n                for (plane = 0; plane < s->bpp; plane++) {\n\n                    const uint8_t * start = buf + (plane * avctx->height + y) * s->planesize;\n\n                    if (start >= buf_end)\n\n                        break;\n\n                    decodeplane8(s->ham_buf, start, FFMIN(s->planesize, buf_end - start), plane);\n\n                }\n\n                decode_ham_plane32((uint32_t *) row, s->ham_buf, s->ham_palbuf, s->planesize);\n\n            }\n\n        }\n\n    } else if (avctx->codec_tag == MKTAG('D','E','E','P')) {\n\n        int raw_width = avctx->width * (av_get_bits_per_pixel(&av_pix_fmt_descriptors[avctx->pix_fmt]) >> 3);\n\n        int x;\n\n        for(y = 0; y < avctx->height && buf < buf_end; y++ ) {\n\n            uint8_t *row = &s->frame.data[0][y * s->frame.linesize[0]];\n\n            memcpy(row, buf, FFMIN(raw_width, buf_end - buf));\n\n            buf += raw_width;\n\n            if (avctx->pix_fmt == PIX_FMT_BGR32) {\n\n                for(x = 0; x < avctx->width; x++)\n\n                    row[4 * x + 3] = row[4 * x + 3] & 0xF0 | (row[4 * x + 3] >> 4);\n\n            }\n\n        }\n\n    } else if (avctx->codec_tag == MKTAG('I','L','B','M')) { // interleaved\n\n        if (avctx->pix_fmt == PIX_FMT_PAL8 || avctx->pix_fmt == PIX_FMT_GRAY8) {\n\n            for(y = 0; y < avctx->height; y++ ) {\n\n                uint8_t *row = &s->frame.data[0][ y*s->frame.linesize[0] ];\n\n                memset(row, 0, avctx->width);\n\n                for (plane = 0; plane < s->bpp && buf < buf_end; plane++) {\n\n                    decodeplane8(row, buf, FFMIN(s->planesize, buf_end - buf), plane);\n\n                    buf += s->planesize;\n\n                }\n\n            }\n\n        } else if (s->ham) { // HAM to PIX_FMT_BGR32\n\n            for (y = 0; y < avctx->height; y++) {\n\n                uint8_t *row = &s->frame.data[0][ y*s->frame.linesize[0] ];\n\n                memset(s->ham_buf, 0, s->planesize * 8);\n\n                for (plane = 0; plane < s->bpp && buf < buf_end; plane++) {\n\n                    decodeplane8(s->ham_buf, buf, FFMIN(s->planesize, buf_end - buf), plane);\n\n                    buf += s->planesize;\n\n                }\n\n                decode_ham_plane32((uint32_t *) row, s->ham_buf, s->ham_palbuf, s->planesize);\n\n            }\n\n        } else { // PIX_FMT_BGR32\n\n            for(y = 0; y < avctx->height; y++ ) {\n\n                uint8_t *row = &s->frame.data[0][y*s->frame.linesize[0]];\n\n                memset(row, 0, avctx->width << 2);\n\n                for (plane = 0; plane < s->bpp && buf < buf_end; plane++) {\n\n                    decodeplane32((uint32_t *) row, buf, FFMIN(s->planesize, buf_end - buf), plane);\n\n                    buf += s->planesize;\n\n                }\n\n            }\n\n        }\n\n    } else if (avctx->codec_tag == MKTAG('P','B','M',' ')) { // IFF-PBM\n\n        if (avctx->pix_fmt == PIX_FMT_PAL8 || avctx->pix_fmt == PIX_FMT_GRAY8) {\n\n            for(y = 0; y < avctx->height; y++ ) {\n\n                uint8_t *row = &s->frame.data[0][y * s->frame.linesize[0]];\n\n                memcpy(row, buf, FFMIN(avctx->width, buf_end - buf));\n\n                buf += avctx->width + (avctx->width % 2); // padding if odd\n\n            }\n\n        } else if (s->ham) { // IFF-PBM: HAM to PIX_FMT_BGR32\n\n            for (y = 0; y < avctx->height; y++) {\n\n                uint8_t *row = &s->frame.data[0][ y*s->frame.linesize[0] ];\n\n                memcpy(s->ham_buf, buf, FFMIN(avctx->width, buf_end - buf));\n\n                buf += avctx->width + (avctx->width & 1); // padding if odd\n\n                decode_ham_plane32((uint32_t *) row, s->ham_buf, s->ham_palbuf, s->planesize);\n\n            }\n\n        } else {\n\n            av_log_ask_for_sample(avctx, \"unsupported bpp\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame*)data = s->frame;\n\n    return buf_size;\n\n}\n", "idx": 24896}
{"project": "FFmpeg", "commit_id": "8cd80b5fcbfaefdb92faa8f3ed0b7f5651f38481", "target": 1, "func": "static int jacosub_read_header(AVFormatContext *s)\n\n{\n\n    AVBPrint header;\n\n    AVIOContext *pb = s->pb;\n\n    char line[JSS_MAX_LINESIZE];\n\n    JACOsubContext *jacosub = s->priv_data;\n\n    int shift_set = 0; // only the first shift matters\n\n    int merge_line = 0;\n\n    int i, ret;\n\n\n\n    AVStream *st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n    avpriv_set_pts_info(st, 64, 1, 100);\n\n    st->codec->codec_type = AVMEDIA_TYPE_SUBTITLE;\n\n    st->codec->codec_id   = AV_CODEC_ID_JACOSUB;\n\n\n\n    jacosub->timeres = 30;\n\n\n\n    av_bprint_init(&header, 1024+FF_INPUT_BUFFER_PADDING_SIZE, 4096);\n\n\n\n    while (!avio_feof(pb)) {\n\n        int cmd_len;\n\n        const char *p = line;\n\n        int64_t pos = avio_tell(pb);\n\n        int len = ff_get_line(pb, line, sizeof(line));\n\n\n\n        p = jss_skip_whitespace(p);\n\n\n\n        /* queue timed line */\n\n        if (merge_line || timed_line(p)) {\n\n            AVPacket *sub;\n\n\n\n            sub = ff_subtitles_queue_insert(&jacosub->q, line, len, merge_line);\n\n            if (!sub)\n\n                return AVERROR(ENOMEM);\n\n            sub->pos = pos;\n\n            merge_line = len > 1 && !strcmp(&line[len - 2], \"\\\\\\n\");\n\n            continue;\n\n        }\n\n\n\n        /* skip all non-compiler commands and focus on the command */\n\n        if (*p != '#')\n\n            continue;\n\n        p++;\n\n        i = get_jss_cmd(p[0]);\n\n        if (i == -1)\n\n            continue;\n\n\n\n        /* trim command + spaces */\n\n        cmd_len = strlen(cmds[i]);\n\n        if (av_strncasecmp(p, cmds[i], cmd_len) == 0)\n\n            p += cmd_len;\n\n        else\n\n            p++;\n\n        p = jss_skip_whitespace(p);\n\n\n\n        /* handle commands which affect the whole script */\n\n        switch (cmds[i][0]) {\n\n        case 'S': // SHIFT command affect the whole script...\n\n            if (!shift_set) {\n\n                jacosub->shift = get_shift(jacosub->timeres, p);\n\n                shift_set = 1;\n\n            }\n\n            av_bprintf(&header, \"#S %s\", p);\n\n            break;\n\n        case 'T': // ...but must be placed after TIMERES\n\n            jacosub->timeres = strtol(p, NULL, 10);\n\n            if (!jacosub->timeres)\n\n                jacosub->timeres = 30;\n\n            else\n\n                av_bprintf(&header, \"#T %s\", p);\n\n            break;\n\n        }\n\n    }\n\n\n\n    /* general/essential directives in the extradata */\n\n    ret = avpriv_bprint_to_extradata(st->codec, &header);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    /* SHIFT and TIMERES affect the whole script so packet timing can only be\n\n     * done in a second pass */\n\n    for (i = 0; i < jacosub->q.nb_subs; i++) {\n\n        AVPacket *sub = &jacosub->q.subs[i];\n\n        read_ts(jacosub, sub->data, &sub->pts, &sub->duration);\n\n    }\n\n    ff_subtitles_queue_finalize(&jacosub->q);\n\n\n\n    return 0;\n\n}\n", "idx": 24900}
{"project": "FFmpeg", "commit_id": "224944895efe6ac23e3b8f9d35abfee9f5c6c440", "target": 0, "func": "static int get_packet_payload_size(AVFormatContext *ctx, int stream_index,\n\n                                   int64_t pts, int64_t dts)\n\n{\n\n    MpegMuxContext *s = ctx->priv_data;\n\n    int buf_index;\n\n    StreamInfo *stream;\n\n\n\n    stream = ctx->streams[stream_index]->priv_data;\n\n\n\n    buf_index = 0;\n\n    if (((s->packet_number % s->pack_header_freq) == 0)) {\n\n        /* pack header size */\n\n        if (s->is_mpeg2) \n\n            buf_index += 14;\n\n        else\n\n            buf_index += 12;\n\n        \n\n        if (s->is_vcd) {\n\n            /* there is exactly one system header for each stream in a VCD MPEG,\n\n               One in the very first video packet and one in the very first\n\n               audio packet (see VCD standard p. IV-7 and IV-8).*/\n\n            \n\n            if (stream->packet_number==0)\n\n                /* The system headers refer only to the stream they occur in,\n\n                   so they have a constant size.*/\n\n                buf_index += 15;\n\n\n\n        } else {            \n\n            if ((s->packet_number % s->system_header_freq) == 0)\n\n                buf_index += s->system_header_size;\n\n        }\n\n    }\n\n\n\n    if (s->is_vcd && stream->packet_number==0)\n\n        /* the first pack of each stream contains only the pack header,\n\n           the system header and some padding (see VCD standard p. IV-6) \n\n           Add the padding size, so that the actual payload becomes 0.*/\n\n        buf_index += s->packet_size - buf_index;\n\n    else {\n\n        /* packet header size */\n\n        buf_index += 6;\n\n        if (s->is_mpeg2)\n\n            buf_index += 3;\n\n        if (pts != AV_NOPTS_VALUE) {\n\n            if (dts != pts)\n\n                buf_index += 5 + 5;\n\n            else\n\n                buf_index += 5;\n\n\n\n        } else {\n\n            if (!s->is_mpeg2)\n\n                buf_index++;\n\n        }\n\n    \n\n        if (stream->id < 0xc0) {\n\n            /* AC3/LPCM private data header */\n\n            buf_index += 4;\n\n            if (stream->id >= 0xa0) {\n\n                int n;\n\n                buf_index += 3;\n\n                /* NOTE: we round the payload size to an integer number of\n\n                   LPCM samples */\n\n                n = (s->packet_size - buf_index) % stream->lpcm_align;\n\n                if (n)\n\n                    buf_index += (stream->lpcm_align - n);\n\n            }\n\n        }\n\n\n\n        if (s->is_vcd && stream->id == AUDIO_ID)\n\n            /* The VCD standard demands that 20 zero bytes follow\n\n               each audio packet (see standard p. IV-8).*/\n\n            buf_index+=20;\n\n    }\n\n    return s->packet_size - buf_index; \n\n}\n", "idx": 24901}
{"project": "FFmpeg", "commit_id": "b348c852aa8312d361123df0fa20e16feff7c2f1", "target": 1, "func": "static int flic_decode_frame_15_16BPP(AVCodecContext *avctx,\n\n                                      void *data, int *data_size,\n\n                                      const uint8_t *buf, int buf_size)\n\n{\n\n    /* Note, the only difference between the 15Bpp and 16Bpp */\n\n    /* Format is the pixel format, the packets are processed the same. */\n\n    FlicDecodeContext *s = avctx->priv_data;\n\n\n\n    int stream_ptr = 0;\n\n    int pixel_ptr;\n\n    unsigned char palette_idx1;\n\n\n\n    unsigned int frame_size;\n\n    int num_chunks;\n\n\n\n    unsigned int chunk_size;\n\n    int chunk_type;\n\n\n\n    int i, j;\n\n\n\n    int lines;\n\n    int compressed_lines;\n\n    signed short line_packets;\n\n    int y_ptr;\n\n    int byte_run;\n\n    int pixel_skip;\n\n    int pixel_countdown;\n\n    unsigned char *pixels;\n\n    int pixel;\n\n    unsigned int pixel_limit;\n\n\n\n    s->frame.reference = 1;\n\n    s->frame.buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE;\n\n    if (avctx->reget_buffer(avctx, &s->frame) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    pixels = s->frame.data[0];\n\n    pixel_limit = s->avctx->height * s->frame.linesize[0];\n\n\n\n    frame_size = AV_RL32(&buf[stream_ptr]);\n\n    stream_ptr += 6;  /* skip the magic number */\n\n    num_chunks = AV_RL16(&buf[stream_ptr]);\n\n    stream_ptr += 10;  /* skip padding */\n\n\n\n    frame_size -= 16;\n\n\n\n    /* iterate through the chunks */\n\n    while ((frame_size > 0) && (num_chunks > 0)) {\n\n        chunk_size = AV_RL32(&buf[stream_ptr]);\n\n        stream_ptr += 4;\n\n        chunk_type = AV_RL16(&buf[stream_ptr]);\n\n        stream_ptr += 2;\n\n\n\n        switch (chunk_type) {\n\n        case FLI_256_COLOR:\n\n        case FLI_COLOR:\n\n            /* For some reason, it seems that non-palettized flics do\n\n             * include one of these chunks in their first frame.\n\n             * Why I do not know, it seems rather extraneous. */\n\n/*            av_log(avctx, AV_LOG_ERROR, \"Unexpected Palette chunk %d in non-paletised FLC\\n\",chunk_type);*/\n\n            stream_ptr = stream_ptr + chunk_size - 6;\n\n            break;\n\n\n\n        case FLI_DELTA:\n\n        case FLI_DTA_LC:\n\n            y_ptr = 0;\n\n            compressed_lines = AV_RL16(&buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            while (compressed_lines > 0) {\n\n                line_packets = AV_RL16(&buf[stream_ptr]);\n\n                stream_ptr += 2;\n\n                if (line_packets < 0) {\n\n                    line_packets = -line_packets;\n\n                    y_ptr += line_packets * s->frame.linesize[0];\n\n                } else {\n\n                    compressed_lines--;\n\n                    pixel_ptr = y_ptr;\n\n                    CHECK_PIXEL_PTR(0);\n\n                    pixel_countdown = s->avctx->width;\n\n                    for (i = 0; i < line_packets; i++) {\n\n                        /* account for the skip bytes */\n\n                        pixel_skip = buf[stream_ptr++];\n\n                        pixel_ptr += (pixel_skip*2); /* Pixel is 2 bytes wide */\n\n                        pixel_countdown -= pixel_skip;\n\n                        byte_run = (signed char)(buf[stream_ptr++]);\n\n                        if (byte_run < 0) {\n\n                            byte_run = -byte_run;\n\n                            pixel    = AV_RL16(&buf[stream_ptr]);\n\n                            stream_ptr += 2;\n\n                            CHECK_PIXEL_PTR(2 * byte_run);\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown -= 2) {\n\n                                *((signed short*)(&pixels[pixel_ptr])) = pixel;\n\n                                pixel_ptr += 2;\n\n                            }\n\n                        } else {\n\n                            CHECK_PIXEL_PTR(2 * byte_run);\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown--) {\n\n                                *((signed short*)(&pixels[pixel_ptr])) = AV_RL16(&buf[stream_ptr]);\n\n                                stream_ptr += 2;\n\n                                pixel_ptr += 2;\n\n                            }\n\n                        }\n\n                    }\n\n\n\n                    y_ptr += s->frame.linesize[0];\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_LC:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unexpected FLI_LC chunk in non-paletised FLC\\n\");\n\n            stream_ptr = stream_ptr + chunk_size - 6;\n\n            break;\n\n\n\n        case FLI_BLACK:\n\n            /* set the whole frame to 0x0000 which is black in both 15Bpp and 16Bpp modes. */\n\n            memset(pixels, 0x0000,\n\n                   s->frame.linesize[0] * s->avctx->height);\n\n            break;\n\n\n\n        case FLI_BRUN:\n\n            y_ptr = 0;\n\n            for (lines = 0; lines < s->avctx->height; lines++) {\n\n                pixel_ptr = y_ptr;\n\n                /* disregard the line packets; instead, iterate through all\n\n                 * pixels on a row */\n\n                stream_ptr++;\n\n                pixel_countdown = (s->avctx->width * 2);\n\n\n\n                while (pixel_countdown > 0) {\n\n                    byte_run = (signed char)(buf[stream_ptr++]);\n\n                    if (byte_run > 0) {\n\n                        palette_idx1 = buf[stream_ptr++];\n\n                        CHECK_PIXEL_PTR(byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            pixels[pixel_ptr++] = palette_idx1;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d) (linea%d)\\n\",\n\n                                       pixel_countdown, lines);\n\n                        }\n\n                    } else {  /* copy bytes if byte_run < 0 */\n\n                        byte_run = -byte_run;\n\n                        CHECK_PIXEL_PTR(byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            palette_idx1 = buf[stream_ptr++];\n\n                            pixels[pixel_ptr++] = palette_idx1;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d) at line %d\\n\",\n\n                                       pixel_countdown, lines);\n\n                        }\n\n                    }\n\n                }\n\n\n\n                /* Now FLX is strange, in that it is \"byte\" as opposed to \"pixel\" run length compressed.\n\n                 * This does not give us any good oportunity to perform word endian conversion\n\n                 * during decompression. So if it is required (i.e., this is not a LE target, we do\n\n                 * a second pass over the line here, swapping the bytes.\n\n                 */\n\n#if HAVE_BIGENDIAN\n\n                pixel_ptr = y_ptr;\n\n                pixel_countdown = s->avctx->width;\n\n                while (pixel_countdown > 0) {\n\n                    *((signed short*)(&pixels[pixel_ptr])) = AV_RL16(&buf[pixel_ptr]);\n\n                    pixel_ptr += 2;\n\n                }\n\n#endif\n\n                y_ptr += s->frame.linesize[0];\n\n            }\n\n            break;\n\n\n\n        case FLI_DTA_BRUN:\n\n            y_ptr = 0;\n\n            for (lines = 0; lines < s->avctx->height; lines++) {\n\n                pixel_ptr = y_ptr;\n\n                /* disregard the line packets; instead, iterate through all\n\n                 * pixels on a row */\n\n                stream_ptr++;\n\n                pixel_countdown = s->avctx->width; /* Width is in pixels, not bytes */\n\n\n\n                while (pixel_countdown > 0) {\n\n                    byte_run = (signed char)(buf[stream_ptr++]);\n\n                    if (byte_run > 0) {\n\n                        pixel    = AV_RL16(&buf[stream_ptr]);\n\n                        stream_ptr += 2;\n\n                        CHECK_PIXEL_PTR(2 * byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            *((signed short*)(&pixels[pixel_ptr])) = pixel;\n\n                            pixel_ptr += 2;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d)\\n\",\n\n                                       pixel_countdown);\n\n                        }\n\n                    } else {  /* copy pixels if byte_run < 0 */\n\n                        byte_run = -byte_run;\n\n                        CHECK_PIXEL_PTR(2 * byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            *((signed short*)(&pixels[pixel_ptr])) = AV_RL16(&buf[stream_ptr]);\n\n                            stream_ptr += 2;\n\n                            pixel_ptr  += 2;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d)\\n\",\n\n                                       pixel_countdown);\n\n                        }\n\n                    }\n\n                }\n\n\n\n                y_ptr += s->frame.linesize[0];\n\n            }\n\n            break;\n\n\n\n        case FLI_COPY:\n\n        case FLI_DTA_COPY:\n\n            /* copy the chunk (uncompressed frame) */\n\n            if (chunk_size - 6 > (unsigned int)(s->avctx->width * s->avctx->height)*2) {\n\n                av_log(avctx, AV_LOG_ERROR, \"In chunk FLI_COPY : source data (%d bytes) \" \\\n\n                       \"bigger than image, skipping chunk\\n\", chunk_size - 6);\n\n                stream_ptr += chunk_size - 6;\n\n            } else {\n\n\n\n                for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;\n\n                     y_ptr += s->frame.linesize[0]) {\n\n\n\n                    pixel_countdown = s->avctx->width;\n\n                    pixel_ptr = 0;\n\n                    while (pixel_countdown > 0) {\n\n                      *((signed short*)(&pixels[y_ptr + pixel_ptr])) = AV_RL16(&buf[stream_ptr+pixel_ptr]);\n\n                      pixel_ptr += 2;\n\n                      pixel_countdown--;\n\n                    }\n\n                    stream_ptr += s->avctx->width*2;\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_MINI:\n\n            /* some sort of a thumbnail? disregard this chunk... */\n\n            stream_ptr += chunk_size - 6;\n\n            break;\n\n\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unrecognized chunk type: %d\\n\", chunk_type);\n\n            break;\n\n        }\n\n\n\n        frame_size -= chunk_size;\n\n        num_chunks--;\n\n    }\n\n\n\n    /* by the end of the chunk, the stream ptr should equal the frame\n\n     * size (minus 1, possibly); if it doesn't, issue a warning */\n\n    if ((stream_ptr != buf_size) && (stream_ptr != buf_size - 1))\n\n        av_log(avctx, AV_LOG_ERROR, \"Processed FLI chunk where chunk size = %d \" \\\n\n               \"and final chunk ptr = %d\\n\", buf_size, stream_ptr);\n\n\n\n\n\n    *data_size=sizeof(AVFrame);\n\n    *(AVFrame*)data = s->frame;\n\n\n\n    return buf_size;\n\n}\n", "idx": 24903}
{"project": "FFmpeg", "commit_id": "9ed388f5985992a0a6a43fdc0b1732962b6b5619", "target": 1, "func": "ogm_header(AVFormatContext *s, int idx)\n\n{\n\n    struct ogg *ogg = s->priv_data;\n\n    struct ogg_stream *os = ogg->streams + idx;\n\n    AVStream *st = s->streams[idx];\n\n    const uint8_t *p = os->buf + os->pstart;\n\n    uint64_t time_unit;\n\n    uint64_t spu;\n\n    uint32_t size;\n\n\n\n    if(!(*p & 1))\n\n        return 0;\n\n\n\n    if(*p == 1) {\n\n        p++;\n\n\n\n        if(*p == 'v'){\n\n            int tag;\n\n            st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n            p += 8;\n\n            tag = bytestream_get_le32(&p);\n\n            st->codec->codec_id = ff_codec_get_id(ff_codec_bmp_tags, tag);\n\n            st->codec->codec_tag = tag;\n\n        } else if (*p == 't') {\n\n            st->codec->codec_type = AVMEDIA_TYPE_SUBTITLE;\n\n            st->codec->codec_id = CODEC_ID_TEXT;\n\n            p += 12;\n\n        } else {\n\n            uint8_t acid[5];\n\n            int cid;\n\n            st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n            p += 8;\n\n            bytestream_get_buffer(&p, acid, 4);\n\n            acid[4] = 0;\n\n            cid = strtol(acid, NULL, 16);\n\n            st->codec->codec_id = ff_codec_get_id(ff_codec_wav_tags, cid);\n\n            // our parser completely breaks AAC in Ogg\n\n            if (st->codec->codec_id != CODEC_ID_AAC)\n\n                st->need_parsing = AVSTREAM_PARSE_FULL;\n\n        }\n\n\n\n        size        = bytestream_get_le32(&p);\n\n        size        = FFMIN(size, os->psize);\n\n        time_unit   = bytestream_get_le64(&p);\n\n        spu         = bytestream_get_le64(&p);\n\n        p += 4;                     /* default_len */\n\n        p += 8;                     /* buffersize + bits_per_sample */\n\n\n\n        if(st->codec->codec_type == AVMEDIA_TYPE_VIDEO){\n\n            st->codec->width = bytestream_get_le32(&p);\n\n            st->codec->height = bytestream_get_le32(&p);\n\n            avpriv_set_pts_info(st, 64, time_unit, spu * 10000000);\n\n        } else {\n\n            st->codec->channels = bytestream_get_le16(&p);\n\n            p += 2;                 /* block_align */\n\n            st->codec->bit_rate = bytestream_get_le32(&p) * 8;\n\n            st->codec->sample_rate = spu * 10000000 / time_unit;\n\n            avpriv_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n            if (size >= 56 && st->codec->codec_id == CODEC_ID_AAC) {\n\n                p += 4;\n\n                size -= 4;\n\n            }\n\n            if (size > 52) {\n\n                av_assert0(FF_INPUT_BUFFER_PADDING_SIZE <= 52);\n\n                size -= 52;\n\n                st->codec->extradata_size = size;\n\n                st->codec->extradata = av_malloc(size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                bytestream_get_buffer(&p, st->codec->extradata, size);\n\n            }\n\n        }\n\n    } else if (*p == 3) {\n\n        if (os->psize > 8)\n\n            ff_vorbis_comment(s, &st->metadata, p+7, os->psize-8);\n\n    }\n\n\n\n    return 1;\n\n}\n", "idx": 24904}
{"project": "FFmpeg", "commit_id": "99978320c0dcf16c34bdba19ff8f0cd61628cc41", "target": 1, "func": "static int ape_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    AVFrame *frame     = data;\n\n    const uint8_t *buf = avpkt->data;\n\n    APEContext *s = avctx->priv_data;\n\n    uint8_t *sample8;\n\n    int16_t *sample16;\n\n    int32_t *sample24;\n\n    int i, ch, ret;\n\n    int blockstodecode;\n\n\n\n    /* this should never be negative, but bad things will happen if it is, so\n\n       check it just to make sure. */\n\n    av_assert0(s->samples >= 0);\n\n\n\n    if(!s->samples){\n\n        uint32_t nblocks, offset;\n\n        int buf_size;\n\n\n\n        if (!avpkt->size) {\n\n            *got_frame_ptr = 0;\n\n            return 0;\n\n        }\n\n        if (avpkt->size < 8) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        buf_size = avpkt->size & ~3;\n\n        if (buf_size != avpkt->size) {\n\n            av_log(avctx, AV_LOG_WARNING, \"packet size is not a multiple of 4. \"\n\n                   \"extra bytes at the end will be skipped.\\n\");\n\n        }\n\n        if (s->fileversion < 3950) // previous versions overread two bytes\n\n            buf_size += 2;\n\n        av_fast_malloc(&s->data, &s->data_size, buf_size);\n\n        if (!s->data)\n\n            return AVERROR(ENOMEM);\n\n        s->dsp.bswap_buf((uint32_t*)s->data, (const uint32_t*)buf, buf_size >> 2);\n\n        memset(s->data + (buf_size & ~3), 0, buf_size & 3);\n\n        s->ptr = s->data;\n\n        s->data_end = s->data + buf_size;\n\n\n\n        nblocks = bytestream_get_be32(&s->ptr);\n\n        offset  = bytestream_get_be32(&s->ptr);\n\n        if (s->fileversion >= 3900) {\n\n            if (offset > 3) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Incorrect offset passed\\n\");\n\n                s->data = NULL;\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if (s->data_end - s->ptr < offset) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            s->ptr += offset;\n\n        } else {\n\n            if ((ret = init_get_bits8(&s->gb, s->ptr, s->data_end - s->ptr)) < 0)\n\n                return ret;\n\n            if (s->fileversion > 3800)\n\n                skip_bits_long(&s->gb, offset * 8);\n\n            else\n\n                skip_bits_long(&s->gb, offset);\n\n        }\n\n\n\n        if (!nblocks || nblocks > INT_MAX) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Invalid sample count: %u.\\n\", nblocks);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        s->samples = nblocks;\n\n\n\n        /* Initialize the frame decoder */\n\n        if (init_frame_decoder(s) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Error reading frame header\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    if (!s->data) {\n\n        *got_frame_ptr = 0;\n\n        return avpkt->size;\n\n    }\n\n\n\n    blockstodecode = FFMIN(s->blocks_per_loop, s->samples);\n\n    // for old files coefficients were not interleaved,\n\n    // so we need to decode all of them at once\n\n    if (s->fileversion < 3930)\n\n        blockstodecode = s->samples;\n\n\n\n    /* reallocate decoded sample buffer if needed */\n\n    av_fast_malloc(&s->decoded_buffer, &s->decoded_size,\n\n                   2 * FFALIGN(blockstodecode, 8) * sizeof(*s->decoded_buffer));\n\n    if (!s->decoded_buffer)\n\n        return AVERROR(ENOMEM);\n\n    memset(s->decoded_buffer, 0, s->decoded_size);\n\n    s->decoded[0] = s->decoded_buffer;\n\n    s->decoded[1] = s->decoded_buffer + FFALIGN(blockstodecode, 8);\n\n\n\n    /* get output buffer */\n\n    frame->nb_samples = blockstodecode;\n\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n\n        return ret;\n\n\n\n    s->error=0;\n\n\n\n    if ((s->channels == 1) || (s->frameflags & APE_FRAMECODE_PSEUDO_STEREO))\n\n        ape_unpack_mono(s, blockstodecode);\n\n    else\n\n        ape_unpack_stereo(s, blockstodecode);\n\n    emms_c();\n\n\n\n    if (s->error) {\n\n        s->samples=0;\n\n        av_log(avctx, AV_LOG_ERROR, \"Error decoding frame\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    switch (s->bps) {\n\n    case 8:\n\n        for (ch = 0; ch < s->channels; ch++) {\n\n            sample8 = (uint8_t *)frame->data[ch];\n\n            for (i = 0; i < blockstodecode; i++)\n\n                *sample8++ = (s->decoded[ch][i] + 0x80) & 0xff;\n\n        }\n\n        break;\n\n    case 16:\n\n        for (ch = 0; ch < s->channels; ch++) {\n\n            sample16 = (int16_t *)frame->data[ch];\n\n            for (i = 0; i < blockstodecode; i++)\n\n                *sample16++ = s->decoded[ch][i];\n\n        }\n\n        break;\n\n    case 24:\n\n        for (ch = 0; ch < s->channels; ch++) {\n\n            sample24 = (int32_t *)frame->data[ch];\n\n            for (i = 0; i < blockstodecode; i++)\n\n                *sample24++ = s->decoded[ch][i] << 8;\n\n        }\n\n        break;\n\n    }\n\n\n\n    s->samples -= blockstodecode;\n\n\n\n    *got_frame_ptr = 1;\n\n\n\n    return !s->samples ? avpkt->size : 0;\n\n}\n", "idx": 24905}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(rgb32tobgr16)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n    const uint8_t *s = src;\n\n    const uint8_t *end;\n\n#if COMPILE_TEMPLATE_MMX\n\n    const uint8_t *mm_end;\n\n#endif\n\n    uint16_t *d = (uint16_t *)dst;\n\n    end = s + src_size;\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*src):\"memory\");\n\n    __asm__ volatile(\n\n        \"movq          %0, %%mm7    \\n\\t\"\n\n        \"movq          %1, %%mm6    \\n\\t\"\n\n        ::\"m\"(red_16mask),\"m\"(green_16mask));\n\n    mm_end = end - 15;\n\n    while (s < mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"    32%1           \\n\\t\"\n\n            \"movd          %1, %%mm0    \\n\\t\"\n\n            \"movd         4%1, %%mm3    \\n\\t\"\n\n            \"punpckldq    8%1, %%mm0    \\n\\t\"\n\n            \"punpckldq   12%1, %%mm3    \\n\\t\"\n\n            \"movq       %%mm0, %%mm1    \\n\\t\"\n\n            \"movq       %%mm0, %%mm2    \\n\\t\"\n\n            \"movq       %%mm3, %%mm4    \\n\\t\"\n\n            \"movq       %%mm3, %%mm5    \\n\\t\"\n\n            \"psllq         $8, %%mm0    \\n\\t\"\n\n            \"psllq         $8, %%mm3    \\n\\t\"\n\n            \"pand       %%mm7, %%mm0    \\n\\t\"\n\n            \"pand       %%mm7, %%mm3    \\n\\t\"\n\n            \"psrlq         $5, %%mm1    \\n\\t\"\n\n            \"psrlq         $5, %%mm4    \\n\\t\"\n\n            \"pand       %%mm6, %%mm1    \\n\\t\"\n\n            \"pand       %%mm6, %%mm4    \\n\\t\"\n\n            \"psrlq        $19, %%mm2    \\n\\t\"\n\n            \"psrlq        $19, %%mm5    \\n\\t\"\n\n            \"pand          %2, %%mm2    \\n\\t\"\n\n            \"pand          %2, %%mm5    \\n\\t\"\n\n            \"por        %%mm1, %%mm0    \\n\\t\"\n\n            \"por        %%mm4, %%mm3    \\n\\t\"\n\n            \"por        %%mm2, %%mm0    \\n\\t\"\n\n            \"por        %%mm5, %%mm3    \\n\\t\"\n\n            \"psllq        $16, %%mm3    \\n\\t\"\n\n            \"por        %%mm3, %%mm0    \\n\\t\"\n\n            MOVNTQ\"     %%mm0, %0       \\n\\t\"\n\n            :\"=m\"(*d):\"m\"(*s),\"m\"(blue_16mask):\"memory\");\n\n        d += 4;\n\n        s += 16;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n#endif\n\n    while (s < end) {\n\n        register int rgb = *(const uint32_t*)s; s += 4;\n\n        *d++ = ((rgb&0xF8)<<8) + ((rgb&0xFC00)>>5) + ((rgb&0xF80000)>>19);\n\n    }\n\n}\n", "idx": 24909}
{"project": "FFmpeg", "commit_id": "8e37a1deb30c51e2e2ef5726f550b698303bc029", "target": 0, "func": "static int truemotion1_decode_header(TrueMotion1Context *s)\n\n{\n\n    int i;\n\n    int width_shift = 0;\n\n    int new_pix_fmt;\n\n    struct frame_header header;\n\n    uint8_t header_buffer[128];  /* logical maximum size of the header */\n\n    const uint8_t *sel_vector_table;\n\n\n\n    header.header_size = ((s->buf[0] >> 5) | (s->buf[0] << 3)) & 0x7f;\n\n    if (s->buf[0] < 0x10)\n\n    {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"invalid header size (%d)\\n\", s->buf[0]);\n\n        return -1;\n\n    }\n\n\n\n    /* unscramble the header bytes with a XOR operation */\n\n    memset(header_buffer, 0, 128);\n\n    for (i = 1; i < header.header_size; i++)\n\n        header_buffer[i - 1] = s->buf[i] ^ s->buf[i + 1];\n\n\n\n    header.compression = header_buffer[0];\n\n    header.deltaset = header_buffer[1];\n\n    header.vectable = header_buffer[2];\n\n    header.ysize = AV_RL16(&header_buffer[3]);\n\n    header.xsize = AV_RL16(&header_buffer[5]);\n\n    header.checksum = AV_RL16(&header_buffer[7]);\n\n    header.version = header_buffer[9];\n\n    header.header_type = header_buffer[10];\n\n    header.flags = header_buffer[11];\n\n    header.control = header_buffer[12];\n\n\n\n    /* Version 2 */\n\n    if (header.version >= 2)\n\n    {\n\n        if (header.header_type > 3)\n\n        {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"invalid header type (%d)\\n\", header.header_type);\n\n            return -1;\n\n        } else if ((header.header_type == 2) || (header.header_type == 3)) {\n\n            s->flags = header.flags;\n\n            if (!(s->flags & FLAG_INTERFRAME))\n\n                s->flags |= FLAG_KEYFRAME;\n\n        } else\n\n            s->flags = FLAG_KEYFRAME;\n\n    } else /* Version 1 */\n\n        s->flags = FLAG_KEYFRAME;\n\n\n\n    if (s->flags & FLAG_SPRITE) {\n\n        av_log(s->avctx, AV_LOG_INFO, \"SPRITE frame found, please report the sample to the developers\\n\");\n\n        /* FIXME header.width, height, xoffset and yoffset aren't initialized */\n\n#if 0\n\n        s->w = header.width;\n\n        s->h = header.height;\n\n        s->x = header.xoffset;\n\n        s->y = header.yoffset;\n\n#else\n\n        return -1;\n\n#endif\n\n    } else {\n\n        s->w = header.xsize;\n\n        s->h = header.ysize;\n\n        if (header.header_type < 2) {\n\n            if ((s->w < 213) && (s->h >= 176))\n\n            {\n\n                s->flags |= FLAG_INTERPOLATED;\n\n                av_log(s->avctx, AV_LOG_INFO, \"INTERPOLATION selected, please report the sample to the developers\\n\");\n\n            }\n\n        }\n\n    }\n\n\n\n    if (header.compression >= 17) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"invalid compression type (%d)\\n\", header.compression);\n\n        return -1;\n\n    }\n\n\n\n    if ((header.deltaset != s->last_deltaset) ||\n\n        (header.vectable != s->last_vectable))\n\n        select_delta_tables(s, header.deltaset);\n\n\n\n    if ((header.compression & 1) && header.header_type)\n\n        sel_vector_table = pc_tbl2;\n\n    else {\n\n        if (header.vectable < 4)\n\n            sel_vector_table = tables[header.vectable - 1];\n\n        else {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"invalid vector table id (%d)\\n\", header.vectable);\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    if (compression_types[header.compression].algorithm == ALGO_RGB24H) {\n\n        new_pix_fmt = PIX_FMT_RGB32;\n\n        width_shift = 1;\n\n    } else\n\n        new_pix_fmt = PIX_FMT_RGB555; // RGB565 is supported as well\n\n\n\n    s->w >>= width_shift;\n\n    if (av_image_check_size(s->w, s->h, 0, s->avctx) < 0)\n\n        return -1;\n\n\n\n    if (s->w != s->avctx->width || s->h != s->avctx->height ||\n\n        new_pix_fmt != s->avctx->pix_fmt) {\n\n        if (s->frame.data[0])\n\n            s->avctx->release_buffer(s->avctx, &s->frame);\n\n        s->avctx->sample_aspect_ratio = (AVRational){ 1 << width_shift, 1 };\n\n        s->avctx->pix_fmt = new_pix_fmt;\n\n        avcodec_set_dimensions(s->avctx, s->w, s->h);\n\n        av_fast_malloc(&s->vert_pred, &s->vert_pred_size, s->avctx->width * sizeof(unsigned int));\n\n    }\n\n\n\n    /* There is 1 change bit per 4 pixels, so each change byte represents\n\n     * 32 pixels; divide width by 4 to obtain the number of change bits and\n\n     * then round up to the nearest byte. */\n\n    s->mb_change_bits_row_size = ((s->avctx->width >> (2 - width_shift)) + 7) >> 3;\n\n\n\n    if ((header.deltaset != s->last_deltaset) || (header.vectable != s->last_vectable))\n\n    {\n\n        if (compression_types[header.compression].algorithm == ALGO_RGB24H)\n\n            gen_vector_table24(s, sel_vector_table);\n\n        else\n\n        if (s->avctx->pix_fmt == PIX_FMT_RGB555)\n\n            gen_vector_table15(s, sel_vector_table);\n\n        else\n\n            gen_vector_table16(s, sel_vector_table);\n\n    }\n\n\n\n    /* set up pointers to the other key data chunks */\n\n    s->mb_change_bits = s->buf + header.header_size;\n\n    if (s->flags & FLAG_KEYFRAME) {\n\n        /* no change bits specified for a keyframe; only index bytes */\n\n        s->index_stream = s->mb_change_bits;\n\n    } else {\n\n        /* one change bit per 4x4 block */\n\n        s->index_stream = s->mb_change_bits +\n\n            (s->mb_change_bits_row_size * (s->avctx->height >> 2));\n\n    }\n\n    s->index_stream_size = s->size - (s->index_stream - s->buf);\n\n\n\n    s->last_deltaset = header.deltaset;\n\n    s->last_vectable = header.vectable;\n\n    s->compression = header.compression;\n\n    s->block_width = compression_types[header.compression].block_width;\n\n    s->block_height = compression_types[header.compression].block_height;\n\n    s->block_type = compression_types[header.compression].block_type;\n\n\n\n    if (s->avctx->debug & FF_DEBUG_PICT_INFO)\n\n        av_log(s->avctx, AV_LOG_INFO, \"tables: %d / %d c:%d %dx%d t:%d %s%s%s%s\\n\",\n\n            s->last_deltaset, s->last_vectable, s->compression, s->block_width,\n\n            s->block_height, s->block_type,\n\n            s->flags & FLAG_KEYFRAME ? \" KEY\" : \"\",\n\n            s->flags & FLAG_INTERFRAME ? \" INTER\" : \"\",\n\n            s->flags & FLAG_SPRITE ? \" SPRITE\" : \"\",\n\n            s->flags & FLAG_INTERPOLATED ? \" INTERPOL\" : \"\");\n\n\n\n    return header.header_size;\n\n}\n", "idx": 24910}
{"project": "FFmpeg", "commit_id": "c7dd3e7e43555b2922481a9242a306c5b138d69c", "target": 0, "func": "static int opt_input_ts_scale(const char *opt, const char *arg)\n\n{\n\n    unsigned int stream;\n\n    double scale;\n\n    char *p;\n\n\n\n    stream = strtol(arg, &p, 0);\n\n    if (*p)\n\n        p++;\n\n    scale= strtod(p, &p);\n\n\n\n    if(stream >= MAX_STREAMS)\n\n        ffmpeg_exit(1);\n\n\n\n    ts_scale = grow_array(ts_scale, sizeof(*ts_scale), &nb_ts_scale, stream + 1);\n\n    ts_scale[stream] = scale;\n\n    return 0;\n\n}\n", "idx": 24911}
{"project": "FFmpeg", "commit_id": "5245c04da332ab9585133ad55f8ec7a06d43b0b0", "target": 0, "func": "static av_always_inline int normal_limit(uint8_t *p, int stride, int E, int I)\n\n{\n\n    LOAD_PIXELS\n\n    return simple_limit(p, stride, 2*E+I)\n\n        && FFABS(p3-p2) <= I && FFABS(p2-p1) <= I && FFABS(p1-p0) <= I\n\n        && FFABS(q3-q2) <= I && FFABS(q2-q1) <= I && FFABS(q1-q0) <= I;\n\n}\n", "idx": 24912}
{"project": "FFmpeg", "commit_id": "8003816e1619e77d8de051883264aa090e0d78cc", "target": 0, "func": "static int mov_open_dref(AVIOContext **pb, const char *src, MOVDref *ref,\n\n                         AVIOInterruptCB *int_cb, int use_absolute_path, AVFormatContext *fc)\n\n{\n\n    /* try relative path, we do not try the absolute because it can leak information about our\n\n       system to an attacker */\n\n    if (ref->nlvl_to > 0 && ref->nlvl_from > 0) {\n\n        char filename[1024];\n\n        const char *src_path;\n\n        int i, l;\n\n\n\n        /* find a source dir */\n\n        src_path = strrchr(src, '/');\n\n        if (src_path)\n\n            src_path++;\n\n        else\n\n            src_path = src;\n\n\n\n        /* find a next level down to target */\n\n        for (i = 0, l = strlen(ref->path) - 1; l >= 0; l--)\n\n            if (ref->path[l] == '/') {\n\n                if (i == ref->nlvl_to - 1)\n\n                    break;\n\n                else\n\n                    i++;\n\n            }\n\n\n\n        /* compose filename if next level down to target was found */\n\n        if (i == ref->nlvl_to - 1 && src_path - src  < sizeof(filename)) {\n\n            memcpy(filename, src, src_path - src);\n\n            filename[src_path - src] = 0;\n\n\n\n            for (i = 1; i < ref->nlvl_from; i++)\n\n                av_strlcat(filename, \"../\", sizeof(filename));\n\n\n\n            av_strlcat(filename, ref->path + l + 1, sizeof(filename));\n\n\n\n            if (!avio_open2(pb, filename, AVIO_FLAG_READ, int_cb, NULL))\n\n                return 0;\n\n        }\n\n    } else if (use_absolute_path) {\n\n        av_log(fc, AV_LOG_WARNING, \"Using absolute path on user request, \"\n\n               \"this is a possible security issue\\n\");\n\n        if (!avio_open2(pb, ref->path, AVIO_FLAG_READ, int_cb, NULL))\n\n            return 0;\n\n    }\n\n\n\n    return AVERROR(ENOENT);\n\n}\n", "idx": 24913}
{"project": "FFmpeg", "commit_id": "13a099799e89a76eb921ca452e1b04a7a28a9855", "target": 0, "func": "static int swScale(SwsContext *c, const uint8_t* src[],\n\n                   int srcStride[], int srcSliceY,\n\n                   int srcSliceH, uint8_t* dst[], int dstStride[])\n\n{\n\n    /* load a few things into local vars to make the code more readable? and faster */\n\n    const int srcW= c->srcW;\n\n    const int dstW= c->dstW;\n\n    const int dstH= c->dstH;\n\n    const int chrDstW= c->chrDstW;\n\n    const int chrSrcW= c->chrSrcW;\n\n    const int lumXInc= c->lumXInc;\n\n    const int chrXInc= c->chrXInc;\n\n    const enum PixelFormat dstFormat= c->dstFormat;\n\n    const int flags= c->flags;\n\n    int16_t *vLumFilterPos= c->vLumFilterPos;\n\n    int16_t *vChrFilterPos= c->vChrFilterPos;\n\n    int16_t *hLumFilterPos= c->hLumFilterPos;\n\n    int16_t *hChrFilterPos= c->hChrFilterPos;\n\n    int16_t *vLumFilter= c->vLumFilter;\n\n    int16_t *vChrFilter= c->vChrFilter;\n\n    int16_t *hLumFilter= c->hLumFilter;\n\n    int16_t *hChrFilter= c->hChrFilter;\n\n    int32_t *lumMmxFilter= c->lumMmxFilter;\n\n    int32_t *chrMmxFilter= c->chrMmxFilter;\n\n    int32_t av_unused *alpMmxFilter= c->alpMmxFilter;\n\n    const int vLumFilterSize= c->vLumFilterSize;\n\n    const int vChrFilterSize= c->vChrFilterSize;\n\n    const int hLumFilterSize= c->hLumFilterSize;\n\n    const int hChrFilterSize= c->hChrFilterSize;\n\n    int16_t **lumPixBuf= c->lumPixBuf;\n\n    int16_t **chrUPixBuf= c->chrUPixBuf;\n\n    int16_t **chrVPixBuf= c->chrVPixBuf;\n\n    int16_t **alpPixBuf= c->alpPixBuf;\n\n    const int vLumBufSize= c->vLumBufSize;\n\n    const int vChrBufSize= c->vChrBufSize;\n\n    uint8_t *formatConvBuffer= c->formatConvBuffer;\n\n    const int chrSrcSliceY= srcSliceY >> c->chrSrcVSubSample;\n\n    const int chrSrcSliceH= -((-srcSliceH) >> c->chrSrcVSubSample);\n\n    int lastDstY;\n\n    uint32_t *pal=c->pal_yuv;\n\n    yuv2planar1_fn yuv2yuv1 = c->yuv2yuv1;\n\n    yuv2planarX_fn yuv2yuvX = c->yuv2yuvX;\n\n    yuv2packed1_fn yuv2packed1 = c->yuv2packed1;\n\n    yuv2packed2_fn yuv2packed2 = c->yuv2packed2;\n\n    yuv2packedX_fn yuv2packedX = c->yuv2packedX;\n\n\n\n    /* vars which will change and which we need to store back in the context */\n\n    int dstY= c->dstY;\n\n    int lumBufIndex= c->lumBufIndex;\n\n    int chrBufIndex= c->chrBufIndex;\n\n    int lastInLumBuf= c->lastInLumBuf;\n\n    int lastInChrBuf= c->lastInChrBuf;\n\n\n\n    if (isPacked(c->srcFormat)) {\n\n        src[0]=\n\n        src[1]=\n\n        src[2]=\n\n        src[3]= src[0];\n\n        srcStride[0]=\n\n        srcStride[1]=\n\n        srcStride[2]=\n\n        srcStride[3]= srcStride[0];\n\n    }\n\n    srcStride[1]<<= c->vChrDrop;\n\n    srcStride[2]<<= c->vChrDrop;\n\n\n\n    DEBUG_BUFFERS(\"swScale() %p[%d] %p[%d] %p[%d] %p[%d] -> %p[%d] %p[%d] %p[%d] %p[%d]\\n\",\n\n                  src[0], srcStride[0], src[1], srcStride[1], src[2], srcStride[2], src[3], srcStride[3],\n\n                  dst[0], dstStride[0], dst[1], dstStride[1], dst[2], dstStride[2], dst[3], dstStride[3]);\n\n    DEBUG_BUFFERS(\"srcSliceY: %d srcSliceH: %d dstY: %d dstH: %d\\n\",\n\n                   srcSliceY,    srcSliceH,    dstY,    dstH);\n\n    DEBUG_BUFFERS(\"vLumFilterSize: %d vLumBufSize: %d vChrFilterSize: %d vChrBufSize: %d\\n\",\n\n                   vLumFilterSize,    vLumBufSize,    vChrFilterSize,    vChrBufSize);\n\n\n\n    if (dstStride[0]%8 !=0 || dstStride[1]%8 !=0 || dstStride[2]%8 !=0 || dstStride[3]%8 != 0) {\n\n        static int warnedAlready=0; //FIXME move this into the context perhaps\n\n        if (flags & SWS_PRINT_INFO && !warnedAlready) {\n\n            av_log(c, AV_LOG_WARNING, \"Warning: dstStride is not aligned!\\n\"\n\n                   \"         ->cannot do aligned memory accesses anymore\\n\");\n\n            warnedAlready=1;\n\n        }\n\n    }\n\n\n\n    /* Note the user might start scaling the picture in the middle so this\n\n       will not get executed. This is not really intended but works\n\n       currently, so people might do it. */\n\n    if (srcSliceY ==0) {\n\n        lumBufIndex=-1;\n\n        chrBufIndex=-1;\n\n        dstY=0;\n\n        lastInLumBuf= -1;\n\n        lastInChrBuf= -1;\n\n    }\n\n\n\n    lastDstY= dstY;\n\n\n\n    for (;dstY < dstH; dstY++) {\n\n        unsigned char *dest =dst[0]+dstStride[0]*dstY;\n\n        const int chrDstY= dstY>>c->chrDstVSubSample;\n\n        unsigned char *uDest=dst[1]+dstStride[1]*chrDstY;\n\n        unsigned char *vDest=dst[2]+dstStride[2]*chrDstY;\n\n        unsigned char *aDest=(CONFIG_SWSCALE_ALPHA && alpPixBuf) ? dst[3]+dstStride[3]*dstY : NULL;\n\n\n\n        const int firstLumSrcY= vLumFilterPos[dstY]; //First line needed as input\n\n        const int firstLumSrcY2= vLumFilterPos[FFMIN(dstY | ((1<<c->chrDstVSubSample) - 1), dstH-1)];\n\n        const int firstChrSrcY= vChrFilterPos[chrDstY]; //First line needed as input\n\n        int lastLumSrcY= firstLumSrcY + vLumFilterSize -1; // Last line needed as input\n\n        int lastLumSrcY2=firstLumSrcY2+ vLumFilterSize -1; // Last line needed as input\n\n        int lastChrSrcY= firstChrSrcY + vChrFilterSize -1; // Last line needed as input\n\n        int enough_lines;\n\n\n\n        //handle holes (FAST_BILINEAR & weird filters)\n\n        if (firstLumSrcY > lastInLumBuf) lastInLumBuf= firstLumSrcY-1;\n\n        if (firstChrSrcY > lastInChrBuf) lastInChrBuf= firstChrSrcY-1;\n\n        assert(firstLumSrcY >= lastInLumBuf - vLumBufSize + 1);\n\n        assert(firstChrSrcY >= lastInChrBuf - vChrBufSize + 1);\n\n\n\n        DEBUG_BUFFERS(\"dstY: %d\\n\", dstY);\n\n        DEBUG_BUFFERS(\"\\tfirstLumSrcY: %d lastLumSrcY: %d lastInLumBuf: %d\\n\",\n\n                         firstLumSrcY,    lastLumSrcY,    lastInLumBuf);\n\n        DEBUG_BUFFERS(\"\\tfirstChrSrcY: %d lastChrSrcY: %d lastInChrBuf: %d\\n\",\n\n                         firstChrSrcY,    lastChrSrcY,    lastInChrBuf);\n\n\n\n        // Do we have enough lines in this slice to output the dstY line\n\n        enough_lines = lastLumSrcY2 < srcSliceY + srcSliceH && lastChrSrcY < -((-srcSliceY - srcSliceH)>>c->chrSrcVSubSample);\n\n\n\n        if (!enough_lines) {\n\n            lastLumSrcY = srcSliceY + srcSliceH - 1;\n\n            lastChrSrcY = chrSrcSliceY + chrSrcSliceH - 1;\n\n            DEBUG_BUFFERS(\"buffering slice: lastLumSrcY %d lastChrSrcY %d\\n\",\n\n                                            lastLumSrcY, lastChrSrcY);\n\n        }\n\n\n\n        //Do horizontal scaling\n\n        while(lastInLumBuf < lastLumSrcY) {\n\n            const uint8_t *src1= src[0]+(lastInLumBuf + 1 - srcSliceY)*srcStride[0];\n\n            const uint8_t *src2= src[3]+(lastInLumBuf + 1 - srcSliceY)*srcStride[3];\n\n            lumBufIndex++;\n\n            assert(lumBufIndex < 2*vLumBufSize);\n\n            assert(lastInLumBuf + 1 - srcSliceY < srcSliceH);\n\n            assert(lastInLumBuf + 1 - srcSliceY >= 0);\n\n            hyscale(c, lumPixBuf[ lumBufIndex ], dstW, src1, srcW, lumXInc,\n\n                    hLumFilter, hLumFilterPos, hLumFilterSize,\n\n                    formatConvBuffer,\n\n                    pal, 0);\n\n            if (CONFIG_SWSCALE_ALPHA && alpPixBuf)\n\n                hyscale(c, alpPixBuf[ lumBufIndex ], dstW, src2, srcW,\n\n                        lumXInc, hLumFilter, hLumFilterPos, hLumFilterSize,\n\n                        formatConvBuffer,\n\n                        pal, 1);\n\n            lastInLumBuf++;\n\n            DEBUG_BUFFERS(\"\\t\\tlumBufIndex %d: lastInLumBuf: %d\\n\",\n\n                               lumBufIndex,    lastInLumBuf);\n\n        }\n\n        while(lastInChrBuf < lastChrSrcY) {\n\n            const uint8_t *src1= src[1]+(lastInChrBuf + 1 - chrSrcSliceY)*srcStride[1];\n\n            const uint8_t *src2= src[2]+(lastInChrBuf + 1 - chrSrcSliceY)*srcStride[2];\n\n            chrBufIndex++;\n\n            assert(chrBufIndex < 2*vChrBufSize);\n\n            assert(lastInChrBuf + 1 - chrSrcSliceY < (chrSrcSliceH));\n\n            assert(lastInChrBuf + 1 - chrSrcSliceY >= 0);\n\n            //FIXME replace parameters through context struct (some at least)\n\n\n\n            if (c->needs_hcscale)\n\n                hcscale(c, chrUPixBuf[chrBufIndex], chrVPixBuf[chrBufIndex],\n\n                          chrDstW, src1, src2, chrSrcW, chrXInc,\n\n                          hChrFilter, hChrFilterPos, hChrFilterSize,\n\n                          formatConvBuffer, pal);\n\n            lastInChrBuf++;\n\n            DEBUG_BUFFERS(\"\\t\\tchrBufIndex %d: lastInChrBuf: %d\\n\",\n\n                               chrBufIndex,    lastInChrBuf);\n\n        }\n\n        //wrap buf index around to stay inside the ring buffer\n\n        if (lumBufIndex >= vLumBufSize) lumBufIndex-= vLumBufSize;\n\n        if (chrBufIndex >= vChrBufSize) chrBufIndex-= vChrBufSize;\n\n        if (!enough_lines)\n\n            break; //we can't output a dstY line so let's try with the next slice\n\n\n\n#if HAVE_MMX\n\n        updateMMXDitherTables(c, dstY, lumBufIndex, chrBufIndex, lastInLumBuf, lastInChrBuf);\n\n#endif\n\n        if (dstY >= dstH-2) {\n\n            // hmm looks like we can't use MMX here without overwriting this array's tail\n\n            find_c_packed_planar_out_funcs(c, &yuv2yuv1, &yuv2yuvX,\n\n                                           &yuv2packed1, &yuv2packed2,\n\n                                           &yuv2packedX);\n\n        }\n\n\n\n        {\n\n            const int16_t **lumSrcPtr= (const int16_t **) lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n            const int16_t **chrUSrcPtr= (const int16_t **) chrUPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n            const int16_t **chrVSrcPtr= (const int16_t **) chrVPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n            const int16_t **alpSrcPtr= (CONFIG_SWSCALE_ALPHA && alpPixBuf) ? (const int16_t **) alpPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize : NULL;\n\n            if (isPlanarYUV(dstFormat) || dstFormat==PIX_FMT_GRAY8) { //YV12 like\n\n                const int chrSkipMask= (1<<c->chrDstVSubSample)-1;\n\n                if ((dstY&chrSkipMask) || isGray(dstFormat)) uDest=vDest= NULL; //FIXME split functions in lumi / chromi\n\n                if (c->yuv2yuv1 && vLumFilterSize == 1 && vChrFilterSize == 1) { // unscaled YV12\n\n                    const int16_t *lumBuf = lumSrcPtr[0];\n\n                    const int16_t *chrUBuf= chrUSrcPtr[0];\n\n                    const int16_t *chrVBuf= chrVSrcPtr[0];\n\n                    const int16_t *alpBuf= (CONFIG_SWSCALE_ALPHA && alpPixBuf) ? alpSrcPtr[0] : NULL;\n\n                    yuv2yuv1(c, lumBuf, chrUBuf, chrVBuf, alpBuf, dest,\n\n                                uDest, vDest, aDest, dstW, chrDstW);\n\n                } else { //General YV12\n\n                    yuv2yuvX(c,\n\n                                vLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n                                vChrFilter+chrDstY*vChrFilterSize, chrUSrcPtr,\n\n                                chrVSrcPtr, vChrFilterSize,\n\n                                alpSrcPtr, dest, uDest, vDest, aDest, dstW, chrDstW);\n\n                }\n\n            } else {\n\n                assert(lumSrcPtr  + vLumFilterSize - 1 < lumPixBuf  + vLumBufSize*2);\n\n                assert(chrUSrcPtr + vChrFilterSize - 1 < chrUPixBuf + vChrBufSize*2);\n\n                if (c->yuv2packed1 && vLumFilterSize == 1 && vChrFilterSize == 2) { //unscaled RGB\n\n                    int chrAlpha= vChrFilter[2*dstY+1];\n\n                    yuv2packed1(c, *lumSrcPtr, *chrUSrcPtr, *(chrUSrcPtr+1),\n\n                                   *chrVSrcPtr, *(chrVSrcPtr+1),\n\n                                   alpPixBuf ? *alpSrcPtr : NULL,\n\n                                   dest, dstW, chrAlpha, dstFormat, flags, dstY);\n\n                } else if (c->yuv2packed2 && vLumFilterSize == 2 && vChrFilterSize == 2) { //bilinear upscale RGB\n\n                    int lumAlpha= vLumFilter[2*dstY+1];\n\n                    int chrAlpha= vChrFilter[2*dstY+1];\n\n                    lumMmxFilter[2]=\n\n                    lumMmxFilter[3]= vLumFilter[2*dstY   ]*0x10001;\n\n                    chrMmxFilter[2]=\n\n                    chrMmxFilter[3]= vChrFilter[2*chrDstY]*0x10001;\n\n                    yuv2packed2(c, *lumSrcPtr, *(lumSrcPtr+1), *chrUSrcPtr, *(chrUSrcPtr+1),\n\n                                   *chrVSrcPtr, *(chrVSrcPtr+1),\n\n                                   alpPixBuf ? *alpSrcPtr : NULL, alpPixBuf ? *(alpSrcPtr+1) : NULL,\n\n                                   dest, dstW, lumAlpha, chrAlpha, dstY);\n\n                } else { //general RGB\n\n                    yuv2packedX(c,\n\n                                   vLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n                                   vChrFilter+dstY*vChrFilterSize, chrUSrcPtr, chrVSrcPtr, vChrFilterSize,\n\n                                   alpSrcPtr, dest, dstW, dstY);\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    if ((dstFormat == PIX_FMT_YUVA420P) && !alpPixBuf)\n\n        fillPlane(dst[3], dstStride[3], dstW, dstY-lastDstY, lastDstY, 255);\n\n\n\n#if HAVE_MMX2\n\n    if (av_get_cpu_flags() & AV_CPU_FLAG_MMX2)\n\n        __asm__ volatile(\"sfence\":::\"memory\");\n\n#endif\n\n    emms_c();\n\n\n\n    /* store changed local vars back in the context */\n\n    c->dstY= dstY;\n\n    c->lumBufIndex= lumBufIndex;\n\n    c->chrBufIndex= chrBufIndex;\n\n    c->lastInLumBuf= lastInLumBuf;\n\n    c->lastInChrBuf= lastInChrBuf;\n\n\n\n    return dstY - lastDstY;\n\n}\n", "idx": 24914}
{"project": "FFmpeg", "commit_id": "f61bece684d9685b07895508e6c1c733b5564ccf", "target": 0, "func": "int sws_setColorspaceDetails(struct SwsContext *c, const int inv_table[4],\n\n                             int srcRange, const int table[4], int dstRange,\n\n                             int brightness, int contrast, int saturation)\n\n{\n\n    const AVPixFmtDescriptor *desc_dst = av_pix_fmt_desc_get(c->dstFormat);\n\n    const AVPixFmtDescriptor *desc_src = av_pix_fmt_desc_get(c->srcFormat);\n\n    memcpy(c->srcColorspaceTable, inv_table, sizeof(int) * 4);\n\n    memcpy(c->dstColorspaceTable, table, sizeof(int) * 4);\n\n\n\n    c->brightness = brightness;\n\n    c->contrast   = contrast;\n\n    c->saturation = saturation;\n\n    c->srcRange   = srcRange;\n\n    c->dstRange   = dstRange;\n\n    if (isYUV(c->dstFormat) || isGray(c->dstFormat))\n\n        return -1;\n\n\n\n    c->dstFormatBpp = av_get_bits_per_pixel(desc_dst);\n\n    c->srcFormatBpp = av_get_bits_per_pixel(desc_src);\n\n\n\n    ff_yuv2rgb_c_init_tables(c, inv_table, srcRange, brightness,\n\n                             contrast, saturation);\n\n    // FIXME factorize\n\n\n\n    if (HAVE_ALTIVEC && av_get_cpu_flags() & AV_CPU_FLAG_ALTIVEC)\n\n        ff_yuv2rgb_init_tables_altivec(c, inv_table, brightness,\n\n                                       contrast, saturation);\n\n    return 0;\n\n}\n", "idx": 24915}
{"project": "FFmpeg", "commit_id": "27216bf314c62125c408be1a5a79e5c9dba88e76", "target": 1, "func": "static int submit_stats(AVCodecContext *avctx)\n\n{\n\n#ifdef TH_ENCCTL_2PASS_IN\n\n    TheoraContext *h = avctx->priv_data;\n\n    int bytes;\n\n\n        if (!avctx->stats_in) {\n\n            av_log(avctx, AV_LOG_ERROR, \"No statsfile for second pass\\n\");\n\n            return AVERROR(EINVAL);\n\n\n        h->stats_size = strlen(avctx->stats_in) * 3/4;\n\n        h->stats      = av_malloc(h->stats_size);\n\n\n\n\n\n        h->stats_size = av_base64_decode(h->stats, avctx->stats_in, h->stats_size);\n\n\n    while (h->stats_size - h->stats_offset > 0) {\n\n        bytes = th_encode_ctl(h->t_state, TH_ENCCTL_2PASS_IN,\n\n                              h->stats + h->stats_offset,\n\n                              h->stats_size - h->stats_offset);\n\n        if (bytes < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Error submitting stats\\n\");\n\n            return AVERROR_EXTERNAL;\n\n\n        if (!bytes)\n\n            return 0;\n\n        h->stats_offset += bytes;\n\n\n    return 0;\n\n#else\n\n    av_log(avctx, AV_LOG_ERROR, \"libtheora too old to support 2pass\\n\");\n\n    return AVERROR(ENOSUP);\n\n#endif\n", "idx": 24919}
{"project": "FFmpeg", "commit_id": "0fa26bd4703cf8ee84ae9b9859be2b4e0e77d42f", "target": 1, "func": "static int encode_plane(AVCodecContext *avctx, uint8_t *src,\n\n                        uint8_t *dst, int stride,\n\n                        int width, int height, PutByteContext *pb)\n\n{\n\n    UtvideoContext *c        = avctx->priv_data;\n\n    uint8_t  lengths[256];\n\n    uint64_t counts[256]     = { 0 };\n\n\n\n    HuffEntry he[256];\n\n\n\n    uint32_t offset = 0, slice_len = 0;\n\n    int      i, sstart, send = 0;\n\n    int      symbol;\n\n\n\n    /* Do prediction / make planes */\n\n    switch (c->frame_pred) {\n\n    case PRED_NONE:\n\n        for (i = 0; i < c->slices; i++) {\n\n            sstart = send;\n\n            send   = height * (i + 1) / c->slices;\n\n            write_plane(src + sstart * stride, dst + sstart * width,\n\n                        stride, width, send - sstart);\n\n        }\n\n        break;\n\n    case PRED_LEFT:\n\n        for (i = 0; i < c->slices; i++) {\n\n            sstart = send;\n\n            send   = height * (i + 1) / c->slices;\n\n            left_predict(src + sstart * stride, dst + sstart * width,\n\n                         stride, width, send - sstart);\n\n        }\n\n        break;\n\n    case PRED_MEDIAN:\n\n        for (i = 0; i < c->slices; i++) {\n\n            sstart = send;\n\n            send   = height * (i + 1) / c->slices;\n\n            median_predict(c, src + sstart * stride, dst + sstart * width,\n\n                           stride, width, send - sstart);\n\n        }\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown prediction mode: %d\\n\",\n\n               c->frame_pred);\n\n        return AVERROR_OPTION_NOT_FOUND;\n\n    }\n\n\n\n    /* Count the usage of values */\n\n    count_usage(dst, width, height, counts);\n\n\n\n    /* Check for a special case where only one symbol was used */\n\n    for (symbol = 0; symbol < 256; symbol++) {\n\n        /* If non-zero count is found, see if it matches width * height */\n\n        if (counts[symbol]) {\n\n            /* Special case if only one symbol was used */\n\n            if (counts[symbol] == width * height) {\n\n                /*\n\n                 * Write a zero for the single symbol\n\n                 * used in the plane, else 0xFF.\n\n                 */\n\n                for (i = 0; i < 256; i++) {\n\n                    if (i == symbol)\n\n                        bytestream2_put_byte(pb, 0);\n\n                    else\n\n                        bytestream2_put_byte(pb, 0xFF);\n\n                }\n\n\n\n                /* Write zeroes for lengths */\n\n                for (i = 0; i < c->slices; i++)\n\n                    bytestream2_put_le32(pb, 0);\n\n\n\n                /* And that's all for that plane folks */\n\n                return 0;\n\n            }\n\n            break;\n\n        }\n\n    }\n\n\n\n    /* Calculate huffman lengths */\n\n    ff_huff_gen_len_table(lengths, counts);\n\n\n\n    /*\n\n     * Write the plane's header into the output packet:\n\n     * - huffman code lengths (256 bytes)\n\n     * - slice end offsets (gotten from the slice lengths)\n\n     */\n\n    for (i = 0; i < 256; i++) {\n\n        bytestream2_put_byte(pb, lengths[i]);\n\n\n\n        he[i].len = lengths[i];\n\n        he[i].sym = i;\n\n    }\n\n\n\n    /* Calculate the huffman codes themselves */\n\n    calculate_codes(he);\n\n\n\n    send = 0;\n\n    for (i = 0; i < c->slices; i++) {\n\n        sstart  = send;\n\n        send    = height * (i + 1) / c->slices;\n\n\n\n        /*\n\n         * Write the huffman codes to a buffer,\n\n         * get the offset in bits and convert to bytes.\n\n         */\n\n        offset += write_huff_codes(dst + sstart * width, c->slice_bits,\n\n                                   width * (send - sstart), width,\n\n                                   send - sstart, he) >> 3;\n\n\n\n        slice_len = offset - slice_len;\n\n\n\n        /* Byteswap the written huffman codes */\n\n        c->dsp.bswap_buf((uint32_t *) c->slice_bits,\n\n                         (uint32_t *) c->slice_bits,\n\n                         slice_len >> 2);\n\n\n\n        /* Write the offset to the stream */\n\n        bytestream2_put_le32(pb, offset);\n\n\n\n        /* Seek to the data part of the packet */\n\n        bytestream2_seek_p(pb, 4 * (c->slices - i - 1) +\n\n                           offset - slice_len, SEEK_CUR);\n\n\n\n        /* Write the slices' data into the output packet */\n\n        bytestream2_put_buffer(pb, c->slice_bits, slice_len);\n\n\n\n        /* Seek back to the slice offsets */\n\n        bytestream2_seek_p(pb, -4 * (c->slices - i - 1) - offset,\n\n                           SEEK_CUR);\n\n\n\n        slice_len = offset;\n\n    }\n\n\n\n    /* And at the end seek to the end of written slice(s) */\n\n    bytestream2_seek_p(pb, offset, SEEK_CUR);\n\n\n\n    return 0;\n\n}\n", "idx": 24920}
{"project": "FFmpeg", "commit_id": "50969c0f46ce60a32c292b8375b4a442cc908c64", "target": 0, "func": "static av_cold int g726_encode_init(AVCodecContext *avctx)\n\n{\n\n    G726Context* c = avctx->priv_data;\n\n\n\n    if (avctx->strict_std_compliance > FF_COMPLIANCE_UNOFFICIAL &&\n\n        avctx->sample_rate != 8000) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Sample rates other than 8kHz are not \"\n\n               \"allowed when the compliance level is higher than unofficial. \"\n\n               \"Resample or reduce the compliance level.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    av_assert0(avctx->sample_rate > 0);\n\n\n\n    if(avctx->channels != 1){\n\n        av_log(avctx, AV_LOG_ERROR, \"Only mono is supported\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (avctx->bit_rate % avctx->sample_rate) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Bitrate - Samplerate combination is invalid\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    c->code_size = (avctx->bit_rate + avctx->sample_rate/2) / avctx->sample_rate;\n\n    if (c->code_size < 2 || c->code_size > 5) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid number of bits %d\\n\", c->code_size);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    avctx->bits_per_coded_sample = c->code_size;\n\n\n\n    g726_reset(c, c->code_size - 2);\n\n\n\n    avctx->coded_frame = avcodec_alloc_frame();\n\n    if (!avctx->coded_frame)\n\n        return AVERROR(ENOMEM);\n\n    avctx->coded_frame->key_frame = 1;\n\n\n\n    /* select a frame size that will end on a byte boundary and have a size of\n\n       approximately 1024 bytes */\n\n    avctx->frame_size = ((int[]){ 4096, 2736, 2048, 1640 })[c->code_size - 2];\n\n\n\n    return 0;\n\n}\n", "idx": 24928}
{"project": "FFmpeg", "commit_id": "b933c72b5e36967b6be73555e8289cc074fb44a7", "target": 0, "func": "static void write_audio_frame(AVFormatContext *oc, AVStream *st)\n\n{\n\n    AVCodecContext *c;\n\n    AVPacket pkt = { 0 }; // data and size must be 0;\n\n    int got_packet, ret, dst_nb_samples;\n\n\n\n    av_init_packet(&pkt);\n\n    c = st->codec;\n\n\n\n    get_audio_frame((int16_t *)src_samples_data[0], src_nb_samples, c->channels);\n\n\n\n    /* convert samples from native format to destination codec format, using the resampler */\n\n    if (swr_ctx) {\n\n        /* compute destination number of samples */\n\n        dst_nb_samples = av_rescale_rnd(swr_get_delay(swr_ctx, c->sample_rate) + src_nb_samples,\n\n                                        c->sample_rate, c->sample_rate, AV_ROUND_UP);\n\n        if (dst_nb_samples > max_dst_nb_samples) {\n\n            av_free(dst_samples_data[0]);\n\n            ret = av_samples_alloc(dst_samples_data, &dst_samples_linesize, c->channels,\n\n                                   dst_nb_samples, c->sample_fmt, 0);\n\n            if (ret < 0)\n\n                exit(1);\n\n            max_dst_nb_samples = dst_nb_samples;\n\n            dst_samples_size = av_samples_get_buffer_size(NULL, c->channels, dst_nb_samples,\n\n                                                          c->sample_fmt, 0);\n\n        }\n\n\n\n        /* convert to destination format */\n\n        ret = swr_convert(swr_ctx,\n\n                          dst_samples_data, dst_nb_samples,\n\n                          (const uint8_t **)src_samples_data, src_nb_samples);\n\n        if (ret < 0) {\n\n            fprintf(stderr, \"Error while converting\\n\");\n\n            exit(1);\n\n        }\n\n    } else {\n\n        dst_nb_samples = src_nb_samples;\n\n    }\n\n\n\n    audio_frame->nb_samples = dst_nb_samples;\n\n    audio_frame->pts = av_rescale_q(samples_count, (AVRational){1, c->sample_rate}, c->time_base);\n\n    avcodec_fill_audio_frame(audio_frame, c->channels, c->sample_fmt,\n\n                             dst_samples_data[0], dst_samples_size, 0);\n\n    samples_count += dst_nb_samples;\n\n\n\n    ret = avcodec_encode_audio2(c, &pkt, audio_frame, &got_packet);\n\n    if (ret < 0) {\n\n        fprintf(stderr, \"Error encoding audio frame: %s\\n\", av_err2str(ret));\n\n        exit(1);\n\n    }\n\n\n\n    if (!got_packet)\n\n        return;\n\n\n\n    ret = write_frame(oc, &c->time_base, st, &pkt);\n\n    if (ret != 0) {\n\n        fprintf(stderr, \"Error while writing audio frame: %s\\n\",\n\n                av_err2str(ret));\n\n        exit(1);\n\n    }\n\n}\n", "idx": 24939}
{"project": "FFmpeg", "commit_id": "2254b559cbcfc0418135f09add37c0a5866b1981", "target": 1, "func": "static void RENAME(hyscale_fast)(SwsContext *c, int16_t *dst,\n\n                                 int dstWidth, const uint8_t *src,\n\n                                 int srcW, int xInc)\n\n{\n\n    int16_t *filterPos = c->hLumFilterPos;\n\n    int16_t *filter    = c->hLumFilter;\n\n    void    *mmx2FilterCode= c->lumMmx2FilterCode;\n\n    int i;\n\n#if defined(PIC)\n\n    uint64_t ebxsave;\n\n#endif\n\n#if ARCH_X86_64\n\n    uint64_t retsave;\n\n#endif\n\n\n\n    __asm__ volatile(\n\n#if defined(PIC)\n\n        \"mov               %%\"REG_b\", %5        \\n\\t\"\n\n#if ARCH_X86_64\n\n        \"mov               -8(%%rsp), %%\"REG_a\" \\n\\t\"\n\n        \"mov               %%\"REG_a\", %6        \\n\\t\"\n\n#endif\n\n#else\n\n#if ARCH_X86_64\n\n        \"mov               -8(%%rsp), %%\"REG_a\" \\n\\t\"\n\n        \"mov               %%\"REG_a\", %5        \\n\\t\"\n\n#endif\n\n#endif\n\n        \"pxor                  %%mm7, %%mm7     \\n\\t\"\n\n        \"mov                      %0, %%\"REG_c\" \\n\\t\"\n\n        \"mov                      %1, %%\"REG_D\" \\n\\t\"\n\n        \"mov                      %2, %%\"REG_d\" \\n\\t\"\n\n        \"mov                      %3, %%\"REG_b\" \\n\\t\"\n\n        \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\" // i\n\n        PREFETCH\"        (%%\"REG_c\")            \\n\\t\"\n\n        PREFETCH\"      32(%%\"REG_c\")            \\n\\t\"\n\n        PREFETCH\"      64(%%\"REG_c\")            \\n\\t\"\n\n\n\n#if ARCH_X86_64\n\n#define CALL_MMX2_FILTER_CODE \\\n\n        \"movl            (%%\"REG_b\"), %%esi     \\n\\t\"\\\n\n        \"call                    *%4            \\n\\t\"\\\n\n        \"movl (%%\"REG_b\", %%\"REG_a\"), %%esi     \\n\\t\"\\\n\n        \"add               %%\"REG_S\", %%\"REG_c\" \\n\\t\"\\\n\n        \"add               %%\"REG_a\", %%\"REG_D\" \\n\\t\"\\\n\n        \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\"\\\n\n\n\n#else\n\n#define CALL_MMX2_FILTER_CODE \\\n\n        \"movl (%%\"REG_b\"), %%esi        \\n\\t\"\\\n\n        \"call         *%4                       \\n\\t\"\\\n\n        \"addl (%%\"REG_b\", %%\"REG_a\"), %%\"REG_c\" \\n\\t\"\\\n\n        \"add               %%\"REG_a\", %%\"REG_D\" \\n\\t\"\\\n\n        \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\"\\\n\n\n\n#endif /* ARCH_X86_64 */\n\n\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n\n\n#if defined(PIC)\n\n        \"mov                      %5, %%\"REG_b\" \\n\\t\"\n\n#if ARCH_X86_64\n\n        \"mov                      %6, %%\"REG_a\" \\n\\t\"\n\n        \"mov               %%\"REG_a\", -8(%%rsp) \\n\\t\"\n\n#endif\n\n#else\n\n#if ARCH_X86_64\n\n        \"mov                      %5, %%\"REG_a\" \\n\\t\"\n\n        \"mov               %%\"REG_a\", -8(%%rsp) \\n\\t\"\n\n#endif\n\n#endif\n\n        :: \"m\" (src), \"m\" (dst), \"m\" (filter), \"m\" (filterPos),\n\n           \"m\" (mmx2FilterCode)\n\n#if defined(PIC)\n\n          ,\"m\" (ebxsave)\n\n#endif\n\n#if ARCH_X86_64\n\n          ,\"m\"(retsave)\n\n#endif\n\n        : \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S, \"%\"REG_D\n\n#if !defined(PIC)\n\n         ,\"%\"REG_b\n\n#endif\n\n    );\n\n\n\n    for (i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--)\n\n        dst[i] = src[srcW-1]*128;\n\n}\n", "idx": 24944}
{"project": "FFmpeg", "commit_id": "40fa6a2fa2c255293a780a194eecae5df52644a1", "target": 1, "func": "static int decode_dc_progressive(MJpegDecodeContext *s, int16_t *block,\n\n                                 int component, int dc_index,\n\n                                 uint16_t *quant_matrix, int Al)\n\n{\n\n    int val;\n\n    s->bdsp.clear_block(block);\n\n    val = mjpeg_decode_dc(s, dc_index);\n\n    if (val == 0xfffff) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"error dc\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    val = (val * (quant_matrix[0] << Al)) + s->last_dc[component];\n\n    s->last_dc[component] = val;\n\n    block[0] = val;\n\n    return 0;\n\n}\n", "idx": 24945}
{"project": "FFmpeg", "commit_id": "8824b7370a9fb72f9c699c3751a5ceb56e0cc41d", "target": 1, "func": "static void vp7_idct_add_c(uint8_t *dst, int16_t block[16], ptrdiff_t stride)\n\n{\n\n    int i, a1, b1, c1, d1;\n\n    int16_t tmp[16];\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        a1 = (block[i * 4 + 0] + block[i * 4 + 2]) * 23170;\n\n        b1 = (block[i * 4 + 0] - block[i * 4 + 2]) * 23170;\n\n        c1 = block[i * 4 + 1] * 12540 - block[i * 4 + 3] * 30274;\n\n        d1 = block[i * 4 + 1] * 30274 + block[i * 4 + 3] * 12540;\n\n        AV_ZERO64(block + i * 4);\n\n        tmp[i * 4 + 0] = (a1 + d1) >> 14;\n\n        tmp[i * 4 + 3] = (a1 - d1) >> 14;\n\n        tmp[i * 4 + 1] = (b1 + c1) >> 14;\n\n        tmp[i * 4 + 2] = (b1 - c1) >> 14;\n\n    }\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        a1 = (tmp[i + 0] + tmp[i + 8]) * 23170;\n\n        b1 = (tmp[i + 0] - tmp[i + 8]) * 23170;\n\n        c1 = tmp[i + 4] * 12540 - tmp[i + 12] * 30274;\n\n        d1 = tmp[i + 4] * 30274 + tmp[i + 12] * 12540;\n\n        dst[0 * stride + i] = av_clip_uint8(dst[0 * stride + i] +\n\n                                            ((a1 + d1 + 0x20000) >> 18));\n\n        dst[3 * stride + i] = av_clip_uint8(dst[3 * stride + i] +\n\n                                            ((a1 - d1 + 0x20000) >> 18));\n\n        dst[1 * stride + i] = av_clip_uint8(dst[1 * stride + i] +\n\n                                            ((b1 + c1 + 0x20000) >> 18));\n\n        dst[2 * stride + i] = av_clip_uint8(dst[2 * stride + i] +\n\n                                            ((b1 - c1 + 0x20000) >> 18));\n\n    }\n\n}\n", "idx": 24949}
{"project": "FFmpeg", "commit_id": "cf880ccb6a82476e1b944d5d0e742b63de21283a", "target": 1, "func": "void ff_er_add_slice(ERContext *s, int startx, int starty,\n\n                     int endx, int endy, int status)\n\n{\n\n    const int start_i  = av_clip(startx + starty * s->mb_width, 0, s->mb_num - 1);\n\n    const int end_i    = av_clip(endx   + endy   * s->mb_width, 0, s->mb_num);\n\n    const int start_xy = s->mb_index2xy[start_i];\n\n    const int end_xy   = s->mb_index2xy[end_i];\n\n    int mask           = -1;\n\n\n\n    if (s->avctx->hwaccel && s->avctx->hwaccel->decode_slice)\n\n        return;\n\n\n\n    if (start_i > end_i || start_xy > end_xy) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"internal error, slice end before start\\n\");\n\n        return;\n\n    }\n\n\n\n    if (!s->avctx->error_concealment)\n\n        return;\n\n\n\n    mask &= ~VP_START;\n\n    if (status & (ER_AC_ERROR | ER_AC_END)) {\n\n        mask           &= ~(ER_AC_ERROR | ER_AC_END);\n\n        s->error_count -= end_i - start_i + 1;\n\n    }\n\n    if (status & (ER_DC_ERROR | ER_DC_END)) {\n\n        mask           &= ~(ER_DC_ERROR | ER_DC_END);\n\n        s->error_count -= end_i - start_i + 1;\n\n    }\n\n    if (status & (ER_MV_ERROR | ER_MV_END)) {\n\n        mask           &= ~(ER_MV_ERROR | ER_MV_END);\n\n        s->error_count -= end_i - start_i + 1;\n\n    }\n\n\n\n    if (status & ER_MB_ERROR) {\n\n        s->error_occurred = 1;\n\n        s->error_count    = INT_MAX;\n\n    }\n\n\n\n    if (mask == ~0x7F) {\n\n        memset(&s->error_status_table[start_xy], 0,\n\n               (end_xy - start_xy) * sizeof(uint8_t));\n\n    } else {\n\n        int i;\n\n        for (i = start_xy; i < end_xy; i++)\n\n            s->error_status_table[i] &= mask;\n\n    }\n\n\n\n    if (end_i == s->mb_num)\n\n        s->error_count = INT_MAX;\n\n    else {\n\n        s->error_status_table[end_xy] &= mask;\n\n        s->error_status_table[end_xy] |= status;\n\n    }\n\n\n\n    s->error_status_table[start_xy] |= VP_START;\n\n\n\n    if (start_xy > 0 && !(s->avctx->active_thread_type & FF_THREAD_SLICE) &&\n\n        er_supported(s) && s->avctx->skip_top * s->mb_width < start_i) {\n\n        int prev_status = s->error_status_table[s->mb_index2xy[start_i - 1]];\n\n\n\n        prev_status &= ~ VP_START;\n\n        if (prev_status != (ER_MV_END | ER_DC_END | ER_AC_END)) {\n\n            s->error_occurred = 1;\n\n            s->error_count = INT_MAX;\n\n        }\n\n    }\n\n}\n", "idx": 24951}
{"project": "FFmpeg", "commit_id": "39d607e5bbc25ad9629683702b510e865434ef21", "target": 1, "func": "static inline void RENAME(yuv2yuvX)(SwsContext *c, const int16_t *lumFilter,\n\n                                    const int16_t **lumSrc, int lumFilterSize,\n\n                                    const int16_t *chrFilter, const int16_t **chrUSrc,\n\n                                    const int16_t **chrVSrc,\n\n                                    int chrFilterSize, const int16_t **alpSrc,\n\n                                    uint8_t *dest, uint8_t *uDest, uint8_t *vDest,\n\n                                    uint8_t *aDest, long dstW, long chrDstW)\n\n{\n\n    if (uDest) {\n\n        YSCALEYUV2YV12X(CHR_MMX_FILTER_OFFSET, uDest, chrDstW, 0)\n\n        YSCALEYUV2YV12X(CHR_MMX_FILTER_OFFSET, vDest, chrDstW + c->uv_off, c->uv_off)\n\n    }\n\n    if (CONFIG_SWSCALE_ALPHA && aDest) {\n\n        YSCALEYUV2YV12X(ALP_MMX_FILTER_OFFSET, aDest, dstW, 0)\n\n    }\n\n\n\n    YSCALEYUV2YV12X(LUM_MMX_FILTER_OFFSET, dest, dstW, 0)\n\n}\n", "idx": 24952}
{"project": "FFmpeg", "commit_id": "c084a975aa13eb1d0161f36a06051a9b2d4abb83", "target": 1, "func": "AVFrame *avcodec_alloc_frame(void)\n\n{\n\n    AVFrame *frame = av_malloc(sizeof(AVFrame));\n\n\n\n    if (frame == NULL)\n\n        return NULL;\n\n\n\n    avcodec_get_frame_defaults(frame);\n\n\n\n    return frame;\n\n}\n", "idx": 24953}
{"project": "FFmpeg", "commit_id": "7a2efd2e447d5e7c7c0af61417a838b042fb7d0a", "target": 0, "func": "int av_cold ff_mlp_init_crc2D(AVCodecParserContext *s)\n\n{\n\n    if (!crc_init_2D) {\n\n        av_crc_init(crc_2D, 0, 16, 0x002D, sizeof(crc_2D));\n\n        crc_init_2D = 1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24957}
{"project": "FFmpeg", "commit_id": "5a31f2318b8fed1f4711cb86eab6d9b679946878", "target": 1, "func": "static AVStream *add_av_stream1(FFServerStream *stream,\n\n                                AVCodecContext *codec, int copy)\n\n{\n\n    AVStream *fst;\n\n\n\n    if(stream->nb_streams >= FF_ARRAY_ELEMS(stream->streams))\n\n        return NULL;\n\n\n\n    fst = av_mallocz(sizeof(AVStream));\n\n    if (!fst)\n\n        return NULL;\n\n    if (copy) {\n\n        fst->codec = avcodec_alloc_context3(codec->codec);\n\n        if (!fst->codec) {\n\n            av_free(fst);\n\n            return NULL;\n\n        }\n\n        avcodec_copy_context(fst->codec, codec);\n\n    } else\n\n        /* live streams must use the actual feed's codec since it may be\n\n         * updated later to carry extradata needed by them.\n\n         */\n\n        fst->codec = codec;\n\n\n\n    fst->priv_data = av_mallocz(sizeof(FeedData));\n\n\n    fst->index = stream->nb_streams;\n\n    avpriv_set_pts_info(fst, 33, 1, 90000);\n\n    fst->sample_aspect_ratio = codec->sample_aspect_ratio;\n\n    stream->streams[stream->nb_streams++] = fst;\n\n    return fst;\n\n}", "idx": 24961}
{"project": "FFmpeg", "commit_id": "1125606a1f8bdcabbdd9107831d20e86f0dfeeae", "target": 1, "func": "static av_cold int vp3_decode_init(AVCodecContext *avctx)\n\n{\n\n    Vp3DecodeContext *s = avctx->priv_data;\n\n    int i, inter, plane;\n\n    int c_width;\n\n    int c_height;\n\n    int y_fragment_count, c_fragment_count;\n\n\n\n    if (avctx->codec_tag == MKTAG('V','P','3','0'))\n\n        s->version = 0;\n\n    else\n\n        s->version = 1;\n\n\n\n    s->avctx = avctx;\n\n    s->width = FFALIGN(avctx->width, 16);\n\n    s->height = FFALIGN(avctx->height, 16);\n\n    if (avctx->pix_fmt == PIX_FMT_NONE)\n\n        avctx->pix_fmt = PIX_FMT_YUV420P;\n\n    avctx->chroma_sample_location = AVCHROMA_LOC_CENTER;\n\n    if(avctx->idct_algo==FF_IDCT_AUTO)\n\n        avctx->idct_algo=FF_IDCT_VP3;\n\n    ff_dsputil_init(&s->dsp, avctx);\n\n\n\n    ff_init_scantable(s->dsp.idct_permutation, &s->scantable, ff_zigzag_direct);\n\n\n\n    /* initialize to an impossible value which will force a recalculation\n\n     * in the first frame decode */\n\n    for (i = 0; i < 3; i++)\n\n        s->qps[i] = -1;\n\n\n\n    avcodec_get_chroma_sub_sample(avctx->pix_fmt, &s->chroma_x_shift, &s->chroma_y_shift);\n\n\n\n    s->y_superblock_width = (s->width + 31) / 32;\n\n    s->y_superblock_height = (s->height + 31) / 32;\n\n    s->y_superblock_count = s->y_superblock_width * s->y_superblock_height;\n\n\n\n    /* work out the dimensions for the C planes */\n\n    c_width = s->width >> s->chroma_x_shift;\n\n    c_height = s->height >> s->chroma_y_shift;\n\n    s->c_superblock_width = (c_width + 31) / 32;\n\n    s->c_superblock_height = (c_height + 31) / 32;\n\n    s->c_superblock_count = s->c_superblock_width * s->c_superblock_height;\n\n\n\n    s->superblock_count = s->y_superblock_count + (s->c_superblock_count * 2);\n\n    s->u_superblock_start = s->y_superblock_count;\n\n    s->v_superblock_start = s->u_superblock_start + s->c_superblock_count;\n\n\n\n    s->macroblock_width = (s->width + 15) / 16;\n\n    s->macroblock_height = (s->height + 15) / 16;\n\n    s->macroblock_count = s->macroblock_width * s->macroblock_height;\n\n\n\n    s->fragment_width[0] = s->width / FRAGMENT_PIXELS;\n\n    s->fragment_height[0] = s->height / FRAGMENT_PIXELS;\n\n    s->fragment_width[1]  = s->fragment_width[0]  >> s->chroma_x_shift;\n\n    s->fragment_height[1] = s->fragment_height[0] >> s->chroma_y_shift;\n\n\n\n    /* fragment count covers all 8x8 blocks for all 3 planes */\n\n    y_fragment_count     = s->fragment_width[0] * s->fragment_height[0];\n\n    c_fragment_count     = s->fragment_width[1] * s->fragment_height[1];\n\n    s->fragment_count    = y_fragment_count + 2*c_fragment_count;\n\n    s->fragment_start[1] = y_fragment_count;\n\n    s->fragment_start[2] = y_fragment_count + c_fragment_count;\n\n\n\n    if (!s->theora_tables)\n\n    {\n\n        for (i = 0; i < 64; i++) {\n\n            s->coded_dc_scale_factor[i] = vp31_dc_scale_factor[i];\n\n            s->coded_ac_scale_factor[i] = vp31_ac_scale_factor[i];\n\n            s->base_matrix[0][i] = vp31_intra_y_dequant[i];\n\n            s->base_matrix[1][i] = vp31_intra_c_dequant[i];\n\n            s->base_matrix[2][i] = vp31_inter_dequant[i];\n\n            s->filter_limit_values[i] = vp31_filter_limit_values[i];\n\n        }\n\n\n\n        for(inter=0; inter<2; inter++){\n\n            for(plane=0; plane<3; plane++){\n\n                s->qr_count[inter][plane]= 1;\n\n                s->qr_size [inter][plane][0]= 63;\n\n                s->qr_base [inter][plane][0]=\n\n                s->qr_base [inter][plane][1]= 2*inter + (!!plane)*!inter;\n\n            }\n\n        }\n\n\n\n        /* init VLC tables */\n\n        for (i = 0; i < 16; i++) {\n\n\n\n            /* DC histograms */\n\n            init_vlc(&s->dc_vlc[i], 11, 32,\n\n                &dc_bias[i][0][1], 4, 2,\n\n                &dc_bias[i][0][0], 4, 2, 0);\n\n\n\n            /* group 1 AC histograms */\n\n            init_vlc(&s->ac_vlc_1[i], 11, 32,\n\n                &ac_bias_0[i][0][1], 4, 2,\n\n                &ac_bias_0[i][0][0], 4, 2, 0);\n\n\n\n            /* group 2 AC histograms */\n\n            init_vlc(&s->ac_vlc_2[i], 11, 32,\n\n                &ac_bias_1[i][0][1], 4, 2,\n\n                &ac_bias_1[i][0][0], 4, 2, 0);\n\n\n\n            /* group 3 AC histograms */\n\n            init_vlc(&s->ac_vlc_3[i], 11, 32,\n\n                &ac_bias_2[i][0][1], 4, 2,\n\n                &ac_bias_2[i][0][0], 4, 2, 0);\n\n\n\n            /* group 4 AC histograms */\n\n            init_vlc(&s->ac_vlc_4[i], 11, 32,\n\n                &ac_bias_3[i][0][1], 4, 2,\n\n                &ac_bias_3[i][0][0], 4, 2, 0);\n\n        }\n\n    } else {\n\n\n\n        for (i = 0; i < 16; i++) {\n\n            /* DC histograms */\n\n            if (init_vlc(&s->dc_vlc[i], 11, 32,\n\n                &s->huffman_table[i][0][1], 8, 4,\n\n                &s->huffman_table[i][0][0], 8, 4, 0) < 0)\n\n                goto vlc_fail;\n\n\n\n            /* group 1 AC histograms */\n\n            if (init_vlc(&s->ac_vlc_1[i], 11, 32,\n\n                &s->huffman_table[i+16][0][1], 8, 4,\n\n                &s->huffman_table[i+16][0][0], 8, 4, 0) < 0)\n\n                goto vlc_fail;\n\n\n\n            /* group 2 AC histograms */\n\n            if (init_vlc(&s->ac_vlc_2[i], 11, 32,\n\n                &s->huffman_table[i+16*2][0][1], 8, 4,\n\n                &s->huffman_table[i+16*2][0][0], 8, 4, 0) < 0)\n\n                goto vlc_fail;\n\n\n\n            /* group 3 AC histograms */\n\n            if (init_vlc(&s->ac_vlc_3[i], 11, 32,\n\n                &s->huffman_table[i+16*3][0][1], 8, 4,\n\n                &s->huffman_table[i+16*3][0][0], 8, 4, 0) < 0)\n\n                goto vlc_fail;\n\n\n\n            /* group 4 AC histograms */\n\n            if (init_vlc(&s->ac_vlc_4[i], 11, 32,\n\n                &s->huffman_table[i+16*4][0][1], 8, 4,\n\n                &s->huffman_table[i+16*4][0][0], 8, 4, 0) < 0)\n\n                goto vlc_fail;\n\n        }\n\n    }\n\n\n\n    init_vlc(&s->superblock_run_length_vlc, 6, 34,\n\n        &superblock_run_length_vlc_table[0][1], 4, 2,\n\n        &superblock_run_length_vlc_table[0][0], 4, 2, 0);\n\n\n\n    init_vlc(&s->fragment_run_length_vlc, 5, 30,\n\n        &fragment_run_length_vlc_table[0][1], 4, 2,\n\n        &fragment_run_length_vlc_table[0][0], 4, 2, 0);\n\n\n\n    init_vlc(&s->mode_code_vlc, 3, 8,\n\n        &mode_code_vlc_table[0][1], 2, 1,\n\n        &mode_code_vlc_table[0][0], 2, 1, 0);\n\n\n\n    init_vlc(&s->motion_vector_vlc, 6, 63,\n\n        &motion_vector_vlc_table[0][1], 2, 1,\n\n        &motion_vector_vlc_table[0][0], 2, 1, 0);\n\n\n\n    for (i = 0; i < 3; i++) {\n\n        s->current_frame.data[i] = NULL;\n\n        s->last_frame.data[i] = NULL;\n\n        s->golden_frame.data[i] = NULL;\n\n    }\n\n\n\n    return allocate_tables(avctx);\n\n\n\nvlc_fail:\n\n    av_log(avctx, AV_LOG_FATAL, \"Invalid huffman table\\n\");\n\n    return -1;\n\n}\n", "idx": 24962}
{"project": "FFmpeg", "commit_id": "4bff9ef9d0781c4de228bf1f85634d2706fc589b", "target": 0, "func": "static inline void RENAME(bgr24ToUV)(uint8_t *dstU, uint8_t *dstV, uint8_t *src1, uint8_t *src2, long width)\n\n{\n\n#ifdef HAVE_MMX\n\n\tasm volatile(\n\n\t\t\"mov %4, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\"movq \"MANGLE(w1111)\", %%mm5\t\t\\n\\t\"\n\n\t\t\"movq \"MANGLE(bgr2UCoeff)\", %%mm6\t\t\\n\\t\"\n\n\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\"lea (%%\"REG_a\", %%\"REG_a\", 2), %%\"REG_b\"\t\\n\\t\"\n\n\t\t\"add %%\"REG_b\", %%\"REG_b\"\t\\n\\t\"\n\n\t\tASMALIGN16\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\tPREFETCH\" 64(%0, %%\"REG_b\")\t\\n\\t\"\n\n\t\tPREFETCH\" 64(%1, %%\"REG_b\")\t\\n\\t\"\n\n#if defined (HAVE_MMX2) || defined (HAVE_3DNOW)\n\n\t\t\"movq (%0, %%\"REG_b\"), %%mm0\t\\n\\t\"\n\n\t\t\"movq (%1, %%\"REG_b\"), %%mm1\t\\n\\t\"\n\n\t\t\"movq 6(%0, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\"movq 6(%1, %%\"REG_b\"), %%mm3\t\\n\\t\"\n\n\t\tPAVGB(%%mm1, %%mm0)\n\n\t\tPAVGB(%%mm3, %%mm2)\n\n\t\t\"movq %%mm0, %%mm1\t\t\\n\\t\"\n\n\t\t\"movq %%mm2, %%mm3\t\t\\n\\t\"\n\n\t\t\"psrlq $24, %%mm0\t\t\\n\\t\"\n\n\t\t\"psrlq $24, %%mm2\t\t\\n\\t\"\n\n\t\tPAVGB(%%mm1, %%mm0)\n\n\t\tPAVGB(%%mm3, %%mm2)\n\n\t\t\"punpcklbw %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n#else\n\n\t\t\"movd (%0, %%\"REG_b\"), %%mm0\t\\n\\t\"\n\n\t\t\"movd (%1, %%\"REG_b\"), %%mm1\t\\n\\t\"\n\n\t\t\"movd 3(%0, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\"movd 3(%1, %%\"REG_b\"), %%mm3\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm1\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm3\t\t\\n\\t\"\n\n\t\t\"paddw %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\"paddw %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\"paddw %%mm2, %%mm0\t\t\\n\\t\"\n\n\t\t\"movd 6(%0, %%\"REG_b\"), %%mm4\t\\n\\t\"\n\n\t\t\"movd 6(%1, %%\"REG_b\"), %%mm1\t\\n\\t\"\n\n\t\t\"movd 9(%0, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\"movd 9(%1, %%\"REG_b\"), %%mm3\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm4\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm1\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm3\t\t\\n\\t\"\n\n\t\t\"paddw %%mm1, %%mm4\t\t\\n\\t\"\n\n\t\t\"paddw %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\"paddw %%mm4, %%mm2\t\t\\n\\t\"\n\n\t\t\"psrlw $2, %%mm0\t\t\\n\\t\"\n\n\t\t\"psrlw $2, %%mm2\t\t\\n\\t\"\n\n#endif\n\n\t\t\"movq \"MANGLE(bgr2VCoeff)\", %%mm1\t\t\\n\\t\"\n\n\t\t\"movq \"MANGLE(bgr2VCoeff)\", %%mm3\t\t\\n\\t\"\n\n\t\t\n\n\t\t\"pmaddwd %%mm0, %%mm1\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm2, %%mm3\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm6, %%mm0\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm6, %%mm2\t\t\\n\\t\"\n\n#ifndef FAST_BGR2YV12\n\n\t\t\"psrad $8, %%mm0\t\t\\n\\t\"\n\n\t\t\"psrad $8, %%mm1\t\t\\n\\t\"\n\n\t\t\"psrad $8, %%mm2\t\t\\n\\t\"\n\n\t\t\"psrad $8, %%mm3\t\t\\n\\t\"\n\n#endif\n\n\t\t\"packssdw %%mm2, %%mm0\t\t\\n\\t\"\n\n\t\t\"packssdw %%mm3, %%mm1\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm5, %%mm0\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm5, %%mm1\t\t\\n\\t\"\n\n\t\t\"packssdw %%mm1, %%mm0\t\t\\n\\t\" // V1 V0 U1 U0\n\n\t\t\"psraw $7, %%mm0\t\t\\n\\t\"\n\n\n\n#if defined (HAVE_MMX2) || defined (HAVE_3DNOW)\n\n\t\t\"movq 12(%0, %%\"REG_b\"), %%mm4\t\\n\\t\"\n\n\t\t\"movq 12(%1, %%\"REG_b\"), %%mm1\t\\n\\t\"\n\n\t\t\"movq 18(%0, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\"movq 18(%1, %%\"REG_b\"), %%mm3\t\\n\\t\"\n\n\t\tPAVGB(%%mm1, %%mm4)\n\n\t\tPAVGB(%%mm3, %%mm2)\n\n\t\t\"movq %%mm4, %%mm1\t\t\\n\\t\"\n\n\t\t\"movq %%mm2, %%mm3\t\t\\n\\t\"\n\n\t\t\"psrlq $24, %%mm4\t\t\\n\\t\"\n\n\t\t\"psrlq $24, %%mm2\t\t\\n\\t\"\n\n\t\tPAVGB(%%mm1, %%mm4)\n\n\t\tPAVGB(%%mm3, %%mm2)\n\n\t\t\"punpcklbw %%mm7, %%mm4\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n#else\n\n\t\t\"movd 12(%0, %%\"REG_b\"), %%mm4\t\\n\\t\"\n\n\t\t\"movd 12(%1, %%\"REG_b\"), %%mm1\t\\n\\t\"\n\n\t\t\"movd 15(%0, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\"movd 15(%1, %%\"REG_b\"), %%mm3\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm4\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm1\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm3\t\t\\n\\t\"\n\n\t\t\"paddw %%mm1, %%mm4\t\t\\n\\t\"\n\n\t\t\"paddw %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\"paddw %%mm2, %%mm4\t\t\\n\\t\"\n\n\t\t\"movd 18(%0, %%\"REG_b\"), %%mm5\t\\n\\t\"\n\n\t\t\"movd 18(%1, %%\"REG_b\"), %%mm1\t\\n\\t\"\n\n\t\t\"movd 21(%0, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\"movd 21(%1, %%\"REG_b\"), %%mm3\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm5\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm1\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm3\t\t\\n\\t\"\n\n\t\t\"paddw %%mm1, %%mm5\t\t\\n\\t\"\n\n\t\t\"paddw %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\"paddw %%mm5, %%mm2\t\t\\n\\t\"\n\n\t\t\"movq \"MANGLE(w1111)\", %%mm5\t\t\\n\\t\"\n\n\t\t\"psrlw $2, %%mm4\t\t\\n\\t\"\n\n\t\t\"psrlw $2, %%mm2\t\t\\n\\t\"\n\n#endif\n\n\t\t\"movq \"MANGLE(bgr2VCoeff)\", %%mm1\t\t\\n\\t\"\n\n\t\t\"movq \"MANGLE(bgr2VCoeff)\", %%mm3\t\t\\n\\t\"\n\n\t\t\n\n\t\t\"pmaddwd %%mm4, %%mm1\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm2, %%mm3\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm6, %%mm4\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm6, %%mm2\t\t\\n\\t\"\n\n#ifndef FAST_BGR2YV12\n\n\t\t\"psrad $8, %%mm4\t\t\\n\\t\"\n\n\t\t\"psrad $8, %%mm1\t\t\\n\\t\"\n\n\t\t\"psrad $8, %%mm2\t\t\\n\\t\"\n\n\t\t\"psrad $8, %%mm3\t\t\\n\\t\"\n\n#endif\n\n\t\t\"packssdw %%mm2, %%mm4\t\t\\n\\t\"\n\n\t\t\"packssdw %%mm3, %%mm1\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm5, %%mm4\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm5, %%mm1\t\t\\n\\t\"\n\n\t\t\"add $24, %%\"REG_b\"\t\t\\n\\t\"\n\n\t\t\"packssdw %%mm1, %%mm4\t\t\\n\\t\" // V3 V2 U3 U2\n\n\t\t\"psraw $7, %%mm4\t\t\\n\\t\"\n\n\t\t\n\n\t\t\"movq %%mm0, %%mm1\t\t\\n\\t\"\n\n\t\t\"punpckldq %%mm4, %%mm0\t\t\\n\\t\"\n\n\t\t\"punpckhdq %%mm4, %%mm1\t\t\\n\\t\"\n\n\t\t\"packsswb %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\"paddb \"MANGLE(bgr2UVOffset)\", %%mm0\t\\n\\t\"\n\n\n\n\t\t\"movd %%mm0, (%2, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\"punpckhdq %%mm0, %%mm0\t\t\\n\\t\"\n\n\t\t\"movd %%mm0, (%3, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\"add $4, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\" js 1b\t\t\t\t\\n\\t\"\n\n\t\t: : \"r\" (src1+width*6), \"r\" (src2+width*6), \"r\" (dstU+width), \"r\" (dstV+width), \"g\" (-width)\n\n\t\t: \"%\"REG_a, \"%\"REG_b\n\n\t);\n\n#else\n\n\tint i;\n\n\tfor(i=0; i<width; i++)\n\n\t{\n\n\t\tint b= src1[6*i + 0] + src1[6*i + 3] + src2[6*i + 0] + src2[6*i + 3];\n\n\t\tint g= src1[6*i + 1] + src1[6*i + 4] + src2[6*i + 1] + src2[6*i + 4];\n\n\t\tint r= src1[6*i + 2] + src1[6*i + 5] + src2[6*i + 2] + src2[6*i + 5];\n\n\n\n\t\tdstU[i]= ((RU*r + GU*g + BU*b)>>(RGB2YUV_SHIFT+2)) + 128;\n\n\t\tdstV[i]= ((RV*r + GV*g + BV*b)>>(RGB2YUV_SHIFT+2)) + 128;\n\n\t}\n\n#endif\n\n}\n", "idx": 24963}
{"project": "FFmpeg", "commit_id": "b04af34600d01502ac844551d157d83f7ae5db26", "target": 0, "func": "static av_cold int fbdev_write_header(AVFormatContext *h)\n\n{\n\n    FBDevContext *fbdev = h->priv_data;\n\n    enum AVPixelFormat pix_fmt;\n\n    AVStream *st = NULL;\n\n    int ret, flags = O_RDWR;\n\n    int i;\n\n\n\n    for (i = 0; i < h->nb_streams; i++) {\n\n        if (h->streams[i]->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            if (!st) {\n\n                fbdev->index = i;\n\n                st = h->streams[i];\n\n            } else {\n\n                av_log(h, AV_LOG_WARNING, \"More than one video stream found. First one is used.\\n\");\n\n                break;\n\n            }\n\n        }\n\n    }\n\n    if (!st) {\n\n        av_log(h, AV_LOG_ERROR, \"No video stream found.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if ((fbdev->fd = avpriv_open(h->filename, flags)) == -1) {\n\n        ret = AVERROR(errno);\n\n        av_log(h, AV_LOG_ERROR,\n\n               \"Could not open framebuffer device '%s': %s\\n\",\n\n               h->filename, av_err2str(ret));\n\n        return ret;\n\n    }\n\n\n\n    if (ioctl(fbdev->fd, FBIOGET_VSCREENINFO, &fbdev->varinfo) < 0) {\n\n        ret = AVERROR(errno);\n\n        av_log(h, AV_LOG_ERROR, \"FBIOGET_VSCREENINFO: %s\\n\", av_err2str(ret));\n\n        goto fail;\n\n    }\n\n\n\n    if (ioctl(fbdev->fd, FBIOGET_FSCREENINFO, &fbdev->fixinfo) < 0) {\n\n        ret = AVERROR(errno);\n\n        av_log(h, AV_LOG_ERROR, \"FBIOGET_FSCREENINFO: %s\\n\", av_err2str(ret));\n\n        goto fail;\n\n    }\n\n\n\n    pix_fmt = ff_get_pixfmt_from_fb_varinfo(&fbdev->varinfo);\n\n    if (pix_fmt == AV_PIX_FMT_NONE) {\n\n        ret = AVERROR(EINVAL);\n\n        av_log(h, AV_LOG_ERROR, \"Framebuffer pixel format not supported.\\n\");\n\n        goto fail;\n\n    }\n\n\n\n    fbdev->data = mmap(NULL, fbdev->fixinfo.smem_len, PROT_WRITE, MAP_SHARED, fbdev->fd, 0);\n\n    if (fbdev->data == MAP_FAILED) {\n\n        ret = AVERROR(errno);\n\n        av_log(h, AV_LOG_ERROR, \"Error in mmap(): %s\\n\", av_err2str(ret));\n\n        goto fail;\n\n    }\n\n\n\n    return 0;\n\n  fail:\n\n    close(fbdev->fd);\n\n    return ret;\n\n}\n", "idx": 24964}
{"project": "FFmpeg", "commit_id": "985688b8e597b616246746a16649653db6dcf023", "target": 1, "func": "static int mov_write_hdlr_tag(ByteIOContext *pb, MOVTrack *track)\n\n{\n\n    const char *descr, *hdlr, *hdlr_type;\n\n    int64_t pos = url_ftell(pb);\n\n\n\n    if (!track) { /* no media --> data handler */\n\n        hdlr = \"dhlr\";\n\n        hdlr_type = \"url \";\n\n        descr = \"DataHandler\";\n\n    } else {\n\n        hdlr = (track->mode == MODE_MOV) ? \"mhlr\" : \"\\0\\0\\0\\0\";\n\n        if (track->enc->codec_type == CODEC_TYPE_VIDEO) {\n\n            hdlr_type = \"vide\";\n\n            descr = \"VideoHandler\";\n\n        } else if (track->enc->codec_type == CODEC_TYPE_AUDIO){\n\n            hdlr_type = \"soun\";\n\n            descr = \"SoundHandler\";\n\n        } else if (track->enc->codec_type == CODEC_TYPE_SUBTITLE){\n\n            if (track->mode == MODE_IPOD) hdlr_type = \"sbtl\";\n\n            else                          hdlr_type = \"text\";\n\n            descr = \"SubtitleHandler\";\n\n        }\n\n    }\n\n\n\n    put_be32(pb, 0); /* size */\n\n    put_tag(pb, \"hdlr\");\n\n    put_be32(pb, 0); /* Version & flags */\n\n    put_buffer(pb, hdlr, 4); /* handler */\n\n    put_tag(pb, hdlr_type); /* handler type */\n\n    put_be32(pb ,0); /* reserved */\n\n    put_be32(pb ,0); /* reserved */\n\n    put_be32(pb ,0); /* reserved */\n\n    put_byte(pb, strlen(descr)); /* string counter */\n\n    put_buffer(pb, descr, strlen(descr)); /* handler description */\n\n    return updateSize(pb, pos);\n\n}\n", "idx": 24966}
{"project": "FFmpeg", "commit_id": "3b175384bb6491ecd44761e5282ae4c79567db57", "target": 0, "func": "static int swScale(SwsContext *c, const uint8_t *src[],\n\n                   int srcStride[], int srcSliceY,\n\n                   int srcSliceH, uint8_t *dst[], int dstStride[])\n\n{\n\n    /* load a few things into local vars to make the code more readable?\n\n     * and faster */\n\n    const int srcW                   = c->srcW;\n\n    const int dstW                   = c->dstW;\n\n    const int dstH                   = c->dstH;\n\n    const int chrDstW                = c->chrDstW;\n\n    const int chrSrcW                = c->chrSrcW;\n\n    const int lumXInc                = c->lumXInc;\n\n    const int chrXInc                = c->chrXInc;\n\n    const enum PixelFormat dstFormat = c->dstFormat;\n\n    const int flags                  = c->flags;\n\n    int32_t *vLumFilterPos           = c->vLumFilterPos;\n\n    int32_t *vChrFilterPos           = c->vChrFilterPos;\n\n    int32_t *hLumFilterPos           = c->hLumFilterPos;\n\n    int32_t *hChrFilterPos           = c->hChrFilterPos;\n\n    int16_t *vLumFilter              = c->vLumFilter;\n\n    int16_t *vChrFilter              = c->vChrFilter;\n\n    int16_t *hLumFilter              = c->hLumFilter;\n\n    int16_t *hChrFilter              = c->hChrFilter;\n\n    int32_t *lumMmxFilter            = c->lumMmxFilter;\n\n    int32_t *chrMmxFilter            = c->chrMmxFilter;\n\n    const int vLumFilterSize         = c->vLumFilterSize;\n\n    const int vChrFilterSize         = c->vChrFilterSize;\n\n    const int hLumFilterSize         = c->hLumFilterSize;\n\n    const int hChrFilterSize         = c->hChrFilterSize;\n\n    int16_t **lumPixBuf              = c->lumPixBuf;\n\n    int16_t **chrUPixBuf             = c->chrUPixBuf;\n\n    int16_t **chrVPixBuf             = c->chrVPixBuf;\n\n    int16_t **alpPixBuf              = c->alpPixBuf;\n\n    const int vLumBufSize            = c->vLumBufSize;\n\n    const int vChrBufSize            = c->vChrBufSize;\n\n    uint8_t *formatConvBuffer        = c->formatConvBuffer;\n\n    uint32_t *pal                    = c->pal_yuv;\n\n    yuv2planar1_fn yuv2plane1        = c->yuv2plane1;\n\n    yuv2planarX_fn yuv2planeX        = c->yuv2planeX;\n\n    yuv2interleavedX_fn yuv2nv12cX   = c->yuv2nv12cX;\n\n    yuv2packed1_fn yuv2packed1       = c->yuv2packed1;\n\n    yuv2packed2_fn yuv2packed2       = c->yuv2packed2;\n\n    yuv2packedX_fn yuv2packedX       = c->yuv2packedX;\n\n    const int chrSrcSliceY           =     srcSliceY  >> c->chrSrcVSubSample;\n\n    const int chrSrcSliceH           = -((-srcSliceH) >> c->chrSrcVSubSample);\n\n    int should_dither                = is9_OR_10BPS(c->srcFormat) ||\n\n                                       is16BPS(c->srcFormat);\n\n    int lastDstY;\n\n\n\n    /* vars which will change and which we need to store back in the context */\n\n    int dstY         = c->dstY;\n\n    int lumBufIndex  = c->lumBufIndex;\n\n    int chrBufIndex  = c->chrBufIndex;\n\n    int lastInLumBuf = c->lastInLumBuf;\n\n    int lastInChrBuf = c->lastInChrBuf;\n\n\n\n    if (isPacked(c->srcFormat)) {\n\n        src[0] =\n\n        src[1] =\n\n        src[2] =\n\n        src[3] = src[0];\n\n        srcStride[0] =\n\n        srcStride[1] =\n\n        srcStride[2] =\n\n        srcStride[3] = srcStride[0];\n\n    }\n\n    srcStride[1] <<= c->vChrDrop;\n\n    srcStride[2] <<= c->vChrDrop;\n\n\n\n    DEBUG_BUFFERS(\"swScale() %p[%d] %p[%d] %p[%d] %p[%d] -> %p[%d] %p[%d] %p[%d] %p[%d]\\n\",\n\n                  src[0], srcStride[0], src[1], srcStride[1],\n\n                  src[2], srcStride[2], src[3], srcStride[3],\n\n                  dst[0], dstStride[0], dst[1], dstStride[1],\n\n                  dst[2], dstStride[2], dst[3], dstStride[3]);\n\n    DEBUG_BUFFERS(\"srcSliceY: %d srcSliceH: %d dstY: %d dstH: %d\\n\",\n\n                  srcSliceY, srcSliceH, dstY, dstH);\n\n    DEBUG_BUFFERS(\"vLumFilterSize: %d vLumBufSize: %d vChrFilterSize: %d vChrBufSize: %d\\n\",\n\n                  vLumFilterSize, vLumBufSize, vChrFilterSize, vChrBufSize);\n\n\n\n    if (dstStride[0] % 8 != 0 || dstStride[1] % 8 != 0 ||\n\n        dstStride[2] % 8 != 0 || dstStride[3] % 8 != 0) {\n\n        static int warnedAlready = 0; // FIXME maybe move this into the context\n\n        if (flags & SWS_PRINT_INFO && !warnedAlready) {\n\n            av_log(c, AV_LOG_WARNING,\n\n                   \"Warning: dstStride is not aligned!\\n\"\n\n                   \"         ->cannot do aligned memory accesses anymore\\n\");\n\n            warnedAlready = 1;\n\n        }\n\n    }\n\n\n\n    /* Note the user might start scaling the picture in the middle so this\n\n     * will not get executed. This is not really intended but works\n\n     * currently, so people might do it. */\n\n    if (srcSliceY == 0) {\n\n        lumBufIndex  = -1;\n\n        chrBufIndex  = -1;\n\n        dstY         = 0;\n\n        lastInLumBuf = -1;\n\n        lastInChrBuf = -1;\n\n    }\n\n\n\n    if (!should_dither) {\n\n        c->chrDither8 = c->lumDither8 = ff_sws_pb_64;\n\n    }\n\n    lastDstY = dstY;\n\n\n\n    for (; dstY < dstH; dstY++) {\n\n        const int chrDstY = dstY >> c->chrDstVSubSample;\n\n        uint8_t *dest[4]  = {\n\n            dst[0] + dstStride[0] * dstY,\n\n            dst[1] + dstStride[1] * chrDstY,\n\n            dst[2] + dstStride[2] * chrDstY,\n\n            (CONFIG_SWSCALE_ALPHA && alpPixBuf) ? dst[3] + dstStride[3] * dstY : NULL,\n\n        };\n\n\n\n        // First line needed as input\n\n        const int firstLumSrcY  = FFMAX(1 - vLumFilterSize, vLumFilterPos[dstY]);\n\n        const int firstLumSrcY2 = FFMAX(1 - vLumFilterSize, vLumFilterPos[FFMIN(dstY | ((1 << c->chrDstVSubSample) - 1), dstH - 1)]);\n\n        // First line needed as input\n\n        const int firstChrSrcY  = FFMAX(1 - vChrFilterSize, vChrFilterPos[chrDstY]);\n\n\n\n        // Last line needed as input\n\n        int lastLumSrcY  = FFMIN(c->srcH,    firstLumSrcY  + vLumFilterSize) - 1;\n\n        int lastLumSrcY2 = FFMIN(c->srcH,    firstLumSrcY2 + vLumFilterSize) - 1;\n\n        int lastChrSrcY  = FFMIN(c->chrSrcH, firstChrSrcY  + vChrFilterSize) - 1;\n\n        int enough_lines;\n\n\n\n        // handle holes (FAST_BILINEAR & weird filters)\n\n        if (firstLumSrcY > lastInLumBuf)\n\n            lastInLumBuf = firstLumSrcY - 1;\n\n        if (firstChrSrcY > lastInChrBuf)\n\n            lastInChrBuf = firstChrSrcY - 1;\n\n        assert(firstLumSrcY >= lastInLumBuf - vLumBufSize + 1);\n\n        assert(firstChrSrcY >= lastInChrBuf - vChrBufSize + 1);\n\n\n\n        DEBUG_BUFFERS(\"dstY: %d\\n\", dstY);\n\n        DEBUG_BUFFERS(\"\\tfirstLumSrcY: %d lastLumSrcY: %d lastInLumBuf: %d\\n\",\n\n                      firstLumSrcY, lastLumSrcY, lastInLumBuf);\n\n        DEBUG_BUFFERS(\"\\tfirstChrSrcY: %d lastChrSrcY: %d lastInChrBuf: %d\\n\",\n\n                      firstChrSrcY, lastChrSrcY, lastInChrBuf);\n\n\n\n        // Do we have enough lines in this slice to output the dstY line\n\n        enough_lines = lastLumSrcY2 < srcSliceY + srcSliceH &&\n\n                       lastChrSrcY < -((-srcSliceY - srcSliceH) >> c->chrSrcVSubSample);\n\n\n\n        if (!enough_lines) {\n\n            lastLumSrcY = srcSliceY + srcSliceH - 1;\n\n            lastChrSrcY = chrSrcSliceY + chrSrcSliceH - 1;\n\n            DEBUG_BUFFERS(\"buffering slice: lastLumSrcY %d lastChrSrcY %d\\n\",\n\n                          lastLumSrcY, lastChrSrcY);\n\n        }\n\n\n\n        // Do horizontal scaling\n\n        while (lastInLumBuf < lastLumSrcY) {\n\n            const uint8_t *src1[4] = {\n\n                src[0] + (lastInLumBuf + 1 - srcSliceY) * srcStride[0],\n\n                src[1] + (lastInLumBuf + 1 - srcSliceY) * srcStride[1],\n\n                src[2] + (lastInLumBuf + 1 - srcSliceY) * srcStride[2],\n\n                src[3] + (lastInLumBuf + 1 - srcSliceY) * srcStride[3],\n\n            };\n\n            lumBufIndex++;\n\n            assert(lumBufIndex < 2 * vLumBufSize);\n\n            assert(lastInLumBuf + 1 - srcSliceY < srcSliceH);\n\n            assert(lastInLumBuf + 1 - srcSliceY >= 0);\n\n            hyscale(c, lumPixBuf[lumBufIndex], dstW, src1, srcW, lumXInc,\n\n                    hLumFilter, hLumFilterPos, hLumFilterSize,\n\n                    formatConvBuffer, pal, 0);\n\n            if (CONFIG_SWSCALE_ALPHA && alpPixBuf)\n\n                hyscale(c, alpPixBuf[lumBufIndex], dstW, src1, srcW,\n\n                        lumXInc, hLumFilter, hLumFilterPos, hLumFilterSize,\n\n                        formatConvBuffer, pal, 1);\n\n            lastInLumBuf++;\n\n            DEBUG_BUFFERS(\"\\t\\tlumBufIndex %d: lastInLumBuf: %d\\n\",\n\n                          lumBufIndex, lastInLumBuf);\n\n        }\n\n        while (lastInChrBuf < lastChrSrcY) {\n\n            const uint8_t *src1[4] = {\n\n                src[0] + (lastInChrBuf + 1 - chrSrcSliceY) * srcStride[0],\n\n                src[1] + (lastInChrBuf + 1 - chrSrcSliceY) * srcStride[1],\n\n                src[2] + (lastInChrBuf + 1 - chrSrcSliceY) * srcStride[2],\n\n                src[3] + (lastInChrBuf + 1 - chrSrcSliceY) * srcStride[3],\n\n            };\n\n            chrBufIndex++;\n\n            assert(chrBufIndex < 2 * vChrBufSize);\n\n            assert(lastInChrBuf + 1 - chrSrcSliceY < (chrSrcSliceH));\n\n            assert(lastInChrBuf + 1 - chrSrcSliceY >= 0);\n\n            // FIXME replace parameters through context struct (some at least)\n\n\n\n            if (c->needs_hcscale)\n\n                hcscale(c, chrUPixBuf[chrBufIndex], chrVPixBuf[chrBufIndex],\n\n                        chrDstW, src1, chrSrcW, chrXInc,\n\n                        hChrFilter, hChrFilterPos, hChrFilterSize,\n\n                        formatConvBuffer, pal);\n\n            lastInChrBuf++;\n\n            DEBUG_BUFFERS(\"\\t\\tchrBufIndex %d: lastInChrBuf: %d\\n\",\n\n                          chrBufIndex, lastInChrBuf);\n\n        }\n\n        // wrap buf index around to stay inside the ring buffer\n\n        if (lumBufIndex >= vLumBufSize)\n\n            lumBufIndex -= vLumBufSize;\n\n        if (chrBufIndex >= vChrBufSize)\n\n            chrBufIndex -= vChrBufSize;\n\n        if (!enough_lines)\n\n            break;  // we can't output a dstY line so let's try with the next slice\n\n\n\n#if HAVE_MMX\n\n        updateMMXDitherTables(c, dstY, lumBufIndex, chrBufIndex,\n\n                              lastInLumBuf, lastInChrBuf);\n\n#endif\n\n        if (should_dither) {\n\n            c->chrDither8 = dither_8x8_128[chrDstY & 7];\n\n            c->lumDither8 = dither_8x8_128[dstY    & 7];\n\n        }\n\n        if (dstY >= dstH - 2) {\n\n            /* hmm looks like we can't use MMX here without overwriting\n\n             * this array's tail */\n\n            ff_sws_init_output_funcs(c, &yuv2plane1, &yuv2planeX, &yuv2nv12cX,\n\n                                     &yuv2packed1, &yuv2packed2, &yuv2packedX);\n\n        }\n\n\n\n        {\n\n            const int16_t **lumSrcPtr  = (const int16_t **)lumPixBuf  + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n            const int16_t **chrUSrcPtr = (const int16_t **)chrUPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n            const int16_t **chrVSrcPtr = (const int16_t **)chrVPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n            const int16_t **alpSrcPtr  = (CONFIG_SWSCALE_ALPHA && alpPixBuf) ?\n\n                                         (const int16_t **)alpPixBuf  + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize : NULL;\n\n\n\n            if (firstLumSrcY < 0 || firstLumSrcY + vLumFilterSize > c->srcH) {\n\n                const int16_t **tmpY = (const int16_t **)lumPixBuf +\n\n                                       2 * vLumBufSize;\n\n                int neg = -firstLumSrcY, i;\n\n                int end = FFMIN(c->srcH - firstLumSrcY, vLumFilterSize);\n\n                for (i = 0; i < neg; i++)\n\n                    tmpY[i] = lumSrcPtr[neg];\n\n                for (; i < end; i++)\n\n                    tmpY[i] = lumSrcPtr[i];\n\n                for (; i < vLumFilterSize; i++)\n\n                    tmpY[i] = tmpY[i - 1];\n\n                lumSrcPtr = tmpY;\n\n\n\n                if (alpSrcPtr) {\n\n                    const int16_t **tmpA = (const int16_t **)alpPixBuf +\n\n                                           2 * vLumBufSize;\n\n                    for (i = 0; i < neg; i++)\n\n                        tmpA[i] = alpSrcPtr[neg];\n\n                    for (; i < end; i++)\n\n                        tmpA[i] = alpSrcPtr[i];\n\n                    for (; i < vLumFilterSize; i++)\n\n                        tmpA[i] = tmpA[i - 1];\n\n                    alpSrcPtr = tmpA;\n\n                }\n\n            }\n\n            if (firstChrSrcY < 0 ||\n\n                firstChrSrcY + vChrFilterSize > c->chrSrcH) {\n\n                const int16_t **tmpU = (const int16_t **)chrUPixBuf + 2 * vChrBufSize,\n\n                **tmpV               = (const int16_t **)chrVPixBuf + 2 * vChrBufSize;\n\n                int neg = -firstChrSrcY, i;\n\n                int end = FFMIN(c->chrSrcH - firstChrSrcY, vChrFilterSize);\n\n                for (i = 0; i < neg; i++) {\n\n                    tmpU[i] = chrUSrcPtr[neg];\n\n                    tmpV[i] = chrVSrcPtr[neg];\n\n                }\n\n                for (; i < end; i++) {\n\n                    tmpU[i] = chrUSrcPtr[i];\n\n                    tmpV[i] = chrVSrcPtr[i];\n\n                }\n\n                for (; i < vChrFilterSize; i++) {\n\n                    tmpU[i] = tmpU[i - 1];\n\n                    tmpV[i] = tmpV[i - 1];\n\n                }\n\n                chrUSrcPtr = tmpU;\n\n                chrVSrcPtr = tmpV;\n\n            }\n\n\n\n            if (isPlanarYUV(dstFormat) ||\n\n                (isGray(dstFormat) && !isALPHA(dstFormat))) { // YV12 like\n\n                const int chrSkipMask = (1 << c->chrDstVSubSample) - 1;\n\n\n\n                if (vLumFilterSize == 1) {\n\n                    yuv2plane1(lumSrcPtr[0], dest[0], dstW, c->lumDither8, 0);\n\n                } else {\n\n                    yuv2planeX(vLumFilter + dstY * vLumFilterSize,\n\n                               vLumFilterSize, lumSrcPtr, dest[0],\n\n                               dstW, c->lumDither8, 0);\n\n                }\n\n\n\n                if (!((dstY & chrSkipMask) || isGray(dstFormat))) {\n\n                    if (yuv2nv12cX) {\n\n                        yuv2nv12cX(c, vChrFilter + chrDstY * vChrFilterSize,\n\n                                   vChrFilterSize, chrUSrcPtr, chrVSrcPtr,\n\n                                   dest[1], chrDstW);\n\n                    } else if (vChrFilterSize == 1) {\n\n                        yuv2plane1(chrUSrcPtr[0], dest[1], chrDstW, c->chrDither8, 0);\n\n                        yuv2plane1(chrVSrcPtr[0], dest[2], chrDstW, c->chrDither8, 3);\n\n                    } else {\n\n                        yuv2planeX(vChrFilter + chrDstY * vChrFilterSize,\n\n                                   vChrFilterSize, chrUSrcPtr, dest[1],\n\n                                   chrDstW, c->chrDither8, 0);\n\n                        yuv2planeX(vChrFilter + chrDstY * vChrFilterSize,\n\n                                   vChrFilterSize, chrVSrcPtr, dest[2],\n\n                                   chrDstW, c->chrDither8, 3);\n\n                    }\n\n                }\n\n\n\n                if (CONFIG_SWSCALE_ALPHA && alpPixBuf) {\n\n                    if (vLumFilterSize == 1) {\n\n                        yuv2plane1(alpSrcPtr[0], dest[3], dstW,\n\n                                   c->lumDither8, 0);\n\n                    } else {\n\n                        yuv2planeX(vLumFilter + dstY * vLumFilterSize,\n\n                                   vLumFilterSize, alpSrcPtr, dest[3],\n\n                                   dstW, c->lumDither8, 0);\n\n                    }\n\n                }\n\n            } else {\n\n                assert(lumSrcPtr  + vLumFilterSize - 1 < lumPixBuf  + vLumBufSize * 2);\n\n                assert(chrUSrcPtr + vChrFilterSize - 1 < chrUPixBuf + vChrBufSize * 2);\n\n                if (c->yuv2packed1 && vLumFilterSize == 1 &&\n\n                    vChrFilterSize <= 2) { // unscaled RGB\n\n                    int chrAlpha = vChrFilterSize == 1 ? 0 : vChrFilter[2 * dstY + 1];\n\n                    yuv2packed1(c, *lumSrcPtr, chrUSrcPtr, chrVSrcPtr,\n\n                                alpPixBuf ? *alpSrcPtr : NULL,\n\n                                dest[0], dstW, chrAlpha, dstY);\n\n                } else if (c->yuv2packed2 && vLumFilterSize == 2 &&\n\n                           vChrFilterSize == 2) { // bilinear upscale RGB\n\n                    int lumAlpha = vLumFilter[2 * dstY + 1];\n\n                    int chrAlpha = vChrFilter[2 * dstY + 1];\n\n                    lumMmxFilter[2] =\n\n                    lumMmxFilter[3] = vLumFilter[2 * dstY]    * 0x10001;\n\n                    chrMmxFilter[2] =\n\n                    chrMmxFilter[3] = vChrFilter[2 * chrDstY] * 0x10001;\n\n                    yuv2packed2(c, lumSrcPtr, chrUSrcPtr, chrVSrcPtr,\n\n                                alpPixBuf ? alpSrcPtr : NULL,\n\n                                dest[0], dstW, lumAlpha, chrAlpha, dstY);\n\n                } else { // general RGB\n\n                    yuv2packedX(c, vLumFilter + dstY * vLumFilterSize,\n\n                                lumSrcPtr, vLumFilterSize,\n\n                                vChrFilter + dstY * vChrFilterSize,\n\n                                chrUSrcPtr, chrVSrcPtr, vChrFilterSize,\n\n                                alpSrcPtr, dest[0], dstW, dstY);\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    if (isPlanar(dstFormat) && isALPHA(dstFormat) && !alpPixBuf)\n\n        fillPlane(dst[3], dstStride[3], dstW, dstY - lastDstY, lastDstY, 255);\n\n\n\n#if HAVE_MMX2\n\n    if (av_get_cpu_flags() & AV_CPU_FLAG_MMX2)\n\n        __asm__ volatile (\"sfence\" ::: \"memory\");\n\n#endif\n\n    emms_c();\n\n\n\n    /* store changed local vars back in the context */\n\n    c->dstY         = dstY;\n\n    c->lumBufIndex  = lumBufIndex;\n\n    c->chrBufIndex  = chrBufIndex;\n\n    c->lastInLumBuf = lastInLumBuf;\n\n    c->lastInChrBuf = lastInChrBuf;\n\n\n\n    return dstY - lastDstY;\n\n}\n", "idx": 24972}
{"project": "FFmpeg", "commit_id": "9351a156de724edb69ba6e1f05884fe806a13a21", "target": 1, "func": "static inline int spx_strategy(AC3DecodeContext *s, int blk)\n\n{\n\n    GetBitContext *bc = &s->gbc;\n\n    int fbw_channels = s->fbw_channels;\n\n    int dst_start_freq, dst_end_freq, src_start_freq,\n\n        start_subband, end_subband, ch;\n\n\n\n    /* determine which channels use spx */\n\n    if (s->channel_mode == AC3_CHMODE_MONO) {\n\n        s->channel_uses_spx[1] = 1;\n\n    } else {\n\n        for (ch = 1; ch <= fbw_channels; ch++)\n\n            s->channel_uses_spx[ch] = get_bits1(bc);\n\n    }\n\n\n\n    /* get the frequency bins of the spx copy region and the spx start\n\n       and end subbands */\n\n    dst_start_freq = get_bits(bc, 2);\n\n    start_subband  = get_bits(bc, 3) + 2;\n\n    if (start_subband > 7)\n\n        start_subband += start_subband - 7;\n\n    end_subband    = get_bits(bc, 3) + 5;\n\n#if USE_FIXED\n\n    s->spx_dst_end_freq = end_freq_inv_tab[end_subband-5];\n\n#endif\n\n    if (end_subband   > 7)\n\n        end_subband   += end_subband   - 7;\n\n    dst_start_freq = dst_start_freq * 12 + 25;\n\n    src_start_freq = start_subband  * 12 + 25;\n\n    dst_end_freq   = end_subband    * 12 + 25;\n\n\n\n    /* check validity of spx ranges */\n\n    if (start_subband >= end_subband) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"invalid spectral extension \"\n\n               \"range (%d >= %d)\\n\", start_subband, end_subband);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (dst_start_freq >= src_start_freq) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"invalid spectral extension \"\n\n               \"copy start bin (%d >= %d)\\n\", dst_start_freq, src_start_freq);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    s->spx_dst_start_freq = dst_start_freq;\n\n    s->spx_src_start_freq = src_start_freq;\n\n    if (!USE_FIXED)\n\n        s->spx_dst_end_freq   = dst_end_freq;\n\n\n\n    decode_band_structure(bc, blk, s->eac3, 0,\n\n                          start_subband, end_subband,\n\n                          ff_eac3_default_spx_band_struct,\n\n                          &s->num_spx_bands,\n\n                          s->spx_band_sizes);\n\n    return 0;\n\n}\n", "idx": 24973}
{"project": "FFmpeg", "commit_id": "fc78b0cb7e115ae494861c37a9928cff74df8db9", "target": 1, "func": "static void finalize_packet(RTPDemuxContext *s, AVPacket *pkt, uint32_t timestamp)\n\n{\n\n    if (s->last_rtcp_ntp_time != AV_NOPTS_VALUE) {\n\n        int64_t addend;\n\n        int delta_timestamp;\n\n\n\n        /* compute pts from timestamp with received ntp_time */\n\n        delta_timestamp = timestamp - s->last_rtcp_timestamp;\n\n        /* convert to the PTS timebase */\n\n        addend = av_rescale(s->last_rtcp_ntp_time - s->first_rtcp_ntp_time, s->st->time_base.den, (uint64_t)s->st->time_base.num << 32);\n\n        pkt->pts = addend + delta_timestamp;\n\n    }\n\n}\n", "idx": 24975}
{"project": "FFmpeg", "commit_id": "47775cb8de880dfd2f82029d109229ae65aae767", "target": 0, "func": "static av_always_inline void decode_cabac_residual_internal( H264Context *h, DCTELEM *block, int cat, int n, const uint8_t *scantable, const uint32_t *qmul, int max_coeff, int is_dc ) {\n\n    static const int significant_coeff_flag_offset[2][6] = {\n\n      { 105+0, 105+15, 105+29, 105+44, 105+47, 402 },\n\n      { 277+0, 277+15, 277+29, 277+44, 277+47, 436 }\n\n    };\n\n    static const int last_coeff_flag_offset[2][6] = {\n\n      { 166+0, 166+15, 166+29, 166+44, 166+47, 417 },\n\n      { 338+0, 338+15, 338+29, 338+44, 338+47, 451 }\n\n    };\n\n    static const int coeff_abs_level_m1_offset[6] = {\n\n        227+0, 227+10, 227+20, 227+30, 227+39, 426\n\n    };\n\n    static const uint8_t significant_coeff_flag_offset_8x8[2][63] = {\n\n      { 0, 1, 2, 3, 4, 5, 5, 4, 4, 3, 3, 4, 4, 4, 5, 5,\n\n        4, 4, 4, 4, 3, 3, 6, 7, 7, 7, 8, 9,10, 9, 8, 7,\n\n        7, 6,11,12,13,11, 6, 7, 8, 9,14,10, 9, 8, 6,11,\n\n       12,13,11, 6, 9,14,10, 9,11,12,13,11,14,10,12 },\n\n      { 0, 1, 1, 2, 2, 3, 3, 4, 5, 6, 7, 7, 7, 8, 4, 5,\n\n        6, 9,10,10, 8,11,12,11, 9, 9,10,10, 8,11,12,11,\n\n        9, 9,10,10, 8,11,12,11, 9, 9,10,10, 8,13,13, 9,\n\n        9,10,10, 8,13,13, 9, 9,10,10,14,14,14,14,14 }\n\n    };\n\n    /* node ctx: 0..3: abslevel1 (with abslevelgt1 == 0).\n\n     * 4..7: abslevelgt1 + 3 (and abslevel1 doesn't matter).\n\n     * map node ctx => cabac ctx for level=1 */\n\n    static const uint8_t coeff_abs_level1_ctx[8] = { 1, 2, 3, 4, 0, 0, 0, 0 };\n\n    /* map node ctx => cabac ctx for level>1 */\n\n    static const uint8_t coeff_abs_levelgt1_ctx[8] = { 5, 5, 5, 5, 6, 7, 8, 9 };\n\n    static const uint8_t coeff_abs_level_transition[2][8] = {\n\n    /* update node ctx after decoding a level=1 */\n\n        { 1, 2, 3, 3, 4, 5, 6, 7 },\n\n    /* update node ctx after decoding a level>1 */\n\n        { 4, 4, 4, 4, 5, 6, 7, 7 }\n\n    };\n\n\n\n    int index[64];\n\n\n\n    int av_unused last;\n\n    int coeff_count = 0;\n\n    int node_ctx = 0;\n\n\n\n    uint8_t *significant_coeff_ctx_base;\n\n    uint8_t *last_coeff_ctx_base;\n\n    uint8_t *abs_level_m1_ctx_base;\n\n\n\n#ifndef ARCH_X86\n\n#define CABAC_ON_STACK\n\n#endif\n\n#ifdef CABAC_ON_STACK\n\n#define CC &cc\n\n    CABACContext cc;\n\n    cc.range     = h->cabac.range;\n\n    cc.low       = h->cabac.low;\n\n    cc.bytestream= h->cabac.bytestream;\n\n#else\n\n#define CC &h->cabac\n\n#endif\n\n\n\n\n\n    /* cat: 0-> DC 16x16  n = 0\n\n     *      1-> AC 16x16  n = luma4x4idx\n\n     *      2-> Luma4x4   n = luma4x4idx\n\n     *      3-> DC Chroma n = iCbCr\n\n     *      4-> AC Chroma n = 4 * iCbCr + chroma4x4idx\n\n     *      5-> Luma8x8   n = 4 * luma8x8idx\n\n     */\n\n\n\n    /* read coded block flag */\n\n    if( is_dc || cat != 5 ) {\n\n        if( get_cabac( CC, &h->cabac_state[85 + get_cabac_cbf_ctx( h, cat, n, is_dc ) ] ) == 0 ) {\n\n            if( !is_dc ) {\n\n                if( cat == 1 || cat == 2 )\n\n                    h->non_zero_count_cache[scan8[n]] = 0;\n\n                else\n\n                    h->non_zero_count_cache[scan8[16+n]] = 0;\n\n            }\n\n\n\n#ifdef CABAC_ON_STACK\n\n            h->cabac.range     = cc.range     ;\n\n            h->cabac.low       = cc.low       ;\n\n            h->cabac.bytestream= cc.bytestream;\n\n#endif\n\n            return;\n\n        }\n\n    }\n\n\n\n    significant_coeff_ctx_base = h->cabac_state\n\n        + significant_coeff_flag_offset[MB_FIELD][cat];\n\n    last_coeff_ctx_base = h->cabac_state\n\n        + last_coeff_flag_offset[MB_FIELD][cat];\n\n    abs_level_m1_ctx_base = h->cabac_state\n\n        + coeff_abs_level_m1_offset[cat];\n\n\n\n    if( !is_dc && cat == 5 ) {\n\n#define DECODE_SIGNIFICANCE( coefs, sig_off, last_off ) \\\n\n        for(last= 0; last < coefs; last++) { \\\n\n            uint8_t *sig_ctx = significant_coeff_ctx_base + sig_off; \\\n\n            if( get_cabac( CC, sig_ctx )) { \\\n\n                uint8_t *last_ctx = last_coeff_ctx_base + last_off; \\\n\n                index[coeff_count++] = last; \\\n\n                if( get_cabac( CC, last_ctx ) ) { \\\n\n                    last= max_coeff; \\\n\n                    break; \\\n\n                } \\\n\n            } \\\n\n        }\\\n\n        if( last == max_coeff -1 ) {\\\n\n            index[coeff_count++] = last;\\\n\n        }\n\n        const uint8_t *sig_off = significant_coeff_flag_offset_8x8[MB_FIELD];\n\n#if defined(ARCH_X86) && defined(HAVE_7REGS) && defined(HAVE_EBX_AVAILABLE) && !defined(BROKEN_RELOCATIONS)\n\n        coeff_count= decode_significance_8x8_x86(CC, significant_coeff_ctx_base, index, sig_off);\n\n    } else {\n\n        coeff_count= decode_significance_x86(CC, max_coeff, significant_coeff_ctx_base, index);\n\n#else\n\n        DECODE_SIGNIFICANCE( 63, sig_off[last], last_coeff_flag_offset_8x8[last] );\n\n    } else {\n\n        DECODE_SIGNIFICANCE( max_coeff - 1, last, last );\n\n#endif\n\n    }\n\n    assert(coeff_count > 0);\n\n\n\n    if( is_dc ) {\n\n        if( cat == 0 )\n\n            h->cbp_table[h->mb_xy] |= 0x100;\n\n        else\n\n            h->cbp_table[h->mb_xy] |= 0x40 << n;\n\n    } else {\n\n        if( cat == 1 || cat == 2 )\n\n            h->non_zero_count_cache[scan8[n]] = coeff_count;\n\n        else if( cat == 4 )\n\n            h->non_zero_count_cache[scan8[16+n]] = coeff_count;\n\n        else {\n\n            assert( cat == 5 );\n\n            fill_rectangle(&h->non_zero_count_cache[scan8[n]], 2, 2, 8, coeff_count, 1);\n\n        }\n\n    }\n\n\n\n    for( coeff_count--; coeff_count >= 0; coeff_count-- ) {\n\n        uint8_t *ctx = coeff_abs_level1_ctx[node_ctx] + abs_level_m1_ctx_base;\n\n\n\n        int j= scantable[index[coeff_count]];\n\n\n\n        if( get_cabac( CC, ctx ) == 0 ) {\n\n            node_ctx = coeff_abs_level_transition[0][node_ctx];\n\n            if( is_dc ) {\n\n                block[j] = get_cabac_bypass_sign( CC, -1);\n\n            }else{\n\n                block[j] = (get_cabac_bypass_sign( CC, -qmul[j]) + 32) >> 6;\n\n            }\n\n        } else {\n\n            int coeff_abs = 2;\n\n            ctx = coeff_abs_levelgt1_ctx[node_ctx] + abs_level_m1_ctx_base;\n\n            node_ctx = coeff_abs_level_transition[1][node_ctx];\n\n\n\n            while( coeff_abs < 15 && get_cabac( CC, ctx ) ) {\n\n                coeff_abs++;\n\n            }\n\n\n\n            if( coeff_abs >= 15 ) {\n\n                int j = 0;\n\n                while( get_cabac_bypass( CC ) ) {\n\n                    j++;\n\n                }\n\n\n\n                coeff_abs=1;\n\n                while( j-- ) {\n\n                    coeff_abs += coeff_abs + get_cabac_bypass( CC );\n\n                }\n\n                coeff_abs+= 14;\n\n            }\n\n\n\n            if( is_dc ) {\n\n                if( get_cabac_bypass( CC ) ) block[j] = -coeff_abs;\n\n                else                                block[j] =  coeff_abs;\n\n            }else{\n\n                if( get_cabac_bypass( CC ) ) block[j] = (-coeff_abs * qmul[j] + 32) >> 6;\n\n                else                                block[j] = ( coeff_abs * qmul[j] + 32) >> 6;\n\n            }\n\n        }\n\n    }\n\n#ifdef CABAC_ON_STACK\n\n            h->cabac.range     = cc.range     ;\n\n            h->cabac.low       = cc.low       ;\n\n            h->cabac.bytestream= cc.bytestream;\n\n#endif\n\n\n\n}\n", "idx": 24976}
{"project": "FFmpeg", "commit_id": "dd561441b1e849df7d8681c6f32af82d4088dafd", "target": 0, "func": "static void h264_v_loop_filter_chroma_intra_c(uint8_t *pix, int stride, int alpha, int beta)\n\n{\n\n    h264_loop_filter_chroma_intra_c(pix, stride, 1, alpha, beta);\n\n}\n", "idx": 24977}
{"project": "FFmpeg", "commit_id": "26ce266e3df8d50b0e6b3b402f2436903424c30c", "target": 0, "func": "static void mpc8_parse_seektable(AVFormatContext *s, int64_t off)\n\n{\n\n    MPCContext *c = s->priv_data;\n\n    int tag;\n\n    int64_t size, pos, ppos[2];\n\n    uint8_t *buf;\n\n    int i, t, seekd;\n\n    GetBitContext gb;\n\n\n\n    if (s->nb_streams == 0) {\n\n        av_log(s, AV_LOG_ERROR, \"No stream added before parsing seek table\\n\");\n\n        return;\n\n    }\n\n\n\n    avio_seek(s->pb, off, SEEK_SET);\n\n    mpc8_get_chunk_header(s->pb, &tag, &size);\n\n    if(tag != TAG_SEEKTABLE){\n\n        av_log(s, AV_LOG_ERROR, \"No seek table at given position\\n\");\n\n        return;\n\n    }\n\n    if (size > INT_MAX/10 || size<=0) {\n\n        av_log(s, AV_LOG_ERROR, \"Bad seek table size\\n\");\n\n        return;\n\n    }\n\n    if(!(buf = av_malloc(size + FF_INPUT_BUFFER_PADDING_SIZE)))\n\n        return;\n\n    avio_read(s->pb, buf, size);\n\n    memset(buf+size, 0, FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n    init_get_bits(&gb, buf, size * 8);\n\n    size = gb_get_v(&gb);\n\n    if(size > UINT_MAX/4 || size > c->samples/1152){\n\n        av_log(s, AV_LOG_ERROR, \"Seek table is too big\\n\");\n\n        return;\n\n    }\n\n    seekd = get_bits(&gb, 4);\n\n    for(i = 0; i < 2; i++){\n\n        pos = gb_get_v(&gb) + c->header_pos;\n\n        ppos[1 - i] = pos;\n\n        av_add_index_entry(s->streams[0], pos, i, 0, 0, AVINDEX_KEYFRAME);\n\n    }\n\n    for(; i < size; i++){\n\n        t = get_unary(&gb, 1, 33) << 12;\n\n        t += get_bits(&gb, 12);\n\n        if(t & 1)\n\n            t = -(t & ~1);\n\n        pos = (t >> 1) + ppos[0]*2 - ppos[1];\n\n        av_add_index_entry(s->streams[0], pos, i << seekd, 0, 0, AVINDEX_KEYFRAME);\n\n        ppos[1] = ppos[0];\n\n        ppos[0] = pos;\n\n    }\n\n    av_free(buf);\n\n}\n", "idx": 24978}
{"project": "FFmpeg", "commit_id": "e71ca21f308432cac3deaabe522ac1b856471162", "target": 1, "func": "static av_always_inline int small_diamond_search(MpegEncContext * s, int *best, int dmin,\n\n                                       int src_index, int ref_index, int const penalty_factor,\n\n                                       int size, int h, int flags)\n\n{\n\n    MotionEstContext * const c= &s->me;\n\n    me_cmp_func cmpf, chroma_cmpf;\n\n    int next_dir=-1;\n\n    LOAD_COMMON\n\n    LOAD_COMMON2\n\n    unsigned map_generation = c->map_generation;\n\n\n\n    cmpf        = s->mecc.me_cmp[size];\n\n    chroma_cmpf = s->mecc.me_cmp[size + 1];\n\n\n\n    { /* ensure that the best point is in the MAP as h/qpel refinement needs it */\n\n        const unsigned key = (best[1]<<ME_MAP_MV_BITS) + best[0] + map_generation;\n\n        const int index= ((best[1]<<ME_MAP_SHIFT) + best[0])&(ME_MAP_SIZE-1);\n\n        if(map[index]!=key){ //this will be executed only very rarey\n\n            score_map[index]= cmp(s, best[0], best[1], 0, 0, size, h, ref_index, src_index, cmpf, chroma_cmpf, flags);\n\n            map[index]= key;\n\n        }\n\n    }\n\n\n\n    for(;;){\n\n        int d;\n\n        const int dir= next_dir;\n\n        const int x= best[0];\n\n        const int y= best[1];\n\n        next_dir=-1;\n\n\n\n        if(dir!=2 && x>xmin) CHECK_MV_DIR(x-1, y  , 0)\n\n        if(dir!=3 && y>ymin) CHECK_MV_DIR(x  , y-1, 1)\n\n        if(dir!=0 && x<xmax) CHECK_MV_DIR(x+1, y  , 2)\n\n        if(dir!=1 && y<ymax) CHECK_MV_DIR(x  , y+1, 3)\n\n\n\n        if(next_dir==-1){\n\n            return dmin;\n\n        }\n\n    }\n\n}\n", "idx": 24981}
{"project": "FFmpeg", "commit_id": "0886267e3cc4ce12bcd48b712d8affa8c953bc38", "target": 1, "func": "static void opt_frame_aspect_ratio(const char *arg)\n\n{\n\n    int x = 0, y = 0;\n\n    double ar = 0;\n\n    const char *p;\n\n    char *end;\n\n\n\n    p = strchr(arg, ':');\n\n    if (p) {\n\n        x = strtol(arg, &end, 10);\n\n        if (end == p)\n\n            y = strtol(end+1, &end, 10);\n\n        if (x > 0 && y > 0)\n\n            ar = (double)x / (double)y;\n\n    } else\n\n        ar = strtod(arg, NULL);\n\n\n\n    if (!ar) {\n\n        fprintf(stderr, \"Incorrect aspect ratio specification.\\n\");\n\n        ffmpeg_exit(1);\n\n    }\n\n    frame_aspect_ratio = ar;\n\n\n\n    x = vfilters ? strlen(vfilters) : 0;\n\n    vfilters = av_realloc(vfilters, x+100);\n\n    snprintf(vfilters+x, x+100, \"%csetdar=%f\\n\", x?',':' ', ar);\n\n}\n", "idx": 24984}
{"project": "FFmpeg", "commit_id": "db85d11d9d880c932b13d37b5f1ca2bc9e3a253b", "target": 1, "func": "static int ftp_features(FTPContext *s)\n\n{\n\n    static const char *feat_command        = \"FEAT\\r\\n\";\n\n    static const char *enable_utf8_command = \"OPTS UTF8 ON\\r\\n\";\n\n    static const int feat_codes[] = {211, 0};\n\n    static const int opts_codes[] = {200, 451};\n\n    char *feat;\n\n\n\n    if (ftp_send_command(s, feat_command, feat_codes, &feat) == 211) {\n\n        if (av_stristr(feat, \"UTF8\"))\n\n            ftp_send_command(s, enable_utf8_command, opts_codes, NULL);\n\n    }\n\n    return 0;\n\n}\n", "idx": 24985}
{"project": "FFmpeg", "commit_id": "b51469a0c54b30079eecc4891cc050778f343683", "target": 0, "func": "static int tcp_write(URLContext *h, uint8_t *buf, int size)\n\n{\n\n    TCPContext *s = h->priv_data;\n\n    int ret, size1, fd_max;\n\n    fd_set wfds;\n\n    struct timeval tv;\n\n\n\n    size1 = size;\n\n    while (size > 0) {\n\n        if (url_interrupt_cb())\n\n            return -EINTR;\n\n        fd_max = s->fd;\n\n        FD_ZERO(&wfds);\n\n        FD_SET(s->fd, &wfds);\n\n        tv.tv_sec = 0;\n\n        tv.tv_usec = 100 * 1000;\n\n        select(fd_max + 1, NULL, &wfds, NULL, &tv);\n\n#ifdef __BEOS__\n\n        ret = send(s->fd, buf, size, 0);\n\n#else\n\n        ret = write(s->fd, buf, size);\n\n#endif\n\n        if (ret < 0) {\n\n            if (errno != EINTR && errno != EAGAIN) {\n\n#ifdef __BEOS__\n\n                return errno;\n\n#else\n\n                return -errno;\n\n#endif\n\n            }\n\n            continue;\n\n        }\n\n        size -= ret;\n\n        buf += ret;\n\n    }\n\n    return size1 - size;\n\n}\n", "idx": 24986}
{"project": "FFmpeg", "commit_id": "17ba719d9ba30c970f65747f42d5fbb1e447ca28", "target": 1, "func": "static av_cold int mm_decode_init(AVCodecContext *avctx)\n{\n    MmContext *s = avctx->priv_data;\n    s->avctx = avctx;\n    avctx->pix_fmt = AV_PIX_FMT_PAL8;\n    s->frame = av_frame_alloc();\n    if (!s->frame)\n        return AVERROR(ENOMEM);\n    return 0;", "idx": 24988}
{"project": "FFmpeg", "commit_id": "3d2515a8f3ba35f10a69d077936770955b5394da", "target": 0, "func": "static int split_init(AVFilterContext *ctx, const char *args, void *opaque)\n\n{\n\n    int i, nb_outputs = 2;\n\n\n\n    if (args) {\n\n        nb_outputs = strtol(args, NULL, 0);\n\n        if (nb_outputs <= 0) {\n\n            av_log(ctx, AV_LOG_ERROR, \"Invalid number of outputs specified: %d.\\n\",\n\n                   nb_outputs);\n\n            return AVERROR(EINVAL);\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < nb_outputs; i++) {\n\n        char name[32];\n\n        AVFilterPad pad = { 0 };\n\n\n\n        snprintf(name, sizeof(name), \"output%d\", i);\n\n        pad.type = !strcmp(ctx->name, \"split\") ? AVMEDIA_TYPE_VIDEO : AVMEDIA_TYPE_AUDIO;\n\n        pad.name = av_strdup(name);\n\n\n\n        avfilter_insert_outpad(ctx, i, &pad);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25000}
{"project": "FFmpeg", "commit_id": "9c097f1cfc1825882353dc73e24a0d707d2495f2", "target": 0, "func": "static int ffserver_apply_stream_config(AVCodecContext *enc, const AVDictionary *conf, AVDictionary **opts)\n\n{\n\n    AVDictionaryEntry *e;\n\n    int ret = 0;\n\n\n\n    /* Return values from ffserver_set_*_param are ignored.\n\n       Values are initially parsed and checked before inserting to AVDictionary. */\n\n\n\n    //video params\n\n    if ((e = av_dict_get(conf, \"VideoBitRateRangeMin\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->rc_min_rate, e->value, 1000, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoBitRateRangeMax\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->rc_max_rate, e->value, 1000, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"Debug\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->debug, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"Strict\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->strict_std_compliance, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoBufferSize\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->rc_buffer_size, e->value, 8*1024, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoBitRateTolerance\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->bit_rate_tolerance, e->value, 1000, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoBitRate\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->bit_rate, e->value, 1000, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoSizeWidth\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->width, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoSizeHeight\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->height, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"PixelFormat\", NULL, 0))) {\n\n        int val;\n\n        ffserver_set_int_param(&val, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n        enc->pix_fmt = val;\n\n    }\n\n    if ((e = av_dict_get(conf, \"VideoGopSize\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->gop_size, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoFrameRateNum\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->time_base.num, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoFrameRateDen\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->time_base.den, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoQDiff\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->max_qdiff, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoQMax\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->qmax, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoQMin\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->qmin, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"LumiMask\", NULL, 0)))\n\n        ffserver_set_float_param(&enc->lumi_masking, e->value, 0, -FLT_MAX, FLT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"DarkMask\", NULL, 0)))\n\n        ffserver_set_float_param(&enc->dark_masking, e->value, 0, -FLT_MAX, FLT_MAX, NULL, 0, NULL);\n\n    if (av_dict_get(conf, \"BitExact\", NULL, 0))\n\n        enc->flags |= CODEC_FLAG_BITEXACT;\n\n    if (av_dict_get(conf, \"DctFastint\", NULL, 0))\n\n        enc->dct_algo  = FF_DCT_FASTINT;\n\n    if (av_dict_get(conf, \"IdctSimple\", NULL, 0))\n\n        enc->idct_algo = FF_IDCT_SIMPLE;\n\n    if (av_dict_get(conf, \"VideoHighQuality\", NULL, 0))\n\n        enc->mb_decision = FF_MB_DECISION_BITS;\n\n    if ((e = av_dict_get(conf, \"VideoTag\", NULL, 0)))\n\n        enc->codec_tag = MKTAG(e->value[0], e->value[1], e->value[2], e->value[3]);\n\n    if (av_dict_get(conf, \"Qscale\", NULL, 0)) {\n\n        enc->flags |= CODEC_FLAG_QSCALE;\n\n        ffserver_set_int_param(&enc->global_quality, e->value, FF_QP2LAMBDA, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    }\n\n    if (av_dict_get(conf, \"Video4MotionVector\", NULL, 0)) {\n\n        enc->mb_decision = FF_MB_DECISION_BITS; //FIXME remove\n\n        enc->flags |= CODEC_FLAG_4MV;\n\n    }\n\n    //audio params\n\n    if ((e = av_dict_get(conf, \"AudioChannels\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->channels, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"AudioSampleRate\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->sample_rate, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"AudioBitRate\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->bit_rate, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n\n\n    av_opt_set_dict2(enc, opts, AV_OPT_SEARCH_CHILDREN);\n\n    e = NULL;\n\n    while (e = av_dict_get(*opts, \"\", e, AV_DICT_IGNORE_SUFFIX)) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Provided AVOption '%s' doesn't match any existing option.\\n\", e->key);\n\n        ret = AVERROR(EINVAL);\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 25011}
{"project": "FFmpeg", "commit_id": "c04c52d3a8bb323d71436512495c8ecf58be69ee", "target": 0, "func": "static int amf_parse_object(AVFormatContext *s, AVStream *astream, AVStream *vstream, const char *key, unsigned int max_pos, int depth) {\n\n    AVCodecContext *acodec, *vcodec;\n\n    ByteIOContext *ioc;\n\n    AMFDataType amf_type;\n\n    char str_val[256];\n\n    double num_val;\n\n\n\n    num_val = 0;\n\n    ioc = s->pb;\n\n\n\n    amf_type = get_byte(ioc);\n\n\n\n    switch(amf_type) {\n\n        case AMF_DATA_TYPE_NUMBER:\n\n            num_val = av_int2dbl(get_be64(ioc)); break;\n\n        case AMF_DATA_TYPE_BOOL:\n\n            num_val = get_byte(ioc); break;\n\n        case AMF_DATA_TYPE_STRING:\n\n            if(amf_get_string(ioc, str_val, sizeof(str_val)) < 0)\n\n                return -1;\n\n            break;\n\n        case AMF_DATA_TYPE_OBJECT: {\n\n            unsigned int keylen;\n\n\n\n            while(url_ftell(ioc) < max_pos - 2 && (keylen = get_be16(ioc))) {\n\n                url_fskip(ioc, keylen); //skip key string\n\n                if(amf_parse_object(s, NULL, NULL, NULL, max_pos, depth + 1) < 0)\n\n                    return -1; //if we couldn't skip, bomb out.\n\n            }\n\n            if(get_byte(ioc) != AMF_END_OF_OBJECT)\n\n                return -1;\n\n        }\n\n            break;\n\n        case AMF_DATA_TYPE_NULL:\n\n        case AMF_DATA_TYPE_UNDEFINED:\n\n        case AMF_DATA_TYPE_UNSUPPORTED:\n\n            break; //these take up no additional space\n\n        case AMF_DATA_TYPE_MIXEDARRAY:\n\n            url_fskip(ioc, 4); //skip 32-bit max array index\n\n            while(url_ftell(ioc) < max_pos - 2 && amf_get_string(ioc, str_val, sizeof(str_val)) > 0) {\n\n                //this is the only case in which we would want a nested parse to not skip over the object\n\n                if(amf_parse_object(s, astream, vstream, str_val, max_pos, depth + 1) < 0)\n\n                    return -1;\n\n            }\n\n            if(get_byte(ioc) != AMF_END_OF_OBJECT)\n\n                return -1;\n\n            break;\n\n        case AMF_DATA_TYPE_ARRAY: {\n\n            unsigned int arraylen, i;\n\n\n\n            arraylen = get_be32(ioc);\n\n            for(i = 0; i < arraylen && url_ftell(ioc) < max_pos - 1; i++) {\n\n                if(amf_parse_object(s, NULL, NULL, NULL, max_pos, depth + 1) < 0)\n\n                    return -1; //if we couldn't skip, bomb out.\n\n            }\n\n        }\n\n            break;\n\n        case AMF_DATA_TYPE_DATE:\n\n            url_fskip(ioc, 8 + 2); //timestamp (double) and UTC offset (int16)\n\n            break;\n\n        default: //unsupported type, we couldn't skip\n\n            return -1;\n\n    }\n\n\n\n    if(depth == 1 && key) { //only look for metadata values when we are not nested and key != NULL\n\n        acodec = astream ? astream->codec : NULL;\n\n        vcodec = vstream ? vstream->codec : NULL;\n\n\n\n        if(amf_type == AMF_DATA_TYPE_BOOL) {\n\n            if(!strcmp(key, \"stereo\") && acodec) acodec->channels = num_val > 0 ? 2 : 1;\n\n        } else if(amf_type == AMF_DATA_TYPE_NUMBER) {\n\n            if(!strcmp(key, \"duration\")) s->duration = num_val * AV_TIME_BASE;\n\n//            else if(!strcmp(key, \"width\")  && vcodec && num_val > 0) vcodec->width  = num_val;\n\n//            else if(!strcmp(key, \"height\") && vcodec && num_val > 0) vcodec->height = num_val;\n\n            else if(!strcmp(key, \"audiocodecid\") && acodec) flv_set_audio_codec(s, astream, (int)num_val << FLV_AUDIO_CODECID_OFFSET);\n\n            else if(!strcmp(key, \"videocodecid\") && vcodec) flv_set_video_codec(s, vstream, (int)num_val);\n\n            else if(!strcmp(key, \"audiosamplesize\") && acodec && num_val >= 0) {\n\n                acodec->bits_per_sample = num_val;\n\n                //we may have to rewrite a previously read codecid because FLV only marks PCM endianness.\n\n                if(num_val == 8 && (acodec->codec_id == CODEC_ID_PCM_S16BE || acodec->codec_id == CODEC_ID_PCM_S16LE))\n\n                    acodec->codec_id = CODEC_ID_PCM_S8;\n\n            }\n\n            else if(!strcmp(key, \"audiosamplerate\") && acodec && num_val >= 0) {\n\n                //some tools, like FLVTool2, write consistently approximate metadata sample rates\n\n                if (!acodec->sample_rate) {\n\n                    switch((int)num_val) {\n\n                        case 44000: acodec->sample_rate = 44100  ; break;\n\n                        case 22000: acodec->sample_rate = 22050  ; break;\n\n                        case 11000: acodec->sample_rate = 11025  ; break;\n\n                        case 5000 : acodec->sample_rate = 5512   ; break;\n\n                        default   : acodec->sample_rate = num_val;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25018}
{"project": "FFmpeg", "commit_id": "8aeb33225aed5a0da03f9145a09ca1bbd6ac6532", "target": 0, "func": "static void draw_slice(AVFilterLink *link, int y, int h)\n\n{\n\n    ScaleContext *scale = link->dst->priv;\n\n    int out_h;\n\n    AVFilterPicRef *cur_pic = link->cur_pic;\n\n    uint8_t *data[4];\n\n\n\n    if (!scale->slice_dir) {\n\n        if (y != 0 && y + h != link->h) {\n\n            av_log(scale, AV_LOG_ERROR, \"Slices start in the middle!\\n\");\n\n            return;\n\n        }\n\n        scale->slice_dir = y ?                       -1 : 1;\n\n        scale->slice_y   = y ? link->dst->outputs[0]->h : y;\n\n    }\n\n\n\n    data[0] = cur_pic->data[0] +  y               * cur_pic->linesize[0];\n\n    data[1] = scale->input_is_pal ?\n\n              cur_pic->data[1] :\n\n              cur_pic->data[1] + (y>>scale->vsub) * cur_pic->linesize[1];\n\n    data[2] = cur_pic->data[2] + (y>>scale->vsub) * cur_pic->linesize[2];\n\n    data[3] = cur_pic->data[3] +  y               * cur_pic->linesize[3];\n\n\n\n    out_h = sws_scale(scale->sws, data, cur_pic->linesize, y, h,\n\n                      link->dst->outputs[0]->outpic->data,\n\n                      link->dst->outputs[0]->outpic->linesize);\n\n\n\n    if (scale->slice_dir == -1)\n\n        scale->slice_y -= out_h;\n\n    avfilter_draw_slice(link->dst->outputs[0], scale->slice_y, out_h);\n\n    if (scale->slice_dir == 1)\n\n        scale->slice_y += out_h;\n\n}\n", "idx": 25029}
{"project": "FFmpeg", "commit_id": "fd2784c3b5e5ea13dd308b1eeeef0dd3c22a3d4a", "target": 1, "func": "static int join_request_frame(AVFilterLink *outlink)\n\n{\n\n    AVFilterContext *ctx = outlink->src;\n\n    JoinContext *s       = ctx->priv;\n\n    AVFilterBufferRef *buf;\n\n    JoinBufferPriv *priv;\n\n    int linesize   = INT_MAX;\n\n    int perms      = ~0;\n\n    int nb_samples;\n\n    int i, j, ret;\n\n\n\n    /* get a frame on each input */\n\n    for (i = 0; i < ctx->nb_inputs; i++) {\n\n        AVFilterLink *inlink = ctx->inputs[i];\n\n\n\n        if (!s->input_frames[i] &&\n\n            (ret = ff_request_frame(inlink)) < 0)\n\n            return ret;\n\n\n\n        /* request the same number of samples on all inputs */\n\n        if (i == 0) {\n\n            nb_samples = s->input_frames[0]->audio->nb_samples;\n\n\n\n            for (j = 1; !i && j < ctx->nb_inputs; j++)\n\n                ctx->inputs[j]->request_samples = nb_samples;\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < s->nb_channels; i++) {\n\n        ChannelMap *ch = &s->channels[i];\n\n        AVFilterBufferRef *cur_buf = s->input_frames[ch->input];\n\n\n\n        s->data[i] = cur_buf->extended_data[ch->in_channel_idx];\n\n        linesize   = FFMIN(linesize, cur_buf->linesize[0]);\n\n        perms     &= cur_buf->perms;\n\n    }\n\n\n\n    buf = avfilter_get_audio_buffer_ref_from_arrays(s->data, linesize, perms,\n\n                                                    nb_samples, outlink->format,\n\n                                                    outlink->channel_layout);\n\n    if (!buf)\n\n        return AVERROR(ENOMEM);\n\n\n\n    buf->buf->free = join_free_buffer;\n\n    buf->pts       = s->input_frames[0]->pts;\n\n\n\n    if (!(priv = av_mallocz(sizeof(*priv))))\n\n        goto fail;\n\n    if (!(priv->in_buffers = av_mallocz(sizeof(*priv->in_buffers) * ctx->nb_inputs)))\n\n        goto fail;\n\n\n\n    for (i = 0; i < ctx->nb_inputs; i++)\n\n        priv->in_buffers[i] = s->input_frames[i];\n\n    priv->nb_in_buffers = ctx->nb_inputs;\n\n    buf->buf->priv      = priv;\n\n\n\n    ff_filter_samples(outlink, buf);\n\n\n\n    memset(s->input_frames, 0, sizeof(*s->input_frames) * ctx->nb_inputs);\n\n\n\n    return 0;\n\n\n\nfail:\n\n    avfilter_unref_buffer(buf);\n\n    if (priv)\n\n        av_freep(&priv->in_buffers);\n\n    av_freep(&priv);\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 25037}
{"project": "FFmpeg", "commit_id": "8b2fce0d3f5a56c40c28899c9237210ca8f9cf75", "target": 1, "func": "static inline void yuv2yuvXinC(int16_t *lumFilter, int16_t **lumSrc, int lumFilterSize,\n\n                               int16_t *chrFilter, int16_t **chrSrc, int chrFilterSize,\n\n                               uint8_t *dest, uint8_t *uDest, uint8_t *vDest, int dstW, int chrDstW)\n\n{\n\n    //FIXME Optimize (just quickly writen not opti..)\n\n    int i;\n\n    for (i=0; i<dstW; i++)\n\n    {\n\n        int val=1<<18;\n\n        int j;\n\n        for (j=0; j<lumFilterSize; j++)\n\n            val += lumSrc[j][i] * lumFilter[j];\n\n\n\n        dest[i]= av_clip_uint8(val>>19);\n\n    }\n\n\n\n    if (uDest)\n\n        for (i=0; i<chrDstW; i++)\n\n        {\n\n            int u=1<<18;\n\n            int v=1<<18;\n\n            int j;\n\n            for (j=0; j<chrFilterSize; j++)\n\n            {\n\n                u += chrSrc[j][i] * chrFilter[j];\n\n                v += chrSrc[j][i + 2048] * chrFilter[j];\n\n            }\n\n\n\n            uDest[i]= av_clip_uint8(u>>19);\n\n            vDest[i]= av_clip_uint8(v>>19);\n\n        }\n\n}\n", "idx": 25038}
{"project": "FFmpeg", "commit_id": "b69b43e2c471c4febbffaf313875396256b6a51e", "target": 1, "func": "static void check_decode_result(int *got_output, int ret)\n\n{\n\n    if (*got_output || ret<0)\n\n        decode_error_stat[ret<0] ++;\n\n\n\n    if (ret < 0 && exit_on_error)\n\n        exit_program(1);\n\n}\n", "idx": 25040}
{"project": "FFmpeg", "commit_id": "2e59ffbb7964214e192a9f77c4445ff29c6510d7", "target": 1, "func": "static int mace_decode_frame(AVCodecContext *avctx, void *data,\n                             int *got_frame_ptr, AVPacket *avpkt)\n{\n    AVFrame *frame     = data;\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size;\n    int16_t **samples;\n    MACEContext *ctx = avctx->priv_data;\n    int i, j, k, l, ret;\n    int is_mace3 = (avctx->codec_id == AV_CODEC_ID_MACE3);\n    /* get output buffer */\n    frame->nb_samples = 3 * (buf_size << (1 - is_mace3)) / avctx->channels;\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n        return ret;\n    samples = (int16_t **)frame->extended_data;\n    for(i = 0; i < avctx->channels; i++) {\n        int16_t *output = samples[i];\n        for (j=0; j < buf_size / (avctx->channels << is_mace3); j++)\n            for (k=0; k < (1 << is_mace3); k++) {\n                uint8_t pkt = buf[(i << is_mace3) +\n                                  (j*avctx->channels << is_mace3) + k];\n                uint8_t val[2][3] = {{pkt >> 5, (pkt >> 3) & 3, pkt & 7 },\n                                     {pkt & 7 , (pkt >> 3) & 3, pkt >> 5}};\n                for (l=0; l < 3; l++) {\n                    if (is_mace3)\n                        chomp3(&ctx->chd[i], output, val[1][l], l);\n                    else\n                        chomp6(&ctx->chd[i], output, val[0][l], l);\n                    output += 1 << (1-is_mace3);\n    *got_frame_ptr = 1;\n    return buf_size;", "idx": 25043}
{"project": "FFmpeg", "commit_id": "be524ffc16bf14cab0ad112b0dcb48d09a2a40ff", "target": 1, "func": "static av_cold int rv30_decode_init(AVCodecContext *avctx)\n\n{\n\n    RV34DecContext *r = avctx->priv_data;\n\n    int ret;\n\n\n\n    r->rv30 = 1;\n\n    if ((ret = ff_rv34_decode_init(avctx)) < 0)\n\n        return ret;\n\n    if(avctx->extradata_size < 2){\n\n        av_log(avctx, AV_LOG_ERROR, \"Extradata is too small.\\n\");\n\n        return -1;\n\n\n\n\n    r->max_rpr = avctx->extradata[1] & 7;\n\n\n\n\n\n\n\n    r->parse_slice_header = rv30_parse_slice_header;\n\n    r->decode_intra_types = rv30_decode_intra_types;\n\n    r->decode_mb_info     = rv30_decode_mb_info;\n\n    r->loop_filter        = rv30_loop_filter;\n\n    r->luma_dc_quant_i = rv30_luma_dc_quant;\n\n    r->luma_dc_quant_p = rv30_luma_dc_quant;\n\n    return 0;\n", "idx": 25044}
{"project": "FFmpeg", "commit_id": "dcc39ee10e82833ce24aa57926c00ffeb1948198", "target": 0, "func": "static int mpeg_decode_slice(MpegEncContext *s, int mb_y,\n\n                             const uint8_t **buf, int buf_size)\n\n{\n\n    AVCodecContext *avctx = s->avctx;\n\n    const int field_pic   = s->picture_structure != PICT_FRAME;\n\n    int ret;\n\n\n\n    s->resync_mb_x =\n\n    s->resync_mb_y = -1;\n\n\n\n    assert(mb_y < s->mb_height);\n\n\n\n    init_get_bits(&s->gb, *buf, buf_size * 8);\n\n\n\n    ff_mpeg1_clean_buffers(s);\n\n    s->interlaced_dct = 0;\n\n\n\n    s->qscale = get_qscale(s);\n\n\n\n    if (s->qscale == 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"qscale == 0\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* extra slice info */\n\n    while (get_bits1(&s->gb) != 0)\n\n        skip_bits(&s->gb, 8);\n\n\n\n    s->mb_x = 0;\n\n\n\n    if (mb_y == 0 && s->codec_tag == AV_RL32(\"SLIF\")) {\n\n        skip_bits1(&s->gb);\n\n    } else {\n\n        while (get_bits_left(&s->gb) > 0) {\n\n            int code = get_vlc2(&s->gb, ff_mbincr_vlc.table,\n\n                                MBINCR_VLC_BITS, 2);\n\n            if (code < 0) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"first mb_incr damaged\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if (code >= 33) {\n\n                if (code == 33)\n\n                    s->mb_x += 33;\n\n                /* otherwise, stuffing, nothing to do */\n\n            } else {\n\n                s->mb_x += code;\n\n                break;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (s->mb_x >= (unsigned) s->mb_width) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"initial skip overflow\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (avctx->hwaccel) {\n\n        const uint8_t *buf_end, *buf_start = *buf - 4; /* include start_code */\n\n        int start_code = -1;\n\n        buf_end = avpriv_find_start_code(buf_start + 2, *buf + buf_size, &start_code);\n\n        if (buf_end < *buf + buf_size)\n\n            buf_end -= 4;\n\n        s->mb_y = mb_y;\n\n        if (avctx->hwaccel->decode_slice(avctx, buf_start, buf_end - buf_start) < 0)\n\n            return DECODE_SLICE_ERROR;\n\n        *buf = buf_end;\n\n        return DECODE_SLICE_OK;\n\n    }\n\n\n\n    s->resync_mb_x = s->mb_x;\n\n    s->resync_mb_y = s->mb_y = mb_y;\n\n    s->mb_skip_run = 0;\n\n    ff_init_block_index(s);\n\n\n\n    if (s->mb_y == 0 && s->mb_x == 0 && (s->first_field || s->picture_structure == PICT_FRAME)) {\n\n        if (s->avctx->debug & FF_DEBUG_PICT_INFO) {\n\n            av_log(s->avctx, AV_LOG_DEBUG,\n\n                   \"qp:%d fc:%2d%2d%2d%2d %s %s %s %s %s dc:%d pstruct:%d fdct:%d cmv:%d qtype:%d ivlc:%d rff:%d %s\\n\",\n\n                   s->qscale,\n\n                   s->mpeg_f_code[0][0], s->mpeg_f_code[0][1],\n\n                   s->mpeg_f_code[1][0], s->mpeg_f_code[1][1],\n\n                   s->pict_type  == AV_PICTURE_TYPE_I ? \"I\" :\n\n                   (s->pict_type == AV_PICTURE_TYPE_P ? \"P\" :\n\n                   (s->pict_type == AV_PICTURE_TYPE_B ? \"B\" : \"S\")),\n\n                   s->progressive_sequence ? \"ps\"  : \"\",\n\n                   s->progressive_frame    ? \"pf\"  : \"\",\n\n                   s->alternate_scan       ? \"alt\" : \"\",\n\n                   s->top_field_first      ? \"top\" : \"\",\n\n                   s->intra_dc_precision, s->picture_structure,\n\n                   s->frame_pred_frame_dct, s->concealment_motion_vectors,\n\n                   s->q_scale_type, s->intra_vlc_format,\n\n                   s->repeat_first_field, s->chroma_420_type ? \"420\" : \"\");\n\n        }\n\n    }\n\n\n\n    for (;;) {\n\n#if FF_API_XVMC\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n        // If 1, we memcpy blocks in xvmcvideo.\n\n        if (CONFIG_MPEG_XVMC_DECODER && s->avctx->xvmc_acceleration > 1)\n\n            ff_xvmc_init_block(s); // set s->block\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif /* FF_API_XVMC */\n\n\n\n        if ((ret = mpeg_decode_mb(s, s->block)) < 0)\n\n            return ret;\n\n\n\n        // Note motion_val is normally NULL unless we want to extract the MVs.\n\n        if (s->current_picture.motion_val[0] && !s->encoding) {\n\n            const int wrap = s->b8_stride;\n\n            int xy         = s->mb_x * 2 + s->mb_y * 2 * wrap;\n\n            int b8_xy      = 4 * (s->mb_x + s->mb_y * s->mb_stride);\n\n            int motion_x, motion_y, dir, i;\n\n\n\n            for (i = 0; i < 2; i++) {\n\n                for (dir = 0; dir < 2; dir++) {\n\n                    if (s->mb_intra ||\n\n                        (dir == 1 && s->pict_type != AV_PICTURE_TYPE_B)) {\n\n                        motion_x = motion_y = 0;\n\n                    } else if (s->mv_type == MV_TYPE_16X16 ||\n\n                               (s->mv_type == MV_TYPE_FIELD && field_pic)) {\n\n                        motion_x = s->mv[dir][0][0];\n\n                        motion_y = s->mv[dir][0][1];\n\n                    } else { /* if ((s->mv_type == MV_TYPE_FIELD) || (s->mv_type == MV_TYPE_16X8)) */\n\n                        motion_x = s->mv[dir][i][0];\n\n                        motion_y = s->mv[dir][i][1];\n\n                    }\n\n\n\n                    s->current_picture.motion_val[dir][xy][0]     = motion_x;\n\n                    s->current_picture.motion_val[dir][xy][1]     = motion_y;\n\n                    s->current_picture.motion_val[dir][xy + 1][0] = motion_x;\n\n                    s->current_picture.motion_val[dir][xy + 1][1] = motion_y;\n\n                    s->current_picture.ref_index [dir][b8_xy]     =\n\n                    s->current_picture.ref_index [dir][b8_xy + 1] = s->field_select[dir][i];\n\n                    assert(s->field_select[dir][i] == 0 ||\n\n                           s->field_select[dir][i] == 1);\n\n                }\n\n                xy    += wrap;\n\n                b8_xy += 2;\n\n            }\n\n        }\n\n\n\n        s->dest[0] += 16;\n\n        s->dest[1] += 16 >> s->chroma_x_shift;\n\n        s->dest[2] += 16 >> s->chroma_x_shift;\n\n\n\n        ff_mpv_decode_mb(s, s->block);\n\n\n\n        if (++s->mb_x >= s->mb_width) {\n\n            const int mb_size = 16;\n\n\n\n            ff_mpeg_draw_horiz_band(s, mb_size * (s->mb_y >> field_pic), mb_size);\n\n            ff_mpv_report_decode_progress(s);\n\n\n\n            s->mb_x  = 0;\n\n            s->mb_y += 1 << field_pic;\n\n\n\n            if (s->mb_y >= s->mb_height) {\n\n                int left   = get_bits_left(&s->gb);\n\n                int is_d10 = s->chroma_format == 2 &&\n\n                             s->pict_type == AV_PICTURE_TYPE_I &&\n\n                             avctx->profile == 0 && avctx->level == 5 &&\n\n                             s->intra_dc_precision == 2 &&\n\n                             s->q_scale_type == 1 && s->alternate_scan == 0 &&\n\n                             s->progressive_frame == 0\n\n                             /* vbv_delay == 0xBBB || 0xE10 */;\n\n\n\n                if (left < 0 ||\n\n                    (left && show_bits(&s->gb, FFMIN(left, 23)) && !is_d10) ||\n\n                    ((avctx->err_recognition & AV_EF_BUFFER) && left > 8)) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"end mismatch left=%d %0X\\n\",\n\n                           left, show_bits(&s->gb, FFMIN(left, 23)));\n\n                    return AVERROR_INVALIDDATA;\n\n                } else\n\n                    goto eos;\n\n            }\n\n\n\n            ff_init_block_index(s);\n\n        }\n\n\n\n        /* skip mb handling */\n\n        if (s->mb_skip_run == -1) {\n\n            /* read increment again */\n\n            s->mb_skip_run = 0;\n\n            for (;;) {\n\n                int code = get_vlc2(&s->gb, ff_mbincr_vlc.table,\n\n                                    MBINCR_VLC_BITS, 2);\n\n                if (code < 0) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"mb incr damaged\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                if (code >= 33) {\n\n                    if (code == 33) {\n\n                        s->mb_skip_run += 33;\n\n                    } else if (code == 35) {\n\n                        if (s->mb_skip_run != 0 || show_bits(&s->gb, 15) != 0) {\n\n                            av_log(s->avctx, AV_LOG_ERROR, \"slice mismatch\\n\");\n\n                            return AVERROR_INVALIDDATA;\n\n                        }\n\n                        goto eos; /* end of slice */\n\n                    }\n\n                    /* otherwise, stuffing, nothing to do */\n\n                } else {\n\n                    s->mb_skip_run += code;\n\n                    break;\n\n                }\n\n            }\n\n            if (s->mb_skip_run) {\n\n                int i;\n\n                if (s->pict_type == AV_PICTURE_TYPE_I) {\n\n                    av_log(s->avctx, AV_LOG_ERROR,\n\n                           \"skipped MB in I-frame at %d %d\\n\", s->mb_x, s->mb_y);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                /* skip mb */\n\n                s->mb_intra = 0;\n\n                for (i = 0; i < 12; i++)\n\n                    s->block_last_index[i] = -1;\n\n                if (s->picture_structure == PICT_FRAME)\n\n                    s->mv_type = MV_TYPE_16X16;\n\n                else\n\n                    s->mv_type = MV_TYPE_FIELD;\n\n                if (s->pict_type == AV_PICTURE_TYPE_P) {\n\n                    /* if P type, zero motion vector is implied */\n\n                    s->mv_dir             = MV_DIR_FORWARD;\n\n                    s->mv[0][0][0]        = s->mv[0][0][1]      = 0;\n\n                    s->last_mv[0][0][0]   = s->last_mv[0][0][1] = 0;\n\n                    s->last_mv[0][1][0]   = s->last_mv[0][1][1] = 0;\n\n                    s->field_select[0][0] = (s->picture_structure - 1) & 1;\n\n                } else {\n\n                    /* if B type, reuse previous vectors and directions */\n\n                    s->mv[0][0][0] = s->last_mv[0][0][0];\n\n                    s->mv[0][0][1] = s->last_mv[0][0][1];\n\n                    s->mv[1][0][0] = s->last_mv[1][0][0];\n\n                    s->mv[1][0][1] = s->last_mv[1][0][1];\n\n                }\n\n            }\n\n        }\n\n    }\n\neos: // end of slice\n\n    *buf += (get_bits_count(&s->gb) - 1) / 8;\n\n    ff_dlog(s, \"y %d %d %d %d\\n\", s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y);\n\n    return 0;\n\n}\n", "idx": 25050}
{"project": "FFmpeg", "commit_id": "8055433b492fe971a145a07470119ef8c2c71571", "target": 1, "func": "int avfilter_graph_parse(AVFilterGraph *graph, const char *filters,\n\n                         AVFilterInOut **open_inputs, AVFilterInOut **open_outputs,\n\n                         void *log_ctx)\n\n{\n\n    int index = 0, ret;\n\n    char chr = 0;\n\n\n\n    AVFilterInOut *curr_inputs = NULL;\n\n\n\n    do {\n\n        AVFilterContext *filter;\n\n        const char *filterchain = filters;\n\n        filters += strspn(filters, WHITESPACES);\n\n\n\n        if ((ret = parse_inputs(&filters, &curr_inputs, open_outputs, log_ctx)) < 0)\n\n            goto fail;\n\n\n\n        if ((ret = parse_filter(&filter, &filters, graph, index, log_ctx)) < 0)\n\n            goto fail;\n\n\n\n        if (filter->input_count == 1 && !curr_inputs && !index) {\n\n            /* First input can be omitted if it is \"[in]\" */\n\n            const char *tmp = \"[in]\";\n\n            if ((ret = parse_inputs(&tmp, &curr_inputs, open_outputs, log_ctx)) < 0)\n\n                goto fail;\n\n        }\n\n\n\n        if ((ret = link_filter_inouts(filter, &curr_inputs, open_inputs, log_ctx)) < 0)\n\n            goto fail;\n\n\n\n        if ((ret = parse_outputs(&filters, &curr_inputs, open_inputs, open_outputs,\n\n                                 log_ctx)) < 0)\n\n            goto fail;\n\n\n\n        filters += strspn(filters, WHITESPACES);\n\n        chr = *filters++;\n\n\n\n        if (chr == ';' && curr_inputs) {\n\n            av_log(log_ctx, AV_LOG_ERROR,\n\n                   \"Invalid filterchain containing an unlabelled output pad: \\\"%s\\\"\\n\",\n\n                   filterchain);\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n        index++;\n\n    } while (chr == ',' || chr == ';');\n\n\n\n    if (chr) {\n\n        av_log(log_ctx, AV_LOG_ERROR,\n\n               \"Unable to parse graph description substring: \\\"%s\\\"\\n\",\n\n               filters - 1);\n\n        ret = AVERROR(EINVAL);\n\n        goto fail;\n\n    }\n\n\n\n    if (*open_inputs && !strcmp((*open_inputs)->name, \"out\") && curr_inputs) {\n\n        /* Last output can be omitted if it is \"[out]\" */\n\n        const char *tmp = \"[out]\";\n\n        if ((ret = parse_outputs(&tmp, &curr_inputs, open_inputs, open_outputs,\n\n                                 log_ctx)) < 0)\n\n            goto fail;\n\n    }\n\n\n\n    return 0;\n\n\n\n fail:\n\n    for (; graph->filter_count > 0; graph->filter_count--)\n\n        avfilter_free(graph->filters[graph->filter_count - 1]);\n\n    av_freep(&graph->filters);\n\n    avfilter_inout_free(open_inputs);\n\n    avfilter_inout_free(open_outputs);\n\n    avfilter_inout_free(&curr_inputs);\n\n    return ret;\n\n}\n", "idx": 25051}
{"project": "FFmpeg", "commit_id": "f66f3819b96847cd28589b718dbcd03b782e7a5c", "target": 1, "func": "static int vid_probe(AVProbeData *p)\n{\n    // little-endian VID tag, file starts with \"VID\\0\"\n    if (AV_RL32(p->buf) != MKTAG('V', 'I', 'D', 0))\n        return 0;\n    return AVPROBE_SCORE_MAX;\n}", "idx": 25053}
{"project": "FFmpeg", "commit_id": "bb463d81020a2f3c5cf3403e18f980171773f48a", "target": 0, "func": "static int mpeg_decode_frame(AVCodecContext *avctx, \n\n                             void *data, int *data_size,\n\n                             uint8_t *buf, int buf_size)\n\n{\n\n    Mpeg1Context *s = avctx->priv_data;\n\n    uint8_t *buf_end, *buf_ptr;\n\n    int ret, start_code, input_size;\n\n    AVFrame *picture = data;\n\n    MpegEncContext *s2 = &s->mpeg_enc_ctx;\n\n    dprintf(\"fill_buffer\\n\");\n\n\n\n    *data_size = 0;\n\n\n\n    /* special case for last picture */\n\n    if (buf_size == 0) {\n\n        if (s2->picture_number > 0) {\n\n            *picture= *(AVFrame*)&s2->next_picture;\n\n\n\n            *data_size = sizeof(AVFrame);\n\n        }\n\n        return 0;\n\n    }\n\n\n\n    if(s2->flags&CODEC_FLAG_TRUNCATED){\n\n        int next;\n\n        \n\n        next= mpeg1_find_frame_end(s2, buf, buf_size);\n\n        \n\n        if( ff_combine_frame(s2, next, &buf, &buf_size) < 0 )\n\n            return buf_size;\n\n    }    \n\n    \n\n    buf_ptr = buf;\n\n    buf_end = buf + buf_size;\n\n\n\n#if 0    \n\n    if (s->repeat_field % 2 == 1) { \n\n        s->repeat_field++;\n\n        //fprintf(stderr,\"\\nRepeating last frame: %d -> %d! pict: %d %d\", avctx->frame_number-1, avctx->frame_number,\n\n        //        s2->picture_number, s->repeat_field);\n\n        if (avctx->flags & CODEC_FLAG_REPEAT_FIELD) {\n\n            *data_size = sizeof(AVPicture);\n\n            goto the_end;\n\n        }\n\n    }\n\n#endif\n\n    for(;;) {\n\n        /* find start next code */\n\n        start_code = find_start_code(&buf_ptr, buf_end);\n\n        if (start_code < 0){ \n\n            printf(\"missing end of picture\\n\");\n\n            return FFMAX(1, buf_ptr - buf - s2->parse_context.last_index);\n\n        }\n\n\n\n                /* prepare data for next start code */\n\n                input_size = buf_end - buf_ptr;\n\n                switch(start_code) {\n\n                case SEQ_START_CODE:\n\n                    mpeg1_decode_sequence(avctx, buf_ptr, \n\n                                          input_size);\n\n                    break;\n\n                            \n\n                case PICTURE_START_CODE:\n\n                    /* we have a complete image : we try to decompress it */\n\n                    mpeg1_decode_picture(avctx, \n\n                                         buf_ptr, input_size);\n\n                    break;\n\n                case EXT_START_CODE:\n\n                    mpeg_decode_extension(avctx,\n\n                                          buf_ptr, input_size);\n\n                    break;\n\n                case USER_START_CODE:\n\n                    mpeg_decode_user_data(avctx, \n\n                                          buf_ptr, input_size);\n\n                    break;\n\n                default:\n\n                    if (start_code >= SLICE_MIN_START_CODE &&\n\n                        start_code <= SLICE_MAX_START_CODE) {\n\n                        \n\n                        /* skip b frames if we dont have reference frames */\n\n                        if(s2->last_picture_ptr==NULL && s2->pict_type==B_TYPE) break;\n\n                        /* skip b frames if we are in a hurry */\n\n                        if(avctx->hurry_up && s2->pict_type==B_TYPE) break;\n\n                        /* skip everything if we are in a hurry>=5 */\n\n                        if(avctx->hurry_up>=5) break;\n\n                        \n\n                        if (!s->mpeg_enc_ctx_allocated) break;\n\n\n\n                        ret = mpeg_decode_slice(avctx, picture,\n\n                                                start_code, &buf_ptr, input_size);\n\n\n\n                        if (ret == DECODE_SLICE_EOP) {\n\n                            if(s2->last_picture_ptr) //FIXME merge with the stuff in mpeg_decode_slice\n\n                                *data_size = sizeof(AVPicture);\n\n                            return FFMAX(1, buf_ptr - buf - s2->parse_context.last_index);\n\n                        }else if(ret < 0){\n\n                            if(ret == DECODE_SLICE_ERROR)\n\n                                ff_er_add_slice(s2, s2->resync_mb_x, s2->resync_mb_y, s2->mb_x, s2->mb_y, AC_ERROR|DC_ERROR|MV_ERROR);\n\n                                \n\n                            fprintf(stderr,\"Error while decoding slice\\n\");\n\n\t\t\t    if(ret==DECODE_SLICE_FATAL_ERROR) return -1;\n\n                        }\n\n                    }\n\n                    break;\n\n                }\n\n    }\n\n}\n", "idx": 25056}
{"project": "FFmpeg", "commit_id": "02fb320adadacfc8446a1278582351078a024dee", "target": 1, "func": "static int libopenjpeg_decode_frame(AVCodecContext *avctx,\n\n                                    void *data, int *data_size,\n\n                                    AVPacket *avpkt)\n\n{\n\n    uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    LibOpenJPEGContext *ctx = avctx->priv_data;\n\n    AVFrame *picture = &ctx->image, *output = data;\n\n    opj_dinfo_t *dec;\n\n    opj_cio_t *stream;\n\n    opj_image_t *image;\n\n    int width, height, ret = -1;\n\n    int pixel_size = 0;\n\n    int ispacked = 0;\n\n\n\n    *data_size = 0;\n\n\n\n    // Check if input is a raw jpeg2k codestream or in jp2 wrapping\n\n    if((AV_RB32(buf) == 12) &&\n\n       (AV_RB32(buf + 4) == JP2_SIG_TYPE) &&\n\n       (AV_RB32(buf + 8) == JP2_SIG_VALUE)) {\n\n        dec = opj_create_decompress(CODEC_JP2);\n\n    } else {\n\n        // If the AVPacket contains a jp2c box, then skip to\n\n        // the starting byte of the codestream.\n\n        if (AV_RB32(buf + 4) == AV_RB32(\"jp2c\"))\n\n            buf += 8;\n\n        dec = opj_create_decompress(CODEC_J2K);\n\n\n\n\n    if(!dec) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error initializing decoder.\\n\");\n\n\n\n    opj_set_event_mgr((opj_common_ptr)dec, NULL, NULL);\n\n\n\n    ctx->dec_params.cp_limit_decoding = LIMIT_TO_MAIN_HEADER;\n\n    // Tie decoder with decoding parameters\n\n    opj_setup_decoder(dec, &ctx->dec_params);\n\n    stream = opj_cio_open((opj_common_ptr)dec, buf, buf_size);\n\n    if(!stream) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Codestream could not be opened for reading.\\n\");\n\n\n\n\n\n\n    // Decode the header only\n\n    image = opj_decode_with_info(dec, stream, NULL);\n\n    opj_cio_close(stream);\n\n\n\n\n\n\n    width  = image->x1 - image->x0;\n\n    height = image->y1 - image->y0;\n\n    if(av_image_check_size(width, height, 0, avctx) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"%dx%d dimension invalid.\\n\", width, height);\n\n        goto done;\n\n\n    avcodec_set_dimensions(avctx, width, height);\n\n\n\n    switch (image->numcomps) {\n\n    case 1:  avctx->pix_fmt = (image->comps[0].bpp == 8) ? PIX_FMT_GRAY8 : PIX_FMT_GRAY16;\n\n             break;\n\n    case 2:  avctx->pix_fmt = PIX_FMT_GRAY8A;\n\n             break;\n\n    case 3:\n\n    case 4:  avctx->pix_fmt = check_image_attributes(avctx, image);\n\n             break;\n\n    default: av_log(avctx, AV_LOG_ERROR, \"%d components unsupported.\\n\", image->numcomps);\n\n             goto done;\n\n\n\n\n    if(picture->data[0])\n\n        ff_thread_release_buffer(avctx, picture);\n\n\n\n    if(ff_thread_get_buffer(avctx, picture) < 0){\n\n        av_log(avctx, AV_LOG_ERROR, \"ff_thread_get_buffer() failed\\n\");\n\n\n\n\n\n    ctx->dec_params.cp_limit_decoding = NO_LIMITATION;\n\n    ctx->dec_params.cp_reduce = avctx->lowres;\n\n    // Tie decoder with decoding parameters\n\n    opj_setup_decoder(dec, &ctx->dec_params);\n\n    stream = opj_cio_open((opj_common_ptr)dec, buf, buf_size);\n\n    if(!stream) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Codestream could not be opened for reading.\\n\");\n\n\n\n\n\n\n    // Decode the codestream\n\n    image = opj_decode_with_info(dec, stream, NULL);\n\n    opj_cio_close(stream);\n\n\n\n\n\n\n\n\n    pixel_size = av_pix_fmt_descriptors[avctx->pix_fmt].comp[0].step_minus1 + 1;\n\n    ispacked = libopenjpeg_ispacked(avctx->pix_fmt);\n\n\n\n    switch (pixel_size) {\n\n    case 1:\n\n        if (ispacked) {\n\n            libopenjpeg_copy_to_packed8(picture, image);\n\n        } else {\n\n            libopenjpeg_copyto8(picture, image);\n\n\n        break;\n\n    case 2:\n\n        if (ispacked) {\n\n            libopenjpeg_copy_to_packed8(picture, image);\n\n        } else {\n\n            libopenjpeg_copyto16(picture, image);\n\n\n        break;\n\n    case 3:\n\n    case 4:\n\n        if (ispacked) {\n\n            libopenjpeg_copy_to_packed8(picture, image);\n\n\n        break;\n\n    case 6:\n\n    case 8:\n\n        if (ispacked) {\n\n            libopenjpeg_copy_to_packed16(picture, image);\n\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"unsupported pixel size %d\\n\", pixel_size);\n\n        goto done;\n\n\n\n\n    *output    = ctx->image;\n\n    *data_size = sizeof(AVPicture);\n\n    ret = buf_size;\n\n\n\ndone:\n\n    opj_image_destroy(image);\n\n\n    return ret;\n", "idx": 25058}
{"project": "FFmpeg", "commit_id": "bcaf64b605442e1622d16da89d4ec0e7730b8a8c", "target": 0, "func": "static int pcm_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n\n                            const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    int n, c, sample_size, v, ret;\n\n    const short *samples;\n\n    unsigned char *dst;\n\n    const uint8_t *samples_uint8_t;\n\n    const int16_t *samples_int16_t;\n\n    const int32_t *samples_int32_t;\n\n    const int64_t *samples_int64_t;\n\n    const uint16_t *samples_uint16_t;\n\n    const uint32_t *samples_uint32_t;\n\n\n\n    sample_size = av_get_bits_per_sample(avctx->codec->id) / 8;\n\n    n           = frame->nb_samples * avctx->channels;\n\n    samples     = (const short *)frame->data[0];\n\n\n\n    if ((ret = ff_alloc_packet2(avctx, avpkt, n * sample_size)))\n\n        return ret;\n\n    dst = avpkt->data;\n\n\n\n    switch (avctx->codec->id) {\n\n    case AV_CODEC_ID_PCM_U32LE:\n\n        ENCODE(uint32_t, le32, samples, dst, n, 0, 0x80000000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_U32BE:\n\n        ENCODE(uint32_t, be32, samples, dst, n, 0, 0x80000000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S24LE:\n\n        ENCODE(int32_t, le24, samples, dst, n, 8, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S24LE_PLANAR:\n\n        ENCODE_PLANAR(int32_t, le24, dst, n, 8, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S24BE:\n\n        ENCODE(int32_t, be24, samples, dst, n, 8, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_U24LE:\n\n        ENCODE(uint32_t, le24, samples, dst, n, 8, 0x800000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_U24BE:\n\n        ENCODE(uint32_t, be24, samples, dst, n, 8, 0x800000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S24DAUD:\n\n        for (; n > 0; n--) {\n\n            uint32_t tmp = ff_reverse[(*samples >> 8) & 0xff] +\n\n                           (ff_reverse[*samples & 0xff] << 8);\n\n            tmp <<= 4; // sync flags would go here\n\n            bytestream_put_be24(&dst, tmp);\n\n            samples++;\n\n        }\n\n        break;\n\n    case AV_CODEC_ID_PCM_U16LE:\n\n        ENCODE(uint16_t, le16, samples, dst, n, 0, 0x8000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_U16BE:\n\n        ENCODE(uint16_t, be16, samples, dst, n, 0, 0x8000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S8:\n\n        ENCODE(uint8_t, byte, samples, dst, n, 0, -128)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S8_PLANAR:\n\n        ENCODE_PLANAR(uint8_t, byte, dst, n, 0, -128)\n\n        break;\n\n#if HAVE_BIGENDIAN\n\n    case AV_CODEC_ID_PCM_F64LE:\n\n        ENCODE(int64_t, le64, samples, dst, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S32LE:\n\n    case AV_CODEC_ID_PCM_F32LE:\n\n        ENCODE(int32_t, le32, samples, dst, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S32LE_PLANAR:\n\n        ENCODE_PLANAR(int32_t, le32, dst, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S16LE:\n\n        ENCODE(int16_t, le16, samples, dst, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S16LE_PLANAR:\n\n        ENCODE_PLANAR(int16_t, le16, dst, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_F64BE:\n\n    case AV_CODEC_ID_PCM_F32BE:\n\n    case AV_CODEC_ID_PCM_S32BE:\n\n    case AV_CODEC_ID_PCM_S16BE:\n\n#else\n\n    case AV_CODEC_ID_PCM_F64BE:\n\n        ENCODE(int64_t, be64, samples, dst, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_F32BE:\n\n    case AV_CODEC_ID_PCM_S32BE:\n\n        ENCODE(int32_t, be32, samples, dst, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S16BE:\n\n        ENCODE(int16_t, be16, samples, dst, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S16BE_PLANAR:\n\n        ENCODE_PLANAR(int16_t, be16, dst, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_F64LE:\n\n    case AV_CODEC_ID_PCM_F32LE:\n\n    case AV_CODEC_ID_PCM_S32LE:\n\n    case AV_CODEC_ID_PCM_S16LE:\n\n#endif /* HAVE_BIGENDIAN */\n\n    case AV_CODEC_ID_PCM_U8:\n\n        memcpy(dst, samples, n * sample_size);\n\n        break;\n\n#if HAVE_BIGENDIAN\n\n    case AV_CODEC_ID_PCM_S16BE_PLANAR:\n\n#else\n\n    case AV_CODEC_ID_PCM_S16LE_PLANAR:\n\n    case AV_CODEC_ID_PCM_S32LE_PLANAR:\n\n#endif /* HAVE_BIGENDIAN */\n\n        n /= avctx->channels;\n\n        for (c = 0; c < avctx->channels; c++) {\n\n            const uint8_t *src = frame->extended_data[c];\n\n            bytestream_put_buffer(&dst, src, n * sample_size);\n\n        }\n\n        break;\n\n    case AV_CODEC_ID_PCM_ALAW:\n\n        for (; n > 0; n--) {\n\n            v      = *samples++;\n\n            *dst++ = linear_to_alaw[(v + 32768) >> 2];\n\n        }\n\n        break;\n\n    case AV_CODEC_ID_PCM_MULAW:\n\n        for (; n > 0; n--) {\n\n            v      = *samples++;\n\n            *dst++ = linear_to_ulaw[(v + 32768) >> 2];\n\n        }\n\n        break;\n\n    default:\n\n        return -1;\n\n    }\n\n\n\n    *got_packet_ptr = 1;\n\n    return 0;\n\n}\n", "idx": 25061}
{"project": "FFmpeg", "commit_id": "80ee9fc0e305b815b4b67bbf8fa9ceccdc1d369e", "target": 0, "func": "static int RENAME(epzs_motion_search)(MpegEncContext * s,\n\n                             int *mx_ptr, int *my_ptr,\n\n                             int P[10][2], int pred_x, int pred_y, uint8_t *src_data[3], \n\n                             uint8_t *ref_data[3], int stride, int uvstride, int16_t (*last_mv)[2], \n\n                             int ref_mv_scale, uint8_t * const mv_penalty)\n\n{\n\n    int best[2]={0, 0};\n\n    int d, dmin; \n\n    const int shift= 1+s->quarter_sample;\n\n    uint32_t *map= s->me.map;\n\n    int map_generation;\n\n    const int penalty_factor= s->me.penalty_factor;\n\n    const int size=0;\n\n    const int h=16;\n\n    const int ref_mv_stride= s->mb_stride; //pass as arg  FIXME\n\n    const int ref_mv_xy= s->mb_x + s->mb_y*ref_mv_stride; //add to last_mv beforepassing FIXME\n\n    me_cmp_func cmp, chroma_cmp;\n\n    LOAD_COMMON\n\n    \n\n    cmp= s->dsp.me_cmp[size];\n\n    chroma_cmp= s->dsp.me_cmp[size+1];\n\n    \n\n    map_generation= update_map_generation(s);\n\n\n\n    CMP(dmin, 0, 0, size);\n\n    map[0]= map_generation;\n\n    score_map[0]= dmin;\n\n\n\n    /* first line */\n\n    if (s->first_slice_line) {\n\n        CHECK_MV(P_LEFT[0]>>shift, P_LEFT[1]>>shift)\n\n        CHECK_CLIPED_MV((last_mv[ref_mv_xy][0]*ref_mv_scale + (1<<15))>>16, \n\n                        (last_mv[ref_mv_xy][1]*ref_mv_scale + (1<<15))>>16)\n\n    }else{\n\n        if(dmin<256 && ( P_LEFT[0]    |P_LEFT[1]\n\n                        |P_TOP[0]     |P_TOP[1]\n\n                        |P_TOPRIGHT[0]|P_TOPRIGHT[1])==0){\n\n            *mx_ptr= 0;\n\n            *my_ptr= 0;\n\n            s->me.skip=1;\n\n            return dmin;\n\n        }\n\n        CHECK_MV(P_MEDIAN[0]>>shift, P_MEDIAN[1]>>shift)\n\n        if(dmin>256*2){\n\n            CHECK_CLIPED_MV((last_mv[ref_mv_xy][0]*ref_mv_scale + (1<<15))>>16, \n\n                            (last_mv[ref_mv_xy][1]*ref_mv_scale + (1<<15))>>16)\n\n            CHECK_MV(P_LEFT[0]    >>shift, P_LEFT[1]    >>shift)\n\n            CHECK_MV(P_TOP[0]     >>shift, P_TOP[1]     >>shift)\n\n            CHECK_MV(P_TOPRIGHT[0]>>shift, P_TOPRIGHT[1]>>shift)\n\n        }\n\n    }\n\n    if(dmin>256*4){\n\n        if(s->me.pre_pass){\n\n            CHECK_CLIPED_MV((last_mv[ref_mv_xy-1][0]*ref_mv_scale + (1<<15))>>16, \n\n                            (last_mv[ref_mv_xy-1][1]*ref_mv_scale + (1<<15))>>16)\n\n            if(!s->first_slice_line)\n\n                CHECK_CLIPED_MV((last_mv[ref_mv_xy-ref_mv_stride][0]*ref_mv_scale + (1<<15))>>16, \n\n                                (last_mv[ref_mv_xy-ref_mv_stride][1]*ref_mv_scale + (1<<15))>>16)\n\n        }else{\n\n            CHECK_CLIPED_MV((last_mv[ref_mv_xy+1][0]*ref_mv_scale + (1<<15))>>16, \n\n                            (last_mv[ref_mv_xy+1][1]*ref_mv_scale + (1<<15))>>16)\n\n            if(s->end_mb_y == s->mb_height || s->mb_y+1<s->end_mb_y)  //FIXME replace at least with last_slice_line\n\n                CHECK_CLIPED_MV((last_mv[ref_mv_xy+ref_mv_stride][0]*ref_mv_scale + (1<<15))>>16, \n\n                                (last_mv[ref_mv_xy+ref_mv_stride][1]*ref_mv_scale + (1<<15))>>16)\n\n        }\n\n    }\n\n\n\n    if(s->avctx->last_predictor_count){\n\n        const int count= s->avctx->last_predictor_count;\n\n        const int xstart= FFMAX(0, s->mb_x - count);\n\n        const int ystart= FFMAX(0, s->mb_y - count);\n\n        const int xend= FFMIN(s->mb_width , s->mb_x + count + 1);\n\n        const int yend= FFMIN(s->mb_height, s->mb_y + count + 1);\n\n        int mb_y;\n\n\n\n        for(mb_y=ystart; mb_y<yend; mb_y++){\n\n            int mb_x;\n\n            for(mb_x=xstart; mb_x<xend; mb_x++){\n\n                const int xy= mb_x + 1 + (mb_y + 1)*ref_mv_stride;\n\n                int mx= (last_mv[xy][0]*ref_mv_scale + (1<<15))>>16;\n\n                int my= (last_mv[xy][1]*ref_mv_scale + (1<<15))>>16;\n\n\n\n                if(mx>xmax || mx<xmin || my>ymax || my<ymin) continue;\n\n                CHECK_MV(mx,my)\n\n            }\n\n        }\n\n    }\n\n\n\n//check(best[0],best[1],0, b0)\n\n    if(s->me.dia_size==-1)\n\n        dmin= RENAME(funny_diamond_search)(s, best, dmin, src_data, ref_data, stride, uvstride,\n\n                                   pred_x, pred_y, penalty_factor, \n\n\t\t\t\t   shift, map, map_generation, size, h, mv_penalty);\n\n    else if(s->me.dia_size<-1)\n\n        dmin= RENAME(sab_diamond_search)(s, best, dmin, src_data, ref_data, stride, uvstride,\n\n                                   pred_x, pred_y, penalty_factor, \n\n\t\t\t\t   shift, map, map_generation, size, h, mv_penalty);\n\n    else if(s->me.dia_size<2)\n\n        dmin= RENAME(small_diamond_search)(s, best, dmin, src_data, ref_data, stride, uvstride,\n\n                                   pred_x, pred_y, penalty_factor, \n\n\t\t\t\t   shift, map, map_generation, size, h, mv_penalty);\n\n    else\n\n        dmin= RENAME(var_diamond_search)(s, best, dmin, src_data, ref_data, stride, uvstride,\n\n                                   pred_x, pred_y, penalty_factor, \n\n\t\t\t\t   shift, map, map_generation, size, h, mv_penalty);\n\n\n\n//check(best[0],best[1],0, b1)\n\n    *mx_ptr= best[0];\n\n    *my_ptr= best[1];    \n\n\n\n//    printf(\"%d %d %d \\n\", best[0], best[1], dmin);\n\n    return dmin;\n\n}\n", "idx": 25062}
{"project": "FFmpeg", "commit_id": "6138ed777db101c26d19b96e6a27b8499ab9f4e7", "target": 1, "func": "static int decode_residual_block(AVSContext *h, GetBitContext *gb,\n\n                                 const dec_2dvlc_t *r, int esc_golomb_order,\n\n                                 int qp, uint8_t *dst, int stride) {\n\n    int i, level_code, esc_code, level, run, mask;\n\n    DCTELEM level_buf[64];\n\n    uint8_t run_buf[64];\n\n    DCTELEM *block = h->block;\n\n\n\n    for(i=0;i<65;i++) {\n\n        level_code = get_ue_code(gb,r->golomb_order);\n\n        if(level_code >= ESCAPE_CODE) {\n\n            run = ((level_code - ESCAPE_CODE) >> 1) + 1;\n\n            esc_code = get_ue_code(gb,esc_golomb_order);\n\n            level = esc_code + (run > r->max_run ? 1 : r->level_add[run]);\n\n            while(level > r->inc_limit)\n\n                r++;\n\n            mask = -(level_code & 1);\n\n            level = (level^mask) - mask;\n\n        } else {\n\n            level = r->rltab[level_code][0];\n\n            if(!level) //end of block signal\n\n                break;\n\n            run   = r->rltab[level_code][1];\n\n            r += r->rltab[level_code][2];\n\n        }\n\n        level_buf[i] = level;\n\n        run_buf[i] = run;\n\n    }\n\n    if(dequant(h,level_buf, run_buf, block, ff_cavs_dequant_mul[qp],\n\n               ff_cavs_dequant_shift[qp], i))\n\n        return -1;\n\n    h->s.dsp.cavs_idct8_add(dst,block,stride);\n\n    return 0;\n\n}\n", "idx": 25064}
{"project": "FFmpeg", "commit_id": "1269cd5b6f540bef5913bf134d2f461aac50d70b", "target": 1, "func": "int ff_thread_decode_frame(AVCodecContext *avctx,\n\n                           AVFrame *picture, int *got_picture_ptr,\n\n                           AVPacket *avpkt)\n\n{\n\n    FrameThreadContext *fctx = avctx->internal->thread_ctx;\n\n    int finished = fctx->next_finished;\n\n    PerThreadContext *p;\n\n    int err;\n\n\n\n    /* release the async lock, permitting blocked hwaccel threads to\n\n     * go forward while we are in this function */\n\n    async_unlock(fctx);\n\n\n\n    /*\n\n     * Submit a packet to the next decoding thread.\n\n     */\n\n\n\n    p = &fctx->threads[fctx->next_decoding];\n\n    err = update_context_from_user(p->avctx, avctx);\n\n    if (err)\n\n        goto finish;\n\n    err = submit_packet(p, avpkt);\n\n    if (err)\n\n        goto finish;\n\n\n\n    /*\n\n     * If we're still receiving the initial packets, don't return a frame.\n\n     */\n\n\n\n    if (fctx->next_decoding > (avctx->thread_count-1-(avctx->codec_id == AV_CODEC_ID_FFV1)))\n\n        fctx->delaying = 0;\n\n\n\n    if (fctx->delaying) {\n\n        *got_picture_ptr=0;\n\n        if (avpkt->size) {\n\n            err = avpkt->size;\n\n            goto finish;\n\n        }\n\n    }\n\n\n\n    /*\n\n     * Return the next available frame from the oldest thread.\n\n     * If we're at the end of the stream, then we have to skip threads that\n\n     * didn't output a frame, because we don't want to accidentally signal\n\n     * EOF (avpkt->size == 0 && *got_picture_ptr == 0).\n\n     */\n\n\n\n    do {\n\n        p = &fctx->threads[finished++];\n\n\n\n        if (atomic_load(&p->state) != STATE_INPUT_READY) {\n\n            pthread_mutex_lock(&p->progress_mutex);\n\n            while (atomic_load_explicit(&p->state, memory_order_relaxed) != STATE_INPUT_READY)\n\n                pthread_cond_wait(&p->output_cond, &p->progress_mutex);\n\n            pthread_mutex_unlock(&p->progress_mutex);\n\n        }\n\n\n\n        av_frame_move_ref(picture, p->frame);\n\n        *got_picture_ptr = p->got_frame;\n\n        picture->pkt_dts = p->avpkt.dts;\n\n\n\n        if (p->result < 0)\n\n            err = p->result;\n\n\n\n        /*\n\n         * A later call with avkpt->size == 0 may loop over all threads,\n\n         * including this one, searching for a frame to return before being\n\n         * stopped by the \"finished != fctx->next_finished\" condition.\n\n         * Make sure we don't mistakenly return the same frame again.\n\n         */\n\n        p->got_frame = 0;\n\n\n\n        if (finished >= avctx->thread_count) finished = 0;\n\n    } while (!avpkt->size && !*got_picture_ptr && finished != fctx->next_finished);\n\n\n\n    update_context_from_thread(avctx, p->avctx, 1);\n\n\n\n    if (fctx->next_decoding >= avctx->thread_count) fctx->next_decoding = 0;\n\n\n\n    fctx->next_finished = finished;\n\n\n\n    /* return the size of the consumed packet if no error occurred */\n\n    if (err >= 0)\n\n        err = avpkt->size;\n\nfinish:\n\n    async_lock(fctx);\n\n    return err;\n\n}\n", "idx": 25065}
{"project": "FFmpeg", "commit_id": "39e0accb7a934bfe3d42324b016dd8790790746d", "target": 1, "func": "static unsigned int find_best(struct vf_instance *vf){\n\n  int is_format_okay = vf->next->query_format(vf->next, IMGFMT_YV12);\n\n  if ((is_format_okay & VFCAP_CSP_SUPPORTED_BY_HW) || (is_format_okay & VFCAP_CSP_SUPPORTED))\n\n    return IMGFMT_YV12;\n\n  else\n\n    return 0;\n\n}\n", "idx": 25066}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int swf_probe(AVProbeData *p)\n\n{\n\n    /* check file header */\n\n    if (p->buf_size <= 16)\n\n        return 0;\n\n    if ((p->buf[0] == 'F' || p->buf[0] == 'C') && p->buf[1] == 'W' &&\n\n        p->buf[2] == 'S')\n\n        return AVPROBE_SCORE_MAX;\n\n    else\n\n        return 0;\n\n}\n", "idx": 25069}
{"project": "FFmpeg", "commit_id": "4240e6a92117811509be3e5f360a44dde8618040", "target": 0, "func": "static int16_t *precalc_coefs(double dist25, int depth)\n\n{\n\n    int i;\n\n    double gamma, simil, C;\n\n    int16_t *ct = av_malloc((512<<LUT_BITS)*sizeof(int16_t));\n\n    if (!ct)\n\n        return NULL;\n\n\n\n    gamma = log(0.25) / log(1.0 - FFMIN(dist25,252.0)/255.0 - 0.00001);\n\n\n\n    for (i = -255<<LUT_BITS; i <= 255<<LUT_BITS; i++) {\n\n        double f = ((i<<(9-LUT_BITS)) + (1<<(8-LUT_BITS)) - 1) / 512.0; // midpoint of the bin\n\n        simil = 1.0 - FFABS(f) / 255.0;\n\n        C = pow(simil, gamma) * 256.0 * f;\n\n        ct[(256<<LUT_BITS)+i] = lrint(C);\n\n    }\n\n\n\n    ct[0] = !!dist25;\n\n    return ct;\n\n}\n", "idx": 25070}
{"project": "FFmpeg", "commit_id": "4bb1070c154e49d35805fbcdac9c9e92f702ef96", "target": 0, "func": "void ffv1_clear_slice_state(FFV1Context *f, FFV1Context *fs)\n\n{\n\n    int i, j;\n\n\n\n    for (i = 0; i < f->plane_count; i++) {\n\n        PlaneContext *p = &fs->plane[i];\n\n\n\n        p->interlace_bit_state[0] = 128;\n\n        p->interlace_bit_state[1] = 128;\n\n\n\n        if (fs->ac) {\n\n            if (f->initial_states[p->quant_table_index]) {\n\n                memcpy(p->state, f->initial_states[p->quant_table_index],\n\n                       CONTEXT_SIZE * p->context_count);\n\n            } else\n\n                memset(p->state, 128, CONTEXT_SIZE * p->context_count);\n\n        } else {\n\n            for (j = 0; j < p->context_count; j++) {\n\n                p->vlc_state[j].drift     = 0;\n\n                p->vlc_state[j].error_sum = 4;    //FFMAX((RANGE + 32)/64, 2);\n\n                p->vlc_state[j].bias      = 0;\n\n                p->vlc_state[j].count     = 1;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 25071}
{"project": "FFmpeg", "commit_id": "bcd7bf7eeb09a395cc01698842d1b8be9af483fc", "target": 0, "func": "static void avc_biwgt_4x2_msa(uint8_t *src,\n\n                              int32_t src_stride,\n\n                              uint8_t *dst,\n\n                              int32_t dst_stride,\n\n                              int32_t log2_denom,\n\n                              int32_t src_weight,\n\n                              int32_t dst_weight,\n\n                              int32_t offset_in)\n\n{\n\n    uint32_t load0, load1, out0, out1;\n\n    v16i8 src_wgt, dst_wgt, wgt;\n\n    v16i8 src0, src1, dst0, dst1;\n\n    v8i16 temp0, temp1, denom, offset, add_val;\n\n    int32_t val = 128 * (src_weight + dst_weight);\n\n\n\n    offset_in = ((offset_in + 1) | 1) << log2_denom;\n\n\n\n    src_wgt = __msa_fill_b(src_weight);\n\n    dst_wgt = __msa_fill_b(dst_weight);\n\n    offset = __msa_fill_h(offset_in);\n\n    denom = __msa_fill_h(log2_denom + 1);\n\n    add_val = __msa_fill_h(val);\n\n    offset += add_val;\n\n\n\n    wgt = __msa_ilvev_b(dst_wgt, src_wgt);\n\n\n\n    load0 = LOAD_WORD(src);\n\n    src += src_stride;\n\n    load1 = LOAD_WORD(src);\n\n\n\n    src0 = (v16i8) __msa_fill_w(load0);\n\n    src1 = (v16i8) __msa_fill_w(load1);\n\n\n\n    load0 = LOAD_WORD(dst);\n\n    load1 = LOAD_WORD(dst + dst_stride);\n\n\n\n    dst0 = (v16i8) __msa_fill_w(load0);\n\n    dst1 = (v16i8) __msa_fill_w(load1);\n\n\n\n    XORI_B_4VECS_SB(src0, src1, dst0, dst1, src0, src1, dst0, dst1, 128);\n\n\n\n    ILVR_B_2VECS_SH(src0, src1, dst0, dst1, temp0, temp1);\n\n\n\n    temp0 = __msa_dpadd_s_h(offset, wgt, (v16i8) temp0);\n\n    temp1 = __msa_dpadd_s_h(offset, wgt, (v16i8) temp1);\n\n\n\n    temp0 >>= denom;\n\n    temp1 >>= denom;\n\n\n\n    temp0 = CLIP_UNSIGNED_CHAR_H(temp0);\n\n    temp1 = CLIP_UNSIGNED_CHAR_H(temp1);\n\n\n\n    dst0 = __msa_pckev_b((v16i8) temp0, (v16i8) temp0);\n\n    dst1 = __msa_pckev_b((v16i8) temp1, (v16i8) temp1);\n\n\n\n    out0 = __msa_copy_u_w((v4i32) dst0, 0);\n\n    out1 = __msa_copy_u_w((v4i32) dst1, 0);\n\n\n\n    STORE_WORD(dst, out0);\n\n    dst += dst_stride;\n\n    STORE_WORD(dst, out1);\n\n}\n", "idx": 25072}
{"project": "FFmpeg", "commit_id": "fdbc544d29176ba69d67dd879df4696f0a19052e", "target": 1, "func": "static int asf_read_value(AVFormatContext *s, uint8_t *name, uint16_t name_len,\n\n                          uint16_t val_len, int type, AVDictionary **met)\n\n{\n\n    int ret;\n\n    uint8_t *value;\n\n    uint16_t buflen = 2 * val_len + 1;\n\n    AVIOContext *pb = s->pb;\n\n\n\n    value = av_malloc(buflen);\n\n    if (!value)\n\n        return AVERROR(ENOMEM);\n\n    if (type == ASF_UNICODE) {\n\n        // get_asf_string reads UTF-16 and converts it to UTF-8 which needs longer buffer\n\n        if ((ret = get_asf_string(pb, val_len, value, buflen)) < 0)\n\n            goto failed;\n\n        if (av_dict_set(met, name, value, 0) < 0)\n\n            av_log(s, AV_LOG_WARNING, \"av_dict_set failed.\\n\");\n\n    } else {\n\n        char buf[256];\n\n        if (val_len > sizeof(buf)) {\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto failed;\n\n        }\n\n        if ((ret = avio_read(pb, value, val_len)) < 0)\n\n            goto failed;\n\n        if (ret < 2 * val_len)\n\n            value[ret] = '\\0';\n\n        else\n\n            value[2 * val_len - 1] = '\\0';\n\n        snprintf(buf, sizeof(buf), \"%s\", value);\n\n        if (av_dict_set(met, name, buf, 0) < 0)\n\n            av_log(s, AV_LOG_WARNING, \"av_dict_set failed.\\n\");\n\n    }\n\n    av_freep(&value);\n\n\n\n    return 0;\n\n\n\nfailed:\n\n    av_freep(&value);\n\n    return ret;\n\n}\n", "idx": 25073}
{"project": "FFmpeg", "commit_id": "d8dccf69ff2df7014a2bb8e0e17828a820f45b27", "target": 1, "func": "static int av_buffersrc_add_frame_internal(AVFilterContext *ctx,\n\n                                           AVFrame *frame, int flags)\n\n{\n\n    BufferSourceContext *s = ctx->priv;\n\n    AVFrame *copy;\n\n    int ret;\n\n\n\n    if (!frame) {\n\n        s->eof = 1;\n\n        return 0;\n\n    } else if (s->eof)\n\n        return AVERROR(EINVAL);\n\n\n\n    if (!(flags & AV_BUFFERSRC_FLAG_NO_CHECK_FORMAT)) {\n\n\n\n    switch (ctx->outputs[0]->type) {\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        CHECK_VIDEO_PARAM_CHANGE(ctx, s, frame->width, frame->height,\n\n                                 frame->format);\n\n        break;\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        CHECK_AUDIO_PARAM_CHANGE(ctx, s, frame->sample_rate, frame->channel_layout,\n\n                                 frame->format);\n\n        break;\n\n    default:\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    }\n\n\n\n    if (!av_fifo_space(s->fifo) &&\n\n        (ret = av_fifo_realloc2(s->fifo, av_fifo_size(s->fifo) +\n\n                                         sizeof(copy))) < 0)\n\n        return ret;\n\n\n\n    if (!(copy = av_frame_alloc()))\n\n        return AVERROR(ENOMEM);\n\n    av_frame_move_ref(copy, frame);\n\n\n\n    if ((ret = av_fifo_generic_write(s->fifo, &copy, sizeof(copy), NULL)) < 0) {\n\n        av_frame_move_ref(frame, copy);\n\n        av_frame_free(&copy);\n\n        return ret;\n\n    }\n\n\n\n    if ((flags & AV_BUFFERSRC_FLAG_PUSH))\n\n        if ((ret = ctx->output_pads[0].request_frame(ctx->outputs[0])) < 0)\n\n            return ret;\n\n\n\n    return 0;\n\n}\n", "idx": 25077}
{"project": "FFmpeg", "commit_id": "1007a805a486a1348a0543ac2dd99d823148d25c", "target": 1, "func": "static void smc_decode_stream(SmcContext *s)\n\n{\n\n    int width = s->avctx->width;\n\n    int height = s->avctx->height;\n\n    int stride = s->frame.linesize[0];\n\n    int i;\n\n    int stream_ptr = 0;\n\n    int chunk_size;\n\n    unsigned char opcode;\n\n    int n_blocks;\n\n    unsigned int color_flags;\n\n    unsigned int color_flags_a;\n\n    unsigned int color_flags_b;\n\n    unsigned int flag_mask;\n\n\n\n    unsigned char *pixels = s->frame.data[0];\n\n\n\n    int image_size = height * s->frame.linesize[0];\n\n    int row_ptr = 0;\n\n    int pixel_ptr = 0;\n\n    int pixel_x, pixel_y;\n\n    int row_inc = stride - 4;\n\n    int block_ptr;\n\n    int prev_block_ptr;\n\n    int prev_block_ptr1, prev_block_ptr2;\n\n    int prev_block_flag;\n\n    int total_blocks;\n\n    int color_table_index;  /* indexes to color pair, quad, or octet tables */\n\n    int pixel;\n\n\n\n    int color_pair_index = 0;\n\n    int color_quad_index = 0;\n\n    int color_octet_index = 0;\n\n\n\n    /* make the palette available */\n\n    memcpy(s->frame.data[1], s->pal, AVPALETTE_SIZE);\n\n\n\n    chunk_size = AV_RB32(&s->buf[stream_ptr]) & 0x00FFFFFF;\n\n    stream_ptr += 4;\n\n    if (chunk_size != s->size)\n\n        av_log(s->avctx, AV_LOG_INFO, \"warning: MOV chunk size != encoded chunk size (%d != %d); using MOV chunk size\\n\",\n\n            chunk_size, s->size);\n\n\n\n    chunk_size = s->size;\n\n    total_blocks = ((s->avctx->width + 3) / 4) * ((s->avctx->height + 3) / 4);\n\n\n\n    /* traverse through the blocks */\n\n    while (total_blocks) {\n\n        /* sanity checks */\n\n        /* make sure stream ptr hasn't gone out of bounds */\n\n        if (stream_ptr > chunk_size) {\n\n            av_log(s->avctx, AV_LOG_INFO, \"SMC decoder just went out of bounds (stream ptr = %d, chunk size = %d)\\n\",\n\n                stream_ptr, chunk_size);\n\n            return;\n\n        }\n\n        /* make sure the row pointer hasn't gone wild */\n\n        if (row_ptr >= image_size) {\n\n            av_log(s->avctx, AV_LOG_INFO, \"SMC decoder just went out of bounds (row ptr = %d, height = %d)\\n\",\n\n                row_ptr, image_size);\n\n            return;\n\n        }\n\n\n\n        opcode = s->buf[stream_ptr++];\n\n        switch (opcode & 0xF0) {\n\n        /* skip n blocks */\n\n        case 0x00:\n\n        case 0x10:\n\n            n_blocks = GET_BLOCK_COUNT();\n\n            while (n_blocks--) {\n\n                ADVANCE_BLOCK();\n\n            }\n\n            break;\n\n\n\n        /* repeat last block n times */\n\n        case 0x20:\n\n        case 0x30:\n\n            n_blocks = GET_BLOCK_COUNT();\n\n\n\n            /* sanity check */\n\n            if ((row_ptr == 0) && (pixel_ptr == 0)) {\n\n                av_log(s->avctx, AV_LOG_INFO, \"encountered repeat block opcode (%02X) but no blocks rendered yet\\n\",\n\n                    opcode & 0xF0);\n\n                break;\n\n            }\n\n\n\n            /* figure out where the previous block started */\n\n            if (pixel_ptr == 0)\n\n                prev_block_ptr1 =\n\n                    (row_ptr - s->avctx->width * 4) + s->avctx->width - 4;\n\n            else\n\n                prev_block_ptr1 = row_ptr + pixel_ptr - 4;\n\n\n\n            while (n_blocks--) {\n\n                block_ptr = row_ptr + pixel_ptr;\n\n                prev_block_ptr = prev_block_ptr1;\n\n                for (pixel_y = 0; pixel_y < 4; pixel_y++) {\n\n                    for (pixel_x = 0; pixel_x < 4; pixel_x++) {\n\n                        pixels[block_ptr++] = pixels[prev_block_ptr++];\n\n                    }\n\n                    block_ptr += row_inc;\n\n                    prev_block_ptr += row_inc;\n\n                }\n\n                ADVANCE_BLOCK();\n\n            }\n\n            break;\n\n\n\n        /* repeat previous pair of blocks n times */\n\n        case 0x40:\n\n        case 0x50:\n\n            n_blocks = GET_BLOCK_COUNT();\n\n            n_blocks *= 2;\n\n\n\n            /* sanity check */\n\n            if ((row_ptr == 0) && (pixel_ptr < 2 * 4)) {\n\n                av_log(s->avctx, AV_LOG_INFO, \"encountered repeat block opcode (%02X) but not enough blocks rendered yet\\n\",\n\n                    opcode & 0xF0);\n\n                break;\n\n            }\n\n\n\n            /* figure out where the previous 2 blocks started */\n\n            if (pixel_ptr == 0)\n\n                prev_block_ptr1 = (row_ptr - s->avctx->width * 4) +\n\n                    s->avctx->width - 4 * 2;\n\n            else if (pixel_ptr == 4)\n\n                prev_block_ptr1 = (row_ptr - s->avctx->width * 4) + row_inc;\n\n            else\n\n                prev_block_ptr1 = row_ptr + pixel_ptr - 4 * 2;\n\n\n\n            if (pixel_ptr == 0)\n\n                prev_block_ptr2 = (row_ptr - s->avctx->width * 4) + row_inc;\n\n            else\n\n                prev_block_ptr2 = row_ptr + pixel_ptr - 4;\n\n\n\n            prev_block_flag = 0;\n\n            while (n_blocks--) {\n\n                block_ptr = row_ptr + pixel_ptr;\n\n                if (prev_block_flag)\n\n                    prev_block_ptr = prev_block_ptr2;\n\n                else\n\n                    prev_block_ptr = prev_block_ptr1;\n\n                prev_block_flag = !prev_block_flag;\n\n\n\n                for (pixel_y = 0; pixel_y < 4; pixel_y++) {\n\n                    for (pixel_x = 0; pixel_x < 4; pixel_x++) {\n\n                        pixels[block_ptr++] = pixels[prev_block_ptr++];\n\n                    }\n\n                    block_ptr += row_inc;\n\n                    prev_block_ptr += row_inc;\n\n                }\n\n                ADVANCE_BLOCK();\n\n            }\n\n            break;\n\n\n\n        /* 1-color block encoding */\n\n        case 0x60:\n\n        case 0x70:\n\n            n_blocks = GET_BLOCK_COUNT();\n\n            pixel = s->buf[stream_ptr++];\n\n\n\n            while (n_blocks--) {\n\n                block_ptr = row_ptr + pixel_ptr;\n\n                for (pixel_y = 0; pixel_y < 4; pixel_y++) {\n\n                    for (pixel_x = 0; pixel_x < 4; pixel_x++) {\n\n                        pixels[block_ptr++] = pixel;\n\n                    }\n\n                    block_ptr += row_inc;\n\n                }\n\n                ADVANCE_BLOCK();\n\n            }\n\n            break;\n\n\n\n        /* 2-color block encoding */\n\n        case 0x80:\n\n        case 0x90:\n\n            n_blocks = (opcode & 0x0F) + 1;\n\n\n\n            /* figure out which color pair to use to paint the 2-color block */\n\n            if ((opcode & 0xF0) == 0x80) {\n\n                /* fetch the next 2 colors from bytestream and store in next\n\n                 * available entry in the color pair table */\n\n                for (i = 0; i < CPAIR; i++) {\n\n                    pixel = s->buf[stream_ptr++];\n\n                    color_table_index = CPAIR * color_pair_index + i;\n\n                    s->color_pairs[color_table_index] = pixel;\n\n                }\n\n                /* this is the base index to use for this block */\n\n                color_table_index = CPAIR * color_pair_index;\n\n                color_pair_index++;\n\n                /* wraparound */\n\n                if (color_pair_index == COLORS_PER_TABLE)\n\n                    color_pair_index = 0;\n\n            } else\n\n                color_table_index = CPAIR * s->buf[stream_ptr++];\n\n\n\n            while (n_blocks--) {\n\n                color_flags = AV_RB16(&s->buf[stream_ptr]);\n\n                stream_ptr += 2;\n\n                flag_mask = 0x8000;\n\n                block_ptr = row_ptr + pixel_ptr;\n\n                for (pixel_y = 0; pixel_y < 4; pixel_y++) {\n\n                    for (pixel_x = 0; pixel_x < 4; pixel_x++) {\n\n                        if (color_flags & flag_mask)\n\n                            pixel = color_table_index + 1;\n\n                        else\n\n                            pixel = color_table_index;\n\n                        flag_mask >>= 1;\n\n                        pixels[block_ptr++] = s->color_pairs[pixel];\n\n                    }\n\n                    block_ptr += row_inc;\n\n                }\n\n                ADVANCE_BLOCK();\n\n            }\n\n            break;\n\n\n\n        /* 4-color block encoding */\n\n        case 0xA0:\n\n        case 0xB0:\n\n            n_blocks = (opcode & 0x0F) + 1;\n\n\n\n            /* figure out which color quad to use to paint the 4-color block */\n\n            if ((opcode & 0xF0) == 0xA0) {\n\n                /* fetch the next 4 colors from bytestream and store in next\n\n                 * available entry in the color quad table */\n\n                for (i = 0; i < CQUAD; i++) {\n\n                    pixel = s->buf[stream_ptr++];\n\n                    color_table_index = CQUAD * color_quad_index + i;\n\n                    s->color_quads[color_table_index] = pixel;\n\n                }\n\n                /* this is the base index to use for this block */\n\n                color_table_index = CQUAD * color_quad_index;\n\n                color_quad_index++;\n\n                /* wraparound */\n\n                if (color_quad_index == COLORS_PER_TABLE)\n\n                    color_quad_index = 0;\n\n            } else\n\n                color_table_index = CQUAD * s->buf[stream_ptr++];\n\n\n\n            while (n_blocks--) {\n\n                color_flags = AV_RB32(&s->buf[stream_ptr]);\n\n                stream_ptr += 4;\n\n                /* flag mask actually acts as a bit shift count here */\n\n                flag_mask = 30;\n\n                block_ptr = row_ptr + pixel_ptr;\n\n                for (pixel_y = 0; pixel_y < 4; pixel_y++) {\n\n                    for (pixel_x = 0; pixel_x < 4; pixel_x++) {\n\n                        pixel = color_table_index +\n\n                            ((color_flags >> flag_mask) & 0x03);\n\n                        flag_mask -= 2;\n\n                        pixels[block_ptr++] = s->color_quads[pixel];\n\n                    }\n\n                    block_ptr += row_inc;\n\n                }\n\n                ADVANCE_BLOCK();\n\n            }\n\n            break;\n\n\n\n        /* 8-color block encoding */\n\n        case 0xC0:\n\n        case 0xD0:\n\n            n_blocks = (opcode & 0x0F) + 1;\n\n\n\n            /* figure out which color octet to use to paint the 8-color block */\n\n            if ((opcode & 0xF0) == 0xC0) {\n\n                /* fetch the next 8 colors from bytestream and store in next\n\n                 * available entry in the color octet table */\n\n                for (i = 0; i < COCTET; i++) {\n\n                    pixel = s->buf[stream_ptr++];\n\n                    color_table_index = COCTET * color_octet_index + i;\n\n                    s->color_octets[color_table_index] = pixel;\n\n                }\n\n                /* this is the base index to use for this block */\n\n                color_table_index = COCTET * color_octet_index;\n\n                color_octet_index++;\n\n                /* wraparound */\n\n                if (color_octet_index == COLORS_PER_TABLE)\n\n                    color_octet_index = 0;\n\n            } else\n\n                color_table_index = COCTET * s->buf[stream_ptr++];\n\n\n\n            while (n_blocks--) {\n\n                /*\n\n                  For this input of 6 hex bytes:\n\n                    01 23 45 67 89 AB\n\n                  Mangle it to this output:\n\n                    flags_a = xx012456, flags_b = xx89A37B\n\n                */\n\n                /* build the color flags */\n\n                color_flags_a =\n\n                    ((AV_RB16(s->buf + stream_ptr    ) & 0xFFF0) << 8) |\n\n                     (AV_RB16(s->buf + stream_ptr + 2) >> 4);\n\n                color_flags_b =\n\n                    ((AV_RB16(s->buf + stream_ptr + 4) & 0xFFF0) << 8) |\n\n                    ((s->buf[stream_ptr + 1] & 0x0F) << 8) |\n\n                    ((s->buf[stream_ptr + 3] & 0x0F) << 4) |\n\n                    (s->buf[stream_ptr + 5] & 0x0F);\n\n                stream_ptr += 6;\n\n\n\n                color_flags = color_flags_a;\n\n                /* flag mask actually acts as a bit shift count here */\n\n                flag_mask = 21;\n\n                block_ptr = row_ptr + pixel_ptr;\n\n                for (pixel_y = 0; pixel_y < 4; pixel_y++) {\n\n                    /* reload flags at third row (iteration pixel_y == 2) */\n\n                    if (pixel_y == 2) {\n\n                        color_flags = color_flags_b;\n\n                        flag_mask = 21;\n\n                    }\n\n                    for (pixel_x = 0; pixel_x < 4; pixel_x++) {\n\n                        pixel = color_table_index +\n\n                            ((color_flags >> flag_mask) & 0x07);\n\n                        flag_mask -= 3;\n\n                        pixels[block_ptr++] = s->color_octets[pixel];\n\n                    }\n\n                    block_ptr += row_inc;\n\n                }\n\n                ADVANCE_BLOCK();\n\n            }\n\n            break;\n\n\n\n        /* 16-color block encoding (every pixel is a different color) */\n\n        case 0xE0:\n\n            n_blocks = (opcode & 0x0F) + 1;\n\n\n\n            while (n_blocks--) {\n\n                block_ptr = row_ptr + pixel_ptr;\n\n                for (pixel_y = 0; pixel_y < 4; pixel_y++) {\n\n                    for (pixel_x = 0; pixel_x < 4; pixel_x++) {\n\n                        pixels[block_ptr++] = s->buf[stream_ptr++];\n\n                    }\n\n                    block_ptr += row_inc;\n\n                }\n\n                ADVANCE_BLOCK();\n\n            }\n\n            break;\n\n\n\n        case 0xF0:\n\n            av_log(s->avctx, AV_LOG_INFO, \"0xF0 opcode seen in SMC chunk (contact the developers)\\n\");\n\n            break;\n\n        }\n\n    }\n\n}\n", "idx": 25080}
{"project": "FFmpeg", "commit_id": "5d5118f81bd51b9c33500616b3c637123e8e4691", "target": 1, "func": "static inline void idct_col(int16_t *blk, const uint8_t *quant)\n\n{\n\n    int t0, t1, t2, t3, t4, t5, t6, t7, t8, t9, tA, tB, tC, tD, tE, tF;\n\n    int t10, t11, t12, t13;\n\n    int s0, s1, s2, s3, s4, s5, s6, s7;\n\n\n\n    s0 = (int) blk[0 * 8] * quant[0 * 8];\n\n    s1 = (int) blk[1 * 8] * quant[1 * 8];\n\n    s2 = (int) blk[2 * 8] * quant[2 * 8];\n\n    s3 = (int) blk[3 * 8] * quant[3 * 8];\n\n    s4 = (int) blk[4 * 8] * quant[4 * 8];\n\n    s5 = (int) blk[5 * 8] * quant[5 * 8];\n\n    s6 = (int) blk[6 * 8] * quant[6 * 8];\n\n    s7 = (int) blk[7 * 8] * quant[7 * 8];\n\n\n\n    t0  =  (s3 * 19266 + s5 * 12873) >> 15;\n\n    t1  =  (s5 * 19266 - s3 * 12873) >> 15;\n\n    t2  = ((s7 * 4520  + s1 * 22725) >> 15) - t0;\n\n    t3  = ((s1 * 4520  - s7 * 22725) >> 15) - t1;\n\n    t4  = t0 * 2 + t2;\n\n    t5  = t1 * 2 + t3;\n\n    t6  = t2 - t3;\n\n    t7  = t3 * 2 + t6;\n\n    t8  = (t6 * 11585) >> 14;\n\n    t9  = (t7 * 11585) >> 14;\n\n    tA  = (s2 * 8867 - s6 * 21407) >> 14;\n\n    tB  = (s6 * 8867 + s2 * 21407) >> 14;\n\n    tC  = (s0 >> 1) - (s4 >> 1);\n\n    tD  = (s4 >> 1) * 2 + tC;\n\n    tE  = tC - (tA >> 1);\n\n    tF  = tD - (tB >> 1);\n\n    t10 = tF - t5;\n\n    t11 = tE - t8;\n\n    t12 = tE + (tA >> 1) * 2 - t9;\n\n    t13 = tF + (tB >> 1) * 2 - t4;\n\n\n\n    blk[0 * 8] = t13 + t4 * 2;\n\n    blk[1 * 8] = t12 + t9 * 2;\n\n    blk[2 * 8] = t11 + t8 * 2;\n\n    blk[3 * 8] = t10 + t5 * 2;\n\n    blk[4 * 8] = t10;\n\n    blk[5 * 8] = t11;\n\n    blk[6 * 8] = t12;\n\n    blk[7 * 8] = t13;\n\n}\n", "idx": 25081}
{"project": "FFmpeg", "commit_id": "c4c0245686bc2fcc545644101c7b328fed71f268", "target": 1, "func": "static int estimate_sid_gain(G723_1_Context *p)\n\n{\n\n    int i, shift, seg, seg2, t, val, val_add, x, y;\n\n\n\n    shift = 16 - p->cur_gain * 2;\n\n    if (shift > 0)\n\n        t = p->sid_gain << shift;\n\n    else\n\n        t = p->sid_gain >> -shift;\n\n    x = av_clipl_int32(t * (int64_t)cng_filt[0] >> 16);\n\n\n\n    if (x >= cng_bseg[2])\n\n        return 0x3F;\n\n\n\n    if (x >= cng_bseg[1]) {\n\n        shift = 4;\n\n        seg   = 3;\n\n    } else {\n\n        shift = 3;\n\n        seg   = (x >= cng_bseg[0]);\n\n    }\n\n    seg2 = FFMIN(seg, 3);\n\n\n\n    val     = 1 << shift;\n\n    val_add = val >> 1;\n\n    for (i = 0; i < shift; i++) {\n\n        t = seg * 32 + (val << seg2);\n\n        t *= t;\n\n        if (x >= t)\n\n            val += val_add;\n\n        else\n\n            val -= val_add;\n\n        val_add >>= 1;\n\n    }\n\n\n\n    t = seg * 32 + (val << seg2);\n\n    y = t * t - x;\n\n    if (y <= 0) {\n\n        t = seg * 32 + (val + 1 << seg2);\n\n        t = t * t - x;\n\n        val = (seg2 - 1 << 4) + val;\n\n        if (t >= y)\n\n            val++;\n\n    } else {\n\n        t = seg * 32 + (val - 1 << seg2);\n\n        t = t * t - x;\n\n        val = (seg2 - 1 << 4) + val;\n\n        if (t >= y)\n\n            val--;\n\n    }\n\n\n\n    return val;\n\n}\n", "idx": 25084}
{"project": "FFmpeg", "commit_id": "b4bccf3e4e58f6fe58043791ca09db01a4343fac", "target": 1, "func": "static int decode_exp_vlc(WMACodecContext *s, int ch)\n\n{\n\n    int last_exp, n, code;\n\n    const uint16_t *ptr;\n\n    float v, max_scale;\n\n    uint32_t *q, *q_end, iv;\n\n    const float *ptab = pow_tab + 60;\n\n    const uint32_t *iptab = (const uint32_t*)ptab;\n\n\n\n    ptr = s->exponent_bands[s->frame_len_bits - s->block_len_bits];\n\n    q = (uint32_t *)s->exponents[ch];\n\n    q_end = q + s->block_len;\n\n    max_scale = 0;\n\n    if (s->version == 1) {\n\n        last_exp = get_bits(&s->gb, 5) + 10;\n\n        v = ptab[last_exp];\n\n        iv = iptab[last_exp];\n\n        max_scale = v;\n\n        n = *ptr++;\n\n        switch (n & 3) do {\n\n        case 0: *q++ = iv;\n\n        case 3: *q++ = iv;\n\n        case 2: *q++ = iv;\n\n        case 1: *q++ = iv;\n\n        } while ((n -= 4) > 0);\n\n    }else\n\n        last_exp = 36;\n\n\n\n    while (q < q_end) {\n\n        code = get_vlc2(&s->gb, s->exp_vlc.table, EXPVLCBITS, EXPMAX);\n\n        if (code < 0){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Exponent vlc invalid\\n\");\n\n            return -1;\n\n        }\n\n        /* NOTE: this offset is the same as MPEG4 AAC ! */\n\n        last_exp += code - 60;\n\n        if ((unsigned)last_exp + 60 > FF_ARRAY_ELEMS(pow_tab)) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Exponent out of range: %d\\n\",\n\n                   last_exp);\n\n            return -1;\n\n        }\n\n        v = ptab[last_exp];\n\n        iv = iptab[last_exp];\n\n        if (v > max_scale)\n\n            max_scale = v;\n\n        n = *ptr++;\n\n        switch (n & 3) do {\n\n        case 0: *q++ = iv;\n\n        case 3: *q++ = iv;\n\n        case 2: *q++ = iv;\n\n        case 1: *q++ = iv;\n\n        } while ((n -= 4) > 0);\n\n    }\n\n    s->max_exponent[ch] = max_scale;\n\n    return 0;\n\n}\n", "idx": 25085}
{"project": "FFmpeg", "commit_id": "ae7a4a1594e3624f7c844dec44266d2dc74a6be2", "target": 1, "func": "static int decode(AVCodecContext *avctx, void *data, int *data_size, AVPacket *avpkt)\n\n{\n\n    BC_STATUS ret;\n\n    BC_DTS_STATUS decoder_status;\n\n    CopyRet rec_ret;\n\n    CHDContext *priv   = avctx->priv_data;\n\n    HANDLE dev         = priv->dev;\n\n    int len            = avpkt->size;\n\n    uint8_t pic_type   = 0;\n\n\n\n    av_log(avctx, AV_LOG_VERBOSE, \"CrystalHD: decode_frame\\n\");\n\n\n\n    if (len) {\n\n        int32_t tx_free = (int32_t)DtsTxFreeSize(dev);\n\n\n\n        if (priv->parser) {\n\n            uint8_t *pout;\n\n            int psize = len;\n\n            H264Context *h = priv->parser->priv_data;\n\n\n\n            while (psize)\n\n                ret = av_parser_parse2(priv->parser, avctx, &pout, &psize,\n\n                                       avpkt->data, len, avctx->pkt->pts,\n\n                                       avctx->pkt->dts, len - psize);\n\n            av_log(avctx, AV_LOG_VERBOSE,\n\n                   \"CrystalHD: parser picture type %d\\n\",\n\n                   h->s.picture_structure);\n\n            pic_type = h->s.picture_structure;\n\n        }\n\n\n\n        if (len < tx_free - 1024) {\n\n            /*\n\n             * Despite being notionally opaque, either libcrystalhd or\n\n             * the hardware itself will mangle pts values that are too\n\n             * small or too large. The docs claim it should be in units\n\n             * of 100ns. Given that we're nominally dealing with a black\n\n             * box on both sides, any transform we do has no guarantee of\n\n             * avoiding mangling so we need to build a mapping to values\n\n             * we know will not be mangled.\n\n             */\n\n            uint64_t pts = opaque_list_push(priv, avctx->pkt->pts, pic_type);\n\n            if (!pts) {\n\n                return AVERROR(ENOMEM);\n\n            }\n\n            av_log(priv->avctx, AV_LOG_VERBOSE,\n\n                   \"input \\\"pts\\\": %\"PRIu64\"\\n\", pts);\n\n            ret = DtsProcInput(dev, avpkt->data, len, pts, 0);\n\n            if (ret == BC_STS_BUSY) {\n\n                av_log(avctx, AV_LOG_WARNING,\n\n                       \"CrystalHD: ProcInput returned busy\\n\");\n\n                usleep(BASE_WAIT);\n\n                return AVERROR(EBUSY);\n\n            } else if (ret != BC_STS_SUCCESS) {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"CrystalHD: ProcInput failed: %u\\n\", ret);\n\n                return -1;\n\n            }\n\n            avctx->has_b_frames++;\n\n        } else {\n\n            av_log(avctx, AV_LOG_WARNING, \"CrystalHD: Input buffer full\\n\");\n\n            len = 0; // We didn't consume any bytes.\n\n        }\n\n    } else {\n\n        av_log(avctx, AV_LOG_INFO, \"CrystalHD: No more input data\\n\");\n\n    }\n\n\n\n    if (priv->skip_next_output) {\n\n        av_log(avctx, AV_LOG_VERBOSE, \"CrystalHD: Skipping next output.\\n\");\n\n        priv->skip_next_output = 0;\n\n        avctx->has_b_frames--;\n\n        return len;\n\n    }\n\n\n\n    ret = DtsGetDriverStatus(dev, &decoder_status);\n\n    if (ret != BC_STS_SUCCESS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"CrystalHD: GetDriverStatus failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /*\n\n     * No frames ready. Don't try to extract.\n\n     *\n\n     * Empirical testing shows that ReadyListCount can be a damn lie,\n\n     * and ProcOut still fails when count > 0. The same testing showed\n\n     * that two more iterations were needed before ProcOutput would\n\n     * succeed.\n\n     */\n\n    if (priv->output_ready < 2) {\n\n        if (decoder_status.ReadyListCount != 0)\n\n            priv->output_ready++;\n\n        usleep(BASE_WAIT);\n\n        av_log(avctx, AV_LOG_INFO, \"CrystalHD: Filling pipeline.\\n\");\n\n        return len;\n\n    } else if (decoder_status.ReadyListCount == 0) {\n\n        /*\n\n         * After the pipeline is established, if we encounter a lack of frames\n\n         * that probably means we're not giving the hardware enough time to\n\n         * decode them, so start increasing the wait time at the end of a\n\n         * decode call.\n\n         */\n\n        usleep(BASE_WAIT);\n\n        priv->decode_wait += WAIT_UNIT;\n\n        av_log(avctx, AV_LOG_INFO, \"CrystalHD: No frames ready. Returning\\n\");\n\n        return len;\n\n    }\n\n\n\n    do {\n\n        rec_ret = receive_frame(avctx, data, data_size, 0);\n\n        if (rec_ret == RET_OK && *data_size == 0) {\n\n            /*\n\n             * This case is for when the encoded fields are stored\n\n             * separately and we get a separate avpkt for each one. To keep\n\n             * the pipeline stable, we should return nothing and wait for\n\n             * the next time round to grab the second field.\n\n             * H.264 PAFF is an example of this.\n\n             */\n\n            av_log(avctx, AV_LOG_VERBOSE, \"Returning after first field.\\n\");\n\n            avctx->has_b_frames--;\n\n        } else if (rec_ret == RET_COPY_NEXT_FIELD) {\n\n            /*\n\n             * This case is for when the encoded fields are stored in a\n\n             * single avpkt but the hardware returns then separately. Unless\n\n             * we grab the second field before returning, we'll slip another\n\n             * frame in the pipeline and if that happens a lot, we're sunk.\n\n             * So we have to get that second field now.\n\n             * Interlaced mpeg2 and vc1 are examples of this.\n\n             */\n\n            av_log(avctx, AV_LOG_VERBOSE, \"Trying to get second field.\\n\");\n\n            while (1) {\n\n                usleep(priv->decode_wait);\n\n                ret = DtsGetDriverStatus(dev, &decoder_status);\n\n                if (ret == BC_STS_SUCCESS &&\n\n                    decoder_status.ReadyListCount > 0) {\n\n                    rec_ret = receive_frame(avctx, data, data_size, 1);\n\n                    if ((rec_ret == RET_OK && *data_size > 0) ||\n\n                        rec_ret == RET_ERROR)\n\n                        break;\n\n                }\n\n            }\n\n            av_log(avctx, AV_LOG_VERBOSE, \"CrystalHD: Got second field.\\n\");\n\n        } else if (rec_ret == RET_SKIP_NEXT_COPY) {\n\n            /*\n\n             * Two input packets got turned into a field pair. Gawd.\n\n             */\n\n            av_log(avctx, AV_LOG_VERBOSE,\n\n                   \"Don't output on next decode call.\\n\");\n\n            priv->skip_next_output = 1;\n\n        }\n\n        /*\n\n         * If rec_ret == RET_COPY_AGAIN, that means that either we just handled\n\n         * a FMT_CHANGE event and need to go around again for the actual frame,\n\n         * we got a busy status and need to try again, or we're dealing with\n\n         * packed b-frames, where the hardware strangely returns the packed\n\n         * p-frame twice. We choose to keep the second copy as it carries the\n\n         * valid pts.\n\n         */\n\n    } while (rec_ret == RET_COPY_AGAIN);\n\n    usleep(priv->decode_wait);\n\n    return len;\n\n}\n", "idx": 25086}
{"project": "FFmpeg", "commit_id": "7effbee66cf457c62f795d9b9ed3a1110b364b89", "target": 1, "func": "static int au_read_packet(AVFormatContext *s,\n\n                          AVPacket *pkt)\n\n{\n\n    int ret;\n\n\n\n    ret= av_get_packet(s->pb, pkt, BLOCK_SIZE *\n\n                       s->streams[0]->codec->channels *\n\n                       av_get_bits_per_sample(s->streams[0]->codec->codec_id) >> 3);\n\n    if (ret < 0)\n\n        return ret;\n\n\n    pkt->stream_index = 0;\n\n\n\n    /* note: we need to modify the packet size here to handle the last\n\n       packet */\n\n    pkt->size = ret;\n\n    return 0;\n\n}", "idx": 25087}
{"project": "FFmpeg", "commit_id": "50d2d05d3436922e89fcdfdd87411669eab61c02", "target": 0, "func": "static int mov_find_codec_tag(AVFormatContext *s, MOVTrack *track)\n\n{\n\n    int tag = track->enc->codec_tag;\n\n    if (track->mode == MODE_MP4 || track->mode == MODE_PSP) {\n\n        if (!codec_get_tag(ff_mp4_obj_type, track->enc->codec_id))\n\n            return 0;\n\n        if      (track->enc->codec_id == CODEC_ID_H264)      tag = MKTAG('a','v','c','1');\n\n        else if (track->enc->codec_id == CODEC_ID_AC3)       tag = MKTAG('a','c','-','3');\n\n        else if (track->enc->codec_id == CODEC_ID_DIRAC)     tag = MKTAG('d','r','a','c');\n\n        else if (track->enc->codec_id == CODEC_ID_MOV_TEXT)  tag = MKTAG('t','x','3','g');\n\n        else if (track->enc->codec_type == CODEC_TYPE_VIDEO) tag = MKTAG('m','p','4','v');\n\n        else if (track->enc->codec_type == CODEC_TYPE_AUDIO) tag = MKTAG('m','p','4','a');\n\n    } else if (track->mode == MODE_IPOD) {\n\n        if (track->enc->codec_type == CODEC_TYPE_SUBTITLE &&\n\n            (tag == MKTAG('t','x','3','g') ||\n\n             tag == MKTAG('t','e','x','t')))\n\n            track->tag = tag; // keep original tag\n\n        else\n\n            tag = codec_get_tag(codec_ipod_tags, track->enc->codec_id);\n\n        if (!match_ext(s->filename, \"m4a\") && !match_ext(s->filename, \"m4v\"))\n\n            av_log(s, AV_LOG_WARNING, \"Warning, extension is not .m4a nor .m4v \"\n\n                   \"Quicktime/Ipod might not play the file\\n\");\n\n    } else if (track->mode & MODE_3GP) {\n\n        tag = codec_get_tag(codec_3gp_tags, track->enc->codec_id);\n\n    } else if (!tag || (track->enc->strict_std_compliance >= FF_COMPLIANCE_NORMAL &&\n\n                        (tag == MKTAG('d','v','c','p') ||\n\n                         track->enc->codec_id == CODEC_ID_RAWVIDEO))) {\n\n        if (track->enc->codec_id == CODEC_ID_DVVIDEO) {\n\n            if (track->enc->height == 480) /* NTSC */\n\n                if  (track->enc->pix_fmt == PIX_FMT_YUV422P) tag = MKTAG('d','v','5','n');\n\n                else                                         tag = MKTAG('d','v','c',' ');\n\n            else if (track->enc->pix_fmt == PIX_FMT_YUV422P) tag = MKTAG('d','v','5','p');\n\n            else if (track->enc->pix_fmt == PIX_FMT_YUV420P) tag = MKTAG('d','v','c','p');\n\n            else                                             tag = MKTAG('d','v','p','p');\n\n        } else if (track->enc->codec_id == CODEC_ID_RAWVIDEO) {\n\n            tag = codec_get_tag(mov_pix_fmt_tags, track->enc->pix_fmt);\n\n            if (!tag) // restore tag\n\n                tag = track->enc->codec_tag;\n\n        } else {\n\n            if (track->enc->codec_type == CODEC_TYPE_VIDEO) {\n\n                tag = codec_get_tag(codec_movvideo_tags, track->enc->codec_id);\n\n                if (!tag) { // if no mac fcc found, try with Microsoft tags\n\n                    tag = codec_get_tag(codec_bmp_tags, track->enc->codec_id);\n\n                    if (tag)\n\n                        av_log(s, AV_LOG_INFO, \"Warning, using MS style video codec tag, \"\n\n                               \"the file may be unplayable!\\n\");\n\n                }\n\n            } else if (track->enc->codec_type == CODEC_TYPE_AUDIO) {\n\n                tag = codec_get_tag(codec_movaudio_tags, track->enc->codec_id);\n\n                if (!tag) { // if no mac fcc found, try with Microsoft tags\n\n                    int ms_tag = codec_get_tag(codec_wav_tags, track->enc->codec_id);\n\n                    if (ms_tag) {\n\n                        tag = MKTAG('m', 's', ((ms_tag >> 8) & 0xff), (ms_tag & 0xff));\n\n                        av_log(s, AV_LOG_INFO, \"Warning, using MS style audio codec tag, \"\n\n                               \"the file may be unplayable!\\n\");\n\n                    }\n\n                }\n\n            } else if (track->enc->codec_type == CODEC_TYPE_SUBTITLE) {\n\n                tag = codec_get_tag(ff_codec_movsubtitle_tags, track->enc->codec_id);\n\n            }\n\n        }\n\n    }\n\n    return tag;\n\n}\n", "idx": 25088}
{"project": "FFmpeg", "commit_id": "ac1d489320f476c18d6a8125f73389aecb73f3d3", "target": 0, "func": "static int asf_read_seek(AVFormatContext *s, int stream_index, int64_t pts, int flags)\n\n{\n\n    ASFContext *asf = s->priv_data;\n\n    AVStream *st = s->streams[stream_index];\n\n    int64_t pos;\n\n    int index;\n\n\n\n    if (s->packet_size <= 0)\n\n        return -1;\n\n\n\n    /* Try using the protocol's read_seek if available */\n\n    if(s->pb) {\n\n        int ret = avio_seek_time(s->pb, stream_index, pts, flags);\n\n        if(ret >= 0)\n\n            asf_reset_header(s);\n\n        if (ret != AVERROR(ENOSYS))\n\n            return ret;\n\n    }\n\n\n\n    if (!asf->index_read)\n\n        asf_build_simple_index(s, stream_index);\n\n\n\n    if((asf->index_read && st->index_entries)){\n\n        index= av_index_search_timestamp(st, pts, flags);\n\n        if(index >= 0) {\n\n            /* find the position */\n\n            pos = st->index_entries[index].pos;\n\n\n\n            /* do the seek */\n\n            av_log(s, AV_LOG_DEBUG, \"SEEKTO: %\"PRId64\"\\n\", pos);\n\n            avio_seek(s->pb, pos, SEEK_SET);\n\n            asf_reset_header(s);\n\n            return 0;\n\n        }\n\n    }\n\n    /* no index or seeking by index failed */\n\n    if(av_seek_frame_binary(s, stream_index, pts, flags)<0)\n\n        return -1;\n\n    asf_reset_header(s);\n\n    return 0;\n\n}\n", "idx": 25089}
{"project": "FFmpeg", "commit_id": "e3751aa6ec8147ab7ca2649d4daadf8d4dce27d5", "target": 0, "func": "static void decode(RA288Context *ractx, float gain, int cb_coef)\n\n{\n\n    int i, j;\n\n    double sumsum;\n\n    float sum, buffer[5];\n\n\n\n    memmove(ractx->sp_block + 5, ractx->sp_block, 36*sizeof(*ractx->sp_block));\n\n\n\n    for (i=4; i >= 0; i--)\n\n        ractx->sp_block[i] = -scalar_product_float(ractx->sp_block + i + 1,\n\n                                             ractx->sp_lpc, 36);\n\n\n\n    /* block 46 of G.728 spec */\n\n    sum = 32. - scalar_product_float(ractx->gain_lpc, ractx->gain_block, 10);\n\n\n\n    /* block 47 of G.728 spec */\n\n    sum = av_clipf(sum, 0, 60);\n\n\n\n    /* block 48 of G.728 spec */\n\n    sumsum = exp(sum * 0.1151292546497) * gain; /* pow(10.0,sum/20)*gain */\n\n\n\n    for (i=0; i < 5; i++)\n\n        buffer[i] = codetable[cb_coef][i] * sumsum;\n\n\n\n    sum = scalar_product_float(buffer, buffer, 5) / 5;\n\n\n\n    sum = FFMAX(sum, 1);\n\n\n\n    /* shift and store */\n\n    memmove(ractx->gain_block, ractx->gain_block - 1,\n\n            10 * sizeof(*ractx->gain_block));\n\n\n\n    *ractx->gain_block = 10 * log10(sum) - 32;\n\n\n\n    for (i=1; i < 5; i++)\n\n        for (j=i-1; j >= 0; j--)\n\n            buffer[i] -= ractx->sp_lpc[i-j-1] * buffer[j];\n\n\n\n    /* output */\n\n    for (i=0; i < 5; i++)\n\n        ractx->sp_block[4-i] =\n\n            av_clipf(ractx->sp_block[4-i] + buffer[i], -4095, 4095);\n\n}\n", "idx": 25090}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int fourxm_probe(AVProbeData *p)\n\n{\n\n    if (p->buf_size < 12)\n\n        return 0;\n\n\n\n    if ((AV_RL32(&p->buf[0]) != RIFF_TAG) ||\n\n        (AV_RL32(&p->buf[8]) != _4XMV_TAG))\n\n        return 0;\n\n\n\n    return AVPROBE_SCORE_MAX;\n\n}\n", "idx": 25091}
{"project": "FFmpeg", "commit_id": "67db4ff3b66e96a20ddf1c264d07e146334ae88e", "target": 0, "func": "static av_cold void nvenc_setup_rate_control(AVCodecContext *avctx)\n\n{\n\n    NvencContext *ctx = avctx->priv_data;\n\n\n\n    if (avctx->bit_rate > 0) {\n\n        ctx->encode_config.rcParams.averageBitRate = avctx->bit_rate;\n\n    } else if (ctx->encode_config.rcParams.averageBitRate > 0) {\n\n        ctx->encode_config.rcParams.maxBitRate = ctx->encode_config.rcParams.averageBitRate;\n\n    }\n\n\n\n    if (avctx->rc_max_rate > 0)\n\n        ctx->encode_config.rcParams.maxBitRate = avctx->rc_max_rate;\n\n\n\n    if (ctx->rc < 0) {\n\n        if (ctx->flags & NVENC_ONE_PASS)\n\n            ctx->twopass = 0;\n\n        if (ctx->flags & NVENC_TWO_PASSES)\n\n            ctx->twopass = 1;\n\n\n\n        if (ctx->twopass < 0)\n\n            ctx->twopass = (ctx->flags & NVENC_LOWLATENCY) != 0;\n\n\n\n        if (ctx->cbr) {\n\n            if (ctx->twopass) {\n\n                ctx->rc = NV_ENC_PARAMS_RC_2_PASS_QUALITY;\n\n            } else {\n\n                ctx->rc = NV_ENC_PARAMS_RC_CBR;\n\n            }\n\n        } else if (avctx->global_quality > 0) {\n\n            ctx->rc = NV_ENC_PARAMS_RC_CONSTQP;\n\n        } else if (ctx->twopass) {\n\n            ctx->rc = NV_ENC_PARAMS_RC_2_PASS_VBR;\n\n        } else if (avctx->qmin >= 0 && avctx->qmax >= 0) {\n\n            ctx->rc = NV_ENC_PARAMS_RC_VBR_MINQP;\n\n        }\n\n    }\n\n\n\n    if (ctx->flags & NVENC_LOSSLESS) {\n\n        set_lossless(avctx);\n\n    } else if (ctx->rc >= 0) {\n\n        nvenc_override_rate_control(avctx);\n\n    } else {\n\n        ctx->encode_config.rcParams.rateControlMode = NV_ENC_PARAMS_RC_VBR;\n\n        set_vbr(avctx);\n\n    }\n\n\n\n    if (avctx->rc_buffer_size > 0) {\n\n        ctx->encode_config.rcParams.vbvBufferSize = avctx->rc_buffer_size;\n\n    } else if (ctx->encode_config.rcParams.averageBitRate > 0) {\n\n        ctx->encode_config.rcParams.vbvBufferSize = 2 * ctx->encode_config.rcParams.averageBitRate;\n\n    }\n\n\n\n    if (ctx->aq) {\n\n        ctx->encode_config.rcParams.enableAQ   = 1;\n\n        ctx->encode_config.rcParams.aqStrength = ctx->aq_strength;\n\n        av_log(avctx, AV_LOG_VERBOSE, \"AQ enabled.\\n\");\n\n    }\n\n\n\n    if (ctx->temporal_aq) {\n\n        ctx->encode_config.rcParams.enableTemporalAQ = 1;\n\n        av_log(avctx, AV_LOG_VERBOSE, \"Temporal AQ enabled.\\n\");\n\n    }\n\n\n\n    if (ctx->rc_lookahead) {\n\n        int lkd_bound = FFMIN(ctx->nb_surfaces, ctx->async_depth) -\n\n                        ctx->encode_config.frameIntervalP - 4;\n\n\n\n        if (lkd_bound < 0) {\n\n            av_log(avctx, AV_LOG_WARNING,\n\n                   \"Lookahead not enabled. Increase buffer delay (-delay).\\n\");\n\n        } else {\n\n            ctx->encode_config.rcParams.enableLookahead = 1;\n\n            ctx->encode_config.rcParams.lookaheadDepth  = av_clip(ctx->rc_lookahead, 0, lkd_bound);\n\n            ctx->encode_config.rcParams.disableIadapt   = ctx->no_scenecut;\n\n            ctx->encode_config.rcParams.disableBadapt   = !ctx->b_adapt;\n\n            av_log(avctx, AV_LOG_VERBOSE,\n\n                   \"Lookahead enabled: depth %d, scenecut %s, B-adapt %s.\\n\",\n\n                   ctx->encode_config.rcParams.lookaheadDepth,\n\n                   ctx->encode_config.rcParams.disableIadapt ? \"disabled\" : \"enabled\",\n\n                   ctx->encode_config.rcParams.disableBadapt ? \"disabled\" : \"enabled\");\n\n        }\n\n    }\n\n\n\n    if (ctx->strict_gop) {\n\n        ctx->encode_config.rcParams.strictGOPTarget = 1;\n\n        av_log(avctx, AV_LOG_VERBOSE, \"Strict GOP target enabled.\\n\");\n\n    }\n\n\n\n    if (ctx->nonref_p)\n\n        ctx->encode_config.rcParams.enableNonRefP = 1;\n\n\n\n    if (ctx->zerolatency)\n\n        ctx->encode_config.rcParams.zeroReorderDelay = 1;\n\n\n\n    if (ctx->quality)\n\n        ctx->encode_config.rcParams.targetQuality = ctx->quality;\n\n}\n", "idx": 25092}
{"project": "FFmpeg", "commit_id": "de8cac167d52557aa0aced5c013c98f44ade98cf", "target": 0, "func": "int ff_rv34_decode_frame(AVCodecContext *avctx,\n\n                            void *data, int *data_size,\n\n                            uint8_t *buf, int buf_size)\n\n{\n\n    RV34DecContext *r = avctx->priv_data;\n\n    MpegEncContext *s = &r->s;\n\n    AVFrame *pict = data;\n\n    SliceInfo si;\n\n    int i;\n\n    int slice_count;\n\n    uint8_t *slices_hdr = NULL;\n\n    int last = 0;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0) {\n\n        /* special case for last picture */\n\n        if (s->low_delay==0 && s->next_picture_ptr) {\n\n            *pict= *(AVFrame*)s->next_picture_ptr;\n\n            s->next_picture_ptr= NULL;\n\n\n\n            *data_size = sizeof(AVFrame);\n\n        }\n\n        return 0;\n\n    }\n\n\n\n    if(!avctx->slice_count){\n\n        slice_count = (*buf++) + 1;\n\n        slices_hdr = buf + 4;\n\n        buf += 8 * slice_count;\n\n    }else\n\n        slice_count = avctx->slice_count;\n\n\n\n    for(i=0; i<slice_count; i++){\n\n        int offset= get_slice_offset(avctx, slices_hdr, i);\n\n        int size;\n\n        if(i+1 == slice_count)\n\n            size= buf_size - offset;\n\n        else\n\n            size= get_slice_offset(avctx, slices_hdr, i+1) - offset;\n\n\n\n        r->si.end = s->mb_width * s->mb_height;\n\n        if(i+1 < slice_count){\n\n            init_get_bits(&s->gb, buf+get_slice_offset(avctx, slices_hdr, i+1), (buf_size-get_slice_offset(avctx, slices_hdr, i+1))*8);\n\n            if(r->parse_slice_header(r, &r->s.gb, &si) < 0){\n\n                if(i+2 < slice_count)\n\n                    size = get_slice_offset(avctx, slices_hdr, i+2) - offset;\n\n                else\n\n                    size = buf_size - offset;\n\n            }else\n\n                r->si.end = si.start;\n\n        }\n\n        last = rv34_decode_slice(r, r->si.end, buf + offset, size);\n\n        s->mb_num_left = r->s.mb_x + r->s.mb_y*r->s.mb_width - r->si.start;\n\n        if(last)\n\n            break;\n\n    }\n\n\n\n    if(last){\n\n        if(r->loop_filter)\n\n            r->loop_filter(r);\n\n        ff_er_frame_end(s);\n\n        MPV_frame_end(s);\n\n        if (s->pict_type == FF_B_TYPE || s->low_delay) {\n\n            *pict= *(AVFrame*)s->current_picture_ptr;\n\n        } else if (s->last_picture_ptr != NULL) {\n\n            *pict= *(AVFrame*)s->last_picture_ptr;\n\n        }\n\n\n\n        if(s->last_picture_ptr || s->low_delay){\n\n            *data_size = sizeof(AVFrame);\n\n            ff_print_debug_info(s, pict);\n\n        }\n\n        s->current_picture_ptr= NULL; //so we can detect if frame_end wasnt called (find some nicer solution...)\n\n    }\n\n    return buf_size;\n\n}\n", "idx": 25093}
{"project": "FFmpeg", "commit_id": "03037a4aad8b92c00ef2f115605ad20fc4410fe5", "target": 0, "func": "static void blend_subrect(AVPicture *dst, const AVSubtitleRect *rect, int imgw, int imgh)\n\n{\n\n    int x, y, Y, U, V, A;\n\n    uint8_t *lum, *cb, *cr;\n\n    int dstx, dsty, dstw, dsth;\n\n    const AVPicture *src = &rect->pict;\n\n\n\n    dstw = av_clip(rect->w, 0, imgw);\n\n    dsth = av_clip(rect->h, 0, imgh);\n\n    dstx = av_clip(rect->x, 0, imgw - dstw);\n\n    dsty = av_clip(rect->y, 0, imgh - dsth);\n\n    lum = dst->data[0] + dstx + dsty * dst->linesize[0];\n\n    cb  = dst->data[1] + dstx/2 + (dsty >> 1) * dst->linesize[1];\n\n    cr  = dst->data[2] + dstx/2 + (dsty >> 1) * dst->linesize[2];\n\n\n\n    for (y = 0; y<dsth; y++) {\n\n        for (x = 0; x<dstw; x++) {\n\n            Y = src->data[0][x + y*src->linesize[0]];\n\n            A = src->data[3][x + y*src->linesize[3]];\n\n            lum[0] = ALPHA_BLEND(A, lum[0], Y, 0);\n\n            lum++;\n\n        }\n\n        lum += dst->linesize[0] - dstw;\n\n    }\n\n\n\n    for (y = 0; y<dsth/2; y++) {\n\n        for (x = 0; x<dstw/2; x++) {\n\n            U = src->data[1][x + y*src->linesize[1]];\n\n            V = src->data[2][x + y*src->linesize[2]];\n\n            A = src->data[3][2*x     +  2*y   *src->linesize[3]]\n\n              + src->data[3][2*x + 1 +  2*y   *src->linesize[3]]\n\n              + src->data[3][2*x + 1 + (2*y+1)*src->linesize[3]]\n\n              + src->data[3][2*x     + (2*y+1)*src->linesize[3]];\n\n            cb[0] = ALPHA_BLEND(A>>2, cb[0], U, 0);\n\n            cr[0] = ALPHA_BLEND(A>>2, cr[0], V, 0);\n\n            cb++;\n\n            cr++;\n\n        }\n\n        cb += dst->linesize[1] - dstw/2;\n\n        cr += dst->linesize[2] - dstw/2;\n\n    }\n\n}\n", "idx": 25094}
{"project": "FFmpeg", "commit_id": "2c9be3882a03823413945bd9e2d9af33e6e322d5", "target": 0, "func": "static void jpeg_table_header(AVCodecContext *avctx, PutBitContext *p,\n\n                              ScanTable *intra_scantable,\n\n                              uint16_t luma_intra_matrix[64],\n\n                              uint16_t chroma_intra_matrix[64],\n\n                              int hsample[3])\n\n{\n\n    int i, j, size;\n\n    uint8_t *ptr;\n\n    MpegEncContext *s = avctx->priv_data;\n\n\n\n    if (avctx->codec_id != AV_CODEC_ID_LJPEG) {\n\n        int matrix_count = 1 + !!memcmp(luma_intra_matrix,\n\n                                        chroma_intra_matrix,\n\n                                        sizeof(luma_intra_matrix[0]) * 64);\n\n    if (s->force_duplicated_matrix)\n\n        matrix_count = 2;\n\n    /* quant matrixes */\n\n    put_marker(p, DQT);\n\n    put_bits(p, 16, 2 + matrix_count * (1 + 64));\n\n    put_bits(p, 4, 0); /* 8 bit precision */\n\n    put_bits(p, 4, 0); /* table 0 */\n\n    for(i=0;i<64;i++) {\n\n        j = intra_scantable->permutated[i];\n\n        put_bits(p, 8, luma_intra_matrix[j]);\n\n    }\n\n\n\n        if (matrix_count > 1) {\n\n            put_bits(p, 4, 0); /* 8 bit precision */\n\n            put_bits(p, 4, 1); /* table 1 */\n\n            for(i=0;i<64;i++) {\n\n                j = intra_scantable->permutated[i];\n\n                put_bits(p, 8, chroma_intra_matrix[j]);\n\n            }\n\n        }\n\n    }\n\n\n\n    if(avctx->active_thread_type & FF_THREAD_SLICE){\n\n        put_marker(p, DRI);\n\n        put_bits(p, 16, 4);\n\n        put_bits(p, 16, (avctx->width-1)/(8*hsample[0]) + 1);\n\n    }\n\n\n\n    /* huffman table */\n\n    put_marker(p, DHT);\n\n    flush_put_bits(p);\n\n    ptr = put_bits_ptr(p);\n\n    put_bits(p, 16, 0); /* patched later */\n\n    size = 2;\n\n\n\n    // Only MJPEG can have a variable Huffman variable. All other\n\n    // formats use the default Huffman table.\n\n    if (s->out_format == FMT_MJPEG && s->huffman == HUFFMAN_TABLE_OPTIMAL) {\n\n        size += put_huffman_table(p, 0, 0, s->mjpeg_ctx->bits_dc_luminance,\n\n                                  s->mjpeg_ctx->val_dc_luminance);\n\n        size += put_huffman_table(p, 0, 1, s->mjpeg_ctx->bits_dc_chrominance,\n\n                                  s->mjpeg_ctx->val_dc_chrominance);\n\n\n\n        size += put_huffman_table(p, 1, 0, s->mjpeg_ctx->bits_ac_luminance,\n\n                                  s->mjpeg_ctx->val_ac_luminance);\n\n        size += put_huffman_table(p, 1, 1, s->mjpeg_ctx->bits_ac_chrominance,\n\n                                  s->mjpeg_ctx->val_ac_chrominance);\n\n    } else {\n\n        size += put_huffman_table(p, 0, 0, avpriv_mjpeg_bits_dc_luminance,\n\n                                  avpriv_mjpeg_val_dc);\n\n        size += put_huffman_table(p, 0, 1, avpriv_mjpeg_bits_dc_chrominance,\n\n                                  avpriv_mjpeg_val_dc);\n\n\n\n        size += put_huffman_table(p, 1, 0, avpriv_mjpeg_bits_ac_luminance,\n\n                                  avpriv_mjpeg_val_ac_luminance);\n\n        size += put_huffman_table(p, 1, 1, avpriv_mjpeg_bits_ac_chrominance,\n\n                                  avpriv_mjpeg_val_ac_chrominance);\n\n    }\n\n    AV_WB16(ptr, size);\n\n}\n", "idx": 25095}
{"project": "FFmpeg", "commit_id": "a606f27f4c610708fa96e35eed7b7537d3d8f712", "target": 0, "func": "int avio_read_partial(AVIOContext *s, unsigned char *buf, int size)\n\n{\n\n    int len;\n\n\n\n    if (size < 0)\n\n        return -1;\n\n\n\n    if (s->read_packet && s->write_flag) {\n\n        len = s->read_packet(s->opaque, buf, size);\n\n        if (len > 0)\n\n            s->pos += len;\n\n        return len;\n\n    }\n\n\n\n    len = s->buf_end - s->buf_ptr;\n\n    if (len == 0) {\n\n        /* Reset the buf_end pointer to the start of the buffer, to make sure\n\n         * the fill_buffer call tries to read as much data as fits into the\n\n         * full buffer, instead of just what space is left after buf_end.\n\n         * This avoids returning partial packets at the end of the buffer,\n\n         * for packet based inputs.\n\n         */\n\n        s->buf_end = s->buf_ptr = s->buffer;\n\n        fill_buffer(s);\n\n        len = s->buf_end - s->buf_ptr;\n\n    }\n\n    if (len > size)\n\n        len = size;\n\n    memcpy(buf, s->buf_ptr, len);\n\n    s->buf_ptr += len;\n\n    if (!len) {\n\n        if (s->error)      return s->error;\n\n        if (avio_feof(s))  return AVERROR_EOF;\n\n    }\n\n    return len;\n\n}\n", "idx": 25096}
{"project": "FFmpeg", "commit_id": "934982c4ace1a3d5d627b518782ed092a456c49e", "target": 0, "func": "static int sp5x_decode_frame(AVCodecContext *avctx, \n\n                              void *data, int *data_size,\n\n                              uint8_t *buf, int buf_size)\n\n{\n\n#if 0\n\n    MJpegDecodeContext *s = avctx->priv_data;\n\n#endif\n\n    const int qscale = 5;\n\n    uint8_t *buf_ptr, *buf_end, *recoded;\n\n    int i = 0, j = 0;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0)\n\n        return 0;\n\n\n\n    if (!avctx->width || !avctx->height)\n\n\treturn -1;\n\n\n\n    buf_ptr = buf;\n\n    buf_end = buf + buf_size;\n\n\n\n#if 1\n\n    recoded = av_mallocz(buf_size + 1024);\n\n    if (!recoded)\n\n\treturn -1;\n\n\n\n    /* SOI */\n\n    recoded[j++] = 0xFF;\n\n    recoded[j++] = 0xD8;\n\n\n\n    memcpy(recoded+j, &sp5x_data_dqt[0], sizeof(sp5x_data_dqt));\n\n    memcpy(recoded+j+5, &sp5x_quant_table[qscale * 2], 64);\n\n    memcpy(recoded+j+70, &sp5x_quant_table[(qscale * 2) + 1], 64);\n\n    j += sizeof(sp5x_data_dqt);\n\n\n\n    memcpy(recoded+j, &sp5x_data_dht[0], sizeof(sp5x_data_dht));\n\n    j += sizeof(sp5x_data_dht);\n\n\n\n    memcpy(recoded+j, &sp5x_data_sof[0], sizeof(sp5x_data_sof));\n\n    recoded[j+5] = (avctx->coded_height >> 8) & 0xFF;\n\n    recoded[j+6] = avctx->coded_height & 0xFF;\n\n    recoded[j+7] = (avctx->coded_width >> 8) & 0xFF;\n\n    recoded[j+8] = avctx->coded_width & 0xFF;\n\n    j += sizeof(sp5x_data_sof);\n\n\n\n    memcpy(recoded+j, &sp5x_data_sos[0], sizeof(sp5x_data_sos));\n\n    j += sizeof(sp5x_data_sos);\n\n\n\n    for (i = 14; i < buf_size && j < buf_size+1024-2; i++)\n\n    {\n\n\trecoded[j++] = buf[i];\n\n\tif (buf[i] == 0xff)\n\n\t    recoded[j++] = 0;\n\n    }\n\n\n\n    /* EOI */\n\n    recoded[j++] = 0xFF;\n\n    recoded[j++] = 0xD9;\n\n\n\n    i = mjpeg_decode_frame(avctx, data, data_size, recoded, j);\n\n\n\n    av_free(recoded);\n\n\n\n#else\n\n    /* SOF */\n\n    s->bits = 8;\n\n    s->width  = avctx->coded_width;\n\n    s->height = avctx->coded_height;\n\n    s->nb_components = 3;\n\n    s->component_id[0] = 0;\n\n    s->h_count[0] = 2;\n\n    s->v_count[0] = 2;\n\n    s->quant_index[0] = 0;\n\n    s->component_id[1] = 1;\n\n    s->h_count[1] = 1;\n\n    s->v_count[1] = 1;\n\n    s->quant_index[1] = 1;\n\n    s->component_id[2] = 2;\n\n    s->h_count[2] = 1;\n\n    s->v_count[2] = 1;\n\n    s->quant_index[2] = 1;\n\n    s->h_max = 2;\n\n    s->v_max = 2;\n\n    \n\n    s->qscale_table = av_mallocz((s->width+15)/16);\n\n    avctx->pix_fmt = s->cs_itu601 ? PIX_FMT_YUV420P : PIX_FMT_YUVJ420;\n\n    s->interlaced = 0;\n\n    \n\n    s->picture.reference = 0;\n\n    if (avctx->get_buffer(avctx, &s->picture) < 0)\n\n    {\n\n\tfprintf(stderr, \"get_buffer() failed\\n\");\n\n\treturn -1;\n\n    }\n\n\n\n    s->picture.pict_type = I_TYPE;\n\n    s->picture.key_frame = 1;\n\n\n\n    for (i = 0; i < 3; i++)\n\n\ts->linesize[i] = s->picture.linesize[i] << s->interlaced;\n\n\n\n    /* DQT */\n\n    for (i = 0; i < 64; i++)\n\n    {\n\n\tj = s->scantable.permutated[i];\n\n\ts->quant_matrixes[0][j] = sp5x_quant_table[(qscale * 2) + i];\n\n    }\n\n    s->qscale[0] = FFMAX(\n\n\ts->quant_matrixes[0][s->scantable.permutated[1]],\n\n\ts->quant_matrixes[0][s->scantable.permutated[8]]) >> 1;\n\n\n\n    for (i = 0; i < 64; i++)\n\n    {\n\n\tj = s->scantable.permutated[i];\n\n\ts->quant_matrixes[1][j] = sp5x_quant_table[(qscale * 2) + 1 + i];\n\n    }\n\n    s->qscale[1] = FFMAX(\n\n\ts->quant_matrixes[1][s->scantable.permutated[1]],\n\n\ts->quant_matrixes[1][s->scantable.permutated[8]]) >> 1;\n\n\n\n    /* DHT */\n\n\n\n    /* SOS */\n\n    s->comp_index[0] = 0;\n\n    s->nb_blocks[0] = s->h_count[0] * s->v_count[0];\n\n    s->h_scount[0] = s->h_count[0];\n\n    s->v_scount[0] = s->v_count[0];\n\n    s->dc_index[0] = 0;\n\n    s->ac_index[0] = 0;\n\n\n\n    s->comp_index[1] = 1;\n\n    s->nb_blocks[1] = s->h_count[1] * s->v_count[1];\n\n    s->h_scount[1] = s->h_count[1];\n\n    s->v_scount[1] = s->v_count[1];\n\n    s->dc_index[1] = 1;\n\n    s->ac_index[1] = 1;\n\n\n\n    s->comp_index[2] = 2;\n\n    s->nb_blocks[2] = s->h_count[2] * s->v_count[2];\n\n    s->h_scount[2] = s->h_count[2];\n\n    s->v_scount[2] = s->v_count[2];\n\n    s->dc_index[2] = 1;\n\n    s->ac_index[2] = 1;\n\n    \n\n    for (i = 0; i < 3; i++)\n\n\ts->last_dc[i] = 1024;\n\n\n\n    s->mb_width = (s->width * s->h_max * 8 -1) / (s->h_max * 8);\n\n    s->mb_height = (s->height * s->v_max * 8 -1) / (s->v_max * 8);\n\n\n\n    init_get_bits(&s->gb, buf+14, (buf_size-14)*8);\n\n    \n\n    return mjpeg_decode_scan(s);\n\n#endif\n\n\n\n    return i;\n\n}\n", "idx": 25097}
{"project": "FFmpeg", "commit_id": "db592f3b03a21d5bd5237021c00af3ce0431fc60", "target": 0, "func": "static void color16(WaveformContext *s, AVFrame *in, AVFrame *out,\n\n                    int component, int intensity, int offset, int column)\n\n{\n\n    const int plane = s->desc->comp[component].plane;\n\n    const int mirror = s->mirror;\n\n    const int limit = s->size - 1;\n\n    const uint16_t *c0_data = (const uint16_t *)in->data[plane + 0];\n\n    const uint16_t *c1_data = (const uint16_t *)in->data[(plane + 1) % s->ncomp];\n\n    const uint16_t *c2_data = (const uint16_t *)in->data[(plane + 2) % s->ncomp];\n\n    const int c0_linesize = in->linesize[ plane + 0 ] / 2;\n\n    const int c1_linesize = in->linesize[(plane + 1) % s->ncomp] / 2;\n\n    const int c2_linesize = in->linesize[(plane + 2) % s->ncomp] / 2;\n\n    const int d0_linesize = out->linesize[ plane + 0 ] / 2;\n\n    const int d1_linesize = out->linesize[(plane + 1) % s->ncomp] / 2;\n\n    const int d2_linesize = out->linesize[(plane + 2) % s->ncomp] / 2;\n\n    const int src_h = in->height;\n\n    const int src_w = in->width;\n\n    int x, y;\n\n\n\n    if (s->mode) {\n\n        const int d0_signed_linesize = d0_linesize * (mirror == 1 ? -1 : 1);\n\n        const int d1_signed_linesize = d1_linesize * (mirror == 1 ? -1 : 1);\n\n        const int d2_signed_linesize = d2_linesize * (mirror == 1 ? -1 : 1);\n\n        uint16_t *d0_data = (uint16_t *)out->data[plane] + offset * d0_linesize;\n\n        uint16_t *d1_data = (uint16_t *)out->data[(plane + 1) % s->ncomp] + offset * d1_linesize;\n\n        uint16_t *d2_data = (uint16_t *)out->data[(plane + 2) % s->ncomp] + offset * d2_linesize;\n\n        uint16_t * const d0_bottom_line = d0_data + d0_linesize * (s->size - 1);\n\n        uint16_t * const d0 = (mirror ? d0_bottom_line : d0_data);\n\n        uint16_t * const d1_bottom_line = d1_data + d1_linesize * (s->size - 1);\n\n        uint16_t * const d1 = (mirror ? d1_bottom_line : d1_data);\n\n        uint16_t * const d2_bottom_line = d2_data + d2_linesize * (s->size - 1);\n\n        uint16_t * const d2 = (mirror ? d2_bottom_line : d2_data);\n\n\n\n        for (y = 0; y < src_h; y++) {\n\n            for (x = 0; x < src_w; x++) {\n\n                const int c0 = FFMIN(c0_data[x], limit);\n\n                const int c1 = c1_data[x];\n\n                const int c2 = c2_data[x];\n\n\n\n                *(d0 + d0_signed_linesize * c0 + x) = c0;\n\n                *(d1 + d1_signed_linesize * c0 + x) = c1;\n\n                *(d2 + d2_signed_linesize * c0 + x) = c2;\n\n            }\n\n\n\n            c0_data += c0_linesize;\n\n            c1_data += c1_linesize;\n\n            c2_data += c2_linesize;\n\n            d0_data += d0_linesize;\n\n            d1_data += d1_linesize;\n\n            d2_data += d2_linesize;\n\n        }\n\n    } else {\n\n        uint16_t *d0_data = (uint16_t *)out->data[plane] + offset;\n\n        uint16_t *d1_data = (uint16_t *)out->data[(plane + 1) % s->ncomp] + offset;\n\n        uint16_t *d2_data = (uint16_t *)out->data[(plane + 2) % s->ncomp] + offset;\n\n\n\n        if (mirror) {\n\n            d0_data += s->size - 1;\n\n            d1_data += s->size - 1;\n\n            d2_data += s->size - 1;\n\n        }\n\n\n\n        for (y = 0; y < src_h; y++) {\n\n            for (x = 0; x < src_w; x++) {\n\n                const int c0 = FFMIN(c0_data[x], limit);\n\n                const int c1 = c1_data[x];\n\n                const int c2 = c2_data[x];\n\n\n\n                if (mirror) {\n\n                    *(d0_data - c0) = c0;\n\n                    *(d1_data - c0) = c1;\n\n                    *(d2_data - c0) = c2;\n\n                } else {\n\n                    *(d0_data + c0) = c0;\n\n                    *(d1_data + c0) = c1;\n\n                    *(d2_data + c0) = c2;\n\n                }\n\n            }\n\n\n\n            c0_data += c0_linesize;\n\n            c1_data += c1_linesize;\n\n            c2_data += c2_linesize;\n\n            d0_data += d0_linesize;\n\n            d1_data += d1_linesize;\n\n            d2_data += d2_linesize;\n\n        }\n\n    }\n\n\n\n    envelope16(s, out, plane, plane);\n\n}\n", "idx": 25098}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(hyscale_fast)(SwsContext *c, int16_t *dst,\n\n                                        long dstWidth, const uint8_t *src, int srcW,\n\n                                        int xInc)\n\n{\n\n#if ARCH_X86\n\n#if COMPILE_TEMPLATE_MMX2\n\n    int32_t *filterPos = c->hLumFilterPos;\n\n    int16_t *filter    = c->hLumFilter;\n\n    int     canMMX2BeUsed  = c->canMMX2BeUsed;\n\n    void    *mmx2FilterCode= c->lumMmx2FilterCode;\n\n    int i;\n\n#if defined(PIC)\n\n    DECLARE_ALIGNED(8, uint64_t, ebxsave);\n\n#endif\n\n    if (canMMX2BeUsed) {\n\n        __asm__ volatile(\n\n#if defined(PIC)\n\n            \"mov               %%\"REG_b\", %5        \\n\\t\"\n\n#endif\n\n            \"pxor                  %%mm7, %%mm7     \\n\\t\"\n\n            \"mov                      %0, %%\"REG_c\" \\n\\t\"\n\n            \"mov                      %1, %%\"REG_D\" \\n\\t\"\n\n            \"mov                      %2, %%\"REG_d\" \\n\\t\"\n\n            \"mov                      %3, %%\"REG_b\" \\n\\t\"\n\n            \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\" // i\n\n            PREFETCH\"        (%%\"REG_c\")            \\n\\t\"\n\n            PREFETCH\"      32(%%\"REG_c\")            \\n\\t\"\n\n            PREFETCH\"      64(%%\"REG_c\")            \\n\\t\"\n\n\n\n#if ARCH_X86_64\n\n\n\n#define CALL_MMX2_FILTER_CODE \\\n\n            \"movl            (%%\"REG_b\"), %%esi     \\n\\t\"\\\n\n            \"call                    *%4            \\n\\t\"\\\n\n            \"movl (%%\"REG_b\", %%\"REG_a\"), %%esi     \\n\\t\"\\\n\n            \"add               %%\"REG_S\", %%\"REG_c\" \\n\\t\"\\\n\n            \"add               %%\"REG_a\", %%\"REG_D\" \\n\\t\"\\\n\n            \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\"\\\n\n\n\n#else\n\n\n\n#define CALL_MMX2_FILTER_CODE \\\n\n            \"movl (%%\"REG_b\"), %%esi        \\n\\t\"\\\n\n            \"call         *%4                       \\n\\t\"\\\n\n            \"addl (%%\"REG_b\", %%\"REG_a\"), %%\"REG_c\" \\n\\t\"\\\n\n            \"add               %%\"REG_a\", %%\"REG_D\" \\n\\t\"\\\n\n            \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\"\\\n\n\n\n#endif /* ARCH_X86_64 */\n\n\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n\n\n#if defined(PIC)\n\n            \"mov                      %5, %%\"REG_b\" \\n\\t\"\n\n#endif\n\n            :: \"m\" (src), \"m\" (dst), \"m\" (filter), \"m\" (filterPos),\n\n            \"m\" (mmx2FilterCode)\n\n#if defined(PIC)\n\n            ,\"m\" (ebxsave)\n\n#endif\n\n            : \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S, \"%\"REG_D\n\n#if !defined(PIC)\n\n            ,\"%\"REG_b\n\n#endif\n\n        );\n\n        for (i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--) dst[i] = src[srcW-1]*128;\n\n    } else {\n\n#endif /* COMPILE_TEMPLATE_MMX2 */\n\n    x86_reg xInc_shr16 = xInc >> 16;\n\n    uint16_t xInc_mask = xInc & 0xffff;\n\n    x86_reg dstWidth_reg = dstWidth;\n\n    //NO MMX just normal asm ...\n\n    __asm__ volatile(\n\n        \"xor %%\"REG_a\", %%\"REG_a\"            \\n\\t\" // i\n\n        \"xor %%\"REG_d\", %%\"REG_d\"            \\n\\t\" // xx\n\n        \"xorl    %%ecx, %%ecx                \\n\\t\" // xalpha\n\n        \".p2align    4                       \\n\\t\"\n\n        \"1:                                  \\n\\t\"\n\n        \"movzbl    (%0, %%\"REG_d\"), %%edi    \\n\\t\" //src[xx]\n\n        \"movzbl   1(%0, %%\"REG_d\"), %%esi    \\n\\t\" //src[xx+1]\n\n        FAST_BILINEAR_X86\n\n        \"movw     %%si, (%%\"REG_D\", %%\"REG_a\", 2)   \\n\\t\"\n\n        \"addw       %4, %%cx                 \\n\\t\" //xalpha += xInc&0xFFFF\n\n        \"adc        %3, %%\"REG_d\"            \\n\\t\" //xx+= xInc>>16 + carry\n\n\n\n        \"movzbl    (%0, %%\"REG_d\"), %%edi    \\n\\t\" //src[xx]\n\n        \"movzbl   1(%0, %%\"REG_d\"), %%esi    \\n\\t\" //src[xx+1]\n\n        FAST_BILINEAR_X86\n\n        \"movw     %%si, 2(%%\"REG_D\", %%\"REG_a\", 2)  \\n\\t\"\n\n        \"addw       %4, %%cx                 \\n\\t\" //xalpha += xInc&0xFFFF\n\n        \"adc        %3, %%\"REG_d\"            \\n\\t\" //xx+= xInc>>16 + carry\n\n\n\n\n\n        \"add        $2, %%\"REG_a\"            \\n\\t\"\n\n        \"cmp        %2, %%\"REG_a\"            \\n\\t\"\n\n        \" jb        1b                       \\n\\t\"\n\n\n\n\n\n        :: \"r\" (src), \"m\" (dst), \"m\" (dstWidth_reg), \"m\" (xInc_shr16), \"m\" (xInc_mask)\n\n        : \"%\"REG_a, \"%\"REG_d, \"%ecx\", \"%\"REG_D, \"%esi\"\n\n    );\n\n#if COMPILE_TEMPLATE_MMX2\n\n    } //if MMX2 can't be used\n\n#endif\n\n#else\n\n    int i;\n\n    unsigned int xpos=0;\n\n    for (i=0;i<dstWidth;i++) {\n\n        register unsigned int xx=xpos>>16;\n\n        register unsigned int xalpha=(xpos&0xFFFF)>>9;\n\n        dst[i]= (src[xx]<<7) + (src[xx+1] - src[xx])*xalpha;\n\n        xpos+=xInc;\n\n    }\n\n#endif /* ARCH_X86 */\n\n}\n", "idx": 25107}
{"project": "FFmpeg", "commit_id": "53c05b1eacd5f7dbfa3651b45e797adaea0a5ff8", "target": 0, "func": "static void filter_mb( H264Context *h, int mb_x, int mb_y ) {\n\n    MpegEncContext * const s = &h->s;\n\n    const int mb_xy= mb_x + mb_y*s->mb_stride;\n\n    uint8_t *img_y  = s->current_picture.data[0] + (mb_y * 16* s->linesize  ) + mb_x * 16;\n\n    uint8_t *img_cb = s->current_picture.data[1] + (mb_y * 8 * s->uvlinesize) + mb_x * 8;\n\n    uint8_t *img_cr = s->current_picture.data[2] + (mb_y * 8 * s->uvlinesize) + mb_x * 8;\n\n    int linesize, uvlinesize;\n\n    int dir;\n\n#if 0\n\n    /* FIXME what's that ? */\n\n    if( !s->decode )\n\n        return;\n\n#endif\n\n\n\n    /* FIXME Implement deblocking filter for field MB */\n\n    if( h->sps.mb_aff ) {\n\n        return;\n\n    }\n\n    linesize = s->linesize;\n\n    uvlinesize = s->uvlinesize;\n\n\n\n    /* dir : 0 -> vertical edge, 1 -> horizontal edge */\n\n    for( dir = 0; dir < 2; dir++ )\n\n    {\n\n        int start = 0;\n\n        int edge;\n\n\n\n        /* test picture boundary */\n\n        if( ( dir == 0 && mb_x == 0 ) || ( dir == 1 && mb_y == 0 ) ) {\n\n            start = 1;\n\n        }\n\n        /* FIXME test slice boundary */\n\n        if( h->disable_deblocking_filter_idc == 2 ) {\n\n        }\n\n\n\n        /* Calculate bS */\n\n        for( edge = start; edge < 4; edge++ ) {\n\n            /* mbn_xy: neighbour macroblock (how that works for field ?) */\n\n            int mbn_xy = edge > 0 ? mb_xy : ( dir == 0 ? mb_xy -1 : mb_xy - s->mb_stride );\n\n            int bS[4];\n\n            int qp;\n\n\n\n            if( IS_INTRA( s->current_picture.mb_type[mb_xy] ) ||\n\n                IS_INTRA( s->current_picture.mb_type[mbn_xy] ) ) {\n\n                bS[0] = bS[1] = bS[2] = bS[3] = ( edge == 0 ? 4 : 3 );\n\n            } else {\n\n                int i;\n\n                for( i = 0; i < 4; i++ ) {\n\n                    static const uint8_t block_idx_xy[4][4] = {\n\n                        { 0, 2, 8,  10}, { 1, 3, 9,  11},\n\n                        { 4, 6, 12, 14}, { 5, 7, 13, 15}\n\n                    };\n\n\n\n                    int x = dir == 0 ? edge : i;\n\n                    int y = dir == 0 ? i    : edge;\n\n                    int xn = (x - (dir == 0 ? 1 : 0 ))&0x03;\n\n                    int yn = (y - (dir == 0 ? 0 : 1 ))&0x03;\n\n\n\n                    if( h->non_zero_count[mb_xy][block_idx_xy[x][y]] != 0 ||\n\n                        h->non_zero_count[mbn_xy][block_idx_xy[xn][yn]] != 0 ) {\n\n                        bS[i] = 2;\n\n                    }\n\n                    else if( h->slice_type == P_TYPE ) {\n\n                        const int b8_xy = h->mb2b8_xy[mb_xy]+(y>>1)*h->b8_stride+(x>>1);\n\n                        const int b8n_xy= h->mb2b8_xy[mbn_xy]+(yn>>1)*h->b8_stride+(xn>>1);\n\n                        const int b_xy  = h->mb2b_xy[mb_xy]+y*h->b_stride+x;\n\n                        const int bn_xy = h->mb2b_xy[mbn_xy]+yn*h->b_stride+xn;\n\n                        if( s->current_picture.ref_index[0][b8_xy] != s->current_picture.ref_index[0][b8n_xy] ||\n\n                            ABS( s->current_picture.motion_val[0][b_xy][0] - s->current_picture.motion_val[0][bn_xy][0] ) >= 4 ||\n\n                            ABS( s->current_picture.motion_val[0][b_xy][1] - s->current_picture.motion_val[0][bn_xy][1] ) >= 4 )\n\n                            bS[i] = 1;\n\n                        else\n\n                            bS[i] = 0;\n\n                    }\n\n                    else {\n\n                        /* FIXME Add support for B frame */\n\n                        return;\n\n                    }\n\n                }\n\n            }\n\n\n\n            /* Filter edge */\n\n            qp = ( s->current_picture.qscale_table[mb_xy] + s->current_picture.qscale_table[mbn_xy] + 1 ) >> 1;\n\n            if( dir == 0 ) {\n\n                filter_mb_edgev( h, &img_y[4*edge], linesize, bS, qp );\n\n                if( (edge&1) == 0 ) {\n\n                    int chroma_qp = ( get_chroma_qp( h, s->current_picture.qscale_table[mb_xy] ) +\n\n                                      get_chroma_qp( h, s->current_picture.qscale_table[mbn_xy] ) + 1 ) >> 1;\n\n                    filter_mb_edgecv( h, &img_cb[2*edge], uvlinesize, bS, chroma_qp );\n\n                    filter_mb_edgecv( h, &img_cr[2*edge], uvlinesize, bS, chroma_qp );\n\n                }\n\n            } else {\n\n                filter_mb_edgeh( h, &img_y[4*edge*linesize], linesize, bS, qp );\n\n                if( (edge&1) == 0 ) {\n\n                    int chroma_qp = ( get_chroma_qp( h, s->current_picture.qscale_table[mb_xy] ) +\n\n                                      get_chroma_qp( h, s->current_picture.qscale_table[mbn_xy] ) + 1 ) >> 1;\n\n                    filter_mb_edgech( h, &img_cb[2*edge*uvlinesize], uvlinesize, bS, chroma_qp );\n\n                    filter_mb_edgech( h, &img_cr[2*edge*uvlinesize], uvlinesize, bS, chroma_qp );\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 25118}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "void mpeg_motion_internal(MpegEncContext *s,\n\n                          uint8_t *dest_y,\n\n                          uint8_t *dest_cb,\n\n                          uint8_t *dest_cr,\n\n                          int field_based,\n\n                          int bottom_field,\n\n                          int field_select,\n\n                          uint8_t **ref_picture,\n\n                          op_pixels_func (*pix_op)[4],\n\n                          int motion_x,\n\n                          int motion_y,\n\n                          int h,\n\n                          int is_mpeg12,\n\n                          int mb_y)\n\n{\n\n    uint8_t *ptr_y, *ptr_cb, *ptr_cr;\n\n    int dxy, uvdxy, mx, my, src_x, src_y,\n\n        uvsrc_x, uvsrc_y, v_edge_pos;\n\n    ptrdiff_t uvlinesize, linesize;\n\n\n\n#if 0\n\n    if (s->quarter_sample) {\n\n        motion_x >>= 1;\n\n        motion_y >>= 1;\n\n    }\n\n#endif\n\n\n\n    v_edge_pos = s->v_edge_pos >> field_based;\n\n    linesize   = s->current_picture.f.linesize[0] << field_based;\n\n    uvlinesize = s->current_picture.f.linesize[1] << field_based;\n\n\n\n    dxy   = ((motion_y & 1) << 1) | (motion_x & 1);\n\n    src_x = s->mb_x * 16 + (motion_x >> 1);\n\n    src_y = (mb_y << (4 - field_based)) + (motion_y >> 1);\n\n\n\n    if (!is_mpeg12 && s->out_format == FMT_H263) {\n\n        if ((s->workaround_bugs & FF_BUG_HPEL_CHROMA) && field_based) {\n\n            mx      = (motion_x >> 1) | (motion_x & 1);\n\n            my      = motion_y >> 1;\n\n            uvdxy   = ((my & 1) << 1) | (mx & 1);\n\n            uvsrc_x = s->mb_x * 8 + (mx >> 1);\n\n            uvsrc_y = (mb_y << (3 - field_based)) + (my >> 1);\n\n        } else {\n\n            uvdxy   = dxy | (motion_y & 2) | ((motion_x & 2) >> 1);\n\n            uvsrc_x = src_x >> 1;\n\n            uvsrc_y = src_y >> 1;\n\n        }\n\n    // Even chroma mv's are full pel in H261\n\n    } else if (!is_mpeg12 && s->out_format == FMT_H261) {\n\n        mx      = motion_x / 4;\n\n        my      = motion_y / 4;\n\n        uvdxy   = 0;\n\n        uvsrc_x = s->mb_x * 8 + mx;\n\n        uvsrc_y = mb_y * 8 + my;\n\n    } else {\n\n        if (s->chroma_y_shift) {\n\n            mx      = motion_x / 2;\n\n            my      = motion_y / 2;\n\n            uvdxy   = ((my & 1) << 1) | (mx & 1);\n\n            uvsrc_x = s->mb_x * 8 + (mx >> 1);\n\n            uvsrc_y = (mb_y << (3 - field_based)) + (my >> 1);\n\n        } else {\n\n            if (s->chroma_x_shift) {\n\n                // Chroma422\n\n                mx      = motion_x / 2;\n\n                uvdxy   = ((motion_y & 1) << 1) | (mx & 1);\n\n                uvsrc_x = s->mb_x * 8 + (mx >> 1);\n\n                uvsrc_y = src_y;\n\n            } else {\n\n                // Chroma444\n\n                uvdxy   = dxy;\n\n                uvsrc_x = src_x;\n\n                uvsrc_y = src_y;\n\n            }\n\n        }\n\n    }\n\n\n\n    ptr_y  = ref_picture[0] + src_y * linesize + src_x;\n\n    ptr_cb = ref_picture[1] + uvsrc_y * uvlinesize + uvsrc_x;\n\n    ptr_cr = ref_picture[2] + uvsrc_y * uvlinesize + uvsrc_x;\n\n\n\n    if ((unsigned)src_x > FFMAX(s->h_edge_pos - (motion_x & 1) - 16, 0) ||\n\n        (unsigned)src_y > FFMAX(v_edge_pos - (motion_y & 1) - h, 0)) {\n\n        if (is_mpeg12 ||\n\n            s->codec_id == AV_CODEC_ID_MPEG2VIDEO ||\n\n            s->codec_id == AV_CODEC_ID_MPEG1VIDEO) {\n\n            av_log(s->avctx, AV_LOG_DEBUG,\n\n                   \"MPEG motion vector out of boundary (%d %d)\\n\", src_x,\n\n                   src_y);\n\n            return;\n\n        }\n\n        s->vdsp.emulated_edge_mc(s->edge_emu_buffer, ptr_y,\n\n                                 s->linesize, s->linesize,\n\n                                 17, 17 + field_based,\n\n                                 src_x, src_y << field_based,\n\n                                 s->h_edge_pos, s->v_edge_pos);\n\n        ptr_y = s->edge_emu_buffer;\n\n        if (!CONFIG_GRAY || !(s->flags & CODEC_FLAG_GRAY)) {\n\n            uint8_t *uvbuf = s->edge_emu_buffer + 18 * s->linesize;\n\n            s->vdsp.emulated_edge_mc(uvbuf, ptr_cb,\n\n                                     s->uvlinesize, s->uvlinesize,\n\n                                     9, 9 + field_based,\n\n                                     uvsrc_x, uvsrc_y << field_based,\n\n                                     s->h_edge_pos >> 1, s->v_edge_pos >> 1);\n\n            s->vdsp.emulated_edge_mc(uvbuf + 16, ptr_cr,\n\n                                     s->uvlinesize, s->uvlinesize,\n\n                                     9, 9 + field_based,\n\n                                     uvsrc_x, uvsrc_y << field_based,\n\n                                     s->h_edge_pos >> 1, s->v_edge_pos >> 1);\n\n            ptr_cb = uvbuf;\n\n            ptr_cr = uvbuf + 16;\n\n        }\n\n    }\n\n\n\n    /* FIXME use this for field pix too instead of the obnoxious hack which\n\n     * changes picture.data */\n\n    if (bottom_field) {\n\n        dest_y  += s->linesize;\n\n        dest_cb += s->uvlinesize;\n\n        dest_cr += s->uvlinesize;\n\n    }\n\n\n\n    if (field_select) {\n\n        ptr_y  += s->linesize;\n\n        ptr_cb += s->uvlinesize;\n\n        ptr_cr += s->uvlinesize;\n\n    }\n\n\n\n    pix_op[0][dxy](dest_y, ptr_y, linesize, h);\n\n\n\n    if (!CONFIG_GRAY || !(s->flags & CODEC_FLAG_GRAY)) {\n\n        pix_op[s->chroma_x_shift][uvdxy]\n\n            (dest_cb, ptr_cb, uvlinesize, h >> s->chroma_y_shift);\n\n        pix_op[s->chroma_x_shift][uvdxy]\n\n            (dest_cr, ptr_cr, uvlinesize, h >> s->chroma_y_shift);\n\n    }\n\n    if (!is_mpeg12 && (CONFIG_H261_ENCODER || CONFIG_H261_DECODER) &&\n\n        s->out_format == FMT_H261) {\n\n        ff_h261_loop_filter(s);\n\n    }\n\n}\n", "idx": 25120}
{"project": "FFmpeg", "commit_id": "5b0fc078191138795e817244555741356f9d12e9", "target": 1, "func": "static av_cold int vp9_decode_free(AVCodecContext *ctx)\n\n{\n\n    VP9Context *s = ctx->priv_data;\n\n    int i;\n\n\n\n    for (i = 0; i < 2; i++) {\n\n        if (s->frames[i].tf.f->data[0])\n\n            vp9_unref_frame(ctx, &s->frames[i]);\n\n        av_frame_free(&s->frames[i].tf.f);\n\n    }\n\n    for (i = 0; i < 8; i++) {\n\n        if (s->refs[i].f->data[0])\n\n            ff_thread_release_buffer(ctx, &s->refs[i]);\n\n        av_frame_free(&s->refs[i].f);\n\n        if (s->next_refs[i].f->data[0])\n\n            ff_thread_release_buffer(ctx, &s->next_refs[i]);\n\n        av_frame_free(&s->next_refs[i].f);\n\n    }\n\n    av_freep(&s->above_partition_ctx);\n\n    av_freep(&s->c_b);\n\n    s->c_b_size = 0;\n\n    av_freep(&s->b_base);\n\n    av_freep(&s->block_base);\n\n\n\n    return 0;\n\n}\n", "idx": 25124}
{"project": "FFmpeg", "commit_id": "78baa450d9939957f52d5187beb95d763d2f1f18", "target": 1, "func": "static int ffm_read_header(AVFormatContext *s)\n\n{\n\n    FFMContext *ffm = s->priv_data;\n\n    AVStream *st;\n\n    AVIOContext *pb = s->pb;\n\n    AVCodecContext *codec;\n\n    const AVCodecDescriptor *codec_desc;\n\n    int i, nb_streams;\n\n    uint32_t tag;\n\n\n\n    /* header */\n\n    tag = avio_rl32(pb);\n\n    if (tag == MKTAG('F', 'F', 'M', '2'))\n\n        return ffm2_read_header(s);\n\n    if (tag != MKTAG('F', 'F', 'M', '1'))\n\n\n    ffm->packet_size = avio_rb32(pb);\n\n    if (ffm->packet_size != FFM_PACKET_SIZE)\n\n\n    ffm->write_index = avio_rb64(pb);\n\n    /* get also filesize */\n\n    if (pb->seekable) {\n\n        ffm->file_size = avio_size(pb);\n\n        if (ffm->write_index && 0)\n\n            adjust_write_index(s);\n\n    } else {\n\n        ffm->file_size = (UINT64_C(1) << 63) - 1;\n\n\n\n\n    nb_streams = avio_rb32(pb);\n\n    avio_rb32(pb); /* total bitrate */\n\n    /* read each stream */\n\n    for(i=0;i<nb_streams;i++) {\n\n        char rc_eq_buf[128];\n\n\n\n        st = avformat_new_stream(s, NULL);\n\n        if (!st)\n\n\n\n\n        avpriv_set_pts_info(st, 64, 1, 1000000);\n\n\n\n        codec = st->codec;\n\n        /* generic info */\n\n        codec->codec_id = avio_rb32(pb);\n\n        codec_desc = avcodec_descriptor_get(codec->codec_id);\n\n        if (!codec_desc) {\n\n            av_log(s, AV_LOG_ERROR, \"Invalid codec id: %d\\n\", codec->codec_id);\n\n            codec->codec_id = AV_CODEC_ID_NONE;\n\n\n\n        codec->codec_type = avio_r8(pb); /* codec_type */\n\n        if (codec->codec_type != codec_desc->type) {\n\n            av_log(s, AV_LOG_ERROR, \"Codec type mismatch: expected %d, found %d\\n\",\n\n                   codec_desc->type, codec->codec_type);\n\n            codec->codec_id = AV_CODEC_ID_NONE;\n\n            codec->codec_type = AVMEDIA_TYPE_UNKNOWN;\n\n\n\n        codec->bit_rate = avio_rb32(pb);\n\n        codec->flags = avio_rb32(pb);\n\n        codec->flags2 = avio_rb32(pb);\n\n        codec->debug = avio_rb32(pb);\n\n        /* specific info */\n\n        switch(codec->codec_type) {\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            codec->time_base.num = avio_rb32(pb);\n\n            codec->time_base.den = avio_rb32(pb);\n\n            if (codec->time_base.num <= 0 || codec->time_base.den <= 0) {\n\n                av_log(s, AV_LOG_ERROR, \"Invalid time base %d/%d\\n\",\n\n                       codec->time_base.num, codec->time_base.den);\n\n\n\n            codec->width = avio_rb16(pb);\n\n            codec->height = avio_rb16(pb);\n\n            codec->gop_size = avio_rb16(pb);\n\n            codec->pix_fmt = avio_rb32(pb);\n\n\n\n\n\n\n            codec->qmin = avio_r8(pb);\n\n            codec->qmax = avio_r8(pb);\n\n            codec->max_qdiff = avio_r8(pb);\n\n            codec->qcompress = avio_rb16(pb) / 10000.0;\n\n            codec->qblur = avio_rb16(pb) / 10000.0;\n\n            codec->bit_rate_tolerance = avio_rb32(pb);\n\n            avio_get_str(pb, INT_MAX, rc_eq_buf, sizeof(rc_eq_buf));\n\n            codec->rc_eq = av_strdup(rc_eq_buf);\n\n            codec->rc_max_rate = avio_rb32(pb);\n\n            codec->rc_min_rate = avio_rb32(pb);\n\n            codec->rc_buffer_size = avio_rb32(pb);\n\n            codec->i_quant_factor = av_int2double(avio_rb64(pb));\n\n            codec->b_quant_factor = av_int2double(avio_rb64(pb));\n\n            codec->i_quant_offset = av_int2double(avio_rb64(pb));\n\n            codec->b_quant_offset = av_int2double(avio_rb64(pb));\n\n            codec->dct_algo = avio_rb32(pb);\n\n            codec->strict_std_compliance = avio_rb32(pb);\n\n            codec->max_b_frames = avio_rb32(pb);\n\n            codec->mpeg_quant = avio_rb32(pb);\n\n            codec->intra_dc_precision = avio_rb32(pb);\n\n            codec->me_method = avio_rb32(pb);\n\n            codec->mb_decision = avio_rb32(pb);\n\n            codec->nsse_weight = avio_rb32(pb);\n\n            codec->frame_skip_cmp = avio_rb32(pb);\n\n            codec->rc_buffer_aggressivity = av_int2double(avio_rb64(pb));\n\n            codec->codec_tag = avio_rb32(pb);\n\n            codec->thread_count = avio_r8(pb);\n\n            codec->coder_type = avio_rb32(pb);\n\n            codec->me_cmp = avio_rb32(pb);\n\n            codec->me_subpel_quality = avio_rb32(pb);\n\n            codec->me_range = avio_rb32(pb);\n\n            codec->keyint_min = avio_rb32(pb);\n\n            codec->scenechange_threshold = avio_rb32(pb);\n\n            codec->b_frame_strategy = avio_rb32(pb);\n\n            codec->qcompress = av_int2double(avio_rb64(pb));\n\n            codec->qblur = av_int2double(avio_rb64(pb));\n\n            codec->max_qdiff = avio_rb32(pb);\n\n            codec->refs = avio_rb32(pb);\n\n            break;\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            codec->sample_rate = avio_rb32(pb);\n\n            codec->channels = avio_rl16(pb);\n\n            codec->frame_size = avio_rl16(pb);\n\n            break;\n\n        default:\n\n\n\n        if (codec->flags & AV_CODEC_FLAG_GLOBAL_HEADER) {\n\n            int size = avio_rb32(pb);\n\n            codec->extradata = av_mallocz(size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n            if (!codec->extradata)\n\n                return AVERROR(ENOMEM);\n\n            codec->extradata_size = size;\n\n            avio_read(pb, codec->extradata, size);\n\n\n\n\n        avcodec_parameters_from_context(st->codecpar, codec);\n\n\n\n\n    /* get until end of block reached */\n\n    while ((avio_tell(pb) % ffm->packet_size) != 0 && !pb->eof_reached)\n\n        avio_r8(pb);\n\n\n\n    /* init packet demux */\n\n    ffm->packet_ptr = ffm->packet;\n\n    ffm->packet_end = ffm->packet;\n\n    ffm->frame_offset = 0;\n\n    ffm->dts = 0;\n\n    ffm->read_state = READ_HEADER;\n\n    ffm->first_packet = 1;\n\n    return 0;\n\n fail:\n\n    ffm_close(s);\n\n    return -1;\n", "idx": 25127}
{"project": "FFmpeg", "commit_id": "fb1473080223a634b8ac2cca48a632d037a0a69d", "target": 1, "func": "static int aac_sync(uint64_t state, AACAC3ParseContext *hdr_info,\n\n        int *need_next_header, int *new_frame_start)\n\n{\n\n    GetBitContext bits;\n\n    AACADTSHeaderInfo hdr;\n\n    int size;\n\n    union {\n\n        uint64_t u64;\n\n        uint8_t  u8[8];\n\n    } tmp;\n\n\n\n    tmp.u64 = av_be2ne64(state);\n\n    init_get_bits(&bits, tmp.u8+8-AAC_ADTS_HEADER_SIZE, AAC_ADTS_HEADER_SIZE * 8);\n\n\n\n    if ((size = avpriv_aac_parse_header(&bits, &hdr)) < 0)\n\n        return 0;\n\n    *need_next_header = 0;\n\n    *new_frame_start  = 1;\n\n    hdr_info->sample_rate = hdr.sample_rate;\n\n    hdr_info->channels    = ff_mpeg4audio_channels[hdr.chan_config];\n\n    hdr_info->samples     = hdr.samples;\n\n    hdr_info->bit_rate    = hdr.bit_rate;\n\n    return size;\n\n}\n", "idx": 25130}
{"project": "FFmpeg", "commit_id": "4b030025278ac4adc3616510f36de4c7a113c5fb", "target": 1, "func": "static int sdp_read_header(AVFormatContext *s)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    RTSPStream *rtsp_st;\n\n    int size, i, err;\n\n    char *content;\n\n    char url[1024];\n\n\n\n    if (!ff_network_init())\n\n        return AVERROR(EIO);\n\n\n\n    if (s->max_delay < 0) /* Not set by the caller */\n\n        s->max_delay = DEFAULT_REORDERING_DELAY;\n\n    if (rt->rtsp_flags & RTSP_FLAG_CUSTOM_IO)\n\n        rt->lower_transport = RTSP_LOWER_TRANSPORT_CUSTOM;\n\n\n\n    /* read the whole sdp file */\n\n    /* XXX: better loading */\n\n    content = av_malloc(SDP_MAX_SIZE);\n\n\n\n    size = avio_read(s->pb, content, SDP_MAX_SIZE - 1);\n\n    if (size <= 0) {\n\n        av_free(content);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    content[size] ='\\0';\n\n\n\n    err = ff_sdp_parse(s, content);\n\n    av_freep(&content);\n\n    if (err) goto fail;\n\n\n\n    /* open each RTP stream */\n\n    for (i = 0; i < rt->nb_rtsp_streams; i++) {\n\n        char namebuf[50];\n\n        rtsp_st = rt->rtsp_streams[i];\n\n\n\n        if (!(rt->rtsp_flags & RTSP_FLAG_CUSTOM_IO)) {\n\n            AVDictionary *opts = map_to_opts(rt);\n\n\n\n            getnameinfo((struct sockaddr*) &rtsp_st->sdp_ip, sizeof(rtsp_st->sdp_ip),\n\n                        namebuf, sizeof(namebuf), NULL, 0, NI_NUMERICHOST);\n\n            ff_url_join(url, sizeof(url), \"rtp\", NULL,\n\n                        namebuf, rtsp_st->sdp_port,\n\n                        \"?localport=%d&ttl=%d&connect=%d&write_to_source=%d\",\n\n                        rtsp_st->sdp_port, rtsp_st->sdp_ttl,\n\n                        rt->rtsp_flags & RTSP_FLAG_FILTER_SRC ? 1 : 0,\n\n                        rt->rtsp_flags & RTSP_FLAG_RTCP_TO_SOURCE ? 1 : 0);\n\n\n\n            append_source_addrs(url, sizeof(url), \"sources\",\n\n                                rtsp_st->nb_include_source_addrs,\n\n                                rtsp_st->include_source_addrs);\n\n            append_source_addrs(url, sizeof(url), \"block\",\n\n                                rtsp_st->nb_exclude_source_addrs,\n\n                                rtsp_st->exclude_source_addrs);\n\n            err = ffurl_open(&rtsp_st->rtp_handle, url, AVIO_FLAG_READ_WRITE,\n\n                           &s->interrupt_callback, &opts);\n\n\n\n            av_dict_free(&opts);\n\n\n\n            if (err < 0) {\n\n                err = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n        }\n\n        if ((err = ff_rtsp_open_transport_ctx(s, rtsp_st)))\n\n            goto fail;\n\n    }\n\n    return 0;\n\nfail:\n\n    ff_rtsp_close_streams(s);\n\n    ff_network_close();\n\n    return err;\n\n}", "idx": 25131}
{"project": "FFmpeg", "commit_id": "4d122b01e4ce539269ee2df193b061772c7374f6", "target": 1, "func": "static int mov_create_chapter_track(AVFormatContext *s, int tracknum)\n\n{\n\n    MOVMuxContext *mov = s->priv_data;\n\n    MOVTrack *track = &mov->tracks[tracknum];\n\n    AVPacket pkt = { .stream_index = tracknum, .flags = AV_PKT_FLAG_KEY };\n\n    int i, len;\n\n    // These properties are required to make QT recognize the chapter track\n\n    uint8_t chapter_properties[43] = { 0, 0, 0, 0, 0, 0, 0, 1, };\n\n\n\n    track->mode = mov->mode;\n\n    track->tag = MKTAG('t','e','x','t');\n\n    track->timescale = MOV_TIMESCALE;\n\n    track->enc = avcodec_alloc_context3(NULL);\n\n    if (!track->enc)\n\n\n    track->enc->codec_type = AVMEDIA_TYPE_SUBTITLE;\n\n    track->enc->extradata = av_malloc(sizeof(chapter_properties));\n\n    if (track->enc->extradata == NULL)\n\n\n    track->enc->extradata_size = sizeof(chapter_properties);\n\n    memcpy(track->enc->extradata, chapter_properties, sizeof(chapter_properties));\n\n\n\n    for (i = 0; i < s->nb_chapters; i++) {\n\n        AVChapter *c = s->chapters[i];\n\n        AVDictionaryEntry *t;\n\n\n\n        int64_t end = av_rescale_q(c->end, c->time_base, (AVRational){1,MOV_TIMESCALE});\n\n        pkt.pts = pkt.dts = av_rescale_q(c->start, c->time_base, (AVRational){1,MOV_TIMESCALE});\n\n        pkt.duration = end - pkt.dts;\n\n\n\n        if ((t = av_dict_get(c->metadata, \"title\", NULL, 0))) {\n\n            len      = strlen(t->value);\n\n            pkt.size = len + 2;\n\n            pkt.data = av_malloc(pkt.size);\n\n\n\n            AV_WB16(pkt.data, len);\n\n            memcpy(pkt.data + 2, t->value, len);\n\n            ff_mov_write_packet(s, &pkt);\n\n            av_freep(&pkt.data);\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}", "idx": 25133}
{"project": "FFmpeg", "commit_id": "3228ac730c11eca49d5680d5550128e397061c85", "target": 1, "func": "static av_cold int vc2_encode_init(AVCodecContext *avctx)\n\n{\n\n    Plane *p;\n\n    SubBand *b;\n\n    int i, j, level, o, shift, ret;\n\n    const AVPixFmtDescriptor *fmt = av_pix_fmt_desc_get(avctx->pix_fmt);\n\n    const int depth = fmt->comp[0].depth;\n\n    VC2EncContext *s = avctx->priv_data;\n\n\n\n    s->picture_number = 0;\n\n\n\n    /* Total allowed quantization range */\n\n    s->q_ceil    = DIRAC_MAX_QUANT_INDEX;\n\n\n\n    s->ver.major = 2;\n\n    s->ver.minor = 0;\n\n    s->profile   = 3;\n\n    s->level     = 3;\n\n\n\n    s->base_vf   = -1;\n\n    s->strict_compliance = 1;\n\n\n\n    s->q_avg = 0;\n\n    s->slice_max_bytes = 0;\n\n    s->slice_min_bytes = 0;\n\n\n\n    /* Mark unknown as progressive */\n\n    s->interlaced = !((avctx->field_order == AV_FIELD_UNKNOWN) ||\n\n                      (avctx->field_order == AV_FIELD_PROGRESSIVE));\n\n\n\n    for (i = 0; i < base_video_fmts_len; i++) {\n\n        const VC2BaseVideoFormat *fmt = &base_video_fmts[i];\n\n        if (avctx->pix_fmt != fmt->pix_fmt)\n\n            continue;\n\n        if (avctx->time_base.num != fmt->time_base.num)\n\n            continue;\n\n        if (avctx->time_base.den != fmt->time_base.den)\n\n            continue;\n\n        if (avctx->width != fmt->width)\n\n            continue;\n\n        if (avctx->height != fmt->height)\n\n            continue;\n\n        if (s->interlaced != fmt->interlaced)\n\n            continue;\n\n        s->base_vf = i;\n\n        s->level   = base_video_fmts[i].level;\n\n        break;\n\n    }\n\n\n\n    if (s->interlaced)\n\n        av_log(avctx, AV_LOG_WARNING, \"Interlacing enabled!\\n\");\n\n\n\n    if ((s->slice_width  & (s->slice_width  - 1)) ||\n\n        (s->slice_height & (s->slice_height - 1))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Slice size is not a power of two!\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    if ((s->slice_width > avctx->width) ||\n\n        (s->slice_height > avctx->height)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Slice size is bigger than the image!\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    if (s->base_vf <= 0) {\n\n        if (avctx->strict_std_compliance < FF_COMPLIANCE_STRICT) {\n\n            s->strict_compliance = s->base_vf = 0;\n\n            av_log(avctx, AV_LOG_WARNING, \"Format does not strictly comply with VC2 specs\\n\");\n\n        } else {\n\n            av_log(avctx, AV_LOG_WARNING, \"Given format does not strictly comply with \"\n\n                   \"the specifications, decrease strictness to use it.\\n\");\n\n            return AVERROR_UNKNOWN;\n\n        }\n\n    } else {\n\n        av_log(avctx, AV_LOG_INFO, \"Selected base video format = %i (%s)\\n\",\n\n               s->base_vf, base_video_fmts[s->base_vf].name);\n\n    }\n\n\n\n    /* Chroma subsampling */\n\n    ret = av_pix_fmt_get_chroma_sub_sample(avctx->pix_fmt, &s->chroma_x_shift, &s->chroma_y_shift);\n\n    if (ret)\n\n        return ret;\n\n\n\n    /* Bit depth and color range index */\n\n    if (depth == 8 && avctx->color_range == AVCOL_RANGE_JPEG) {\n\n        s->bpp = 1;\n\n        s->bpp_idx = 1;\n\n        s->diff_offset = 128;\n\n    } else if (depth == 8 && (avctx->color_range == AVCOL_RANGE_MPEG ||\n\n               avctx->color_range == AVCOL_RANGE_UNSPECIFIED)) {\n\n        s->bpp = 1;\n\n        s->bpp_idx = 2;\n\n        s->diff_offset = 128;\n\n    } else if (depth == 10) {\n\n        s->bpp = 2;\n\n        s->bpp_idx = 3;\n\n        s->diff_offset = 512;\n\n    } else {\n\n        s->bpp = 2;\n\n        s->bpp_idx = 4;\n\n        s->diff_offset = 2048;\n\n    }\n\n\n\n    /* Planes initialization */\n\n    for (i = 0; i < 3; i++) {\n\n        int w, h;\n\n        p = &s->plane[i];\n\n        p->width      = avctx->width  >> (i ? s->chroma_x_shift : 0);\n\n        p->height     = avctx->height >> (i ? s->chroma_y_shift : 0);\n\n        if (s->interlaced)\n\n            p->height >>= 1;\n\n        p->dwt_width  = w = FFALIGN(p->width,  (1 << s->wavelet_depth));\n\n        p->dwt_height = h = FFALIGN(p->height, (1 << s->wavelet_depth));\n\n        p->coef_stride = FFALIGN(p->dwt_width, 32);\n\n        p->coef_buf = av_malloc(p->coef_stride*p->dwt_height*sizeof(dwtcoef));\n\n        if (!p->coef_buf)\n\n            goto alloc_fail;\n\n        for (level = s->wavelet_depth-1; level >= 0; level--) {\n\n            w = w >> 1;\n\n            h = h >> 1;\n\n            for (o = 0; o < 4; o++) {\n\n                b = &p->band[level][o];\n\n                b->width  = w;\n\n                b->height = h;\n\n                b->stride = p->coef_stride;\n\n                shift = (o > 1)*b->height*b->stride + (o & 1)*b->width;\n\n                b->buf = p->coef_buf + shift;\n\n            }\n\n        }\n\n\n\n        /* DWT init */\n\n        if (ff_vc2enc_init_transforms(&s->transform_args[i].t,\n\n                                      s->plane[i].coef_stride,\n\n                                      s->plane[i].dwt_height))\n\n            goto alloc_fail;\n\n    }\n\n\n\n    /* Slices */\n\n    s->num_x = s->plane[0].dwt_width/s->slice_width;\n\n    s->num_y = s->plane[0].dwt_height/s->slice_height;\n\n\n\n    s->slice_args = av_calloc(s->num_x*s->num_y, sizeof(SliceArgs));\n\n    if (!s->slice_args)\n\n        goto alloc_fail;\n\n\n\n    /* Lookup tables */\n\n    s->coef_lut_len = av_malloc(COEF_LUT_TAB*(s->q_ceil+1)*sizeof(*s->coef_lut_len));\n\n    if (!s->coef_lut_len)\n\n        goto alloc_fail;\n\n\n\n    s->coef_lut_val = av_malloc(COEF_LUT_TAB*(s->q_ceil+1)*sizeof(*s->coef_lut_val));\n\n    if (!s->coef_lut_val)\n\n        goto alloc_fail;\n\n\n\n    for (i = 0; i < s->q_ceil; i++) {\n\n        uint8_t  *len_lut = &s->coef_lut_len[i*COEF_LUT_TAB];\n\n        uint32_t *val_lut = &s->coef_lut_val[i*COEF_LUT_TAB];\n\n        for (j = 0; j < COEF_LUT_TAB; j++) {\n\n            get_vc2_ue_uint(QUANT(j, ff_dirac_qscale_tab[i]),\n\n                            &len_lut[j], &val_lut[j]);\n\n            if (len_lut[j] != 1) {\n\n                len_lut[j] += 1;\n\n                val_lut[j] <<= 1;\n\n            } else {\n\n                val_lut[j] = 1;\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n\n\nalloc_fail:\n\n    vc2_encode_end(avctx);\n\n    av_log(avctx, AV_LOG_ERROR, \"Unable to allocate memory!\\n\");\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 25135}
{"project": "FFmpeg", "commit_id": "f507a9fe002c6a444cbd38a1326ee4f9df8c10a1", "target": 0, "func": "static void compute_rematrixing_strategy(AC3EncodeContext *s)\n\n{\n\n    int nb_coefs;\n\n    int blk, bnd, i;\n\n    AC3Block *block, *av_uninit(block0);\n\n\n\n    if (s->channel_mode != AC3_CHMODE_STEREO)\n\n        return;\n\n\n\n    for (blk = 0; blk < AC3_MAX_BLOCKS; blk++) {\n\n        block = &s->blocks[blk];\n\n        block->new_rematrixing_strategy = !blk;\n\n\n\n        if (!s->rematrixing_enabled) {\n\n            block0 = block;\n\n            continue;\n\n        }\n\n\n\n        block->num_rematrixing_bands = 4;\n\n        if (block->cpl_in_use) {\n\n            block->num_rematrixing_bands -= (s->start_freq[CPL_CH] <= 61);\n\n            block->num_rematrixing_bands -= (s->start_freq[CPL_CH] == 37);\n\n            if (blk && block->num_rematrixing_bands != block0->num_rematrixing_bands)\n\n                block->new_rematrixing_strategy = 1;\n\n        }\n\n        nb_coefs = FFMIN(block->end_freq[1], block->end_freq[2]);\n\n\n\n        for (bnd = 0; bnd < block->num_rematrixing_bands; bnd++) {\n\n            /* calculate calculate sum of squared coeffs for one band in one block */\n\n            int start = ff_ac3_rematrix_band_tab[bnd];\n\n            int end   = FFMIN(nb_coefs, ff_ac3_rematrix_band_tab[bnd+1]);\n\n            CoefSumType sum[4] = {0,};\n\n            for (i = start; i < end; i++) {\n\n                CoefType lt = block->mdct_coef[1][i];\n\n                CoefType rt = block->mdct_coef[2][i];\n\n                CoefType md = lt + rt;\n\n                CoefType sd = lt - rt;\n\n                MAC_COEF(sum[0], lt, lt);\n\n                MAC_COEF(sum[1], rt, rt);\n\n                MAC_COEF(sum[2], md, md);\n\n                MAC_COEF(sum[3], sd, sd);\n\n            }\n\n\n\n            /* compare sums to determine if rematrixing will be used for this band */\n\n            if (FFMIN(sum[2], sum[3]) < FFMIN(sum[0], sum[1]))\n\n                block->rematrixing_flags[bnd] = 1;\n\n            else\n\n                block->rematrixing_flags[bnd] = 0;\n\n\n\n            /* determine if new rematrixing flags will be sent */\n\n            if (blk &&\n\n                block->rematrixing_flags[bnd] != block0->rematrixing_flags[bnd]) {\n\n                block->new_rematrixing_strategy = 1;\n\n            }\n\n        }\n\n        block0 = block;\n\n    }\n\n}\n", "idx": 25138}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "int ff_msmpeg4_pred_dc(MpegEncContext *s, int n,\n\n                       int16_t **dc_val_ptr, int *dir_ptr)\n\n{\n\n    int a, b, c, wrap, pred, scale;\n\n    int16_t *dc_val;\n\n\n\n    /* find prediction */\n\n    if (n < 4) {\n\n        scale = s->y_dc_scale;\n\n    } else {\n\n        scale = s->c_dc_scale;\n\n    }\n\n\n\n    wrap = s->block_wrap[n];\n\n    dc_val= s->dc_val[0] + s->block_index[n];\n\n\n\n    /* B C\n\n     * A X\n\n     */\n\n    a = dc_val[ - 1];\n\n    b = dc_val[ - 1 - wrap];\n\n    c = dc_val[ - wrap];\n\n\n\n    if(s->first_slice_line && (n&2)==0 && s->msmpeg4_version<4){\n\n        b=c=1024;\n\n    }\n\n\n\n    /* XXX: the following solution consumes divisions, but it does not\n\n       necessitate to modify mpegvideo.c. The problem comes from the\n\n       fact they decided to store the quantized DC (which would lead\n\n       to problems if Q could vary !) */\n\n#if ARCH_X86 && HAVE_7REGS && HAVE_EBX_AVAILABLE\n\n    __asm__ volatile(\n\n        \"movl %3, %%eax         \\n\\t\"\n\n        \"shrl $1, %%eax         \\n\\t\"\n\n        \"addl %%eax, %2         \\n\\t\"\n\n        \"addl %%eax, %1         \\n\\t\"\n\n        \"addl %0, %%eax         \\n\\t\"\n\n        \"mull %4                \\n\\t\"\n\n        \"movl %%edx, %0         \\n\\t\"\n\n        \"movl %1, %%eax         \\n\\t\"\n\n        \"mull %4                \\n\\t\"\n\n        \"movl %%edx, %1         \\n\\t\"\n\n        \"movl %2, %%eax         \\n\\t\"\n\n        \"mull %4                \\n\\t\"\n\n        \"movl %%edx, %2         \\n\\t\"\n\n        : \"+b\" (a), \"+c\" (b), \"+D\" (c)\n\n        : \"g\" (scale), \"S\" (ff_inverse[scale])\n\n        : \"%eax\", \"%edx\"\n\n    );\n\n#else\n\n    /* Divisions are costly everywhere; optimize the most common case. */\n\n    if (scale == 8) {\n\n        a = (a + (8 >> 1)) / 8;\n\n        b = (b + (8 >> 1)) / 8;\n\n        c = (c + (8 >> 1)) / 8;\n\n    } else {\n\n        a = FASTDIV((a + (scale >> 1)), scale);\n\n        b = FASTDIV((b + (scale >> 1)), scale);\n\n        c = FASTDIV((c + (scale >> 1)), scale);\n\n    }\n\n#endif\n\n    /* XXX: WARNING: they did not choose the same test as MPEG4. This\n\n       is very important ! */\n\n    if(s->msmpeg4_version>3){\n\n        if(s->inter_intra_pred){\n\n            uint8_t *dest;\n\n            int wrap;\n\n\n\n            if(n==1){\n\n                pred=a;\n\n                *dir_ptr = 0;\n\n            }else if(n==2){\n\n                pred=c;\n\n                *dir_ptr = 1;\n\n            }else if(n==3){\n\n                if (abs(a - b) < abs(b - c)) {\n\n                    pred = c;\n\n                    *dir_ptr = 1;\n\n                } else {\n\n                    pred = a;\n\n                    *dir_ptr = 0;\n\n                }\n\n            }else{\n\n                if(n<4){\n\n                    wrap= s->linesize;\n\n                    dest= s->current_picture.f.data[0] + (((n >> 1) + 2*s->mb_y) * 8*  wrap ) + ((n & 1) + 2*s->mb_x) * 8;\n\n                }else{\n\n                    wrap= s->uvlinesize;\n\n                    dest= s->current_picture.f.data[n - 3] + (s->mb_y * 8 * wrap) + s->mb_x * 8;\n\n                }\n\n                if(s->mb_x==0) a= (1024 + (scale>>1))/scale;\n\n                else           a= get_dc(dest-8, wrap, scale*8);\n\n                if(s->mb_y==0) c= (1024 + (scale>>1))/scale;\n\n                else           c= get_dc(dest-8*wrap, wrap, scale*8);\n\n\n\n                if (s->h263_aic_dir==0) {\n\n                    pred= a;\n\n                    *dir_ptr = 0;\n\n                }else if (s->h263_aic_dir==1) {\n\n                    if(n==0){\n\n                        pred= c;\n\n                        *dir_ptr = 1;\n\n                    }else{\n\n                        pred= a;\n\n                        *dir_ptr = 0;\n\n                    }\n\n                }else if (s->h263_aic_dir==2) {\n\n                    if(n==0){\n\n                        pred= a;\n\n                        *dir_ptr = 0;\n\n                    }else{\n\n                        pred= c;\n\n                        *dir_ptr = 1;\n\n                    }\n\n                } else {\n\n                    pred= c;\n\n                    *dir_ptr = 1;\n\n                }\n\n            }\n\n        }else{\n\n            if (abs(a - b) < abs(b - c)) {\n\n                pred = c;\n\n                *dir_ptr = 1;\n\n            } else {\n\n                pred = a;\n\n                *dir_ptr = 0;\n\n            }\n\n        }\n\n    }else{\n\n        if (abs(a - b) <= abs(b - c)) {\n\n            pred = c;\n\n            *dir_ptr = 1;\n\n        } else {\n\n            pred = a;\n\n            *dir_ptr = 0;\n\n        }\n\n    }\n\n\n\n    /* update predictor */\n\n    *dc_val_ptr = &dc_val[0];\n\n    return pred;\n\n}\n", "idx": 25140}
{"project": "FFmpeg", "commit_id": "bc574408dc011943b82de012451f95266bed9989", "target": 1, "func": "int url_open(URLContext **puc, const char *filename, int flags)\n\n{\n\n    URLProtocol *up;\n\n    const char *p;\n\n    char proto_str[128], *q;\n\n\n\n    p = filename;\n\n    q = proto_str;\n\n    while (*p != '\\0' && *p != ':') {\n\n        /* protocols can only contain alphabetic chars */\n\n        if (!isalpha(*p))\n\n            goto file_proto;\n\n        if ((q - proto_str) < sizeof(proto_str) - 1)\n\n            *q++ = *p;\n\n        p++;\n\n    }\n\n    /* if the protocol has length 1, we consider it is a dos drive */\n\n    if (*p == '\\0' || (q - proto_str) <= 1) {\n\n    file_proto:\n\n        strcpy(proto_str, \"file\");\n\n    } else {\n\n        *q = '\\0';\n\n    }\n\n\n\n    up = first_protocol;\n\n    while (up != NULL) {\n\n        if (!strcmp(proto_str, up->name))\n\n            return url_open_protocol (puc, up, filename, flags);\n\n        up = up->next;\n\n    }\n\n    *puc = NULL;\n\n    return AVERROR(ENOENT);\n\n}\n", "idx": 25141}
{"project": "FFmpeg", "commit_id": "f15e6b869fc1ff3ffef1b1ac7b394e2155b5fafe", "target": 1, "func": "struct SwsContext *sws_getContext(int srcW, int srcH, int srcFormat,\n\n                                  int dstW, int dstH, int dstFormat,\n\n                                  int flags, SwsFilter *srcFilter,\n\n                                  SwsFilter *dstFilter, double *param)\n\n{\n\n    struct SwsContext *ctx;\n\n\n\n    ctx = av_malloc(sizeof(struct SwsContext));\n\n    if (ctx)\n\n        ctx->av_class = av_mallocz(sizeof(AVClass));\n\n    if (!ctx || !ctx->av_class) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Cannot allocate a resampling context!\\n\");\n\n\n\n        return NULL;\n\n    }\n\n\n\n    if ((srcH != dstH) || (srcW != dstW)) {\n\n        if ((srcFormat != PIX_FMT_YUV420P) || (dstFormat != PIX_FMT_YUV420P)) {\n\n            av_log(NULL, AV_LOG_INFO, \"PIX_FMT_YUV420P will be used as an intermediate format for rescaling\\n\");\n\n        }\n\n        ctx->resampling_ctx = img_resample_init(dstW, dstH, srcW, srcH);\n\n    } else {\n\n        ctx->resampling_ctx = av_malloc(sizeof(ImgReSampleContext));\n\n        ctx->resampling_ctx->iheight = srcH;\n\n        ctx->resampling_ctx->iwidth = srcW;\n\n        ctx->resampling_ctx->oheight = dstH;\n\n        ctx->resampling_ctx->owidth = dstW;\n\n    }\n\n    ctx->src_pix_fmt = srcFormat;\n\n    ctx->dst_pix_fmt = dstFormat;\n\n\n\n    return ctx;\n\n}\n", "idx": 25143}
{"project": "FFmpeg", "commit_id": "21518f5a0a6b644d1dedda5650c15bc3df62a567", "target": 1, "func": "static int vp8_encode(AVCodecContext *avctx, AVPacket *pkt,\n\n                      const AVFrame *frame, int *got_packet)\n\n{\n\n    VP8Context *ctx = avctx->priv_data;\n\n    struct vpx_image *rawimg = NULL;\n\n    struct vpx_image *rawimg_alpha = NULL;\n\n    int64_t timestamp = 0;\n\n    int res, coded_size;\n\n    vpx_enc_frame_flags_t flags = 0;\n\n\n\n    if (frame) {\n\n        rawimg                      = &ctx->rawimg;\n\n        rawimg->planes[VPX_PLANE_Y] = frame->data[0];\n\n        rawimg->planes[VPX_PLANE_U] = frame->data[1];\n\n        rawimg->planes[VPX_PLANE_V] = frame->data[2];\n\n        rawimg->stride[VPX_PLANE_Y] = frame->linesize[0];\n\n        rawimg->stride[VPX_PLANE_U] = frame->linesize[1];\n\n        rawimg->stride[VPX_PLANE_V] = frame->linesize[2];\n\n        if (ctx->is_alpha) {\n\n            uint8_t *u_plane, *v_plane;\n\n            rawimg_alpha = &ctx->rawimg_alpha;\n\n            rawimg_alpha->planes[VPX_PLANE_Y] = frame->data[3];\n\n            u_plane = av_malloc(frame->linesize[1] * frame->height);\n\n            memset(u_plane, 0x80, frame->linesize[1] * frame->height);\n\n            rawimg_alpha->planes[VPX_PLANE_U] = u_plane;\n\n            v_plane = av_malloc(frame->linesize[2] * frame->height);\n\n            memset(v_plane, 0x80, frame->linesize[2] * frame->height);\n\n            rawimg_alpha->planes[VPX_PLANE_V] = v_plane;\n\n            rawimg_alpha->stride[VPX_PLANE_Y] = frame->linesize[0];\n\n            rawimg_alpha->stride[VPX_PLANE_U] = frame->linesize[1];\n\n            rawimg_alpha->stride[VPX_PLANE_V] = frame->linesize[2];\n\n        }\n\n        timestamp                   = frame->pts;\n\n        if (frame->pict_type == AV_PICTURE_TYPE_I)\n\n            flags |= VPX_EFLAG_FORCE_KF;\n\n    }\n\n\n\n    res = vpx_codec_encode(&ctx->encoder, rawimg, timestamp,\n\n                           avctx->ticks_per_frame, flags, ctx->deadline);\n\n    if (res != VPX_CODEC_OK) {\n\n        log_encoder_error(avctx, \"Error encoding frame\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (ctx->is_alpha) {\n\n        res = vpx_codec_encode(&ctx->encoder_alpha, rawimg_alpha, timestamp,\n\n                               avctx->ticks_per_frame, flags, ctx->deadline);\n\n        if (res != VPX_CODEC_OK) {\n\n            log_encoder_error(avctx, \"Error encoding alpha frame\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    coded_size = queue_frames(avctx, pkt, avctx->coded_frame);\n\n\n\n    if (!frame && avctx->flags & CODEC_FLAG_PASS1) {\n\n        unsigned int b64_size = AV_BASE64_SIZE(ctx->twopass_stats.sz);\n\n\n\n        avctx->stats_out = av_malloc(b64_size);\n\n        if (!avctx->stats_out) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Stat buffer alloc (%d bytes) failed\\n\",\n\n                   b64_size);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        av_base64_encode(avctx->stats_out, b64_size, ctx->twopass_stats.buf,\n\n                         ctx->twopass_stats.sz);\n\n    }\n\n\n\n    if (rawimg_alpha) {\n\n        av_freep(&rawimg_alpha->planes[VPX_PLANE_U]);\n\n        av_freep(&rawimg_alpha->planes[VPX_PLANE_V]);\n\n    }\n\n\n\n    *got_packet = !!coded_size;\n\n    return 0;\n\n}\n", "idx": 25144}
{"project": "FFmpeg", "commit_id": "3aac5fcfa9d3748659d78ab2a66d0ccce22cfd4f", "target": 1, "func": "void av_opt_freep_ranges(AVOptionRanges **rangesp)\n\n{\n\n    int i;\n\n    AVOptionRanges *ranges = *rangesp;\n\n\n\n    if (!ranges)\n\n        return;\n\n\n\n    for (i = 0; i < ranges->nb_ranges * ranges->nb_components; i++) {\n\n        AVOptionRange *range = ranges->range[i];\n\n        av_freep(&range->str);\n\n        av_freep(&ranges->range[i]);\n\n    }\n\n    av_freep(&ranges->range);\n\n    av_freep(rangesp);\n\n}\n", "idx": 25145}
{"project": "FFmpeg", "commit_id": "bcaf64b605442e1622d16da89d4ec0e7730b8a8c", "target": 0, "func": "static int oggvorbis_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n\n                                  const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    OggVorbisEncContext *s = avctx->priv_data;\n\n    ogg_packet op;\n\n    int ret, duration;\n\n\n\n    /* send samples to libvorbis */\n\n    if (frame) {\n\n        const int samples = frame->nb_samples;\n\n        float **buffer;\n\n        int c, channels = s->vi.channels;\n\n\n\n        buffer = vorbis_analysis_buffer(&s->vd, samples);\n\n        for (c = 0; c < channels; c++) {\n\n            int co = (channels > 8) ? c :\n\n                     ff_vorbis_encoding_channel_layout_offsets[channels - 1][c];\n\n            memcpy(buffer[c], frame->extended_data[co],\n\n                   samples * sizeof(*buffer[c]));\n\n        }\n\n        if ((ret = vorbis_analysis_wrote(&s->vd, samples)) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"error in vorbis_analysis_wrote()\\n\");\n\n            return vorbis_error_to_averror(ret);\n\n        }\n\n        if ((ret = ff_af_queue_add(&s->afq, frame)) < 0)\n\n            return ret;\n\n    } else {\n\n        if (!s->eof)\n\n            if ((ret = vorbis_analysis_wrote(&s->vd, 0)) < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"error in vorbis_analysis_wrote()\\n\");\n\n                return vorbis_error_to_averror(ret);\n\n            }\n\n        s->eof = 1;\n\n    }\n\n\n\n    /* retrieve available packets from libvorbis */\n\n    while ((ret = vorbis_analysis_blockout(&s->vd, &s->vb)) == 1) {\n\n        if ((ret = vorbis_analysis(&s->vb, NULL)) < 0)\n\n            break;\n\n        if ((ret = vorbis_bitrate_addblock(&s->vb)) < 0)\n\n            break;\n\n\n\n        /* add any available packets to the output packet buffer */\n\n        while ((ret = vorbis_bitrate_flushpacket(&s->vd, &op)) == 1) {\n\n            if (av_fifo_space(s->pkt_fifo) < sizeof(ogg_packet) + op.bytes) {\n\n                av_log(avctx, AV_LOG_ERROR, \"packet buffer is too small\\n\");\n\n                return AVERROR_BUG;\n\n            }\n\n            av_fifo_generic_write(s->pkt_fifo, &op, sizeof(ogg_packet), NULL);\n\n            av_fifo_generic_write(s->pkt_fifo, op.packet, op.bytes, NULL);\n\n        }\n\n        if (ret < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"error getting available packets\\n\");\n\n            break;\n\n        }\n\n    }\n\n    if (ret < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"error getting available packets\\n\");\n\n        return vorbis_error_to_averror(ret);\n\n    }\n\n\n\n    /* check for available packets */\n\n    if (av_fifo_size(s->pkt_fifo) < sizeof(ogg_packet))\n\n        return 0;\n\n\n\n    av_fifo_generic_read(s->pkt_fifo, &op, sizeof(ogg_packet), NULL);\n\n\n\n    if ((ret = ff_alloc_packet2(avctx, avpkt, op.bytes)))\n\n        return ret;\n\n    av_fifo_generic_read(s->pkt_fifo, avpkt->data, op.bytes, NULL);\n\n\n\n    avpkt->pts = ff_samples_to_time_base(avctx, op.granulepos);\n\n\n\n    duration = avpriv_vorbis_parse_frame(&s->vp, avpkt->data, avpkt->size);\n\n    if (duration > 0) {\n\n        /* we do not know encoder delay until we get the first packet from\n\n         * libvorbis, so we have to update the AudioFrameQueue counts */\n\n        if (!avctx->delay && s->afq.frames) {\n\n            avctx->delay              = duration;\n\n            av_assert0(!s->afq.remaining_delay);\n\n            s->afq.frames->duration  += duration;\n\n            s->afq.frames->pts       -= duration;\n\n            s->afq.remaining_samples += duration;\n\n        }\n\n        ff_af_queue_remove(&s->afq, duration, &avpkt->pts, &avpkt->duration);\n\n    }\n\n\n\n    *got_packet_ptr = 1;\n\n    return 0;\n\n}\n", "idx": 25147}
{"project": "FFmpeg", "commit_id": "b86651a208ee67666a7305b002bc9f14b21dae7f", "target": 1, "func": "static av_cold int rv40_decode_init(AVCodecContext *avctx)\n\n{\n\n    RV34DecContext *r = avctx->priv_data;\n\n\n\n    r->rv30 = 0;\n\n    ff_rv34_decode_init(avctx);\n\n    if(!aic_top_vlc.bits)\n\n        rv40_init_tables();\n\n    r->parse_slice_header = rv40_parse_slice_header;\n\n    r->decode_intra_types = rv40_decode_intra_types;\n\n    r->decode_mb_info     = rv40_decode_mb_info;\n\n    r->loop_filter        = rv40_loop_filter;\n\n    r->luma_dc_quant_i = rv40_luma_dc_quant[0];\n\n    r->luma_dc_quant_p = rv40_luma_dc_quant[1];\n\n    return 0;\n\n}\n", "idx": 25149}
{"project": "FFmpeg", "commit_id": "346e09638cc159a3c3e4cf971a5b795644faac16", "target": 0, "func": "void ff_er_add_slice(ERContext *s, int startx, int starty,\n\n                     int endx, int endy, int status)\n\n{\n\n    const int start_i  = av_clip(startx + starty * s->mb_width, 0, s->mb_num - 1);\n\n    const int end_i    = av_clip(endx   + endy   * s->mb_width, 0, s->mb_num);\n\n    const int start_xy = s->mb_index2xy[start_i];\n\n    const int end_xy   = s->mb_index2xy[end_i];\n\n    int mask           = -1;\n\n\n\n    if (s->avctx->hwaccel)\n\n        return;\n\n\n\n    if (start_i > end_i || start_xy > end_xy) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"internal error, slice end before start\\n\");\n\n        return;\n\n    }\n\n\n\n    if (!s->avctx->err_recognition)\n\n        return;\n\n\n\n    mask &= ~VP_START;\n\n    if (status & (ER_AC_ERROR | ER_AC_END)) {\n\n        mask           &= ~(ER_AC_ERROR | ER_AC_END);\n\n        s->error_count -= end_i - start_i + 1;\n\n    }\n\n    if (status & (ER_DC_ERROR | ER_DC_END)) {\n\n        mask           &= ~(ER_DC_ERROR | ER_DC_END);\n\n        s->error_count -= end_i - start_i + 1;\n\n    }\n\n    if (status & (ER_MV_ERROR | ER_MV_END)) {\n\n        mask           &= ~(ER_MV_ERROR | ER_MV_END);\n\n        s->error_count -= end_i - start_i + 1;\n\n    }\n\n\n\n    if (status & ER_MB_ERROR) {\n\n        s->error_occurred = 1;\n\n        s->error_count    = INT_MAX;\n\n    }\n\n\n\n    if (mask == ~0x7F) {\n\n        memset(&s->error_status_table[start_xy], 0,\n\n               (end_xy - start_xy) * sizeof(uint8_t));\n\n    } else {\n\n        int i;\n\n        for (i = start_xy; i < end_xy; i++)\n\n            s->error_status_table[i] &= mask;\n\n    }\n\n\n\n    if (end_i == s->mb_num)\n\n        s->error_count = INT_MAX;\n\n    else {\n\n        s->error_status_table[end_xy] &= mask;\n\n        s->error_status_table[end_xy] |= status;\n\n    }\n\n\n\n    s->error_status_table[start_xy] |= VP_START;\n\n\n\n    if (start_xy > 0 && !(s->avctx->active_thread_type & FF_THREAD_SLICE) &&\n\n        s->avctx->skip_top * s->mb_width < start_i) {\n\n        int prev_status = s->error_status_table[s->mb_index2xy[start_i - 1]];\n\n\n\n        prev_status &= ~ VP_START;\n\n        if (prev_status != (ER_MV_END | ER_DC_END | ER_AC_END)) {\n\n            s->error_occurred = 1;\n\n            s->error_count = INT_MAX;\n\n        }\n\n    }\n\n}\n", "idx": 25151}
{"project": "FFmpeg", "commit_id": "2aab7c2dfaca4386c38e5d565cd2bf73096bcc86", "target": 0, "func": "static void avc_luma_hv_qrt_4w_msa(const uint8_t *src_x, const uint8_t *src_y,\n\n                                   int32_t src_stride, uint8_t *dst,\n\n                                   int32_t dst_stride, int32_t height)\n\n{\n\n    uint32_t loop_cnt;\n\n    v16i8 src_hz0, src_hz1, src_hz2, src_hz3;\n\n    v16i8 src_vt0, src_vt1, src_vt2, src_vt3, src_vt4;\n\n    v16i8 src_vt5, src_vt6, src_vt7, src_vt8;\n\n    v16i8 mask0, mask1, mask2;\n\n    v8i16 hz_out0, hz_out1, vert_out0, vert_out1;\n\n    v8i16 out0, out1;\n\n    v16u8 out;\n\n\n\n    LD_SB3(&luma_mask_arr[48], 16, mask0, mask1, mask2);\n\n\n\n    LD_SB5(src_y, src_stride, src_vt0, src_vt1, src_vt2, src_vt3, src_vt4);\n\n    src_y += (5 * src_stride);\n\n\n\n    src_vt0 = (v16i8) __msa_insve_w((v4i32) src_vt0, 1, (v4i32) src_vt1);\n\n    src_vt1 = (v16i8) __msa_insve_w((v4i32) src_vt1, 1, (v4i32) src_vt2);\n\n    src_vt2 = (v16i8) __msa_insve_w((v4i32) src_vt2, 1, (v4i32) src_vt3);\n\n    src_vt3 = (v16i8) __msa_insve_w((v4i32) src_vt3, 1, (v4i32) src_vt4);\n\n\n\n    XORI_B4_128_SB(src_vt0, src_vt1, src_vt2, src_vt3);\n\n\n\n    for (loop_cnt = (height >> 2); loop_cnt--;) {\n\n        LD_SB4(src_x, src_stride, src_hz0, src_hz1, src_hz2, src_hz3);\n\n        src_x += (4 * src_stride);\n\n\n\n        XORI_B4_128_SB(src_hz0, src_hz1, src_hz2, src_hz3);\n\n\n\n        hz_out0 = AVC_XOR_VSHF_B_AND_APPLY_6TAP_HORIZ_FILT_SH(src_hz0,\n\n                                                              src_hz1, mask0,\n\n                                                              mask1, mask2);\n\n        hz_out1 = AVC_XOR_VSHF_B_AND_APPLY_6TAP_HORIZ_FILT_SH(src_hz2,\n\n                                                              src_hz3, mask0,\n\n                                                              mask1, mask2);\n\n\n\n        SRARI_H2_SH(hz_out0, hz_out1, 5);\n\n        SAT_SH2_SH(hz_out0, hz_out1, 7);\n\n\n\n        LD_SB4(src_y, src_stride, src_vt5, src_vt6, src_vt7, src_vt8);\n\n        src_y += (4 * src_stride);\n\n\n\n        src_vt4 = (v16i8) __msa_insve_w((v4i32) src_vt4, 1, (v4i32) src_vt5);\n\n        src_vt5 = (v16i8) __msa_insve_w((v4i32) src_vt5, 1, (v4i32) src_vt6);\n\n        src_vt6 = (v16i8) __msa_insve_w((v4i32) src_vt6, 1, (v4i32) src_vt7);\n\n        src_vt7 = (v16i8) __msa_insve_w((v4i32) src_vt7, 1, (v4i32) src_vt8);\n\n\n\n        XORI_B4_128_SB(src_vt4, src_vt5, src_vt6, src_vt7);\n\n\n\n        /* filter calc */\n\n        vert_out0 = AVC_CALC_DPADD_B_6PIX_2COEFF_R_SH(src_vt0, src_vt1,\n\n                                                      src_vt2, src_vt3,\n\n                                                      src_vt4, src_vt5);\n\n        vert_out1 = AVC_CALC_DPADD_B_6PIX_2COEFF_R_SH(src_vt2, src_vt3,\n\n                                                      src_vt4, src_vt5,\n\n                                                      src_vt6, src_vt7);\n\n\n\n        SRARI_H2_SH(vert_out0, vert_out1, 5);\n\n        SAT_SH2_SH(vert_out0, vert_out1, 7);\n\n\n\n        out0 = __msa_srari_h((hz_out0 + vert_out0), 1);\n\n        out1 = __msa_srari_h((hz_out1 + vert_out1), 1);\n\n\n\n        SAT_SH2_SH(out0, out1, 7);\n\n        out = PCKEV_XORI128_UB(out0, out1);\n\n        ST4x4_UB(out, out, 0, 1, 2, 3, dst, dst_stride);\n\n        dst += (4 * dst_stride);\n\n\n\n        src_vt3 = src_vt7;\n\n        src_vt1 = src_vt5;\n\n        src_vt0 = src_vt4;\n\n        src_vt4 = src_vt8;\n\n        src_vt2 = src_vt6;\n\n    }\n\n}\n", "idx": 25152}
{"project": "FFmpeg", "commit_id": "5b0e811a65737463c7e4206b68a23e19d4473519", "target": 1, "func": "static void qtrle_decode_24bpp(QtrleContext *s)\n\n{\n\n    int stream_ptr;\n\n    int header;\n\n    int start_line;\n\n    int lines_to_change;\n\n    signed char rle_code;\n\n    int row_ptr, pixel_ptr;\n\n    int row_inc = s->frame.linesize[0];\n\n    unsigned char r, g, b;\n\n    unsigned char *rgb = s->frame.data[0];\n\n    int pixel_limit = s->frame.linesize[0] * s->avctx->height;\n\n\n\n    /* check if this frame is even supposed to change */\n\n    if (s->size < 8)\n\n        return;\n\n\n\n    /* start after the chunk size */\n\n    stream_ptr = 4;\n\n\n\n    /* fetch the header */\n\n    CHECK_STREAM_PTR(2);\n\n    header = BE_16(&s->buf[stream_ptr]);\n\n    stream_ptr += 2;\n\n\n\n    /* if a header is present, fetch additional decoding parameters */\n\n    if (header & 0x0008) {\n\n        CHECK_STREAM_PTR(8);\n\n        start_line = BE_16(&s->buf[stream_ptr]);\n\n        stream_ptr += 4;\n\n        lines_to_change = BE_16(&s->buf[stream_ptr]);\n\n        stream_ptr += 4;\n\n    } else {\n\n        start_line = 0;\n\n        lines_to_change = s->avctx->height;\n\n    }\n\n\n\n    row_ptr = row_inc * start_line;\n\n    while (lines_to_change--) {\n\n        CHECK_STREAM_PTR(2);\n\n        pixel_ptr = row_ptr + (s->buf[stream_ptr++] - 1) * 3;\n\n\n\n        while ((rle_code = (signed char)s->buf[stream_ptr++]) != -1) {\n\n            if (rle_code == 0) {\n\n                /* there's another skip code in the stream */\n\n                CHECK_STREAM_PTR(1);\n\n                pixel_ptr += (s->buf[stream_ptr++] - 1) * 3;\n\n                CHECK_PIXEL_PTR(0);  /* make sure pixel_ptr is positive */\n\n            } else if (rle_code < 0) {\n\n                /* decode the run length code */\n\n                rle_code = -rle_code;\n\n                CHECK_STREAM_PTR(3);\n\n                r = s->buf[stream_ptr++];\n\n                g = s->buf[stream_ptr++];\n\n                b = s->buf[stream_ptr++];\n\n\n\n                CHECK_PIXEL_PTR(rle_code * 3);\n\n\n\n                while (rle_code--) {\n\n                    rgb[pixel_ptr++] = r;\n\n                    rgb[pixel_ptr++] = g;\n\n                    rgb[pixel_ptr++] = b;\n\n                }\n\n            } else {\n\n                CHECK_STREAM_PTR(rle_code * 3);\n\n                CHECK_PIXEL_PTR(rle_code * 3);\n\n\n\n                /* copy pixels directly to output */\n\n                while (rle_code--) {\n\n                    rgb[pixel_ptr++] = s->buf[stream_ptr++];\n\n                    rgb[pixel_ptr++] = s->buf[stream_ptr++];\n\n                    rgb[pixel_ptr++] = s->buf[stream_ptr++];\n\n                }\n\n            }\n\n        }\n\n        row_ptr += row_inc;\n\n    }\n\n}\n", "idx": 25155}
{"project": "FFmpeg", "commit_id": "a4696aa2fe88c21927835e59d543eb2efbfabaef", "target": 1, "func": "static void rtcp_send_sr(AVFormatContext *s1, int64_t ntp_time)\n\n{\n\n    RTPDemuxContext *s = s1->priv_data;\n\n    uint32_t rtp_ts;\n\n\n\n#if defined(DEBUG)\n\n    printf(\"RTCP: %02x %\"PRIx64\" %x\\n\", s->payload_type, ntp_time, s->timestamp);\n\n#endif\n\n\n\n    if (s->first_rtcp_ntp_time == AV_NOPTS_VALUE) s->first_rtcp_ntp_time = ntp_time;\n\n    s->last_rtcp_ntp_time = ntp_time;\n\n    rtp_ts = av_rescale_q(ntp_time - s->first_rtcp_ntp_time, AV_TIME_BASE_Q,\n\n                          s1->streams[0]->time_base) + s->base_timestamp;\n\n    put_byte(s1->pb, (RTP_VERSION << 6));\n\n    put_byte(s1->pb, 200);\n\n    put_be16(s1->pb, 6); /* length in words - 1 */\n\n    put_be32(s1->pb, s->ssrc);\n\n    put_be32(s1->pb, ntp_time / 1000000);\n\n    put_be32(s1->pb, ((ntp_time % 1000000) << 32) / 1000000);\n\n    put_be32(s1->pb, rtp_ts);\n\n    put_be32(s1->pb, s->packet_count);\n\n    put_be32(s1->pb, s->octet_count);\n\n    put_flush_packet(s1->pb);\n\n}\n", "idx": 25156}
{"project": "FFmpeg", "commit_id": "9588ec340c3f33c7474b4cd2893046cfdaee42bf", "target": 0, "func": "static void decode_cabac_residual( H264Context *h, DCTELEM *block, int cat, int n, const uint8_t *scantable, const uint32_t *qmul, int max_coeff) {\n\n    static const int significant_coeff_flag_offset[2][6] = {\n\n      { 105+0, 105+15, 105+29, 105+44, 105+47, 402 },\n\n      { 277+0, 277+15, 277+29, 277+44, 277+47, 436 }\n\n    };\n\n    static const int last_coeff_flag_offset[2][6] = {\n\n      { 166+0, 166+15, 166+29, 166+44, 166+47, 417 },\n\n      { 338+0, 338+15, 338+29, 338+44, 338+47, 451 }\n\n    };\n\n    static const int coeff_abs_level_m1_offset[6] = {\n\n        227+0, 227+10, 227+20, 227+30, 227+39, 426\n\n    };\n\n    static const uint8_t significant_coeff_flag_offset_8x8[2][63] = {\n\n      { 0, 1, 2, 3, 4, 5, 5, 4, 4, 3, 3, 4, 4, 4, 5, 5,\n\n        4, 4, 4, 4, 3, 3, 6, 7, 7, 7, 8, 9,10, 9, 8, 7,\n\n        7, 6,11,12,13,11, 6, 7, 8, 9,14,10, 9, 8, 6,11,\n\n       12,13,11, 6, 9,14,10, 9,11,12,13,11,14,10,12 },\n\n      { 0, 1, 1, 2, 2, 3, 3, 4, 5, 6, 7, 7, 7, 8, 4, 5,\n\n        6, 9,10,10, 8,11,12,11, 9, 9,10,10, 8,11,12,11,\n\n        9, 9,10,10, 8,11,12,11, 9, 9,10,10, 8,13,13, 9,\n\n        9,10,10, 8,13,13, 9, 9,10,10,14,14,14,14,14 }\n\n    };\n\n    /* node ctx: 0..3: abslevel1 (with abslevelgt1 == 0).\n\n     * 4..7: abslevelgt1 + 3 (and abslevel1 doesn't matter).\n\n     * map node ctx => cabac ctx for level=1 */\n\n    static const uint8_t coeff_abs_level1_ctx[8] = { 1, 2, 3, 4, 0, 0, 0, 0 };\n\n    /* map node ctx => cabac ctx for level>1 */\n\n    static const uint8_t coeff_abs_levelgt1_ctx[8] = { 5, 5, 5, 5, 6, 7, 8, 9 };\n\n    static const uint8_t coeff_abs_level_transition[2][8] = {\n\n    /* update node ctx after decoding a level=1 */\n\n        { 1, 2, 3, 3, 4, 5, 6, 7 },\n\n    /* update node ctx after decoding a level>1 */\n\n        { 4, 4, 4, 4, 5, 6, 7, 7 }\n\n    };\n\n\n\n    int index[64];\n\n\n\n    int av_unused last;\n\n    int coeff_count = 0;\n\n    int node_ctx = 0;\n\n\n\n    uint8_t *significant_coeff_ctx_base;\n\n    uint8_t *last_coeff_ctx_base;\n\n    uint8_t *abs_level_m1_ctx_base;\n\n\n\n#ifndef ARCH_X86\n\n#define CABAC_ON_STACK\n\n#endif\n\n#ifdef CABAC_ON_STACK\n\n#define CC &cc\n\n    CABACContext cc;\n\n    cc.range     = h->cabac.range;\n\n    cc.low       = h->cabac.low;\n\n    cc.bytestream= h->cabac.bytestream;\n\n#else\n\n#define CC &h->cabac\n\n#endif\n\n\n\n\n\n    /* cat: 0-> DC 16x16  n = 0\n\n     *      1-> AC 16x16  n = luma4x4idx\n\n     *      2-> Luma4x4   n = luma4x4idx\n\n     *      3-> DC Chroma n = iCbCr\n\n     *      4-> AC Chroma n = 4 * iCbCr + chroma4x4idx\n\n     *      5-> Luma8x8   n = 4 * luma8x8idx\n\n     */\n\n\n\n    /* read coded block flag */\n\n    if( cat != 5 ) {\n\n        if( get_cabac( CC, &h->cabac_state[85 + get_cabac_cbf_ctx( h, cat, n ) ] ) == 0 ) {\n\n            if( cat == 1 || cat == 2 )\n\n                h->non_zero_count_cache[scan8[n]] = 0;\n\n            else if( cat == 4 )\n\n                h->non_zero_count_cache[scan8[16+n]] = 0;\n\n#ifdef CABAC_ON_STACK\n\n            h->cabac.range     = cc.range     ;\n\n            h->cabac.low       = cc.low       ;\n\n            h->cabac.bytestream= cc.bytestream;\n\n#endif\n\n            return;\n\n        }\n\n    }\n\n\n\n    significant_coeff_ctx_base = h->cabac_state\n\n        + significant_coeff_flag_offset[MB_FIELD][cat];\n\n    last_coeff_ctx_base = h->cabac_state\n\n        + last_coeff_flag_offset[MB_FIELD][cat];\n\n    abs_level_m1_ctx_base = h->cabac_state\n\n        + coeff_abs_level_m1_offset[cat];\n\n\n\n    if( cat == 5 ) {\n\n#define DECODE_SIGNIFICANCE( coefs, sig_off, last_off ) \\\n\n        for(last= 0; last < coefs; last++) { \\\n\n            uint8_t *sig_ctx = significant_coeff_ctx_base + sig_off; \\\n\n            if( get_cabac( CC, sig_ctx )) { \\\n\n                uint8_t *last_ctx = last_coeff_ctx_base + last_off; \\\n\n                index[coeff_count++] = last; \\\n\n                if( get_cabac( CC, last_ctx ) ) { \\\n\n                    last= max_coeff; \\\n\n                    break; \\\n\n                } \\\n\n            } \\\n\n        }\\\n\n        if( last == max_coeff -1 ) {\\\n\n            index[coeff_count++] = last;\\\n\n        }\n\n        const uint8_t *sig_off = significant_coeff_flag_offset_8x8[MB_FIELD];\n\n#if defined(ARCH_X86) && defined(HAVE_7REGS) && defined(HAVE_EBX_AVAILABLE) && !defined(BROKEN_RELOCATIONS)\n\n        coeff_count= decode_significance_8x8_x86(CC, significant_coeff_ctx_base, index, sig_off);\n\n    } else {\n\n        coeff_count= decode_significance_x86(CC, max_coeff, significant_coeff_ctx_base, index);\n\n#else\n\n        DECODE_SIGNIFICANCE( 63, sig_off[last], last_coeff_flag_offset_8x8[last] );\n\n    } else {\n\n        DECODE_SIGNIFICANCE( max_coeff - 1, last, last );\n\n#endif\n\n    }\n\n    assert(coeff_count > 0);\n\n\n\n    if( cat == 0 )\n\n        h->cbp_table[h->mb_xy] |= 0x100;\n\n    else if( cat == 1 || cat == 2 )\n\n        h->non_zero_count_cache[scan8[n]] = coeff_count;\n\n    else if( cat == 3 )\n\n        h->cbp_table[h->mb_xy] |= 0x40 << n;\n\n    else if( cat == 4 )\n\n        h->non_zero_count_cache[scan8[16+n]] = coeff_count;\n\n    else {\n\n        assert( cat == 5 );\n\n        fill_rectangle(&h->non_zero_count_cache[scan8[n]], 2, 2, 8, coeff_count, 1);\n\n    }\n\n\n\n    for( coeff_count--; coeff_count >= 0; coeff_count-- ) {\n\n        uint8_t *ctx = coeff_abs_level1_ctx[node_ctx] + abs_level_m1_ctx_base;\n\n\n\n        int j= scantable[index[coeff_count]];\n\n\n\n        if( get_cabac( CC, ctx ) == 0 ) {\n\n            node_ctx = coeff_abs_level_transition[0][node_ctx];\n\n            if( !qmul ) {\n\n                block[j] = get_cabac_bypass_sign( CC, -1);\n\n            }else{\n\n                block[j] = (get_cabac_bypass_sign( CC, -qmul[j]) + 32) >> 6;\n\n            }\n\n        } else {\n\n            int coeff_abs = 2;\n\n            ctx = coeff_abs_levelgt1_ctx[node_ctx] + abs_level_m1_ctx_base;\n\n            node_ctx = coeff_abs_level_transition[1][node_ctx];\n\n\n\n            while( coeff_abs < 15 && get_cabac( CC, ctx ) ) {\n\n                coeff_abs++;\n\n            }\n\n\n\n            if( coeff_abs >= 15 ) {\n\n                int j = 0;\n\n                while( get_cabac_bypass( CC ) ) {\n\n                    j++;\n\n                }\n\n\n\n                coeff_abs=1;\n\n                while( j-- ) {\n\n                    coeff_abs += coeff_abs + get_cabac_bypass( CC );\n\n                }\n\n                coeff_abs+= 14;\n\n            }\n\n\n\n            if( !qmul ) {\n\n                if( get_cabac_bypass( CC ) ) block[j] = -coeff_abs;\n\n                else                                block[j] =  coeff_abs;\n\n            }else{\n\n                if( get_cabac_bypass( CC ) ) block[j] = (-coeff_abs * qmul[j] + 32) >> 6;\n\n                else                                block[j] = ( coeff_abs * qmul[j] + 32) >> 6;\n\n            }\n\n        }\n\n    }\n\n#ifdef CABAC_ON_STACK\n\n            h->cabac.range     = cc.range     ;\n\n            h->cabac.low       = cc.low       ;\n\n            h->cabac.bytestream= cc.bytestream;\n\n#endif\n\n\n\n}\n", "idx": 25164}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static inline void downmix_2f_2r_to_dolby(float *samples)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        samples[i] -= samples[i + 512];\n\n        samples[i + 256] += samples[i + 768];\n\n        samples[i + 512] = samples[i + 768] = 0;\n\n    }\n\n}\n", "idx": 25175}
{"project": "FFmpeg", "commit_id": "5a412a5c3cc216ae1d15e6b884bda7214b73a5b0", "target": 1, "func": "static int extract_extradata_h2645(AVBSFContext *ctx, AVPacket *pkt,\n\n                                   uint8_t **data, int *size)\n\n{\n\n    static const int extradata_nal_types_hevc[] = {\n\n        HEVC_NAL_VPS, HEVC_NAL_SPS, HEVC_NAL_PPS,\n\n    };\n\n    static const int extradata_nal_types_h264[] = {\n\n        H264_NAL_SPS, H264_NAL_PPS,\n\n    };\n\n\n\n    ExtractExtradataContext *s = ctx->priv_data;\n\n\n\n    H2645Packet h2645_pkt = { 0 };\n\n    int extradata_size = 0;\n\n    const int *extradata_nal_types;\n\n    int nb_extradata_nal_types;\n\n    int i, has_sps = 0, has_vps = 0, ret = 0;\n\n\n\n    if (ctx->par_in->codec_id == AV_CODEC_ID_HEVC) {\n\n        extradata_nal_types    = extradata_nal_types_hevc;\n\n        nb_extradata_nal_types = FF_ARRAY_ELEMS(extradata_nal_types_hevc);\n\n    } else {\n\n        extradata_nal_types    = extradata_nal_types_h264;\n\n        nb_extradata_nal_types = FF_ARRAY_ELEMS(extradata_nal_types_h264);\n\n    }\n\n\n\n    ret = ff_h2645_packet_split(&h2645_pkt, pkt->data, pkt->size,\n\n                                ctx, 0, 0, ctx->par_in->codec_id, 1);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    for (i = 0; i < h2645_pkt.nb_nals; i++) {\n\n        H2645NAL *nal = &h2645_pkt.nals[i];\n\n        if (val_in_array(extradata_nal_types, nb_extradata_nal_types, nal->type)) {\n\n            extradata_size += nal->raw_size + 3;\n\n            if (ctx->par_in->codec_id == AV_CODEC_ID_HEVC) {\n\n                if (nal->type == HEVC_NAL_SPS) has_sps = 1;\n\n                if (nal->type == HEVC_NAL_VPS) has_vps = 1;\n\n            } else {\n\n                if (nal->type == H264_NAL_SPS) has_sps = 1;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (extradata_size &&\n\n        ((ctx->par_in->codec_id == AV_CODEC_ID_HEVC && has_sps && has_vps) ||\n\n         (ctx->par_in->codec_id == AV_CODEC_ID_H264 && has_sps))) {\n\n        AVBufferRef *filtered_buf;\n\n        uint8_t *extradata, *filtered_data;\n\n\n\n        if (s->remove) {\n\n            filtered_buf = av_buffer_alloc(pkt->size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n            if (!filtered_buf) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto fail;\n\n            }\n\n            filtered_data = filtered_buf->data;\n\n        }\n\n\n\n        extradata = av_malloc(extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!extradata) {\n\n            av_buffer_unref(&filtered_buf);\n\n            ret = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n\n\n        *data = extradata;\n\n        *size = extradata_size;\n\n\n\n        for (i = 0; i < h2645_pkt.nb_nals; i++) {\n\n            H2645NAL *nal = &h2645_pkt.nals[i];\n\n            if (val_in_array(extradata_nal_types, nb_extradata_nal_types,\n\n                             nal->type)) {\n\n                AV_WB24(extradata, 1); // startcode\n\n                memcpy(extradata + 3, nal->raw_data, nal->raw_size);\n\n                extradata += 3 + nal->raw_size;\n\n            } else if (s->remove) {\n\n                AV_WB24(filtered_data, 1); // startcode\n\n                memcpy(filtered_data + 3, nal->raw_data, nal->raw_size);\n\n                filtered_data += 3 + nal->raw_size;\n\n            }\n\n        }\n\n\n\n        if (s->remove) {\n\n            av_buffer_unref(&pkt->buf);\n\n            pkt->buf  = filtered_buf;\n\n            pkt->data = filtered_buf->data;\n\n            pkt->size = filtered_data - filtered_buf->data;\n\n        }\n\n    }\n\n\n\nfail:\n\n    ff_h2645_packet_uninit(&h2645_pkt);\n\n    return ret;\n\n}\n", "idx": 25179}
{"project": "FFmpeg", "commit_id": "f4aa8085f23c3abff3114d7bf638698d42110526", "target": 1, "func": "av_cold void ff_psy_end(FFPsyContext *ctx)\n\n{\n\n    if (ctx->model->end)\n\n        ctx->model->end(ctx);\n\n    av_freep(&ctx->bands);\n\n    av_freep(&ctx->num_bands);\n\n    av_freep(&ctx->group);\n\n    av_freep(&ctx->ch);\n\n}\n", "idx": 25180}
{"project": "FFmpeg", "commit_id": "0409d333115e623b5ccdbb364d64ca2a52fd8467", "target": 1, "func": "static void FUNC(put_hevc_epel_bi_w_h)(uint8_t *_dst, ptrdiff_t _dststride, uint8_t *_src, ptrdiff_t _srcstride,\n\n                                       int16_t *src2,\n\n                                       int height, int denom, int wx0, int wx1,\n\n                                       int ox0, int ox1, intptr_t mx, intptr_t my, int width)\n\n{\n\n    int x, y;\n\n    pixel *src = (pixel *)_src;\n\n    ptrdiff_t srcstride  = _srcstride / sizeof(pixel);\n\n    pixel *dst          = (pixel *)_dst;\n\n    ptrdiff_t dststride = _dststride / sizeof(pixel);\n\n    const int8_t *filter = ff_hevc_epel_filters[mx - 1];\n\n    int shift = 14 + 1 - BIT_DEPTH;\n\n    int log2Wd = denom + shift - 1;\n\n\n\n    ox0     = ox0 * (1 << (BIT_DEPTH - 8));\n\n    ox1     = ox1 * (1 << (BIT_DEPTH - 8));\n\n    for (y = 0; y < height; y++) {\n\n        for (x = 0; x < width; x++)\n\n            dst[x] = av_clip_pixel(((EPEL_FILTER(src, 1) >> (BIT_DEPTH - 8)) * wx1 + src2[x] * wx0 +\n\n                                    ((ox0 + ox1 + 1) << log2Wd)) >> (log2Wd + 1));\n\n        src  += srcstride;\n\n        dst  += dststride;\n\n        src2 += MAX_PB_SIZE;\n\n    }\n\n}\n", "idx": 25181}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(yuvPlanartoyuy2)(const uint8_t *ysrc, const uint8_t *usrc, const uint8_t *vsrc, uint8_t *dst,\n\n\tunsigned int width, unsigned int height,\n\n\tint lumStride, int chromStride, int dstStride, int vertLumPerChroma)\n\n{\n\n\tunsigned y;\n\n\tconst unsigned chromWidth= width>>1;\n\n\tfor(y=0; y<height; y++)\n\n\t{\n\n#ifdef HAVE_MMX\n\n//FIXME handle 2 lines a once (fewer prefetch, reuse some chrom, but very likely limited by mem anyway)\n\n\t\tasm volatile(\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\"\n\n\t\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%1, %%\"REG_a\", 2)\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%2, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%3, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\t\"movq (%2, %%\"REG_a\"), %%mm0\t\\n\\t\" // U(0)\n\n\t\t\t\"movq %%mm0, %%mm2\t\t\\n\\t\" // U(0)\n\n\t\t\t\"movq (%3, %%\"REG_a\"), %%mm1\t\\n\\t\" // V(0)\n\n\t\t\t\"punpcklbw %%mm1, %%mm0\t\t\\n\\t\" // UVUV UVUV(0)\n\n\t\t\t\"punpckhbw %%mm1, %%mm2\t\t\\n\\t\" // UVUV UVUV(8)\n\n\n\n\t\t\t\"movq (%1, %%\"REG_a\",2), %%mm3\t\\n\\t\" // Y(0)\n\n\t\t\t\"movq 8(%1, %%\"REG_a\",2), %%mm5\t\\n\\t\" // Y(8)\n\n\t\t\t\"movq %%mm3, %%mm4\t\t\\n\\t\" // Y(0)\n\n\t\t\t\"movq %%mm5, %%mm6\t\t\\n\\t\" // Y(8)\n\n\t\t\t\"punpcklbw %%mm0, %%mm3\t\t\\n\\t\" // YUYV YUYV(0)\n\n\t\t\t\"punpckhbw %%mm0, %%mm4\t\t\\n\\t\" // YUYV YUYV(4)\n\n\t\t\t\"punpcklbw %%mm2, %%mm5\t\t\\n\\t\" // YUYV YUYV(8)\n\n\t\t\t\"punpckhbw %%mm2, %%mm6\t\t\\n\\t\" // YUYV YUYV(12)\n\n\n\n\t\t\tMOVNTQ\" %%mm3, (%0, %%\"REG_a\", 4)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm4, 8(%0, %%\"REG_a\", 4)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm5, 16(%0, %%\"REG_a\", 4)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm6, 24(%0, %%\"REG_a\", 4)\\n\\t\"\n\n\n\n\t\t\t\"add $8, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\"cmp %4, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\t\t\t::\"r\"(dst), \"r\"(ysrc), \"r\"(usrc), \"r\"(vsrc), \"g\" ((long)chromWidth)\n\n\t\t\t: \"%\"REG_a\n\n\t\t);\n\n#else\n\n\n\n#if defined ARCH_ALPHA && defined HAVE_MVI\n\n#define pl2yuy2(n)\t\t\t\t\t\\\n\n\ty1 = yc[n];\t\t\t\t\t\\\n\n\ty2 = yc2[n];\t\t\t\t\t\\\n\n\tu = uc[n];\t\t\t\t\t\\\n\n\tv = vc[n];\t\t\t\t\t\\\n\n\tasm(\"unpkbw %1, %0\" : \"=r\"(y1) : \"r\"(y1));\t\\\n\n\tasm(\"unpkbw %1, %0\" : \"=r\"(y2) : \"r\"(y2));\t\\\n\n\tasm(\"unpkbl %1, %0\" : \"=r\"(u) : \"r\"(u));\t\\\n\n\tasm(\"unpkbl %1, %0\" : \"=r\"(v) : \"r\"(v));\t\\\n\n\tyuv1 = (u << 8) + (v << 24);\t\t\t\\\n\n\tyuv2 = yuv1 + y2;\t\t\t\t\\\n\n\tyuv1 += y1;\t\t\t\t\t\\\n\n\tqdst[n] = yuv1;\t\t\t\t\t\\\n\n\tqdst2[n] = yuv2;\n\n\n\n\t\tint i;\n\n\t\tuint64_t *qdst = (uint64_t *) dst;\n\n\t\tuint64_t *qdst2 = (uint64_t *) (dst + dstStride);\n\n\t\tconst uint32_t *yc = (uint32_t *) ysrc;\n\n\t\tconst uint32_t *yc2 = (uint32_t *) (ysrc + lumStride);\n\n\t\tconst uint16_t *uc = (uint16_t*) usrc, *vc = (uint16_t*) vsrc;\n\n\t\tfor(i = 0; i < chromWidth; i += 8){\n\n\t\t\tuint64_t y1, y2, yuv1, yuv2;\n\n\t\t\tuint64_t u, v;\n\n\t\t\t/* Prefetch */\n\n\t\t\tasm(\"ldq $31,64(%0)\" :: \"r\"(yc));\n\n\t\t\tasm(\"ldq $31,64(%0)\" :: \"r\"(yc2));\n\n\t\t\tasm(\"ldq $31,64(%0)\" :: \"r\"(uc));\n\n\t\t\tasm(\"ldq $31,64(%0)\" :: \"r\"(vc));\n\n\n\n\t\t\tpl2yuy2(0);\n\n\t\t\tpl2yuy2(1);\n\n\t\t\tpl2yuy2(2);\n\n\t\t\tpl2yuy2(3);\n\n\n\n\t\t\tyc += 4;\n\n\t\t\tyc2 += 4;\n\n\t\t\tuc += 4;\n\n\t\t\tvc += 4;\n\n\t\t\tqdst += 4;\n\n\t\t\tqdst2 += 4;\n\n\t\t}\n\n\t\ty++;\n\n\t\tysrc += lumStride;\n\n\t\tdst += dstStride;\n\n\n\n#elif __WORDSIZE >= 64\n\n\t\tint i;\n\n\t\tuint64_t *ldst = (uint64_t *) dst;\n\n\t\tconst uint8_t *yc = ysrc, *uc = usrc, *vc = vsrc;\n\n\t\tfor(i = 0; i < chromWidth; i += 2){\n\n\t\t\tuint64_t k, l;\n\n\t\t\tk = yc[0] + (uc[0] << 8) +\n\n\t\t\t    (yc[1] << 16) + (vc[0] << 24);\n\n\t\t\tl = yc[2] + (uc[1] << 8) +\n\n\t\t\t    (yc[3] << 16) + (vc[1] << 24);\n\n\t\t\t*ldst++ = k + (l << 32);\n\n\t\t\tyc += 4;\n\n\t\t\tuc += 2;\n\n\t\t\tvc += 2;\n\n\t\t}\n\n\n\n#else\n\n\t\tint i, *idst = (int32_t *) dst;\n\n\t\tconst uint8_t *yc = ysrc, *uc = usrc, *vc = vsrc;\n\n\t\tfor(i = 0; i < chromWidth; i++){\n\n#ifdef WORDS_BIGENDIAN\n\n\t\t\t*idst++ = (yc[0] << 24)+ (uc[0] << 16) +\n\n\t\t\t    (yc[1] << 8) + (vc[0] << 0);\n\n#else\n\n\t\t\t*idst++ = yc[0] + (uc[0] << 8) +\n\n\t\t\t    (yc[1] << 16) + (vc[0] << 24);\n\n#endif\n\n\t\t\tyc += 2;\n\n\t\t\tuc++;\n\n\t\t\tvc++;\n\n\t\t}\n\n#endif\n\n#endif\n\n\t\tif((y&(vertLumPerChroma-1))==(vertLumPerChroma-1) )\n\n\t\t{\n\n\t\t\tusrc += chromStride;\n\n\t\t\tvsrc += chromStride;\n\n\t\t}\n\n\t\tysrc += lumStride;\n\n\t\tdst += dstStride;\n\n\t}\n\n#ifdef HAVE_MMX\n\nasm(    EMMS\" \\n\\t\"\n\n        SFENCE\" \\n\\t\"\n\n        :::\"memory\");\n\n#endif\n\n}\n", "idx": 25184}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "static void vc1_inv_trans_4x4_dc_c(uint8_t *dest, int linesize, DCTELEM *block)\n\n{\n\n    int i;\n\n    int dc = block[0];\n\n    const uint8_t *cm;\n\n    dc = (17 * dc +  4) >> 3;\n\n    dc = (17 * dc + 64) >> 7;\n\n    cm = ff_cropTbl + MAX_NEG_CROP + dc;\n\n    for(i = 0; i < 4; i++){\n\n        dest[0] = cm[dest[0]];\n\n        dest[1] = cm[dest[1]];\n\n        dest[2] = cm[dest[2]];\n\n        dest[3] = cm[dest[3]];\n\n        dest += linesize;\n\n    }\n\n}\n", "idx": 25194}
{"project": "FFmpeg", "commit_id": "bfd0e02dd64e912a6b67c25d9f86b3b0b849ad10", "target": 0, "func": "static void read_sbr_noise(SpectralBandReplication *sbr, GetBitContext *gb,\n\n                           SBRData *ch_data, int ch)\n\n{\n\n    int i, j;\n\n    VLC_TYPE (*t_huff)[2], (*f_huff)[2];\n\n    int t_lav, f_lav;\n\n    int delta = (ch == 1 && sbr->bs_coupling == 1) + 1;\n\n\n\n    if (sbr->bs_coupling && ch) {\n\n        t_huff = vlc_sbr[T_HUFFMAN_NOISE_BAL_3_0DB].table;\n\n        t_lav  = vlc_sbr_lav[T_HUFFMAN_NOISE_BAL_3_0DB];\n\n        f_huff = vlc_sbr[F_HUFFMAN_ENV_BAL_3_0DB].table;\n\n        f_lav  = vlc_sbr_lav[F_HUFFMAN_ENV_BAL_3_0DB];\n\n    } else {\n\n        t_huff = vlc_sbr[T_HUFFMAN_NOISE_3_0DB].table;\n\n        t_lav  = vlc_sbr_lav[T_HUFFMAN_NOISE_3_0DB];\n\n        f_huff = vlc_sbr[F_HUFFMAN_ENV_3_0DB].table;\n\n        f_lav  = vlc_sbr_lav[F_HUFFMAN_ENV_3_0DB];\n\n    }\n\n\n\n#if USE_FIXED\n\n    for (i = 0; i < ch_data->bs_num_noise; i++) {\n\n        if (ch_data->bs_df_noise[i]) {\n\n            for (j = 0; j < sbr->n_q; j++)\n\n                ch_data->noise_facs[i + 1][j].mant = ch_data->noise_facs[i][j].mant + delta * (get_vlc2(gb, t_huff, 9, 2) - t_lav);\n\n        } else {\n\n            ch_data->noise_facs[i + 1][0].mant = delta * get_bits(gb, 5); // bs_noise_start_value_balance or bs_noise_start_value_level\n\n            for (j = 1; j < sbr->n_q; j++)\n\n                ch_data->noise_facs[i + 1][j].mant = ch_data->noise_facs[i + 1][j - 1].mant + delta * (get_vlc2(gb, f_huff, 9, 3) - f_lav);\n\n        }\n\n    }\n\n#else\n\n    for (i = 0; i < ch_data->bs_num_noise; i++) {\n\n        if (ch_data->bs_df_noise[i]) {\n\n            for (j = 0; j < sbr->n_q; j++)\n\n                ch_data->noise_facs[i + 1][j] = ch_data->noise_facs[i][j] + delta * (get_vlc2(gb, t_huff, 9, 2) - t_lav);\n\n        } else {\n\n            ch_data->noise_facs[i + 1][0] = delta * get_bits(gb, 5); // bs_noise_start_value_balance or bs_noise_start_value_level\n\n            for (j = 1; j < sbr->n_q; j++)\n\n                ch_data->noise_facs[i + 1][j] = ch_data->noise_facs[i + 1][j - 1] + delta * (get_vlc2(gb, f_huff, 9, 3) - f_lav);\n\n        }\n\n    }\n\n#endif /* USE_FIXED */\n\n\n\n    //assign 0th elements of noise_facs from last elements\n\n    memcpy(ch_data->noise_facs[0], ch_data->noise_facs[ch_data->bs_num_noise],\n\n           sizeof(ch_data->noise_facs[0]));\n\n}\n", "idx": 25197}
{"project": "FFmpeg", "commit_id": "ce1ebb31a9a0e556a89cd7681082af19fbc1cced", "target": 0, "func": "static unsigned tget_short(GetByteContext *gb, int le)\n\n{\n\n    unsigned v = le ? bytestream2_get_le16u(gb) : bytestream2_get_be16u(gb);\n\n    return v;\n\n}\n", "idx": 25208}
{"project": "FFmpeg", "commit_id": "68e39d6efeacbf95144e3fd47b34fc79f907df3c", "target": 1, "func": "static int dv_decode_video_segment(AVCodecContext *avctx, void *arg)\n\n{\n\n    DVVideoContext *s = avctx->priv_data;\n\n    DVwork_chunk *work_chunk = arg;\n\n    int quant, dc, dct_mode, class1, j;\n\n    int mb_index, mb_x, mb_y, last_index;\n\n    int y_stride, linesize;\n\n    DCTELEM *block, *block1;\n\n    int c_offset;\n\n    uint8_t *y_ptr;\n\n    const uint8_t *buf_ptr;\n\n    PutBitContext pb, vs_pb;\n\n    GetBitContext gb;\n\n    BlockInfo mb_data[5 * DV_MAX_BPM], *mb, *mb1;\n\n    LOCAL_ALIGNED_16(DCTELEM, sblock, [5*DV_MAX_BPM], [64]);\n\n    LOCAL_ALIGNED_16(uint8_t, mb_bit_buffer, [80 + 4]); /* allow some slack */\n\n    LOCAL_ALIGNED_16(uint8_t, vs_bit_buffer, [5 * 80 + 4]); /* allow some slack */\n\n    const int log2_blocksize = 3-s->avctx->lowres;\n\n    int is_field_mode[5];\n\n\n\n    assert((((int)mb_bit_buffer) & 7) == 0);\n\n    assert((((int)vs_bit_buffer) & 7) == 0);\n\n\n\n    memset(sblock, 0, 5*DV_MAX_BPM*sizeof(*sblock));\n\n\n\n    /* pass 1: read DC and AC coefficients in blocks */\n\n    buf_ptr = &s->buf[work_chunk->buf_offset*80];\n\n    block1  = &sblock[0][0];\n\n    mb1     = mb_data;\n\n    init_put_bits(&vs_pb, vs_bit_buffer, 5 * 80);\n\n    for (mb_index = 0; mb_index < 5; mb_index++, mb1 += s->sys->bpm, block1 += s->sys->bpm * 64) {\n\n        /* skip header */\n\n        quant = buf_ptr[3] & 0x0f;\n\n        buf_ptr += 4;\n\n        init_put_bits(&pb, mb_bit_buffer, 80);\n\n        mb    = mb1;\n\n        block = block1;\n\n        is_field_mode[mb_index] = 0;\n\n        for (j = 0; j < s->sys->bpm; j++) {\n\n            last_index = s->sys->block_sizes[j];\n\n            init_get_bits(&gb, buf_ptr, last_index);\n\n\n\n            /* get the DC */\n\n            dc       = get_sbits(&gb, 9);\n\n            dct_mode = get_bits1(&gb);\n\n            class1   = get_bits(&gb, 2);\n\n            if (DV_PROFILE_IS_HD(s->sys)) {\n\n                mb->idct_put     = s->idct_put[0];\n\n                mb->scan_table   = s->dv_zigzag[0];\n\n                mb->factor_table = &s->sys->idct_factor[(j >= 4)*4*16*64 + class1*16*64 + quant*64];\n\n                is_field_mode[mb_index] |= !j && dct_mode;\n\n            } else {\n\n                mb->idct_put     = s->idct_put[dct_mode && log2_blocksize == 3];\n\n                mb->scan_table   = s->dv_zigzag[dct_mode];\n\n                mb->factor_table = &s->sys->idct_factor[(class1 == 3)*2*22*64 + dct_mode*22*64 +\n\n                                                        (quant + dv_quant_offset[class1])*64];\n\n            }\n\n            dc = dc << 2;\n\n            /* convert to unsigned because 128 is not added in the\n\n               standard IDCT */\n\n            dc += 1024;\n\n            block[0] = dc;\n\n            buf_ptr += last_index >> 3;\n\n            mb->pos               = 0;\n\n            mb->partial_bit_count = 0;\n\n\n\n            av_dlog(avctx, \"MB block: %d, %d \", mb_index, j);\n\n            dv_decode_ac(&gb, mb, block);\n\n\n\n            /* write the remaining bits in a new buffer only if the\n\n               block is finished */\n\n            if (mb->pos >= 64)\n\n                bit_copy(&pb, &gb);\n\n\n\n            block += 64;\n\n            mb++;\n\n        }\n\n\n\n        /* pass 2: we can do it just after */\n\n        av_dlog(avctx, \"***pass 2 size=%d MB#=%d\\n\", put_bits_count(&pb), mb_index);\n\n        block = block1;\n\n        mb    = mb1;\n\n        init_get_bits(&gb, mb_bit_buffer, put_bits_count(&pb));\n\n        flush_put_bits(&pb);\n\n        for (j = 0; j < s->sys->bpm; j++, block += 64, mb++) {\n\n            if (mb->pos < 64 && get_bits_left(&gb) > 0) {\n\n                dv_decode_ac(&gb, mb, block);\n\n                /* if still not finished, no need to parse other blocks */\n\n                if (mb->pos < 64)\n\n                    break;\n\n            }\n\n        }\n\n        /* all blocks are finished, so the extra bytes can be used at\n\n           the video segment level */\n\n        if (j >= s->sys->bpm)\n\n            bit_copy(&vs_pb, &gb);\n\n    }\n\n\n\n    /* we need a pass over the whole video segment */\n\n    av_dlog(avctx, \"***pass 3 size=%d\\n\", put_bits_count(&vs_pb));\n\n    block = &sblock[0][0];\n\n    mb    = mb_data;\n\n    init_get_bits(&gb, vs_bit_buffer, put_bits_count(&vs_pb));\n\n    flush_put_bits(&vs_pb);\n\n    for (mb_index = 0; mb_index < 5; mb_index++) {\n\n        for (j = 0; j < s->sys->bpm; j++) {\n\n            if (mb->pos < 64) {\n\n                av_dlog(avctx, \"start %d:%d\\n\", mb_index, j);\n\n                dv_decode_ac(&gb, mb, block);\n\n            }\n\n            if (mb->pos >= 64 && mb->pos < 127)\n\n                av_log(avctx, AV_LOG_ERROR, \"AC EOB marker is absent pos=%d\\n\", mb->pos);\n\n            block += 64;\n\n            mb++;\n\n        }\n\n    }\n\n\n\n    /* compute idct and place blocks */\n\n    block = &sblock[0][0];\n\n    mb    = mb_data;\n\n    for (mb_index = 0; mb_index < 5; mb_index++) {\n\n        dv_calculate_mb_xy(s, work_chunk, mb_index, &mb_x, &mb_y);\n\n\n\n        /* idct_put'ting luminance */\n\n        if ((s->sys->pix_fmt == PIX_FMT_YUV420P) ||\n\n            (s->sys->pix_fmt == PIX_FMT_YUV411P && mb_x >= (704 / 8)) ||\n\n            (s->sys->height >= 720 && mb_y != 134)) {\n\n            y_stride = (s->picture.linesize[0] << ((!is_field_mode[mb_index]) * log2_blocksize));\n\n        } else {\n\n            y_stride = (2 << log2_blocksize);\n\n        }\n\n        y_ptr = s->picture.data[0] + ((mb_y * s->picture.linesize[0] + mb_x) << log2_blocksize);\n\n        linesize = s->picture.linesize[0] << is_field_mode[mb_index];\n\n        mb[0]    .idct_put(y_ptr                                   , linesize, block + 0*64);\n\n        if (s->sys->video_stype == 4) { /* SD 422 */\n\n            mb[2].idct_put(y_ptr + (1 << log2_blocksize)           , linesize, block + 2*64);\n\n        } else {\n\n            mb[1].idct_put(y_ptr + (1 << log2_blocksize)           , linesize, block + 1*64);\n\n            mb[2].idct_put(y_ptr                         + y_stride, linesize, block + 2*64);\n\n            mb[3].idct_put(y_ptr + (1 << log2_blocksize) + y_stride, linesize, block + 3*64);\n\n        }\n\n        mb += 4;\n\n        block += 4*64;\n\n\n\n        /* idct_put'ting chrominance */\n\n        c_offset = (((mb_y >>  (s->sys->pix_fmt == PIX_FMT_YUV420P)) * s->picture.linesize[1] +\n\n                     (mb_x >> ((s->sys->pix_fmt == PIX_FMT_YUV411P) ? 2 : 1))) << log2_blocksize);\n\n        for (j = 2; j; j--) {\n\n            uint8_t *c_ptr = s->picture.data[j] + c_offset;\n\n            if (s->sys->pix_fmt == PIX_FMT_YUV411P && mb_x >= (704 / 8)) {\n\n                  uint64_t aligned_pixels[64/8];\n\n                  uint8_t *pixels = (uint8_t*)aligned_pixels;\n\n                  uint8_t *c_ptr1, *ptr1;\n\n                  int x, y;\n\n                  mb->idct_put(pixels, 8, block);\n\n                  for (y = 0; y < (1 << log2_blocksize); y++, c_ptr += s->picture.linesize[j], pixels += 8) {\n\n                      ptr1   = pixels + (1 << (log2_blocksize - 1));\n\n                      c_ptr1 = c_ptr + (s->picture.linesize[j] << log2_blocksize);\n\n                      for (x = 0; x < (1 << (log2_blocksize - 1)); x++) {\n\n                          c_ptr[x]  = pixels[x];\n\n                          c_ptr1[x] = ptr1[x];\n\n                      }\n\n                  }\n\n                  block += 64; mb++;\n\n            } else {\n\n                  y_stride = (mb_y == 134) ? (1 << log2_blocksize) :\n\n                                             s->picture.linesize[j] << ((!is_field_mode[mb_index]) * log2_blocksize);\n\n                  linesize = s->picture.linesize[j] << is_field_mode[mb_index];\n\n                  (mb++)->    idct_put(c_ptr           , linesize, block); block += 64;\n\n                  if (s->sys->bpm == 8) {\n\n                      (mb++)->idct_put(c_ptr + y_stride, linesize, block); block += 64;\n\n                  }\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 25218}
{"project": "FFmpeg", "commit_id": "073811cdd29e365498b3455ee4e0eda4b957a957", "target": 0, "func": "static int decode_syncpoint(NUTContext *nut, int64_t *ts, int64_t *back_ptr){\n\n    AVFormatContext *s= nut->avf;\n\n    ByteIOContext *bc = &s->pb;\n\n    int64_t end, tmp;\n\n    AVRational time_base;\n\n\n\n    nut->last_syncpoint_pos= url_ftell(bc)-8;\n\n\n\n    end= get_packetheader(nut, bc, 1);\n\n    end += url_ftell(bc);\n\n\n\n    tmp= get_v(bc);\n\n    *back_ptr= nut->last_syncpoint_pos - 16*get_v(bc);\n\n    if(*back_ptr < 0)\n\n        return -1;\n\n\n\n    ff_nut_reset_ts(nut, nut->time_base[tmp % nut->time_base_count], tmp);\n\n\n\n    if(skip_reserved(bc, end) || get_checksum(bc)){\n\n        av_log(s, AV_LOG_ERROR, \"sync point checksum mismatch\\n\");\n\n        return -1;\n\n    }\n\n\n\n    *ts= tmp / s->nb_streams * av_q2d(nut->time_base[tmp % s->nb_streams])*AV_TIME_BASE;\n\n    add_sp(nut, nut->last_syncpoint_pos, *back_ptr, *ts);\n\n\n\n    return 0;\n\n}\n", "idx": 25227}
{"project": "FFmpeg", "commit_id": "6950cca97fed890ec56259a2f868f37b65513d92", "target": 0, "func": "int av_image_fill_linesizes(int linesizes[4], enum PixelFormat pix_fmt, int width)\n\n{\n\n    int i;\n\n    const AVPixFmtDescriptor *desc = &av_pix_fmt_descriptors[pix_fmt];\n\n    int max_step     [4];       /* max pixel step for each plane */\n\n    int max_step_comp[4];       /* the component for each plane which has the max pixel step */\n\n\n\n    memset(linesizes, 0, 4*sizeof(linesizes[0]));\n\n\n\n    if (desc->flags & PIX_FMT_HWACCEL)\n\n        return AVERROR(EINVAL);\n\n\n\n    if (desc->flags & PIX_FMT_BITSTREAM) {\n\n        linesizes[0] = (width * (desc->comp[0].step_minus1+1) + 7) >> 3;\n\n        return 0;\n\n    }\n\n\n\n    av_image_fill_max_pixsteps(max_step, max_step_comp, desc);\n\n    for (i = 0; i < 4; i++) {\n\n        int s = (max_step_comp[i] == 1 || max_step_comp[i] == 2) ? desc->log2_chroma_w : 0;\n\n        linesizes[i] = max_step[i] * (((width + (1 << s) - 1)) >> s);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25228}
{"project": "FFmpeg", "commit_id": "6369ba3c9cc74becfaad2a8882dff3dd3e7ae3c0", "target": 0, "func": "av_cold void ff_vorbisdsp_init_x86(VorbisDSPContext *dsp)\n\n{\n\n#if HAVE_YASM\n\n    int cpu_flags = av_get_cpu_flags();\n\n\n\n#if ARCH_X86_32\n\n    if (cpu_flags & AV_CPU_FLAG_3DNOW)\n\n        dsp->vorbis_inverse_coupling = ff_vorbis_inverse_coupling_3dnow;\n\n#endif /* ARCH_X86_32 */\n\n    if (cpu_flags & AV_CPU_FLAG_SSE)\n\n        dsp->vorbis_inverse_coupling = ff_vorbis_inverse_coupling_sse;\n\n#endif /* HAVE_YASM */\n\n}\n", "idx": 25239}
{"project": "FFmpeg", "commit_id": "398f015f077c6a2406deffd9e37ff34b9c7bb3bc", "target": 0, "func": "static void output_packet(AVFormatContext *s, AVPacket *pkt, OutputStream *ost)\n\n{\n\n    int ret = 0;\n\n\n\n    /* apply the output bitstream filters, if any */\n\n    if (ost->nb_bitstream_filters) {\n\n        int idx;\n\n\n\n        ret = av_bsf_send_packet(ost->bsf_ctx[0], pkt);\n\n        if (ret < 0)\n\n            goto finish;\n\n\n\n        idx = 1;\n\n        while (idx) {\n\n            /* get a packet from the previous filter up the chain */\n\n            ret = av_bsf_receive_packet(ost->bsf_ctx[idx - 1], pkt);\n\n            if (ret == AVERROR(EAGAIN)) {\n\n                ret = 0;\n\n                idx--;\n\n                continue;\n\n            } else if (ret < 0)\n\n                goto finish;\n\n\n\n            /* send it to the next filter down the chain or to the muxer */\n\n            if (idx < ost->nb_bitstream_filters) {\n\n                ret = av_bsf_send_packet(ost->bsf_ctx[idx], pkt);\n\n                if (ret < 0)\n\n                    goto finish;\n\n                idx++;\n\n            } else\n\n                write_packet(s, pkt, ost);\n\n        }\n\n    } else\n\n        write_packet(s, pkt, ost);\n\n\n\nfinish:\n\n    if (ret < 0 && ret != AVERROR_EOF) {\n\n        av_log(NULL, AV_LOG_FATAL, \"Error applying bitstream filters to an output \"\n\n               \"packet for stream #%d:%d.\\n\", ost->file_index, ost->index);\n\n        exit_program(1);\n\n    }\n\n}\n", "idx": 25240}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "static void pred_temp_direct_motion(const H264Context *const h, H264SliceContext *sl,\n\n                                    int *mb_type)\n\n{\n\n    int b8_stride = 2;\n\n    int b4_stride = h->b_stride;\n\n    int mb_xy = sl->mb_xy, mb_y = sl->mb_y;\n\n    int mb_type_col[2];\n\n    const int16_t (*l1mv0)[2], (*l1mv1)[2];\n\n    const int8_t *l1ref0, *l1ref1;\n\n    const int is_b8x8 = IS_8X8(*mb_type);\n\n    unsigned int sub_mb_type;\n\n    int i8, i4;\n\n\n\n    assert(sl->ref_list[1][0].reference & 3);\n\n\n\n    await_reference_mb_row(h, sl->ref_list[1][0].parent,\n\n                           sl->mb_y + !!IS_INTERLACED(*mb_type));\n\n\n\n    if (IS_INTERLACED(sl->ref_list[1][0].parent->mb_type[mb_xy])) { // AFL/AFR/FR/FL -> AFL/FL\n\n        if (!IS_INTERLACED(*mb_type)) {                    //     AFR/FR    -> AFL/FL\n\n            mb_y  = (sl->mb_y & ~1) + sl->col_parity;\n\n            mb_xy = sl->mb_x +\n\n                    ((sl->mb_y & ~1) + sl->col_parity) * h->mb_stride;\n\n            b8_stride = 0;\n\n        } else {\n\n            mb_y  += sl->col_fieldoff;\n\n            mb_xy += h->mb_stride * sl->col_fieldoff; // non-zero for FL -> FL & differ parity\n\n        }\n\n        goto single_col;\n\n    } else {                                        // AFL/AFR/FR/FL -> AFR/FR\n\n        if (IS_INTERLACED(*mb_type)) {              // AFL       /FL -> AFR/FR\n\n            mb_y           = sl->mb_y & ~1;\n\n            mb_xy          = sl->mb_x + (sl->mb_y & ~1) * h->mb_stride;\n\n            mb_type_col[0] = sl->ref_list[1][0].parent->mb_type[mb_xy];\n\n            mb_type_col[1] = sl->ref_list[1][0].parent->mb_type[mb_xy + h->mb_stride];\n\n            b8_stride      = 2 + 4 * h->mb_stride;\n\n            b4_stride     *= 6;\n\n            if (IS_INTERLACED(mb_type_col[0]) !=\n\n                IS_INTERLACED(mb_type_col[1])) {\n\n                mb_type_col[0] &= ~MB_TYPE_INTERLACED;\n\n                mb_type_col[1] &= ~MB_TYPE_INTERLACED;\n\n            }\n\n\n\n            sub_mb_type = MB_TYPE_16x16 | MB_TYPE_P0L0 | MB_TYPE_P0L1 |\n\n                          MB_TYPE_DIRECT2;                  /* B_SUB_8x8 */\n\n\n\n            if ((mb_type_col[0] & MB_TYPE_16x16_OR_INTRA) &&\n\n                (mb_type_col[1] & MB_TYPE_16x16_OR_INTRA) &&\n\n                !is_b8x8) {\n\n                *mb_type |= MB_TYPE_16x8 | MB_TYPE_L0L1 |\n\n                            MB_TYPE_DIRECT2;                /* B_16x8 */\n\n            } else {\n\n                *mb_type |= MB_TYPE_8x8 | MB_TYPE_L0L1;\n\n            }\n\n        } else {                                    //     AFR/FR    -> AFR/FR\n\nsingle_col:\n\n            mb_type_col[0]     =\n\n                mb_type_col[1] = sl->ref_list[1][0].parent->mb_type[mb_xy];\n\n\n\n            sub_mb_type = MB_TYPE_16x16 | MB_TYPE_P0L0 | MB_TYPE_P0L1 |\n\n                          MB_TYPE_DIRECT2;                  /* B_SUB_8x8 */\n\n            if (!is_b8x8 && (mb_type_col[0] & MB_TYPE_16x16_OR_INTRA)) {\n\n                *mb_type |= MB_TYPE_16x16 | MB_TYPE_P0L0 | MB_TYPE_P0L1 |\n\n                            MB_TYPE_DIRECT2;                /* B_16x16 */\n\n            } else if (!is_b8x8 &&\n\n                       (mb_type_col[0] & (MB_TYPE_16x8 | MB_TYPE_8x16))) {\n\n                *mb_type |= MB_TYPE_L0L1 | MB_TYPE_DIRECT2 |\n\n                            (mb_type_col[0] & (MB_TYPE_16x8 | MB_TYPE_8x16));\n\n            } else {\n\n                if (!h->sps.direct_8x8_inference_flag) {\n\n                    /* FIXME: save sub mb types from previous frames (or derive\n\n                     * from MVs) so we know exactly what block size to use */\n\n                    sub_mb_type = MB_TYPE_8x8 | MB_TYPE_P0L0 | MB_TYPE_P0L1 |\n\n                                  MB_TYPE_DIRECT2;          /* B_SUB_4x4 */\n\n                }\n\n                *mb_type |= MB_TYPE_8x8 | MB_TYPE_L0L1;\n\n            }\n\n        }\n\n    }\n\n\n\n    await_reference_mb_row(h, sl->ref_list[1][0].parent, mb_y);\n\n\n\n    l1mv0  = &sl->ref_list[1][0].parent->motion_val[0][h->mb2b_xy[mb_xy]];\n\n    l1mv1  = &sl->ref_list[1][0].parent->motion_val[1][h->mb2b_xy[mb_xy]];\n\n    l1ref0 = &sl->ref_list[1][0].parent->ref_index[0][4 * mb_xy];\n\n    l1ref1 = &sl->ref_list[1][0].parent->ref_index[1][4 * mb_xy];\n\n    if (!b8_stride) {\n\n        if (sl->mb_y & 1) {\n\n            l1ref0 += 2;\n\n            l1ref1 += 2;\n\n            l1mv0  += 2 * b4_stride;\n\n            l1mv1  += 2 * b4_stride;\n\n        }\n\n    }\n\n\n\n    {\n\n        const int *map_col_to_list0[2] = { sl->map_col_to_list0[0],\n\n                                           sl->map_col_to_list0[1] };\n\n        const int *dist_scale_factor = sl->dist_scale_factor;\n\n        int ref_offset;\n\n\n\n        if (FRAME_MBAFF(h) && IS_INTERLACED(*mb_type)) {\n\n            map_col_to_list0[0] = sl->map_col_to_list0_field[sl->mb_y & 1][0];\n\n            map_col_to_list0[1] = sl->map_col_to_list0_field[sl->mb_y & 1][1];\n\n            dist_scale_factor   = sl->dist_scale_factor_field[sl->mb_y & 1];\n\n        }\n\n        ref_offset = (sl->ref_list[1][0].parent->mbaff << 4) & (mb_type_col[0] >> 3);\n\n\n\n        if (IS_INTERLACED(*mb_type) != IS_INTERLACED(mb_type_col[0])) {\n\n            int y_shift = 2 * !IS_INTERLACED(*mb_type);\n\n            assert(h->sps.direct_8x8_inference_flag);\n\n\n\n            for (i8 = 0; i8 < 4; i8++) {\n\n                const int x8 = i8 & 1;\n\n                const int y8 = i8 >> 1;\n\n                int ref0, scale;\n\n                const int16_t (*l1mv)[2] = l1mv0;\n\n\n\n                if (is_b8x8 && !IS_DIRECT(sl->sub_mb_type[i8]))\n\n                    continue;\n\n                sl->sub_mb_type[i8] = sub_mb_type;\n\n\n\n                fill_rectangle(&sl->ref_cache[1][scan8[i8 * 4]], 2, 2, 8, 0, 1);\n\n                if (IS_INTRA(mb_type_col[y8])) {\n\n                    fill_rectangle(&sl->ref_cache[0][scan8[i8 * 4]], 2, 2, 8, 0, 1);\n\n                    fill_rectangle(&sl->mv_cache[0][scan8[i8 * 4]], 2, 2, 8, 0, 4);\n\n                    fill_rectangle(&sl->mv_cache[1][scan8[i8 * 4]], 2, 2, 8, 0, 4);\n\n                    continue;\n\n                }\n\n\n\n                ref0 = l1ref0[x8 + y8 * b8_stride];\n\n                if (ref0 >= 0)\n\n                    ref0 = map_col_to_list0[0][ref0 + ref_offset];\n\n                else {\n\n                    ref0 = map_col_to_list0[1][l1ref1[x8 + y8 * b8_stride] +\n\n                                               ref_offset];\n\n                    l1mv = l1mv1;\n\n                }\n\n                scale = dist_scale_factor[ref0];\n\n                fill_rectangle(&sl->ref_cache[0][scan8[i8 * 4]], 2, 2, 8,\n\n                               ref0, 1);\n\n\n\n                {\n\n                    const int16_t *mv_col = l1mv[x8 * 3 + y8 * b4_stride];\n\n                    int my_col            = (mv_col[1] << y_shift) / 2;\n\n                    int mx                = (scale * mv_col[0] + 128) >> 8;\n\n                    int my                = (scale * my_col    + 128) >> 8;\n\n                    fill_rectangle(&sl->mv_cache[0][scan8[i8 * 4]], 2, 2, 8,\n\n                                   pack16to32(mx, my), 4);\n\n                    fill_rectangle(&sl->mv_cache[1][scan8[i8 * 4]], 2, 2, 8,\n\n                                   pack16to32(mx - mv_col[0], my - my_col), 4);\n\n                }\n\n            }\n\n            return;\n\n        }\n\n\n\n        /* one-to-one mv scaling */\n\n\n\n        if (IS_16X16(*mb_type)) {\n\n            int ref, mv0, mv1;\n\n\n\n            fill_rectangle(&sl->ref_cache[1][scan8[0]], 4, 4, 8, 0, 1);\n\n            if (IS_INTRA(mb_type_col[0])) {\n\n                ref = mv0 = mv1 = 0;\n\n            } else {\n\n                const int ref0 = l1ref0[0] >= 0 ? map_col_to_list0[0][l1ref0[0] + ref_offset]\n\n                                                : map_col_to_list0[1][l1ref1[0] + ref_offset];\n\n                const int scale = dist_scale_factor[ref0];\n\n                const int16_t *mv_col = l1ref0[0] >= 0 ? l1mv0[0] : l1mv1[0];\n\n                int mv_l0[2];\n\n                mv_l0[0] = (scale * mv_col[0] + 128) >> 8;\n\n                mv_l0[1] = (scale * mv_col[1] + 128) >> 8;\n\n                ref      = ref0;\n\n                mv0      = pack16to32(mv_l0[0], mv_l0[1]);\n\n                mv1      = pack16to32(mv_l0[0] - mv_col[0], mv_l0[1] - mv_col[1]);\n\n            }\n\n            fill_rectangle(&sl->ref_cache[0][scan8[0]], 4, 4, 8, ref, 1);\n\n            fill_rectangle(&sl->mv_cache[0][scan8[0]], 4, 4, 8, mv0, 4);\n\n            fill_rectangle(&sl->mv_cache[1][scan8[0]], 4, 4, 8, mv1, 4);\n\n        } else {\n\n            for (i8 = 0; i8 < 4; i8++) {\n\n                const int x8 = i8 & 1;\n\n                const int y8 = i8 >> 1;\n\n                int ref0, scale;\n\n                const int16_t (*l1mv)[2] = l1mv0;\n\n\n\n                if (is_b8x8 && !IS_DIRECT(sl->sub_mb_type[i8]))\n\n                    continue;\n\n                sl->sub_mb_type[i8] = sub_mb_type;\n\n                fill_rectangle(&sl->ref_cache[1][scan8[i8 * 4]], 2, 2, 8, 0, 1);\n\n                if (IS_INTRA(mb_type_col[0])) {\n\n                    fill_rectangle(&sl->ref_cache[0][scan8[i8 * 4]], 2, 2, 8, 0, 1);\n\n                    fill_rectangle(&sl->mv_cache[0][scan8[i8 * 4]], 2, 2, 8, 0, 4);\n\n                    fill_rectangle(&sl->mv_cache[1][scan8[i8 * 4]], 2, 2, 8, 0, 4);\n\n                    continue;\n\n                }\n\n\n\n                assert(b8_stride == 2);\n\n                ref0 = l1ref0[i8];\n\n                if (ref0 >= 0)\n\n                    ref0 = map_col_to_list0[0][ref0 + ref_offset];\n\n                else {\n\n                    ref0 = map_col_to_list0[1][l1ref1[i8] + ref_offset];\n\n                    l1mv = l1mv1;\n\n                }\n\n                scale = dist_scale_factor[ref0];\n\n\n\n                fill_rectangle(&sl->ref_cache[0][scan8[i8 * 4]], 2, 2, 8,\n\n                               ref0, 1);\n\n                if (IS_SUB_8X8(sub_mb_type)) {\n\n                    const int16_t *mv_col = l1mv[x8 * 3 + y8 * 3 * b4_stride];\n\n                    int mx                = (scale * mv_col[0] + 128) >> 8;\n\n                    int my                = (scale * mv_col[1] + 128) >> 8;\n\n                    fill_rectangle(&sl->mv_cache[0][scan8[i8 * 4]], 2, 2, 8,\n\n                                   pack16to32(mx, my), 4);\n\n                    fill_rectangle(&sl->mv_cache[1][scan8[i8 * 4]], 2, 2, 8,\n\n                                   pack16to32(mx - mv_col[0], my - mv_col[1]), 4);\n\n                } else {\n\n                    for (i4 = 0; i4 < 4; i4++) {\n\n                        const int16_t *mv_col = l1mv[x8 * 2 + (i4 & 1) +\n\n                                                     (y8 * 2 + (i4 >> 1)) * b4_stride];\n\n                        int16_t *mv_l0 = sl->mv_cache[0][scan8[i8 * 4 + i4]];\n\n                        mv_l0[0] = (scale * mv_col[0] + 128) >> 8;\n\n                        mv_l0[1] = (scale * mv_col[1] + 128) >> 8;\n\n                        AV_WN32A(sl->mv_cache[1][scan8[i8 * 4 + i4]],\n\n                                 pack16to32(mv_l0[0] - mv_col[0],\n\n                                            mv_l0[1] - mv_col[1]));\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 25241}
{"project": "FFmpeg", "commit_id": "5a667322f5cb0e77c15891fc06725c19d8f3314f", "target": 0, "func": "static int vaapi_vc1_start_frame(AVCodecContext *avctx, av_unused const uint8_t *buffer, av_unused uint32_t size)\n\n{\n\n    const VC1Context *v = avctx->priv_data;\n\n    const MpegEncContext *s = &v->s;\n\n    struct vaapi_context * const vactx = avctx->hwaccel_context;\n\n    VAPictureParameterBufferVC1 *pic_param;\n\n\n\n    vactx->slice_param_size = sizeof(VASliceParameterBufferVC1);\n\n\n\n    /* Fill in VAPictureParameterBufferVC1 */\n\n    pic_param = ff_vaapi_alloc_pic_param(vactx, sizeof(VAPictureParameterBufferVC1));\n\n    if (!pic_param)\n\n        return -1;\n\n    pic_param->forward_reference_picture                            = VA_INVALID_ID;\n\n    pic_param->backward_reference_picture                           = VA_INVALID_ID;\n\n    pic_param->inloop_decoded_picture                               = VA_INVALID_ID;\n\n    pic_param->sequence_fields.value                                = 0; /* reset all bits */\n\n    pic_param->sequence_fields.bits.pulldown                        = v->broadcast;\n\n    pic_param->sequence_fields.bits.interlace                       = v->interlace;\n\n    pic_param->sequence_fields.bits.tfcntrflag                      = v->tfcntrflag;\n\n    pic_param->sequence_fields.bits.finterpflag                     = v->finterpflag;\n\n    pic_param->sequence_fields.bits.psf                             = v->psf;\n\n    pic_param->sequence_fields.bits.multires                        = v->multires;\n\n    pic_param->sequence_fields.bits.overlap                         = v->overlap;\n\n    pic_param->sequence_fields.bits.syncmarker                      = v->resync_marker;\n\n    pic_param->sequence_fields.bits.rangered                        = v->rangered;\n\n    pic_param->sequence_fields.bits.max_b_frames                    = s->avctx->max_b_frames;\n\n#if VA_CHECK_VERSION(0,32,0)\n\n    pic_param->sequence_fields.bits.profile                         = v->profile;\n\n#endif\n\n    pic_param->coded_width                                          = s->avctx->coded_width;\n\n    pic_param->coded_height                                         = s->avctx->coded_height;\n\n    pic_param->entrypoint_fields.value                              = 0; /* reset all bits */\n\n    pic_param->entrypoint_fields.bits.broken_link                   = v->broken_link;\n\n    pic_param->entrypoint_fields.bits.closed_entry                  = v->closed_entry;\n\n    pic_param->entrypoint_fields.bits.panscan_flag                  = v->panscanflag;\n\n    pic_param->entrypoint_fields.bits.loopfilter                    = s->loop_filter;\n\n    pic_param->conditional_overlap_flag                             = v->condover;\n\n    pic_param->fast_uvmc_flag                                       = v->fastuvmc;\n\n    pic_param->range_mapping_fields.value                           = 0; /* reset all bits */\n\n    pic_param->range_mapping_fields.bits.luma_flag                  = v->range_mapy_flag;\n\n    pic_param->range_mapping_fields.bits.luma                       = v->range_mapy;\n\n    pic_param->range_mapping_fields.bits.chroma_flag                = v->range_mapuv_flag;\n\n    pic_param->range_mapping_fields.bits.chroma                     = v->range_mapuv;\n\n    pic_param->b_picture_fraction                                   = v->bfraction_lut_index;\n\n    pic_param->cbp_table                                            = v->cbpcy_vlc ? v->cbpcy_vlc - ff_vc1_cbpcy_p_vlc : 0;\n\n    pic_param->mb_mode_table                                        = 0; /* XXX: interlaced frame */\n\n    pic_param->range_reduction_frame                                = v->rangeredfrm;\n\n    pic_param->rounding_control                                     = v->rnd;\n\n    pic_param->post_processing                                      = v->postproc;\n\n    pic_param->picture_resolution_index                             = v->respic;\n\n    pic_param->luma_scale                                           = v->lumscale;\n\n    pic_param->luma_shift                                           = v->lumshift;\n\n    pic_param->picture_fields.value                                 = 0; /* reset all bits */\n\n    pic_param->picture_fields.bits.picture_type                     = vc1_get_PTYPE(v);\n\n    pic_param->picture_fields.bits.frame_coding_mode                = v->fcm;\n\n    pic_param->picture_fields.bits.top_field_first                  = v->tff;\n\n    pic_param->picture_fields.bits.is_first_field                   = v->fcm == 0; /* XXX: interlaced frame */\n\n    pic_param->picture_fields.bits.intensity_compensation           = v->mv_mode == MV_PMODE_INTENSITY_COMP;\n\n    pic_param->raw_coding.value                                     = 0; /* reset all bits */\n\n    pic_param->raw_coding.flags.mv_type_mb                          = v->mv_type_is_raw;\n\n    pic_param->raw_coding.flags.direct_mb                           = v->dmb_is_raw;\n\n    pic_param->raw_coding.flags.skip_mb                             = v->skip_is_raw;\n\n    pic_param->raw_coding.flags.field_tx                            = 0; /* XXX: interlaced frame */\n\n    pic_param->raw_coding.flags.forward_mb                          = 0; /* XXX: interlaced frame */\n\n    pic_param->raw_coding.flags.ac_pred                             = v->acpred_is_raw;\n\n    pic_param->raw_coding.flags.overflags                           = v->overflg_is_raw;\n\n    pic_param->bitplane_present.value                               = 0; /* reset all bits */\n\n    pic_param->bitplane_present.flags.bp_mv_type_mb                 = vc1_has_MVTYPEMB_bitplane(v);\n\n    pic_param->bitplane_present.flags.bp_direct_mb                  = vc1_has_DIRECTMB_bitplane(v);\n\n    pic_param->bitplane_present.flags.bp_skip_mb                    = vc1_has_SKIPMB_bitplane(v);\n\n    pic_param->bitplane_present.flags.bp_field_tx                   = 0; /* XXX: interlaced frame */\n\n    pic_param->bitplane_present.flags.bp_forward_mb                 = 0; /* XXX: interlaced frame */\n\n    pic_param->bitplane_present.flags.bp_ac_pred                    = vc1_has_ACPRED_bitplane(v);\n\n    pic_param->bitplane_present.flags.bp_overflags                  = vc1_has_OVERFLAGS_bitplane(v);\n\n    pic_param->reference_fields.value                               = 0; /* reset all bits */\n\n    pic_param->reference_fields.bits.reference_distance_flag        = v->refdist_flag;\n\n    pic_param->reference_fields.bits.reference_distance             = 0; /* XXX: interlaced frame */\n\n    pic_param->reference_fields.bits.num_reference_pictures         = 0; /* XXX: interlaced frame */\n\n    pic_param->reference_fields.bits.reference_field_pic_indicator  = 0; /* XXX: interlaced frame */\n\n    pic_param->mv_fields.value                                      = 0; /* reset all bits */\n\n    pic_param->mv_fields.bits.mv_mode                               = vc1_get_MVMODE(v);\n\n    pic_param->mv_fields.bits.mv_mode2                              = vc1_get_MVMODE2(v);\n\n    pic_param->mv_fields.bits.mv_table                              = s->mv_table_index;\n\n    pic_param->mv_fields.bits.two_mv_block_pattern_table            = 0; /* XXX: interlaced frame */\n\n    pic_param->mv_fields.bits.four_mv_switch                        = 0; /* XXX: interlaced frame */\n\n    pic_param->mv_fields.bits.four_mv_block_pattern_table           = 0; /* XXX: interlaced frame */\n\n    pic_param->mv_fields.bits.extended_mv_flag                      = v->extended_mv;\n\n    pic_param->mv_fields.bits.extended_mv_range                     = v->mvrange;\n\n    pic_param->mv_fields.bits.extended_dmv_flag                     = v->extended_dmv;\n\n    pic_param->mv_fields.bits.extended_dmv_range                    = 0; /* XXX: interlaced frame */\n\n    pic_param->pic_quantizer_fields.value                           = 0; /* reset all bits */\n\n    pic_param->pic_quantizer_fields.bits.dquant                     = v->dquant;\n\n    pic_param->pic_quantizer_fields.bits.quantizer                  = v->quantizer_mode;\n\n    pic_param->pic_quantizer_fields.bits.half_qp                    = v->halfpq;\n\n    pic_param->pic_quantizer_fields.bits.pic_quantizer_scale        = v->pq;\n\n    pic_param->pic_quantizer_fields.bits.pic_quantizer_type         = v->pquantizer;\n\n    pic_param->pic_quantizer_fields.bits.dq_frame                   = v->dquantfrm;\n\n    pic_param->pic_quantizer_fields.bits.dq_profile                 = v->dqprofile;\n\n    pic_param->pic_quantizer_fields.bits.dq_sb_edge                 = v->dqprofile == DQPROFILE_SINGLE_EDGE  ? v->dqsbedge : 0;\n\n    pic_param->pic_quantizer_fields.bits.dq_db_edge                 = v->dqprofile == DQPROFILE_DOUBLE_EDGES ? v->dqsbedge : 0;\n\n    pic_param->pic_quantizer_fields.bits.dq_binary_level            = v->dqbilevel;\n\n    pic_param->pic_quantizer_fields.bits.alt_pic_quantizer          = v->altpq;\n\n    pic_param->transform_fields.value                               = 0; /* reset all bits */\n\n    pic_param->transform_fields.bits.variable_sized_transform_flag  = v->vstransform;\n\n    pic_param->transform_fields.bits.mb_level_transform_type_flag   = v->ttmbf;\n\n    pic_param->transform_fields.bits.frame_level_transform_type     = vc1_get_TTFRM(v);\n\n    pic_param->transform_fields.bits.transform_ac_codingset_idx1    = v->c_ac_table_index;\n\n    pic_param->transform_fields.bits.transform_ac_codingset_idx2    = v->y_ac_table_index;\n\n    pic_param->transform_fields.bits.intra_transform_dc_table       = v->s.dc_table_index;\n\n\n\n    switch (s->pict_type) {\n\n    case AV_PICTURE_TYPE_B:\n\n        pic_param->backward_reference_picture = ff_vaapi_get_surface_id(s->next_picture.f);\n\n        // fall-through\n\n    case AV_PICTURE_TYPE_P:\n\n        pic_param->forward_reference_picture = ff_vaapi_get_surface_id(s->last_picture.f);\n\n        break;\n\n    }\n\n\n\n    if (pic_param->bitplane_present.value) {\n\n        uint8_t *bitplane;\n\n        const uint8_t *ff_bp[3];\n\n        int x, y, n;\n\n\n\n        switch (s->pict_type) {\n\n        case AV_PICTURE_TYPE_P:\n\n            ff_bp[0] = pic_param->bitplane_present.flags.bp_direct_mb  ? v->direct_mb_plane    : NULL;\n\n            ff_bp[1] = pic_param->bitplane_present.flags.bp_skip_mb    ? s->mbskip_table       : NULL;\n\n            ff_bp[2] = pic_param->bitplane_present.flags.bp_mv_type_mb ? v->mv_type_mb_plane   : NULL;\n\n            break;\n\n        case AV_PICTURE_TYPE_B:\n\n            if (!v->bi_type) {\n\n                ff_bp[0] = pic_param->bitplane_present.flags.bp_direct_mb ? v->direct_mb_plane : NULL;\n\n                ff_bp[1] = pic_param->bitplane_present.flags.bp_skip_mb   ? s->mbskip_table    : NULL;\n\n                ff_bp[2] = NULL; /* XXX: interlaced frame (FORWARD plane) */\n\n                break;\n\n            }\n\n            /* fall-through (BI-type) */\n\n        case AV_PICTURE_TYPE_I:\n\n            ff_bp[0] = NULL; /* XXX: interlaced frame (FIELDTX plane) */\n\n            ff_bp[1] = pic_param->bitplane_present.flags.bp_ac_pred    ? v->acpred_plane       : NULL;\n\n            ff_bp[2] = pic_param->bitplane_present.flags.bp_overflags  ? v->over_flags_plane   : NULL;\n\n            break;\n\n        default:\n\n            ff_bp[0] = NULL;\n\n            ff_bp[1] = NULL;\n\n            ff_bp[2] = NULL;\n\n            break;\n\n        }\n\n\n\n        bitplane = ff_vaapi_alloc_bitplane(vactx, (s->mb_width * s->mb_height + 1) / 2);\n\n        if (!bitplane)\n\n            return -1;\n\n\n\n        n = 0;\n\n        for (y = 0; y < s->mb_height; y++)\n\n            for (x = 0; x < s->mb_width; x++, n++)\n\n                vc1_pack_bitplanes(bitplane, n, ff_bp, x, y, s->mb_stride);\n\n        if (n & 1) /* move last nibble to the high order */\n\n            bitplane[n/2] <<= 4;\n\n    }\n\n    return 0;\n\n}\n", "idx": 25242}
{"project": "FFmpeg", "commit_id": "68f593b48433842f3407586679fe07f3e5199ab9", "target": 0, "func": "static int read_huffman_tables(HYuvContext *s, uint8_t *src, int length){\n\n    GetBitContext gb;\n\n    int i;\n\n    \n\n    init_get_bits(&gb, src, length);\n\n    \n\n    for(i=0; i<3; i++){\n\n        read_len_table(s->len[i], &gb);\n\n        \n\n        if(generate_bits_table(s->bits[i], s->len[i])<0){\n\n            return -1;\n\n        }\n\n#if 0\n\nfor(j=0; j<256; j++){\n\nprintf(\"%6X, %2d,  %3d\\n\", s->bits[i][j], s->len[i][j], j);\n\n}\n\n#endif\n\n        init_vlc(&s->vlc[i], VLC_BITS, 256, s->len[i], 1, 1, s->bits[i], 4, 4);\n\n    }\n\n    \n\n    return 0;\n\n}\n", "idx": 25243}
{"project": "FFmpeg", "commit_id": "04763c6f87690b31cfcd0d324cf36a451531dcd0", "target": 1, "func": "static void pred_spatial_direct_motion(const H264Context *const h, H264SliceContext *sl,\n\n                                       int *mb_type)\n\n{\n\n    int b8_stride = 2;\n\n    int b4_stride = h->b_stride;\n\n    int mb_xy = sl->mb_xy, mb_y = sl->mb_y;\n\n    int mb_type_col[2];\n\n    const int16_t (*l1mv0)[2], (*l1mv1)[2];\n\n    const int8_t *l1ref0, *l1ref1;\n\n    const int is_b8x8 = IS_8X8(*mb_type);\n\n    unsigned int sub_mb_type = MB_TYPE_L0L1;\n\n    int i8, i4;\n\n    int ref[2];\n\n    int mv[2];\n\n    int list;\n\n\n\n    assert(sl->ref_list[1][0].reference & 3);\n\n\n\n    await_reference_mb_row(h, sl->ref_list[1][0].parent,\n\n                           sl->mb_y + !!IS_INTERLACED(*mb_type));\n\n\n\n#define MB_TYPE_16x16_OR_INTRA (MB_TYPE_16x16 | MB_TYPE_INTRA4x4 | \\\n\n                                MB_TYPE_INTRA16x16 | MB_TYPE_INTRA_PCM)\n\n\n\n    /* ref = min(neighbors) */\n\n    for (list = 0; list < 2; list++) {\n\n        int left_ref     = sl->ref_cache[list][scan8[0] - 1];\n\n        int top_ref      = sl->ref_cache[list][scan8[0] - 8];\n\n        int refc         = sl->ref_cache[list][scan8[0] - 8 + 4];\n\n        const int16_t *C = sl->mv_cache[list][scan8[0]  - 8 + 4];\n\n        if (refc == PART_NOT_AVAILABLE) {\n\n            refc = sl->ref_cache[list][scan8[0] - 8 - 1];\n\n            C    = sl->mv_cache[list][scan8[0]  - 8 - 1];\n\n        }\n\n        ref[list] = FFMIN3((unsigned)left_ref,\n\n                           (unsigned)top_ref,\n\n                           (unsigned)refc);\n\n        if (ref[list] >= 0) {\n\n            /* This is just pred_motion() but with the cases removed that\n\n             * cannot happen for direct blocks. */\n\n            const int16_t *const A = sl->mv_cache[list][scan8[0] - 1];\n\n            const int16_t *const B = sl->mv_cache[list][scan8[0] - 8];\n\n\n\n            int match_count = (left_ref == ref[list]) +\n\n                              (top_ref  == ref[list]) +\n\n                              (refc     == ref[list]);\n\n\n\n            if (match_count > 1) { // most common\n\n                mv[list] = pack16to32(mid_pred(A[0], B[0], C[0]),\n\n                                      mid_pred(A[1], B[1], C[1]));\n\n            } else {\n\n                assert(match_count == 1);\n\n                if (left_ref == ref[list])\n\n                    mv[list] = AV_RN32A(A);\n\n                else if (top_ref == ref[list])\n\n                    mv[list] = AV_RN32A(B);\n\n                else\n\n                    mv[list] = AV_RN32A(C);\n\n            }\n\n        } else {\n\n            int mask = ~(MB_TYPE_L0 << (2 * list));\n\n            mv[list]  = 0;\n\n            ref[list] = -1;\n\n            if (!is_b8x8)\n\n                *mb_type &= mask;\n\n            sub_mb_type &= mask;\n\n        }\n\n    }\n\n    if (ref[0] < 0 && ref[1] < 0) {\n\n        ref[0] = ref[1] = 0;\n\n        if (!is_b8x8)\n\n            *mb_type |= MB_TYPE_L0L1;\n\n        sub_mb_type |= MB_TYPE_L0L1;\n\n    }\n\n\n\n    if (!(is_b8x8 | mv[0] | mv[1])) {\n\n        fill_rectangle(&sl->ref_cache[0][scan8[0]], 4, 4, 8, (uint8_t)ref[0], 1);\n\n        fill_rectangle(&sl->ref_cache[1][scan8[0]], 4, 4, 8, (uint8_t)ref[1], 1);\n\n        fill_rectangle(&sl->mv_cache[0][scan8[0]], 4, 4, 8, 0, 4);\n\n        fill_rectangle(&sl->mv_cache[1][scan8[0]], 4, 4, 8, 0, 4);\n\n        *mb_type = (*mb_type & ~(MB_TYPE_8x8 | MB_TYPE_16x8 | MB_TYPE_8x16 |\n\n                                 MB_TYPE_P1L0 | MB_TYPE_P1L1)) |\n\n                   MB_TYPE_16x16 | MB_TYPE_DIRECT2;\n\n        return;\n\n    }\n\n\n\n    if (IS_INTERLACED(sl->ref_list[1][0].parent->mb_type[mb_xy])) { // AFL/AFR/FR/FL -> AFL/FL\n\n        if (!IS_INTERLACED(*mb_type)) {                    //     AFR/FR    -> AFL/FL\n\n            mb_y  = (sl->mb_y & ~1) + sl->col_parity;\n\n            mb_xy = sl->mb_x +\n\n                    ((sl->mb_y & ~1) + sl->col_parity) * h->mb_stride;\n\n            b8_stride = 0;\n\n        } else {\n\n            mb_y  += sl->col_fieldoff;\n\n            mb_xy += h->mb_stride * sl->col_fieldoff; // non-zero for FL -> FL & differ parity\n\n        }\n\n        goto single_col;\n\n    } else {                                             // AFL/AFR/FR/FL -> AFR/FR\n\n        if (IS_INTERLACED(*mb_type)) {                   // AFL       /FL -> AFR/FR\n\n            mb_y           =  sl->mb_y & ~1;\n\n            mb_xy          = (sl->mb_y & ~1) * h->mb_stride + sl->mb_x;\n\n            mb_type_col[0] = sl->ref_list[1][0].parent->mb_type[mb_xy];\n\n            mb_type_col[1] = sl->ref_list[1][0].parent->mb_type[mb_xy + h->mb_stride];\n\n            b8_stride      = 2 + 4 * h->mb_stride;\n\n            b4_stride     *= 6;\n\n            if (IS_INTERLACED(mb_type_col[0]) !=\n\n                IS_INTERLACED(mb_type_col[1])) {\n\n                mb_type_col[0] &= ~MB_TYPE_INTERLACED;\n\n                mb_type_col[1] &= ~MB_TYPE_INTERLACED;\n\n            }\n\n\n\n            sub_mb_type |= MB_TYPE_16x16 | MB_TYPE_DIRECT2; /* B_SUB_8x8 */\n\n            if ((mb_type_col[0] & MB_TYPE_16x16_OR_INTRA) &&\n\n                (mb_type_col[1] & MB_TYPE_16x16_OR_INTRA) &&\n\n                !is_b8x8) {\n\n                *mb_type |= MB_TYPE_16x8 | MB_TYPE_DIRECT2;  /* B_16x8 */\n\n            } else {\n\n                *mb_type |= MB_TYPE_8x8;\n\n            }\n\n        } else {                                         //     AFR/FR    -> AFR/FR\n\nsingle_col:\n\n            mb_type_col[0] =\n\n            mb_type_col[1] = sl->ref_list[1][0].parent->mb_type[mb_xy];\n\n\n\n            sub_mb_type |= MB_TYPE_16x16 | MB_TYPE_DIRECT2; /* B_SUB_8x8 */\n\n            if (!is_b8x8 && (mb_type_col[0] & MB_TYPE_16x16_OR_INTRA)) {\n\n                *mb_type |= MB_TYPE_16x16 | MB_TYPE_DIRECT2; /* B_16x16 */\n\n            } else if (!is_b8x8 &&\n\n                       (mb_type_col[0] & (MB_TYPE_16x8 | MB_TYPE_8x16))) {\n\n                *mb_type |= MB_TYPE_DIRECT2 |\n\n                            (mb_type_col[0] & (MB_TYPE_16x8 | MB_TYPE_8x16));\n\n            } else {\n\n                if (!h->ps.sps->direct_8x8_inference_flag) {\n\n                    /* FIXME: Save sub mb types from previous frames (or derive\n\n                     * from MVs) so we know exactly what block size to use. */\n\n                    sub_mb_type += (MB_TYPE_8x8 - MB_TYPE_16x16); /* B_SUB_4x4 */\n\n                }\n\n                *mb_type |= MB_TYPE_8x8;\n\n            }\n\n        }\n\n    }\n\n\n\n    await_reference_mb_row(h, sl->ref_list[1][0].parent, mb_y);\n\n\n\n    l1mv0  = &sl->ref_list[1][0].parent->motion_val[0][h->mb2b_xy[mb_xy]];\n\n    l1mv1  = &sl->ref_list[1][0].parent->motion_val[1][h->mb2b_xy[mb_xy]];\n\n    l1ref0 = &sl->ref_list[1][0].parent->ref_index[0][4 * mb_xy];\n\n    l1ref1 = &sl->ref_list[1][0].parent->ref_index[1][4 * mb_xy];\n\n    if (!b8_stride) {\n\n        if (sl->mb_y & 1) {\n\n            l1ref0 += 2;\n\n            l1ref1 += 2;\n\n            l1mv0  += 2 * b4_stride;\n\n            l1mv1  += 2 * b4_stride;\n\n        }\n\n    }\n\n\n\n    if (IS_INTERLACED(*mb_type) != IS_INTERLACED(mb_type_col[0])) {\n\n        int n = 0;\n\n        for (i8 = 0; i8 < 4; i8++) {\n\n            int x8  = i8 & 1;\n\n            int y8  = i8 >> 1;\n\n            int xy8 = x8     + y8 * b8_stride;\n\n            int xy4 = x8 * 3 + y8 * b4_stride;\n\n            int a, b;\n\n\n\n            if (is_b8x8 && !IS_DIRECT(sl->sub_mb_type[i8]))\n\n                continue;\n\n            sl->sub_mb_type[i8] = sub_mb_type;\n\n\n\n            fill_rectangle(&sl->ref_cache[0][scan8[i8 * 4]], 2, 2, 8,\n\n                           (uint8_t)ref[0], 1);\n\n            fill_rectangle(&sl->ref_cache[1][scan8[i8 * 4]], 2, 2, 8,\n\n                           (uint8_t)ref[1], 1);\n\n            if (!IS_INTRA(mb_type_col[y8]) && !sl->ref_list[1][0].parent->long_ref &&\n\n                ((l1ref0[xy8] == 0 &&\n\n                  FFABS(l1mv0[xy4][0]) <= 1 &&\n\n                  FFABS(l1mv0[xy4][1]) <= 1) ||\n\n                 (l1ref0[xy8] < 0 &&\n\n                  l1ref1[xy8] == 0 &&\n\n                  FFABS(l1mv1[xy4][0]) <= 1 &&\n\n                  FFABS(l1mv1[xy4][1]) <= 1))) {\n\n                a =\n\n                b = 0;\n\n                if (ref[0] > 0)\n\n                    a = mv[0];\n\n                if (ref[1] > 0)\n\n                    b = mv[1];\n\n                n++;\n\n            } else {\n\n                a = mv[0];\n\n                b = mv[1];\n\n            }\n\n            fill_rectangle(&sl->mv_cache[0][scan8[i8 * 4]], 2, 2, 8, a, 4);\n\n            fill_rectangle(&sl->mv_cache[1][scan8[i8 * 4]], 2, 2, 8, b, 4);\n\n        }\n\n        if (!is_b8x8 && !(n & 3))\n\n            *mb_type = (*mb_type & ~(MB_TYPE_8x8 | MB_TYPE_16x8 | MB_TYPE_8x16 |\n\n                                     MB_TYPE_P1L0 | MB_TYPE_P1L1)) |\n\n                       MB_TYPE_16x16 | MB_TYPE_DIRECT2;\n\n    } else if (IS_16X16(*mb_type)) {\n\n        int a, b;\n\n\n\n        fill_rectangle(&sl->ref_cache[0][scan8[0]], 4, 4, 8, (uint8_t)ref[0], 1);\n\n        fill_rectangle(&sl->ref_cache[1][scan8[0]], 4, 4, 8, (uint8_t)ref[1], 1);\n\n        if (!IS_INTRA(mb_type_col[0]) && !sl->ref_list[1][0].parent->long_ref &&\n\n            ((l1ref0[0] == 0 &&\n\n              FFABS(l1mv0[0][0]) <= 1 &&\n\n              FFABS(l1mv0[0][1]) <= 1) ||\n\n             (l1ref0[0] < 0 && !l1ref1[0] &&\n\n              FFABS(l1mv1[0][0]) <= 1 &&\n\n              FFABS(l1mv1[0][1]) <= 1 &&\n\n              h->sei.unregistered.x264_build > 33U))) {\n\n            a = b = 0;\n\n            if (ref[0] > 0)\n\n                a = mv[0];\n\n            if (ref[1] > 0)\n\n                b = mv[1];\n\n        } else {\n\n            a = mv[0];\n\n            b = mv[1];\n\n        }\n\n        fill_rectangle(&sl->mv_cache[0][scan8[0]], 4, 4, 8, a, 4);\n\n        fill_rectangle(&sl->mv_cache[1][scan8[0]], 4, 4, 8, b, 4);\n\n    } else {\n\n        int n = 0;\n\n        for (i8 = 0; i8 < 4; i8++) {\n\n            const int x8 = i8 & 1;\n\n            const int y8 = i8 >> 1;\n\n\n\n            if (is_b8x8 && !IS_DIRECT(sl->sub_mb_type[i8]))\n\n                continue;\n\n            sl->sub_mb_type[i8] = sub_mb_type;\n\n\n\n            fill_rectangle(&sl->mv_cache[0][scan8[i8 * 4]], 2, 2, 8, mv[0], 4);\n\n            fill_rectangle(&sl->mv_cache[1][scan8[i8 * 4]], 2, 2, 8, mv[1], 4);\n\n            fill_rectangle(&sl->ref_cache[0][scan8[i8 * 4]], 2, 2, 8,\n\n                           (uint8_t)ref[0], 1);\n\n            fill_rectangle(&sl->ref_cache[1][scan8[i8 * 4]], 2, 2, 8,\n\n                           (uint8_t)ref[1], 1);\n\n\n\n            assert(b8_stride == 2);\n\n            /* col_zero_flag */\n\n            if (!IS_INTRA(mb_type_col[0]) && !sl->ref_list[1][0].parent->long_ref &&\n\n                (l1ref0[i8] == 0 ||\n\n                 (l1ref0[i8] < 0 &&\n\n                  l1ref1[i8] == 0 &&\n\n                  h->sei.unregistered.x264_build > 33U))) {\n\n                const int16_t (*l1mv)[2] = l1ref0[i8] == 0 ? l1mv0 : l1mv1;\n\n                if (IS_SUB_8X8(sub_mb_type)) {\n\n                    const int16_t *mv_col = l1mv[x8 * 3 + y8 * 3 * b4_stride];\n\n                    if (FFABS(mv_col[0]) <= 1 && FFABS(mv_col[1]) <= 1) {\n\n                        if (ref[0] == 0)\n\n                            fill_rectangle(&sl->mv_cache[0][scan8[i8 * 4]], 2, 2,\n\n                                           8, 0, 4);\n\n                        if (ref[1] == 0)\n\n                            fill_rectangle(&sl->mv_cache[1][scan8[i8 * 4]], 2, 2,\n\n                                           8, 0, 4);\n\n                        n += 4;\n\n                    }\n\n                } else {\n\n                    int m = 0;\n\n                    for (i4 = 0; i4 < 4; i4++) {\n\n                        const int16_t *mv_col = l1mv[x8 * 2 + (i4 & 1) +\n\n                                                     (y8 * 2 + (i4 >> 1)) * b4_stride];\n\n                        if (FFABS(mv_col[0]) <= 1 && FFABS(mv_col[1]) <= 1) {\n\n                            if (ref[0] == 0)\n\n                                AV_ZERO32(sl->mv_cache[0][scan8[i8 * 4 + i4]]);\n\n                            if (ref[1] == 0)\n\n                                AV_ZERO32(sl->mv_cache[1][scan8[i8 * 4 + i4]]);\n\n                            m++;\n\n                        }\n\n                    }\n\n                    if (!(m & 3))\n\n                        sl->sub_mb_type[i8] += MB_TYPE_16x16 - MB_TYPE_8x8;\n\n                    n += m;\n\n                }\n\n            }\n\n        }\n\n        if (!is_b8x8 && !(n & 15))\n\n            *mb_type = (*mb_type & ~(MB_TYPE_8x8 | MB_TYPE_16x8 | MB_TYPE_8x16 |\n\n                                     MB_TYPE_P1L0 | MB_TYPE_P1L1)) |\n\n                       MB_TYPE_16x16 | MB_TYPE_DIRECT2;\n\n    }\n\n}\n", "idx": 25245}
{"project": "FFmpeg", "commit_id": "24ae353dfbe61019a86093a9c5cd15476aabef49", "target": 1, "func": "static int wc3_read_packet(AVFormatContext *s,\n\n                           AVPacket *pkt)\n\n{\n\n    Wc3DemuxContext *wc3 = s->priv_data;\n\n    ByteIOContext *pb = s->pb;\n\n    unsigned int fourcc_tag;\n\n    unsigned int size;\n\n    int packet_read = 0;\n\n    int ret = 0;\n\n    unsigned char text[1024];\n\n    unsigned int palette_number;\n\n    int i;\n\n    unsigned char r, g, b;\n\n    int base_palette_index;\n\n\n\n    while (!packet_read) {\n\n\n\n        fourcc_tag = get_le32(pb);\n\n        /* chunk sizes are 16-bit aligned */\n\n        size = (get_be32(pb) + 1) & (~1);\n\n        if (url_feof(pb))\n\n            return AVERROR(EIO);\n\n\n\n        switch (fourcc_tag) {\n\n\n\n        case BRCH_TAG:\n\n            /* no-op */\n\n            break;\n\n\n\n        case SHOT_TAG:\n\n            /* load up new palette */\n\n            palette_number = get_le32(pb);\n\n            if (palette_number >= wc3->palette_count)\n\n                return AVERROR_INVALIDDATA;\n\n            base_palette_index = palette_number * PALETTE_COUNT * 3;\n\n            for (i = 0; i < PALETTE_COUNT; i++) {\n\n                r = wc3->palettes[base_palette_index + i * 3 + 0];\n\n                g = wc3->palettes[base_palette_index + i * 3 + 1];\n\n                b = wc3->palettes[base_palette_index + i * 3 + 2];\n\n                wc3->palette_control.palette[i] = (r << 16) | (g << 8) | (b);\n\n            }\n\n            wc3->palette_control.palette_changed = 1;\n\n            break;\n\n\n\n        case VGA__TAG:\n\n            /* send out video chunk */\n\n            ret= av_get_packet(pb, pkt, size);\n\n            pkt->stream_index = wc3->video_stream_index;\n\n            pkt->pts = wc3->pts;\n\n            packet_read = 1;\n\n            break;\n\n\n\n        case TEXT_TAG:\n\n            /* subtitle chunk */\n\n#if 0\n\n            url_fseek(pb, size, SEEK_CUR);\n\n#else\n\n            if ((unsigned)size > sizeof(text) || (ret = get_buffer(pb, text, size)) != size)\n\n                ret = AVERROR(EIO);\n\n            else {\n\n                int i = 0;\n\n                av_log (s, AV_LOG_DEBUG, \"Subtitle time!\\n\");\n\n                av_log (s, AV_LOG_DEBUG, \"  inglish: %s\\n\", &text[i + 1]);\n\n                i += text[i] + 1;\n\n                av_log (s, AV_LOG_DEBUG, \"  doytsch: %s\\n\", &text[i + 1]);\n\n                i += text[i] + 1;\n\n                av_log (s, AV_LOG_DEBUG, \"  fronsay: %s\\n\", &text[i + 1]);\n\n            }\n\n#endif\n\n            break;\n\n\n\n        case AUDI_TAG:\n\n            /* send out audio chunk */\n\n            ret= av_get_packet(pb, pkt, size);\n\n            pkt->stream_index = wc3->audio_stream_index;\n\n            pkt->pts = wc3->pts;\n\n\n\n            /* time to advance pts */\n\n            wc3->pts++;\n\n\n\n            packet_read = 1;\n\n            break;\n\n\n\n        default:\n\n            av_log (s, AV_LOG_ERROR, \"  unrecognized WC3 chunk: %c%c%c%c (0x%02X%02X%02X%02X)\\n\",\n\n                (uint8_t)fourcc_tag, (uint8_t)(fourcc_tag >> 8), (uint8_t)(fourcc_tag >> 16), (uint8_t)(fourcc_tag >> 24),\n\n                (uint8_t)fourcc_tag, (uint8_t)(fourcc_tag >> 8), (uint8_t)(fourcc_tag >> 16), (uint8_t)(fourcc_tag >> 24));\n\n            ret = AVERROR_INVALIDDATA;\n\n            packet_read = 1;\n\n            break;\n\n        }\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 25250}
{"project": "FFmpeg", "commit_id": "7cdea450c67d24a3503a0eb64f491f58e474973f", "target": 1, "func": "static int rate_control(AVCodecContext *avctx, void *arg)\n\n{\n\n    SliceArgs *slice_dat = arg;\n\n    VC2EncContext *s = slice_dat->ctx;\n\n    const int sx = slice_dat->x;\n\n    const int sy = slice_dat->y;\n\n    int quant_buf[2], bits_buf[2], quant = s->q_start, range = s->q_start/3;\n\n    const int64_t top = slice_dat->bits_ceil;\n\n    const double percent = s->tolerance;\n\n    const double bottom = top - top*(percent/100.0f);\n\n    int bits = count_hq_slice(s, sx, sy, quant);\n\n    range -= range & 1; /* Make it an even number */\n\n    while ((bits > top) || (bits < bottom)) {\n\n        range *= bits > top ? +1 : -1;\n\n        quant = av_clip(quant + range, 0, s->q_ceil);\n\n        bits = count_hq_slice(s, sx, sy, quant);\n\n        range = av_clip(range/2, 1, s->q_ceil);\n\n        if (quant_buf[1] == quant) {\n\n            quant = bits_buf[0] < bits ? quant_buf[0] : quant;\n\n            bits = bits_buf[0] < bits ? bits_buf[0] : bits;\n\n            break;\n\n        }\n\n        quant_buf[1] = quant_buf[0];\n\n        quant_buf[0] = quant;\n\n        bits_buf[1] = bits_buf[0];\n\n        bits_buf[0] = bits;\n\n    }\n\n    slice_dat->quant_idx = av_clip(quant, 0, s->q_ceil);\n\n    slice_dat->bytes = FFALIGN((bits >> 3), s->size_scaler) + 4 + s->prefix_bytes;\n\n\n\n    return 0;\n\n}\n", "idx": 25255}
{"project": "FFmpeg", "commit_id": "ef0d779706c77ca9007527bd8d41e9400682f4e4", "target": 1, "func": "static int ogg_read_page(AVFormatContext *s, int *str)\n\n{\n\n    AVIOContext *bc = s->pb;\n\n    struct ogg *ogg = s->priv_data;\n\n    struct ogg_stream *os;\n\n    int ret, i = 0;\n\n    int flags, nsegs;\n\n    uint64_t gp;\n\n    uint32_t serial;\n\n    int size, idx;\n\n    uint8_t sync[4];\n\n    int sp = 0;\n\n\n\n    ret = avio_read(bc, sync, 4);\n\n    if (ret < 4)\n\n        return ret < 0 ? ret : AVERROR_EOF;\n\n\n\n    do{\n\n        int c;\n\n\n\n        if (sync[sp & 3] == 'O' &&\n\n            sync[(sp + 1) & 3] == 'g' &&\n\n            sync[(sp + 2) & 3] == 'g' && sync[(sp + 3) & 3] == 'S')\n\n            break;\n\n\n\n        c = avio_r8(bc);\n\n        if (bc->eof_reached)\n\n            return AVERROR_EOF;\n\n        sync[sp++ & 3] = c;\n\n    }while (i++ < MAX_PAGE_SIZE);\n\n\n\n    if (i >= MAX_PAGE_SIZE){\n\n        av_log (s, AV_LOG_INFO, \"ogg, can't find sync word\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (avio_r8(bc) != 0)      /* version */\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    flags = avio_r8(bc);\n\n    gp = avio_rl64 (bc);\n\n    serial = avio_rl32 (bc);\n\n    avio_skip(bc, 8); /* seq, crc */\n\n    nsegs = avio_r8(bc);\n\n\n\n    idx = ogg_find_stream (ogg, serial);\n\n    if (idx < 0){\n\n        if (ogg->headers) {\n\n            int n;\n\n\n\n            for (n = 0; n < ogg->nstreams; n++) {\n\n                av_freep(&ogg->streams[n].buf);\n\n                if (!ogg->state || ogg->state->streams[n].private != ogg->streams[n].private)\n\n                    av_freep(&ogg->streams[n].private);\n\n            }\n\n            ogg->curidx   = -1;\n\n            ogg->nstreams = 0;\n\n            idx = ogg_new_stream(s, serial, 0);\n\n        } else {\n\n            idx = ogg_new_stream(s, serial, 1);\n\n        }\n\n        if (idx < 0)\n\n            return idx;\n\n    }\n\n\n\n    os = ogg->streams + idx;\n\n    os->page_pos = avio_tell(bc) - 27;\n\n\n\n    if(os->psize > 0)\n\n        ogg_new_buf(ogg, idx);\n\n\n\n    ret = avio_read(bc, os->segments, nsegs);\n\n    if (ret < nsegs)\n\n        return ret < 0 ? ret : AVERROR_EOF;\n\n\n\n    os->nsegs = nsegs;\n\n    os->segp = 0;\n\n\n\n    size = 0;\n\n    for (i = 0; i < nsegs; i++)\n\n        size += os->segments[i];\n\n\n\n    if (flags & OGG_FLAG_CONT || os->incomplete){\n\n        if (!os->psize){\n\n            while (os->segp < os->nsegs){\n\n                int seg = os->segments[os->segp++];\n\n                os->pstart += seg;\n\n                if (seg < 255)\n\n                    break;\n\n            }\n\n            os->sync_pos = os->page_pos;\n\n        }\n\n    }else{\n\n        os->psize = 0;\n\n        os->sync_pos = os->page_pos;\n\n    }\n\n\n\n    if (os->bufsize - os->bufpos < size){\n\n        uint8_t *nb = av_malloc (os->bufsize *= 2);\n\n        memcpy (nb, os->buf, os->bufpos);\n\n        av_free (os->buf);\n\n        os->buf = nb;\n\n    }\n\n\n\n    ret = avio_read(bc, os->buf + os->bufpos, size);\n\n    if (ret < size)\n\n        return ret < 0 ? ret : AVERROR_EOF;\n\n\n\n    os->bufpos += size;\n\n    os->granule = gp;\n\n    os->flags = flags;\n\n\n\n    if (str)\n\n        *str = idx;\n\n\n\n    return 0;\n\n}\n", "idx": 25258}
{"project": "FFmpeg", "commit_id": "8fb00b3e858b7a5aeccfe6bdfc10290c2121c3ec", "target": 1, "func": "void ff_ivi_recompose53(const IVIPlaneDesc *plane, uint8_t *dst,\n\n                        const ptrdiff_t dst_pitch)\n\n{\n\n    int             x, y, indx;\n\n    int32_t         p0, p1, p2, p3, tmp0, tmp1, tmp2;\n\n    int32_t         b0_1, b0_2, b1_1, b1_2, b1_3, b2_1, b2_2, b2_3, b2_4, b2_5, b2_6;\n\n    int32_t         b3_1, b3_2, b3_3, b3_4, b3_5, b3_6, b3_7, b3_8, b3_9;\n\n    ptrdiff_t       pitch, back_pitch;\n\n    const short     *b0_ptr, *b1_ptr, *b2_ptr, *b3_ptr;\n\n    const int       num_bands = 4;\n\n\n\n    /* all bands should have the same pitch */\n\n    pitch = plane->bands[0].pitch;\n\n\n\n    /* pixels at the position \"y-1\" will be set to pixels at the \"y\" for the 1st iteration */\n\n    back_pitch = 0;\n\n\n\n    /* get pointers to the wavelet bands */\n\n    b0_ptr = plane->bands[0].buf;\n\n    b1_ptr = plane->bands[1].buf;\n\n    b2_ptr = plane->bands[2].buf;\n\n    b3_ptr = plane->bands[3].buf;\n\n\n\n    for (y = 0; y < plane->height; y += 2) {\n\n\n\n        if (y+2 >= plane->height)\n\n            pitch= 0;\n\n        /* load storage variables with values */\n\n        if (num_bands > 0) {\n\n            b0_1 = b0_ptr[0];\n\n            b0_2 = b0_ptr[pitch];\n\n        }\n\n\n\n        if (num_bands > 1) {\n\n            b1_1 = b1_ptr[back_pitch];\n\n            b1_2 = b1_ptr[0];\n\n            b1_3 = b1_1 - b1_2*6 + b1_ptr[pitch];\n\n        }\n\n\n\n        if (num_bands > 2) {\n\n            b2_2 = b2_ptr[0];     // b2[x,  y  ]\n\n            b2_3 = b2_2;          // b2[x+1,y  ] = b2[x,y]\n\n            b2_5 = b2_ptr[pitch]; // b2[x  ,y+1]\n\n            b2_6 = b2_5;          // b2[x+1,y+1] = b2[x,y+1]\n\n        }\n\n\n\n        if (num_bands > 3) {\n\n            b3_2 = b3_ptr[back_pitch]; // b3[x  ,y-1]\n\n            b3_3 = b3_2;               // b3[x+1,y-1] = b3[x  ,y-1]\n\n            b3_5 = b3_ptr[0];          // b3[x  ,y  ]\n\n            b3_6 = b3_5;               // b3[x+1,y  ] = b3[x  ,y  ]\n\n            b3_8 = b3_2 - b3_5*6 + b3_ptr[pitch];\n\n            b3_9 = b3_8;\n\n        }\n\n\n\n        for (x = 0, indx = 0; x < plane->width; x+=2, indx++) {\n\n            if (x+2 >= plane->width) {\n\n                b0_ptr --;\n\n                b1_ptr --;\n\n                b2_ptr --;\n\n                b3_ptr --;\n\n            }\n\n\n\n            /* some values calculated in the previous iterations can */\n\n            /* be reused in the next ones, so do appropriate copying */\n\n            b2_1 = b2_2; // b2[x-1,y  ] = b2[x,  y  ]\n\n            b2_2 = b2_3; // b2[x  ,y  ] = b2[x+1,y  ]\n\n            b2_4 = b2_5; // b2[x-1,y+1] = b2[x  ,y+1]\n\n            b2_5 = b2_6; // b2[x  ,y+1] = b2[x+1,y+1]\n\n            b3_1 = b3_2; // b3[x-1,y-1] = b3[x  ,y-1]\n\n            b3_2 = b3_3; // b3[x  ,y-1] = b3[x+1,y-1]\n\n            b3_4 = b3_5; // b3[x-1,y  ] = b3[x  ,y  ]\n\n            b3_5 = b3_6; // b3[x  ,y  ] = b3[x+1,y  ]\n\n            b3_7 = b3_8; // vert_HPF(x-1)\n\n            b3_8 = b3_9; // vert_HPF(x  )\n\n\n\n            p0 = p1 = p2 = p3 = 0;\n\n\n\n            /* process the LL-band by applying LPF both vertically and horizontally */\n\n            if (num_bands > 0) {\n\n                tmp0 = b0_1;\n\n                tmp2 = b0_2;\n\n                b0_1 = b0_ptr[indx+1];\n\n                b0_2 = b0_ptr[pitch+indx+1];\n\n                tmp1 = tmp0 + b0_1;\n\n\n\n                p0 =  tmp0 << 4;\n\n                p1 =  tmp1 << 3;\n\n                p2 = (tmp0 + tmp2) << 3;\n\n                p3 = (tmp1 + tmp2 + b0_2) << 2;\n\n            }\n\n\n\n            /* process the HL-band by applying HPF vertically and LPF horizontally */\n\n            if (num_bands > 1) {\n\n                tmp0 = b1_2;\n\n                tmp1 = b1_1;\n\n                b1_2 = b1_ptr[indx+1];\n\n                b1_1 = b1_ptr[back_pitch+indx+1];\n\n\n\n                tmp2 = tmp1 - tmp0*6 + b1_3;\n\n                b1_3 = b1_1 - b1_2*6 + b1_ptr[pitch+indx+1];\n\n\n\n                p0 += (tmp0 + tmp1) << 3;\n\n                p1 += (tmp0 + tmp1 + b1_1 + b1_2) << 2;\n\n                p2 +=  tmp2 << 2;\n\n                p3 += (tmp2 + b1_3) << 1;\n\n            }\n\n\n\n            /* process the LH-band by applying LPF vertically and HPF horizontally */\n\n            if (num_bands > 2) {\n\n                b2_3 = b2_ptr[indx+1];\n\n                b2_6 = b2_ptr[pitch+indx+1];\n\n\n\n                tmp0 = b2_1 + b2_2;\n\n                tmp1 = b2_1 - b2_2*6 + b2_3;\n\n\n\n                p0 += tmp0 << 3;\n\n                p1 += tmp1 << 2;\n\n                p2 += (tmp0 + b2_4 + b2_5) << 2;\n\n                p3 += (tmp1 + b2_4 - b2_5*6 + b2_6) << 1;\n\n            }\n\n\n\n            /* process the HH-band by applying HPF both vertically and horizontally */\n\n            if (num_bands > 3) {\n\n                b3_6 = b3_ptr[indx+1];            // b3[x+1,y  ]\n\n                b3_3 = b3_ptr[back_pitch+indx+1]; // b3[x+1,y-1]\n\n\n\n                tmp0 = b3_1 + b3_4;\n\n                tmp1 = b3_2 + b3_5;\n\n                tmp2 = b3_3 + b3_6;\n\n\n\n                b3_9 = b3_3 - b3_6*6 + b3_ptr[pitch+indx+1];\n\n\n\n                p0 += (tmp0 + tmp1) << 2;\n\n                p1 += (tmp0 - tmp1*6 + tmp2) << 1;\n\n                p2 += (b3_7 + b3_8) << 1;\n\n                p3 +=  b3_7 - b3_8*6 + b3_9;\n\n            }\n\n\n\n            /* output four pixels */\n\n            dst[x]             = av_clip_uint8((p0 >> 6) + 128);\n\n            dst[x+1]           = av_clip_uint8((p1 >> 6) + 128);\n\n            dst[dst_pitch+x]   = av_clip_uint8((p2 >> 6) + 128);\n\n            dst[dst_pitch+x+1] = av_clip_uint8((p3 >> 6) + 128);\n\n        }// for x\n\n\n\n        dst += dst_pitch << 1;\n\n\n\n        back_pitch = -pitch;\n\n\n\n        b0_ptr += pitch + 1;\n\n        b1_ptr += pitch + 1;\n\n        b2_ptr += pitch + 1;\n\n        b3_ptr += pitch + 1;\n\n    }\n\n}\n", "idx": 25261}
{"project": "FFmpeg", "commit_id": "c2c1726847fe3a043762062db40774bf0cc434c3", "target": 0, "func": "static void compute_status(HTTPContext *c)\n\n{\n\n    HTTPContext *c1;\n\n    FFStream *stream;\n\n    char *p;\n\n    time_t ti;\n\n    int i, len;\n\n    AVIOContext *pb;\n\n\n\n    if (avio_open_dyn_buf(&pb) < 0) {\n\n        /* XXX: return an error ? */\n\n        c->buffer_ptr = c->buffer;\n\n        c->buffer_end = c->buffer;\n\n        return;\n\n    }\n\n\n\n    avio_printf(pb, \"HTTP/1.0 200 OK\\r\\n\");\n\n    avio_printf(pb, \"Content-type: %s\\r\\n\", \"text/html\");\n\n    avio_printf(pb, \"Pragma: no-cache\\r\\n\");\n\n    avio_printf(pb, \"\\r\\n\");\n\n\n\n    avio_printf(pb, \"<html><head><title>%s Status</title>\\n\", program_name);\n\n    if (c->stream->feed_filename[0])\n\n        avio_printf(pb, \"<link rel=\\\"shortcut icon\\\" href=\\\"%s\\\">\\n\", c->stream->feed_filename);\n\n    avio_printf(pb, \"</head>\\n<body>\");\n\n    avio_printf(pb, \"<h1>%s Status</h1>\\n\", program_name);\n\n    /* format status */\n\n    avio_printf(pb, \"<h2>Available Streams</h2>\\n\");\n\n    avio_printf(pb, \"<table cellspacing=0 cellpadding=4>\\n\");\n\n    avio_printf(pb, \"<tr><th valign=top>Path<th align=left>Served<br>Conns<th><br>bytes<th valign=top>Format<th>Bit rate<br>kbits/s<th align=left>Video<br>kbits/s<th><br>Codec<th align=left>Audio<br>kbits/s<th><br>Codec<th align=left valign=top>Feed\\n\");\n\n    stream = first_stream;\n\n    while (stream != NULL) {\n\n        char sfilename[1024];\n\n        char *eosf;\n\n\n\n        if (stream->feed != stream) {\n\n            av_strlcpy(sfilename, stream->filename, sizeof(sfilename) - 10);\n\n            eosf = sfilename + strlen(sfilename);\n\n            if (eosf - sfilename >= 4) {\n\n                if (strcmp(eosf - 4, \".asf\") == 0)\n\n                    strcpy(eosf - 4, \".asx\");\n\n                else if (strcmp(eosf - 3, \".rm\") == 0)\n\n                    strcpy(eosf - 3, \".ram\");\n\n                else if (stream->fmt && !strcmp(stream->fmt->name, \"rtp\")) {\n\n                    /* generate a sample RTSP director if\n\n                       unicast. Generate an SDP redirector if\n\n                       multicast */\n\n                    eosf = strrchr(sfilename, '.');\n\n                    if (!eosf)\n\n                        eosf = sfilename + strlen(sfilename);\n\n                    if (stream->is_multicast)\n\n                        strcpy(eosf, \".sdp\");\n\n                    else\n\n                        strcpy(eosf, \".rtsp\");\n\n                }\n\n            }\n\n\n\n            avio_printf(pb, \"<tr><td><a href=\\\"/%s\\\">%s</a> \",\n\n                         sfilename, stream->filename);\n\n            avio_printf(pb, \"<td align=right> %d <td align=right> \",\n\n                        stream->conns_served);\n\n            fmt_bytecount(pb, stream->bytes_served);\n\n            switch(stream->stream_type) {\n\n            case STREAM_TYPE_LIVE: {\n\n                    int audio_bit_rate = 0;\n\n                    int video_bit_rate = 0;\n\n                    const char *audio_codec_name = \"\";\n\n                    const char *video_codec_name = \"\";\n\n                    const char *audio_codec_name_extra = \"\";\n\n                    const char *video_codec_name_extra = \"\";\n\n\n\n                    for(i=0;i<stream->nb_streams;i++) {\n\n                        AVStream *st = stream->streams[i];\n\n                        AVCodec *codec = avcodec_find_encoder(st->codec->codec_id);\n\n                        switch(st->codec->codec_type) {\n\n                        case AVMEDIA_TYPE_AUDIO:\n\n                            audio_bit_rate += st->codec->bit_rate;\n\n                            if (codec) {\n\n                                if (*audio_codec_name)\n\n                                    audio_codec_name_extra = \"...\";\n\n                                audio_codec_name = codec->name;\n\n                            }\n\n                            break;\n\n                        case AVMEDIA_TYPE_VIDEO:\n\n                            video_bit_rate += st->codec->bit_rate;\n\n                            if (codec) {\n\n                                if (*video_codec_name)\n\n                                    video_codec_name_extra = \"...\";\n\n                                video_codec_name = codec->name;\n\n                            }\n\n                            break;\n\n                        case AVMEDIA_TYPE_DATA:\n\n                            video_bit_rate += st->codec->bit_rate;\n\n                            break;\n\n                        default:\n\n                            abort();\n\n                        }\n\n                    }\n\n                    avio_printf(pb, \"<td align=center> %s <td align=right> %d <td align=right> %d <td> %s %s <td align=right> %d <td> %s %s\",\n\n                                 stream->fmt->name,\n\n                                 stream->bandwidth,\n\n                                 video_bit_rate / 1000, video_codec_name, video_codec_name_extra,\n\n                                 audio_bit_rate / 1000, audio_codec_name, audio_codec_name_extra);\n\n                    if (stream->feed)\n\n                        avio_printf(pb, \"<td>%s\", stream->feed->filename);\n\n                    else\n\n                        avio_printf(pb, \"<td>%s\", stream->feed_filename);\n\n                    avio_printf(pb, \"\\n\");\n\n                }\n\n                break;\n\n            default:\n\n                avio_printf(pb, \"<td align=center> - <td align=right> - <td align=right> - <td><td align=right> - <td>\\n\");\n\n                break;\n\n            }\n\n        }\n\n        stream = stream->next;\n\n    }\n\n    avio_printf(pb, \"</table>\\n\");\n\n\n\n    stream = first_stream;\n\n    while (stream != NULL) {\n\n        if (stream->feed == stream) {\n\n            avio_printf(pb, \"<h2>Feed %s</h2>\", stream->filename);\n\n            if (stream->pid) {\n\n                avio_printf(pb, \"Running as pid %d.\\n\", stream->pid);\n\n\n\n#if defined(linux) && !defined(CONFIG_NOCUTILS)\n\n                {\n\n                    FILE *pid_stat;\n\n                    char ps_cmd[64];\n\n\n\n                    /* This is somewhat linux specific I guess */\n\n                    snprintf(ps_cmd, sizeof(ps_cmd),\n\n                             \"ps -o \\\"%%cpu,cputime\\\" --no-headers %d\",\n\n                             stream->pid);\n\n\n\n                    pid_stat = popen(ps_cmd, \"r\");\n\n                    if (pid_stat) {\n\n                        char cpuperc[10];\n\n                        char cpuused[64];\n\n\n\n                        if (fscanf(pid_stat, \"%9s %63s\", cpuperc,\n\n                                   cpuused) == 2) {\n\n                            avio_printf(pb, \"Currently using %s%% of the cpu. Total time used %s.\\n\",\n\n                                         cpuperc, cpuused);\n\n                        }\n\n                        fclose(pid_stat);\n\n                    }\n\n                }\n\n#endif\n\n\n\n                avio_printf(pb, \"<p>\");\n\n            }\n\n            avio_printf(pb, \"<table cellspacing=0 cellpadding=4><tr><th>Stream<th>type<th>kbits/s<th align=left>codec<th align=left>Parameters\\n\");\n\n\n\n            for (i = 0; i < stream->nb_streams; i++) {\n\n                AVStream *st = stream->streams[i];\n\n                AVCodec *codec = avcodec_find_encoder(st->codec->codec_id);\n\n                const char *type = \"unknown\";\n\n                char parameters[64];\n\n\n\n                parameters[0] = 0;\n\n\n\n                switch(st->codec->codec_type) {\n\n                case AVMEDIA_TYPE_AUDIO:\n\n                    type = \"audio\";\n\n                    snprintf(parameters, sizeof(parameters), \"%d channel(s), %d Hz\", st->codec->channels, st->codec->sample_rate);\n\n                    break;\n\n                case AVMEDIA_TYPE_VIDEO:\n\n                    type = \"video\";\n\n                    snprintf(parameters, sizeof(parameters), \"%dx%d, q=%d-%d, fps=%d\", st->codec->width, st->codec->height,\n\n                                st->codec->qmin, st->codec->qmax, st->codec->time_base.den / st->codec->time_base.num);\n\n                    break;\n\n                default:\n\n                    abort();\n\n                }\n\n                avio_printf(pb, \"<tr><td align=right>%d<td>%s<td align=right>%d<td>%s<td>%s\\n\",\n\n                        i, type, st->codec->bit_rate/1000, codec ? codec->name : \"\", parameters);\n\n            }\n\n            avio_printf(pb, \"</table>\\n\");\n\n\n\n        }\n\n        stream = stream->next;\n\n    }\n\n\n\n    /* connection status */\n\n    avio_printf(pb, \"<h2>Connection Status</h2>\\n\");\n\n\n\n    avio_printf(pb, \"Number of connections: %d / %d<br>\\n\",\n\n                 nb_connections, nb_max_connections);\n\n\n\n    avio_printf(pb, \"Bandwidth in use: %\"PRIu64\"k / %\"PRIu64\"k<br>\\n\",\n\n                 current_bandwidth, max_bandwidth);\n\n\n\n    avio_printf(pb, \"<table>\\n\");\n\n    avio_printf(pb, \"<tr><th>#<th>File<th>IP<th>Proto<th>State<th>Target bits/sec<th>Actual bits/sec<th>Bytes transferred\\n\");\n\n    c1 = first_http_ctx;\n\n    i = 0;\n\n    while (c1 != NULL) {\n\n        int bitrate;\n\n        int j;\n\n\n\n        bitrate = 0;\n\n        if (c1->stream) {\n\n            for (j = 0; j < c1->stream->nb_streams; j++) {\n\n                if (!c1->stream->feed)\n\n                    bitrate += c1->stream->streams[j]->codec->bit_rate;\n\n                else if (c1->feed_streams[j] >= 0)\n\n                    bitrate += c1->stream->feed->streams[c1->feed_streams[j]]->codec->bit_rate;\n\n            }\n\n        }\n\n\n\n        i++;\n\n        p = inet_ntoa(c1->from_addr.sin_addr);\n\n        avio_printf(pb, \"<tr><td><b>%d</b><td>%s%s<td>%s<td>%s<td>%s<td align=right>\",\n\n                    i,\n\n                    c1->stream ? c1->stream->filename : \"\",\n\n                    c1->state == HTTPSTATE_RECEIVE_DATA ? \"(input)\" : \"\",\n\n                    p,\n\n                    c1->protocol,\n\n                    http_state[c1->state]);\n\n        fmt_bytecount(pb, bitrate);\n\n        avio_printf(pb, \"<td align=right>\");\n\n        fmt_bytecount(pb, compute_datarate(&c1->datarate, c1->data_count) * 8);\n\n        avio_printf(pb, \"<td align=right>\");\n\n        fmt_bytecount(pb, c1->data_count);\n\n        avio_printf(pb, \"\\n\");\n\n        c1 = c1->next;\n\n    }\n\n    avio_printf(pb, \"</table>\\n\");\n\n\n\n    /* date */\n\n    ti = time(NULL);\n\n    p = ctime(&ti);\n\n    avio_printf(pb, \"<hr size=1 noshade>Generated at %s\", p);\n\n    avio_printf(pb, \"</body>\\n</html>\\n\");\n\n\n\n    len = avio_close_dyn_buf(pb, &c->pb_buffer);\n\n    c->buffer_ptr = c->pb_buffer;\n\n    c->buffer_end = c->pb_buffer + len;\n\n}\n", "idx": 25265}
{"project": "FFmpeg", "commit_id": "6950cca97fed890ec56259a2f868f37b65513d92", "target": 0, "func": "int av_image_fill_pointers(uint8_t *data[4], enum PixelFormat pix_fmt, int height,\n\n                           uint8_t *ptr, const int linesizes[4])\n\n{\n\n    int i, total_size, size[4], has_plane[4];\n\n\n\n    const AVPixFmtDescriptor *desc = &av_pix_fmt_descriptors[pix_fmt];\n\n    memset(data     , 0, sizeof(data[0])*4);\n\n    memset(size     , 0, sizeof(size));\n\n    memset(has_plane, 0, sizeof(has_plane));\n\n\n\n    if (desc->flags & PIX_FMT_HWACCEL)\n\n        return AVERROR(EINVAL);\n\n\n\n    data[0] = ptr;\n\n    size[0] = linesizes[0] * height;\n\n\n\n    if (desc->flags & PIX_FMT_PAL) {\n\n        size[0] = (size[0] + 3) & ~3;\n\n        data[1] = ptr + size[0]; /* palette is stored here as 256 32 bits words */\n\n        return size[0] + 256 * 4;\n\n    }\n\n\n\n    for (i = 0; i < 4; i++)\n\n        has_plane[desc->comp[i].plane] = 1;\n\n\n\n    total_size = size[0];\n\n    for (i = 1; has_plane[i] && i < 4; i++) {\n\n        int h, s = (i == 1 || i == 2) ? desc->log2_chroma_h : 0;\n\n        data[i] = data[i-1] + size[i-1];\n\n        h = (height + (1 << s) - 1) >> s;\n\n        size[i] = h * linesizes[i];\n\n        total_size += size[i];\n\n    }\n\n\n\n    return total_size;\n\n}\n", "idx": 25266}
{"project": "FFmpeg", "commit_id": "acf23d9451e9ea014a4eddf2abdb476c4f33edc4", "target": 0, "func": "static int genh_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    AVCodecContext *codec = s->streams[0]->codec;\n\n    GENHDemuxContext *c = s->priv_data;\n\n    int ret;\n\n\n\n    if (c->dsp_int_type == 1 && codec->codec_id == AV_CODEC_ID_ADPCM_THP &&\n\n        codec->channels > 1) {\n\n        int i, ch;\n\n\n\n        if (avio_feof(s->pb))\n\n            return AVERROR_EOF;\n\n        av_new_packet(pkt, 8 * codec->channels);\n\n        for (i = 0; i < 8 / c->interleave_size; i++) {\n\n            for (ch = 0; ch < codec->channels; ch++) {\n\n                pkt->data[ch * 8 + i*c->interleave_size+0] = avio_r8(s->pb);\n\n                pkt->data[ch * 8 + i*c->interleave_size+1] = avio_r8(s->pb);\n\n            }\n\n        }\n\n        ret = 0;\n\n    } else {\n\n        ret = av_get_packet(s->pb, pkt, codec->block_align ? codec->block_align : 1024 * codec->channels);\n\n    }\n\n\n\n    pkt->stream_index = 0;\n\n    return ret;\n\n}\n", "idx": 25267}
{"project": "FFmpeg", "commit_id": "a42e3a6700547e4e49445bda81d3a89ec3e081a9", "target": 1, "func": "static int pcm_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    const uint8_t *src = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    PCMDecode *s       = avctx->priv_data;\n\n    AVFrame *frame     = data;\n\n    int sample_size, c, n, ret, samples_per_block;\n\n    uint8_t *samples;\n\n    int32_t *dst_int32_t;\n\n\n\n    sample_size = av_get_bits_per_sample(avctx->codec_id) / 8;\n\n\n\n    /* av_get_bits_per_sample returns 0 for AV_CODEC_ID_PCM_DVD */\n\n    samples_per_block = 1;\n\n    if (avctx->codec->id == AV_CODEC_ID_PCM_DVD) {\n\n        if (avctx->bits_per_coded_sample != 20 &&\n\n            avctx->bits_per_coded_sample != 24) {\n\n            av_log(avctx, AV_LOG_ERROR, \"PCM DVD unsupported sample depth\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n        /* 2 samples are interleaved per block in PCM_DVD */\n\n        samples_per_block = 2;\n\n        sample_size       = avctx->bits_per_coded_sample * 2 / 8;\n\n    } else if (avctx->codec_id == AV_CODEC_ID_PCM_LXF) {\n\n        /* we process 40-bit blocks per channel for LXF */\n\n        samples_per_block = 2;\n\n        sample_size       = 5;\n\n    }\n\n\n\n    if (sample_size == 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid sample_size\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    n = avctx->channels * sample_size;\n\n\n\n    if (n && buf_size % n) {\n\n        if (buf_size < n) {\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid PCM packet\\n\");\n\n            return -1;\n\n        } else\n\n            buf_size -= buf_size % n;\n\n    }\n\n\n\n    n = buf_size / sample_size;\n\n\n\n    /* get output buffer */\n\n    frame->nb_samples = n * samples_per_block / avctx->channels;\n\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n    samples = frame->data[0];\n\n\n\n    switch (avctx->codec->id) {\n\n    case AV_CODEC_ID_PCM_U32LE:\n\n        DECODE(32, le32, src, samples, n, 0, 0x80000000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_U32BE:\n\n        DECODE(32, be32, src, samples, n, 0, 0x80000000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S24LE:\n\n        DECODE(32, le24, src, samples, n, 8, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S24BE:\n\n        DECODE(32, be24, src, samples, n, 8, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_U24LE:\n\n        DECODE(32, le24, src, samples, n, 8, 0x800000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_U24BE:\n\n        DECODE(32, be24, src, samples, n, 8, 0x800000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S24DAUD:\n\n        for (; n > 0; n--) {\n\n            uint32_t v = bytestream_get_be24(&src);\n\n            v >>= 4; // sync flags are here\n\n            AV_WN16A(samples, ff_reverse[(v >> 8) & 0xff] +\n\n                             (ff_reverse[v        & 0xff] << 8));\n\n            samples += 2;\n\n        }\n\n        break;\n\n    case AV_CODEC_ID_PCM_S16LE_PLANAR:\n\n    {\n\n        int av_unused n2;\n\n        n /= avctx->channels;\n\n        for (c = 0; c < avctx->channels; c++) {\n\n            samples = frame->extended_data[c];\n\n#if HAVE_BIGENDIAN\n\n            n2 = n;\n\n            DECODE(16, le16, src, samples, n2, 0, 0)\n\n#else\n\n            memcpy(samples, src, n * 2);\n\n            src += n * 2;\n\n#endif\n\n        }\n\n        break;\n\n    }\n\n    case AV_CODEC_ID_PCM_U16LE:\n\n        DECODE(16, le16, src, samples, n, 0, 0x8000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_U16BE:\n\n        DECODE(16, be16, src, samples, n, 0, 0x8000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S8:\n\n        for (; n > 0; n--)\n\n            *samples++ = *src++ + 128;\n\n        break;\n\n#if HAVE_BIGENDIAN\n\n    case AV_CODEC_ID_PCM_F64LE:\n\n        DECODE(64, le64, src, samples, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S32LE:\n\n    case AV_CODEC_ID_PCM_F32LE:\n\n        DECODE(32, le32, src, samples, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S16LE:\n\n        DECODE(16, le16, src, samples, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_F64BE:\n\n    case AV_CODEC_ID_PCM_F32BE:\n\n    case AV_CODEC_ID_PCM_S32BE:\n\n    case AV_CODEC_ID_PCM_S16BE:\n\n#else\n\n    case AV_CODEC_ID_PCM_F64BE:\n\n        DECODE(64, be64, src, samples, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_F32BE:\n\n    case AV_CODEC_ID_PCM_S32BE:\n\n        DECODE(32, be32, src, samples, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S16BE:\n\n        DECODE(16, be16, src, samples, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_F64LE:\n\n    case AV_CODEC_ID_PCM_F32LE:\n\n    case AV_CODEC_ID_PCM_S32LE:\n\n    case AV_CODEC_ID_PCM_S16LE:\n\n#endif /* HAVE_BIGENDIAN */\n\n    case AV_CODEC_ID_PCM_U8:\n\n        memcpy(samples, src, n * sample_size);\n\n        break;\n\n    case AV_CODEC_ID_PCM_ZORK:\n\n        for (; n > 0; n--) {\n\n            int v = *src++;\n\n            if (v < 128)\n\n                v = 128 - v;\n\n            *samples++ = v;\n\n        }\n\n        break;\n\n    case AV_CODEC_ID_PCM_ALAW:\n\n    case AV_CODEC_ID_PCM_MULAW:\n\n        for (; n > 0; n--) {\n\n            AV_WN16A(samples, s->table[*src++]);\n\n            samples += 2;\n\n        }\n\n        break;\n\n    case AV_CODEC_ID_PCM_DVD:\n\n    {\n\n        const uint8_t *src8;\n\n        dst_int32_t = (int32_t *)frame->data[0];\n\n        n /= avctx->channels;\n\n        switch (avctx->bits_per_coded_sample) {\n\n        case 20:\n\n            while (n--) {\n\n                c    = avctx->channels;\n\n                src8 = src + 4 * c;\n\n                while (c--) {\n\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8   & 0xf0) <<  8);\n\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8++ & 0x0f) << 12);\n\n                }\n\n                src = src8;\n\n            }\n\n            break;\n\n        case 24:\n\n            while (n--) {\n\n                c    = avctx->channels;\n\n                src8 = src + 4 * c;\n\n                while (c--) {\n\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8++) << 8);\n\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8++) << 8);\n\n                }\n\n                src = src8;\n\n            }\n\n            break;\n\n        }\n\n        break;\n\n    }\n\n    case AV_CODEC_ID_PCM_LXF:\n\n    {\n\n        int i;\n\n        n /= avctx->channels;\n\n        for (c = 0; c < avctx->channels; c++) {\n\n            dst_int32_t = (int32_t *)frame->extended_data[c];\n\n            for (i = 0; i < n; i++) {\n\n                // extract low 20 bits and expand to 32 bits\n\n                *dst_int32_t++ =  (src[2]         << 28) |\n\n                                  (src[1]         << 20) |\n\n                                  (src[0]         << 12) |\n\n                                 ((src[2] & 0x0F) <<  8) |\n\n                                   src[1];\n\n                // extract high 20 bits and expand to 32 bits\n\n                *dst_int32_t++ =  (src[4]         << 24) |\n\n                                  (src[3]         << 16) |\n\n                                 ((src[2] & 0xF0) <<  8) |\n\n                                  (src[4]         <<  4) |\n\n                                  (src[3]         >>  4);\n\n                src += 5;\n\n            }\n\n        }\n\n        break;\n\n    }\n\n    default:\n\n        return -1;\n\n    }\n\n\n\n    *got_frame_ptr = 1;\n\n\n\n    return buf_size;\n\n}\n", "idx": 25271}
{"project": "FFmpeg", "commit_id": "2df0c32ea12ddfa72ba88309812bfb13b674130f", "target": 0, "func": "static av_cold int MPA_encode_init(AVCodecContext *avctx)\n\n{\n\n    MpegAudioContext *s = avctx->priv_data;\n\n    int freq = avctx->sample_rate;\n\n    int bitrate = avctx->bit_rate;\n\n    int channels = avctx->channels;\n\n    int i, v, table;\n\n    float a;\n\n\n\n    if (channels <= 0 || channels > 2){\n\n        av_log(avctx, AV_LOG_ERROR, \"encoding %d channel(s) is not allowed in mp2\\n\", channels);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    bitrate = bitrate / 1000;\n\n    s->nb_channels = channels;\n\n    avctx->frame_size = MPA_FRAME_SIZE;\n\n    avctx->delay      = 512 - 32 + 1;\n\n\n\n    /* encoding freq */\n\n    s->lsf = 0;\n\n    for(i=0;i<3;i++) {\n\n        if (avpriv_mpa_freq_tab[i] == freq)\n\n            break;\n\n        if ((avpriv_mpa_freq_tab[i] / 2) == freq) {\n\n            s->lsf = 1;\n\n            break;\n\n        }\n\n    }\n\n    if (i == 3){\n\n        av_log(avctx, AV_LOG_ERROR, \"Sampling rate %d is not allowed in mp2\\n\", freq);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    s->freq_index = i;\n\n\n\n    /* encoding bitrate & frequency */\n\n    for(i=0;i<15;i++) {\n\n        if (avpriv_mpa_bitrate_tab[s->lsf][1][i] == bitrate)\n\n            break;\n\n    }\n\n    if (i == 15){\n\n        av_log(avctx, AV_LOG_ERROR, \"bitrate %d is not allowed in mp2\\n\", bitrate);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    s->bitrate_index = i;\n\n\n\n    /* compute total header size & pad bit */\n\n\n\n    a = (float)(bitrate * 1000 * MPA_FRAME_SIZE) / (freq * 8.0);\n\n    s->frame_size = ((int)a) * 8;\n\n\n\n    /* frame fractional size to compute padding */\n\n    s->frame_frac = 0;\n\n    s->frame_frac_incr = (int)((a - floor(a)) * 65536.0);\n\n\n\n    /* select the right allocation table */\n\n    table = ff_mpa_l2_select_table(bitrate, s->nb_channels, freq, s->lsf);\n\n\n\n    /* number of used subbands */\n\n    s->sblimit = ff_mpa_sblimit_table[table];\n\n    s->alloc_table = ff_mpa_alloc_tables[table];\n\n\n\n    av_dlog(avctx, \"%d kb/s, %d Hz, frame_size=%d bits, table=%d, padincr=%x\\n\",\n\n            bitrate, freq, s->frame_size, table, s->frame_frac_incr);\n\n\n\n    for(i=0;i<s->nb_channels;i++)\n\n        s->samples_offset[i] = 0;\n\n\n\n    for(i=0;i<257;i++) {\n\n        int v;\n\n        v = ff_mpa_enwindow[i];\n\n#if WFRAC_BITS != 16\n\n        v = (v + (1 << (16 - WFRAC_BITS - 1))) >> (16 - WFRAC_BITS);\n\n#endif\n\n        s->filter_bank[i] = v;\n\n        if ((i & 63) != 0)\n\n            v = -v;\n\n        if (i != 0)\n\n            s->filter_bank[512 - i] = v;\n\n    }\n\n\n\n    for(i=0;i<64;i++) {\n\n        v = (int)(pow(2.0, (3 - i) / 3.0) * (1 << 20));\n\n        if (v <= 0)\n\n            v = 1;\n\n        s->scale_factor_table[i] = v;\n\n        s->scale_factor_inv_table[i] = pow(2.0, -(3 - i) / 3.0) / (float)(1 << 20);\n\n    }\n\n    for(i=0;i<128;i++) {\n\n        v = i - 64;\n\n        if (v <= -3)\n\n            v = 0;\n\n        else if (v < 0)\n\n            v = 1;\n\n        else if (v == 0)\n\n            v = 2;\n\n        else if (v < 3)\n\n            v = 3;\n\n        else\n\n            v = 4;\n\n        s->scale_diff_table[i] = v;\n\n    }\n\n\n\n    for(i=0;i<17;i++) {\n\n        v = ff_mpa_quant_bits[i];\n\n        if (v < 0)\n\n            v = -v;\n\n        else\n\n            v = v * 3;\n\n        s->total_quant_bits[i] = 12 * v;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25282}
{"project": "FFmpeg", "commit_id": "72dbc610be3272ba36603f78a39cc2d2d8fe0cc3", "target": 0, "func": "void ff_avg_h264_qpel8_mc32_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_midh_qrt_and_aver_dst_8w_msa(src - (2 * stride) - 2,\n\n                                          stride, dst, stride, 8, 1);\n\n}\n", "idx": 25293}
{"project": "FFmpeg", "commit_id": "73bb8f61d48dbf7237df2e9cacd037f12b84b00a", "target": 0, "func": "static void deblocking_filter_CTB(HEVCContext *s, int x0, int y0)\n\n{\n\n    uint8_t *src;\n\n    int x, y, x_end, y_end, chroma;\n\n    int c_tc[2], beta[2], tc[2];\n\n    uint8_t no_p[2] = { 0 };\n\n    uint8_t no_q[2] = { 0 };\n\n\n\n    int log2_ctb_size = s->sps->log2_ctb_size;\n\n    int ctb_size        = 1 << log2_ctb_size;\n\n    int ctb             = (x0 >> log2_ctb_size) +\n\n                          (y0 >> log2_ctb_size) * s->sps->ctb_width;\n\n    int cur_tc_offset   = s->deblock[ctb].tc_offset;\n\n    int cur_beta_offset = s->deblock[ctb].beta_offset;\n\n    int tc_offset, left_tc_offset, beta_offset, left_beta_offset;\n\n    int pcmf = (s->sps->pcm_enabled_flag &&\n\n                s->sps->pcm.loop_filter_disable_flag) ||\n\n               s->pps->transquant_bypass_enable_flag;\n\n\n\n    if (x0) {\n\n        left_tc_offset   = s->deblock[ctb - 1].tc_offset;\n\n        left_beta_offset = s->deblock[ctb - 1].beta_offset;\n\n    }\n\n\n\n    x_end = x0 + ctb_size;\n\n    if (x_end > s->sps->width)\n\n        x_end = s->sps->width;\n\n    y_end = y0 + ctb_size;\n\n    if (y_end > s->sps->height)\n\n        y_end = s->sps->height;\n\n\n\n    tc_offset   = cur_tc_offset;\n\n    beta_offset = cur_beta_offset;\n\n\n\n    // vertical filtering luma\n\n    for (y = y0; y < y_end; y += 8) {\n\n        for (x = x0 ? x0 : 8; x < x_end; x += 8) {\n\n            const int bs0 = s->vertical_bs[(x >> 3) + (y       >> 2) * s->bs_width];\n\n            const int bs1 = s->vertical_bs[(x >> 3) + ((y + 4) >> 2) * s->bs_width];\n\n            if (bs0 || bs1) {\n\n                const int qp0 = (get_qPy(s, x - 1, y)     + get_qPy(s, x, y)     + 1) >> 1;\n\n                const int qp1 = (get_qPy(s, x - 1, y + 4) + get_qPy(s, x, y + 4) + 1) >> 1;\n\n\n\n                beta[0] = betatable[av_clip(qp0 + beta_offset, 0, MAX_QP)];\n\n                beta[1] = betatable[av_clip(qp1 + beta_offset, 0, MAX_QP)];\n\n                tc[0]   = bs0 ? TC_CALC(qp0, bs0) : 0;\n\n                tc[1]   = bs1 ? TC_CALC(qp1, bs1) : 0;\n\n                src     = &s->frame->data[LUMA][y * s->frame->linesize[LUMA] + (x << s->sps->pixel_shift)];\n\n                if (pcmf) {\n\n                    no_p[0] = get_pcm(s, x - 1, y);\n\n                    no_p[1] = get_pcm(s, x - 1, y + 4);\n\n                    no_q[0] = get_pcm(s, x, y);\n\n                    no_q[1] = get_pcm(s, x, y + 4);\n\n                    s->hevcdsp.hevc_v_loop_filter_luma_c(src,\n\n                                                         s->frame->linesize[LUMA],\n\n                                                         beta, tc, no_p, no_q);\n\n                } else\n\n                    s->hevcdsp.hevc_v_loop_filter_luma(src,\n\n                                                       s->frame->linesize[LUMA],\n\n                                                       beta, tc, no_p, no_q);\n\n            }\n\n        }\n\n    }\n\n\n\n    // vertical filtering chroma\n\n    for (chroma = 1; chroma <= 2; chroma++) {\n\n        for (y = y0; y < y_end; y += 16) {\n\n            for (x = x0 ? x0 : 16; x < x_end; x += 16) {\n\n                const int bs0 = s->vertical_bs[(x >> 3) + (y       >> 2) * s->bs_width];\n\n                const int bs1 = s->vertical_bs[(x >> 3) + ((y + 8) >> 2) * s->bs_width];\n\n                if ((bs0 == 2) || (bs1 == 2)) {\n\n                    const int qp0 = (get_qPy(s, x - 1, y)     + get_qPy(s, x, y)     + 1) >> 1;\n\n                    const int qp1 = (get_qPy(s, x - 1, y + 8) + get_qPy(s, x, y + 8) + 1) >> 1;\n\n\n\n                    c_tc[0] = (bs0 == 2) ? chroma_tc(s, qp0, chroma, tc_offset) : 0;\n\n                    c_tc[1] = (bs1 == 2) ? chroma_tc(s, qp1, chroma, tc_offset) : 0;\n\n                    src     = &s->frame->data[chroma][y / 2 * s->frame->linesize[chroma] + ((x / 2) << s->sps->pixel_shift)];\n\n                    if (pcmf) {\n\n                        no_p[0] = get_pcm(s, x - 1, y);\n\n                        no_p[1] = get_pcm(s, x - 1, y + 8);\n\n                        no_q[0] = get_pcm(s, x, y);\n\n                        no_q[1] = get_pcm(s, x, y + 8);\n\n                        s->hevcdsp.hevc_v_loop_filter_chroma_c(src,\n\n                                                               s->frame->linesize[chroma],\n\n                                                               c_tc, no_p, no_q);\n\n                    } else\n\n                        s->hevcdsp.hevc_v_loop_filter_chroma(src,\n\n                                                             s->frame->linesize[chroma],\n\n                                                             c_tc, no_p, no_q);\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    // horizontal filtering luma\n\n    if (x_end != s->sps->width)\n\n        x_end -= 8;\n\n    for (y = y0 ? y0 : 8; y < y_end; y += 8) {\n\n        for (x = x0 ? x0 - 8 : 0; x < x_end; x += 8) {\n\n            const int bs0 = s->horizontal_bs[(x +     y * s->bs_width) >> 2];\n\n            const int bs1 = s->horizontal_bs[(x + 4 + y * s->bs_width) >> 2];\n\n            if (bs0 || bs1) {\n\n                const int qp0 = (get_qPy(s, x, y - 1)     + get_qPy(s, x, y)     + 1) >> 1;\n\n                const int qp1 = (get_qPy(s, x + 4, y - 1) + get_qPy(s, x + 4, y) + 1) >> 1;\n\n\n\n                tc_offset   = x >= x0 ? cur_tc_offset : left_tc_offset;\n\n                beta_offset = x >= x0 ? cur_beta_offset : left_beta_offset;\n\n\n\n                beta[0] = betatable[av_clip(qp0 + beta_offset, 0, MAX_QP)];\n\n                beta[1] = betatable[av_clip(qp1 + beta_offset, 0, MAX_QP)];\n\n                tc[0]   = bs0 ? TC_CALC(qp0, bs0) : 0;\n\n                tc[1]   = bs1 ? TC_CALC(qp1, bs1) : 0;\n\n                src     = &s->frame->data[LUMA][y * s->frame->linesize[LUMA] + (x << s->sps->pixel_shift)];\n\n                if (pcmf) {\n\n                    no_p[0] = get_pcm(s, x, y - 1);\n\n                    no_p[1] = get_pcm(s, x + 4, y - 1);\n\n                    no_q[0] = get_pcm(s, x, y);\n\n                    no_q[1] = get_pcm(s, x + 4, y);\n\n                    s->hevcdsp.hevc_h_loop_filter_luma_c(src,\n\n                                                         s->frame->linesize[LUMA],\n\n                                                         beta, tc, no_p, no_q);\n\n                } else\n\n                    s->hevcdsp.hevc_h_loop_filter_luma(src,\n\n                                                       s->frame->linesize[LUMA],\n\n                                                       beta, tc, no_p, no_q);\n\n            }\n\n        }\n\n    }\n\n\n\n    // horizontal filtering chroma\n\n    for (chroma = 1; chroma <= 2; chroma++) {\n\n        for (y = y0 ? y0 : 16; y < y_end; y += 16) {\n\n            for (x = x0 - 8; x < x_end; x += 16) {\n\n                int bs0, bs1;\n\n                // to make sure no memory access over boundary when x = -8\n\n                // TODO: simplify with row based deblocking\n\n                if (x < 0) {\n\n                    bs0 = 0;\n\n                    bs1 = s->horizontal_bs[(x + 8 + y * s->bs_width) >> 2];\n\n                } else if (x >= x_end - 8) {\n\n                    bs0 = s->horizontal_bs[(x +     y * s->bs_width) >> 2];\n\n                    bs1 = 0;\n\n                } else {\n\n                    bs0 = s->horizontal_bs[(x + y     * s->bs_width) >> 2];\n\n                    bs1 = s->horizontal_bs[(x + 8 + y * s->bs_width) >> 2];\n\n                }\n\n\n\n                if ((bs0 == 2) || (bs1 == 2)) {\n\n                    const int qp0 = bs0 == 2 ? (get_qPy(s, x,     y - 1) + get_qPy(s, x,     y) + 1) >> 1 : 0;\n\n                    const int qp1 = bs1 == 2 ? (get_qPy(s, x + 8, y - 1) + get_qPy(s, x + 8, y) + 1) >> 1 : 0;\n\n\n\n                    tc_offset = x >= x0 ? cur_tc_offset : left_tc_offset;\n\n                    c_tc[0]   = bs0 == 2 ? chroma_tc(s, qp0, chroma, tc_offset)     : 0;\n\n                    c_tc[1]   = bs1 == 2 ? chroma_tc(s, qp1, chroma, cur_tc_offset) : 0;\n\n                    src       = &s->frame->data[chroma][y / 2 * s->frame->linesize[chroma] + ((x / 2) << s->sps->pixel_shift)];\n\n                    if (pcmf) {\n\n                        no_p[0] = get_pcm(s, x, y - 1);\n\n                        no_p[1] = get_pcm(s, x + 8, y - 1);\n\n                        no_q[0] = get_pcm(s, x, y);\n\n                        no_q[1] = get_pcm(s, x + 8, y);\n\n                        s->hevcdsp.hevc_h_loop_filter_chroma_c(src,\n\n                                                               s->frame->linesize[chroma],\n\n                                                               c_tc, no_p, no_q);\n\n                    } else\n\n                        s->hevcdsp.hevc_h_loop_filter_chroma(src,\n\n                                                             s->frame->linesize[chroma],\n\n                                                             c_tc, no_p, no_q);\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 25296}
{"project": "FFmpeg", "commit_id": "486637af8ef29ec215e0e0b7ecd3b5470f0e04e5", "target": 0, "func": "static inline void mix_2f_2r_to_dolby(AC3DecodeContext *ctx)\n\n{\n\n    int i;\n\n    float (*output)[256] = ctx->audio_block.block_output;\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        output[1][i] -= output[3][i];\n\n        output[2][i] += output[4][i];\n\n    }\n\n    memset(output[3], 0, sizeof(output[3]));\n\n    memset(output[4], 0, sizeof(output[4]));\n\n}\n", "idx": 25297}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "int ff_qsv_enc_close(AVCodecContext *avctx, QSVEncContext *q)\n\n{\n\n    QSVFrame *cur;\n\n\n\n    MFXVideoENCODE_Close(q->session);\n\n    if (q->internal_session)\n\n        MFXClose(q->internal_session);\n\n    q->session          = NULL;\n\n    q->internal_session = NULL;\n\n\n\n    cur = q->work_frames;\n\n    while (cur) {\n\n        q->work_frames = cur->next;\n\n        av_frame_free(&cur->frame);\n\n        av_freep(&cur);\n\n        cur = q->work_frames;\n\n    }\n\n\n\n    while (q->async_fifo && av_fifo_size(q->async_fifo)) {\n\n        AVPacket pkt;\n\n        mfxSyncPoint sync;\n\n        mfxBitstream *bs;\n\n\n\n        av_fifo_generic_read(q->async_fifo, &pkt,  sizeof(pkt),  NULL);\n\n        av_fifo_generic_read(q->async_fifo, &sync, sizeof(sync), NULL);\n\n        av_fifo_generic_read(q->async_fifo, &bs,   sizeof(bs),   NULL);\n\n\n\n        av_freep(&bs);\n\n        av_packet_unref(&pkt);\n\n    }\n\n    av_fifo_free(q->async_fifo);\n\n    q->async_fifo = NULL;\n\n\n\n    av_frame_free(&avctx->coded_frame);\n\n\n\n    return 0;\n\n}\n", "idx": 25298}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int raw_encode_init(AVCodecContext *avctx)\n\n{\n\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(avctx->pix_fmt);\n\n\n\n    avctx->coded_frame            = av_frame_alloc();\n\n    if (!avctx->coded_frame)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;\n\n    avctx->coded_frame->key_frame = 1;\n\n    avctx->bits_per_coded_sample = av_get_bits_per_pixel(desc);\n\n    if(!avctx->codec_tag)\n\n        avctx->codec_tag = avcodec_pix_fmt_to_codec_tag(avctx->pix_fmt);\n\n    return 0;\n\n}\n", "idx": 25299}
{"project": "FFmpeg", "commit_id": "3d95d27376e59de14f984e7a22a52e066d85df35", "target": 1, "func": "int ff_audio_mix(AudioMix *am, AudioData *src)\n\n{\n\n    int use_generic = 1;\n\n    int len = src->nb_samples;\n\n    int i, j;\n\n\n\n    /* determine whether to use the optimized function based on pointer and\n\n       samples alignment in both the input and output */\n\n    if (am->has_optimized_func) {\n\n        int aligned_len = FFALIGN(len, am->samples_align);\n\n        if (!(src->ptr_align % am->ptr_align) &&\n\n            src->samples_align >= aligned_len) {\n\n            len = aligned_len;\n\n            use_generic = 0;\n\n        }\n\n    }\n\n    av_dlog(am->avr, \"audio_mix: %d samples - %d to %d channels (%s)\\n\",\n\n            src->nb_samples, am->in_channels, am->out_channels,\n\n            use_generic ? am->func_descr_generic : am->func_descr);\n\n\n\n    if (am->in_matrix_channels && am->out_matrix_channels) {\n\n        uint8_t **data;\n\n        uint8_t *data0[AVRESAMPLE_MAX_CHANNELS];\n\n\n\n        if (am->out_matrix_channels < am->out_channels ||\n\n             am->in_matrix_channels <  am->in_channels) {\n\n            for (i = 0, j = 0; i < FFMAX(am->in_channels, am->out_channels); i++) {\n\n                if (am->input_skip[i] || am->output_skip[i] || am->output_zero[i])\n\n                    continue;\n\n                data0[j++] = src->data[i];\n\n            }\n\n            data = data0;\n\n        } else {\n\n            data = src->data;\n\n        }\n\n\n\n        if (use_generic)\n\n            am->mix_generic(data, am->matrix, len, am->out_matrix_channels,\n\n                            am->in_matrix_channels);\n\n        else\n\n            am->mix(data, am->matrix, len, am->out_matrix_channels,\n\n                    am->in_matrix_channels);\n\n    }\n\n\n\n    if (am->out_matrix_channels < am->out_channels) {\n\n        for (i = 0; i < am->out_channels; i++)\n\n            if (am->output_zero[i])\n\n                av_samples_set_silence(&src->data[i], 0, len, 1, am->fmt);\n\n    }\n\n\n\n    ff_audio_data_set_channels(src, am->out_channels);\n\n\n\n    return 0;\n\n}\n", "idx": 25300}
{"project": "FFmpeg", "commit_id": "091bc6ca8c643bfece2c70ff2404c7b31574e1f1", "target": 0, "func": "static void mm_decode_intra(MmContext * s, int half_horiz, int half_vert, const uint8_t *buf, int buf_size)\n\n{\n\n    int i, x, y;\n\n    i=0; x=0; y=0;\n\n\n\n    while(i<buf_size) {\n\n        int run_length, color;\n\n\n\n        if (buf[i] & 0x80) {\n\n            run_length = 1;\n\n            color = buf[i];\n\n            i++;\n\n        }else{\n\n            run_length = (buf[i] & 0x7f) + 2;\n\n            color = buf[i+1];\n\n            i+=2;\n\n        }\n\n\n\n        if (half_horiz)\n\n            run_length *=2;\n\n\n\n        if (color) {\n\n            memset(s->frame.data[0] + y*s->frame.linesize[0] + x, color, run_length);\n\n            if (half_vert)\n\n                memset(s->frame.data[0] + (y+1)*s->frame.linesize[0] + x, color, run_length);\n\n        }\n\n        x+= run_length;\n\n\n\n        if (x >= s->avctx->width) {\n\n            x=0;\n\n            y += half_vert ? 2 : 1;\n\n        }\n\n    }\n\n}\n", "idx": 25303}
{"project": "FFmpeg", "commit_id": "0247bdee2581a6857a24c5ff297f01d3a3112b11", "target": 1, "func": "void av_log_default_callback(void* ptr, int level, const char* fmt, va_list vl)\n\n{\n\n    static int print_prefix=1;\n\n    static int count;\n\n    static char line[1024], prev[1024];\n\n    static int is_atty;\n\n    AVClass* avc= ptr ? *(AVClass**)ptr : NULL;\n\n    if(level>av_log_level)\n\n        return;\n\n    line[0]=0;\n\n#undef fprintf\n\n    if(print_prefix && avc) {\n\n        if (avc->parent_log_context_offset) {\n\n            AVClass** parent= *(AVClass***)(((uint8_t*)ptr) + avc->parent_log_context_offset);\n\n            if(parent && *parent){\n\n                snprintf(line, sizeof(line), \"[%s @ %p] \", (*parent)->item_name(parent), parent);\n\n            }\n\n        }\n\n        snprintf(line + strlen(line), sizeof(line) - strlen(line), \"[%s @ %p] \", avc->item_name(ptr), ptr);\n\n    }\n\n\n\n    vsnprintf(line + strlen(line), sizeof(line) - strlen(line), fmt, vl);\n\n\n\n    print_prefix= line[strlen(line)-1] == '\\n';\n\n\n\n#if HAVE_ISATTY\n\n    if(!is_atty) is_atty= isatty(2) ? 1 : -1;\n\n#endif\n\n\n\n    if(print_prefix && (flags & AV_LOG_SKIP_REPEATED) && !strcmp(line, prev)){\n\n        count++;\n\n        if(is_atty==1)\n\n            fprintf(stderr, \"    Last message repeated %d times\\r\", count);\n\n        return;\n\n    }\n\n    if(count>0){\n\n        fprintf(stderr, \"    Last message repeated %d times\\n\", count);\n\n        count=0;\n\n    }\n\n    colored_fputs(av_clip(level>>3, 0, 6), line);\n\n    strcpy(prev, line);\n\n}\n", "idx": 25305}
{"project": "FFmpeg", "commit_id": "15c41cb6adc4d6720d51c21f8baebebce923b213", "target": 1, "func": "void ff_thread_await_progress(ThreadFrame *f, int n, int field)\n\n{\n\n    PerThreadContext *p;\n\n    atomic_int *progress = f->progress ? (atomic_int*)f->progress->data : NULL;\n\n\n\n    if (!progress ||\n\n        atomic_load_explicit(&progress[field], memory_order_acquire) >= n)\n\n        return;\n\n\n\n    p = f->owner[field]->internal->thread_ctx;\n\n\n\n    pthread_mutex_lock(&p->progress_mutex);\n\n    if (f->owner[field]->debug&FF_DEBUG_THREADS)\n\n        av_log(f->owner[field], AV_LOG_DEBUG,\n\n               \"thread awaiting %d field %d from %p\\n\", n, field, progress);\n\n    while (atomic_load_explicit(&progress[field], memory_order_relaxed) < n)\n\n        pthread_cond_wait(&p->progress_cond, &p->progress_mutex);\n\n    pthread_mutex_unlock(&p->progress_mutex);\n\n}\n", "idx": 25306}
{"project": "FFmpeg", "commit_id": "eb74839caa2c50018b1d5a88a43c3da9f4345a8d", "target": 0, "func": "int av_opt_is_set_to_default(void *obj, const AVOption *o)\n\n{\n\n    int64_t i64;\n\n    double d, d2;\n\n    float f;\n\n    AVRational q;\n\n    int ret, w, h;\n\n    char *str;\n\n    void *dst;\n\n\n\n    if (!o || !obj)\n\n        return AVERROR(EINVAL);\n\n\n\n    dst = ((uint8_t*)obj) + o->offset;\n\n\n\n    switch (o->type) {\n\n    case AV_OPT_TYPE_CONST:\n\n        return 1;\n\n    case AV_OPT_TYPE_FLAGS:\n\n    case AV_OPT_TYPE_PIXEL_FMT:\n\n    case AV_OPT_TYPE_SAMPLE_FMT:\n\n    case AV_OPT_TYPE_INT:\n\n    case AV_OPT_TYPE_CHANNEL_LAYOUT:\n\n    case AV_OPT_TYPE_DURATION:\n\n    case AV_OPT_TYPE_INT64:\n\n        read_number(o, dst, NULL, NULL, &i64);\n\n        return o->default_val.i64 == i64;\n\n    case AV_OPT_TYPE_STRING:\n\n        str = *(char **)dst;\n\n        if (str == o->default_val.str) //2 NULLs\n\n            return 1;\n\n        if (!str || !o->default_val.str) //1 NULL\n\n            return 0;\n\n        return !strcmp(str, o->default_val.str);\n\n    case AV_OPT_TYPE_DOUBLE:\n\n        read_number(o, dst, &d, NULL, NULL);\n\n        return o->default_val.dbl == d;\n\n    case AV_OPT_TYPE_FLOAT:\n\n        read_number(o, dst, &d, NULL, NULL);\n\n        f = o->default_val.dbl;\n\n        d2 = f;\n\n        return d2 == d;\n\n    case AV_OPT_TYPE_RATIONAL:\n\n        q = av_d2q(o->default_val.dbl, INT_MAX);\n\n        return !av_cmp_q(*(AVRational*)dst, q);\n\n    case AV_OPT_TYPE_BINARY: {\n\n        struct {\n\n            uint8_t *data;\n\n            int size;\n\n        } tmp = {0};\n\n        int opt_size = *(int *)((void **)dst + 1);\n\n        void *opt_ptr = *(void **)dst;\n\n        if (!opt_ptr && (!o->default_val.str || !strlen(o->default_val.str)))\n\n            return 1;\n\n        if (opt_ptr && o->default_val.str && !strlen(o->default_val.str))\n\n            return 0;\n\n        if (opt_size != strlen(o->default_val.str) / 2)\n\n            return 0;\n\n        ret = set_string_binary(NULL, NULL, o->default_val.str, &tmp.data);\n\n        if (!ret)\n\n            ret = !memcmp(opt_ptr, tmp.data, tmp.size);\n\n        av_free(tmp.data);\n\n        return ret;\n\n    }\n\n    case AV_OPT_TYPE_DICT:\n\n        /* Binary and dict have not default support yet. Any pointer is not default. */\n\n        return !!(*(void **)dst);\n\n    case AV_OPT_TYPE_IMAGE_SIZE:\n\n        if (!o->default_val.str || !strcmp(o->default_val.str, \"none\"))\n\n            w = h = 0;\n\n        else if ((ret = av_parse_video_size(&w, &h, o->default_val.str)) < 0)\n\n            return ret;\n\n        return (w == *(int *)dst) && (h == *((int *)dst+1));\n\n    case AV_OPT_TYPE_VIDEO_RATE:\n\n        q = (AVRational){0, 0};\n\n        if (o->default_val.str)\n\n            av_parse_video_rate(&q, o->default_val.str);\n\n        return !av_cmp_q(*(AVRational*)dst, q);\n\n    case AV_OPT_TYPE_COLOR: {\n\n        uint8_t color[4] = {0, 0, 0, 0};\n\n        if (o->default_val.str)\n\n            av_parse_color(color, o->default_val.str, -1, NULL);\n\n        return !memcmp(color, dst, sizeof(color));\n\n    }\n\n    default:\n\n        av_log(obj, AV_LOG_WARNING, \"Not supported option type: %d, option name: %s\\n\", o->type, o->name);\n\n        break;\n\n    }\n\n    return AVERROR_PATCHWELCOME;\n\n}\n", "idx": 25308}
{"project": "FFmpeg", "commit_id": "934982c4ace1a3d5d627b518782ed092a456c49e", "target": 0, "func": "static int indeo3_decode_frame(AVCodecContext *avctx,\n\n                               void *data, int *data_size,\n\n                               unsigned char *buf, int buf_size)\n\n{\n\n    Indeo3DecodeContext *s=avctx->priv_data;\n\n    unsigned char *src, *dest;\n\n    int y;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0) {\n\n        return 0;\n\n    }\n\n\n\n    iv_decode_frame(s, buf, buf_size);\n\n\n\n    if(s->frame.data[0])\n\n        avctx->release_buffer(avctx, &s->frame);\n\n\n\n    s->frame.reference = 0;\n\n    if(avctx->get_buffer(avctx, &s->frame) < 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    src = s->cur_frame->Ybuf;\n\n    dest = s->frame.data[0];\n\n    for (y = 0; y < s->height; y++) {\n\n      memcpy(dest, src, s->cur_frame->y_w);\n\n      src += s->cur_frame->y_w;\n\n      dest += s->frame.linesize[0];\n\n    }\n\n\n\n    if (!(s->avctx->flags & CODEC_FLAG_GRAY))\n\n    {\n\n    src = s->cur_frame->Ubuf;\n\n    dest = s->frame.data[1];\n\n    for (y = 0; y < s->height / 4; y++) {\n\n      memcpy(dest, src, s->cur_frame->uv_w);\n\n      src += s->cur_frame->uv_w;\n\n      dest += s->frame.linesize[1];\n\n    }\n\n\n\n    src = s->cur_frame->Vbuf;\n\n    dest = s->frame.data[2];\n\n    for (y = 0; y < s->height / 4; y++) {\n\n      memcpy(dest, src, s->cur_frame->uv_w);\n\n      src += s->cur_frame->uv_w;\n\n      dest += s->frame.linesize[2];\n\n    }\n\n    }\n\n\n\n    *data_size=sizeof(AVFrame);\n\n    *(AVFrame*)data= s->frame;\n\n\n\n    return buf_size;\n\n}\n", "idx": 25309}
{"project": "FFmpeg", "commit_id": "ed16c2dbf47cdd7c48825b4da6e7036698e5dde1", "target": 0, "func": "void ff_h261_loop_filter(MpegEncContext *s){\n\n    H261Context * h= (H261Context*)s;\n\n    const int linesize  = s->linesize;\n\n    const int uvlinesize= s->uvlinesize;\n\n    uint8_t *dest_y = s->dest[0];\n\n    uint8_t *dest_cb= s->dest[1];\n\n    uint8_t *dest_cr= s->dest[2];\n\n\n\n    if(!(IS_FIL (h->mtype)))\n\n        return;\n\n\n\n    s->dsp.h261_loop_filter(dest_y                   , linesize);\n\n    s->dsp.h261_loop_filter(dest_y                + 8, linesize);\n\n    s->dsp.h261_loop_filter(dest_y + 8 * linesize    , linesize);\n\n    s->dsp.h261_loop_filter(dest_y + 8 * linesize + 8, linesize);\n\n    s->dsp.h261_loop_filter(dest_cb, uvlinesize);\n\n    s->dsp.h261_loop_filter(dest_cr, uvlinesize);\n\n}\n", "idx": 25311}
{"project": "FFmpeg", "commit_id": "6ba5cbc699e77cae66bb719354fa142114b64eab", "target": 0, "func": "int udp_set_remote_url(URLContext *h, const char *uri)\n\n{\n\n    UDPContext *s = h->priv_data;\n\n    char hostname[256];\n\n    int port;\n\n    \n\n    url_split(NULL, 0, hostname, sizeof(hostname), &port, NULL, 0, uri);\n\n\n\n    /* set the destination address */\n\n    if (resolve_host(&s->dest_addr.sin_addr, hostname) < 0)\n\n        return AVERROR_IO;\n\n    s->dest_addr.sin_family = AF_INET;\n\n    s->dest_addr.sin_port = htons(port);\n\n    return 0;\n\n}\n", "idx": 25322}
{"project": "FFmpeg", "commit_id": "61f70416f8542cc86c84ae6e0342ba10a35d7cba", "target": 1, "func": "static int parse_tonal(DCALbrDecoder *s, int group)\n\n{\n\n    unsigned int amp[DCA_LBR_CHANNELS_TOTAL];\n\n    unsigned int phs[DCA_LBR_CHANNELS_TOTAL];\n\n    unsigned int diff, main_amp, shift;\n\n    int sf, sf_idx, ch, main_ch, freq;\n\n    int ch_nbits = av_ceil_log2(s->nchannels_total);\n\n\n\n    // Parse subframes for this group\n\n    for (sf = 0; sf < 1 << group; sf += diff ? 8 : 1) {\n\n        sf_idx = ((s->framenum << group) + sf) & 31;\n\n        s->tonal_bounds[group][sf_idx][0] = s->ntones;\n\n\n\n        // Parse tones for this subframe\n\n        for (freq = 1;; freq++) {\n\n            if (get_bits_left(&s->gb) < 1) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"Tonal group chunk too short\\n\");\n\n                return -1;\n\n            }\n\n\n\n            diff = parse_vlc(&s->gb, &ff_dca_vlc_tnl_grp[group], 2);\n\n            if (diff >= FF_ARRAY_ELEMS(ff_dca_fst_amp)) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"Invalid tonal frequency diff\\n\");\n\n                return -1;\n\n            }\n\n\n\n            diff = get_bitsz(&s->gb, diff >> 2) + ff_dca_fst_amp[diff];\n\n            if (diff <= 1)\n\n                break;  // End of subframe\n\n\n\n            freq += diff - 2;\n\n            if (freq >> (5 - group) > s->nsubbands * 4 - 5) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"Invalid spectral line offset\\n\");\n\n                return -1;\n\n            }\n\n\n\n            // Main channel\n\n            main_ch = get_bitsz(&s->gb, ch_nbits);\n\n            main_amp = parse_vlc(&s->gb, &ff_dca_vlc_tnl_scf, 2)\n\n                + s->tonal_scf[ff_dca_freq_to_sb[freq >> (7 - group)]]\n\n                + s->limited_range - 2;\n\n            amp[main_ch] = main_amp < AMP_MAX ? main_amp : 0;\n\n            phs[main_ch] = get_bits(&s->gb, 3);\n\n\n\n            // Secondary channels\n\n            for (ch = 0; ch < s->nchannels_total; ch++) {\n\n                if (ch == main_ch)\n\n                    continue;\n\n                if (get_bits1(&s->gb)) {\n\n                    amp[ch] = amp[main_ch] - parse_vlc(&s->gb, &ff_dca_vlc_damp, 1);\n\n                    phs[ch] = phs[main_ch] - parse_vlc(&s->gb, &ff_dca_vlc_dph,  1);\n\n                } else {\n\n                    amp[ch] = 0;\n\n                    phs[ch] = 0;\n\n                }\n\n            }\n\n\n\n            if (amp[main_ch]) {\n\n                // Allocate new tone\n\n                DCALbrTone *t = &s->tones[s->ntones];\n\n                s->ntones = (s->ntones + 1) & (DCA_LBR_TONES - 1);\n\n\n\n                t->x_freq = freq >> (5 - group);\n\n                t->f_delt = (freq & ((1 << (5 - group)) - 1)) << group;\n\n                t->ph_rot = 256 - (t->x_freq & 1) * 128 - t->f_delt * 4;\n\n\n\n                shift = ff_dca_ph0_shift[(t->x_freq & 3) * 2 + (freq & 1)]\n\n                    - ((t->ph_rot << (5 - group)) - t->ph_rot);\n\n\n\n                for (ch = 0; ch < s->nchannels; ch++) {\n\n                    t->amp[ch] = amp[ch] < AMP_MAX ? amp[ch] : 0;\n\n                    t->phs[ch] = 128 - phs[ch] * 32 + shift;\n\n                }\n\n            }\n\n        }\n\n\n\n        s->tonal_bounds[group][sf_idx][1] = s->ntones;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25333}
{"project": "FFmpeg", "commit_id": "cf818be4f2f1e06bf63da3a6b55a4c3620952070", "target": 1, "func": "static int make_cdt16_entry(int p1, int p2, int16_t *cdt)\n\n{\n\n    int r, b, lo;\n\n\n\n    b = cdt[p2];\n\n    r = cdt[p1] << 11;\n\n    lo = b + r;\n\n    return (lo + (lo << 16)) << 1;\n\n}\n", "idx": 25335}
{"project": "FFmpeg", "commit_id": "e708afd3c026a9eb547dab07781320a7e2564312", "target": 1, "func": "void ff_estimate_p_frame_motion(MpegEncContext * s,\n\n                                int mb_x, int mb_y)\n\n{\n\n    MotionEstContext * const c= &s->me;\n\n    uint8_t *pix, *ppix;\n\n    int sum, mx, my, dmin;\n\n    int varc;            ///< the variance of the block (sum of squared (p[y][x]-average))\n\n    int vard;            ///< sum of squared differences with the estimated motion vector\n\n    int P[10][2];\n\n    const int shift= 1+s->quarter_sample;\n\n    int mb_type=0;\n\n    Picture * const pic= &s->current_picture;\n\n\n\n    init_ref(c, s->new_picture.f.data, s->last_picture.f.data, NULL, 16*mb_x, 16*mb_y, 0);\n\n\n\n    assert(s->quarter_sample==0 || s->quarter_sample==1);\n\n    assert(s->linesize == c->stride);\n\n    assert(s->uvlinesize == c->uvstride);\n\n\n\n    c->penalty_factor    = get_penalty_factor(s->lambda, s->lambda2, c->avctx->me_cmp);\n\n    c->sub_penalty_factor= get_penalty_factor(s->lambda, s->lambda2, c->avctx->me_sub_cmp);\n\n    c->mb_penalty_factor = get_penalty_factor(s->lambda, s->lambda2, c->avctx->mb_cmp);\n\n    c->current_mv_penalty= c->mv_penalty[s->f_code] + MAX_MV;\n\n\n\n    get_limits(s, 16*mb_x, 16*mb_y);\n\n    c->skip=0;\n\n\n\n    /* intra / predictive decision */\n\n    pix = c->src[0][0];\n\n    sum = s->dsp.pix_sum(pix, s->linesize);\n\n    varc = s->dsp.pix_norm1(pix, s->linesize) - (((unsigned)(sum*sum))>>8) + 500;\n\n\n\n    pic->mb_mean[s->mb_stride * mb_y + mb_x] = (sum+128)>>8;\n\n    pic->mb_var [s->mb_stride * mb_y + mb_x] = (varc+128)>>8;\n\n    c->mb_var_sum_temp += (varc+128)>>8;\n\n\n\n    if(c->avctx->me_threshold){\n\n        vard= check_input_motion(s, mb_x, mb_y, 1);\n\n\n\n        if((vard+128)>>8 < c->avctx->me_threshold){\n\n            int p_score= FFMIN(vard, varc-500+(s->lambda2>>FF_LAMBDA_SHIFT)*100);\n\n            int i_score= varc-500+(s->lambda2>>FF_LAMBDA_SHIFT)*20;\n\n            pic->mc_mb_var[s->mb_stride * mb_y + mb_x] = (vard+128)>>8;\n\n            c->mc_mb_var_sum_temp += (vard+128)>>8;\n\n            c->scene_change_score+= ff_sqrt(p_score) - ff_sqrt(i_score);\n\n            return;\n\n        }\n\n        if((vard+128)>>8 < c->avctx->mb_threshold)\n\n            mb_type= s->mb_type[mb_x + mb_y*s->mb_stride];\n\n    }\n\n\n\n    switch(s->me_method) {\n\n    case ME_ZERO:\n\n    default:\n\n        no_motion_search(s, &mx, &my);\n\n        mx-= mb_x*16;\n\n        my-= mb_y*16;\n\n        dmin = 0;\n\n        break;\n\n    case ME_X1:\n\n    case ME_EPZS:\n\n       {\n\n            const int mot_stride = s->b8_stride;\n\n            const int mot_xy = s->block_index[0];\n\n\n\n            P_LEFT[0] = s->current_picture.f.motion_val[0][mot_xy - 1][0];\n\n            P_LEFT[1] = s->current_picture.f.motion_val[0][mot_xy - 1][1];\n\n\n\n            if(P_LEFT[0]       > (c->xmax<<shift)) P_LEFT[0]       = (c->xmax<<shift);\n\n\n\n            if(!s->first_slice_line) {\n\n                P_TOP[0]      = s->current_picture.f.motion_val[0][mot_xy - mot_stride    ][0];\n\n                P_TOP[1]      = s->current_picture.f.motion_val[0][mot_xy - mot_stride    ][1];\n\n                P_TOPRIGHT[0] = s->current_picture.f.motion_val[0][mot_xy - mot_stride + 2][0];\n\n                P_TOPRIGHT[1] = s->current_picture.f.motion_val[0][mot_xy - mot_stride + 2][1];\n\n                if(P_TOP[1]      > (c->ymax<<shift)) P_TOP[1]     = (c->ymax<<shift);\n\n                if(P_TOPRIGHT[0] < (c->xmin<<shift)) P_TOPRIGHT[0]= (c->xmin<<shift);\n\n                if(P_TOPRIGHT[1] > (c->ymax<<shift)) P_TOPRIGHT[1]= (c->ymax<<shift);\n\n\n\n                P_MEDIAN[0]= mid_pred(P_LEFT[0], P_TOP[0], P_TOPRIGHT[0]);\n\n                P_MEDIAN[1]= mid_pred(P_LEFT[1], P_TOP[1], P_TOPRIGHT[1]);\n\n\n\n                if(s->out_format == FMT_H263){\n\n                    c->pred_x = P_MEDIAN[0];\n\n                    c->pred_y = P_MEDIAN[1];\n\n                }else { /* mpeg1 at least */\n\n                    c->pred_x= P_LEFT[0];\n\n                    c->pred_y= P_LEFT[1];\n\n                }\n\n            }else{\n\n                c->pred_x= P_LEFT[0];\n\n                c->pred_y= P_LEFT[1];\n\n            }\n\n\n\n        }\n\n        dmin = ff_epzs_motion_search(s, &mx, &my, P, 0, 0, s->p_mv_table, (1<<16)>>shift, 0, 16);\n\n\n\n        break;\n\n    }\n\n\n\n    /* At this point (mx,my) are full-pell and the relative displacement */\n\n    ppix = c->ref[0][0] + (my * s->linesize) + mx;\n\n\n\n    vard = s->dsp.sse[0](NULL, pix, ppix, s->linesize, 16);\n\n\n\n    pic->mc_mb_var[s->mb_stride * mb_y + mb_x] = (vard+128)>>8;\n\n//    pic->mb_cmp_score[s->mb_stride * mb_y + mb_x] = dmin;\n\n    c->mc_mb_var_sum_temp += (vard+128)>>8;\n\n\n\n    if(mb_type){\n\n        int p_score= FFMIN(vard, varc-500+(s->lambda2>>FF_LAMBDA_SHIFT)*100);\n\n        int i_score= varc-500+(s->lambda2>>FF_LAMBDA_SHIFT)*20;\n\n        c->scene_change_score+= ff_sqrt(p_score) - ff_sqrt(i_score);\n\n\n\n        if(mb_type == CANDIDATE_MB_TYPE_INTER){\n\n            c->sub_motion_search(s, &mx, &my, dmin, 0, 0, 0, 16);\n\n            set_p_mv_tables(s, mx, my, 1);\n\n        }else{\n\n            mx <<=shift;\n\n            my <<=shift;\n\n        }\n\n        if(mb_type == CANDIDATE_MB_TYPE_INTER4V){\n\n            h263_mv4_search(s, mx, my, shift);\n\n\n\n            set_p_mv_tables(s, mx, my, 0);\n\n        }\n\n        if(mb_type == CANDIDATE_MB_TYPE_INTER_I){\n\n            interlaced_search(s, 0, s->p_field_mv_table, s->p_field_select_table, mx, my, 1);\n\n        }\n\n    }else if(c->avctx->mb_decision > FF_MB_DECISION_SIMPLE){\n\n        int p_score= FFMIN(vard, varc-500+(s->lambda2>>FF_LAMBDA_SHIFT)*100);\n\n        int i_score= varc-500+(s->lambda2>>FF_LAMBDA_SHIFT)*20;\n\n        c->scene_change_score+= ff_sqrt(p_score) - ff_sqrt(i_score);\n\n\n\n        if (vard*2 + 200*256 > varc)\n\n            mb_type|= CANDIDATE_MB_TYPE_INTRA;\n\n        if (varc*2 + 200*256 > vard || s->qscale > 24){\n\n//        if (varc*2 + 200*256 + 50*(s->lambda2>>FF_LAMBDA_SHIFT) > vard){\n\n            mb_type|= CANDIDATE_MB_TYPE_INTER;\n\n            c->sub_motion_search(s, &mx, &my, dmin, 0, 0, 0, 16);\n\n            if(s->flags&CODEC_FLAG_MV0)\n\n                if(mx || my)\n\n                    mb_type |= CANDIDATE_MB_TYPE_SKIPPED; //FIXME check difference\n\n        }else{\n\n            mx <<=shift;\n\n            my <<=shift;\n\n        }\n\n        if((s->flags&CODEC_FLAG_4MV)\n\n           && !c->skip && varc>50<<8 && vard>10<<8){\n\n            if(h263_mv4_search(s, mx, my, shift) < INT_MAX)\n\n                mb_type|=CANDIDATE_MB_TYPE_INTER4V;\n\n\n\n            set_p_mv_tables(s, mx, my, 0);\n\n        }else\n\n            set_p_mv_tables(s, mx, my, 1);\n\n        if((s->flags&CODEC_FLAG_INTERLACED_ME)\n\n           && !c->skip){ //FIXME varc/d checks\n\n            if(interlaced_search(s, 0, s->p_field_mv_table, s->p_field_select_table, mx, my, 0) < INT_MAX)\n\n                mb_type |= CANDIDATE_MB_TYPE_INTER_I;\n\n        }\n\n    }else{\n\n        int intra_score, i;\n\n        mb_type= CANDIDATE_MB_TYPE_INTER;\n\n\n\n        dmin= c->sub_motion_search(s, &mx, &my, dmin, 0, 0, 0, 16);\n\n        if(c->avctx->me_sub_cmp != c->avctx->mb_cmp && !c->skip)\n\n            dmin= ff_get_mb_score(s, mx, my, 0, 0, 0, 16, 1);\n\n\n\n        if((s->flags&CODEC_FLAG_4MV)\n\n           && !c->skip && varc>50<<8 && vard>10<<8){\n\n            int dmin4= h263_mv4_search(s, mx, my, shift);\n\n            if(dmin4 < dmin){\n\n                mb_type= CANDIDATE_MB_TYPE_INTER4V;\n\n                dmin=dmin4;\n\n            }\n\n        }\n\n        if((s->flags&CODEC_FLAG_INTERLACED_ME)\n\n           && !c->skip){ //FIXME varc/d checks\n\n            int dmin_i= interlaced_search(s, 0, s->p_field_mv_table, s->p_field_select_table, mx, my, 0);\n\n            if(dmin_i < dmin){\n\n                mb_type = CANDIDATE_MB_TYPE_INTER_I;\n\n                dmin= dmin_i;\n\n            }\n\n        }\n\n\n\n//        pic->mb_cmp_score[s->mb_stride * mb_y + mb_x] = dmin;\n\n        set_p_mv_tables(s, mx, my, mb_type!=CANDIDATE_MB_TYPE_INTER4V);\n\n\n\n        /* get intra luma score */\n\n        if((c->avctx->mb_cmp&0xFF)==FF_CMP_SSE){\n\n            intra_score= varc - 500;\n\n        }else{\n\n            int mean= (sum+128)>>8;\n\n            mean*= 0x01010101;\n\n\n\n            for(i=0; i<16; i++){\n\n                *(uint32_t*)(&c->scratchpad[i*s->linesize+ 0]) = mean;\n\n                *(uint32_t*)(&c->scratchpad[i*s->linesize+ 4]) = mean;\n\n                *(uint32_t*)(&c->scratchpad[i*s->linesize+ 8]) = mean;\n\n                *(uint32_t*)(&c->scratchpad[i*s->linesize+12]) = mean;\n\n            }\n\n\n\n            intra_score= s->dsp.mb_cmp[0](s, c->scratchpad, pix, s->linesize, 16);\n\n        }\n\n        intra_score += c->mb_penalty_factor*16;\n\n\n\n        if(intra_score < dmin){\n\n            mb_type= CANDIDATE_MB_TYPE_INTRA;\n\n            s->current_picture.f.mb_type[mb_y*s->mb_stride + mb_x] = CANDIDATE_MB_TYPE_INTRA; //FIXME cleanup\n\n        }else\n\n            s->current_picture.f.mb_type[mb_y*s->mb_stride + mb_x] = 0;\n\n\n\n        {\n\n            int p_score= FFMIN(vard, varc-500+(s->lambda2>>FF_LAMBDA_SHIFT)*100);\n\n            int i_score= varc-500+(s->lambda2>>FF_LAMBDA_SHIFT)*20;\n\n            c->scene_change_score+= ff_sqrt(p_score) - ff_sqrt(i_score);\n\n        }\n\n    }\n\n\n\n    s->mb_type[mb_y*s->mb_stride + mb_x]= mb_type;\n\n}\n", "idx": 25341}
{"project": "FFmpeg", "commit_id": "082cf97106e2e94a969877d4f8c05c1e526acf54", "target": 0, "func": "static void filter_mb_mbaff_edgecv( H264Context *h, uint8_t *pix, int stride, int16_t bS[8], int qp[2] ) {\n\n    int i;\n\n    for( i = 0; i < 8; i++, pix += stride) {\n\n        int index_a;\n\n        int alpha;\n\n        int beta;\n\n\n\n        int qp_index;\n\n        int bS_index = i;\n\n\n\n        if( bS[bS_index] == 0 ) {\n\n            continue;\n\n        }\n\n\n\n        qp_index = MB_FIELD ? (i >> 2) : (i & 1);\n\n        index_a = qp[qp_index] + h->slice_alpha_c0_offset;\n\n        alpha = (alpha_table+52)[index_a];\n\n        beta  = (beta_table+52)[qp[qp_index] + h->slice_beta_offset];\n\n\n\n        if( bS[bS_index] < 4 ) {\n\n            const int tc = (tc0_table+52)[index_a][bS[bS_index]] + 1;\n\n            const int p0 = pix[-1];\n\n            const int p1 = pix[-2];\n\n            const int q0 = pix[0];\n\n            const int q1 = pix[1];\n\n\n\n            if( FFABS( p0 - q0 ) < alpha &&\n\n                FFABS( p1 - p0 ) < beta &&\n\n                FFABS( q1 - q0 ) < beta ) {\n\n                const int i_delta = av_clip( (((q0 - p0 ) << 2) + (p1 - q1) + 4) >> 3, -tc, tc );\n\n\n\n                pix[-1] = av_clip_uint8( p0 + i_delta );    /* p0' */\n\n                pix[0]  = av_clip_uint8( q0 - i_delta );    /* q0' */\n\n                tprintf(h->s.avctx, \"filter_mb_mbaff_edgecv i:%d, qp:%d, indexA:%d, alpha:%d, beta:%d, tc:%d\\n# bS:%d -> [%02x, %02x, %02x, %02x, %02x, %02x] =>[%02x, %02x, %02x, %02x]\\n\", i, qp[qp_index], index_a, alpha, beta, tc, bS[bS_index], pix[-3], p1, p0, q0, q1, pix[2], p1, pix[-1], pix[0], q1);\n\n            }\n\n        }else{\n\n            const int p0 = pix[-1];\n\n            const int p1 = pix[-2];\n\n            const int q0 = pix[0];\n\n            const int q1 = pix[1];\n\n\n\n            if( FFABS( p0 - q0 ) < alpha &&\n\n                FFABS( p1 - p0 ) < beta &&\n\n                FFABS( q1 - q0 ) < beta ) {\n\n\n\n                pix[-1] = ( 2*p1 + p0 + q1 + 2 ) >> 2;   /* p0' */\n\n                pix[0]  = ( 2*q1 + q0 + p1 + 2 ) >> 2;   /* q0' */\n\n                tprintf(h->s.avctx, \"filter_mb_mbaff_edgecv i:%d\\n# bS:4 -> [%02x, %02x, %02x, %02x, %02x, %02x] =>[%02x, %02x, %02x, %02x, %02x, %02x]\\n\", i, pix[-3], p1, p0, q0, q1, pix[2], pix[-3], pix[-2], pix[-1], pix[0], pix[1], pix[2]);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 25343}
{"project": "FFmpeg", "commit_id": "4dec101acc393fbfe9a8ce0237b9efbae3f20139", "target": 0, "func": "int ff_dxva2_commit_buffer(AVCodecContext *avctx,\n\n                           AVDXVAContext *ctx,\n\n                           DECODER_BUFFER_DESC *dsc,\n\n                           unsigned type, const void *data, unsigned size,\n\n                           unsigned mb_count)\n\n{\n\n    void     *dxva_data;\n\n    unsigned dxva_size;\n\n    int      result;\n\n    HRESULT hr;\n\n\n\n#if CONFIG_D3D11VA\n\n    if (avctx->pix_fmt == AV_PIX_FMT_D3D11VA_VLD)\n\n        hr = ID3D11VideoContext_GetDecoderBuffer(D3D11VA_CONTEXT(ctx)->video_context,\n\n                                                 D3D11VA_CONTEXT(ctx)->decoder,\n\n                                                 type,\n\n                                                 &dxva_size, &dxva_data);\n\n#endif\n\n#if CONFIG_DXVA2\n\n    if (avctx->pix_fmt == AV_PIX_FMT_DXVA2_VLD)\n\n        hr = IDirectXVideoDecoder_GetBuffer(DXVA2_CONTEXT(ctx)->decoder, type,\n\n                                            &dxva_data, &dxva_size);\n\n#endif\n\n    if (FAILED(hr)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to get a buffer for %u: 0x%x\\n\",\n\n               type, hr);\n\n        return -1;\n\n    }\n\n    if (size <= dxva_size) {\n\n        memcpy(dxva_data, data, size);\n\n\n\n#if CONFIG_D3D11VA\n\n        if (avctx->pix_fmt == AV_PIX_FMT_D3D11VA_VLD) {\n\n            D3D11_VIDEO_DECODER_BUFFER_DESC *dsc11 = dsc;\n\n            memset(dsc11, 0, sizeof(*dsc11));\n\n            dsc11->BufferType           = type;\n\n            dsc11->DataSize             = size;\n\n            dsc11->NumMBsInBuffer       = mb_count;\n\n        }\n\n#endif\n\n#if CONFIG_DXVA2\n\n        if (avctx->pix_fmt == AV_PIX_FMT_DXVA2_VLD) {\n\n            DXVA2_DecodeBufferDesc *dsc2 = dsc;\n\n            memset(dsc2, 0, sizeof(*dsc2));\n\n            dsc2->CompressedBufferType = type;\n\n            dsc2->DataSize             = size;\n\n            dsc2->NumMBsInBuffer       = mb_count;\n\n        }\n\n#endif\n\n\n\n        result = 0;\n\n    } else {\n\n        av_log(avctx, AV_LOG_ERROR, \"Buffer for type %u was too small\\n\", type);\n\n        result = -1;\n\n    }\n\n\n\n#if CONFIG_D3D11VA\n\n    if (avctx->pix_fmt == AV_PIX_FMT_D3D11VA_VLD)\n\n        hr = ID3D11VideoContext_ReleaseDecoderBuffer(D3D11VA_CONTEXT(ctx)->video_context, D3D11VA_CONTEXT(ctx)->decoder, type);\n\n#endif\n\n#if CONFIG_DXVA2\n\n    if (avctx->pix_fmt == AV_PIX_FMT_DXVA2_VLD)\n\n        hr = IDirectXVideoDecoder_ReleaseBuffer(DXVA2_CONTEXT(ctx)->decoder, type);\n\n#endif\n\n    if (FAILED(hr)) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Failed to release buffer type %u: 0x%x\\n\",\n\n               type, hr);\n\n        result = -1;\n\n    }\n\n    return result;\n\n}\n", "idx": 25344}
{"project": "FFmpeg", "commit_id": "0041cdba98d5b636a8d912352dd3d8ca72bba4ce", "target": 0, "func": "int av_seek_frame(AVFormatContext *s, int stream_index, int64_t timestamp, int flags)\n\n{\n\n    int ret;\n\n    AVStream *st;\n\n\n\n    ff_read_frame_flush(s);\n\n\n\n    if(flags & AVSEEK_FLAG_BYTE)\n\n        return seek_frame_byte(s, stream_index, timestamp, flags);\n\n\n\n    if(stream_index < 0){\n\n        stream_index= av_find_default_stream_index(s);\n\n        if(stream_index < 0)\n\n            return -1;\n\n\n\n        st= s->streams[stream_index];\n\n        /* timestamp for default must be expressed in AV_TIME_BASE units */\n\n        timestamp = av_rescale(timestamp, st->time_base.den, AV_TIME_BASE * (int64_t)st->time_base.num);\n\n    }\n\n\n\n    /* first, we try the format specific seek */\n\n    if (s->iformat->read_seek)\n\n        ret = s->iformat->read_seek(s, stream_index, timestamp, flags);\n\n    else\n\n        ret = -1;\n\n    if (ret >= 0) {\n\n        return 0;\n\n    }\n\n\n\n    if(s->iformat->read_timestamp && !(s->iformat->flags & AVFMT_NOBINSEARCH))\n\n        return av_seek_frame_binary(s, stream_index, timestamp, flags);\n\n    else if (!(s->iformat->flags & AVFMT_NOGENSEARCH))\n\n        return seek_frame_generic(s, stream_index, timestamp, flags);\n\n    else\n\n        return -1;\n\n}\n", "idx": 25345}
{"project": "FFmpeg", "commit_id": "b9a07e787bd09036b96370bb87fdf841fe380f9f", "target": 0, "func": "static const char *srt_to_ass(AVCodecContext *avctx, char *out, char *out_end,\n\n                              const char *in, int x1, int y1, int x2, int y2)\n\n{\n\n    char c, *param, buffer[128], tmp[128];\n\n    int len, tag_close, sptr = 1, line_start = 1, an = 0, end = 0;\n\n    SrtStack stack[16];\n\n\n\n    stack[0].tag[0] = 0;\n\n    strcpy(stack[0].param[PARAM_SIZE],  \"{\\\\fs}\");\n\n    strcpy(stack[0].param[PARAM_COLOR], \"{\\\\c}\");\n\n    strcpy(stack[0].param[PARAM_FACE],  \"{\\\\fn}\");\n\n\n\n    if (x1 >= 0 && y1 >= 0) {\n\n        if (x2 >= 0 && y2 >= 0 && (x2 != x1 || y2 != y1))\n\n            out += snprintf(out, out_end-out,\n\n                            \"{\\\\an1}{\\\\move(%d,%d,%d,%d)}\", x1, y1, x2, y2);\n\n        else\n\n            out += snprintf(out, out_end-out, \"{\\\\an1}{\\\\pos(%d,%d)}\", x1, y1);\n\n    }\n\n\n\n    for (; out < out_end && !end && *in; in++) {\n\n        switch (*in) {\n\n        case '\\r':\n\n            break;\n\n        case '\\n':\n\n            if (line_start) {\n\n                end = 1;\n\n                break;\n\n            }\n\n            while (out[-1] == ' ')\n\n                out--;\n\n            out += snprintf(out, out_end-out, \"\\\\N\");\n\n            line_start = 1;\n\n            break;\n\n        case ' ':\n\n            if (!line_start)\n\n                *out++ = *in;\n\n            break;\n\n        case '{':    /* skip all {\\xxx} substrings except for {\\an%d}\n\n                        and all microdvd like styles such as {Y:xxx} */\n\n            an += sscanf(in, \"{\\\\an%*1u}%c\", &c) == 1;\n\n            if ((an != 1 && sscanf(in, \"{\\\\%*[^}]}%n%c\", &len, &c) > 0) ||\n\n                sscanf(in, \"{%*1[CcFfoPSsYy]:%*[^}]}%n%c\", &len, &c) > 0) {\n\n                in += len - 1;\n\n            } else\n\n                *out++ = *in;\n\n            break;\n\n        case '<':\n\n            tag_close = in[1] == '/';\n\n            if (sscanf(in+tag_close+1, \"%127[^>]>%n%c\", buffer, &len,&c) >= 2) {\n\n                if ((param = strchr(buffer, ' ')))\n\n                    *param++ = 0;\n\n                if ((!tag_close && sptr < FF_ARRAY_ELEMS(stack)) ||\n\n                    ( tag_close && sptr > 0 && !strcmp(stack[sptr-1].tag, buffer))) {\n\n                    int i, j, unknown = 0;\n\n                    in += len + tag_close;\n\n                    if (!tag_close)\n\n                        memset(stack+sptr, 0, sizeof(*stack));\n\n                    if (!strcmp(buffer, \"font\")) {\n\n                        if (tag_close) {\n\n                            for (i=PARAM_NUMBER-1; i>=0; i--)\n\n                                if (stack[sptr-1].param[i][0])\n\n                                    for (j=sptr-2; j>=0; j--)\n\n                                        if (stack[j].param[i][0]) {\n\n                                            out += snprintf(out, out_end-out,\n\n                                                            \"%s\", stack[j].param[i]);\n\n                                            break;\n\n                                        }\n\n                        } else {\n\n                            while (param) {\n\n                                if (!strncmp(param, \"size=\", 5)) {\n\n                                    unsigned font_size;\n\n                                    param += 5 + (param[5] == '\"');\n\n                                    if (sscanf(param, \"%u\", &font_size) == 1) {\n\n                                        snprintf(stack[sptr].param[PARAM_SIZE],\n\n                                             sizeof(stack[0].param[PARAM_SIZE]),\n\n                                             \"{\\\\fs%u}\", font_size);\n\n                                    }\n\n                                } else if (!strncmp(param, \"color=\", 6)) {\n\n                                    param += 6 + (param[6] == '\"');\n\n                                    snprintf(stack[sptr].param[PARAM_COLOR],\n\n                                         sizeof(stack[0].param[PARAM_COLOR]),\n\n                                         \"{\\\\c&H%X&}\",\n\n                                         html_color_parse(avctx, param));\n\n                                } else if (!strncmp(param, \"face=\", 5)) {\n\n                                    param += 5 + (param[5] == '\"');\n\n                                    len = strcspn(param,\n\n                                                  param[-1] == '\"' ? \"\\\"\" :\" \");\n\n                                    av_strlcpy(tmp, param,\n\n                                               FFMIN(sizeof(tmp), len+1));\n\n                                    param += len;\n\n                                    snprintf(stack[sptr].param[PARAM_FACE],\n\n                                             sizeof(stack[0].param[PARAM_FACE]),\n\n                                             \"{\\\\fn%s}\", tmp);\n\n                                }\n\n                                if ((param = strchr(param, ' ')))\n\n                                    param++;\n\n                            }\n\n                            for (i=0; i<PARAM_NUMBER; i++)\n\n                                if (stack[sptr].param[i][0])\n\n                                    out += snprintf(out, out_end-out,\n\n                                                    \"%s\", stack[sptr].param[i]);\n\n                        }\n\n                    } else if (!buffer[1] && strspn(buffer, \"bisu\") == 1) {\n\n                        out += snprintf(out, out_end-out,\n\n                                        \"{\\\\%c%d}\", buffer[0], !tag_close);\n\n                    } else {\n\n                        unknown = 1;\n\n                        snprintf(tmp, sizeof(tmp), \"</%s>\", buffer);\n\n                    }\n\n                    if (tag_close) {\n\n                        sptr--;\n\n                    } else if (unknown && !strstr(in, tmp)) {\n\n                        in -= len + tag_close;\n\n                        *out++ = *in;\n\n                    } else\n\n                        av_strlcpy(stack[sptr++].tag, buffer,\n\n                                   sizeof(stack[0].tag));\n\n                    break;\n\n                }\n\n            }\n\n        default:\n\n            *out++ = *in;\n\n            break;\n\n        }\n\n        if (*in != ' ' && *in != '\\r' && *in != '\\n')\n\n            line_start = 0;\n\n    }\n\n\n\n    out = FFMIN(out, out_end-3);\n\n    while (!strncmp(out-2, \"\\\\N\", 2))\n\n        out -= 2;\n\n    while (out[-1] == ' ')\n\n        out--;\n\n    out += snprintf(out, out_end-out, \"\\r\\n\");\n\n    return in;\n\n}\n", "idx": 25346}
{"project": "FFmpeg", "commit_id": "f0ff20a197dd98d2c0ecef3d183185a5c45c7196", "target": 0, "func": "AVResampleContext *av_resample_init(int out_rate, int in_rate, int filter_size, int phase_shift, int linear, double cutoff){\n\n    AVResampleContext *c= av_mallocz(sizeof(AVResampleContext));\n\n    double factor= FFMIN(out_rate * cutoff / in_rate, 1.0);\n\n    int phase_count= 1<<phase_shift;\n\n    \n\n    c->phase_shift= phase_shift;\n\n    c->phase_mask= phase_count-1;\n\n    c->linear= linear;\n\n\n\n    c->filter_length= FFMAX(ceil(filter_size/factor), 1);\n\n    c->filter_bank= av_mallocz(c->filter_length*(phase_count+1)*sizeof(FELEM));\n\n    av_build_filter(c->filter_bank, factor, c->filter_length, phase_count, 1<<FILTER_SHIFT, 1);\n\n    memcpy(&c->filter_bank[c->filter_length*phase_count+1], c->filter_bank, (c->filter_length-1)*sizeof(FELEM));\n\n    c->filter_bank[c->filter_length*phase_count]= c->filter_bank[c->filter_length - 1];\n\n\n\n    c->src_incr= out_rate;\n\n    c->ideal_dst_incr= c->dst_incr= in_rate * phase_count;\n\n    c->index= -phase_count*((c->filter_length-1)/2);\n\n\n\n    return c;\n\n}\n", "idx": 25347}
{"project": "FFmpeg", "commit_id": "baf2ffd3297b707dbb5794ec568c61091acf5c0c", "target": 0, "func": "static int mov_read_elst(MOVContext *c, ByteIOContext *pb, MOVAtom atom)\n\n{\n\n    MOVStreamContext *sc = c->fc->streams[c->fc->nb_streams-1]->priv_data;\n\n    int i, edit_count;\n\n\n\n    get_byte(pb); /* version */\n\n    get_be24(pb); /* flags */\n\n    edit_count= sc->edit_count = get_be32(pb);     /* entries */\n\n\n\n    for(i=0; i<edit_count; i++){\n\n        int time;\n\n        get_be32(pb); /* Track duration */\n\n        time = get_be32(pb); /* Media time */\n\n        get_be32(pb); /* Media rate */\n\n        if (time != 0)\n\n            av_log(c->fc, AV_LOG_WARNING, \"edit list not starting at 0, \"\n\n                   \"a/v desync might occur, patch welcome\\n\");\n\n    }\n\n    dprintf(c->fc, \"track[%i].edit_count = %i\\n\", c->fc->nb_streams-1, sc->edit_count);\n\n    return 0;\n\n}\n", "idx": 25348}
{"project": "FFmpeg", "commit_id": "a181981eb49fc20d1a701fcfebda5cec70def295", "target": 0, "func": "int av_metadata_set(AVMetadata **pm, const char *key, const char *value)\n\n{\n\n    AVMetadata *m= *pm;\n\n    AVMetadataTag *tag= av_metadata_get(m, key, NULL, AV_METADATA_MATCH_CASE);\n\n\n\n    if(!m)\n\n        m=*pm= av_mallocz(sizeof(*m));\n\n\n\n    if(tag){\n\n        av_free(tag->value);\n\n        av_free(tag->key);\n\n        *tag= m->elems[--m->count];\n\n    }else{\n\n        AVMetadataTag *tmp= av_realloc(m->elems, (m->count+1) * sizeof(*m->elems));\n\n        if(tmp){\n\n            m->elems= tmp;\n\n        }else\n\n            return AVERROR(ENOMEM);\n\n    }\n\n    if(value){\n\n        m->elems[m->count].key  = av_strdup(key  );\n\n        m->elems[m->count].value= av_strdup(value);\n\n        m->count++;\n\n    }\n\n    if(!m->count) {\n\n        av_free(m->elems);\n\n        av_freep(pm);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25349}
{"project": "FFmpeg", "commit_id": "a7f27453f64d9020b92b01687baeb5909c6cdad0", "target": 0, "func": "static int mov_read_ares(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    AVCodecContext *codec = c->fc->streams[c->fc->nb_streams-1]->codec;\n\n    if (codec->codec_tag == MKTAG('A', 'V', 'i', 'n') &&\n\n        codec->codec_id == AV_CODEC_ID_H264 &&\n\n        atom.size > 11) {\n\n        avio_skip(pb, 10);\n\n        /* For AVID AVCI50, force width of 1440 to be able to select the correct SPS and PPS */\n\n        if (avio_rb16(pb) == 0xd4d)\n\n            codec->width = 1440;\n\n        return 0;\n\n    }\n\n\n\n    return mov_read_avid(c, pb, atom);\n\n}\n", "idx": 25357}
{"project": "FFmpeg", "commit_id": "332f9ac4e31ce5e6d0c42ac9e0229d7d1b2b4d60", "target": 0, "func": "static int decode_vop_header(MpegEncContext *s, GetBitContext *gb){\n\n    int time_incr, time_increment;\n\n\n\n    s->pict_type = get_bits(gb, 2) + I_TYPE;\t/* pict type: I = 0 , P = 1 */\n\n    if(s->pict_type==B_TYPE && s->low_delay && s->vol_control_parameters==0 && !(s->flags & CODEC_FLAG_LOW_DELAY)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"low_delay flag set, but shouldnt, clearing it\\n\");\n\n        s->low_delay=0;\n\n    }\n\n \n\n    s->partitioned_frame= s->data_partitioning && s->pict_type!=B_TYPE;\n\n    if(s->partitioned_frame)\n\n        s->decode_mb= mpeg4_decode_partitioned_mb;\n\n    else\n\n        s->decode_mb= ff_h263_decode_mb;\n\n\n\n    if(s->time_increment_resolution==0){\n\n        s->time_increment_resolution=1;\n\n//        fprintf(stderr, \"time_increment_resolution is illegal\\n\");\n\n    }\n\n    time_incr=0;\n\n    while (get_bits1(gb) != 0) \n\n        time_incr++;\n\n\n\n    check_marker(gb, \"before time_increment\");\n\n    \n\n    if(s->time_increment_bits==0){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"hmm, seems the headers arnt complete, trying to guess time_increment_bits\\n\");\n\n\n\n        for(s->time_increment_bits=1 ;s->time_increment_bits<16; s->time_increment_bits++){\n\n            if(show_bits(gb, s->time_increment_bits+1)&1) break;\n\n        }\n\n\n\n        av_log(s->avctx, AV_LOG_ERROR, \"my guess is %d bits ;)\\n\",s->time_increment_bits);\n\n    }\n\n    \n\n    if(IS_3IV1) time_increment= get_bits1(gb); //FIXME investigate further\n\n    else time_increment= get_bits(gb, s->time_increment_bits);\n\n    \n\n//    printf(\"%d %X\\n\", s->time_increment_bits, time_increment);\n\n//printf(\" type:%d modulo_time_base:%d increment:%d\\n\", s->pict_type, time_incr, time_increment);\n\n    if(s->pict_type!=B_TYPE){\n\n        s->last_time_base= s->time_base;\n\n        s->time_base+= time_incr;\n\n        s->time= s->time_base*s->time_increment_resolution + time_increment;\n\n        if(s->workaround_bugs&FF_BUG_UMP4){\n\n            if(s->time < s->last_non_b_time){\n\n//                fprintf(stderr, \"header is not mpeg4 compatible, broken encoder, trying to workaround\\n\");\n\n                s->time_base++;\n\n                s->time+= s->time_increment_resolution;\n\n            }\n\n        }\n\n        s->pp_time= s->time - s->last_non_b_time;\n\n        s->last_non_b_time= s->time;\n\n    }else{\n\n        s->time= (s->last_time_base + time_incr)*s->time_increment_resolution + time_increment;\n\n        s->pb_time= s->pp_time - (s->last_non_b_time - s->time);\n\n        if(s->pp_time <=s->pb_time || s->pp_time <= s->pp_time - s->pb_time || s->pp_time<=0){\n\n//            printf(\"messed up order, seeking?, skiping current b frame\\n\");\n\n            return FRAME_SKIPED;\n\n        }\n\n        \n\n        if(s->t_frame==0) s->t_frame= s->time - s->last_time_base;\n\n        if(s->t_frame==0) s->t_frame=1; // 1/0 protection\n\n//printf(\"%Ld %Ld %d %d\\n\", s->last_non_b_time, s->time, s->pp_time, s->t_frame); fflush(stdout);\n\n        s->pp_field_time= (  ROUNDED_DIV(s->last_non_b_time, s->t_frame) \n\n                           - ROUNDED_DIV(s->last_non_b_time - s->pp_time, s->t_frame))*2;\n\n        s->pb_field_time= (  ROUNDED_DIV(s->time, s->t_frame) \n\n                           - ROUNDED_DIV(s->last_non_b_time - s->pp_time, s->t_frame))*2;\n\n    }\n\n    \n\n    s->current_picture_ptr->pts= s->time*1000LL*1000LL / s->time_increment_resolution;\n\n    if(s->avctx->debug&FF_DEBUG_PTS)\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"MPEG4 PTS: %f\\n\", s->current_picture_ptr->pts/(1000.0*1000.0));\n\n    \n\n    check_marker(gb, \"before vop_coded\");\n\n    \n\n    /* vop coded */\n\n    if (get_bits1(gb) != 1){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"vop not coded\\n\");\n\n        return FRAME_SKIPED;\n\n    }\n\n//printf(\"time %d %d %d || %Ld %Ld %Ld\\n\", s->time_increment_bits, s->time_increment_resolution, s->time_base,\n\n//s->time, s->last_non_b_time, s->last_non_b_time - s->pp_time);  \n\n    if (s->shape != BIN_ONLY_SHAPE && ( s->pict_type == P_TYPE\n\n                          || (s->pict_type == S_TYPE && s->vol_sprite_usage==GMC_SPRITE))) {\n\n        /* rounding type for motion estimation */\n\n\ts->no_rounding = get_bits1(gb);\n\n    } else {\n\n\ts->no_rounding = 0;\n\n    }\n\n//FIXME reduced res stuff\n\n\n\n     if (s->shape != RECT_SHAPE) {\n\n         if (s->vol_sprite_usage != 1 || s->pict_type != I_TYPE) {\n\n             int width, height, hor_spat_ref, ver_spat_ref;\n\n \n\n             width = get_bits(gb, 13);\n\n             skip_bits1(gb);   /* marker */\n\n             height = get_bits(gb, 13);\n\n             skip_bits1(gb);   /* marker */\n\n             hor_spat_ref = get_bits(gb, 13); /* hor_spat_ref */\n\n             skip_bits1(gb);   /* marker */\n\n             ver_spat_ref = get_bits(gb, 13); /* ver_spat_ref */\n\n         }\n\n         skip_bits1(gb); /* change_CR_disable */\n\n \n\n         if (get_bits1(gb) != 0) {\n\n             skip_bits(gb, 8); /* constant_alpha_value */\n\n         }\n\n     }\n\n//FIXME complexity estimation stuff\n\n     \n\n     if (s->shape != BIN_ONLY_SHAPE) {\n\n         s->intra_dc_threshold= mpeg4_dc_threshold[ get_bits(gb, 3) ];\n\n         if(!s->progressive_sequence){\n\n             s->top_field_first= get_bits1(gb);\n\n             s->alternate_scan= get_bits1(gb);\n\n         }else\n\n             s->alternate_scan= 0;\n\n     }\n\n\n\n     if(s->alternate_scan){\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->inter_scantable  , ff_alternate_vertical_scan);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_scantable  , ff_alternate_vertical_scan);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_h_scantable, ff_alternate_vertical_scan);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n\n     } else{\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->inter_scantable  , ff_zigzag_direct);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_scantable  , ff_zigzag_direct);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_h_scantable, ff_alternate_horizontal_scan);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n\n     }\n\n \n\n     if(s->pict_type == S_TYPE && (s->vol_sprite_usage==STATIC_SPRITE || s->vol_sprite_usage==GMC_SPRITE)){\n\n         mpeg4_decode_sprite_trajectory(s);\n\n         if(s->sprite_brightness_change) av_log(s->avctx, AV_LOG_ERROR, \"sprite_brightness_change not supported\\n\");\n\n         if(s->vol_sprite_usage==STATIC_SPRITE) av_log(s->avctx, AV_LOG_ERROR, \"static sprite not supported\\n\");\n\n     }\n\n\n\n     if (s->shape != BIN_ONLY_SHAPE) {\n\n         s->qscale = get_bits(gb, s->quant_precision);\n\n         if(s->qscale==0){\n\n             av_log(s->avctx, AV_LOG_ERROR, \"Error, header damaged or not MPEG4 header (qscale=0)\\n\");\n\n             return -1; // makes no sense to continue, as there is nothing left from the image then\n\n         }\n\n  \n\n         if (s->pict_type != I_TYPE) {\n\n             s->f_code = get_bits(gb, 3);\t/* fcode_for */\n\n             if(s->f_code==0){\n\n                 av_log(s->avctx, AV_LOG_ERROR, \"Error, header damaged or not MPEG4 header (f_code=0)\\n\");\n\n                 return -1; // makes no sense to continue, as the MV decoding will break very quickly\n\n             }\n\n         }else\n\n             s->f_code=1;\n\n     \n\n         if (s->pict_type == B_TYPE) {\n\n             s->b_code = get_bits(gb, 3);\n\n         }else\n\n             s->b_code=1;\n\n\n\n         if(s->avctx->debug&FF_DEBUG_PICT_INFO){\n\n             av_log(s->avctx, AV_LOG_DEBUG, \"qp:%d fc:%d,%d %s size:%d pro:%d alt:%d top:%d %spel part:%d resync:%d w:%d a:%d rnd:%d vot:%d%s dc:%d\\n\", \n\n                 s->qscale, s->f_code, s->b_code, \n\n                 s->pict_type == I_TYPE ? \"I\" : (s->pict_type == P_TYPE ? \"P\" : (s->pict_type == B_TYPE ? \"B\" : \"S\")), \n\n                 gb->size_in_bits,s->progressive_sequence, s->alternate_scan, s->top_field_first, \n\n                 s->quarter_sample ? \"q\" : \"h\", s->data_partitioning, s->resync_marker, s->num_sprite_warping_points,\n\n                 s->sprite_warping_accuracy, 1-s->no_rounding, s->vo_type, s->vol_control_parameters ? \" VOLC\" : \" \", s->intra_dc_threshold); \n\n         }\n\n\n\n         if(!s->scalability){\n\n             if (s->shape!=RECT_SHAPE && s->pict_type!=I_TYPE) {\n\n                 skip_bits1(gb); // vop shape coding type\n\n             }\n\n         }else{\n\n             if(s->enhancement_type){\n\n                 int load_backward_shape= get_bits1(gb);\n\n                 if(load_backward_shape){\n\n                     av_log(s->avctx, AV_LOG_ERROR, \"load backward shape isnt supported\\n\");\n\n                 }\n\n             }\n\n             skip_bits(gb, 2); //ref_select_code\n\n         }\n\n     }\n\n     /* detect buggy encoders which dont set the low_delay flag (divx4/xvid/opendivx)*/\n\n     // note we cannot detect divx5 without b-frames easyly (allthough its buggy too)\n\n     if(s->vo_type==0 && s->vol_control_parameters==0 && s->divx_version==0 && s->picture_number==0){\n\n         av_log(s->avctx, AV_LOG_ERROR, \"looks like this file was encoded with (divx4/(old)xvid/opendivx) -> forcing low_delay flag\\n\");\n\n         s->low_delay=1;\n\n     }\n\n\n\n     s->picture_number++; // better than pic number==0 allways ;)\n\n\n\n     s->y_dc_scale_table= ff_mpeg4_y_dc_scale_table; //FIXME add short header support \n\n     s->c_dc_scale_table= ff_mpeg4_c_dc_scale_table;\n\n\n\n     if(s->workaround_bugs&FF_BUG_EDGE){\n\n         s->h_edge_pos= s->width;\n\n         s->v_edge_pos= s->height;\n\n     }\n\n     return 0;\n\n}\n", "idx": 25368}
{"project": "FFmpeg", "commit_id": "daea3209693f28328ca553fb33fdf8fc2ab42044", "target": 0, "func": "static int txd_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n\n                            AVPacket *avpkt) {\n\n    GetByteContext gb;\n\n    AVFrame * const p = data;\n\n    unsigned int version, w, h, d3d_format, depth, stride, flags;\n\n    unsigned int y, v;\n\n    uint8_t *ptr;\n\n    uint32_t *pal;\n\n    int ret;\n\n\n\n    bytestream2_init(&gb, avpkt->data, avpkt->size);\n\n    version         = bytestream2_get_le32(&gb);\n\n    bytestream2_skip(&gb, 72);\n\n    d3d_format      = bytestream2_get_le32(&gb);\n\n    w               = bytestream2_get_le16(&gb);\n\n    h               = bytestream2_get_le16(&gb);\n\n    depth           = bytestream2_get_byte(&gb);\n\n    bytestream2_skip(&gb, 2);\n\n    flags           = bytestream2_get_byte(&gb);\n\n\n\n    if (version < 8 || version > 9) {\n\n        av_log(avctx, AV_LOG_ERROR, \"texture data version %i is unsupported\\n\",\n\n                                                                    version);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if (depth == 8) {\n\n        avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n    } else if (depth == 16 || depth == 32) {\n\n        avctx->pix_fmt = AV_PIX_FMT_RGB32;\n\n    } else {\n\n        av_log(avctx, AV_LOG_ERROR, \"depth of %i is unsupported\\n\", depth);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if ((ret = ff_set_dimensions(avctx, w, h)) < 0)\n\n        return ret;\n\n\n\n    if ((ret = ff_get_buffer(avctx, p, 0)) < 0)\n\n        return ret;\n\n\n\n    p->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    ptr    = p->data[0];\n\n    stride = p->linesize[0];\n\n\n\n    if (depth == 8) {\n\n        pal = (uint32_t *) p->data[1];\n\n        for (y = 0; y < 256; y++) {\n\n            v = bytestream2_get_be32(&gb);\n\n            pal[y] = (v >> 8) + (v << 24);\n\n        }\n\n        if (bytestream2_get_bytes_left(&gb) < w * h)\n\n            return AVERROR_INVALIDDATA;\n\n        bytestream2_skip(&gb, 4);\n\n        for (y=0; y<h; y++) {\n\n            bytestream2_get_buffer(&gb, ptr, w);\n\n            ptr += stride;\n\n        }\n\n    } else if (depth == 16) {\n\n        bytestream2_skip(&gb, 4);\n\n        switch (d3d_format) {\n\n        case 0:\n\n            if (!(flags & 1))\n\n                goto unsupported;\n\n        case FF_S3TC_DXT1:\n\n            if (bytestream2_get_bytes_left(&gb) < (w/4) * (h/4) * 8)\n\n                return AVERROR_INVALIDDATA;\n\n            ff_decode_dxt1(&gb, ptr, w, h, stride);\n\n            break;\n\n        case FF_S3TC_DXT3:\n\n            if (bytestream2_get_bytes_left(&gb) < (w/4) * (h/4) * 16)\n\n                return AVERROR_INVALIDDATA;\n\n            ff_decode_dxt3(&gb, ptr, w, h, stride);\n\n            break;\n\n        default:\n\n            goto unsupported;\n\n        }\n\n    } else if (depth == 32) {\n\n        switch (d3d_format) {\n\n        case 0x15:\n\n        case 0x16:\n\n            if (bytestream2_get_bytes_left(&gb) < h * w * 4)\n\n                return AVERROR_INVALIDDATA;\n\n            for (y=0; y<h; y++) {\n\n                bytestream2_get_buffer(&gb, ptr, w * 4);\n\n                ptr += stride;\n\n            }\n\n            break;\n\n        default:\n\n            goto unsupported;\n\n        }\n\n    }\n\n\n\n    *got_frame = 1;\n\n\n\n    return avpkt->size;\n\n\n\nunsupported:\n\n    av_log(avctx, AV_LOG_ERROR, \"unsupported d3d format (%08x)\\n\", d3d_format);\n\n    return AVERROR_PATCHWELCOME;\n\n}\n", "idx": 25369}
{"project": "FFmpeg", "commit_id": "bf8bcd3b2b51c4d3f0a157e80a8c96c8542217b0", "target": 0, "func": "static int read_packet(AVFormatContext* ctx, AVPacket *pkt)\n\n{\n\n    al_data *ad = ctx->priv_data;\n\n    int error=0;\n\n    const char *error_msg;\n\n    ALCint nb_samples;\n\n\n\n    /* Get number of samples available */\n\n    alcGetIntegerv(ad->device, ALC_CAPTURE_SAMPLES, (ALCsizei) sizeof(ALCint), &nb_samples);\n\n    if (error = al_get_error(ad->device, &error_msg)) goto fail;\n\n\n\n    /* Create a packet of appropriate size */\n\n    av_new_packet(pkt, nb_samples*ad->sample_step);\n\n    pkt->pts = av_gettime();\n\n\n\n    /* Fill the packet with the available samples */\n\n    alcCaptureSamples(ad->device, pkt->data, nb_samples);\n\n    if (error = al_get_error(ad->device, &error_msg)) goto fail;\n\n\n\n    return pkt->size;\n\nfail:\n\n    /* Handle failure */\n\n    if (pkt->data)\n\n        av_destruct_packet(pkt);\n\n    if (error_msg)\n\n        av_log(ctx, AV_LOG_ERROR, \"Error: %s\\n\", error_msg);\n\n    return error;\n\n}\n", "idx": 25371}
{"project": "FFmpeg", "commit_id": "d7a4c43f1830a23f8acd71bea567f7908a99a539", "target": 0, "func": "static int read_header(FFV1Context *f){\n\n    uint8_t state[CONTEXT_SIZE];\n\n    int i, j, context_count;\n\n    RangeCoder * const c= &f->slice_context[0]->c;\n\n\n\n    memset(state, 128, sizeof(state));\n\n\n\n    if(f->version < 2){\n\n        f->version= get_symbol(c, state, 0);\n\n        f->ac= f->avctx->coder_type= get_symbol(c, state, 0);\n\n        if(f->ac>1){\n\n            for(i=1; i<256; i++){\n\n                f->state_transition[i]= get_symbol(c, state, 1) + c->one_state[i];\n\n            }\n\n        }\n\n        f->colorspace= get_symbol(c, state, 0); //YUV cs type\n\n        if(f->version>0)\n\n            f->avctx->bits_per_raw_sample= get_symbol(c, state, 0);\n\n        f->chroma_planes= get_rac(c, state);\n\n        f->chroma_h_shift= get_symbol(c, state, 0);\n\n        f->chroma_v_shift= get_symbol(c, state, 0);\n\n        f->transparency= get_rac(c, state);\n\n        f->plane_count= 2 + f->transparency;\n\n    }\n\n\n\n    if(f->colorspace==0){\n\n        if(!f->transparency && !f->chroma_planes){\n\n            if (f->avctx->bits_per_raw_sample<=8)\n\n                f->avctx->pix_fmt= PIX_FMT_GRAY8;\n\n            else\n\n                f->avctx->pix_fmt= PIX_FMT_GRAY16;\n\n        }else if(f->avctx->bits_per_raw_sample<=8 && !f->transparency){\n\n            switch(16*f->chroma_h_shift + f->chroma_v_shift){\n\n            case 0x00: f->avctx->pix_fmt= PIX_FMT_YUV444P; break;\n\n            case 0x01: f->avctx->pix_fmt= PIX_FMT_YUV440P; break;\n\n            case 0x10: f->avctx->pix_fmt= PIX_FMT_YUV422P; break;\n\n            case 0x11: f->avctx->pix_fmt= PIX_FMT_YUV420P; break;\n\n            case 0x20: f->avctx->pix_fmt= PIX_FMT_YUV411P; break;\n\n            case 0x22: f->avctx->pix_fmt= PIX_FMT_YUV410P; break;\n\n            default:\n\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n\n                return -1;\n\n            }\n\n        }else if(f->avctx->bits_per_raw_sample<=8 && f->transparency){\n\n            switch(16*f->chroma_h_shift + f->chroma_v_shift){\n\n            case 0x00: f->avctx->pix_fmt= PIX_FMT_YUVA444P; break;\n\n            case 0x11: f->avctx->pix_fmt= PIX_FMT_YUVA420P; break;\n\n            default:\n\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n\n                return -1;\n\n            }\n\n        }else if(f->avctx->bits_per_raw_sample==9) {\n\n            f->packed_at_lsb=1;\n\n            switch(16*f->chroma_h_shift + f->chroma_v_shift){\n\n            case 0x00: f->avctx->pix_fmt= PIX_FMT_YUV444P9; break;\n\n            case 0x10: f->avctx->pix_fmt= PIX_FMT_YUV422P9; break;\n\n            case 0x11: f->avctx->pix_fmt= PIX_FMT_YUV420P9; break;\n\n            default:\n\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n\n                return -1;\n\n            }\n\n        }else if(f->avctx->bits_per_raw_sample==10) {\n\n            f->packed_at_lsb=1;\n\n            switch(16*f->chroma_h_shift + f->chroma_v_shift){\n\n            case 0x00: f->avctx->pix_fmt= PIX_FMT_YUV444P10; break;\n\n            case 0x10: f->avctx->pix_fmt= PIX_FMT_YUV422P10; break;\n\n            case 0x11: f->avctx->pix_fmt= PIX_FMT_YUV420P10; break;\n\n            default:\n\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n\n                return -1;\n\n            }\n\n        }else {\n\n            switch(16*f->chroma_h_shift + f->chroma_v_shift){\n\n            case 0x00: f->avctx->pix_fmt= PIX_FMT_YUV444P16; break;\n\n            case 0x10: f->avctx->pix_fmt= PIX_FMT_YUV422P16; break;\n\n            case 0x11: f->avctx->pix_fmt= PIX_FMT_YUV420P16; break;\n\n            default:\n\n                av_log(f->avctx, AV_LOG_ERROR, \"format not supported\\n\");\n\n                return -1;\n\n            }\n\n        }\n\n    }else if(f->colorspace==1){\n\n        if(f->chroma_h_shift || f->chroma_v_shift){\n\n            av_log(f->avctx, AV_LOG_ERROR, \"chroma subsampling not supported in this colorspace\\n\");\n\n            return -1;\n\n        }\n\n        if(f->transparency) f->avctx->pix_fmt= PIX_FMT_RGB32;\n\n        else                f->avctx->pix_fmt= PIX_FMT_0RGB32;\n\n    }else{\n\n        av_log(f->avctx, AV_LOG_ERROR, \"colorspace not supported\\n\");\n\n        return -1;\n\n    }\n\n\n\n//printf(\"%d %d %d\\n\", f->chroma_h_shift, f->chroma_v_shift,f->avctx->pix_fmt);\n\n    if(f->version < 2){\n\n        context_count= read_quant_tables(c, f->quant_table);\n\n        if(context_count < 0){\n\n                av_log(f->avctx, AV_LOG_ERROR, \"read_quant_table error\\n\");\n\n                return -1;\n\n        }\n\n    }else{\n\n        f->slice_count= get_symbol(c, state, 0);\n\n        if(f->slice_count > (unsigned)MAX_SLICES)\n\n            return -1;\n\n    }\n\n\n\n    for(j=0; j<f->slice_count; j++){\n\n        FFV1Context *fs= f->slice_context[j];\n\n        fs->ac= f->ac;\n\n        fs->packed_at_lsb= f->packed_at_lsb;\n\n\n\n        if(f->version >= 2){\n\n            fs->slice_x     = get_symbol(c, state, 0)   *f->width ;\n\n            fs->slice_y     = get_symbol(c, state, 0)   *f->height;\n\n            fs->slice_width =(get_symbol(c, state, 0)+1)*f->width  + fs->slice_x;\n\n            fs->slice_height=(get_symbol(c, state, 0)+1)*f->height + fs->slice_y;\n\n\n\n            fs->slice_x /= f->num_h_slices;\n\n            fs->slice_y /= f->num_v_slices;\n\n            fs->slice_width  = fs->slice_width /f->num_h_slices - fs->slice_x;\n\n            fs->slice_height = fs->slice_height/f->num_v_slices - fs->slice_y;\n\n            if((unsigned)fs->slice_width > f->width || (unsigned)fs->slice_height > f->height)\n\n                return -1;\n\n            if(    (unsigned)fs->slice_x + (uint64_t)fs->slice_width  > f->width\n\n                || (unsigned)fs->slice_y + (uint64_t)fs->slice_height > f->height)\n\n                return -1;\n\n        }\n\n\n\n        for(i=0; i<f->plane_count; i++){\n\n            PlaneContext * const p= &fs->plane[i];\n\n\n\n            if(f->version >= 2){\n\n                int idx=get_symbol(c, state, 0);\n\n                if(idx > (unsigned)f->quant_table_count){\n\n                    av_log(f->avctx, AV_LOG_ERROR, \"quant_table_index out of range\\n\");\n\n                    return -1;\n\n                }\n\n                p->quant_table_index= idx;\n\n                memcpy(p->quant_table, f->quant_tables[idx], sizeof(p->quant_table));\n\n                context_count= f->context_count[idx];\n\n            }else{\n\n                memcpy(p->quant_table, f->quant_table, sizeof(p->quant_table));\n\n            }\n\n\n\n            if(p->context_count < context_count){\n\n                av_freep(&p->state);\n\n                av_freep(&p->vlc_state);\n\n            }\n\n            p->context_count= context_count;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25372}
{"project": "FFmpeg", "commit_id": "bcd7bf7eeb09a395cc01698842d1b8be9af483fc", "target": 0, "func": "static void avc_loopfilter_cb_or_cr_intra_edge_hor_msa(uint8_t *data_cb_or_cr,\n\n                                                       uint8_t alpha_in,\n\n                                                       uint8_t beta_in,\n\n                                                       uint32_t img_width)\n\n{\n\n    v16u8 alpha, beta;\n\n    v16u8 is_less_than;\n\n    v8i16 p0_or_q0, q0_or_p0;\n\n    v16u8 p1_or_q1_org, p0_or_q0_org, q0_or_p0_org, q1_or_p1_org;\n\n    v16i8 zero = { 0 };\n\n    v16u8 p0_asub_q0, p1_asub_p0, q1_asub_q0;\n\n    v16u8 is_less_than_alpha, is_less_than_beta;\n\n    v8i16 p1_org_r, p0_org_r, q0_org_r, q1_org_r;\n\n\n\n    alpha = (v16u8) __msa_fill_b(alpha_in);\n\n    beta = (v16u8) __msa_fill_b(beta_in);\n\n\n\n    p1_or_q1_org = LOAD_UB(data_cb_or_cr - (img_width << 1));\n\n    p0_or_q0_org = LOAD_UB(data_cb_or_cr - img_width);\n\n    q0_or_p0_org = LOAD_UB(data_cb_or_cr);\n\n    q1_or_p1_org = LOAD_UB(data_cb_or_cr + img_width);\n\n\n\n    p0_asub_q0 = __msa_asub_u_b(p0_or_q0_org, q0_or_p0_org);\n\n    p1_asub_p0 = __msa_asub_u_b(p1_or_q1_org, p0_or_q0_org);\n\n    q1_asub_q0 = __msa_asub_u_b(q1_or_p1_org, q0_or_p0_org);\n\n\n\n    is_less_than_alpha = (p0_asub_q0 < alpha);\n\n    is_less_than_beta = (p1_asub_p0 < beta);\n\n    is_less_than = is_less_than_beta & is_less_than_alpha;\n\n    is_less_than_beta = (q1_asub_q0 < beta);\n\n    is_less_than = is_less_than_beta & is_less_than;\n\n\n\n    is_less_than = (v16u8) __msa_ilvr_d((v2i64) zero, (v2i64) is_less_than);\n\n\n\n    if (!__msa_test_bz_v(is_less_than)) {\n\n        p1_org_r = (v8i16) __msa_ilvr_b(zero, (v16i8) p1_or_q1_org);\n\n        p0_org_r = (v8i16) __msa_ilvr_b(zero, (v16i8) p0_or_q0_org);\n\n        q0_org_r = (v8i16) __msa_ilvr_b(zero, (v16i8) q0_or_p0_org);\n\n        q1_org_r = (v8i16) __msa_ilvr_b(zero, (v16i8) q1_or_p1_org);\n\n\n\n        AVC_LOOP_FILTER_P0_OR_Q0(p0_org_r, q1_org_r, p1_org_r, p0_or_q0);\n\n        AVC_LOOP_FILTER_P0_OR_Q0(q0_org_r, p1_org_r, q1_org_r, q0_or_p0);\n\n\n\n        p0_or_q0 = (v8i16) __msa_pckev_b(zero, (v16i8) p0_or_q0);\n\n        q0_or_p0 = (v8i16) __msa_pckev_b(zero, (v16i8) q0_or_p0);\n\n\n\n        p0_or_q0_org =\n\n            __msa_bmnz_v(p0_or_q0_org, (v16u8) p0_or_q0, is_less_than);\n\n        q0_or_p0_org =\n\n            __msa_bmnz_v(q0_or_p0_org, (v16u8) q0_or_p0, is_less_than);\n\n\n\n        STORE_UB(q0_or_p0_org, data_cb_or_cr);\n\n        STORE_UB(p0_or_q0_org, data_cb_or_cr - img_width);\n\n    }\n\n}\n", "idx": 25373}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "static inline void RENAME(uyvytoyv12)(const uint8_t *src, uint8_t *ydst, uint8_t *udst, uint8_t *vdst,\n\n\tlong width, long height,\n\n\tlong lumStride, long chromStride, long srcStride)\n\n{\n\n\tlong y;\n\n\tconst long chromWidth= width>>1;\n\n\tfor(y=0; y<height; y+=2)\n\n\t{\n\n#ifdef HAVE_MMX\n\n\t\tasm volatile(\n\n\t\t\t\"xorl %%eax, %%eax\t\t\\n\\t\"\n\n\t\t\t\"pcmpeqw %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"psrlw $8, %%mm7\t\t\\n\\t\" // FF,00,FF,00...\n\n\t\t\tASMALIGN(4)\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%0, %%eax, 4)\t\\n\\t\"\n\n\t\t\t\"movq (%0, %%eax, 4), %%mm0\t\\n\\t\" // UYVY UYVY(0)\n\n\t\t\t\"movq 8(%0, %%eax, 4), %%mm1\t\\n\\t\" // UYVY UYVY(4)\n\n\t\t\t\"movq %%mm0, %%mm2\t\t\\n\\t\" // UYVY UYVY(0)\n\n\t\t\t\"movq %%mm1, %%mm3\t\t\\n\\t\" // UYVY UYVY(4)\n\n\t\t\t\"pand %%mm7, %%mm0\t\t\\n\\t\" // U0V0 U0V0(0)\n\n\t\t\t\"pand %%mm7, %%mm1\t\t\\n\\t\" // U0V0 U0V0(4)\n\n\t\t\t\"psrlw $8, %%mm2\t\t\\n\\t\" // Y0Y0 Y0Y0(0)\n\n\t\t\t\"psrlw $8, %%mm3\t\t\\n\\t\" // Y0Y0 Y0Y0(4)\n\n\t\t\t\"packuswb %%mm1, %%mm0\t\t\\n\\t\" // UVUV UVUV(0)\n\n\t\t\t\"packuswb %%mm3, %%mm2\t\t\\n\\t\" // YYYY YYYY(0)\n\n\n\n\t\t\tMOVNTQ\" %%mm2, (%1, %%eax, 2)\t\\n\\t\"\n\n\n\n\t\t\t\"movq 16(%0, %%eax, 4), %%mm1\t\\n\\t\" // UYVY UYVY(8)\n\n\t\t\t\"movq 24(%0, %%eax, 4), %%mm2\t\\n\\t\" // UYVY UYVY(12)\n\n\t\t\t\"movq %%mm1, %%mm3\t\t\\n\\t\" // UYVY UYVY(8)\n\n\t\t\t\"movq %%mm2, %%mm4\t\t\\n\\t\" // UYVY UYVY(12)\n\n\t\t\t\"pand %%mm7, %%mm1\t\t\\n\\t\" // U0V0 U0V0(8)\n\n\t\t\t\"pand %%mm7, %%mm2\t\t\\n\\t\" // U0V0 U0V0(12)\n\n\t\t\t\"psrlw $8, %%mm3\t\t\\n\\t\" // Y0Y0 Y0Y0(8)\n\n\t\t\t\"psrlw $8, %%mm4\t\t\\n\\t\" // Y0Y0 Y0Y0(12)\n\n\t\t\t\"packuswb %%mm2, %%mm1\t\t\\n\\t\" // UVUV UVUV(8)\n\n\t\t\t\"packuswb %%mm4, %%mm3\t\t\\n\\t\" // YYYY YYYY(8)\n\n\n\n\t\t\tMOVNTQ\" %%mm3, 8(%1, %%eax, 2)\t\\n\\t\"\n\n\n\n\t\t\t\"movq %%mm0, %%mm2\t\t\\n\\t\" // UVUV UVUV(0)\n\n\t\t\t\"movq %%mm1, %%mm3\t\t\\n\\t\" // UVUV UVUV(8)\n\n\t\t\t\"psrlw $8, %%mm0\t\t\\n\\t\" // V0V0 V0V0(0)\n\n\t\t\t\"psrlw $8, %%mm1\t\t\\n\\t\" // V0V0 V0V0(8)\n\n\t\t\t\"pand %%mm7, %%mm2\t\t\\n\\t\" // U0U0 U0U0(0)\n\n\t\t\t\"pand %%mm7, %%mm3\t\t\\n\\t\" // U0U0 U0U0(8)\n\n\t\t\t\"packuswb %%mm1, %%mm0\t\t\\n\\t\" // VVVV VVVV(0)\n\n\t\t\t\"packuswb %%mm3, %%mm2\t\t\\n\\t\" // UUUU UUUU(0)\n\n\n\n\t\t\tMOVNTQ\" %%mm0, (%3, %%eax)\t\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm2, (%2, %%eax)\t\\n\\t\"\n\n\n\n\t\t\t\"addl $8, %%eax\t\t\t\\n\\t\"\n\n\t\t\t\"cmpl %4, %%eax\t\t\t\\n\\t\"\n\n\t\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\t\t\t::\"r\"(src), \"r\"(ydst), \"r\"(udst), \"r\"(vdst), \"g\" (chromWidth)\n\n\t\t\t: \"memory\", \"%eax\"\n\n\t\t);\n\n\n\n\t\tydst += lumStride;\n\n\t\tsrc  += srcStride;\n\n\n\n\t\tasm volatile(\n\n\t\t\t\"xorl %%eax, %%eax\t\t\\n\\t\"\n\n\t\t\tASMALIGN(4)\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%0, %%eax, 4)\t\\n\\t\"\n\n\t\t\t\"movq (%0, %%eax, 4), %%mm0\t\\n\\t\" // YUYV YUYV(0)\n\n\t\t\t\"movq 8(%0, %%eax, 4), %%mm1\t\\n\\t\" // YUYV YUYV(4)\n\n\t\t\t\"movq 16(%0, %%eax, 4), %%mm2\t\\n\\t\" // YUYV YUYV(8)\n\n\t\t\t\"movq 24(%0, %%eax, 4), %%mm3\t\\n\\t\" // YUYV YUYV(12)\n\n\t\t\t\"psrlw $8, %%mm0\t\t\\n\\t\" // Y0Y0 Y0Y0(0)\n\n\t\t\t\"psrlw $8, %%mm1\t\t\\n\\t\" // Y0Y0 Y0Y0(4)\n\n\t\t\t\"psrlw $8, %%mm2\t\t\\n\\t\" // Y0Y0 Y0Y0(8)\n\n\t\t\t\"psrlw $8, %%mm3\t\t\\n\\t\" // Y0Y0 Y0Y0(12)\n\n\t\t\t\"packuswb %%mm1, %%mm0\t\t\\n\\t\" // YYYY YYYY(0)\n\n\t\t\t\"packuswb %%mm3, %%mm2\t\t\\n\\t\" // YYYY YYYY(8)\n\n\n\n\t\t\tMOVNTQ\" %%mm0, (%1, %%eax, 2)\t\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm2, 8(%1, %%eax, 2)\t\\n\\t\"\n\n\n\n\t\t\t\"addl $8, %%eax\t\t\t\\n\\t\"\n\n\t\t\t\"cmpl %4, %%eax\t\t\t\\n\\t\"\n\n\t\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\n\n\t\t\t::\"r\"(src), \"r\"(ydst), \"r\"(udst), \"r\"(vdst), \"g\" (chromWidth)\n\n\t\t\t: \"memory\", \"%eax\"\n\n\t\t);\n\n#else\n\n\t\tlong i;\n\n\t\tfor(i=0; i<chromWidth; i++)\n\n\t\t{\n\n\t\t\tudst[i] \t= src[4*i+0];\n\n\t\t\tydst[2*i+0] \t= src[4*i+1];\n\n\t\t\tvdst[i] \t= src[4*i+2];\n\n\t\t\tydst[2*i+1] \t= src[4*i+3];\n\n\t\t}\n\n\t\tydst += lumStride;\n\n\t\tsrc  += srcStride;\n\n\n\n\t\tfor(i=0; i<chromWidth; i++)\n\n\t\t{\n\n\t\t\tydst[2*i+0] \t= src[4*i+1];\n\n\t\t\tydst[2*i+1] \t= src[4*i+3];\n\n\t\t}\n\n#endif\n\n\t\tudst += chromStride;\n\n\t\tvdst += chromStride;\n\n\t\tydst += lumStride;\n\n\t\tsrc  += srcStride;\n\n\t}\n\n#ifdef HAVE_MMX\n\nasm volatile(   EMMS\" \\n\\t\"\n\n        \tSFENCE\" \\n\\t\"\n\n        \t:::\"memory\");\n\n#endif\n\n}\n", "idx": 25375}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "void palette8tobgr15(const uint8_t *src, uint8_t *dst, unsigned num_pixels, const uint8_t *palette)\n\n{\n\n\tunsigned i;\n\n\tfor(i=0; i<num_pixels; i++)\n\n\t\t((uint16_t *)dst)[i] = bswap_16(((uint16_t *)palette)[ src[i] ]);\n\n}\n", "idx": 25376}
{"project": "FFmpeg", "commit_id": "76d8c77430e9e0110623705bfb54d922cc2ac3ea", "target": 1, "func": "static int decode_interrupt_cb(void *ctx)\n\n{\n\n    return received_nb_signals > transcode_init_done;\n\n}\n", "idx": 25377}
{"project": "FFmpeg", "commit_id": "0834f2056c7f1a0c09129802a003465e0ebcc9b8", "target": 1, "func": "static int mxf_read_content_storage(void *arg, AVIOContext *pb, int tag, int size, UID uid, int64_t klv_offset)\n\n{\n\n    MXFContext *mxf = arg;\n\n    switch (tag) {\n\n    case 0x1901:\n\n\n\n\n        mxf->packages_count = avio_rb32(pb);\n\n        mxf->packages_refs = av_calloc(mxf->packages_count, sizeof(UID));\n\n        if (!mxf->packages_refs)\n\n            return AVERROR(ENOMEM);\n\n        avio_skip(pb, 4); /* useless size of objects, always 16 according to specs */\n\n        avio_read(pb, (uint8_t *)mxf->packages_refs, mxf->packages_count * sizeof(UID));\n\n        break;\n\n    }\n\n    return 0;\n\n}", "idx": 25378}
{"project": "FFmpeg", "commit_id": "7b5c03064df522aef027490c51af8136ed5f17b3", "target": 1, "func": "int vc1_parse_frame_header_adv(VC1Context *v, GetBitContext* gb)\n\n{\n\n    int pqindex, lowquant;\n\n    int status;\n\n    int mbmodetab, imvtab, icbptab, twomvbptab, fourmvbptab; /* useful only for debugging */\n\n    int scale, shift, i; /* for initializing LUT for intensity compensation */\n\n\n\n    v->numref=0;\n\n    v->fcm=0;\n\n    v->field_mode=0;\n\n    v->p_frame_skipped = 0;\n\n    if (v->second_field) {\n\n        v->s.pict_type = (v->fptype & 1) ? AV_PICTURE_TYPE_P : AV_PICTURE_TYPE_I;\n\n        if (v->fptype & 4)\n\n            v->s.pict_type = (v->fptype & 1) ? AV_PICTURE_TYPE_BI : AV_PICTURE_TYPE_B;\n\n        v->s.current_picture_ptr->f.pict_type = v->s.pict_type;\n\n        if (!v->pic_header_flag)\n\n            goto parse_common_info;\n\n    }\n\n\n\n    if (v->interlace) {\n\n        v->fcm = decode012(gb);\n\n        if (v->fcm) {\n\n            if (v->fcm == 2)\n\n                v->field_mode = 1;\n\n            else\n\n                v->field_mode = 0;\n\n            if (!v->warn_interlaced++)\n\n                av_log(v->s.avctx, AV_LOG_ERROR,\n\n                       \"Interlaced frames/fields support is incomplete\\n\");\n\n        }\n\n    }\n\n\n\n    if (v->field_mode) {\n\n        v->fptype = get_bits(gb, 3);\n\n        v->s.pict_type = (v->fptype & 2) ? AV_PICTURE_TYPE_P : AV_PICTURE_TYPE_I;\n\n        if (v->fptype & 4) // B-picture\n\n            v->s.pict_type = (v->fptype & 2) ? AV_PICTURE_TYPE_BI : AV_PICTURE_TYPE_B;\n\n    } else {\n\n        switch (get_unary(gb, 0, 4)) {\n\n        case 0:\n\n            v->s.pict_type = AV_PICTURE_TYPE_P;\n\n            break;\n\n        case 1:\n\n            v->s.pict_type = AV_PICTURE_TYPE_B;\n\n            break;\n\n        case 2:\n\n            v->s.pict_type = AV_PICTURE_TYPE_I;\n\n            break;\n\n        case 3:\n\n            v->s.pict_type = AV_PICTURE_TYPE_BI;\n\n            break;\n\n        case 4:\n\n            v->s.pict_type = AV_PICTURE_TYPE_P; // skipped pic\n\n            v->p_frame_skipped = 1;\n\n            break;\n\n        }\n\n    }\n\n    if (v->tfcntrflag)\n\n        skip_bits(gb, 8);\n\n    if (v->broadcast) {\n\n        if (!v->interlace || v->psf) {\n\n            v->rptfrm = get_bits(gb, 2);\n\n        } else {\n\n            v->tff = get_bits1(gb);\n\n            v->rff = get_bits1(gb);\n\n        }\n\n    }\n\n    if (v->panscanflag) {\n\n        av_log_missing_feature(v->s.avctx, \"Pan-scan\", 0);\n\n        //...\n\n    }\n\n    if (v->p_frame_skipped) {\n\n        return 0;\n\n    }\n\n    v->rnd = get_bits1(gb);\n\n    if (v->interlace)\n\n        v->uvsamp = get_bits1(gb);\n\n    if (v->field_mode) {\n\n        if (!v->refdist_flag)\n\n            v->refdist = 0;\n\n        else {\n\n            if ((v->s.pict_type != AV_PICTURE_TYPE_B)\n\n                && (v->s.pict_type != AV_PICTURE_TYPE_BI)) {\n\n                v->refdist = get_bits(gb, 2);\n\n                if (v->refdist == 3)\n\n                    v->refdist += get_unary(gb, 0, 16);\n\n            } else {\n\n                v->bfraction_lut_index = get_vlc2(gb, ff_vc1_bfraction_vlc.table, VC1_BFRACTION_VLC_BITS, 1);\n\n                v->bfraction           = ff_vc1_bfraction_lut[v->bfraction_lut_index];\n\n                v->frfd = (v->bfraction * v->refdist) >> 8;\n\n                v->brfd = v->refdist - v->frfd - 1;\n\n                if (v->brfd < 0)\n\n                    v->brfd = 0;\n\n            }\n\n        }\n\n        goto parse_common_info;\n\n    }\n\n    if (v->finterpflag)\n\n        v->interpfrm = get_bits1(gb);\n\n    if (v->s.pict_type == AV_PICTURE_TYPE_B) {\n\n        v->bfraction_lut_index = get_vlc2(gb, ff_vc1_bfraction_vlc.table, VC1_BFRACTION_VLC_BITS, 1);\n\n        v->bfraction           = ff_vc1_bfraction_lut[v->bfraction_lut_index];\n\n        if (v->bfraction == 0) {\n\n            v->s.pict_type = AV_PICTURE_TYPE_BI; /* XXX: should not happen here */\n\n        }\n\n    }\n\n\n\n    parse_common_info:\n\n    if (v->field_mode)\n\n        v->cur_field_type = !(v->tff ^ v->second_field);\n\n    pqindex = get_bits(gb, 5);\n\n    if (!pqindex)\n\n        return -1;\n\n    v->pqindex = pqindex;\n\n    if (v->quantizer_mode == QUANT_FRAME_IMPLICIT)\n\n        v->pq = ff_vc1_pquant_table[0][pqindex];\n\n    else\n\n        v->pq = ff_vc1_pquant_table[1][pqindex];\n\n\n\n    v->pquantizer = 1;\n\n    if (v->quantizer_mode == QUANT_FRAME_IMPLICIT)\n\n        v->pquantizer = pqindex < 9;\n\n    if (v->quantizer_mode == QUANT_NON_UNIFORM)\n\n        v->pquantizer = 0;\n\n    v->pqindex = pqindex;\n\n    if (pqindex < 9)\n\n        v->halfpq = get_bits1(gb);\n\n    else\n\n        v->halfpq = 0;\n\n    if (v->quantizer_mode == QUANT_FRAME_EXPLICIT)\n\n        v->pquantizer = get_bits1(gb);\n\n    if (v->postprocflag)\n\n        v->postproc = get_bits(gb, 2);\n\n\n\n    if (v->s.pict_type == AV_PICTURE_TYPE_I || v->s.pict_type == AV_PICTURE_TYPE_P)\n\n        v->use_ic = 0;\n\n\n\n    if (v->parse_only)\n\n        return 0;\n\n\n\n    switch (v->s.pict_type) {\n\n    case AV_PICTURE_TYPE_I:\n\n    case AV_PICTURE_TYPE_BI:\n\n        if (v->fcm == 1) { //interlace frame picture\n\n            status = bitplane_decoding(v->fieldtx_plane, &v->fieldtx_is_raw, v);\n\n            if (status < 0)\n\n                return -1;\n\n            av_log(v->s.avctx, AV_LOG_DEBUG, \"FIELDTX plane encoding: \"\n\n                   \"Imode: %i, Invert: %i\\n\", status>>1, status&1);\n\n        }\n\n        status = bitplane_decoding(v->acpred_plane, &v->acpred_is_raw, v);\n\n        if (status < 0)\n\n            return -1;\n\n        av_log(v->s.avctx, AV_LOG_DEBUG, \"ACPRED plane encoding: \"\n\n               \"Imode: %i, Invert: %i\\n\", status>>1, status&1);\n\n        v->condover = CONDOVER_NONE;\n\n        if (v->overlap && v->pq <= 8) {\n\n            v->condover = decode012(gb);\n\n            if (v->condover == CONDOVER_SELECT) {\n\n                status = bitplane_decoding(v->over_flags_plane, &v->overflg_is_raw, v);\n\n                if (status < 0)\n\n                    return -1;\n\n                av_log(v->s.avctx, AV_LOG_DEBUG, \"CONDOVER plane encoding: \"\n\n                       \"Imode: %i, Invert: %i\\n\", status>>1, status&1);\n\n            }\n\n        }\n\n        break;\n\n    case AV_PICTURE_TYPE_P:\n\n        if (v->field_mode) {\n\n            av_log(v->s.avctx, AV_LOG_ERROR, \"P Fields do not work currently\\n\");\n\n            return -1;\n\n            v->numref = get_bits1(gb);\n\n            if (!v->numref) {\n\n                v->reffield          = get_bits1(gb);\n\n                v->ref_field_type[0] = v->reffield ^ !v->cur_field_type;\n\n            }\n\n        }\n\n        if (v->extended_mv)\n\n            v->mvrange = get_unary(gb, 0, 3);\n\n        else\n\n            v->mvrange = 0;\n\n        if (v->interlace) {\n\n            if (v->extended_dmv)\n\n                v->dmvrange = get_unary(gb, 0, 3);\n\n            else\n\n                v->dmvrange = 0;\n\n            if (v->fcm == 1) { // interlaced frame picture\n\n                v->fourmvswitch = get_bits1(gb);\n\n                v->intcomp      = get_bits1(gb);\n\n                if (v->intcomp) {\n\n                    v->lumscale = get_bits(gb, 6);\n\n                    v->lumshift = get_bits(gb, 6);\n\n                    INIT_LUT(v->lumscale, v->lumshift, v->luty, v->lutuv);\n\n                }\n\n                status = bitplane_decoding(v->s.mbskip_table, &v->skip_is_raw, v);\n\n                av_log(v->s.avctx, AV_LOG_DEBUG, \"SKIPMB plane encoding: \"\n\n                       \"Imode: %i, Invert: %i\\n\", status>>1, status&1);\n\n                mbmodetab = get_bits(gb, 2);\n\n                if (v->fourmvswitch)\n\n                    v->mbmode_vlc = &ff_vc1_intfr_4mv_mbmode_vlc[mbmodetab];\n\n                else\n\n                    v->mbmode_vlc = &ff_vc1_intfr_non4mv_mbmode_vlc[mbmodetab];\n\n                imvtab         = get_bits(gb, 2);\n\n                v->imv_vlc     = &ff_vc1_1ref_mvdata_vlc[imvtab];\n\n                // interlaced p-picture cbpcy range is [1, 63]\n\n                icbptab        = get_bits(gb, 3);\n\n                v->cbpcy_vlc   = &ff_vc1_icbpcy_vlc[icbptab];\n\n                twomvbptab     = get_bits(gb, 2);\n\n                v->twomvbp_vlc = &ff_vc1_2mv_block_pattern_vlc[twomvbptab];\n\n                if (v->fourmvswitch) {\n\n                    fourmvbptab     = get_bits(gb, 2);\n\n                    v->fourmvbp_vlc = &ff_vc1_4mv_block_pattern_vlc[fourmvbptab];\n\n                }\n\n            }\n\n        }\n\n        v->k_x = v->mvrange + 9 + (v->mvrange >> 1); //k_x can be 9 10 12 13\n\n        v->k_y = v->mvrange + 8; //k_y can be 8 9 10 11\n\n        v->range_x = 1 << (v->k_x - 1);\n\n        v->range_y = 1 << (v->k_y - 1);\n\n\n\n        if (v->pq < 5)\n\n            v->tt_index = 0;\n\n        else if (v->pq < 13)\n\n            v->tt_index = 1;\n\n        else\n\n            v->tt_index = 2;\n\n        if (v->fcm != 1) {\n\n            int mvmode;\n\n            mvmode     = get_unary(gb, 1, 4);\n\n            lowquant   = (v->pq > 12) ? 0 : 1;\n\n            v->mv_mode = ff_vc1_mv_pmode_table[lowquant][mvmode];\n\n            if (v->mv_mode == MV_PMODE_INTENSITY_COMP) {\n\n                int mvmode2;\n\n                mvmode2 = get_unary(gb, 1, 3);\n\n                v->mv_mode2 = ff_vc1_mv_pmode_table2[lowquant][mvmode2];\n\n                if (v->field_mode)\n\n                    v->intcompfield = decode210(gb);\n\n                v->lumscale = get_bits(gb, 6);\n\n                v->lumshift = get_bits(gb, 6);\n\n                INIT_LUT(v->lumscale, v->lumshift, v->luty, v->lutuv);\n\n                if ((v->field_mode) && !v->intcompfield) {\n\n                    v->lumscale2 = get_bits(gb, 6);\n\n                    v->lumshift2 = get_bits(gb, 6);\n\n                    INIT_LUT(v->lumscale2, v->lumshift2, v->luty2, v->lutuv2);\n\n                }\n\n                v->use_ic = 1;\n\n            }\n\n            v->qs_last = v->s.quarter_sample;\n\n            if (v->mv_mode == MV_PMODE_1MV_HPEL || v->mv_mode == MV_PMODE_1MV_HPEL_BILIN)\n\n                v->s.quarter_sample = 0;\n\n            else if (v->mv_mode == MV_PMODE_INTENSITY_COMP) {\n\n                if (v->mv_mode2 == MV_PMODE_1MV_HPEL || v->mv_mode2 == MV_PMODE_1MV_HPEL_BILIN)\n\n                    v->s.quarter_sample = 0;\n\n                else\n\n                    v->s.quarter_sample = 1;\n\n            } else\n\n                v->s.quarter_sample = 1;\n\n            v->s.mspel = !(v->mv_mode == MV_PMODE_1MV_HPEL_BILIN\n\n                           || (v->mv_mode == MV_PMODE_INTENSITY_COMP\n\n                               && v->mv_mode2 == MV_PMODE_1MV_HPEL_BILIN));\n\n        }\n\n        if (v->fcm == 0) { // progressive\n\n            if ((v->mv_mode == MV_PMODE_INTENSITY_COMP &&\n\n                 v->mv_mode2 == MV_PMODE_MIXED_MV)\n\n                || v->mv_mode == MV_PMODE_MIXED_MV) {\n\n                status = bitplane_decoding(v->mv_type_mb_plane, &v->mv_type_is_raw, v);\n\n                if (status < 0)\n\n                    return -1;\n\n                av_log(v->s.avctx, AV_LOG_DEBUG, \"MB MV Type plane encoding: \"\n\n                       \"Imode: %i, Invert: %i\\n\", status>>1, status&1);\n\n            } else {\n\n                v->mv_type_is_raw = 0;\n\n                memset(v->mv_type_mb_plane, 0, v->s.mb_stride * v->s.mb_height);\n\n            }\n\n            status = bitplane_decoding(v->s.mbskip_table, &v->skip_is_raw, v);\n\n            if (status < 0)\n\n                return -1;\n\n            av_log(v->s.avctx, AV_LOG_DEBUG, \"MB Skip plane encoding: \"\n\n                   \"Imode: %i, Invert: %i\\n\", status>>1, status&1);\n\n\n\n            /* Hopefully this is correct for P frames */\n\n            v->s.mv_table_index = get_bits(gb, 2); //but using ff_vc1_ tables\n\n            v->cbpcy_vlc        = &ff_vc1_cbpcy_p_vlc[get_bits(gb, 2)];\n\n        } else if (v->fcm == 1) { // frame interlaced\n\n            v->qs_last          = v->s.quarter_sample;\n\n            v->s.quarter_sample = 1;\n\n            v->s.mspel          = 1;\n\n        } else {    // field interlaced\n\n            mbmodetab = get_bits(gb, 3);\n\n            imvtab = get_bits(gb, 2 + v->numref);\n\n            if (!v->numref)\n\n                v->imv_vlc = &ff_vc1_1ref_mvdata_vlc[imvtab];\n\n            else\n\n                v->imv_vlc = &ff_vc1_2ref_mvdata_vlc[imvtab];\n\n            icbptab = get_bits(gb, 3);\n\n            v->cbpcy_vlc = &ff_vc1_icbpcy_vlc[icbptab];\n\n            if ((v->mv_mode == MV_PMODE_INTENSITY_COMP &&\n\n                v->mv_mode2 == MV_PMODE_MIXED_MV) || v->mv_mode == MV_PMODE_MIXED_MV) {\n\n                fourmvbptab     = get_bits(gb, 2);\n\n                v->fourmvbp_vlc = &ff_vc1_4mv_block_pattern_vlc[fourmvbptab];\n\n                v->mbmode_vlc = &ff_vc1_if_mmv_mbmode_vlc[mbmodetab];\n\n            } else {\n\n                v->mbmode_vlc = &ff_vc1_if_1mv_mbmode_vlc[mbmodetab];\n\n            }\n\n        }\n\n        if (v->dquant) {\n\n            av_log(v->s.avctx, AV_LOG_DEBUG, \"VOP DQuant info\\n\");\n\n            vop_dquant_decoding(v);\n\n        }\n\n\n\n        v->ttfrm = 0; //FIXME Is that so ?\n\n        if (v->vstransform) {\n\n            v->ttmbf = get_bits1(gb);\n\n            if (v->ttmbf) {\n\n                v->ttfrm = ff_vc1_ttfrm_to_tt[get_bits(gb, 2)];\n\n            }\n\n        } else {\n\n            v->ttmbf = 1;\n\n            v->ttfrm = TT_8X8;\n\n        }\n\n        break;\n\n    case AV_PICTURE_TYPE_B:\n\n        // TODO: implement interlaced frame B picture decoding\n\n        if (v->fcm == 1)\n\n            return -1;\n\n        if (v->extended_mv)\n\n            v->mvrange = get_unary(gb, 0, 3);\n\n        else\n\n            v->mvrange = 0;\n\n        v->k_x     = v->mvrange + 9 + (v->mvrange >> 1); //k_x can be 9 10 12 13\n\n        v->k_y     = v->mvrange + 8; //k_y can be 8 9 10 11\n\n        v->range_x = 1 << (v->k_x - 1);\n\n        v->range_y = 1 << (v->k_y - 1);\n\n\n\n        if (v->pq < 5)\n\n            v->tt_index = 0;\n\n        else if (v->pq < 13)\n\n            v->tt_index = 1;\n\n        else\n\n            v->tt_index = 2;\n\n\n\n        if (v->field_mode) {\n\n            int mvmode;\n\n            av_log(v->s.avctx, AV_LOG_ERROR, \"B Fields do not work currently\\n\");\n\n            return -1;\n\n            if (v->extended_dmv)\n\n                v->dmvrange = get_unary(gb, 0, 3);\n\n            mvmode = get_unary(gb, 1, 3);\n\n            lowquant = (v->pq > 12) ? 0 : 1;\n\n            v->mv_mode          = ff_vc1_mv_pmode_table2[lowquant][mvmode];\n\n            v->qs_last          = v->s.quarter_sample;\n\n            v->s.quarter_sample = (v->mv_mode == MV_PMODE_1MV || v->mv_mode == MV_PMODE_MIXED_MV);\n\n            v->s.mspel          = !(v->mv_mode == MV_PMODE_1MV_HPEL_BILIN || v->mv_mode == MV_PMODE_1MV_HPEL);\n\n            status = bitplane_decoding(v->forward_mb_plane, &v->fmb_is_raw, v);\n\n            if (status < 0)\n\n                return -1;\n\n            av_log(v->s.avctx, AV_LOG_DEBUG, \"MB Forward Type plane encoding: \"\n\n                   \"Imode: %i, Invert: %i\\n\", status>>1, status&1);\n\n            mbmodetab = get_bits(gb, 3);\n\n            if (v->mv_mode == MV_PMODE_MIXED_MV)\n\n                v->mbmode_vlc = &ff_vc1_if_mmv_mbmode_vlc[mbmodetab];\n\n            else\n\n                v->mbmode_vlc = &ff_vc1_if_1mv_mbmode_vlc[mbmodetab];\n\n            imvtab       = get_bits(gb, 3);\n\n            v->imv_vlc   = &ff_vc1_2ref_mvdata_vlc[imvtab];\n\n            icbptab      = get_bits(gb, 3);\n\n            v->cbpcy_vlc = &ff_vc1_icbpcy_vlc[icbptab];\n\n            if (v->mv_mode == MV_PMODE_MIXED_MV) {\n\n                fourmvbptab     = get_bits(gb, 2);\n\n                v->fourmvbp_vlc = &ff_vc1_4mv_block_pattern_vlc[fourmvbptab];\n\n            }\n\n            v->numref = 1; // interlaced field B pictures are always 2-ref\n\n        } else {\n\n            v->mv_mode          = get_bits1(gb) ? MV_PMODE_1MV : MV_PMODE_1MV_HPEL_BILIN;\n\n            v->qs_last          = v->s.quarter_sample;\n\n            v->s.quarter_sample = (v->mv_mode == MV_PMODE_1MV);\n\n            v->s.mspel          = v->s.quarter_sample;\n\n            status              = bitplane_decoding(v->direct_mb_plane, &v->dmb_is_raw, v);\n\n            if (status < 0)\n\n                return -1;\n\n            av_log(v->s.avctx, AV_LOG_DEBUG, \"MB Direct Type plane encoding: \"\n\n                   \"Imode: %i, Invert: %i\\n\", status>>1, status&1);\n\n            status = bitplane_decoding(v->s.mbskip_table, &v->skip_is_raw, v);\n\n            if (status < 0)\n\n                return -1;\n\n            av_log(v->s.avctx, AV_LOG_DEBUG, \"MB Skip plane encoding: \"\n\n                   \"Imode: %i, Invert: %i\\n\", status>>1, status&1);\n\n            v->s.mv_table_index = get_bits(gb, 2);\n\n            v->cbpcy_vlc = &ff_vc1_cbpcy_p_vlc[get_bits(gb, 2)];\n\n        }\n\n\n\n        if (v->dquant) {\n\n            av_log(v->s.avctx, AV_LOG_DEBUG, \"VOP DQuant info\\n\");\n\n            vop_dquant_decoding(v);\n\n        }\n\n\n\n        v->ttfrm = 0;\n\n        if (v->vstransform) {\n\n            v->ttmbf = get_bits1(gb);\n\n            if (v->ttmbf) {\n\n                v->ttfrm = ff_vc1_ttfrm_to_tt[get_bits(gb, 2)];\n\n            }\n\n        } else {\n\n            v->ttmbf = 1;\n\n            v->ttfrm = TT_8X8;\n\n        }\n\n        break;\n\n    }\n\n\n\n    /* AC Syntax */\n\n    v->c_ac_table_index = decode012(gb);\n\n    if (v->s.pict_type == AV_PICTURE_TYPE_I || v->s.pict_type == AV_PICTURE_TYPE_BI) {\n\n        v->y_ac_table_index = decode012(gb);\n\n    }\n\n    /* DC Syntax */\n\n    v->s.dc_table_index = get_bits1(gb);\n\n    if ((v->s.pict_type == AV_PICTURE_TYPE_I || v->s.pict_type == AV_PICTURE_TYPE_BI)\n\n        && v->dquant) {\n\n        av_log(v->s.avctx, AV_LOG_DEBUG, \"VOP DQuant info\\n\");\n\n        vop_dquant_decoding(v);\n\n    }\n\n\n\n    v->bi_type = 0;\n\n    if (v->s.pict_type == AV_PICTURE_TYPE_BI) {\n\n        v->s.pict_type = AV_PICTURE_TYPE_B;\n\n        v->bi_type = 1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 25380}
{"project": "FFmpeg", "commit_id": "a779602584b43578e8baa69b367ba7d64e973dd0", "target": 1, "func": "static int decode_mb(MadContext *s, AVFrame *frame, int inter)\n\n{\n\n    int mv_map = 0;\n\n    int mv_x, mv_y;\n\n    int j;\n\n\n\n    if (inter) {\n\n        int v = decode210(&s->gb);\n\n        if (v < 2) {\n\n            mv_map = v ? get_bits(&s->gb, 6) : 63;\n\n            mv_x = decode_motion(&s->gb);\n\n            mv_y = decode_motion(&s->gb);\n\n        }\n\n    }\n\n\n\n    for (j=0; j<6; j++) {\n\n        if (mv_map & (1<<j)) {  // mv_x and mv_y are guarded by mv_map\n\n            int add = 2*decode_motion(&s->gb);\n\n            if (s->last_frame->data[0])\n\n                comp_block(s, frame, s->mb_x, s->mb_y, j, mv_x, mv_y, add);\n\n        } else {\n\n            s->dsp.clear_block(s->block);\n\n            if(decode_block_intra(s, s->block) < 0)\n\n                return -1;\n\n            idct_put(s, frame, s->block, s->mb_x, s->mb_y, j);\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 25381}
{"project": "FFmpeg", "commit_id": "06205b5efdcf0bc4c5463bfdd02f09b5f79fc4cd", "target": 1, "func": "static int hls_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    HLSContext *c = s->priv_data;\n\n    int ret, i, minvariant = -1;\n\n\n\n    if (c->first_packet) {\n\n        recheck_discard_flags(s, 1);\n\n        c->first_packet = 0;\n\n    }\n\n\n\nstart:\n\n    c->end_of_segment = 0;\n\n    for (i = 0; i < c->n_variants; i++) {\n\n        struct variant *var = c->variants[i];\n\n        /* Make sure we've got one buffered packet from each open variant\n\n         * stream */\n\n        if (var->needed && !var->pkt.data) {\n\n            while (1) {\n\n                int64_t ts_diff;\n\n                AVStream *st;\n\n                ret = av_read_frame(var->ctx, &var->pkt);\n\n                if (ret < 0) {\n\n                    if (!var->pb.eof_reached)\n\n                        return ret;\n\n\n                    break;\n\n                } else {\n\n                    if (c->first_timestamp == AV_NOPTS_VALUE &&\n\n                        var->pkt.dts       != AV_NOPTS_VALUE)\n\n                        c->first_timestamp = av_rescale_q(var->pkt.dts,\n\n                            var->ctx->streams[var->pkt.stream_index]->time_base,\n\n                            AV_TIME_BASE_Q);\n\n                }\n\n\n\n                if (c->seek_timestamp == AV_NOPTS_VALUE)\n\n                    break;\n\n\n\n                if (var->pkt.dts == AV_NOPTS_VALUE) {\n\n                    c->seek_timestamp = AV_NOPTS_VALUE;\n\n                    break;\n\n                }\n\n\n\n                st = var->ctx->streams[var->pkt.stream_index];\n\n                ts_diff = av_rescale_rnd(var->pkt.dts, AV_TIME_BASE,\n\n                                         st->time_base.den, AV_ROUND_DOWN) -\n\n                          c->seek_timestamp;\n\n                if (ts_diff >= 0 && (c->seek_flags  & AVSEEK_FLAG_ANY ||\n\n                                     var->pkt.flags & AV_PKT_FLAG_KEY)) {\n\n                    c->seek_timestamp = AV_NOPTS_VALUE;\n\n                    break;\n\n                }\n\n\n\n            }\n\n        }\n\n        /* Check if this stream still is on an earlier segment number, or\n\n         * has the packet with the lowest dts */\n\n        if (var->pkt.data) {\n\n            struct variant *minvar = c->variants[minvariant];\n\n            if (minvariant < 0 || var->cur_seq_no < minvar->cur_seq_no) {\n\n                minvariant = i;\n\n            } else if (var->cur_seq_no == minvar->cur_seq_no) {\n\n                int64_t dts     =    var->pkt.dts;\n\n                int64_t mindts  = minvar->pkt.dts;\n\n                AVStream *st    =    var->ctx->streams[var->pkt.stream_index];\n\n                AVStream *minst = minvar->ctx->streams[minvar->pkt.stream_index];\n\n\n\n                if (dts == AV_NOPTS_VALUE) {\n\n                    minvariant = i;\n\n                } else if (mindts != AV_NOPTS_VALUE) {\n\n                    if (st->start_time    != AV_NOPTS_VALUE)\n\n                        dts    -= st->start_time;\n\n                    if (minst->start_time != AV_NOPTS_VALUE)\n\n                        mindts -= minst->start_time;\n\n\n\n                    if (av_compare_ts(dts, st->time_base,\n\n                                      mindts, minst->time_base) < 0)\n\n                        minvariant = i;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    if (c->end_of_segment) {\n\n        if (recheck_discard_flags(s, 0))\n\n            goto start;\n\n    }\n\n    /* If we got a packet, return it */\n\n    if (minvariant >= 0) {\n\n        *pkt = c->variants[minvariant]->pkt;\n\n        pkt->stream_index += c->variants[minvariant]->stream_offset;\n\n        reset_packet(&c->variants[minvariant]->pkt);\n\n        return 0;\n\n    }\n\n    return AVERROR_EOF;\n\n}", "idx": 25383}
{"project": "FFmpeg", "commit_id": "c341f734e5f9d6af4a8fdcceb6f5d12de6395c76", "target": 1, "func": "static inline void qpel_motion(MpegEncContext *s,\n\n                               uint8_t *dest_y, uint8_t *dest_cb, uint8_t *dest_cr,\n\n                               int field_based, int bottom_field, int field_select,\n\n                               uint8_t **ref_picture, op_pixels_func (*pix_op)[4],\n\n                               qpel_mc_func (*qpix_op)[16],\n\n                               int motion_x, int motion_y, int h)\n\n{\n\n    uint8_t *ptr_y, *ptr_cb, *ptr_cr;\n\n    int dxy, uvdxy, mx, my, src_x, src_y, uvsrc_x, uvsrc_y, v_edge_pos, linesize, uvlinesize;\n\n\n\n    dxy = ((motion_y & 3) << 2) | (motion_x & 3);\n\n    src_x = s->mb_x *  16                 + (motion_x >> 2);\n\n    src_y = s->mb_y * (16 >> field_based) + (motion_y >> 2);\n\n\n\n    v_edge_pos = s->v_edge_pos >> field_based;\n\n    linesize = s->linesize << field_based;\n\n    uvlinesize = s->uvlinesize << field_based;\n\n\n\n    if(field_based){\n\n        mx= motion_x/2;\n\n        my= motion_y>>1;\n\n    }else if(s->workaround_bugs&FF_BUG_QPEL_CHROMA2){\n\n        static const int rtab[8]= {0,0,1,1,0,0,0,1};\n\n        mx= (motion_x>>1) + rtab[motion_x&7];\n\n        my= (motion_y>>1) + rtab[motion_y&7];\n\n    }else if(s->workaround_bugs&FF_BUG_QPEL_CHROMA){\n\n        mx= (motion_x>>1)|(motion_x&1);\n\n        my= (motion_y>>1)|(motion_y&1);\n\n    }else{\n\n        mx= motion_x/2;\n\n        my= motion_y/2;\n\n    }\n\n    mx= (mx>>1)|(mx&1);\n\n    my= (my>>1)|(my&1);\n\n\n\n    uvdxy= (mx&1) | ((my&1)<<1);\n\n    mx>>=1;\n\n    my>>=1;\n\n\n\n    uvsrc_x = s->mb_x *  8                 + mx;\n\n    uvsrc_y = s->mb_y * (8 >> field_based) + my;\n\n\n\n    ptr_y  = ref_picture[0] +   src_y *   linesize +   src_x;\n\n    ptr_cb = ref_picture[1] + uvsrc_y * uvlinesize + uvsrc_x;\n\n    ptr_cr = ref_picture[2] + uvsrc_y * uvlinesize + uvsrc_x;\n\n\n\n    if(   (unsigned)src_x > FFMAX(s->h_edge_pos - (motion_x&3) - 16, 0)\n\n       || (unsigned)src_y > FFMAX(   v_edge_pos - (motion_y&3) - h , 0)){\n\n        s->vdsp.emulated_edge_mc(s->edge_emu_buffer, ptr_y, s->linesize,\n\n                            17, 17+field_based, src_x, src_y<<field_based,\n\n                            s->h_edge_pos, s->v_edge_pos);\n\n        ptr_y= s->edge_emu_buffer;\n\n        if(!CONFIG_GRAY || !(s->flags&CODEC_FLAG_GRAY)){\n\n            uint8_t *uvbuf= s->edge_emu_buffer + 18*s->linesize;\n\n            s->vdsp.emulated_edge_mc(uvbuf, ptr_cb, s->uvlinesize,\n\n                                9, 9 + field_based,\n\n                                uvsrc_x, uvsrc_y<<field_based,\n\n                                s->h_edge_pos>>1, s->v_edge_pos>>1);\n\n            s->vdsp.emulated_edge_mc(uvbuf + 16, ptr_cr, s->uvlinesize,\n\n                                9, 9 + field_based,\n\n                                uvsrc_x, uvsrc_y<<field_based,\n\n                                s->h_edge_pos>>1, s->v_edge_pos>>1);\n\n            ptr_cb= uvbuf;\n\n            ptr_cr= uvbuf + 16;\n\n        }\n\n    }\n\n\n\n    if(!field_based)\n\n        qpix_op[0][dxy](dest_y, ptr_y, linesize);\n\n    else{\n\n        if(bottom_field){\n\n            dest_y += s->linesize;\n\n            dest_cb+= s->uvlinesize;\n\n            dest_cr+= s->uvlinesize;\n\n        }\n\n\n\n        if(field_select){\n\n            ptr_y  += s->linesize;\n\n            ptr_cb += s->uvlinesize;\n\n            ptr_cr += s->uvlinesize;\n\n        }\n\n        //damn interlaced mode\n\n        //FIXME boundary mirroring is not exactly correct here\n\n        qpix_op[1][dxy](dest_y  , ptr_y  , linesize);\n\n        qpix_op[1][dxy](dest_y+8, ptr_y+8, linesize);\n\n    }\n\n    if(!CONFIG_GRAY || !(s->flags&CODEC_FLAG_GRAY)){\n\n        pix_op[1][uvdxy](dest_cr, ptr_cr, uvlinesize, h >> 1);\n\n        pix_op[1][uvdxy](dest_cb, ptr_cb, uvlinesize, h >> 1);\n\n    }\n\n}\n", "idx": 25387}
{"project": "FFmpeg", "commit_id": "dae7ff04160901a30a35af05f2f149b289c4f0b1", "target": 1, "func": "static int decode_packet(AVCodecContext *avctx,\n\n                         void *data, int *data_size, AVPacket* avpkt)\n\n{\n\n    WmallDecodeCtx *s = avctx->priv_data;\n\n    GetBitContext* gb  = &s->pgb;\n\n    const uint8_t* buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    int num_bits_prev_frame;\n\n    int packet_sequence_number;\n\n\n\n    s->samples       = data;\n\n    s->samples_end   = (float*)((int8_t*)data + *data_size);\n\n    *data_size = 0;\n\n\n\n    if (s->packet_done || s->packet_loss) {\n\n        s->packet_done = 0;\n\n\n\n        /** sanity check for the buffer length */\n\n        if (buf_size < avctx->block_align)\n\n            return 0;\n\n\n\n        s->next_packet_start = buf_size - avctx->block_align;\n\n        buf_size = avctx->block_align;\n\n        s->buf_bit_size = buf_size << 3;\n\n\n\n        /** parse packet header */\n\n        init_get_bits(gb, buf, s->buf_bit_size);\n\n        packet_sequence_number = get_bits(gb, 4);\n\n\tint seekable_frame_in_packet = get_bits1(gb);\n\n\tint spliced_packet = get_bits1(gb);\n\n\n\n        /** get number of bits that need to be added to the previous frame */\n\n        num_bits_prev_frame = get_bits(gb, s->log2_frame_size);\n\n\n\n        /** check for packet loss */\n\n        if (!s->packet_loss &&\n\n            ((s->packet_sequence_number + 1) & 0xF) != packet_sequence_number) {\n\n            s->packet_loss = 1;\n\n            av_log(avctx, AV_LOG_ERROR, \"Packet loss detected! seq %x vs %x\\n\",\n\n                   s->packet_sequence_number, packet_sequence_number);\n\n        }\n\n        s->packet_sequence_number = packet_sequence_number;\n\n\n\n        if (num_bits_prev_frame > 0) {\n\n            int remaining_packet_bits = s->buf_bit_size - get_bits_count(gb);\n\n            if (num_bits_prev_frame >= remaining_packet_bits) {\n\n                num_bits_prev_frame = remaining_packet_bits;\n\n                s->packet_done = 1;\n\n            }\n\n\n\n            /** append the previous frame data to the remaining data from the\n\n                previous packet to create a full frame */\n\n            save_bits(s, gb, num_bits_prev_frame, 1);\n\n\n\n            /** decode the cross packet frame if it is valid */\n\n            if (!s->packet_loss)\n\n\t\tdecode_frame(s);\n\n        } else if (s->num_saved_bits - s->frame_offset) {\n\n            dprintf(avctx, \"ignoring %x previously saved bits\\n\",\n\n                    s->num_saved_bits - s->frame_offset);\n\n        }\n\n\n\n        if (s->packet_loss) {\n\n            /** reset number of saved bits so that the decoder\n\n                does not start to decode incomplete frames in the\n\n                s->len_prefix == 0 case */\n\n            s->num_saved_bits = 0;\n\n            s->packet_loss = 0;\n\n        }\n\n\n\n    } else {\n\n        int frame_size;\n\n\n\n        s->buf_bit_size = (avpkt->size - s->next_packet_start) << 3;\n\n        init_get_bits(gb, avpkt->data, s->buf_bit_size);\n\n        skip_bits(gb, s->packet_offset);\n\n\n\n        if (s->len_prefix && remaining_bits(s, gb) > s->log2_frame_size &&\n\n            (frame_size = show_bits(gb, s->log2_frame_size)) &&\n\n            frame_size <= remaining_bits(s, gb)) {\n\n            save_bits(s, gb, frame_size, 0);\n\n            s->packet_done = !decode_frame(s);\n\n        } else if (!s->len_prefix\n\n                   && s->num_saved_bits > get_bits_count(&s->gb)) {\n\n            /** when the frames do not have a length prefix, we don't know\n\n                the compressed length of the individual frames\n\n                however, we know what part of a new packet belongs to the\n\n                previous frame\n\n                therefore we save the incoming packet first, then we append\n\n                the \"previous frame\" data from the next packet so that\n\n                we get a buffer that only contains full frames */\n\n            s->packet_done = !decode_frame(s);\n\n        } else {\n\n            s->packet_done = 1;\n\n\t}\n\n    }\n\n\n\n    if (s->packet_done && !s->packet_loss &&\n\n        remaining_bits(s, gb) > 0) {\n\n        /** save the rest of the data so that it can be decoded\n\n            with the next packet */\n\n        save_bits(s, gb, remaining_bits(s, gb), 0);\n\n    }\n\n\n\n    *data_size = 0; // (int8_t *)s->samples - (int8_t *)data;\n\n    s->packet_offset = get_bits_count(gb) & 7;\n\n\n\n    return (s->packet_loss) ? AVERROR_INVALIDDATA : get_bits_count(gb) >> 3;\n\n}\n", "idx": 25392}
{"project": "FFmpeg", "commit_id": "31247669593e5bf6571192f5e8888ccabd050ec8", "target": 1, "func": "static int asf_read_header(AVFormatContext *s, AVFormatParameters *ap)\n\n{\n\n    ASFContext *asf = s->priv_data;\n\n    ff_asf_guid g;\n\n    ByteIOContext *pb = s->pb;\n\n    AVStream *st;\n\n    ASFStream *asf_st;\n\n    int size, i;\n\n    int64_t gsize;\n\n    AVRational dar[128];\n\n    uint32_t bitrate[128];\n\n\n\n    memset(dar, 0, sizeof(dar));\n\n    memset(bitrate, 0, sizeof(bitrate));\n\n\n\n    get_guid(pb, &g);\n\n    if (guidcmp(&g, &ff_asf_header))\n\n        return -1;\n\n    get_le64(pb);\n\n    get_le32(pb);\n\n    get_byte(pb);\n\n    get_byte(pb);\n\n    memset(&asf->asfid2avid, -1, sizeof(asf->asfid2avid));\n\n    for(;;) {\n\n        uint64_t gpos= url_ftell(pb);\n\n        get_guid(pb, &g);\n\n        gsize = get_le64(pb);\n\n        dprintf(s, \"%08\"PRIx64\": \", gpos);\n\n        print_guid(&g);\n\n        dprintf(s, \"  size=0x%\"PRIx64\"\\n\", gsize);\n\n        if (!guidcmp(&g, &ff_asf_data_header)) {\n\n            asf->data_object_offset = url_ftell(pb);\n\n            // if not streaming, gsize is not unlimited (how?), and there is enough space in the file..\n\n            if (!(asf->hdr.flags & 0x01) && gsize >= 100) {\n\n                asf->data_object_size = gsize - 24;\n\n            } else {\n\n                asf->data_object_size = (uint64_t)-1;\n\n            }\n\n            break;\n\n        }\n\n        if (gsize < 24)\n\n            return -1;\n\n        if (!guidcmp(&g, &ff_asf_file_header)) {\n\n            get_guid(pb, &asf->hdr.guid);\n\n            asf->hdr.file_size          = get_le64(pb);\n\n            asf->hdr.create_time        = get_le64(pb);\n\n            asf->nb_packets             = get_le64(pb);\n\n            asf->hdr.play_time          = get_le64(pb);\n\n            asf->hdr.send_time          = get_le64(pb);\n\n            asf->hdr.preroll            = get_le32(pb);\n\n            asf->hdr.ignore             = get_le32(pb);\n\n            asf->hdr.flags              = get_le32(pb);\n\n            asf->hdr.min_pktsize        = get_le32(pb);\n\n            asf->hdr.max_pktsize        = get_le32(pb);\n\n            asf->hdr.max_bitrate        = get_le32(pb);\n\n            s->packet_size = asf->hdr.max_pktsize;\n\n        } else if (!guidcmp(&g, &ff_asf_stream_header)) {\n\n            enum AVMediaType type;\n\n            int type_specific_size, sizeX;\n\n            uint64_t total_size;\n\n            unsigned int tag1;\n\n            int64_t pos1, pos2, start_time;\n\n            int test_for_ext_stream_audio, is_dvr_ms_audio=0;\n\n\n\n            if (s->nb_streams == ASF_MAX_STREAMS) {\n\n                av_log(s, AV_LOG_ERROR, \"too many streams\\n\");\n\n                return AVERROR(EINVAL);\n\n            }\n\n\n\n            pos1 = url_ftell(pb);\n\n\n\n            st = av_new_stream(s, 0);\n\n            if (!st)\n\n                return AVERROR(ENOMEM);\n\n            av_set_pts_info(st, 32, 1, 1000); /* 32 bit pts in ms */\n\n            asf_st = av_mallocz(sizeof(ASFStream));\n\n            if (!asf_st)\n\n                return AVERROR(ENOMEM);\n\n            st->priv_data = asf_st;\n\n            start_time = asf->hdr.preroll;\n\n\n\n            asf_st->stream_language_index = 128; // invalid stream index means no language info\n\n\n\n            if(!(asf->hdr.flags & 0x01)) { // if we aren't streaming...\n\n                st->duration = asf->hdr.play_time /\n\n                    (10000000 / 1000) - start_time;\n\n            }\n\n            get_guid(pb, &g);\n\n\n\n            test_for_ext_stream_audio = 0;\n\n            if (!guidcmp(&g, &ff_asf_audio_stream)) {\n\n                type = AVMEDIA_TYPE_AUDIO;\n\n            } else if (!guidcmp(&g, &ff_asf_video_stream)) {\n\n                type = AVMEDIA_TYPE_VIDEO;\n\n            } else if (!guidcmp(&g, &ff_asf_command_stream)) {\n\n                type = AVMEDIA_TYPE_DATA;\n\n            } else if (!guidcmp(&g, &ff_asf_ext_stream_embed_stream_header)) {\n\n                test_for_ext_stream_audio = 1;\n\n                type = AVMEDIA_TYPE_UNKNOWN;\n\n            } else {\n\n                return -1;\n\n            }\n\n            get_guid(pb, &g);\n\n            total_size = get_le64(pb);\n\n            type_specific_size = get_le32(pb);\n\n            get_le32(pb);\n\n            st->id = get_le16(pb) & 0x7f; /* stream id */\n\n            // mapping of asf ID to AV stream ID;\n\n            asf->asfid2avid[st->id] = s->nb_streams - 1;\n\n\n\n            get_le32(pb);\n\n\n\n            if (test_for_ext_stream_audio) {\n\n                get_guid(pb, &g);\n\n                if (!guidcmp(&g, &ff_asf_ext_stream_audio_stream)) {\n\n                    type = AVMEDIA_TYPE_AUDIO;\n\n                    is_dvr_ms_audio=1;\n\n                    get_guid(pb, &g);\n\n                    get_le32(pb);\n\n                    get_le32(pb);\n\n                    get_le32(pb);\n\n                    get_guid(pb, &g);\n\n                    get_le32(pb);\n\n                }\n\n            }\n\n\n\n            st->codec->codec_type = type;\n\n            if (type == AVMEDIA_TYPE_AUDIO) {\n\n                ff_get_wav_header(pb, st->codec, type_specific_size);\n\n                if (is_dvr_ms_audio) {\n\n                    // codec_id and codec_tag are unreliable in dvr_ms\n\n                    // files. Set them later by probing stream.\n\n                    st->codec->codec_id = CODEC_ID_PROBE;\n\n                    st->codec->codec_tag = 0;\n\n                }\n\n                if (st->codec->codec_id == CODEC_ID_AAC) {\n\n                    st->need_parsing = AVSTREAM_PARSE_NONE;\n\n                } else {\n\n                    st->need_parsing = AVSTREAM_PARSE_FULL;\n\n                }\n\n                /* We have to init the frame size at some point .... */\n\n                pos2 = url_ftell(pb);\n\n                if (gsize >= (pos2 + 8 - pos1 + 24)) {\n\n                    asf_st->ds_span = get_byte(pb);\n\n                    asf_st->ds_packet_size = get_le16(pb);\n\n                    asf_st->ds_chunk_size = get_le16(pb);\n\n                    get_le16(pb); //ds_data_size\n\n                    get_byte(pb); //ds_silence_data\n\n                }\n\n                //printf(\"Descrambling: ps:%d cs:%d ds:%d s:%d  sd:%d\\n\",\n\n                //       asf_st->ds_packet_size, asf_st->ds_chunk_size,\n\n                //       asf_st->ds_data_size, asf_st->ds_span, asf_st->ds_silence_data);\n\n                if (asf_st->ds_span > 1) {\n\n                    if (!asf_st->ds_chunk_size\n\n                        || (asf_st->ds_packet_size/asf_st->ds_chunk_size <= 1)\n\n                        || asf_st->ds_packet_size % asf_st->ds_chunk_size)\n\n                        asf_st->ds_span = 0; // disable descrambling\n\n                }\n\n                switch (st->codec->codec_id) {\n\n                case CODEC_ID_MP3:\n\n                    st->codec->frame_size = MPA_FRAME_SIZE;\n\n                    break;\n\n                case CODEC_ID_PCM_S16LE:\n\n                case CODEC_ID_PCM_S16BE:\n\n                case CODEC_ID_PCM_U16LE:\n\n                case CODEC_ID_PCM_U16BE:\n\n                case CODEC_ID_PCM_S8:\n\n                case CODEC_ID_PCM_U8:\n\n                case CODEC_ID_PCM_ALAW:\n\n                case CODEC_ID_PCM_MULAW:\n\n                    st->codec->frame_size = 1;\n\n                    break;\n\n                default:\n\n                    /* This is probably wrong, but it prevents a crash later */\n\n                    st->codec->frame_size = 1;\n\n                    break;\n\n                }\n\n            } else if (type == AVMEDIA_TYPE_VIDEO) {\n\n                get_le32(pb);\n\n                get_le32(pb);\n\n                get_byte(pb);\n\n                size = get_le16(pb); /* size */\n\n                sizeX= get_le32(pb); /* size */\n\n                st->codec->width = get_le32(pb);\n\n                st->codec->height = get_le32(pb);\n\n                /* not available for asf */\n\n                get_le16(pb); /* panes */\n\n                st->codec->bits_per_coded_sample = get_le16(pb); /* depth */\n\n                tag1 = get_le32(pb);\n\n                url_fskip(pb, 20);\n\n//                av_log(s, AV_LOG_DEBUG, \"size:%d tsize:%d sizeX:%d\\n\", size, total_size, sizeX);\n\n                size= sizeX;\n\n                if (size > 40) {\n\n                    st->codec->extradata_size = size - 40;\n\n                    st->codec->extradata = av_mallocz(st->codec->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                    get_buffer(pb, st->codec->extradata, st->codec->extradata_size);\n\n                }\n\n\n\n                /* Extract palette from extradata if bpp <= 8 */\n\n                /* This code assumes that extradata contains only palette */\n\n                /* This is true for all paletted codecs implemented in ffmpeg */\n\n                if (st->codec->extradata_size && (st->codec->bits_per_coded_sample <= 8)) {\n\n                    st->codec->palctrl = av_mallocz(sizeof(AVPaletteControl));\n\n#if HAVE_BIGENDIAN\n\n                    for (i = 0; i < FFMIN(st->codec->extradata_size, AVPALETTE_SIZE)/4; i++)\n\n                        st->codec->palctrl->palette[i] = bswap_32(((uint32_t*)st->codec->extradata)[i]);\n\n#else\n\n                    memcpy(st->codec->palctrl->palette, st->codec->extradata,\n\n                           FFMIN(st->codec->extradata_size, AVPALETTE_SIZE));\n\n#endif\n\n                    st->codec->palctrl->palette_changed = 1;\n\n                }\n\n\n\n                st->codec->codec_tag = tag1;\n\n                st->codec->codec_id = ff_codec_get_id(ff_codec_bmp_tags, tag1);\n\n                if(tag1 == MKTAG('D', 'V', 'R', ' '))\n\n                    st->need_parsing = AVSTREAM_PARSE_FULL;\n\n                if(st->codec->codec_id == CODEC_ID_H264)\n\n                    st->need_parsing = AVSTREAM_PARSE_FULL_ONCE;\n\n            }\n\n            pos2 = url_ftell(pb);\n\n            url_fskip(pb, gsize - (pos2 - pos1 + 24));\n\n        } else if (!guidcmp(&g, &ff_asf_comment_header)) {\n\n            int len1, len2, len3, len4, len5;\n\n\n\n            len1 = get_le16(pb);\n\n            len2 = get_le16(pb);\n\n            len3 = get_le16(pb);\n\n            len4 = get_le16(pb);\n\n            len5 = get_le16(pb);\n\n            get_tag(s, \"title\"    , 0, len1);\n\n            get_tag(s, \"author\"   , 0, len2);\n\n            get_tag(s, \"copyright\", 0, len3);\n\n            get_tag(s, \"comment\"  , 0, len4);\n\n            url_fskip(pb, len5);\n\n        } else if (!guidcmp(&g, &stream_bitrate_guid)) {\n\n            int stream_count = get_le16(pb);\n\n            int j;\n\n\n\n//            av_log(s, AV_LOG_ERROR, \"stream bitrate properties\\n\");\n\n//            av_log(s, AV_LOG_ERROR, \"streams %d\\n\", streams);\n\n            for(j = 0; j < stream_count; j++) {\n\n                int flags, bitrate, stream_id;\n\n\n\n                flags= get_le16(pb);\n\n                bitrate= get_le32(pb);\n\n                stream_id= (flags & 0x7f);\n\n//                av_log(s, AV_LOG_ERROR, \"flags: 0x%x stream id %d, bitrate %d\\n\", flags, stream_id, bitrate);\n\n                asf->stream_bitrates[stream_id]= bitrate;\n\n            }\n\n        } else if (!guidcmp(&g, &ff_asf_language_guid)) {\n\n            int j;\n\n            int stream_count = get_le16(pb);\n\n            for(j = 0; j < stream_count; j++) {\n\n                char lang[6];\n\n                unsigned int lang_len = get_byte(pb);\n\n                get_str16_nolen(pb, lang_len, lang, sizeof(lang));\n\n                if (j < 128)\n\n                    av_strlcpy(asf->stream_languages[j], lang, sizeof(*asf->stream_languages));\n\n            }\n\n        } else if (!guidcmp(&g, &ff_asf_extended_content_header)) {\n\n            int desc_count, i;\n\n\n\n            desc_count = get_le16(pb);\n\n            for(i=0;i<desc_count;i++) {\n\n                    int name_len,value_type,value_len;\n\n                    char name[1024];\n\n\n\n                    name_len = get_le16(pb);\n\n                    if (name_len%2)     // must be even, broken lavf versions wrote len-1\n\n                        name_len += 1;\n\n                    get_str16_nolen(pb, name_len, name, sizeof(name));\n\n                    value_type = get_le16(pb);\n\n                    value_len  = get_le16(pb);\n\n                    if (!value_type && value_len%2)\n\n                        value_len += 1;\n\n                    get_tag(s, name, value_type, value_len);\n\n            }\n\n        } else if (!guidcmp(&g, &ff_asf_metadata_header)) {\n\n            int n, stream_num, name_len, value_len, value_type, value_num;\n\n            n = get_le16(pb);\n\n\n\n            for(i=0;i<n;i++) {\n\n                char name[1024];\n\n\n\n                get_le16(pb); //lang_list_index\n\n                stream_num= get_le16(pb);\n\n                name_len=   get_le16(pb);\n\n                value_type= get_le16(pb);\n\n                value_len=  get_le32(pb);\n\n\n\n                get_str16_nolen(pb, name_len, name, sizeof(name));\n\n//av_log(s, AV_LOG_ERROR, \"%d %d %d %d %d <%s>\\n\", i, stream_num, name_len, value_type, value_len, name);\n\n                value_num= get_le16(pb);//we should use get_value() here but it does not work 2 is le16 here but le32 elsewhere\n\n                url_fskip(pb, value_len - 2);\n\n\n\n                if(stream_num<128){\n\n                    if     (!strcmp(name, \"AspectRatioX\")) dar[stream_num].num= value_num;\n\n                    else if(!strcmp(name, \"AspectRatioY\")) dar[stream_num].den= value_num;\n\n                }\n\n            }\n\n        } else if (!guidcmp(&g, &ff_asf_ext_stream_header)) {\n\n            int ext_len, payload_ext_ct, stream_ct;\n\n            uint32_t ext_d, leak_rate, stream_num;\n\n            unsigned int stream_languageid_index;\n\n\n\n            get_le64(pb); // starttime\n\n            get_le64(pb); // endtime\n\n            leak_rate = get_le32(pb); // leak-datarate\n\n            get_le32(pb); // bucket-datasize\n\n            get_le32(pb); // init-bucket-fullness\n\n            get_le32(pb); // alt-leak-datarate\n\n            get_le32(pb); // alt-bucket-datasize\n\n            get_le32(pb); // alt-init-bucket-fullness\n\n            get_le32(pb); // max-object-size\n\n            get_le32(pb); // flags (reliable,seekable,no_cleanpoints?,resend-live-cleanpoints, rest of bits reserved)\n\n            stream_num = get_le16(pb); // stream-num\n\n\n\n            stream_languageid_index = get_le16(pb); // stream-language-id-index\n\n            if (stream_num < 128)\n\n                asf->streams[stream_num].stream_language_index = stream_languageid_index;\n\n\n\n            get_le64(pb); // avg frametime in 100ns units\n\n            stream_ct = get_le16(pb); //stream-name-count\n\n            payload_ext_ct = get_le16(pb); //payload-extension-system-count\n\n\n\n            if (stream_num < 128)\n\n                bitrate[stream_num] = leak_rate;\n\n\n\n            for (i=0; i<stream_ct; i++){\n\n                get_le16(pb);\n\n                ext_len = get_le16(pb);\n\n                url_fseek(pb, ext_len, SEEK_CUR);\n\n            }\n\n\n\n            for (i=0; i<payload_ext_ct; i++){\n\n                get_guid(pb, &g);\n\n                ext_d=get_le16(pb);\n\n                ext_len=get_le32(pb);\n\n                url_fseek(pb, ext_len, SEEK_CUR);\n\n            }\n\n\n\n            // there could be a optional stream properties object to follow\n\n            // if so the next iteration will pick it up\n\n            continue;\n\n        } else if (!guidcmp(&g, &ff_asf_head1_guid)) {\n\n            int v1, v2;\n\n            get_guid(pb, &g);\n\n            v1 = get_le32(pb);\n\n            v2 = get_le16(pb);\n\n            continue;\n\n        } else if (!guidcmp(&g, &ff_asf_marker_header)) {\n\n            int i, count, name_len;\n\n            char name[1024];\n\n\n\n            get_le64(pb);            // reserved 16 bytes\n\n            get_le64(pb);            // ...\n\n            count = get_le32(pb);    // markers count\n\n            get_le16(pb);            // reserved 2 bytes\n\n            name_len = get_le16(pb); // name length\n\n            for(i=0;i<name_len;i++){\n\n                get_byte(pb); // skip the name\n\n            }\n\n\n\n            for(i=0;i<count;i++){\n\n                int64_t pres_time;\n\n                int name_len;\n\n\n\n                get_le64(pb);             // offset, 8 bytes\n\n                pres_time = get_le64(pb); // presentation time\n\n                get_le16(pb);             // entry length\n\n                get_le32(pb);             // send time\n\n                get_le32(pb);             // flags\n\n                name_len = get_le32(pb);  // name length\n\n                get_str16_nolen(pb, name_len * 2, name, sizeof(name));\n\n                ff_new_chapter(s, i, (AVRational){1, 10000000}, pres_time, AV_NOPTS_VALUE, name );\n\n            }\n\n#if 0\n\n        } else if (!guidcmp(&g, &ff_asf_codec_comment_header)) {\n\n            int len, v1, n, num;\n\n            char str[256], *q;\n\n            char tag[16];\n\n\n\n            get_guid(pb, &g);\n\n            print_guid(&g);\n\n\n\n            n = get_le32(pb);\n\n            for(i=0;i<n;i++) {\n\n                num = get_le16(pb); /* stream number */\n\n                get_str16(pb, str, sizeof(str));\n\n                get_str16(pb, str, sizeof(str));\n\n                len = get_le16(pb);\n\n                q = tag;\n\n                while (len > 0) {\n\n                    v1 = get_byte(pb);\n\n                    if ((q - tag) < sizeof(tag) - 1)\n\n                        *q++ = v1;\n\n                    len--;\n\n                }\n\n                *q = '\\0';\n\n            }\n\n#endif\n\n        } else if (url_feof(pb)) {\n\n            return -1;\n\n        } else {\n\n            if (!s->keylen) {\n\n                if (!guidcmp(&g, &ff_asf_content_encryption)) {\n\n                    av_log(s, AV_LOG_WARNING, \"DRM protected stream detected, decoding will likely fail!\\n\");\n\n                } else if (!guidcmp(&g, &ff_asf_ext_content_encryption)) {\n\n                    av_log(s, AV_LOG_WARNING, \"Ext DRM protected stream detected, decoding will likely fail!\\n\");\n\n                } else if (!guidcmp(&g, &ff_asf_digital_signature)) {\n\n                    av_log(s, AV_LOG_WARNING, \"Digital signature detected, decoding will likely fail!\\n\");\n\n                }\n\n            }\n\n        }\n\n        if(url_ftell(pb) != gpos + gsize)\n\n            av_log(s, AV_LOG_DEBUG, \"gpos mismatch our pos=%\"PRIu64\", end=%\"PRIu64\"\\n\", url_ftell(pb)-gpos, gsize);\n\n        url_fseek(pb, gpos + gsize, SEEK_SET);\n\n    }\n\n    get_guid(pb, &g);\n\n    get_le64(pb);\n\n    get_byte(pb);\n\n    get_byte(pb);\n\n    if (url_feof(pb))\n\n        return -1;\n\n    asf->data_offset = url_ftell(pb);\n\n    asf->packet_size_left = 0;\n\n\n\n\n\n    for(i=0; i<128; i++){\n\n        int stream_num= asf->asfid2avid[i];\n\n        if(stream_num>=0){\n\n            AVStream *st = s->streams[stream_num];\n\n            if (!st->codec->bit_rate)\n\n                st->codec->bit_rate = bitrate[i];\n\n            if (dar[i].num > 0 && dar[i].den > 0)\n\n                av_reduce(&st->sample_aspect_ratio.num,\n\n                          &st->sample_aspect_ratio.den,\n\n                          dar[i].num, dar[i].den, INT_MAX);\n\n//av_log(s, AV_LOG_ERROR, \"dar %d:%d sar=%d:%d\\n\", dar[i].num, dar[i].den, st->sample_aspect_ratio.num, st->sample_aspect_ratio.den);\n\n\n\n            // copy and convert language codes to the frontend\n\n            if (asf->streams[i].stream_language_index < 128) {\n\n                const char *rfc1766 = asf->stream_languages[asf->streams[i].stream_language_index];\n\n                if (rfc1766 && strlen(rfc1766) > 1) {\n\n                    const char primary_tag[3] = { rfc1766[0], rfc1766[1], '\\0' }; // ignore country code if any\n\n                    const char *iso6392 = av_convert_lang_to(primary_tag, AV_LANG_ISO639_2_BIBL);\n\n                    if (iso6392)\n\n                        av_metadata_set2(&st->metadata, \"language\", iso6392, 0);\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25398}
{"project": "FFmpeg", "commit_id": "3ca14aa5964ea5d11f7a15f9fff17924d6096d44", "target": 1, "func": "static av_cold int rl2_read_header(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st;\n\n    unsigned int frame_count;\n\n    unsigned int audio_frame_counter = 0;\n\n    unsigned int video_frame_counter = 0;\n\n    unsigned int back_size;\n\n    unsigned short sound_rate;\n\n    unsigned short rate;\n\n    unsigned short channels;\n\n    unsigned short def_sound_size;\n\n    unsigned int signature;\n\n    unsigned int pts_den = 11025; /* video only case */\n\n    unsigned int pts_num = 1103;\n\n    unsigned int* chunk_offset = NULL;\n\n    int* chunk_size = NULL;\n\n    int* audio_size = NULL;\n\n    int i;\n\n    int ret = 0;\n\n\n\n    avio_skip(pb,4);          /* skip FORM tag */\n\n    back_size = avio_rl32(pb); /**< get size of the background frame */\n\n    signature = avio_rb32(pb);\n\n    avio_skip(pb, 4);         /* data size */\n\n    frame_count = avio_rl32(pb);\n\n\n\n    /* disallow back_sizes and frame_counts that may lead to overflows later */\n\n    if(back_size > INT_MAX/2  || frame_count > INT_MAX / sizeof(uint32_t))\n\n\n\n\n    avio_skip(pb, 2);         /* encoding mentod */\n\n    sound_rate = avio_rl16(pb);\n\n    rate = avio_rl16(pb);\n\n    channels = avio_rl16(pb);\n\n    def_sound_size = avio_rl16(pb);\n\n\n\n\n\n\n\n    /** setup video stream */\n\n    st = avformat_new_stream(s, NULL);\n\n    if(!st)\n\n         return AVERROR(ENOMEM);\n\n\n\n    st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id = AV_CODEC_ID_RL2;\n\n    st->codec->codec_tag = 0;  /* no fourcc */\n\n    st->codec->width = 320;\n\n    st->codec->height = 200;\n\n\n\n    /** allocate and fill extradata */\n\n    st->codec->extradata_size = EXTRADATA1_SIZE;\n\n\n\n    if(signature == RLV3_TAG && back_size > 0)\n\n        st->codec->extradata_size += back_size;\n\n\n\n    st->codec->extradata = av_mallocz(st->codec->extradata_size +\n\n                                          FF_INPUT_BUFFER_PADDING_SIZE);\n\n    if(!st->codec->extradata)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if(avio_read(pb,st->codec->extradata,st->codec->extradata_size) !=\n\n                      st->codec->extradata_size)\n\n        return AVERROR(EIO);\n\n\n\n    /** setup audio stream if present */\n\n    if(sound_rate){\n\n        pts_num = def_sound_size;\n\n        pts_den = rate;\n\n\n\n        st = avformat_new_stream(s, NULL);\n\n        if (!st)\n\n            return AVERROR(ENOMEM);\n\n        st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n        st->codec->codec_id = AV_CODEC_ID_PCM_U8;\n\n        st->codec->codec_tag = 1;\n\n        st->codec->channels = channels;\n\n        st->codec->bits_per_coded_sample = 8;\n\n        st->codec->sample_rate = rate;\n\n        st->codec->bit_rate = st->codec->channels * st->codec->sample_rate *\n\n            st->codec->bits_per_coded_sample;\n\n        st->codec->block_align = st->codec->channels *\n\n            st->codec->bits_per_coded_sample / 8;\n\n        avpriv_set_pts_info(st,32,1,rate);\n\n\n\n\n    avpriv_set_pts_info(s->streams[0], 32, pts_num, pts_den);\n\n\n\n    chunk_size =   av_malloc(frame_count * sizeof(uint32_t));\n\n    audio_size =   av_malloc(frame_count * sizeof(uint32_t));\n\n    chunk_offset = av_malloc(frame_count * sizeof(uint32_t));\n\n\n\n    if(!chunk_size || !audio_size || !chunk_offset){\n\n        av_free(chunk_size);\n\n        av_free(audio_size);\n\n        av_free(chunk_offset);\n\n        return AVERROR(ENOMEM);\n\n\n\n\n    /** read offset and size tables */\n\n    for(i=0; i < frame_count;i++)\n\n        chunk_size[i] = avio_rl32(pb);\n\n    for(i=0; i < frame_count;i++)\n\n        chunk_offset[i] = avio_rl32(pb);\n\n    for(i=0; i < frame_count;i++)\n\n        audio_size[i] = avio_rl32(pb) & 0xFFFF;\n\n\n\n    /** build the sample index */\n\n    for(i=0;i<frame_count;i++){\n\n        if(chunk_size[i] < 0 || audio_size[i] > chunk_size[i]){\n\n            ret = AVERROR_INVALIDDATA;\n\n            break;\n\n\n\n\n        if(sound_rate && audio_size[i]){\n\n            av_add_index_entry(s->streams[1], chunk_offset[i],\n\n                audio_frame_counter,audio_size[i], 0, AVINDEX_KEYFRAME);\n\n            audio_frame_counter += audio_size[i] / channels;\n\n\n        av_add_index_entry(s->streams[0], chunk_offset[i] + audio_size[i],\n\n            video_frame_counter,chunk_size[i]-audio_size[i],0,AVINDEX_KEYFRAME);\n\n        ++video_frame_counter;\n\n\n\n\n\n\n    av_free(chunk_size);\n\n    av_free(audio_size);\n\n    av_free(chunk_offset);\n\n\n\n    return ret;\n", "idx": 25400}
{"project": "FFmpeg", "commit_id": "14a90c9ef09a4b046500dceab5ca1875e330a376", "target": 1, "func": "static av_cold int ffmmal_init_decoder(AVCodecContext *avctx)\n{\n    MMALDecodeContext *ctx = avctx->priv_data;\n    MMAL_STATUS_T status;\n    MMAL_ES_FORMAT_T *format_in;\n    MMAL_COMPONENT_T *decoder;\n    char tmp[32];\n    int ret = 0;\n    bcm_host_init();\n    if (mmal_vc_init()) {\n        av_log(avctx, AV_LOG_ERROR, \"Cannot initialize MMAL VC driver!\\n\");\n        return AVERROR(ENOSYS);\n    if ((ret = ff_get_format(avctx, avctx->codec->pix_fmts)) < 0)\n        return ret;\n    avctx->pix_fmt = ret;\n    if ((status = mmal_component_create(MMAL_COMPONENT_DEFAULT_VIDEO_DECODER, &ctx->decoder)))\n        goto fail;\n    decoder = ctx->decoder;\n    format_in = decoder->input[0]->format;\n    format_in->type = MMAL_ES_TYPE_VIDEO;\n    switch (avctx->codec_id) {\n        case AV_CODEC_ID_MPEG2VIDEO:\n            format_in->encoding = MMAL_ENCODING_MP2V;\n            break;\n        case AV_CODEC_ID_MPEG4:\n            format_in->encoding = MMAL_ENCODING_MP4V;\n            break;\n        case AV_CODEC_ID_VC1:\n            format_in->encoding = MMAL_ENCODING_WVC1;\n            break;\n        case AV_CODEC_ID_H264:\n        default:\n            format_in->encoding = MMAL_ENCODING_H264;\n            break;\n    format_in->es->video.width = FFALIGN(avctx->width, 32);\n    format_in->es->video.height = FFALIGN(avctx->height, 16);\n    format_in->es->video.crop.width = avctx->width;\n    format_in->es->video.crop.height = avctx->height;\n    format_in->es->video.frame_rate.num = 24000;\n    format_in->es->video.frame_rate.den = 1001;\n    format_in->es->video.par.num = avctx->sample_aspect_ratio.num;\n    format_in->es->video.par.den = avctx->sample_aspect_ratio.den;\n    format_in->flags = MMAL_ES_FORMAT_FLAG_FRAMED;\n    av_get_codec_tag_string(tmp, sizeof(tmp), format_in->encoding);\n    av_log(avctx, AV_LOG_DEBUG, \"Using MMAL %s encoding.\\n\", tmp);\n    if ((status = mmal_port_format_commit(decoder->input[0])))\n        goto fail;\n    decoder->input[0]->buffer_num =\n        FFMAX(decoder->input[0]->buffer_num_min, 20);\n    decoder->input[0]->buffer_size =\n        FFMAX(decoder->input[0]->buffer_size_min, 512 * 1024);\n    ctx->pool_in = mmal_pool_create(decoder->input[0]->buffer_num, 0);\n    if (!ctx->pool_in) {\n        ret = AVERROR(ENOMEM);\n        goto fail;\n    if ((ret = ffmal_update_format(avctx)) < 0)\n        goto fail;\n    ctx->queue_decoded_frames = mmal_queue_create();\n    if (!ctx->queue_decoded_frames)\n        goto fail;\n    decoder->input[0]->userdata = (void*)avctx;\n    decoder->output[0]->userdata = (void*)avctx;\n    decoder->control->userdata = (void*)avctx;\n    if ((status = mmal_port_enable(decoder->control, control_port_cb)))\n        goto fail;\n    if ((status = mmal_port_enable(decoder->input[0], input_callback)))\n        goto fail;\n    if ((status = mmal_port_enable(decoder->output[0], output_callback)))\n        goto fail;\n    if ((status = mmal_component_enable(decoder)))\n        goto fail;\n    return 0;\nfail:\n    ffmmal_close_decoder(avctx);\n    return ret < 0 ? ret : AVERROR_UNKNOWN;", "idx": 25401}
{"project": "FFmpeg", "commit_id": "1002932a3b16d35c46a08455f76462909eebb5aa", "target": 1, "func": "static int cdxl_decode_frame(AVCodecContext *avctx, void *data,\n\n                             int *got_frame, AVPacket *pkt)\n\n{\n\n    CDXLVideoContext *c = avctx->priv_data;\n\n    AVFrame * const p = data;\n\n    int ret, w, h, encoding, aligned_width, buf_size = pkt->size;\n\n    const uint8_t *buf = pkt->data;\n\n\n\n    if (buf_size < 32)\n\n        return AVERROR_INVALIDDATA;\n\n    encoding        = buf[1] & 7;\n\n    c->format       = buf[1] & 0xE0;\n\n    w               = AV_RB16(&buf[14]);\n\n    h               = AV_RB16(&buf[16]);\n\n    c->bpp          = buf[19];\n\n    c->palette_size = AV_RB16(&buf[20]);\n\n    c->palette      = buf + 32;\n\n    c->video        = c->palette + c->palette_size;\n\n    c->video_size   = buf_size - c->palette_size - 32;\n\n\n\n    if (c->palette_size > 512)\n\n        return AVERROR_INVALIDDATA;\n\n    if (buf_size < c->palette_size + 32)\n\n        return AVERROR_INVALIDDATA;\n\n    if (c->bpp < 1)\n\n        return AVERROR_INVALIDDATA;\n\n    if (c->format != BIT_PLANAR && c->format != BIT_LINE && c->format != CHUNKY) {\n\n        avpriv_request_sample(avctx, \"Pixel format 0x%0x\", c->format);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if ((ret = ff_set_dimensions(avctx, w, h)) < 0)\n\n        return ret;\n\n\n\n    if (c->format == CHUNKY)\n\n        aligned_width = avctx->width;\n\n    else\n\n        aligned_width = FFALIGN(c->avctx->width, 16);\n\n    c->padded_bits  = aligned_width - c->avctx->width;\n\n    if (c->video_size < aligned_width * avctx->height * c->bpp / 8)\n\n        return AVERROR_INVALIDDATA;\n\n    if (!encoding && c->palette_size && c->bpp <= 8) {\n\n        avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n    } else if (encoding == 1 && (c->bpp == 6 || c->bpp == 8)) {\n\n        if (c->palette_size != (1 << (c->bpp - 1)))\n\n            return AVERROR_INVALIDDATA;\n\n        avctx->pix_fmt = AV_PIX_FMT_BGR24;\n\n    } else if (!encoding && c->bpp == 24 && c->format == CHUNKY &&\n\n               !c->palette_size) {\n\n        avctx->pix_fmt = AV_PIX_FMT_RGB24;\n\n    } else {\n\n        avpriv_request_sample(avctx, \"Encoding %d, bpp %d and format 0x%x\",\n\n                              encoding, c->bpp, c->format);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if ((ret = ff_get_buffer(avctx, p, 0)) < 0)\n\n        return ret;\n\n    p->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    if (encoding) {\n\n        av_fast_padded_malloc(&c->new_video, &c->new_video_size,\n\n                              h * w + AV_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!c->new_video)\n\n            return AVERROR(ENOMEM);\n\n        if (c->bpp == 8)\n\n            cdxl_decode_ham8(c, p);\n\n        else\n\n            cdxl_decode_ham6(c, p);\n\n    } else if (avctx->pix_fmt == AV_PIX_FMT_PAL8) {\n\n        cdxl_decode_rgb(c, p);\n\n    } else {\n\n        cdxl_decode_raw(c, p);\n\n    }\n\n    *got_frame = 1;\n\n\n\n    return buf_size;\n\n}\n", "idx": 25402}
{"project": "FFmpeg", "commit_id": "9e1c55cfdec1e1e46fa39b92ea5c425ba9499c68", "target": 1, "func": "static int ogg_get_length(AVFormatContext *s)\n\n{\n\n    struct ogg *ogg = s->priv_data;\n\n    int i;\n\n    int64_t size, end;\n\n    int streams_left=0;\n\n\n\n    if(!s->pb->seekable)\n\n        return 0;\n\n\n\n// already set\n\n    if (s->duration != AV_NOPTS_VALUE)\n\n        return 0;\n\n\n\n    size = avio_size(s->pb);\n\n    if(size < 0)\n\n        return 0;\n\n    end = size > MAX_PAGE_SIZE? size - MAX_PAGE_SIZE: 0;\n\n\n\n    ogg_save (s);\n\n    avio_seek (s->pb, end, SEEK_SET);\n\n\n\n    while (!ogg_read_page (s, &i)){\n\n        if (ogg->streams[i].granule != -1 && ogg->streams[i].granule != 0 &&\n\n            ogg->streams[i].codec) {\n\n            s->streams[i]->duration =\n\n                ogg_gptopts (s, i, ogg->streams[i].granule, NULL);\n\n            if (s->streams[i]->start_time != AV_NOPTS_VALUE){\n\n                s->streams[i]->duration -= s->streams[i]->start_time;\n\n                streams_left-= (ogg->streams[i].got_start==-1);\n\n                ogg->streams[i].got_start= 1;\n\n            }else if(!ogg->streams[i].got_start){\n\n                ogg->streams[i].got_start= -1;\n\n                streams_left++;\n\n            }\n\n        }\n\n    }\n\n\n\n    ogg_restore (s, 0);\n\n\n\n    ogg_save (s);\n\n    avio_seek (s->pb, s->data_offset, SEEK_SET);\n\n    ogg_reset(s);\n\n\n    while (!ogg_packet(s, &i, NULL, NULL, NULL)) {\n\n\n        int64_t pts = ogg_calc_pts(s, i, NULL);\n\n        if (pts != AV_NOPTS_VALUE && s->streams[i]->start_time == AV_NOPTS_VALUE && !ogg->streams[i].got_start){\n\n            s->streams[i]->duration -= pts;\n\n            ogg->streams[i].got_start= 1;\n\n            streams_left--;\n\n        }else if(s->streams[i]->start_time != AV_NOPTS_VALUE && !ogg->streams[i].got_start){\n\n            ogg->streams[i].got_start= 1;\n\n            streams_left--;\n\n        }\n\n        }\n\n            if(streams_left<=0)\n\n                break;\n\n    }\n\n    ogg_restore (s, 0);\n\n\n\n    return 0;\n\n}", "idx": 25404}
{"project": "FFmpeg", "commit_id": "8962da9ec367b535f975c876643ed2cad2bad32e", "target": 1, "func": "static int raw_decode(AVCodecContext *avctx, void *data, int *got_frame,\n\n                      AVPacket *avpkt)\n\n{\n\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(avctx->pix_fmt);\n\n    RawVideoContext *context       = avctx->priv_data;\n\n    const uint8_t *buf             = avpkt->data;\n\n    int buf_size                   = avpkt->size;\n\n    int linesize_align             = 4;\n\n    int res, len;\n\n    int need_copy                  = !avpkt->buf || context->is_2_4_bpp || context->is_yuv2;\n\n\n\n    AVFrame   *frame   = data;\n\n    AVPicture *picture = data;\n\n\n\n    frame->pict_type        = AV_PICTURE_TYPE_I;\n\n    frame->key_frame        = 1;\n\n    frame->reordered_opaque = avctx->reordered_opaque;\n\n    frame->pkt_pts          = avctx->pkt->pts;\n\n    av_frame_set_pkt_pos     (frame, avctx->pkt->pos);\n\n    av_frame_set_pkt_duration(frame, avctx->pkt->duration);\n\n\n\n    if (context->tff >= 0) {\n\n        frame->interlaced_frame = 1;\n\n        frame->top_field_first  = context->tff;\n\n    }\n\n\n\n    if ((res = av_image_check_size(avctx->width, avctx->height, 0, avctx)) < 0)\n\n        return res;\n\n\n\n    if (need_copy)\n\n        frame->buf[0] = av_buffer_alloc(context->frame_size);\n\n    else\n\n        frame->buf[0] = av_buffer_ref(avpkt->buf);\n\n    if (!frame->buf[0])\n\n        return AVERROR(ENOMEM);\n\n\n\n    //2bpp and 4bpp raw in avi and mov (yes this is ugly ...)\n\n    if (context->is_2_4_bpp) {\n\n        int i;\n\n        uint8_t *dst = frame->buf[0]->data;\n\n        buf_size = context->frame_size - AVPALETTE_SIZE;\n\n        if (avctx->bits_per_coded_sample == 4) {\n\n            for (i = 0; 2 * i + 1 < buf_size && i<avpkt->size; i++) {\n\n                dst[2 * i + 0] = buf[i] >> 4;\n\n                dst[2 * i + 1] = buf[i] & 15;\n\n            }\n\n            linesize_align = 8;\n\n        } else {\n\n            av_assert0(avctx->bits_per_coded_sample == 2);\n\n            for (i = 0; 4 * i + 3 < buf_size && i<avpkt->size; i++) {\n\n                dst[4 * i + 0] = buf[i] >> 6;\n\n                dst[4 * i + 1] = buf[i] >> 4 & 3;\n\n                dst[4 * i + 2] = buf[i] >> 2 & 3;\n\n                dst[4 * i + 3] = buf[i]      & 3;\n\n            }\n\n            linesize_align = 16;\n\n        }\n\n        buf = dst;\n\n    } else if (need_copy) {\n\n        memcpy(frame->buf[0]->data, buf, FFMIN(buf_size, context->frame_size));\n\n        buf = frame->buf[0]->data;\n\n    }\n\n\n\n    if (avctx->codec_tag == MKTAG('A', 'V', '1', 'x') ||\n\n        avctx->codec_tag == MKTAG('A', 'V', 'u', 'p'))\n\n        buf += buf_size - context->frame_size;\n\n\n\n    len = context->frame_size - (avctx->pix_fmt==AV_PIX_FMT_PAL8 ? AVPALETTE_SIZE : 0);\n\n    if (buf_size < len) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid buffer size, packet size %d < expected frame_size %d\\n\", buf_size, len);\n\n        av_buffer_unref(&frame->buf[0]);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if ((res = avpicture_fill(picture, buf, avctx->pix_fmt,\n\n                              avctx->width, avctx->height)) < 0) {\n\n        av_buffer_unref(&frame->buf[0]);\n\n        return res;\n\n    }\n\n\n\n    if (avctx->pix_fmt == AV_PIX_FMT_PAL8) {\n\n        const uint8_t *pal = av_packet_get_side_data(avpkt, AV_PKT_DATA_PALETTE,\n\n                                                     NULL);\n\n\n\n        if (pal) {\n\n            av_buffer_unref(&context->palette);\n\n            context->palette = av_buffer_alloc(AVPALETTE_SIZE);\n\n            if (!context->palette) {\n\n                av_buffer_unref(&frame->buf[0]);\n\n                return AVERROR(ENOMEM);\n\n            }\n\n            memcpy(context->palette->data, pal, AVPALETTE_SIZE);\n\n            frame->palette_has_changed = 1;\n\n        }\n\n    }\n\n\n\n    if ((avctx->pix_fmt==AV_PIX_FMT_BGR24    ||\n\n        avctx->pix_fmt==AV_PIX_FMT_GRAY8    ||\n\n        avctx->pix_fmt==AV_PIX_FMT_RGB555LE ||\n\n        avctx->pix_fmt==AV_PIX_FMT_RGB555BE ||\n\n        avctx->pix_fmt==AV_PIX_FMT_RGB565LE ||\n\n        avctx->pix_fmt==AV_PIX_FMT_MONOWHITE ||\n\n        avctx->pix_fmt==AV_PIX_FMT_PAL8) &&\n\n        FFALIGN(frame->linesize[0], linesize_align) * avctx->height <= buf_size)\n\n        frame->linesize[0] = FFALIGN(frame->linesize[0], linesize_align);\n\n\n\n    if (avctx->pix_fmt == AV_PIX_FMT_NV12 && avctx->codec_tag == MKTAG('N', 'V', '1', '2') &&\n\n        FFALIGN(frame->linesize[0], linesize_align) * avctx->height +\n\n        FFALIGN(frame->linesize[1], linesize_align) * ((avctx->height + 1) / 2) <= buf_size) {\n\n        int la0 = FFALIGN(frame->linesize[0], linesize_align);\n\n        frame->data[1] += (la0 - frame->linesize[0]) * avctx->height;\n\n        frame->linesize[0] = la0;\n\n        frame->linesize[1] = FFALIGN(frame->linesize[1], linesize_align);\n\n    }\n\n\n\n    if ((avctx->pix_fmt == AV_PIX_FMT_PAL8 && buf_size < context->frame_size) ||\n\n        (desc->flags & AV_PIX_FMT_FLAG_PSEUDOPAL)) {\n\n        frame->buf[1]  = av_buffer_ref(context->palette);\n\n        if (!frame->buf[1]) {\n\n            av_buffer_unref(&frame->buf[0]);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        frame->data[1] = frame->buf[1]->data;\n\n    }\n\n\n\n    if (avctx->pix_fmt == AV_PIX_FMT_BGR24 &&\n\n        ((frame->linesize[0] + 3) & ~3) * avctx->height <= buf_size)\n\n        frame->linesize[0] = (frame->linesize[0] + 3) & ~3;\n\n\n\n    if (context->flip)\n\n        flip(avctx, picture);\n\n\n\n    if (avctx->codec_tag == MKTAG('Y', 'V', '1', '2') ||\n\n        avctx->codec_tag == MKTAG('Y', 'V', '1', '6') ||\n\n        avctx->codec_tag == MKTAG('Y', 'V', '2', '4') ||\n\n        avctx->codec_tag == MKTAG('Y', 'V', 'U', '9'))\n\n        FFSWAP(uint8_t *, picture->data[1], picture->data[2]);\n\n\n\n    if (avctx->codec_tag == AV_RL32(\"I420\") && (avctx->width+1)*(avctx->height+1) * 3/2 == buf_size) {\n\n        picture->data[1] = picture->data[1] +  (avctx->width+1)*(avctx->height+1) -avctx->width*avctx->height;\n\n        picture->data[2] = picture->data[2] + ((avctx->width+1)*(avctx->height+1) -avctx->width*avctx->height)*5/4;\n\n    }\n\n\n\n    if (avctx->codec_tag == AV_RL32(\"yuv2\") &&\n\n        avctx->pix_fmt   == AV_PIX_FMT_YUYV422) {\n\n        int x, y;\n\n        uint8_t *line = picture->data[0];\n\n        for (y = 0; y < avctx->height; y++) {\n\n            for (x = 0; x < avctx->width; x++)\n\n                line[2 * x + 1] ^= 0x80;\n\n            line += picture->linesize[0];\n\n        }\n\n    }\n\n    if (avctx->codec_tag == AV_RL32(\"YVYU\") &&\n\n        avctx->pix_fmt   == AV_PIX_FMT_YUYV422) {\n\n        int x, y;\n\n        uint8_t *line = picture->data[0];\n\n        for(y = 0; y < avctx->height; y++) {\n\n            for(x = 0; x < avctx->width - 1; x += 2)\n\n                FFSWAP(uint8_t, line[2*x + 1], line[2*x + 3]);\n\n            line += picture->linesize[0];\n\n        }\n\n    }\n\n\n\n    if (avctx->field_order > AV_FIELD_PROGRESSIVE) { /* we have interlaced material flagged in container */\n\n        frame->interlaced_frame = 1;\n\n        if (avctx->field_order == AV_FIELD_TT || avctx->field_order == AV_FIELD_TB)\n\n            frame->top_field_first = 1;\n\n    }\n\n\n\n    *got_frame = 1;\n\n    return buf_size;\n\n}\n", "idx": 25405}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "int ff_vaapi_mpeg_end_frame(AVCodecContext *avctx)\n\n{\n\n    struct vaapi_context * const vactx = avctx->hwaccel_context;\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int ret;\n\n\n\n    ret = ff_vaapi_commit_slices(vactx);\n\n    if (ret < 0)\n\n        goto finish;\n\n\n\n    ret = ff_vaapi_render_picture(vactx,\n\n                                  ff_vaapi_get_surface_id(&s->current_picture_ptr->f));\n\n    if (ret < 0)\n\n        goto finish;\n\n\n\n    ff_mpeg_draw_horiz_band(s, 0, s->avctx->height);\n\n\n\nfinish:\n\n    ff_vaapi_common_end_frame(avctx);\n\n    return ret;\n\n}\n", "idx": 25406}
{"project": "FFmpeg", "commit_id": "934572c5c3592732a30336afdf2df9926a8b4df2", "target": 1, "func": "static int rscc_decode_frame(AVCodecContext *avctx, void *data,\n                                     int *got_frame, AVPacket *avpkt)\n{\n    RsccContext *ctx = avctx->priv_data;\n    GetByteContext *gbc = &ctx->gbc;\n    GetByteContext tiles_gbc;\n    AVFrame *frame = data;\n    const uint8_t *pixels, *raw;\n    uint8_t *inflated_tiles = NULL;\n    int tiles_nb, packed_size, pixel_size = 0;\n    int i, ret = 0;\n    bytestream2_init(gbc, avpkt->data, avpkt->size);\n    /* Size check */\n    if (bytestream2_get_bytes_left(gbc) < 12) {\n        av_log(avctx, AV_LOG_ERROR, \"Packet too small (%d)\\n\", avpkt->size);\n        return AVERROR_INVALIDDATA;\n    /* Read number of tiles, and allocate the array */\n    tiles_nb = bytestream2_get_le16(gbc);\n    av_fast_malloc(&ctx->tiles, &ctx->tiles_size,\n                   tiles_nb * sizeof(*ctx->tiles));\n    if (!ctx->tiles) {\n        ret = AVERROR(ENOMEM);\n    av_log(avctx, AV_LOG_DEBUG, \"Frame with %d tiles.\\n\", tiles_nb);\n    /* When there are more than 5 tiles, they are packed together with\n     * a size header. When that size does not match the number of tiles\n     * times the tile size, it means it needs to be inflated as well */\n    if (tiles_nb > 5) {\n        uLongf packed_tiles_size;\n        if (tiles_nb < 32)\n            packed_tiles_size = bytestream2_get_byte(gbc);\n        else\n            packed_tiles_size = bytestream2_get_le16(gbc);\n        ff_dlog(avctx, \"packed tiles of size %lu.\\n\", packed_tiles_size);\n        /* If necessary, uncompress tiles, and hijack the bytestream reader */\n        if (packed_tiles_size != tiles_nb * TILE_SIZE) {\n            uLongf length = tiles_nb * TILE_SIZE;\n            inflated_tiles = av_malloc(length);\n            if (!inflated_tiles) {\n                ret = AVERROR(ENOMEM);\n            ret = uncompress(inflated_tiles, &length,\n                             gbc->buffer, packed_tiles_size);\n            if (ret) {\n                av_log(avctx, AV_LOG_ERROR, \"Tile deflate error %d.\\n\", ret);\n                ret = AVERROR_UNKNOWN;\n            /* Skip the compressed tile section in the main byte reader,\n             * and point it to read the newly uncompressed data */\n            bytestream2_skip(gbc, packed_tiles_size);\n            bytestream2_init(&tiles_gbc, inflated_tiles, length);\n            gbc = &tiles_gbc;\n    /* Fill in array of tiles, keeping track of how many pixels are updated */\n    for (i = 0; i < tiles_nb; i++) {\n        ctx->tiles[i].x = bytestream2_get_le16(gbc);\n        ctx->tiles[i].w = bytestream2_get_le16(gbc);\n        ctx->tiles[i].y = bytestream2_get_le16(gbc);\n        ctx->tiles[i].h = bytestream2_get_le16(gbc);\n        pixel_size += ctx->tiles[i].w * ctx->tiles[i].h * ctx->component_size;\n        ff_dlog(avctx, \"tile %d orig(%d,%d) %dx%d.\\n\", i,\n                ctx->tiles[i].x, ctx->tiles[i].y,\n                ctx->tiles[i].w, ctx->tiles[i].h);\n        if (ctx->tiles[i].w == 0 || ctx->tiles[i].h == 0) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"invalid tile %d at (%d.%d) with size %dx%d.\\n\", i,\n                   ctx->tiles[i].x, ctx->tiles[i].y,\n                   ctx->tiles[i].w, ctx->tiles[i].h);\n        } else if (ctx->tiles[i].x + ctx->tiles[i].w > avctx->width ||\n                   ctx->tiles[i].y + ctx->tiles[i].h > avctx->height) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"out of bounds tile %d at (%d.%d) with size %dx%d.\\n\", i,\n                   ctx->tiles[i].x, ctx->tiles[i].y,\n                   ctx->tiles[i].w, ctx->tiles[i].h);\n    /* Reset the reader in case it had been modified before */\n    gbc = &ctx->gbc;\n    /* Extract how much pixel data the tiles contain */\n    if (pixel_size < 0x100)\n        packed_size = bytestream2_get_byte(gbc);\n    else if (pixel_size < 0x10000)\n        packed_size = bytestream2_get_le16(gbc);\n    else if (pixel_size < 0x1000000)\n        packed_size = bytestream2_get_le24(gbc);\n    else\n        packed_size = bytestream2_get_le32(gbc);\n    ff_dlog(avctx, \"pixel_size %d packed_size %d.\\n\", pixel_size, packed_size);\n    if (packed_size < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid tile size %d\\n\", packed_size);\n    /* Get pixels buffer, it may be deflated or just raw */\n    if (pixel_size == packed_size) {\n        if (bytestream2_get_bytes_left(gbc) < pixel_size) {\n            av_log(avctx, AV_LOG_ERROR, \"Insufficient input for %d\\n\", pixel_size);\n        pixels = gbc->buffer;\n    } else {\n        uLongf len = ctx->inflated_size;\n        if (bytestream2_get_bytes_left(gbc) < packed_size) {\n            av_log(avctx, AV_LOG_ERROR, \"Insufficient input for %d\\n\", packed_size);\n        ret = uncompress(ctx->inflated_buf, &len, gbc->buffer, packed_size);\n        if (ret) {\n            av_log(avctx, AV_LOG_ERROR, \"Pixel deflate error %d.\\n\", ret);\n            ret = AVERROR_UNKNOWN;\n        pixels = ctx->inflated_buf;\n    /* Allocate when needed */\n    ret = ff_reget_buffer(avctx, ctx->reference);\n    if (ret < 0)\n    /* Pointer to actual pixels, will be updated when data is consumed */\n    raw = pixels;\n    for (i = 0; i < tiles_nb; i++) {\n        uint8_t *dst = ctx->reference->data[0] + ctx->reference->linesize[0] *\n                       (avctx->height - ctx->tiles[i].y - 1) +\n                       ctx->tiles[i].x * ctx->component_size;\n        av_image_copy_plane(dst, -1 * ctx->reference->linesize[0],\n                            raw, ctx->tiles[i].w * ctx->component_size,\n                            ctx->tiles[i].w * ctx->component_size,\n                            ctx->tiles[i].h);\n        raw += ctx->tiles[i].w * ctx->component_size * ctx->tiles[i].h;\n    /* Frame is ready to be output */\n    ret = av_frame_ref(frame, ctx->reference);\n    if (ret < 0)\n    /* Keyframe when the number of pixels updated matches the whole surface */\n    if (pixel_size == ctx->inflated_size) {\n        frame->pict_type = AV_PICTURE_TYPE_I;\n        frame->key_frame = 1;\n    } else {\n        frame->pict_type = AV_PICTURE_TYPE_P;\n    /* Palette handling */\n    if (avctx->pix_fmt == AV_PIX_FMT_PAL8) {\n        int size;\n        const uint8_t *palette = av_packet_get_side_data(avpkt,\n                                                         AV_PKT_DATA_PALETTE,\n                                                         &size);\n        if (palette && size == AVPALETTE_SIZE) {\n            frame->palette_has_changed = 1;\n            memcpy(ctx->palette, palette, AVPALETTE_SIZE);\n        } else if (palette) {\n            av_log(avctx, AV_LOG_ERROR, \"Palette size %d is wrong\\n\", size);\n        memcpy (frame->data[1], ctx->palette, AVPALETTE_SIZE);\n    *got_frame = 1;\n    ret = avpkt->size;\nend:\n    av_free(inflated_tiles);\n    return ret;", "idx": 25408}
{"project": "FFmpeg", "commit_id": "e3496e5dbe277e056800ebe7740ac6467d35d5cb", "target": 1, "func": "static void swap_channel_layouts_on_filter(AVFilterContext *filter)\n\n{\n\n    AVFilterLink *link = NULL;\n\n    int i, j, k;\n\n\n\n    for (i = 0; i < filter->nb_inputs; i++) {\n\n        link = filter->inputs[i];\n\n\n\n        if (link->type == AVMEDIA_TYPE_AUDIO &&\n\n            link->out_channel_layouts->nb_channel_layouts == 1)\n\n            break;\n\n    }\n\n    if (i == filter->nb_inputs)\n\n        return;\n\n\n\n    for (i = 0; i < filter->nb_outputs; i++) {\n\n        AVFilterLink *outlink = filter->outputs[i];\n\n        int best_idx, best_score = INT_MIN, best_count_diff = INT_MAX;\n\n\n\n        if (outlink->type != AVMEDIA_TYPE_AUDIO ||\n\n            outlink->in_channel_layouts->nb_channel_layouts < 2)\n\n            continue;\n\n\n\n        for (j = 0; j < outlink->in_channel_layouts->nb_channel_layouts; j++) {\n\n            uint64_t  in_chlayout = link->out_channel_layouts->channel_layouts[0];\n\n            uint64_t out_chlayout = outlink->in_channel_layouts->channel_layouts[j];\n\n            int  in_channels      = av_get_channel_layout_nb_channels(in_chlayout);\n\n            int out_channels      = av_get_channel_layout_nb_channels(out_chlayout);\n\n            int count_diff        = out_channels - in_channels;\n\n            int matched_channels, extra_channels;\n\n            int score = 0;\n\n\n\n            /* channel substitution */\n\n            for (k = 0; k < FF_ARRAY_ELEMS(ch_subst); k++) {\n\n                uint64_t cmp0 = ch_subst[k][0];\n\n                uint64_t cmp1 = ch_subst[k][1];\n\n                if (( in_chlayout & cmp0) && (!(out_chlayout & cmp0)) &&\n\n                    (out_chlayout & cmp1) && (!( in_chlayout & cmp1))) {\n\n                    in_chlayout  &= ~cmp0;\n\n                    out_chlayout &= ~cmp1;\n\n                    /* add score for channel match, minus a deduction for\n\n                       having to do the substitution */\n\n                    score += 10 * av_get_channel_layout_nb_channels(cmp1) - 2;\n\n                }\n\n            }\n\n\n\n            /* no penalty for LFE channel mismatch */\n\n            if ( (in_chlayout & AV_CH_LOW_FREQUENCY) &&\n\n                (out_chlayout & AV_CH_LOW_FREQUENCY))\n\n                score += 10;\n\n            in_chlayout  &= ~AV_CH_LOW_FREQUENCY;\n\n            out_chlayout &= ~AV_CH_LOW_FREQUENCY;\n\n\n\n            matched_channels = av_get_channel_layout_nb_channels(in_chlayout &\n\n                                                                 out_chlayout);\n\n            extra_channels   = av_get_channel_layout_nb_channels(out_chlayout &\n\n                                                                 (~in_chlayout));\n\n            score += 10 * matched_channels - 5 * extra_channels;\n\n\n\n            if (score > best_score ||\n\n                (count_diff < best_count_diff && score == best_score)) {\n\n                best_score = score;\n\n                best_idx   = j;\n\n                best_count_diff = count_diff;\n\n            }\n\n        }\n\n        FFSWAP(uint64_t, outlink->in_channel_layouts->channel_layouts[0],\n\n               outlink->in_channel_layouts->channel_layouts[best_idx]);\n\n    }\n\n\n\n}\n", "idx": 25409}
{"project": "FFmpeg", "commit_id": "5e53486545726987ab4482321d4dcf7e23e7652f", "target": 0, "func": "int img_convert(AVPicture *dst, int dst_pix_fmt,\n\n                const AVPicture *src, int src_pix_fmt,\n\n                int src_width, int src_height)\n\n{\n\n    static int inited;\n\n    int i, ret, dst_width, dst_height, int_pix_fmt;\n\n    const PixFmtInfo *src_pix, *dst_pix;\n\n    const ConvertEntry *ce;\n\n    AVPicture tmp1, *tmp = &tmp1;\n\n\n\n    if (src_pix_fmt < 0 || src_pix_fmt >= PIX_FMT_NB ||\n\n        dst_pix_fmt < 0 || dst_pix_fmt >= PIX_FMT_NB)\n\n        return -1;\n\n    if (src_width <= 0 || src_height <= 0)\n\n        return 0;\n\n\n\n    if (!inited) {\n\n        inited = 1;\n\n        img_convert_init();\n\n    }\n\n\n\n    dst_width = src_width;\n\n    dst_height = src_height;\n\n\n\n    dst_pix = &pix_fmt_info[dst_pix_fmt];\n\n    src_pix = &pix_fmt_info[src_pix_fmt];\n\n    if (src_pix_fmt == dst_pix_fmt) {\n\n        /* no conversion needed: just copy */\n\n        av_picture_copy(dst, src, dst_pix_fmt, dst_width, dst_height);\n\n        return 0;\n\n    }\n\n\n\n    ce = &convert_table[src_pix_fmt][dst_pix_fmt];\n\n    if (ce->convert) {\n\n        /* specific conversion routine */\n\n        ce->convert(dst, src, dst_width, dst_height);\n\n        return 0;\n\n    }\n\n\n\n    /* gray to YUV */\n\n    if (is_yuv_planar(dst_pix) &&\n\n        src_pix_fmt == PIX_FMT_GRAY8) {\n\n        int w, h, y;\n\n        uint8_t *d;\n\n\n\n        if (dst_pix->color_type == FF_COLOR_YUV_JPEG) {\n\n            ff_img_copy_plane(dst->data[0], dst->linesize[0],\n\n                     src->data[0], src->linesize[0],\n\n                     dst_width, dst_height);\n\n        } else {\n\n            img_apply_table(dst->data[0], dst->linesize[0],\n\n                            src->data[0], src->linesize[0],\n\n                            dst_width, dst_height,\n\n                            y_jpeg_to_ccir);\n\n        }\n\n        /* fill U and V with 128 */\n\n        w = dst_width;\n\n        h = dst_height;\n\n        w >>= dst_pix->x_chroma_shift;\n\n        h >>= dst_pix->y_chroma_shift;\n\n        for(i = 1; i <= 2; i++) {\n\n            d = dst->data[i];\n\n            for(y = 0; y< h; y++) {\n\n                memset(d, 128, w);\n\n                d += dst->linesize[i];\n\n            }\n\n        }\n\n        return 0;\n\n    }\n\n\n\n    /* YUV to gray */\n\n    if (is_yuv_planar(src_pix) &&\n\n        dst_pix_fmt == PIX_FMT_GRAY8) {\n\n        if (src_pix->color_type == FF_COLOR_YUV_JPEG) {\n\n            ff_img_copy_plane(dst->data[0], dst->linesize[0],\n\n                     src->data[0], src->linesize[0],\n\n                     dst_width, dst_height);\n\n        } else {\n\n            img_apply_table(dst->data[0], dst->linesize[0],\n\n                            src->data[0], src->linesize[0],\n\n                            dst_width, dst_height,\n\n                            y_ccir_to_jpeg);\n\n        }\n\n        return 0;\n\n    }\n\n\n\n    /* YUV to YUV planar */\n\n    if (is_yuv_planar(dst_pix) && is_yuv_planar(src_pix)) {\n\n        int x_shift, y_shift, w, h, xy_shift;\n\n        void (*resize_func)(uint8_t *dst, int dst_wrap,\n\n                            const uint8_t *src, int src_wrap,\n\n                            int width, int height);\n\n\n\n        /* compute chroma size of the smallest dimensions */\n\n        w = dst_width;\n\n        h = dst_height;\n\n        if (dst_pix->x_chroma_shift >= src_pix->x_chroma_shift)\n\n            w >>= dst_pix->x_chroma_shift;\n\n        else\n\n            w >>= src_pix->x_chroma_shift;\n\n        if (dst_pix->y_chroma_shift >= src_pix->y_chroma_shift)\n\n            h >>= dst_pix->y_chroma_shift;\n\n        else\n\n            h >>= src_pix->y_chroma_shift;\n\n\n\n        x_shift = (dst_pix->x_chroma_shift - src_pix->x_chroma_shift);\n\n        y_shift = (dst_pix->y_chroma_shift - src_pix->y_chroma_shift);\n\n        xy_shift = ((x_shift & 0xf) << 4) | (y_shift & 0xf);\n\n        /* there must be filters for conversion at least from and to\n\n           YUV444 format */\n\n        switch(xy_shift) {\n\n        case 0x00:\n\n            resize_func = ff_img_copy_plane;\n\n            break;\n\n        case 0x10:\n\n            resize_func = shrink21;\n\n            break;\n\n        case 0x20:\n\n            resize_func = shrink41;\n\n            break;\n\n        case 0x01:\n\n            resize_func = shrink12;\n\n            break;\n\n        case 0x11:\n\n            resize_func = ff_shrink22;\n\n            break;\n\n        case 0x22:\n\n            resize_func = ff_shrink44;\n\n            break;\n\n        case 0xf0:\n\n            resize_func = grow21;\n\n            break;\n\n        case 0x0f:\n\n            resize_func = grow12;\n\n            break;\n\n        case 0xe0:\n\n            resize_func = grow41;\n\n            break;\n\n        case 0xff:\n\n            resize_func = grow22;\n\n            break;\n\n        case 0xee:\n\n            resize_func = grow44;\n\n            break;\n\n        case 0xf1:\n\n            resize_func = conv411;\n\n            break;\n\n        default:\n\n            /* currently not handled */\n\n            goto no_chroma_filter;\n\n        }\n\n\n\n        ff_img_copy_plane(dst->data[0], dst->linesize[0],\n\n                       src->data[0], src->linesize[0],\n\n                       dst_width, dst_height);\n\n\n\n        for(i = 1;i <= 2; i++)\n\n            resize_func(dst->data[i], dst->linesize[i],\n\n                        src->data[i], src->linesize[i],\n\n                        dst_width>>dst_pix->x_chroma_shift, dst_height>>dst_pix->y_chroma_shift);\n\n        /* if yuv color space conversion is needed, we do it here on\n\n           the destination image */\n\n        if (dst_pix->color_type != src_pix->color_type) {\n\n            const uint8_t *y_table, *c_table;\n\n            if (dst_pix->color_type == FF_COLOR_YUV) {\n\n                y_table = y_jpeg_to_ccir;\n\n                c_table = c_jpeg_to_ccir;\n\n            } else {\n\n                y_table = y_ccir_to_jpeg;\n\n                c_table = c_ccir_to_jpeg;\n\n            }\n\n            img_apply_table(dst->data[0], dst->linesize[0],\n\n                            dst->data[0], dst->linesize[0],\n\n                            dst_width, dst_height,\n\n                            y_table);\n\n\n\n            for(i = 1;i <= 2; i++)\n\n                img_apply_table(dst->data[i], dst->linesize[i],\n\n                                dst->data[i], dst->linesize[i],\n\n                                dst_width>>dst_pix->x_chroma_shift,\n\n                                dst_height>>dst_pix->y_chroma_shift,\n\n                                c_table);\n\n        }\n\n        return 0;\n\n    }\n\n no_chroma_filter:\n\n\n\n    /* try to use an intermediate format */\n\n    if (src_pix_fmt == PIX_FMT_YUYV422 ||\n\n        dst_pix_fmt == PIX_FMT_YUYV422) {\n\n        /* specific case: convert to YUV422P first */\n\n        int_pix_fmt = PIX_FMT_YUV422P;\n\n    } else if (src_pix_fmt == PIX_FMT_UYVY422 ||\n\n        dst_pix_fmt == PIX_FMT_UYVY422) {\n\n        /* specific case: convert to YUV422P first */\n\n        int_pix_fmt = PIX_FMT_YUV422P;\n\n    } else if (src_pix_fmt == PIX_FMT_UYYVYY411 ||\n\n        dst_pix_fmt == PIX_FMT_UYYVYY411) {\n\n        /* specific case: convert to YUV411P first */\n\n        int_pix_fmt = PIX_FMT_YUV411P;\n\n    } else if ((src_pix->color_type == FF_COLOR_GRAY &&\n\n                src_pix_fmt != PIX_FMT_GRAY8) ||\n\n               (dst_pix->color_type == FF_COLOR_GRAY &&\n\n                dst_pix_fmt != PIX_FMT_GRAY8)) {\n\n        /* gray8 is the normalized format */\n\n        int_pix_fmt = PIX_FMT_GRAY8;\n\n    } else if ((is_yuv_planar(src_pix) &&\n\n                src_pix_fmt != PIX_FMT_YUV444P &&\n\n                src_pix_fmt != PIX_FMT_YUVJ444P)) {\n\n        /* yuv444 is the normalized format */\n\n        if (src_pix->color_type == FF_COLOR_YUV_JPEG)\n\n            int_pix_fmt = PIX_FMT_YUVJ444P;\n\n        else\n\n            int_pix_fmt = PIX_FMT_YUV444P;\n\n    } else if ((is_yuv_planar(dst_pix) &&\n\n                dst_pix_fmt != PIX_FMT_YUV444P &&\n\n                dst_pix_fmt != PIX_FMT_YUVJ444P)) {\n\n        /* yuv444 is the normalized format */\n\n        if (dst_pix->color_type == FF_COLOR_YUV_JPEG)\n\n            int_pix_fmt = PIX_FMT_YUVJ444P;\n\n        else\n\n            int_pix_fmt = PIX_FMT_YUV444P;\n\n    } else {\n\n        /* the two formats are rgb or gray8 or yuv[j]444p */\n\n        if (src_pix->is_alpha && dst_pix->is_alpha)\n\n            int_pix_fmt = PIX_FMT_RGB32;\n\n        else\n\n            int_pix_fmt = PIX_FMT_RGB24;\n\n    }\n\n    if (src_pix_fmt == int_pix_fmt)\n\n        return -1;\n\n    if (avpicture_alloc(tmp, int_pix_fmt, dst_width, dst_height) < 0)\n\n        return -1;\n\n    ret = -1;\n\n    if (img_convert(tmp, int_pix_fmt,\n\n                    src, src_pix_fmt, src_width, src_height) < 0)\n\n        goto fail1;\n\n    if (img_convert(dst, dst_pix_fmt,\n\n                    tmp, int_pix_fmt, dst_width, dst_height) < 0)\n\n        goto fail1;\n\n    ret = 0;\n\n fail1:\n\n    avpicture_free(tmp);\n\n    return ret;\n\n}\n", "idx": 25410}
{"project": "FFmpeg", "commit_id": "c82bf15dca00f67a701d126e47ea9075fc9459cb", "target": 1, "func": "static void nal_send(AVFormatContext *ctx, const uint8_t *buf, int len, int last_packet_of_frame)\n\n{\n\n    RTPMuxContext *rtp_ctx = ctx->priv_data;\n\n    int rtp_payload_size   = rtp_ctx->max_payload_size - RTP_HEVC_HEADERS_SIZE;\n\n    int nal_type           = (buf[0] >> 1) & 0x3F;\n\n\n\n    /* send it as one single NAL unit? */\n\n    if (len <= rtp_ctx->max_payload_size) {\n\n        int buffered_size = rtp_ctx->buf_ptr - rtp_ctx->buf;\n\n        /* Flush buffered NAL units if the current unit doesn't fit */\n\n        if (buffered_size + 2 + len > rtp_ctx->max_payload_size) {\n\n            flush_buffered(ctx, 0);\n\n            buffered_size = 0;\n\n        }\n\n        /* If the NAL unit fits including the framing, write the unit\n\n         * to the buffer as an aggregate packet, otherwise flush and\n\n         * send as single NAL. */\n\n        if (buffered_size + 4 + len <= rtp_ctx->max_payload_size) {\n\n            if (buffered_size == 0) {\n\n                *rtp_ctx->buf_ptr++ = 48 << 1;\n\n                *rtp_ctx->buf_ptr++ = 1;\n\n            }\n\n            AV_WB16(rtp_ctx->buf_ptr, len);\n\n            rtp_ctx->buf_ptr += 2;\n\n            memcpy(rtp_ctx->buf_ptr, buf, len);\n\n            rtp_ctx->buf_ptr += len;\n\n            rtp_ctx->buffered_nals++;\n\n        } else {\n\n            flush_buffered(ctx, 0);\n\n            ff_rtp_send_data(ctx, buf, len, last_packet_of_frame);\n\n        }\n\n    } else {\n\n        flush_buffered(ctx, 0);\n\n        /*\n\n          create the HEVC payload header and transmit the buffer as fragmentation units (FU)\n\n\n\n             0                   1\n\n             0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5\n\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n            |F|   Type    |  LayerId  | TID |\n\n            +-------------+-----------------+\n\n\n\n               F       = 0\n\n               Type    = 49 (fragmentation unit (FU))\n\n               LayerId = 0\n\n               TID     = 1\n\n         */\n\n        rtp_ctx->buf[0] = 49 << 1;\n\n        rtp_ctx->buf[1] = 1;\n\n\n\n        /*\n\n              create the FU header\n\n\n\n              0 1 2 3 4 5 6 7\n\n             +-+-+-+-+-+-+-+-+\n\n             |S|E|  FuType   |\n\n             +---------------+\n\n\n\n                S       = variable\n\n                E       = variable\n\n                FuType  = NAL unit type\n\n         */\n\n        rtp_ctx->buf[2]  = nal_type;\n\n        /* set the S bit: mark as start fragment */\n\n        rtp_ctx->buf[2] |= 1 << 7;\n\n\n\n        /* pass the original NAL header */\n\n        buf += 2;\n\n        len -= 2;\n\n\n\n        while (len > rtp_payload_size) {\n\n            /* complete and send current RTP packet */\n\n            memcpy(&rtp_ctx->buf[RTP_HEVC_HEADERS_SIZE], buf, rtp_payload_size);\n\n            ff_rtp_send_data(ctx, rtp_ctx->buf, rtp_ctx->max_payload_size, 0);\n\n\n\n            buf += rtp_payload_size;\n\n            len -= rtp_payload_size;\n\n\n\n            /* reset the S bit */\n\n            rtp_ctx->buf[2] &= ~(1 << 7);\n\n        }\n\n\n\n        /* set the E bit: mark as last fragment */\n\n        rtp_ctx->buf[2] |= 1 << 6;\n\n\n\n        /* complete and send last RTP packet */\n\n        memcpy(&rtp_ctx->buf[RTP_HEVC_HEADERS_SIZE], buf, len);\n\n        ff_rtp_send_data(ctx, rtp_ctx->buf, len + 2, last_packet_of_frame);\n\n    }\n\n}\n", "idx": 25411}
{"project": "FFmpeg", "commit_id": "c763f86728f1ae8c64794dc1a2451777539e382d", "target": 1, "func": "static void decode_band_structure(GetBitContext *gbc, int blk, int eac3,\n\n                                  int ecpl, int start_subband, int end_subband,\n\n                                  const uint8_t *default_band_struct,\n\n                                  uint8_t *band_struct, int *num_subbands,\n\n                                  int *num_bands, int *band_sizes)\n\n{\n\n    int subbnd, bnd, n_subbands, n_bands, bnd_sz[22];\n\n\n\n    n_subbands = end_subband - start_subband;\n\n\n\n    /* decode band structure from bitstream or use default */\n\n    if (!eac3 || get_bits1(gbc)) {\n\n        for (subbnd = 0; subbnd < n_subbands - 1; subbnd++) {\n\n            band_struct[subbnd] = get_bits1(gbc);\n\n        }\n\n    } else if (!blk) {\n\n        memcpy(band_struct,\n\n               &default_band_struct[start_subband+1],\n\n               n_subbands-1);\n\n    }\n\n    band_struct[n_subbands-1] = 0;\n\n\n\n    /* calculate number of bands and band sizes based on band structure.\n\n       note that the first 4 subbands in enhanced coupling span only 6 bins\n\n       instead of 12. */\n\n    if (num_bands || band_sizes ) {\n\n        n_bands = n_subbands;\n\n        bnd_sz[0] = ecpl ? 6 : 12;\n\n        for (bnd = 0, subbnd = 1; subbnd < n_subbands; subbnd++) {\n\n            int subbnd_size = (ecpl && subbnd < 4) ? 6 : 12;\n\n            if (band_struct[subbnd-1]) {\n\n                n_bands--;\n\n                bnd_sz[bnd] += subbnd_size;\n\n            } else {\n\n                bnd_sz[++bnd] = subbnd_size;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* set optional output params */\n\n    if (num_subbands)\n\n        *num_subbands = n_subbands;\n\n    if (num_bands)\n\n        *num_bands = n_bands;\n\n    if (band_sizes)\n\n        memcpy(band_sizes, bnd_sz, sizeof(int)*n_bands);\n\n}\n", "idx": 25412}
{"project": "FFmpeg", "commit_id": "80387f0e2568746dce4a68e2217297029a053dae", "target": 1, "func": "static int mimic_decode_frame(AVCodecContext *avctx, void *data,\n\n                              int *data_size, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    MimicContext *ctx = avctx->priv_data;\n\n    GetByteContext gb;\n\n    int is_pframe;\n\n    int width, height;\n\n    int quality, num_coeffs;\n\n    int swap_buf_size = buf_size - MIMIC_HEADER_SIZE;\n\n\n\n    if (buf_size <= MIMIC_HEADER_SIZE) {\n\n        av_log(avctx, AV_LOG_ERROR, \"insufficient data\\n\");\n\n        return -1;\n\n    }\n\n\n\n    bytestream2_init(&gb, buf, MIMIC_HEADER_SIZE);\n\n    bytestream2_skip(&gb, 2); /* some constant (always 256) */\n\n    quality    = bytestream2_get_le16u(&gb);\n\n    width      = bytestream2_get_le16u(&gb);\n\n    height     = bytestream2_get_le16u(&gb);\n\n    bytestream2_skip(&gb, 4); /* some constant */\n\n    is_pframe  = bytestream2_get_le32u(&gb);\n\n    num_coeffs = bytestream2_get_byteu(&gb);\n\n    bytestream2_skip(&gb, 3); /* some constant */\n\n\n\n    if(!ctx->avctx) {\n\n        int i;\n\n\n\n        if(!(width == 160 && height == 120) &&\n\n           !(width == 320 && height == 240)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid width/height!\\n\");\n\n            return -1;\n\n        }\n\n\n\n        ctx->avctx     = avctx;\n\n        avctx->width   = width;\n\n        avctx->height  = height;\n\n        avctx->pix_fmt = PIX_FMT_YUV420P;\n\n        for(i = 0; i < 3; i++) {\n\n            ctx->num_vblocks[i] = -((-height) >> (3 + !!i));\n\n            ctx->num_hblocks[i] =     width   >> (3 + !!i) ;\n\n        }\n\n    } else if(width != ctx->avctx->width || height != ctx->avctx->height) {\n\n        av_log(avctx, AV_LOG_ERROR, \"resolution changing is not supported\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(is_pframe && !ctx->buf_ptrs[ctx->prev_index].data[0]) {\n\n        av_log(avctx, AV_LOG_ERROR, \"decoding must start with keyframe\\n\");\n\n        return -1;\n\n    }\n\n\n\n    ctx->buf_ptrs[ctx->cur_index].reference = 1;\n\n    ctx->buf_ptrs[ctx->cur_index].pict_type = is_pframe ? AV_PICTURE_TYPE_P:AV_PICTURE_TYPE_I;\n\n    if(ff_thread_get_buffer(avctx, &ctx->buf_ptrs[ctx->cur_index])) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    ctx->next_prev_index = ctx->cur_index;\n\n    ctx->next_cur_index  = (ctx->cur_index - 1) & 15;\n\n\n\n    prepare_avpic(ctx, &ctx->flipped_ptrs[ctx->cur_index],\n\n                  (AVPicture*) &ctx->buf_ptrs[ctx->cur_index]);\n\n\n\n    ff_thread_finish_setup(avctx);\n\n\n\n    av_fast_malloc(&ctx->swap_buf, &ctx->swap_buf_size,\n\n                                 swap_buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    if(!ctx->swap_buf)\n\n        return AVERROR(ENOMEM);\n\n\n\n    ctx->dsp.bswap_buf(ctx->swap_buf,\n\n                        (const uint32_t*) (buf + MIMIC_HEADER_SIZE),\n\n                        swap_buf_size>>2);\n\n    init_get_bits(&ctx->gb, ctx->swap_buf, swap_buf_size << 3);\n\n\n\n    if(!decode(ctx, quality, num_coeffs, !is_pframe)) {\n\n        if (avctx->active_thread_type&FF_THREAD_FRAME)\n\n            ff_thread_report_progress(&ctx->buf_ptrs[ctx->cur_index], INT_MAX, 0);\n\n        else {\n\n            ff_thread_release_buffer(avctx, &ctx->buf_ptrs[ctx->cur_index]);\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    *(AVFrame*)data = ctx->buf_ptrs[ctx->cur_index];\n\n    *data_size = sizeof(AVFrame);\n\n\n\n    ctx->prev_index = ctx->next_prev_index;\n\n    ctx->cur_index  = ctx->next_cur_index;\n\n\n\n    /* Only release frames that aren't used for backreferences anymore */\n\n    if(ctx->buf_ptrs[ctx->cur_index].data[0])\n\n        ff_thread_release_buffer(avctx, &ctx->buf_ptrs[ctx->cur_index]);\n\n\n\n    return buf_size;\n\n}\n", "idx": 25413}
{"project": "FFmpeg", "commit_id": "073c2593c9f0aa4445a6fc1b9b24e6e52a8cc2c1", "target": 1, "func": "static void init_coef_vlc(VLC *vlc, \n\n                          uint16_t **prun_table, uint16_t **plevel_table,\n\n                          const CoefVLCTable *vlc_table)\n\n{\n\n    int n = vlc_table->n;\n\n    const uint8_t *table_bits = vlc_table->huffbits;\n\n    const uint32_t *table_codes = vlc_table->huffcodes;\n\n    const uint16_t *levels_table = vlc_table->levels;\n\n    uint16_t *run_table, *level_table;\n\n    const uint16_t *p;\n\n    int i, l, j, level;\n\n\n\n    init_vlc(vlc, 9, n, table_bits, 1, 1, table_codes, 4, 4);\n\n\n\n    run_table = av_malloc(n * sizeof(uint16_t));\n\n    level_table = av_malloc(n * sizeof(uint16_t));\n\n    p = levels_table;\n\n    i = 2;\n\n    level = 1;\n\n    while (i < n) {\n\n        l = *p++;\n\n        for(j=0;j<l;j++) {\n\n            run_table[i] = j;\n\n            level_table[i] = level;\n\n            i++;\n\n        }\n\n        level++;\n\n    }\n\n    *prun_table = run_table;\n\n    *plevel_table = level_table;\n\n}\n", "idx": 25415}
{"project": "FFmpeg", "commit_id": "aaae59700f7fc10fd80cb93b38c5d109900872d9", "target": 0, "func": "static int avisynth_read_packet_video(AVFormatContext *s, AVPacket *pkt,\n\n                                      int discard)\n\n{\n\n    AviSynthContext *avs = s->priv_data;\n\n    AVS_VideoFrame *frame;\n\n    unsigned char *dst_p;\n\n    const unsigned char *src_p;\n\n    int n, i, plane, rowsize, planeheight, pitch, bits;\n\n    const char *error;\n\n\n\n    if (avs->curr_frame >= avs->vi->num_frames)\n\n        return AVERROR_EOF;\n\n\n\n    /* This must happen even if the stream is discarded to prevent desync. */\n\n    n = avs->curr_frame++;\n\n    if (discard)\n\n        return 0;\n\n\n\n#ifdef USING_AVISYNTH\n\n    /* Define the bpp values for the new AviSynth 2.6 colorspaces.\n\n     * Since AvxSynth doesn't have these functions, special-case\n\n     * it in order to avoid implicit declaration errors. */\n\n\n\n    if (avs_library.avs_is_yv24(avs->vi))\n\n        bits = 24;\n\n    else if (avs_library.avs_is_yv16(avs->vi))\n\n        bits = 16;\n\n    else if (avs_library.avs_is_yv411(avs->vi))\n\n        bits = 12;\n\n    else if (avs_library.avs_is_y8(avs->vi))\n\n        bits = 8;\n\n    else\n\n        bits = avs_library.avs_bits_per_pixel(avs->vi);\n\n#else\n\n    bits = avs_bits_per_pixel(avs->vi);\n\n#endif\n\n\n\n    /* Without the cast to int64_t, calculation overflows at about 9k x 9k\n\n     * resolution. */\n\n    pkt->size = (((int64_t)avs->vi->width *\n\n                  (int64_t)avs->vi->height) * bits) / 8;\n\n    if (!pkt->size)\n\n        return AVERROR_UNKNOWN;\n\n\n\n    if (av_new_packet(pkt, pkt->size) < 0)\n\n        return AVERROR(ENOMEM);\n\n\n\n    pkt->pts      = n;\n\n    pkt->dts      = n;\n\n    pkt->duration = 1;\n\n    pkt->stream_index = avs->curr_stream;\n\n\n\n    frame = avs_library.avs_get_frame(avs->clip, n);\n\n    error = avs_library.avs_clip_get_error(avs->clip);\n\n    if (error) {\n\n        av_log(s, AV_LOG_ERROR, \"%s\\n\", error);\n\n        avs->error = 1;\n\n        av_packet_unref(pkt);\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    dst_p = pkt->data;\n\n    for (i = 0; i < avs->n_planes; i++) {\n\n        plane = avs->planes[i];\n\n#ifdef USING_AVISYNTH\n\n        src_p = avs_library.avs_get_read_ptr_p(frame, plane);\n\n        pitch = avs_library.avs_get_pitch_p(frame, plane);\n\n\n\n        rowsize     = avs_library.avs_get_row_size_p(frame, plane);\n\n        planeheight = avs_library.avs_get_height_p(frame, plane);\n\n#else\n\n        src_p = avs_get_read_ptr_p(frame, plane);\n\n        pitch = avs_get_pitch_p(frame, plane);\n\n\n\n        rowsize     = avs_get_row_size_p(frame, plane);\n\n        planeheight = avs_get_height_p(frame, plane);\n\n#endif\n\n\n\n        /* Flip RGB video. */\n\n        if (avs_is_rgb24(avs->vi) || avs_is_rgb(avs->vi)) {\n\n            src_p = src_p + (planeheight - 1) * pitch;\n\n            pitch = -pitch;\n\n        }\n\n\n\n        avs_library.avs_bit_blt(avs->env, dst_p, rowsize, src_p, pitch,\n\n                                 rowsize, planeheight);\n\n        dst_p += rowsize * planeheight;\n\n    }\n\n\n\n    avs_library.avs_release_video_frame(frame);\n\n    return 0;\n\n}\n", "idx": 25416}
{"project": "FFmpeg", "commit_id": "72dbc610be3272ba36603f78a39cc2d2d8fe0cc3", "target": 0, "func": "static void avc_luma_midh_qrt_and_aver_dst_16w_msa(const uint8_t *src,\n\n                                                   int32_t src_stride,\n\n                                                   uint8_t *dst,\n\n                                                   int32_t dst_stride,\n\n                                                   int32_t height,\n\n                                                   uint8_t horiz_offset)\n\n{\n\n    uint32_t multiple8_cnt;\n\n\n\n    for (multiple8_cnt = 4; multiple8_cnt--;) {\n\n        avc_luma_midh_qrt_and_aver_dst_4w_msa(src, src_stride, dst, dst_stride,\n\n                                              height, horiz_offset);\n\n\n\n        src += 4;\n\n        dst += 4;\n\n    }\n\n}\n", "idx": 25417}
{"project": "FFmpeg", "commit_id": "5d996b56499f00f80b02a41bab3d6b7349e36e9d", "target": 1, "func": "static int tiff_decode_tag(TiffContext *s, AVFrame *frame)\n\n{\n\n    unsigned tag, type, count, off, value = 0, value2 = 0;\n\n    int i, start;\n\n    int pos;\n\n    int ret;\n\n    double *dp;\n\n\n\n    ret = ff_tread_tag(&s->gb, s->le, &tag, &type, &count, &start);\n\n    if (ret < 0) {\n\n        goto end;\n\n\n\n\n    off = bytestream2_tell(&s->gb);\n\n    if (count == 1) {\n\n        switch (type) {\n\n        case TIFF_BYTE:\n\n        case TIFF_SHORT:\n\n        case TIFF_LONG:\n\n            value = ff_tget(&s->gb, type, s->le);\n\n            break;\n\n        case TIFF_RATIONAL:\n\n            value  = ff_tget(&s->gb, TIFF_LONG, s->le);\n\n            value2 = ff_tget(&s->gb, TIFF_LONG, s->le);\n\n            break;\n\n        case TIFF_STRING:\n\n            if (count <= 4) {\n\n                break;\n\n\n        default:\n\n            value = UINT_MAX;\n\n\n\n\n\n    switch (tag) {\n\n    case TIFF_WIDTH:\n\n        s->width = value;\n\n        break;\n\n    case TIFF_HEIGHT:\n\n        s->height = value;\n\n        break;\n\n    case TIFF_BPP:\n\n        if (count > 4U) {\n\n\n                   \"This format is not supported (bpp=%d, %d components)\\n\",\n\n                   value, count);\n\n\n\n        s->bppcount = count;\n\n        if (count == 1)\n\n            s->bpp = value;\n\n        else {\n\n            switch (type) {\n\n            case TIFF_BYTE:\n\n            case TIFF_SHORT:\n\n            case TIFF_LONG:\n\n                s->bpp = 0;\n\n                if (bytestream2_get_bytes_left(&s->gb) < type_sizes[type] * count)\n\n\n                for (i = 0; i < count; i++)\n\n                    s->bpp += ff_tget(&s->gb, type, s->le);\n\n                break;\n\n            default:\n\n                s->bpp = -1;\n\n\n\n        break;\n\n    case TIFF_SAMPLES_PER_PIXEL:\n\n        if (count != 1) {\n\n\n                   \"Samples per pixel requires a single value, many provided\\n\");\n\n\n\n        if (value > 4U) {\n\n\n                   \"Samples per pixel %d is too large\\n\", value);\n\n\n\n        if (s->bppcount == 1)\n\n            s->bpp *= value;\n\n        s->bppcount = value;\n\n        break;\n\n    case TIFF_COMPR:\n\n        s->compr     = value;\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"compression: %d\\n\", s->compr);\n\n        s->predictor = 0;\n\n        switch (s->compr) {\n\n        case TIFF_RAW:\n\n        case TIFF_PACKBITS:\n\n        case TIFF_LZW:\n\n        case TIFF_CCITT_RLE:\n\n            break;\n\n        case TIFF_G3:\n\n        case TIFF_G4:\n\n            s->fax_opts = 0;\n\n            break;\n\n        case TIFF_DEFLATE:\n\n        case TIFF_ADOBE_DEFLATE:\n\n#if CONFIG_ZLIB\n\n            break;\n\n#else\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Deflate: ZLib not compiled in\\n\");\n\n            return AVERROR(ENOSYS);\n\n#endif\n\n        case TIFF_JPEG:\n\n        case TIFF_NEWJPEG:\n\n            avpriv_report_missing_feature(s->avctx, \"JPEG compression\");\n\n            return AVERROR_PATCHWELCOME;\n\n        case TIFF_LZMA:\n\n#if CONFIG_LZMA\n\n            break;\n\n#else\n\n            av_log(s->avctx, AV_LOG_ERROR, \"LZMA not compiled in\\n\");\n\n            return AVERROR(ENOSYS);\n\n#endif\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Unknown compression method %i\\n\",\n\n                   s->compr);\n\n\n\n        break;\n\n    case TIFF_ROWSPERSTRIP:\n\n        if (!value || (type == TIFF_LONG && value == UINT_MAX))\n\n            value = s->height;\n\n        s->rps = FFMIN(value, s->height);\n\n        break;\n\n    case TIFF_STRIP_OFFS:\n\n        if (count == 1) {\n\n\n\n\n\n\n            s->strippos = 0;\n\n            s->stripoff = value;\n\n        } else\n\n            s->strippos = off;\n\n        s->strips = count;\n\n        if (s->strips == 1)\n\n            s->rps = s->height;\n\n        s->sot = type;\n\n        break;\n\n    case TIFF_STRIP_SIZE:\n\n        if (count == 1) {\n\n\n\n                    \"stripsize %u too large\\n\", value);\n\n\n\n            s->stripsizesoff = 0;\n\n            s->stripsize     = value;\n\n            s->strips        = 1;\n\n        } else {\n\n            s->stripsizesoff = off;\n\n\n        s->strips = count;\n\n        s->sstype = type;\n\n        break;\n\n    case TIFF_XRES:\n\n    case TIFF_YRES:\n\n        set_sar(s, tag, value, value2);\n\n        break;\n\n    case TIFF_TILE_BYTE_COUNTS:\n\n    case TIFF_TILE_LENGTH:\n\n    case TIFF_TILE_OFFSETS:\n\n    case TIFF_TILE_WIDTH:\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Tiled images are not supported\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n        break;\n\n    case TIFF_PREDICTOR:\n\n        s->predictor = value;\n\n        break;\n\n    case TIFF_PHOTOMETRIC:\n\n        switch (value) {\n\n        case TIFF_PHOTOMETRIC_WHITE_IS_ZERO:\n\n        case TIFF_PHOTOMETRIC_BLACK_IS_ZERO:\n\n        case TIFF_PHOTOMETRIC_RGB:\n\n        case TIFF_PHOTOMETRIC_PALETTE:\n\n        case TIFF_PHOTOMETRIC_YCBCR:\n\n            s->photometric = value;\n\n            break;\n\n        case TIFF_PHOTOMETRIC_ALPHA_MASK:\n\n        case TIFF_PHOTOMETRIC_SEPARATED:\n\n        case TIFF_PHOTOMETRIC_CIE_LAB:\n\n        case TIFF_PHOTOMETRIC_ICC_LAB:\n\n        case TIFF_PHOTOMETRIC_ITU_LAB:\n\n        case TIFF_PHOTOMETRIC_CFA:\n\n        case TIFF_PHOTOMETRIC_LOG_L:\n\n        case TIFF_PHOTOMETRIC_LOG_LUV:\n\n        case TIFF_PHOTOMETRIC_LINEAR_RAW:\n\n            avpriv_report_missing_feature(s->avctx,\n\n                                          \"PhotometricInterpretation 0x%04X\",\n\n                                          value);\n\n            return AVERROR_PATCHWELCOME;\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"PhotometricInterpretation %u is \"\n\n                   \"unknown\\n\", value);\n\n\n\n        break;\n\n    case TIFF_FILL_ORDER:\n\n        if (value < 1 || value > 2) {\n\n\n                   \"Unknown FillOrder value %d, trying default one\\n\", value);\n\n            value = 1;\n\n\n        s->fill_order = value - 1;\n\n        break;\n\n    case TIFF_PAL: {\n\n        GetByteContext pal_gb[3];\n\n        off = type_sizes[type];\n\n        if (count / 3 > 256 ||\n\n            bytestream2_get_bytes_left(&s->gb) < count / 3 * off * 3)\n\n\n\n\n        pal_gb[0] = pal_gb[1] = pal_gb[2] = s->gb;\n\n        bytestream2_skip(&pal_gb[1], count / 3 * off);\n\n        bytestream2_skip(&pal_gb[2], count / 3 * off * 2);\n\n\n\n        off = (type_sizes[type] - 1) << 3;\n\n        if (off > 31U) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"palette shift %d is out of range\\n\", off);\n\n\n\n\n\n        for (i = 0; i < count / 3; i++) {\n\n            uint32_t p = 0xFF000000;\n\n            p |= (ff_tget(&pal_gb[0], type, s->le) >> off) << 16;\n\n            p |= (ff_tget(&pal_gb[1], type, s->le) >> off) << 8;\n\n            p |=  ff_tget(&pal_gb[2], type, s->le) >> off;\n\n            s->palette[i] = p;\n\n\n        s->palette_is_set = 1;\n\n        break;\n\n\n    case TIFF_PLANAR:\n\n        s->planar = value == 2;\n\n        break;\n\n    case TIFF_YCBCR_SUBSAMPLING:\n\n        if (count != 2) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"subsample count invalid\\n\");\n\n\n\n        for (i = 0; i < count; i++) {\n\n            s->subsampling[i] = ff_tget(&s->gb, type, s->le);\n\n            if (s->subsampling[i] <= 0) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"subsampling %d is invalid\\n\", s->subsampling[i]);\n\n\n\n\n        break;\n\n    case TIFF_T4OPTIONS:\n\n        if (s->compr == TIFF_G3)\n\n            s->fax_opts = value;\n\n        break;\n\n    case TIFF_T6OPTIONS:\n\n        if (s->compr == TIFF_G4)\n\n            s->fax_opts = value;\n\n        break;\n\n#define ADD_METADATA(count, name, sep)\\\n\n    if ((ret = add_metadata(count, type, name, sep, s, frame)) < 0) {\\\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\\\n\n        goto end;\\\n\n\n    case TIFF_MODEL_PIXEL_SCALE:\n\n        ADD_METADATA(count, \"ModelPixelScaleTag\", NULL);\n\n        break;\n\n    case TIFF_MODEL_TRANSFORMATION:\n\n        ADD_METADATA(count, \"ModelTransformationTag\", NULL);\n\n        break;\n\n    case TIFF_MODEL_TIEPOINT:\n\n        ADD_METADATA(count, \"ModelTiepointTag\", NULL);\n\n        break;\n\n    case TIFF_GEO_KEY_DIRECTORY:\n\n        if (s->geotag_count) {\n\n            avpriv_request_sample(s->avctx, \"Multiple geo key directories\\n\");\n\n\n\n        ADD_METADATA(1, \"GeoTIFF_Version\", NULL);\n\n        ADD_METADATA(2, \"GeoTIFF_Key_Revision\", \".\");\n\n        s->geotag_count   = ff_tget_short(&s->gb, s->le);\n\n        if (s->geotag_count > count / 4 - 1) {\n\n            s->geotag_count = count / 4 - 1;\n\n            av_log(s->avctx, AV_LOG_WARNING, \"GeoTIFF key directory buffer shorter than specified\\n\");\n\n\n        if (bytestream2_get_bytes_left(&s->gb) < s->geotag_count * sizeof(int16_t) * 4) {\n\n            s->geotag_count = 0;\n\n            return -1;\n\n\n        s->geotags = av_mallocz_array(s->geotag_count, sizeof(TiffGeoTag));\n\n        if (!s->geotags) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n            s->geotag_count = 0;\n\n            goto end;\n\n\n        for (i = 0; i < s->geotag_count; i++) {\n\n            s->geotags[i].key    = ff_tget_short(&s->gb, s->le);\n\n            s->geotags[i].type   = ff_tget_short(&s->gb, s->le);\n\n            s->geotags[i].count  = ff_tget_short(&s->gb, s->le);\n\n\n\n            if (!s->geotags[i].type)\n\n                s->geotags[i].val  = get_geokey_val(s->geotags[i].key, ff_tget_short(&s->gb, s->le));\n\n            else\n\n                s->geotags[i].offset = ff_tget_short(&s->gb, s->le);\n\n\n        break;\n\n    case TIFF_GEO_DOUBLE_PARAMS:\n\n        if (count >= INT_MAX / sizeof(int64_t))\n\n\n        if (bytestream2_get_bytes_left(&s->gb) < count * sizeof(int64_t))\n\n\n        dp = av_malloc_array(count, sizeof(double));\n\n        if (!dp) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n            goto end;\n\n\n        for (i = 0; i < count; i++)\n\n            dp[i] = ff_tget_double(&s->gb, s->le);\n\n        for (i = 0; i < s->geotag_count; i++) {\n\n            if (s->geotags[i].type == TIFF_GEO_DOUBLE_PARAMS) {\n\n                if (s->geotags[i].count == 0\n\n                    || s->geotags[i].offset + s->geotags[i].count > count) {\n\n                    av_log(s->avctx, AV_LOG_WARNING, \"Invalid GeoTIFF key %d\\n\", s->geotags[i].key);\n\n                } else {\n\n                    char *ap = doubles2str(&dp[s->geotags[i].offset], s->geotags[i].count, \", \");\n\n                    if (!ap) {\n\n                        av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n                        av_freep(&dp);\n\n                        return AVERROR(ENOMEM);\n\n\n                    s->geotags[i].val = ap;\n\n\n\n\n        av_freep(&dp);\n\n        break;\n\n    case TIFF_GEO_ASCII_PARAMS:\n\n        pos = bytestream2_tell(&s->gb);\n\n        for (i = 0; i < s->geotag_count; i++) {\n\n            if (s->geotags[i].type == TIFF_GEO_ASCII_PARAMS) {\n\n                if (s->geotags[i].count == 0\n\n                    || s->geotags[i].offset +  s->geotags[i].count > count) {\n\n                    av_log(s->avctx, AV_LOG_WARNING, \"Invalid GeoTIFF key %d\\n\", s->geotags[i].key);\n\n                } else {\n\n                    char *ap;\n\n\n\n                    bytestream2_seek(&s->gb, pos + s->geotags[i].offset, SEEK_SET);\n\n                    if (bytestream2_get_bytes_left(&s->gb) < s->geotags[i].count)\n\n\n                    ap = av_malloc(s->geotags[i].count);\n\n                    if (!ap) {\n\n                        av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n                        return AVERROR(ENOMEM);\n\n\n                    bytestream2_get_bufferu(&s->gb, ap, s->geotags[i].count);\n\n                    ap[s->geotags[i].count - 1] = '\\0'; //replace the \"|\" delimiter with a 0 byte\n\n                    s->geotags[i].val = ap;\n\n\n\n\n        break;\n\n    case TIFF_ARTIST:\n\n        ADD_METADATA(count, \"artist\", NULL);\n\n        break;\n\n    case TIFF_COPYRIGHT:\n\n        ADD_METADATA(count, \"copyright\", NULL);\n\n        break;\n\n    case TIFF_DATE:\n\n        ADD_METADATA(count, \"date\", NULL);\n\n        break;\n\n    case TIFF_DOCUMENT_NAME:\n\n        ADD_METADATA(count, \"document_name\", NULL);\n\n        break;\n\n    case TIFF_HOST_COMPUTER:\n\n        ADD_METADATA(count, \"computer\", NULL);\n\n        break;\n\n    case TIFF_IMAGE_DESCRIPTION:\n\n        ADD_METADATA(count, \"description\", NULL);\n\n        break;\n\n    case TIFF_MAKE:\n\n        ADD_METADATA(count, \"make\", NULL);\n\n        break;\n\n    case TIFF_MODEL:\n\n        ADD_METADATA(count, \"model\", NULL);\n\n        break;\n\n    case TIFF_PAGE_NAME:\n\n        ADD_METADATA(count, \"page_name\", NULL);\n\n        break;\n\n    case TIFF_PAGE_NUMBER:\n\n        ADD_METADATA(count, \"page_number\", \" / \");\n\n        break;\n\n    case TIFF_SOFTWARE_NAME:\n\n        ADD_METADATA(count, \"software\", NULL);\n\n        break;\n\n    default:\n\n        if (s->avctx->err_recognition & AV_EF_EXPLODE) {\n\n\n                   \"Unknown or unsupported tag %d/0X%0X\\n\",\n\n                   tag, tag);\n\n\n\n\nend:\n\n    if (s->bpp > 64U) {\n\n\n                \"This format is not supported (bpp=%d, %d components)\\n\",\n\n                s->bpp, count);\n\n        s->bpp = 0;\n\n\n\n    bytestream2_seek(&s->gb, start, SEEK_SET);\n\n    return 0;\n", "idx": 25418}
{"project": "FFmpeg", "commit_id": "dfea94ce994a916eb7c1a278a09748fd3928c00d", "target": 1, "func": "static av_cold int fieldmatch_init(AVFilterContext *ctx)\n\n{\n\n    const FieldMatchContext *fm = ctx->priv;\n\n    AVFilterPad pad = {\n\n        .name         = av_strdup(\"main\"),\n\n        .type         = AVMEDIA_TYPE_VIDEO,\n\n        .filter_frame = filter_frame,\n\n        .config_props = config_input,\n\n    };\n\n\n\n    if (!pad.name)\n\n        return AVERROR(ENOMEM);\n\n    ff_insert_inpad(ctx, INPUT_MAIN, &pad);\n\n\n\n    if (fm->ppsrc) {\n\n        pad.name = av_strdup(\"clean_src\");\n\n        pad.config_props = NULL;\n\n        if (!pad.name)\n\n            return AVERROR(ENOMEM);\n\n        ff_insert_inpad(ctx, INPUT_CLEANSRC, &pad);\n\n    }\n\n\n\n    if ((fm->blockx & (fm->blockx - 1)) ||\n\n        (fm->blocky & (fm->blocky - 1))) {\n\n        av_log(ctx, AV_LOG_ERROR, \"blockx and blocky settings must be power of two\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (fm->combpel > fm->blockx * fm->blocky) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Combed pixel should not be larger than blockx x blocky\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25422}
{"project": "FFmpeg", "commit_id": "6bd665b7c5798803366b877903fa3bce7f129d05", "target": 0, "func": "void avpriv_tak_parse_streaminfo(GetBitContext *gb, TAKStreamInfo *s)\n\n{\n\n    uint64_t channel_mask = 0;\n\n    int frame_type, i;\n\n\n\n    s->codec = get_bits(gb, TAK_ENCODER_CODEC_BITS);\n\n    skip_bits(gb, TAK_ENCODER_PROFILE_BITS);\n\n\n\n    frame_type = get_bits(gb, TAK_SIZE_FRAME_DURATION_BITS);\n\n    s->samples = get_bits64(gb, TAK_SIZE_SAMPLES_NUM_BITS);\n\n\n\n    s->data_type   = get_bits(gb, TAK_FORMAT_DATA_TYPE_BITS);\n\n    s->sample_rate = get_bits(gb, TAK_FORMAT_SAMPLE_RATE_BITS) +\n\n                     TAK_SAMPLE_RATE_MIN;\n\n    s->bps         = get_bits(gb, TAK_FORMAT_BPS_BITS) +\n\n                     TAK_BPS_MIN;\n\n    s->channels    = get_bits(gb, TAK_FORMAT_CHANNEL_BITS) +\n\n                     TAK_CHANNELS_MIN;\n\n\n\n    if (get_bits1(gb)) {\n\n        skip_bits(gb, TAK_FORMAT_VALID_BITS);\n\n        if (get_bits1(gb)) {\n\n            for (i = 0; i < s->channels; i++) {\n\n                int value = get_bits(gb, TAK_FORMAT_CH_LAYOUT_BITS);\n\n\n\n                if (value < FF_ARRAY_ELEMS(tak_channel_layouts))\n\n                    channel_mask |= tak_channel_layouts[value];\n\n            }\n\n        }\n\n    }\n\n\n\n    s->ch_layout     = channel_mask;\n\n    s->frame_samples = tak_get_nb_samples(s->sample_rate, frame_type);\n\n}\n", "idx": 25425}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "int show_formats(void *optctx, const char *opt, const char *arg)\n\n{\n\n    AVInputFormat *ifmt  = NULL;\n\n    AVOutputFormat *ofmt = NULL;\n\n    const char *last_name;\n\n\n\n    printf(\"File formats:\\n\"\n\n           \" D. = Demuxing supported\\n\"\n\n           \" .E = Muxing supported\\n\"\n\n           \" --\\n\");\n\n    last_name = \"000\";\n\n    for (;;) {\n\n        int decode = 0;\n\n        int encode = 0;\n\n        const char *name      = NULL;\n\n        const char *long_name = NULL;\n\n\n\n        while ((ofmt = av_oformat_next(ofmt))) {\n\n            if ((name == NULL || strcmp(ofmt->name, name) < 0) &&\n\n                strcmp(ofmt->name, last_name) > 0) {\n\n                name      = ofmt->name;\n\n                long_name = ofmt->long_name;\n\n                encode    = 1;\n\n            }\n\n        }\n\n        while ((ifmt = av_iformat_next(ifmt))) {\n\n            if ((name == NULL || strcmp(ifmt->name, name) < 0) &&\n\n                strcmp(ifmt->name, last_name) > 0) {\n\n                name      = ifmt->name;\n\n                long_name = ifmt->long_name;\n\n                encode    = 0;\n\n            }\n\n            if (name && strcmp(ifmt->name, name) == 0)\n\n                decode = 1;\n\n        }\n\n        if (name == NULL)\n\n            break;\n\n        last_name = name;\n\n\n\n        printf(\" %s%s %-15s %s\\n\",\n\n               decode ? \"D\" : \" \",\n\n               encode ? \"E\" : \" \",\n\n               name,\n\n            long_name ? long_name:\" \");\n\n    }\n\n    return 0;\n\n}\n", "idx": 25426}
{"project": "FFmpeg", "commit_id": "be394968c81019887ef996a78a526bdd85d1e216", "target": 0, "func": "static void SET_TYPE(resample_nearest)(void *dst0, int dst_index, const void *src0, int index)\n\n{\n\n    FELEM *dst = dst0;\n\n    const FELEM *src = src0;\n\n    dst[dst_index] = src[index];\n\n}\n", "idx": 25427}
{"project": "FFmpeg", "commit_id": "17779f39b684cd8e545768155c37e97e604489b8", "target": 0, "func": "static inline void mc_dir_part(H264Context *h, Picture *pic, int n, int square, int chroma_height, int delta, int list,\n\n                           uint8_t *dest_y, uint8_t *dest_cb, uint8_t *dest_cr,\n\n                           int src_x_offset, int src_y_offset,\n\n                           qpel_mc_func *qpix_op, h264_chroma_mc_func chroma_op){\n\n    MpegEncContext * const s = &h->s;\n\n    const int mx= h->mv_cache[list][ scan8[n] ][0] + src_x_offset*8;\n\n    int my=       h->mv_cache[list][ scan8[n] ][1] + src_y_offset*8;\n\n    const int luma_xy= (mx&3) + ((my&3)<<2);\n\n    uint8_t * src_y = pic->data[0] + (mx>>2) + (my>>2)*h->mb_linesize;\n\n    uint8_t * src_cb, * src_cr;\n\n    int extra_width= h->emu_edge_width;\n\n    int extra_height= h->emu_edge_height;\n\n    int emu=0;\n\n    const int full_mx= mx>>2;\n\n    const int full_my= my>>2;\n\n    const int pic_width  = 16*s->mb_width;\n\n    const int pic_height = 16*s->mb_height >> MB_FIELD;\n\n\n\n    if(!pic->data[0]) //FIXME this is unacceptable, some sensible error concealment must be done for missing reference frames\n\n        return;\n\n\n\n    if(mx&7) extra_width -= 3;\n\n    if(my&7) extra_height -= 3;\n\n\n\n    if(   full_mx < 0-extra_width\n\n       || full_my < 0-extra_height\n\n       || full_mx + 16/*FIXME*/ > pic_width + extra_width\n\n       || full_my + 16/*FIXME*/ > pic_height + extra_height){\n\n        ff_emulated_edge_mc(s->edge_emu_buffer, src_y - 2 - 2*h->mb_linesize, h->mb_linesize, 16+5, 16+5/*FIXME*/, full_mx-2, full_my-2, pic_width, pic_height);\n\n            src_y= s->edge_emu_buffer + 2 + 2*h->mb_linesize;\n\n        emu=1;\n\n    }\n\n\n\n    qpix_op[luma_xy](dest_y, src_y, h->mb_linesize); //FIXME try variable height perhaps?\n\n    if(!square){\n\n        qpix_op[luma_xy](dest_y + delta, src_y + delta, h->mb_linesize);\n\n    }\n\n\n\n    if(ENABLE_GRAY && s->flags&CODEC_FLAG_GRAY) return;\n\n\n\n    if(MB_FIELD){\n\n        // chroma offset when predicting from a field of opposite parity\n\n        my += 2 * ((s->mb_y & 1) - (pic->reference - 1));\n\n        emu |= (my>>3) < 0 || (my>>3) + 8 >= (pic_height>>1);\n\n    }\n\n    src_cb= pic->data[1] + (mx>>3) + (my>>3)*h->mb_uvlinesize;\n\n    src_cr= pic->data[2] + (mx>>3) + (my>>3)*h->mb_uvlinesize;\n\n\n\n    if(emu){\n\n        ff_emulated_edge_mc(s->edge_emu_buffer, src_cb, h->mb_uvlinesize, 9, 9/*FIXME*/, (mx>>3), (my>>3), pic_width>>1, pic_height>>1);\n\n            src_cb= s->edge_emu_buffer;\n\n    }\n\n    chroma_op(dest_cb, src_cb, h->mb_uvlinesize, chroma_height, mx&7, my&7);\n\n\n\n    if(emu){\n\n        ff_emulated_edge_mc(s->edge_emu_buffer, src_cr, h->mb_uvlinesize, 9, 9/*FIXME*/, (mx>>3), (my>>3), pic_width>>1, pic_height>>1);\n\n            src_cr= s->edge_emu_buffer;\n\n    }\n\n    chroma_op(dest_cr, src_cr, h->mb_uvlinesize, chroma_height, mx&7, my&7);\n\n}\n", "idx": 25428}
{"project": "FFmpeg", "commit_id": "57f94f54c449b1d34b0d6ccf82dfdcdc1ce7cd14", "target": 0, "func": "static void rtsp_send_cmd(AVFormatContext *s,\n\n                          const char *cmd, RTSPMessageHeader *reply,\n\n                          unsigned char **content_ptr)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    char buf[4096], buf1[1024];\n\n\n\n    rt->seq++;\n\n    av_strlcpy(buf, cmd, sizeof(buf));\n\n    snprintf(buf1, sizeof(buf1), \"CSeq: %d\\r\\n\", rt->seq);\n\n    av_strlcat(buf, buf1, sizeof(buf));\n\n    if (rt->session_id[0] != '\\0' && !strstr(cmd, \"\\nIf-Match:\")) {\n\n        snprintf(buf1, sizeof(buf1), \"Session: %s\\r\\n\", rt->session_id);\n\n        av_strlcat(buf, buf1, sizeof(buf));\n\n    }\n\n    av_strlcat(buf, \"\\r\\n\", sizeof(buf));\n\n#ifdef DEBUG\n\n    printf(\"Sending:\\n%s--\\n\", buf);\n\n#endif\n\n    url_write(rt->rtsp_hd, buf, strlen(buf));\n\n\n\n    rtsp_read_reply(rt, reply, content_ptr);\n\n}\n", "idx": 25429}
{"project": "FFmpeg", "commit_id": "79a7451d069f17c72e566d8e76a75c15cc25c515", "target": 0, "func": "static int configure_video_filters(AVFilterGraph *graph, VideoState *is, const char *vfilters)\n\n{\n\n    static const enum PixelFormat pix_fmts[] = { PIX_FMT_YUV420P, PIX_FMT_NONE };\n\n    char sws_flags_str[128];\n\n    char buffersrc_args[256];\n\n    int ret;\n\n    AVBufferSinkParams *buffersink_params = av_buffersink_params_alloc();\n\n    AVFilterContext *filt_src = NULL, *filt_out = NULL, *filt_format;\n\n    AVCodecContext *codec = is->video_st->codec;\n\n\n\n    snprintf(sws_flags_str, sizeof(sws_flags_str), \"flags=%d\", sws_flags);\n\n    graph->scale_sws_opts = av_strdup(sws_flags_str);\n\n\n\n    snprintf(buffersrc_args, sizeof(buffersrc_args),\n\n             \"video_size=%dx%d:pix_fmt=%d:time_base=%d/%d:pixel_aspect=%d/%d\",\n\n             codec->width, codec->height, codec->pix_fmt,\n\n             is->video_st->time_base.num, is->video_st->time_base.den,\n\n             codec->sample_aspect_ratio.num, codec->sample_aspect_ratio.den);\n\n\n\n    if ((ret = avfilter_graph_create_filter(&filt_src,\n\n                                            avfilter_get_by_name(\"buffer\"),\n\n                                            \"ffplay_buffer\", buffersrc_args, NULL,\n\n                                            graph)) < 0)\n\n        return ret;\n\n\n\n    buffersink_params->pixel_fmts = pix_fmts;\n\n    ret = avfilter_graph_create_filter(&filt_out,\n\n                                       avfilter_get_by_name(\"buffersink\"),\n\n                                       \"ffplay_buffersink\", NULL, buffersink_params, graph);\n\n    av_freep(&buffersink_params);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if ((ret = avfilter_graph_create_filter(&filt_format,\n\n                                            avfilter_get_by_name(\"format\"),\n\n                                            \"format\", \"yuv420p\", NULL, graph)) < 0)\n\n        return ret;\n\n    if ((ret = avfilter_link(filt_format, 0, filt_out, 0)) < 0)\n\n        return ret;\n\n\n\n\n\n    if (vfilters) {\n\n        AVFilterInOut *outputs = avfilter_inout_alloc();\n\n        AVFilterInOut *inputs  = avfilter_inout_alloc();\n\n\n\n        outputs->name    = av_strdup(\"in\");\n\n        outputs->filter_ctx = filt_src;\n\n        outputs->pad_idx = 0;\n\n        outputs->next    = NULL;\n\n\n\n        inputs->name    = av_strdup(\"out\");\n\n        inputs->filter_ctx = filt_format;\n\n        inputs->pad_idx = 0;\n\n        inputs->next    = NULL;\n\n\n\n        if ((ret = avfilter_graph_parse(graph, vfilters, &inputs, &outputs, NULL)) < 0)\n\n            return ret;\n\n    } else {\n\n        if ((ret = avfilter_link(filt_src, 0, filt_format, 0)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    if ((ret = avfilter_graph_config(graph, NULL)) < 0)\n\n        return ret;\n\n\n\n    is->in_video_filter  = filt_src;\n\n    is->out_video_filter = filt_out;\n\n\n\n    if (codec->codec->capabilities & CODEC_CAP_DR1) {\n\n        is->use_dr1 = 1;\n\n        codec->get_buffer     = codec_get_buffer;\n\n        codec->release_buffer = codec_release_buffer;\n\n        codec->opaque         = &is->buffer_pool;\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 25430}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int x8_setup_spatial_predictor(IntraX8Context * const w, const int chroma){\n\n    MpegEncContext * const s= w->s;\n\n    int range;\n\n    int sum;\n\n    int quant;\n\n\n\n    w->dsp.setup_spatial_compensation(s->dest[chroma], s->edge_emu_buffer,\n\n                                      s->current_picture.f.linesize[chroma>0],\n\n                                      &range, &sum, w->edges);\n\n    if(chroma){\n\n        w->orient=w->chroma_orient;\n\n        quant=w->quant_dc_chroma;\n\n    }else{\n\n        quant=w->quant;\n\n    }\n\n\n\n    w->flat_dc=0;\n\n    if(range < quant || range < 3){\n\n        w->orient=0;\n\n        if(range < 3){//yep you read right, a +-1 idct error may break decoding!\n\n            w->flat_dc=1;\n\n            sum+=9;\n\n            w->predicted_dc = (sum*6899)>>17;//((1<<17)+9)/(8+8+1+2)=6899\n\n        }\n\n    }\n\n    if(chroma)\n\n        return 0;\n\n\n\n    assert(w->orient < 3);\n\n    if(range < 2*w->quant){\n\n        if( (w->edges&3) == 0){\n\n            if(w->orient==1) w->orient=11;\n\n            if(w->orient==2) w->orient=10;\n\n        }else{\n\n            w->orient=0;\n\n        }\n\n        w->raw_orient=0;\n\n    }else{\n\n        static const uint8_t prediction_table[3][12]={\n\n            {0,8,4, 10,11, 2,6,9,1,3,5,7},\n\n            {4,0,8, 11,10, 3,5,2,6,9,1,7},\n\n            {8,0,4, 10,11, 1,7,2,6,9,3,5}\n\n        };\n\n        w->raw_orient=x8_get_orient_vlc(w);\n\n        if(w->raw_orient<0) return -1;\n\n        assert(w->raw_orient < 12 );\n\n        assert(w->orient<3);\n\n        w->orient=prediction_table[w->orient][w->raw_orient];\n\n    }\n\n    return 0;\n\n}\n", "idx": 25433}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static void vc1_mc_4mv_chroma4(VC1Context *v, int dir, int dir2, int avg)\n\n{\n\n    MpegEncContext *s = &v->s;\n\n    H264ChromaContext *h264chroma = &v->h264chroma;\n\n    uint8_t *srcU, *srcV;\n\n    int uvsrc_x, uvsrc_y;\n\n    int uvmx_field[4], uvmy_field[4];\n\n    int i, off, tx, ty;\n\n    int fieldmv = v->blk_mv_type[s->block_index[0]];\n\n    static const int s_rndtblfield[16] = { 0, 0, 1, 2, 4, 4, 5, 6, 2, 2, 3, 8, 6, 6, 7, 12 };\n\n    int v_dist = fieldmv ? 1 : 4; // vertical offset for lower sub-blocks\n\n    int v_edge_pos = s->v_edge_pos >> 1;\n\n    int use_ic;\n\n    uint8_t (*lutuv)[256];\n\n\n\n    if (s->flags & CODEC_FLAG_GRAY)\n\n        return;\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        int d = i < 2 ? dir: dir2;\n\n        tx = s->mv[d][i][0];\n\n        uvmx_field[i] = (tx + ((tx & 3) == 3)) >> 1;\n\n        ty = s->mv[d][i][1];\n\n        if (fieldmv)\n\n            uvmy_field[i] = (ty >> 4) * 8 + s_rndtblfield[ty & 0xF];\n\n        else\n\n            uvmy_field[i] = (ty + ((ty & 3) == 3)) >> 1;\n\n    }\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        off = (i & 1) * 4 + ((i & 2) ? v_dist * s->uvlinesize : 0);\n\n        uvsrc_x = s->mb_x * 8 +  (i & 1) * 4           + (uvmx_field[i] >> 2);\n\n        uvsrc_y = s->mb_y * 8 + ((i & 2) ? v_dist : 0) + (uvmy_field[i] >> 2);\n\n        // FIXME: implement proper pull-back (see vc1cropmv.c, vc1CROPMV_ChromaPullBack())\n\n        uvsrc_x = av_clip(uvsrc_x, -8, s->avctx->coded_width  >> 1);\n\n        uvsrc_y = av_clip(uvsrc_y, -8, s->avctx->coded_height >> 1);\n\n        if (i < 2 ? dir : dir2) {\n\n            srcU = s->next_picture.f.data[1] + uvsrc_y * s->uvlinesize + uvsrc_x;\n\n            srcV = s->next_picture.f.data[2] + uvsrc_y * s->uvlinesize + uvsrc_x;\n\n            lutuv  = v->next_lutuv;\n\n            use_ic = v->next_use_ic;\n\n        } else {\n\n            srcU = s->last_picture.f.data[1] + uvsrc_y * s->uvlinesize + uvsrc_x;\n\n            srcV = s->last_picture.f.data[2] + uvsrc_y * s->uvlinesize + uvsrc_x;\n\n            lutuv  = v->last_lutuv;\n\n            use_ic = v->last_use_ic;\n\n        }\n\n        uvmx_field[i] = (uvmx_field[i] & 3) << 1;\n\n        uvmy_field[i] = (uvmy_field[i] & 3) << 1;\n\n\n\n        if (fieldmv && !(uvsrc_y & 1))\n\n            v_edge_pos--;\n\n        if (fieldmv && (uvsrc_y & 1) && uvsrc_y < 2)\n\n            uvsrc_y--;\n\n        if (use_ic\n\n            || s->h_edge_pos < 10 || v_edge_pos < (5 << fieldmv)\n\n            || (unsigned)uvsrc_x > (s->h_edge_pos >> 1) - 5\n\n            || (unsigned)uvsrc_y > v_edge_pos - (5 << fieldmv)) {\n\n            s->vdsp.emulated_edge_mc(s->edge_emu_buffer, srcU,\n\n                                     s->uvlinesize, s->uvlinesize,\n\n                                     5, (5 << fieldmv), uvsrc_x, uvsrc_y,\n\n                                     s->h_edge_pos >> 1, v_edge_pos);\n\n            s->vdsp.emulated_edge_mc(s->edge_emu_buffer + 16, srcV,\n\n                                     s->uvlinesize, s->uvlinesize,\n\n                                     5, (5 << fieldmv), uvsrc_x, uvsrc_y,\n\n                                     s->h_edge_pos >> 1, v_edge_pos);\n\n            srcU = s->edge_emu_buffer;\n\n            srcV = s->edge_emu_buffer + 16;\n\n\n\n            /* if we deal with intensity compensation we need to scale source blocks */\n\n            if (use_ic) {\n\n                int i, j;\n\n                uint8_t *src, *src2;\n\n\n\n                src  = srcU;\n\n                src2 = srcV;\n\n                for (j = 0; j < 5; j++) {\n\n                    int f = (uvsrc_y + (j << fieldmv)) & 1;\n\n                    for (i = 0; i < 5; i++) {\n\n                        src[i]  = lutuv[f][src[i]];\n\n                        src2[i] = lutuv[f][src2[i]];\n\n                    }\n\n                    src  += s->uvlinesize << fieldmv;\n\n                    src2 += s->uvlinesize << fieldmv;\n\n                }\n\n            }\n\n        }\n\n        if (avg) {\n\n            if (!v->rnd) {\n\n                h264chroma->avg_h264_chroma_pixels_tab[1](s->dest[1] + off, srcU, s->uvlinesize << fieldmv, 4, uvmx_field[i], uvmy_field[i]);\n\n                h264chroma->avg_h264_chroma_pixels_tab[1](s->dest[2] + off, srcV, s->uvlinesize << fieldmv, 4, uvmx_field[i], uvmy_field[i]);\n\n            } else {\n\n                v->vc1dsp.avg_no_rnd_vc1_chroma_pixels_tab[1](s->dest[1] + off, srcU, s->uvlinesize << fieldmv, 4, uvmx_field[i], uvmy_field[i]);\n\n                v->vc1dsp.avg_no_rnd_vc1_chroma_pixels_tab[1](s->dest[2] + off, srcV, s->uvlinesize << fieldmv, 4, uvmx_field[i], uvmy_field[i]);\n\n            }\n\n        } else {\n\n            if (!v->rnd) {\n\n                h264chroma->put_h264_chroma_pixels_tab[1](s->dest[1] + off, srcU, s->uvlinesize << fieldmv, 4, uvmx_field[i], uvmy_field[i]);\n\n                h264chroma->put_h264_chroma_pixels_tab[1](s->dest[2] + off, srcV, s->uvlinesize << fieldmv, 4, uvmx_field[i], uvmy_field[i]);\n\n            } else {\n\n                v->vc1dsp.put_no_rnd_vc1_chroma_pixels_tab[1](s->dest[1] + off, srcU, s->uvlinesize << fieldmv, 4, uvmx_field[i], uvmy_field[i]);\n\n                v->vc1dsp.put_no_rnd_vc1_chroma_pixels_tab[1](s->dest[2] + off, srcV, s->uvlinesize << fieldmv, 4, uvmx_field[i], uvmy_field[i]);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 25434}
{"project": "FFmpeg", "commit_id": "445a02b1ec5ea94d28ea2503a3ae0272fcff0e12", "target": 1, "func": "static int rtp_asf_fix_header(uint8_t *buf, int len)\n\n{\n\n    uint8_t *p = buf, *end = buf + len;\n\n\n\n    if (len < sizeof(ff_asf_guid) * 2 + 22 ||\n\n        memcmp(p, ff_asf_header, sizeof(ff_asf_guid))) {\n\n        return -1;\n\n    }\n\n    p += sizeof(ff_asf_guid) + 14;\n\n    do {\n\n        uint64_t chunksize = AV_RL64(p + sizeof(ff_asf_guid));\n\n        if (memcmp(p, ff_asf_file_header, sizeof(ff_asf_guid))) {\n\n            if (chunksize > end - p)\n\n                return -1;\n\n            p += chunksize;\n\n            continue;\n\n        }\n\n\n\n        /* skip most of the file header, to min_pktsize */\n\n        p += 6 * 8 + 3 * 4 + sizeof(ff_asf_guid) * 2;\n\n        if (p + 8 <= end && AV_RL32(p) == AV_RL32(p + 4)) {\n\n            /* and set that to zero */\n\n            AV_WL32(p, 0);\n\n            return 0;\n\n        }\n\n        break;\n\n    } while (end - p >= sizeof(ff_asf_guid) + 8);\n\n\n\n    return -1;\n\n}\n", "idx": 25436}
{"project": "FFmpeg", "commit_id": "2da0d70d5eebe42f9fcd27ee554419ebe2a5da06", "target": 1, "func": "static inline void RENAME(uyvyToY)(uint8_t *dst, uint8_t *src, long width)\n\n{\n\n#ifdef HAVE_MMX\n\n\tasm volatile(\n\n\t\t\"mov %0, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\"movq (%1, %%\"REG_a\",2), %%mm0\t\\n\\t\"\n\n\t\t\"movq 8(%1, %%\"REG_a\",2), %%mm1\t\\n\\t\"\n\n\t\t\"psrlw $8, %%mm0\t\t\\n\\t\"\n\n\t\t\"psrlw $8, %%mm1\t\t\\n\\t\"\n\n\t\t\"packuswb %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\"movq %%mm0, (%2, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\"add $8, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\" js 1b\t\t\t\t\\n\\t\"\n\n\t\t: : \"g\" (-width), \"r\" (src+width*2), \"r\" (dst+width)\n\n\t\t: \"%\"REG_a\n\n\t);\n\n#else\n\n\tint i;\n\n\tfor(i=0; i<width; i++)\n\n\t\tdst[i]= src[2*i+1];\n\n#endif\n\n}\n", "idx": 25439}
{"project": "FFmpeg", "commit_id": "6d9dad6a7cb5d544d540abf941fedbd34c14d2bd", "target": 1, "func": "static int kempf_decode_tile(G2MContext *c, int tile_x, int tile_y,\n\n                             const uint8_t *src, int src_size)\n\n{\n\n    int width, height;\n\n    int hdr, zsize, npal, tidx = -1, ret;\n\n    int i, j;\n\n    const uint8_t *src_end = src + src_size;\n\n    uint8_t pal[768], transp[3];\n\n    uLongf dlen = (c->tile_width + 1) * c->tile_height;\n\n    int sub_type;\n\n    int nblocks, cblocks, bstride;\n\n    int bits, bitbuf, coded;\n\n    uint8_t *dst = c->framebuf + tile_x * c->tile_width * 3 +\n\n                   tile_y * c->tile_height * c->framebuf_stride;\n\n\n\n    if (src_size < 2)\n\n\n\n\n    width  = FFMIN(c->width  - tile_x * c->tile_width,  c->tile_width);\n\n    height = FFMIN(c->height - tile_y * c->tile_height, c->tile_height);\n\n\n\n    hdr = *src++;\n\n    sub_type = hdr >> 5;\n\n    if (sub_type == 0) {\n\n        int j;\n\n        memcpy(transp, src, 3);\n\n        src += 3;\n\n        for (j = 0; j < height; j++, dst += c->framebuf_stride)\n\n            for (i = 0; i < width; i++)\n\n                memcpy(dst + i * 3, transp, 3);\n\n        return 0;\n\n    } else if (sub_type == 1) {\n\n        return jpg_decode_data(&c->jc, width, height, src, src_end - src,\n\n                               dst, c->framebuf_stride, NULL, 0, 0, 0);\n\n    }\n\n\n\n    if (sub_type != 2) {\n\n        memcpy(transp, src, 3);\n\n        src += 3;\n\n    }\n\n    npal = *src++ + 1;\n\n\n\n    memcpy(pal, src, npal * 3); src += npal * 3;\n\n    if (sub_type != 2) {\n\n        for (i = 0; i < npal; i++) {\n\n            if (!memcmp(pal + i * 3, transp, 3)) {\n\n               tidx = i;\n\n               break;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (src_end - src < 2)\n\n        return 0;\n\n    zsize = (src[0] << 8) | src[1]; src += 2;\n\n\n\n    if (src_end - src < zsize + (sub_type != 2))\n\n\n\n\n    ret = uncompress(c->kempf_buf, &dlen, src, zsize);\n\n    if (ret)\n\n\n    src += zsize;\n\n\n\n    if (sub_type == 2) {\n\n        kempf_restore_buf(c->kempf_buf, dlen, dst, c->framebuf_stride,\n\n                          NULL, 0, width, height, pal, npal, tidx);\n\n        return 0;\n\n    }\n\n\n\n    nblocks = *src++ + 1;\n\n    cblocks = 0;\n\n    bstride = FFALIGN(width, 16) >> 4;\n\n    // blocks are coded LSB and we need normal bitreader for JPEG data\n\n    bits = 0;\n\n    for (i = 0; i < (FFALIGN(height, 16) >> 4); i++) {\n\n        for (j = 0; j < (FFALIGN(width, 16) >> 4); j++) {\n\n            if (!bits) {\n\n                if (src >= src_end)\n\n\n                bitbuf = *src++;\n\n                bits   = 8;\n\n            }\n\n            coded = bitbuf & 1;\n\n            bits--;\n\n            bitbuf >>= 1;\n\n            cblocks += coded;\n\n            if (cblocks > nblocks)\n\n\n            c->kempf_flags[j + i * bstride] = coded;\n\n        }\n\n    }\n\n\n\n    memset(c->jpeg_tile, 0, c->tile_stride * height);\n\n    jpg_decode_data(&c->jc, width, height, src, src_end - src,\n\n                    c->jpeg_tile, c->tile_stride,\n\n                    c->kempf_flags, bstride, nblocks, 0);\n\n\n\n    kempf_restore_buf(c->kempf_buf, dlen, dst, c->framebuf_stride,\n\n                      c->jpeg_tile, c->tile_stride,\n\n                      width, height, pal, npal, tidx);\n\n\n\n    return 0;\n\n}", "idx": 25440}
{"project": "FFmpeg", "commit_id": "1c5b712c0a643a039d6f34269b4102de313a050a", "target": 1, "func": "static void interpolate_refplane(DiracContext *s, DiracFrame *ref, int plane, int width, int height)\n\n{\n\n    /* chroma allocates an edge of 8 when subsampled\n\n       which for 4:2:2 means an h edge of 16 and v edge of 8\n\n       just use 8 for everything for the moment */\n\n    int i, edge = EDGE_WIDTH/2;\n\n\n\n    ref->hpel[plane][0] = ref->avframe->data[plane];\n\n    s->mpvencdsp.draw_edges(ref->hpel[plane][0], ref->avframe->linesize[plane], width, height, edge, edge, EDGE_TOP | EDGE_BOTTOM); /* EDGE_TOP | EDGE_BOTTOM values just copied to make it build, this needs to be ensured */\n\n\n\n    /* no need for hpel if we only have fpel vectors */\n\n    if (!s->mv_precision)\n\n        return;\n\n\n\n    for (i = 1; i < 4; i++) {\n\n        if (!ref->hpel_base[plane][i])\n\n            ref->hpel_base[plane][i] = av_malloc((height+2*edge) * ref->avframe->linesize[plane] + 32);\n\n        /* we need to be 16-byte aligned even for chroma */\n\n        ref->hpel[plane][i] = ref->hpel_base[plane][i] + edge*ref->avframe->linesize[plane] + 16;\n\n    }\n\n\n\n    if (!ref->interpolated[plane]) {\n\n        s->diracdsp.dirac_hpel_filter(ref->hpel[plane][1], ref->hpel[plane][2],\n\n                                      ref->hpel[plane][3], ref->hpel[plane][0],\n\n                                      ref->avframe->linesize[plane], width, height);\n\n        s->mpvencdsp.draw_edges(ref->hpel[plane][1], ref->avframe->linesize[plane], width, height, edge, edge, EDGE_TOP | EDGE_BOTTOM);\n\n        s->mpvencdsp.draw_edges(ref->hpel[plane][2], ref->avframe->linesize[plane], width, height, edge, edge, EDGE_TOP | EDGE_BOTTOM);\n\n        s->mpvencdsp.draw_edges(ref->hpel[plane][3], ref->avframe->linesize[plane], width, height, edge, edge, EDGE_TOP | EDGE_BOTTOM);\n\n    }\n\n    ref->interpolated[plane] = 1;\n\n}\n", "idx": 25441}
{"project": "FFmpeg", "commit_id": "bb23bf8fd7fb4771b0f08a4ee1ba8fe6ca16d14f", "target": 1, "func": "int avfilter_process_command(AVFilterContext *filter, const char *cmd, const char *arg, char *res, int res_len, int flags)\n{\n    if(!strcmp(cmd, \"ping\")){\n        av_strlcatf(res, res_len, \"pong from:%s %s\\n\", filter->filter->name, filter->name);\n        return 0;\n    }else if(!strcmp(cmd, \"enable\")) {\n        return set_enable_expr(filter, arg);\n    }else if(filter->filter->process_command) {\n        return filter->filter->process_command(filter, cmd, arg, res, res_len, flags);\n    return AVERROR(ENOSYS);", "idx": 25443}
{"project": "FFmpeg", "commit_id": "64f6570c6e2c5a0344383e89c7897809f0c6e1f1", "target": 0, "func": "static void decode_clnpass(Jpeg2000DecoderContext *s, Jpeg2000T1Context *t1,\n\n                           int width, int height, int bpno, int bandno,\n\n                           int seg_symbols)\n\n{\n\n    int mask = 3 << (bpno - 1), y0, x, y, runlen, dec;\n\n\n\n    for (y0 = 0; y0 < height; y0 += 4)\n\n        for (x = 0; x < width; x++) {\n\n            if (y0 + 3 < height &&\n\n                !((t1->flags[y0 + 1][x + 1] & (JPEG2000_T1_SIG_NB | JPEG2000_T1_VIS | JPEG2000_T1_SIG)) ||\n\n                  (t1->flags[y0 + 2][x + 1] & (JPEG2000_T1_SIG_NB | JPEG2000_T1_VIS | JPEG2000_T1_SIG)) ||\n\n                  (t1->flags[y0 + 3][x + 1] & (JPEG2000_T1_SIG_NB | JPEG2000_T1_VIS | JPEG2000_T1_SIG)) ||\n\n                  (t1->flags[y0 + 4][x + 1] & (JPEG2000_T1_SIG_NB | JPEG2000_T1_VIS | JPEG2000_T1_SIG)))) {\n\n                if (!ff_mqc_decode(&t1->mqc, t1->mqc.cx_states + MQC_CX_RL))\n\n                    continue;\n\n                runlen = ff_mqc_decode(&t1->mqc,\n\n                                       t1->mqc.cx_states + MQC_CX_UNI);\n\n                runlen = (runlen << 1) | ff_mqc_decode(&t1->mqc,\n\n                                                       t1->mqc.cx_states +\n\n                                                       MQC_CX_UNI);\n\n                dec = 1;\n\n            } else {\n\n                runlen = 0;\n\n                dec    = 0;\n\n            }\n\n\n\n            for (y = y0 + runlen; y < y0 + 4 && y < height; y++) {\n\n                if (!dec) {\n\n                    if (!(t1->flags[y + 1][x + 1] & (JPEG2000_T1_SIG | JPEG2000_T1_VIS)))\n\n                        dec = ff_mqc_decode(&t1->mqc,\n\n                                            t1->mqc.cx_states +\n\n                                            ff_jpeg2000_getsigctxno(t1->flags[y + 1][x + 1],\n\n                                                                   bandno));\n\n                }\n\n                if (dec) {\n\n                    int xorbit;\n\n                    int ctxno = ff_jpeg2000_getsgnctxno(t1->flags[y + 1][x + 1],\n\n                                                        &xorbit);\n\n                    t1->data[y][x] = (ff_mqc_decode(&t1->mqc,\n\n                                                    t1->mqc.cx_states + ctxno) ^\n\n                                      xorbit)\n\n                                     ? -mask : mask;\n\n                    ff_jpeg2000_set_significance(t1, x, y, t1->data[y][x] < 0);\n\n                }\n\n                dec = 0;\n\n                t1->flags[y + 1][x + 1] &= ~JPEG2000_T1_VIS;\n\n            }\n\n        }\n\n    if (seg_symbols) {\n\n        int val;\n\n        val = ff_mqc_decode(&t1->mqc, t1->mqc.cx_states + MQC_CX_UNI);\n\n        val = (val << 1) + ff_mqc_decode(&t1->mqc, t1->mqc.cx_states + MQC_CX_UNI);\n\n        val = (val << 1) + ff_mqc_decode(&t1->mqc, t1->mqc.cx_states + MQC_CX_UNI);\n\n        val = (val << 1) + ff_mqc_decode(&t1->mqc, t1->mqc.cx_states + MQC_CX_UNI);\n\n        if (val != 0xa)\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Segmentation symbol value incorrect\\n\");\n\n    }\n\n}\n", "idx": 25444}
{"project": "FFmpeg", "commit_id": "6796a1dd8c14843b77925cb83a3ef88706ae1dd0", "target": 0, "func": "void ff_put_h264_qpel8_mc03_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_vt_qrt_8w_msa(src - (stride * 2), stride, dst, stride, 8, 1);\n\n}\n", "idx": 25445}
{"project": "FFmpeg", "commit_id": "e56d1a120324fa49a5367cbf22098c5c7eb23f91", "target": 0, "func": "static av_cold int audio_write_header(AVFormatContext *s1)\n\n{\n\n    AlsaData *s = s1->priv_data;\n\n    AVStream *st;\n\n    unsigned int sample_rate;\n\n    enum AVCodecID codec_id;\n\n    int res;\n\n\n\n    st = s1->streams[0];\n\n    sample_rate = st->codec->sample_rate;\n\n    codec_id    = st->codec->codec_id;\n\n    res = ff_alsa_open(s1, SND_PCM_STREAM_PLAYBACK, &sample_rate,\n\n        st->codec->channels, &codec_id);\n\n    if (sample_rate != st->codec->sample_rate) {\n\n        av_log(s1, AV_LOG_ERROR,\n\n               \"sample rate %d not available, nearest is %d\\n\",\n\n               st->codec->sample_rate, sample_rate);\n\n        goto fail;\n\n    }\n\n    avpriv_set_pts_info(st, 64, 1, sample_rate);\n\n\n\n    return res;\n\n\n\nfail:\n\n    snd_pcm_close(s->h);\n\n    return AVERROR(EIO);\n\n}\n", "idx": 25446}
{"project": "FFmpeg", "commit_id": "2773ab36cc6480ce77845df0b1d1e2f790c59cde", "target": 0, "func": "int ff_jpegls_decode_lse(MJpegDecodeContext *s)\n\n{\n\n    int id;\n\n    int tid, wt, maxtab, i, j;\n\n\n\n    int len = get_bits(&s->gb, 16);  /* length: FIXME: verify field validity */\n\n    id = get_bits(&s->gb, 8);\n\n\n\n    switch (id) {\n\n    case 1:\n\n        s->maxval = get_bits(&s->gb, 16);\n\n        s->t1     = get_bits(&s->gb, 16);\n\n        s->t2     = get_bits(&s->gb, 16);\n\n        s->t3     = get_bits(&s->gb, 16);\n\n        s->reset  = get_bits(&s->gb, 16);\n\n\n\n//        ff_jpegls_reset_coding_parameters(s, 0);\n\n        //FIXME quant table?\n\n        break;\n\n    case 2:\n\n        s->palette_index = 0;\n\n    case 3:\n\n        tid= get_bits(&s->gb, 8);\n\n        wt = get_bits(&s->gb, 8);\n\n\n\n        if (len < 5)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        if (wt < 1 || wt > MAX_COMPONENTS) {\n\n            avpriv_request_sample(s->avctx, \"wt %d\", wt);\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n\n\n        if (!s->maxval)\n\n            maxtab = 255;\n\n        else if ((5 + wt*(s->maxval+1)) < 65535)\n\n            maxtab = s->maxval;\n\n        else\n\n            maxtab = 65530/wt - 1;\n\n\n\n        if(s->avctx->debug & FF_DEBUG_PICT_INFO) {\n\n            av_log(s->avctx, AV_LOG_DEBUG, \"LSE palette %d tid:%d wt:%d maxtab:%d\\n\", id, tid, wt, maxtab);\n\n        }\n\n        if (maxtab >= 256) {\n\n            avpriv_request_sample(s->avctx, \">8bit palette\");\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n        maxtab = FFMIN(maxtab, (len - 5) / wt + s->palette_index);\n\n\n\n        if (s->palette_index > maxtab)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        if ((s->avctx->pix_fmt == AV_PIX_FMT_GRAY8 || s->avctx->pix_fmt == AV_PIX_FMT_PAL8) &&\n\n            (s->picture_ptr->format == AV_PIX_FMT_GRAY8 || s->picture_ptr->format == AV_PIX_FMT_PAL8)) {\n\n            uint32_t *pal = s->picture_ptr->data[1];\n\n            s->picture_ptr->format =\n\n            s->avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n            for (i=s->palette_index; i<=maxtab; i++) {\n\n                pal[i] = 0;\n\n                for (j=0; j<wt; j++) {\n\n                    pal[i] |= get_bits(&s->gb, 8) << (8*(wt-j-1));\n\n                }\n\n            }\n\n            s->palette_index = i;\n\n        }\n\n        break;\n\n    case 4:\n\n        avpriv_request_sample(s->avctx, \"oversize image\");\n\n        return AVERROR(ENOSYS);\n\n    default:\n\n        av_log(s->avctx, AV_LOG_ERROR, \"invalid id %d\\n\", id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    av_dlog(s->avctx, \"ID=%i, T=%i,%i,%i\\n\", id, s->t1, s->t2, s->t3);\n\n\n\n    return 0;\n\n}\n", "idx": 25447}
{"project": "FFmpeg", "commit_id": "80ca19f766aea8f4724aac1b3faa772d25163c8a", "target": 0, "func": "static int ipvideo_decode_block_opcode_0x8(IpvideoContext *s)\n\n{\n\n    int x, y;\n\n    unsigned char P[2];\n\n    unsigned int flags = 0;\n\n\n\n    /* 2-color encoding for each 4x4 quadrant, or 2-color encoding on\n\n     * either top and bottom or left and right halves */\n\n    CHECK_STREAM_PTR(2);\n\n\n\n    P[0] = *s->stream_ptr++;\n\n    P[1] = *s->stream_ptr++;\n\n\n\n    if (P[0] <= P[1]) {\n\n\n\n        CHECK_STREAM_PTR(14);\n\n        s->stream_ptr -= 2;\n\n\n\n        for (y = 0; y < 16; y++) {\n\n            // new values for each 4x4 block\n\n            if (!(y & 3)) {\n\n                P[0] = *s->stream_ptr++; P[1] = *s->stream_ptr++;\n\n                flags = bytestream_get_le16(&s->stream_ptr);\n\n            }\n\n\n\n            for (x = 0; x < 4; x++, flags >>= 1)\n\n                *s->pixel_ptr++ = P[flags & 1];\n\n            s->pixel_ptr += s->stride - 4;\n\n            // switch to right half\n\n            if (y == 7) s->pixel_ptr -= 8 * s->stride - 4;\n\n        }\n\n\n\n    } else {\n\n\n\n        /* need 10 more bytes */\n\n        CHECK_STREAM_PTR(10);\n\n\n\n        if (s->stream_ptr[4] <= s->stream_ptr[5]) {\n\n\n\n            flags = bytestream_get_le32(&s->stream_ptr);\n\n\n\n            /* vertical split; left & right halves are 2-color encoded */\n\n\n\n            for (y = 0; y < 16; y++) {\n\n                for (x = 0; x < 4; x++, flags >>= 1)\n\n                    *s->pixel_ptr++ = P[flags & 1];\n\n                s->pixel_ptr += s->stride - 4;\n\n                // switch to right half\n\n                if (y == 7) {\n\n                    s->pixel_ptr -= 8 * s->stride - 4;\n\n                    P[0] = *s->stream_ptr++; P[1] = *s->stream_ptr++;\n\n                    flags = bytestream_get_le32(&s->stream_ptr);\n\n                }\n\n            }\n\n\n\n        } else {\n\n\n\n            /* horizontal split; top & bottom halves are 2-color encoded */\n\n\n\n            for (y = 0; y < 8; y++) {\n\n                if (y == 4) {\n\n                    P[0] = *s->stream_ptr++;\n\n                    P[1] = *s->stream_ptr++;\n\n                }\n\n                flags = *s->stream_ptr++ | 0x100;\n\n\n\n                for (; flags != 1; flags >>= 1)\n\n                    *s->pixel_ptr++ = P[flags & 1];\n\n                s->pixel_ptr += s->line_inc;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* report success */\n\n    return 0;\n\n}\n", "idx": 25448}
{"project": "FFmpeg", "commit_id": "019247bdc326a90bf20d3ce5d2413cc642e8bb08", "target": 0, "func": "static int mov_read_stss(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st;\n\n    MOVStreamContext *sc;\n\n    unsigned int i, entries;\n\n\n\n    if (c->fc->nb_streams < 1)\n\n        return 0;\n\n    st = c->fc->streams[c->fc->nb_streams-1];\n\n    sc = st->priv_data;\n\n\n\n    avio_r8(pb); /* version */\n\n    avio_rb24(pb); /* flags */\n\n\n\n    entries = avio_rb32(pb);\n\n\n\n    av_dlog(c->fc, \"keyframe_count = %d\\n\", entries);\n\n\n\n    if (!entries)\n\n    {\n\n        sc->keyframe_absent = 1;\n\n        if (!st->need_parsing)\n\n            st->need_parsing = AVSTREAM_PARSE_HEADERS;\n\n        return 0;\n\n    }\n\n    if (entries >= UINT_MAX / sizeof(int))\n\n        return AVERROR_INVALIDDATA;\n\n    sc->keyframes = av_malloc(entries * sizeof(int));\n\n    if (!sc->keyframes)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for (i = 0; i < entries && !pb->eof_reached; i++) {\n\n        sc->keyframes[i] = avio_rb32(pb);\n\n        //av_dlog(c->fc, \"keyframes[]=%d\\n\", sc->keyframes[i]);\n\n    }\n\n\n\n    sc->keyframe_count = i;\n\n\n\n    if (pb->eof_reached)\n\n        return AVERROR_EOF;\n\n\n\n    return 0;\n\n}\n", "idx": 25449}
{"project": "FFmpeg", "commit_id": "741aca793623afeff1d18816f416cc65104b7ef9", "target": 0, "func": "void swr_compensate(struct SwrContext *s, int sample_delta, int compensation_distance){\n\n    ResampleContext *c= s->resample;\n\n//    sample_delta += (c->ideal_dst_incr - c->dst_incr)*(int64_t)c->compensation_distance / c->ideal_dst_incr;\n\n    c->compensation_distance= compensation_distance;\n\n    c->dst_incr = c->ideal_dst_incr - c->ideal_dst_incr * (int64_t)sample_delta / compensation_distance;\n\n}\n", "idx": 25450}
{"project": "FFmpeg", "commit_id": "d52b4abe8b7d58b1680b5ae5fccfcbd50ad98ef0", "target": 0, "func": "int MPV_frame_start(MpegEncContext *s, AVCodecContext *avctx)\n\n{\n\n    int i;\n\n    Picture *pic;\n\n    s->mb_skipped = 0;\n\n\n\n    assert(s->last_picture_ptr==NULL || s->out_format != FMT_H264 || s->codec_id == CODEC_ID_SVQ3);\n\n\n\n    /* mark&release old frames */\n\n    if (s->pict_type != FF_B_TYPE && s->last_picture_ptr && s->last_picture_ptr != s->next_picture_ptr && s->last_picture_ptr->data[0]) {\n\n      if(s->out_format != FMT_H264 || s->codec_id == CODEC_ID_SVQ3){\n\n          free_frame_buffer(s, s->last_picture_ptr);\n\n\n\n        /* release forgotten pictures */\n\n        /* if(mpeg124/h263) */\n\n        if(!s->encoding){\n\n            for(i=0; i<MAX_PICTURE_COUNT; i++){\n\n                if(s->picture[i].data[0] && &s->picture[i] != s->next_picture_ptr && s->picture[i].reference){\n\n                    av_log(avctx, AV_LOG_ERROR, \"releasing zombie picture\\n\");\n\n                    free_frame_buffer(s, &s->picture[i]);\n\n                }\n\n            }\n\n        }\n\n      }\n\n    }\n\nalloc:\n\n    if(!s->encoding){\n\n        /* release non reference frames */\n\n        for(i=0; i<MAX_PICTURE_COUNT; i++){\n\n            if(s->picture[i].data[0] && !s->picture[i].reference /*&& s->picture[i].type!=FF_BUFFER_TYPE_SHARED*/){\n\n                free_frame_buffer(s, &s->picture[i]);\n\n            }\n\n        }\n\n\n\n        if(s->current_picture_ptr && s->current_picture_ptr->data[0]==NULL)\n\n            pic= s->current_picture_ptr; //we already have a unused image (maybe it was set before reading the header)\n\n        else{\n\n            i= ff_find_unused_picture(s, 0);\n\n            pic= &s->picture[i];\n\n        }\n\n\n\n        pic->reference= 0;\n\n        if (!s->dropable){\n\n            if (s->codec_id == CODEC_ID_H264)\n\n                pic->reference = s->picture_structure;\n\n            else if (s->pict_type != FF_B_TYPE)\n\n                pic->reference = 3;\n\n        }\n\n\n\n        pic->coded_picture_number= s->coded_picture_number++;\n\n\n\n        if(ff_alloc_picture(s, pic, 0) < 0)\n\n            return -1;\n\n\n\n        s->current_picture_ptr= pic;\n\n        s->current_picture_ptr->top_field_first= s->top_field_first; //FIXME use only the vars from current_pic\n\n        s->current_picture_ptr->interlaced_frame= !s->progressive_frame && !s->progressive_sequence;\n\n    }\n\n\n\n    s->current_picture_ptr->pict_type= s->pict_type;\n\n//    if(s->flags && CODEC_FLAG_QSCALE)\n\n  //      s->current_picture_ptr->quality= s->new_picture_ptr->quality;\n\n    s->current_picture_ptr->key_frame= s->pict_type == FF_I_TYPE;\n\n\n\n    ff_copy_picture(&s->current_picture, s->current_picture_ptr);\n\n\n\n    if (s->pict_type != FF_B_TYPE) {\n\n        s->last_picture_ptr= s->next_picture_ptr;\n\n        if(!s->dropable)\n\n            s->next_picture_ptr= s->current_picture_ptr;\n\n    }\n\n/*    av_log(s->avctx, AV_LOG_DEBUG, \"L%p N%p C%p L%p N%p C%p type:%d drop:%d\\n\", s->last_picture_ptr, s->next_picture_ptr,s->current_picture_ptr,\n\n        s->last_picture_ptr    ? s->last_picture_ptr->data[0] : NULL,\n\n        s->next_picture_ptr    ? s->next_picture_ptr->data[0] : NULL,\n\n        s->current_picture_ptr ? s->current_picture_ptr->data[0] : NULL,\n\n        s->pict_type, s->dropable);*/\n\n\n\n    if(s->last_picture_ptr) ff_copy_picture(&s->last_picture, s->last_picture_ptr);\n\n    if(s->next_picture_ptr) ff_copy_picture(&s->next_picture, s->next_picture_ptr);\n\n\n\n    if(s->pict_type != FF_I_TYPE && (s->last_picture_ptr==NULL || s->last_picture_ptr->data[0]==NULL) && !s->dropable && s->codec_id != CODEC_ID_H264){\n\n        av_log(avctx, AV_LOG_ERROR, \"warning: first frame is no keyframe\\n\");\n\n        assert(s->pict_type != FF_B_TYPE); //these should have been dropped if we don't have a reference\n\n        goto alloc;\n\n    }\n\n\n\n    assert(s->pict_type == FF_I_TYPE || (s->last_picture_ptr && s->last_picture_ptr->data[0]));\n\n\n\n    if(s->picture_structure!=PICT_FRAME && s->out_format != FMT_H264){\n\n        int i;\n\n        for(i=0; i<4; i++){\n\n            if(s->picture_structure == PICT_BOTTOM_FIELD){\n\n                 s->current_picture.data[i] += s->current_picture.linesize[i];\n\n            }\n\n            s->current_picture.linesize[i] *= 2;\n\n            s->last_picture.linesize[i] *=2;\n\n            s->next_picture.linesize[i] *=2;\n\n        }\n\n    }\n\n\n\n    s->hurry_up= s->avctx->hurry_up;\n\n    s->error_recognition= avctx->error_recognition;\n\n\n\n    /* set dequantizer, we can't do it during init as it might change for mpeg4\n\n       and we can't do it in the header decode as init is not called for mpeg4 there yet */\n\n    if(s->mpeg_quant || s->codec_id == CODEC_ID_MPEG2VIDEO){\n\n        s->dct_unquantize_intra = s->dct_unquantize_mpeg2_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_mpeg2_inter;\n\n    }else if(s->out_format == FMT_H263 || s->out_format == FMT_H261){\n\n        s->dct_unquantize_intra = s->dct_unquantize_h263_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_h263_inter;\n\n    }else{\n\n        s->dct_unquantize_intra = s->dct_unquantize_mpeg1_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_mpeg1_inter;\n\n    }\n\n\n\n    if(s->dct_error_sum){\n\n        assert(s->avctx->noise_reduction && s->encoding);\n\n\n\n        update_noise_reduction(s);\n\n    }\n\n\n\n    if(CONFIG_MPEG_XVMC_DECODER && s->avctx->xvmc_acceleration)\n\n        return ff_xvmc_field_start(s, avctx);\n\n\n\n    return 0;\n\n}\n", "idx": 25451}
{"project": "FFmpeg", "commit_id": "7c1805869d6f8dd9292977393aa4d97417716852", "target": 1, "func": "static int pcm_dvd_decode_frame(AVCodecContext *avctx, void *data,\n\n                                int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    AVFrame *frame     = data;\n\n    const uint8_t *src = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    PCMDVDContext *s   = avctx->priv_data;\n\n    int retval;\n\n    int blocks;\n\n    void *dst;\n\n\n\n    if (buf_size < 3) {\n\n        av_log(avctx, AV_LOG_ERROR, \"PCM packet too small\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n\n\n\n    if ((retval = pcm_dvd_parse_header(avctx, src)))\n\n        return retval;\n\n\n\n\n\n\n    src      += 3;\n\n    buf_size -= 3;\n\n\n\n    blocks = (buf_size + s->extra_sample_count) / s->block_size;\n\n\n\n    /* get output buffer */\n\n    frame->nb_samples = blocks * s->samples_per_block;\n\n    if ((retval = ff_get_buffer(avctx, frame, 0)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return retval;\n\n\n    dst = frame->data[0];\n\n\n\n    /* consume leftover samples from last packet */\n\n    if (s->extra_sample_count) {\n\n        int missing_samples = s->block_size - s->extra_sample_count;\n\n        if (buf_size >= missing_samples) {\n\n            memcpy(s->extra_samples + s->extra_sample_count, src,\n\n                   missing_samples);\n\n            dst = pcm_dvd_decode_samples(avctx, s->extra_samples, dst, 1);\n\n            src += missing_samples;\n\n            buf_size -= missing_samples;\n\n\n            blocks--;\n\n        } else {\n\n            /* new packet still doesn't have enough samples */\n\n            memcpy(s->extra_samples + s->extra_sample_count, src, buf_size);\n\n            s->extra_sample_count += buf_size;\n\n            return avpkt->size;\n\n\n\n\n\n    /* decode remaining complete samples */\n\n    if (blocks) {\n\n        pcm_dvd_decode_samples(avctx, src, dst, blocks);\n\n        buf_size -= blocks * s->block_size;\n\n\n\n\n    /* store leftover samples */\n\n    if (buf_size) {\n\n        src += blocks * s->block_size;\n\n        memcpy(s->extra_samples, src, buf_size);\n\n        s->extra_sample_count = buf_size;\n\n\n\n\n    *got_frame_ptr = 1;\n\n\n\n    return avpkt->size;\n", "idx": 25455}
{"project": "FFmpeg", "commit_id": "6d3f17838db93647f026338cb63103ce57f5d0e2", "target": 1, "func": "static inline void ls_decode_line(JLSState *state, MJpegDecodeContext *s,\n\n                                  void *last, void *dst, int last2, int w,\n\n                                  int stride, int comp, int bits)\n\n{\n\n    int i, x = 0;\n\n    int Ra, Rb, Rc, Rd;\n\n    int D0, D1, D2;\n\n\n\n    while (x < w) {\n\n        int err, pred;\n\n\n\n        /* compute gradients */\n\n        Ra = x ? R(dst, x - stride) : R(last, x);\n\n        Rb = R(last, x);\n\n        Rc = x ? R(last, x - stride) : last2;\n\n        Rd = (x >= w - stride) ? R(last, x) : R(last, x + stride);\n\n        D0 = Rd - Rb;\n\n        D1 = Rb - Rc;\n\n        D2 = Rc - Ra;\n\n        /* run mode */\n\n        if ((FFABS(D0) <= state->near) &&\n\n            (FFABS(D1) <= state->near) &&\n\n            (FFABS(D2) <= state->near)) {\n\n            int r;\n\n            int RItype;\n\n\n\n            /* decode full runs while available */\n\n            while (get_bits1(&s->gb)) {\n\n                int r;\n\n                r = 1 << ff_log2_run[state->run_index[comp]];\n\n                if (x + r * stride > w)\n\n                    r = (w - x) / stride;\n\n                for (i = 0; i < r; i++) {\n\n                    W(dst, x, Ra);\n\n                    x += stride;\n\n                }\n\n                /* if EOL reached, we stop decoding */\n\n                if (r != 1 << ff_log2_run[state->run_index[comp]])\n\n                    return;\n\n                if (state->run_index[comp] < 31)\n\n                    state->run_index[comp]++;\n\n                if (x + stride > w)\n\n                    return;\n\n            }\n\n            /* decode aborted run */\n\n            r = ff_log2_run[state->run_index[comp]];\n\n            if (r)\n\n                r = get_bits_long(&s->gb, r);\n\n            if (x + r * stride > w) {\n\n                r = (w - x) / stride;\n\n            }\n\n            for (i = 0; i < r; i++) {\n\n                W(dst, x, Ra);\n\n                x += stride;\n\n            }\n\n\n\n            if (x >= w) {\n\n                av_log(NULL, AV_LOG_ERROR, \"run overflow\\n\");\n\n\n                return;\n\n            }\n\n\n\n            /* decode run termination value */\n\n            Rb     = R(last, x);\n\n            RItype = (FFABS(Ra - Rb) <= state->near) ? 1 : 0;\n\n            err    = ls_get_code_runterm(&s->gb, state, RItype,\n\n                                         ff_log2_run[state->run_index[comp]]);\n\n            if (state->run_index[comp])\n\n                state->run_index[comp]--;\n\n\n\n            if (state->near && RItype) {\n\n                pred = Ra + err;\n\n            } else {\n\n                if (Rb < Ra)\n\n                    pred = Rb - err;\n\n                else\n\n                    pred = Rb + err;\n\n            }\n\n        } else { /* regular mode */\n\n            int context, sign;\n\n\n\n            context = ff_jpegls_quantize(state, D0) * 81 +\n\n                      ff_jpegls_quantize(state, D1) *  9 +\n\n                      ff_jpegls_quantize(state, D2);\n\n            pred    = mid_pred(Ra, Ra + Rb - Rc, Rb);\n\n\n\n            if (context < 0) {\n\n                context = -context;\n\n                sign    = 1;\n\n            } else {\n\n                sign = 0;\n\n            }\n\n\n\n            if (sign) {\n\n                pred = av_clip(pred - state->C[context], 0, state->maxval);\n\n                err  = -ls_get_code_regular(&s->gb, state, context);\n\n            } else {\n\n                pred = av_clip(pred + state->C[context], 0, state->maxval);\n\n                err  = ls_get_code_regular(&s->gb, state, context);\n\n            }\n\n\n\n            /* we have to do something more for near-lossless coding */\n\n            pred += err;\n\n        }\n\n        if (state->near) {\n\n            if (pred < -state->near)\n\n                pred += state->range * state->twonear;\n\n            else if (pred > state->maxval + state->near)\n\n                pred -= state->range * state->twonear;\n\n            pred = av_clip(pred, 0, state->maxval);\n\n        }\n\n\n\n        pred &= state->maxval;\n\n        W(dst, x, pred);\n\n        x += stride;\n\n    }\n\n}", "idx": 25457}
{"project": "FFmpeg", "commit_id": "dece4f46931cc7870f7ee7022522225b5f49e709", "target": 0, "func": "static void do_video_out(AVFormatContext *s,\n\n                         OutputStream *ost,\n\n                         AVFrame *in_picture,\n\n                         float quality)\n\n{\n\n    int ret, format_video_sync;\n\n    AVPacket pkt;\n\n    AVCodecContext *enc = ost->st->codec;\n\n    int nb_frames;\n\n    double sync_ipts, delta;\n\n    double duration = 0;\n\n    int frame_size = 0;\n\n    InputStream *ist = NULL;\n\n\n\n    if (ost->source_index >= 0)\n\n        ist = input_streams[ost->source_index];\n\n\n\n    if(ist && ist->st->start_time != AV_NOPTS_VALUE && ist->st->first_dts != AV_NOPTS_VALUE && ost->frame_rate.num)\n\n        duration = 1/(av_q2d(ost->frame_rate) * av_q2d(enc->time_base));\n\n\n\n    sync_ipts = in_picture->pts;\n\n    delta = sync_ipts - ost->sync_opts + duration;\n\n\n\n    /* by default, we output a single frame */\n\n    nb_frames = 1;\n\n\n\n    format_video_sync = video_sync_method;\n\n    if (format_video_sync == VSYNC_AUTO)\n\n        format_video_sync = (s->oformat->flags & AVFMT_VARIABLE_FPS) ? ((s->oformat->flags & AVFMT_NOTIMESTAMPS) ? VSYNC_PASSTHROUGH : VSYNC_VFR) : 1;\n\n\n\n    switch (format_video_sync) {\n\n    case VSYNC_CFR:\n\n        // FIXME set to 0.5 after we fix some dts/pts bugs like in avidec.c\n\n        if (delta < -1.1)\n\n            nb_frames = 0;\n\n        else if (delta > 1.1)\n\n            nb_frames = lrintf(delta);\n\n        break;\n\n    case VSYNC_VFR:\n\n        if (delta <= -0.6)\n\n            nb_frames = 0;\n\n        else if (delta > 0.6)\n\n            ost->sync_opts = lrint(sync_ipts);\n\n        break;\n\n    case VSYNC_DROP:\n\n    case VSYNC_PASSTHROUGH:\n\n        ost->sync_opts = lrint(sync_ipts);\n\n        break;\n\n    default:\n\n        av_assert0(0);\n\n    }\n\n\n\n    nb_frames = FFMIN(nb_frames, ost->max_frames - ost->frame_number);\n\n    if (nb_frames == 0) {\n\n        nb_frames_drop++;\n\n        av_log(NULL, AV_LOG_VERBOSE, \"*** drop!\\n\");\n\n        return;\n\n    } else if (nb_frames > 1) {\n\n        if (nb_frames > dts_error_threshold * 30) {\n\n            av_log(NULL, AV_LOG_ERROR, \"%d frame duplication too large, skiping\\n\", nb_frames - 1);\n\n            nb_frames_drop++;\n\n            return;\n\n        }\n\n        nb_frames_dup += nb_frames - 1;\n\n        av_log(NULL, AV_LOG_VERBOSE, \"*** %d dup!\\n\", nb_frames - 1);\n\n    }\n\n\n\n\n\nduplicate_frame:\n\n    av_init_packet(&pkt);\n\n    pkt.data = NULL;\n\n    pkt.size = 0;\n\n\n\n    in_picture->pts = ost->sync_opts;\n\n\n\n    if (!check_recording_time(ost))\n\n        return;\n\n\n\n    if (s->oformat->flags & AVFMT_RAWPICTURE &&\n\n        enc->codec->id == CODEC_ID_RAWVIDEO) {\n\n        /* raw pictures are written as AVPicture structure to\n\n           avoid any copies. We support temporarily the older\n\n           method. */\n\n        enc->coded_frame->interlaced_frame = in_picture->interlaced_frame;\n\n        enc->coded_frame->top_field_first  = in_picture->top_field_first;\n\n        pkt.data   = (uint8_t *)in_picture;\n\n        pkt.size   =  sizeof(AVPicture);\n\n        pkt.pts    = av_rescale_q(in_picture->pts, enc->time_base, ost->st->time_base);\n\n        pkt.flags |= AV_PKT_FLAG_KEY;\n\n\n\n        write_frame(s, &pkt, ost);\n\n        video_size += pkt.size;\n\n    } else {\n\n        int got_packet;\n\n        AVFrame big_picture;\n\n\n\n        big_picture = *in_picture;\n\n        /* better than nothing: use input picture interlaced\n\n           settings */\n\n        big_picture.interlaced_frame = in_picture->interlaced_frame;\n\n        if (ost->st->codec->flags & (CODEC_FLAG_INTERLACED_DCT|CODEC_FLAG_INTERLACED_ME)) {\n\n            if (ost->top_field_first == -1)\n\n                big_picture.top_field_first = in_picture->top_field_first;\n\n            else\n\n                big_picture.top_field_first = !!ost->top_field_first;\n\n        }\n\n\n\n        /* handles same_quant here. This is not correct because it may\n\n           not be a global option */\n\n        big_picture.quality = quality;\n\n        if (!enc->me_threshold)\n\n            big_picture.pict_type = 0;\n\n        if (ost->forced_kf_index < ost->forced_kf_count &&\n\n            big_picture.pts >= ost->forced_kf_pts[ost->forced_kf_index]) {\n\n            big_picture.pict_type = AV_PICTURE_TYPE_I;\n\n            ost->forced_kf_index++;\n\n        }\n\n        update_benchmark(NULL);\n\n        ret = avcodec_encode_video2(enc, &pkt, &big_picture, &got_packet);\n\n        update_benchmark(\"encode_video %d.%d\", ost->file_index, ost->index);\n\n        if (ret < 0) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Video encoding failed\\n\");\n\n            exit_program(1);\n\n        }\n\n\n\n        if (got_packet) {\n\n            if (pkt.pts == AV_NOPTS_VALUE && !(enc->codec->capabilities & CODEC_CAP_DELAY))\n\n                pkt.pts = ost->sync_opts;\n\n\n\n            if (pkt.pts != AV_NOPTS_VALUE)\n\n                pkt.pts = av_rescale_q(pkt.pts, enc->time_base, ost->st->time_base);\n\n            if (pkt.dts != AV_NOPTS_VALUE)\n\n                pkt.dts = av_rescale_q(pkt.dts, enc->time_base, ost->st->time_base);\n\n\n\n            if (debug_ts) {\n\n                av_log(NULL, AV_LOG_INFO, \"encoder -> type:video \"\n\n                    \"pkt_pts:%s pkt_pts_time:%s pkt_dts:%s pkt_dts_time:%s\\n\",\n\n                    av_ts2str(pkt.pts), av_ts2timestr(pkt.pts, &ost->st->time_base),\n\n                    av_ts2str(pkt.dts), av_ts2timestr(pkt.dts, &ost->st->time_base));\n\n            }\n\n\n\n            write_frame(s, &pkt, ost);\n\n            frame_size = pkt.size;\n\n            video_size += pkt.size;\n\n            av_free_packet(&pkt);\n\n\n\n            /* if two pass, output log */\n\n            if (ost->logfile && enc->stats_out) {\n\n                fprintf(ost->logfile, \"%s\", enc->stats_out);\n\n            }\n\n        }\n\n    }\n\n    ost->sync_opts++;\n\n    /*\n\n     * For video, number of frames in == number of packets out.\n\n     * But there may be reordering, so we can't throw away frames on encoder\n\n     * flush, we need to limit them here, before they go into encoder.\n\n     */\n\n    ost->frame_number++;\n\n\n\n    if(--nb_frames)\n\n        goto duplicate_frame;\n\n\n\n    if (vstats_filename && frame_size)\n\n        do_video_stats(output_files[ost->file_index]->ctx, ost, frame_size);\n\n}\n", "idx": 25458}
{"project": "FFmpeg", "commit_id": "1a3598aae768465a8efc8475b6df5a8261bc62fc", "target": 1, "func": "static int jpeg2000_decode_packets(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile)\n\n{\n\n    int layno, reslevelno, compno, precno, ok_reslevel, ret;\n\n    uint8_t prog_order = tile->codsty[0].prog_order;\n\n    uint16_t x;\n\n    uint16_t y;\n\n\n\n    s->bit_index = 8;\n\n    switch (prog_order) {\n\n    case JPEG2000_PGOD_LRCP:\n\n        for (layno = 0; layno < tile->codsty[0].nlayers; layno++) {\n\n            ok_reslevel = 1;\n\n            for (reslevelno = 0; ok_reslevel; reslevelno++) {\n\n                ok_reslevel = 0;\n\n                for (compno = 0; compno < s->ncomponents; compno++) {\n\n                    Jpeg2000CodingStyle *codsty = tile->codsty + compno;\n\n                    Jpeg2000QuantStyle *qntsty  = tile->qntsty + compno;\n\n                    if (reslevelno < codsty->nreslevels) {\n\n                        Jpeg2000ResLevel *rlevel = tile->comp[compno].reslevel +\n\n                                                   reslevelno;\n\n                        ok_reslevel = 1;\n\n                        for (precno = 0; precno < rlevel->num_precincts_x * rlevel->num_precincts_y; precno++)\n\n                            if ((ret = jpeg2000_decode_packet(s,\n\n                                                              codsty, rlevel,\n\n                                                              precno, layno,\n\n                                                              qntsty->expn + (reslevelno ? 3 * (reslevelno - 1) + 1 : 0),\n\n                                                              qntsty->nguardbits)) < 0)\n\n                                return ret;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        break;\n\n\n\n    case JPEG2000_PGOD_CPRL:\n\n        for (compno = 0; compno < s->ncomponents; compno++) {\n\n            Jpeg2000CodingStyle *codsty = tile->codsty + compno;\n\n            Jpeg2000QuantStyle *qntsty  = tile->qntsty + compno;\n\n\n\n            /* Set bit stream buffer address according to tile-part.\n\n             * For DCinema one tile-part per component, so can be\n\n             * indexed by component. */\n\n            s->buf = tile->tile_part[compno].tp_start_bstrm;\n\n\n\n            /* Position loop (y axis)\n\n             * TODO: Automate computing of step 256.\n\n             * Fixed here, but to be computed before entering here. */\n\n            for (y = 0; y < s->height; y += 256) {\n\n                /* Position loop (y axis)\n\n                 * TODO: automate computing of step 256.\n\n                 * Fixed here, but to be computed before entering here. */\n\n                for (x = 0; x < s->width; x += 256) {\n\n                    for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) {\n\n                        uint16_t prcx, prcy;\n\n                        uint8_t reducedresno = codsty->nreslevels - 1 -reslevelno; //  ==> N_L - r\n\n                        Jpeg2000ResLevel *rlevel = tile->comp[compno].reslevel + reslevelno;\n\n\n\n                        if (!((y % (1 << (rlevel->log2_prec_height + reducedresno)) == 0) ||\n\n                              (y == 0))) // TODO: 2nd condition simplified as try0 always =0 for dcinema\n\n                            continue;\n\n\n\n                        if (!((x % (1 << (rlevel->log2_prec_width + reducedresno)) == 0) ||\n\n                              (x == 0))) // TODO: 2nd condition simplified as try0 always =0 for dcinema\n\n                            continue;\n\n\n\n                        // check if a precinct exists\n\n                        prcx   = ff_jpeg2000_ceildivpow2(x, reducedresno) >> rlevel->log2_prec_width;\n\n                        prcy   = ff_jpeg2000_ceildivpow2(y, reducedresno) >> rlevel->log2_prec_height;\n\n                        precno = prcx + rlevel->num_precincts_x * prcy;\n\n                        for (layno = 0; layno < tile->codsty[0].nlayers; layno++) {\n\n                            if ((ret = jpeg2000_decode_packet(s, codsty, rlevel,\n\n                                                              precno, layno,\n\n                                                              qntsty->expn + (reslevelno ? 3 * (reslevelno - 1) + 1 : 0),\n\n                                                              qntsty->nguardbits)) < 0)\n\n                                return ret;\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        break;\n\n\n\n    default:\n\n        break;\n\n    }\n\n\n\n    /* EOC marker reached */\n\n    s->buf += 2;\n\n\n\n    return 0;\n\n}\n", "idx": 25460}
{"project": "FFmpeg", "commit_id": "636ced8e1dc8248a1353b416240b93d70ad03edb", "target": 1, "func": "int opt_loglevel(void *optctx, const char *opt, const char *arg)\n\n{\n\n    const struct { const char *name; int level; } log_levels[] = {\n\n        { \"quiet\"  , AV_LOG_QUIET   },\n\n        { \"panic\"  , AV_LOG_PANIC   },\n\n        { \"fatal\"  , AV_LOG_FATAL   },\n\n        { \"error\"  , AV_LOG_ERROR   },\n\n        { \"warning\", AV_LOG_WARNING },\n\n        { \"info\"   , AV_LOG_INFO    },\n\n        { \"verbose\", AV_LOG_VERBOSE },\n\n        { \"debug\"  , AV_LOG_DEBUG   },\n\n    };\n\n    char *tail;\n\n    int level;\n\n    int i;\n\n\n\n    for (i = 0; i < FF_ARRAY_ELEMS(log_levels); i++) {\n\n        if (!strcmp(log_levels[i].name, arg)) {\n\n            av_log_set_level(log_levels[i].level);\n\n            return 0;\n\n        }\n\n    }\n\n\n\n    level = strtol(arg, &tail, 10);\n\n    if (*tail) {\n\n        av_log(NULL, AV_LOG_FATAL, \"Invalid loglevel \\\"%s\\\". \"\n\n               \"Possible levels are numbers or:\\n\", arg);\n\n        for (i = 0; i < FF_ARRAY_ELEMS(log_levels); i++)\n\n            av_log(NULL, AV_LOG_FATAL, \"\\\"%s\\\"\\n\", log_levels[i].name);\n\n        exit(1);\n\n    }\n\n    av_log_set_level(level);\n\n    return 0;\n\n}\n", "idx": 25461}
{"project": "FFmpeg", "commit_id": "f98dbc7311a30a30802c71571ff5e3d049ea7556", "target": 0, "func": "const AVOption *av_opt_next(void *obj, const AVOption *last)\n\n{\n\n    AVClass *class = *(AVClass**)obj;\n\n    if (!last && class->option && class->option[0].name)\n\n        return class->option;\n\n    if (last && last[1].name)\n\n        return ++last;\n\n    return NULL;\n\n}\n", "idx": 25463}
{"project": "FFmpeg", "commit_id": "0acf7e268b2f873379cd854b4d5aaba6f9c1f0b5", "target": 0, "func": "int avfilter_graph_create_filter(AVFilterContext **filt_ctx, AVFilter *filt,\n\n                                 const char *name, const char *args, void *opaque,\n\n                                 AVFilterGraph *graph_ctx)\n\n{\n\n    int ret;\n\n\n\n    *filt_ctx = avfilter_graph_alloc_filter(graph_ctx, filt, name);\n\n    if (!*filt_ctx)\n\n        return AVERROR(ENOMEM);\n\n\n\n    ret = avfilter_init_filter(*filt_ctx, args, opaque);\n\n    if (ret < 0)\n\n        goto fail;\n\n\n\n    return 0;\n\n\n\nfail:\n\n    if (*filt_ctx)\n\n        avfilter_free(*filt_ctx);\n\n    *filt_ctx = NULL;\n\n    return ret;\n\n}\n", "idx": 25464}
{"project": "FFmpeg", "commit_id": "53e0d5d7247548743e13c59c35e59fc2161e9582", "target": 1, "func": "static int io_open_default(AVFormatContext *s, AVIOContext **pb,\n                           const char *url, int flags, AVDictionary **options)\n{\n#if FF_API_OLD_OPEN_CALLBACKS\nFF_DISABLE_DEPRECATION_WARNINGS\n    if (s->open_cb)\n        return s->open_cb(s, pb, url, flags, &s->interrupt_callback, options);\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n    return ffio_open_whitelist(pb, url, flags, &s->interrupt_callback, options, s->protocol_whitelist, s->protocol_blacklist);\n}", "idx": 25466}
{"project": "FFmpeg", "commit_id": "61296d41e2de3b41304339e4631dd44c2e15f805", "target": 1, "func": "int ff_pred_weight_table(H264Context *h)\n{\n    int list, i;\n    int luma_def, chroma_def;\n    h->use_weight             = 0;\n    h->use_weight_chroma      = 0;\n    h->luma_log2_weight_denom = get_ue_golomb(&h->gb);\n    if (h->sps.chroma_format_idc)\n        h->chroma_log2_weight_denom = get_ue_golomb(&h->gb);\n    luma_def   = 1 << h->luma_log2_weight_denom;\n    chroma_def = 1 << h->chroma_log2_weight_denom;\n    for (list = 0; list < 2; list++) {\n        h->luma_weight_flag[list]   = 0;\n        h->chroma_weight_flag[list] = 0;\n        for (i = 0; i < h->ref_count[list]; i++) {\n            int luma_weight_flag, chroma_weight_flag;\n            luma_weight_flag = get_bits1(&h->gb);\n            if (luma_weight_flag) {\n                h->luma_weight[i][list][0] = get_se_golomb(&h->gb);\n                h->luma_weight[i][list][1] = get_se_golomb(&h->gb);\n                if (h->luma_weight[i][list][0] != luma_def ||\n                    h->luma_weight[i][list][1] != 0) {\n                    h->use_weight             = 1;\n                    h->luma_weight_flag[list] = 1;\n            } else {\n                h->luma_weight[i][list][0] = luma_def;\n                h->luma_weight[i][list][1] = 0;\n            if (h->sps.chroma_format_idc) {\n                chroma_weight_flag = get_bits1(&h->gb);\n                if (chroma_weight_flag) {\n                    int j;\n                    for (j = 0; j < 2; j++) {\n                        h->chroma_weight[i][list][j][0] = get_se_golomb(&h->gb);\n                        h->chroma_weight[i][list][j][1] = get_se_golomb(&h->gb);\n                        if (h->chroma_weight[i][list][j][0] != chroma_def ||\n                            h->chroma_weight[i][list][j][1] != 0) {\n                            h->use_weight_chroma        = 1;\n                            h->chroma_weight_flag[list] = 1;\n                } else {\n                    int j;\n                    for (j = 0; j < 2; j++) {\n                        h->chroma_weight[i][list][j][0] = chroma_def;\n                        h->chroma_weight[i][list][j][1] = 0;\n        if (h->slice_type_nos != AV_PICTURE_TYPE_B)\n            break;\n    h->use_weight = h->use_weight || h->use_weight_chroma;\n    return 0;", "idx": 25470}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int mpeg_decode_frame(AVCodecContext *avctx, void *data,\n\n                             int *got_output, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    Mpeg1Context *s = avctx->priv_data;\n\n    AVFrame *picture = data;\n\n    MpegEncContext *s2 = &s->mpeg_enc_ctx;\n\n    av_dlog(avctx, \"fill_buffer\\n\");\n\n\n\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == SEQ_END_CODE)) {\n\n        /* special case for last picture */\n\n        if (s2->low_delay == 0 && s2->next_picture_ptr) {\n\n            int ret = av_frame_ref(picture, &s2->next_picture_ptr->f);\n\n            if (ret < 0)\n\n                return ret;\n\n\n\n            s2->next_picture_ptr = NULL;\n\n\n\n            *got_output = 1;\n\n        }\n\n        return buf_size;\n\n    }\n\n\n\n    if (s2->flags & CODEC_FLAG_TRUNCATED) {\n\n        int next = ff_mpeg1_find_frame_end(&s2->parse_context, buf,\n\n                                           buf_size, NULL);\n\n\n\n        if (ff_combine_frame(&s2->parse_context, next,\n\n                             (const uint8_t **) &buf, &buf_size) < 0)\n\n            return buf_size;\n\n    }\n\n\n\n    if (s->mpeg_enc_ctx_allocated == 0 && avctx->codec_tag == AV_RL32(\"VCR2\"))\n\n        vcr2_init_sequence(avctx);\n\n\n\n    s->slice_count = 0;\n\n\n\n    if (avctx->extradata && !s->extradata_decoded) {\n\n        int ret = decode_chunks(avctx, picture, got_output,\n\n                                avctx->extradata, avctx->extradata_size);\n\n        s->extradata_decoded = 1;\n\n        if (ret < 0 && (avctx->err_recognition & AV_EF_EXPLODE))\n\n            return ret;\n\n    }\n\n\n\n    return decode_chunks(avctx, picture, got_output, buf, buf_size);\n\n}\n", "idx": 25471}
{"project": "FFmpeg", "commit_id": "0d05406482950b7c129eccfefe0daa3d6d47e292", "target": 1, "func": "static void blur(CoverContext *cover, AVFrame *in, int offx, int offy)\n\n{\n\n    int x, y, p;\n\n\n\n    for (p=0; p<3; p++) {\n\n        int ox = offx>>!!p;\n\n        int oy = offy>>!!p;\n\n        int stride = in->linesize[p];\n\n        uint8_t *data = in->data[p] + ox + oy * stride;\n\n        int w = FF_CEIL_RSHIFT(cover->width , !!p);\n\n        int h = FF_CEIL_RSHIFT(cover->height, !!p);\n\n        int iw = FF_CEIL_RSHIFT(in->width , !!p);\n\n        int ih = FF_CEIL_RSHIFT(in->height, !!p);\n\n        for (y = 0; y < h; y++) {\n\n            for (x = 0; x < w; x++) {\n\n                int c = 0;\n\n                int s = 0;\n\n                if (ox) {\n\n                    int scale = 65536 / (x + 1);\n\n                    s += data[-1 + y*stride] * scale;\n\n                    c += scale;\n\n                }\n\n                if (oy) {\n\n                    int scale = 65536 / (y + 1);\n\n                    s += data[x - stride] * scale;\n\n                    c += scale;\n\n                }\n\n                if (ox + w < iw) {\n\n                    int scale = 65536 / (w - x);\n\n                    s += data[w + y*stride] * scale;\n\n                    c += scale;\n\n                }\n\n                if (oy + h < ih) {\n\n                    int scale = 65536 / (h - y);\n\n                    s += data[x + h*stride] * scale;\n\n                    c += scale;\n\n                }\n\n                data[x + y*stride] = (s + (c>>1)) / c;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 25473}
{"project": "FFmpeg", "commit_id": "f40ec70478648c1e6cde43b8577c3c29380372ee", "target": 1, "func": "static int wav_read_header(AVFormatContext *s)\n{\n    int64_t size, av_uninit(data_size);\n    int64_t sample_count = 0;\n    int rf64 = 0;\n    char start_code[32];\n    uint32_t tag;\n    AVIOContext *pb      = s->pb;\n    AVStream *st         = NULL;\n    WAVDemuxContext *wav = s->priv_data;\n    int ret, got_fmt = 0;\n    int64_t next_tag_ofs, data_ofs = -1;\n    wav->unaligned = avio_tell(s->pb) & 1;\n    wav->smv_data_ofs = -1;\n    /* read chunk ID */\n    tag = avio_rl32(pb);\n    switch (tag) {\n    case MKTAG('R', 'I', 'F', 'F'):\n        break;\n    case MKTAG('R', 'I', 'F', 'X'):\n        wav->rifx = 1;\n        break;\n    case MKTAG('R', 'F', '6', '4'):\n        rf64 = 1;\n        break;\n    default:\n        av_get_codec_tag_string(start_code, sizeof(start_code), tag);\n        av_log(s, AV_LOG_ERROR, \"invalid start code %s in RIFF header\\n\", start_code);\n        return AVERROR_INVALIDDATA;\n    /* read chunk size */\n    avio_rl32(pb);\n    /* read format */\n    if (avio_rl32(pb) != MKTAG('W', 'A', 'V', 'E')) {\n        av_log(s, AV_LOG_ERROR, \"invalid format in RIFF header\\n\");\n        return AVERROR_INVALIDDATA;\n    if (rf64) {\n        if (avio_rl32(pb) != MKTAG('d', 's', '6', '4'))\n            return AVERROR_INVALIDDATA;\n        size = avio_rl32(pb);\n        if (size < 24)\n            return AVERROR_INVALIDDATA;\n        avio_rl64(pb); /* RIFF size */\n        data_size    = avio_rl64(pb);\n        sample_count = avio_rl64(pb);\n        if (data_size < 0 || sample_count < 0) {\n            av_log(s, AV_LOG_ERROR, \"negative data_size and/or sample_count in \"\n                   \"ds64: data_size = %\"PRId64\", sample_count = %\"PRId64\"\\n\",\n                   data_size, sample_count);\n            return AVERROR_INVALIDDATA;\n        avio_skip(pb, size - 24); /* skip rest of ds64 chunk */\n    for (;;) {\n        AVStream *vst;\n        size         = next_tag(pb, &tag, wav->rifx);\n        next_tag_ofs = avio_tell(pb) + size;\n        if (avio_feof(pb))\n            break;\n        switch (tag) {\n        case MKTAG('f', 'm', 't', ' '):\n            /* only parse the first 'fmt ' tag found */\n            if (!got_fmt && (ret = wav_parse_fmt_tag(s, size, &st)) < 0) {\n                return ret;\n            } else if (got_fmt)\n                av_log(s, AV_LOG_WARNING, \"found more than one 'fmt ' tag\\n\");\n            got_fmt = 1;\n            break;\n        case MKTAG('d', 'a', 't', 'a'):\n            if (!got_fmt) {\n                av_log(s, AV_LOG_ERROR,\n                       \"found no 'fmt ' tag before the 'data' tag\\n\");\n                return AVERROR_INVALIDDATA;\n            if (rf64) {\n                next_tag_ofs = wav->data_end = avio_tell(pb) + data_size;\n            } else if (size != 0xFFFFFFFF) {\n                data_size    = size;\n                next_tag_ofs = wav->data_end = size ? next_tag_ofs : INT64_MAX;\n            } else {\n                av_log(s, AV_LOG_WARNING, \"Ignoring maximum wav data size, \"\n                       \"file may be invalid\\n\");\n                data_size    = 0;\n                next_tag_ofs = wav->data_end = INT64_MAX;\n            data_ofs = avio_tell(pb);\n            /* don't look for footer metadata if we can't seek or if we don't\n             * know where the data tag ends\n             */\n            if (!pb->seekable || (!rf64 && !size))\n                goto break_loop;\n            break;\n        case MKTAG('f', 'a', 'c', 't'):\n            if (!sample_count)\n                sample_count = (!wav->rifx ? avio_rl32(pb) : avio_rb32(pb));\n            break;\n        case MKTAG('b', 'e', 'x', 't'):\n            if ((ret = wav_parse_bext_tag(s, size)) < 0)\n                return ret;\n            break;\n        case MKTAG('S','M','V','0'):\n            if (!got_fmt) {\n                av_log(s, AV_LOG_ERROR, \"found no 'fmt ' tag before the 'SMV0' tag\\n\");\n                return AVERROR_INVALIDDATA;\n            // SMV file, a wav file with video appended.\n            if (size != MKTAG('0','2','0','0')) {\n                av_log(s, AV_LOG_ERROR, \"Unknown SMV version found\\n\");\n                goto break_loop;\n            av_log(s, AV_LOG_DEBUG, \"Found SMV data\\n\");\n            wav->smv_given_first = 0;\n            vst = avformat_new_stream(s, NULL);\n            if (!vst)\n                return AVERROR(ENOMEM);\n            avio_r8(pb);\n            vst->id = 1;\n            vst->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n            vst->codec->codec_id = AV_CODEC_ID_SMVJPEG;\n            vst->codec->width  = avio_rl24(pb);\n            vst->codec->height = avio_rl24(pb);\n            if (ff_alloc_extradata(vst->codec, 4)) {\n                av_log(s, AV_LOG_ERROR, \"Could not allocate extradata.\\n\");\n                return AVERROR(ENOMEM);\n            size = avio_rl24(pb);\n            wav->smv_data_ofs = avio_tell(pb) + (size - 5) * 3;\n            avio_rl24(pb);\n            wav->smv_block_size = avio_rl24(pb);\n            avpriv_set_pts_info(vst, 32, 1, avio_rl24(pb));\n            vst->duration = avio_rl24(pb);\n            avio_rl24(pb);\n            avio_rl24(pb);\n            wav->smv_frames_per_jpeg = avio_rl24(pb);\n            if (wav->smv_frames_per_jpeg > 65536) {\n                av_log(s, AV_LOG_ERROR, \"too many frames per jpeg\\n\");\n                return AVERROR_INVALIDDATA;\n            AV_WL32(vst->codec->extradata, wav->smv_frames_per_jpeg);\n            wav->smv_cur_pt = 0;\n            goto break_loop;\n        case MKTAG('L', 'I', 'S', 'T'):\n            if (size < 4) {\n                av_log(s, AV_LOG_ERROR, \"too short LIST tag\\n\");\n                return AVERROR_INVALIDDATA;\n            switch (avio_rl32(pb)) {\n            case MKTAG('I', 'N', 'F', 'O'):\n                ff_read_riff_info(s, size - 4);\n            break;\n        /* seek to next tag unless we know that we'll run into EOF */\n        if ((avio_size(pb) > 0 && next_tag_ofs >= avio_size(pb)) ||\n            wav_seek_tag(wav, pb, next_tag_ofs, SEEK_SET) < 0) {\n            break;\nbreak_loop:\n    if (data_ofs < 0) {\n        av_log(s, AV_LOG_ERROR, \"no 'data' tag found\\n\");\n        return AVERROR_INVALIDDATA;\n    avio_seek(pb, data_ofs, SEEK_SET);\n    if (   data_size > 0 && sample_count && st->codec->channels\n        && (data_size << 3) / sample_count / st->codec->channels > st->codec->bits_per_coded_sample) {\n        av_log(s, AV_LOG_WARNING, \"ignoring wrong sample_count %\"PRId64\"\\n\", sample_count);\n        sample_count = 0;\n    if (!sample_count || av_get_exact_bits_per_sample(st->codec->codec_id) > 0)\n        if (   st->codec->channels\n            && data_size\n            && av_get_bits_per_sample(st->codec->codec_id)\n            && wav->data_end <= avio_size(pb))\n            sample_count = (data_size << 3)\n                                  /\n                (st->codec->channels * (uint64_t)av_get_bits_per_sample(st->codec->codec_id));\n    if (sample_count)\n        st->duration = sample_count;\n    ff_metadata_conv_ctx(s, NULL, wav_metadata_conv);\n    ff_metadata_conv_ctx(s, NULL, ff_riff_info_conv);\n    return 0;", "idx": 25474}
{"project": "FFmpeg", "commit_id": "59f809e9922ad2a8ed5373189e0e2aec0d4dffd7", "target": 1, "func": "static int parse_bsfs(void *log_ctx, const char *bsfs_spec,\n\n                      AVBitStreamFilterContext **bsfs)\n\n{\n\n    char *bsf_name, *buf, *saveptr;\n\n    int ret = 0;\n\n\n\n    if (!(buf = av_strdup(bsfs_spec)))\n\n        return AVERROR(ENOMEM);\n\n\n\n    while (bsf_name = av_strtok(buf, \",\", &saveptr)) {\n\n        AVBitStreamFilterContext *bsf = av_bitstream_filter_init(bsf_name);\n\n\n\n        if (!bsf) {\n\n            av_log(log_ctx, AV_LOG_ERROR,\n\n                   \"Cannot initialize bitstream filter with name '%s', \"\n\n                   \"unknown filter or internal error happened\\n\",\n\n                   bsf_name);\n\n            ret = AVERROR_UNKNOWN;\n\n            goto end;\n\n        }\n\n\n\n        /* append bsf context to the list of bsf contexts */\n\n        *bsfs = bsf;\n\n        bsfs = &bsf->next;\n\n\n\n        buf = NULL;\n\n    }\n\n\n\nend:\n\n    av_free(buf);\n\n    return ret;\n\n}\n", "idx": 25475}
{"project": "FFmpeg", "commit_id": "b18a0cc781b791912549504ca8a257f35a151c5e", "target": 1, "func": "void ff_ivi_output_plane(IVIPlaneDesc *plane, uint8_t *dst, int dst_pitch)\n{\n    int             x, y;\n    const int16_t   *src  = plane->bands[0].buf;\n    uint32_t        pitch = plane->bands[0].pitch;\n    for (y = 0; y < plane->height; y++) {\n        for (x = 0; x < plane->width; x++)\n            dst[x] = av_clip_uint8(src[x] + 128);\n        src += pitch;\n        dst += dst_pitch;\n    }\n}", "idx": 25476}
{"project": "FFmpeg", "commit_id": "f4ae3cce64bd46b1d539bdeac39753f83015f114", "target": 1, "func": "static void rstrip_spaces_buf(AVBPrint *buf)\n\n{\n\n    while (buf->len > 0 && buf->str[buf->len - 1] == ' ')\n\n        buf->str[--buf->len] = 0;\n\n}\n", "idx": 25477}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(rgb24ToY)(uint8_t *dst, const uint8_t *src, long width, uint32_t *unused)\n\n{\n\n#if COMPILE_TEMPLATE_MMX\n\n    RENAME(bgr24ToY_mmx)(dst, src, width, PIX_FMT_RGB24);\n\n#else\n\n    int i;\n\n    for (i=0; i<width; i++) {\n\n        int r= src[i*3+0];\n\n        int g= src[i*3+1];\n\n        int b= src[i*3+2];\n\n\n\n        dst[i]= ((RY*r + GY*g + BY*b + (33<<(RGB2YUV_SHIFT-1)))>>RGB2YUV_SHIFT);\n\n    }\n\n#endif\n\n}\n", "idx": 25481}
{"project": "FFmpeg", "commit_id": "155ec6edf82692bcf3a5f87d2bc697404f4e5aaf", "target": 0, "func": "static int ff_estimate_motion_b(MpegEncContext * s,\n\n                       int mb_x, int mb_y, int16_t (*mv_table)[2], int ref_index, int f_code)\n\n{\n\n    MotionEstContext * const c= &s->me;\n\n    int mx, my, dmin;\n\n    int P[10][2];\n\n    const int shift= 1+s->quarter_sample;\n\n    const int mot_stride = s->mb_stride;\n\n    const int mot_xy = mb_y*mot_stride + mb_x;\n\n    uint8_t * const mv_penalty= c->mv_penalty[f_code] + MAX_MV;\n\n    int mv_scale;\n\n        \n\n    c->penalty_factor    = get_penalty_factor(s->lambda, s->lambda2, c->avctx->me_cmp);\n\n    c->sub_penalty_factor= get_penalty_factor(s->lambda, s->lambda2, c->avctx->me_sub_cmp);\n\n    c->mb_penalty_factor = get_penalty_factor(s->lambda, s->lambda2, c->avctx->mb_cmp);\n\n    c->current_mv_penalty= mv_penalty;\n\n\n\n    get_limits(s, 16*mb_x, 16*mb_y);\n\n\n\n    switch(s->me_method) {\n\n    case ME_ZERO:\n\n    default:\n\n\tno_motion_search(s, &mx, &my);\n\n        dmin = 0;\n\n        mx-= mb_x*16;\n\n        my-= mb_y*16;\n\n        break;\n\n#if 0\n\n    case ME_FULL:\n\n\tdmin = full_motion_search(s, &mx, &my, range, ref_picture);\n\n        mx-= mb_x*16;\n\n        my-= mb_y*16;\n\n        break;\n\n    case ME_LOG:\n\n\tdmin = log_motion_search(s, &mx, &my, range / 2, ref_picture);\n\n        mx-= mb_x*16;\n\n        my-= mb_y*16;\n\n        break;\n\n    case ME_PHODS:\n\n\tdmin = phods_motion_search(s, &mx, &my, range / 2, ref_picture);\n\n        mx-= mb_x*16;\n\n        my-= mb_y*16;\n\n        break;\n\n#endif\n\n    case ME_X1:\n\n    case ME_EPZS:\n\n       {\n\n            P_LEFT[0]        = mv_table[mot_xy - 1][0];\n\n            P_LEFT[1]        = mv_table[mot_xy - 1][1];\n\n\n\n            if(P_LEFT[0]       > (c->xmax<<shift)) P_LEFT[0]       = (c->xmax<<shift);\n\n\n\n            /* special case for first line */\n\n            if (!s->first_slice_line) {\n\n                P_TOP[0] = mv_table[mot_xy - mot_stride             ][0];\n\n                P_TOP[1] = mv_table[mot_xy - mot_stride             ][1];\n\n                P_TOPRIGHT[0] = mv_table[mot_xy - mot_stride + 1         ][0];\n\n                P_TOPRIGHT[1] = mv_table[mot_xy - mot_stride + 1         ][1];\n\n                if(P_TOP[1] > (c->ymax<<shift)) P_TOP[1]= (c->ymax<<shift);\n\n                if(P_TOPRIGHT[0] < (c->xmin<<shift)) P_TOPRIGHT[0]= (c->xmin<<shift);\n\n                if(P_TOPRIGHT[1] > (c->ymax<<shift)) P_TOPRIGHT[1]= (c->ymax<<shift);\n\n        \n\n                P_MEDIAN[0]= mid_pred(P_LEFT[0], P_TOP[0], P_TOPRIGHT[0]);\n\n                P_MEDIAN[1]= mid_pred(P_LEFT[1], P_TOP[1], P_TOPRIGHT[1]);\n\n            }\n\n            c->pred_x= P_LEFT[0];\n\n            c->pred_y= P_LEFT[1];\n\n        }\n\n        \n\n        if(mv_table == s->b_forw_mv_table){\n\n            mv_scale= (s->pb_time<<16) / (s->pp_time<<shift);\n\n        }else{\n\n            mv_scale= ((s->pb_time - s->pp_time)<<16) / (s->pp_time<<shift);\n\n        }\n\n        \n\n        dmin = ff_epzs_motion_search(s, &mx, &my, P, 0, ref_index, s->p_mv_table, mv_scale, 0, 16);\n\n \n\n        break;\n\n    }\n\n    \n\n    dmin= c->sub_motion_search(s, &mx, &my, dmin, 0, ref_index, 0, 16);\n\n                                   \n\n    if(c->avctx->me_sub_cmp != c->avctx->mb_cmp && !c->skip)\n\n        dmin= get_mb_score(s, mx, my, 0, ref_index);\n\n\n\n//printf(\"%d %d %d %d//\", s->mb_x, s->mb_y, mx, my);\n\n//    s->mb_type[mb_y*s->mb_width + mb_x]= mb_type;\n\n    mv_table[mot_xy][0]= mx;\n\n    mv_table[mot_xy][1]= my;\n\n\n\n    return dmin;\n\n}\n", "idx": 25482}
{"project": "FFmpeg", "commit_id": "f4b288a639bbda3ca244072e67b689aa4f40f2c6", "target": 1, "func": "static int vc1_decode_b_mb_intfr(VC1Context *v)\n\n{\n\n    MpegEncContext *s = &v->s;\n\n    GetBitContext *gb = &s->gb;\n\n    int i, j;\n\n    int mb_pos = s->mb_x + s->mb_y * s->mb_stride;\n\n    int cbp = 0; /* cbp decoding stuff */\n\n    int mqdiff, mquant; /* MB quantization */\n\n    int ttmb = v->ttfrm; /* MB Transform type */\n\n    int mvsw = 0; /* motion vector switch */\n\n    int mb_has_coeffs = 1; /* last_flag */\n\n    int dmv_x, dmv_y; /* Differential MV components */\n\n    int val; /* temp value */\n\n    int first_block = 1;\n\n    int dst_idx, off;\n\n    int skipped, direct, twomv = 0;\n\n    int block_cbp = 0, pat, block_tt = 0;\n\n    int idx_mbmode = 0, mvbp;\n\n    int stride_y, fieldtx;\n\n    int bmvtype = BMV_TYPE_BACKWARD;\n\n    int dir, dir2;\n\n\n\n    mquant = v->pq; /* Lossy initialization */\n\n    s->mb_intra = 0;\n\n    if (v->skip_is_raw)\n\n        skipped = get_bits1(gb);\n\n    else\n\n        skipped = v->s.mbskip_table[mb_pos];\n\n\n\n    if (!skipped) {\n\n        idx_mbmode = get_vlc2(gb, v->mbmode_vlc->table, VC1_INTFR_NON4MV_MBMODE_VLC_BITS, 2);\n\n        if (ff_vc1_mbmode_intfrp[0][idx_mbmode][0] == MV_PMODE_INTFR_2MV_FIELD) {\n\n            twomv = 1;\n\n            v->blk_mv_type[s->block_index[0]] = 1;\n\n            v->blk_mv_type[s->block_index[1]] = 1;\n\n            v->blk_mv_type[s->block_index[2]] = 1;\n\n            v->blk_mv_type[s->block_index[3]] = 1;\n\n        } else {\n\n            v->blk_mv_type[s->block_index[0]] = 0;\n\n            v->blk_mv_type[s->block_index[1]] = 0;\n\n            v->blk_mv_type[s->block_index[2]] = 0;\n\n            v->blk_mv_type[s->block_index[3]] = 0;\n\n        }\n\n    }\n\n\n\n    if (v->dmb_is_raw)\n\n        direct = get_bits1(gb);\n\n    else\n\n        direct = v->direct_mb_plane[mb_pos];\n\n\n\n    if (direct) {\n\n\n\n        s->mv[0][0][0] = s->current_picture.motion_val[0][s->block_index[0]][0] = scale_mv(s->next_picture.motion_val[1][s->block_index[0]][0], v->bfraction, 0, s->quarter_sample);\n\n        s->mv[0][0][1] = s->current_picture.motion_val[0][s->block_index[0]][1] = scale_mv(s->next_picture.motion_val[1][s->block_index[0]][1], v->bfraction, 0, s->quarter_sample);\n\n        s->mv[1][0][0] = s->current_picture.motion_val[1][s->block_index[0]][0] = scale_mv(s->next_picture.motion_val[1][s->block_index[0]][0], v->bfraction, 1, s->quarter_sample);\n\n        s->mv[1][0][1] = s->current_picture.motion_val[1][s->block_index[0]][1] = scale_mv(s->next_picture.motion_val[1][s->block_index[0]][1], v->bfraction, 1, s->quarter_sample);\n\n\n\n        if (twomv) {\n\n            s->mv[0][2][0] = s->current_picture.motion_val[0][s->block_index[2]][0] = scale_mv(s->next_picture.motion_val[1][s->block_index[2]][0], v->bfraction, 0, s->quarter_sample);\n\n            s->mv[0][2][1] = s->current_picture.motion_val[0][s->block_index[2]][1] = scale_mv(s->next_picture.motion_val[1][s->block_index[2]][1], v->bfraction, 0, s->quarter_sample);\n\n            s->mv[1][2][0] = s->current_picture.motion_val[1][s->block_index[2]][0] = scale_mv(s->next_picture.motion_val[1][s->block_index[2]][0], v->bfraction, 1, s->quarter_sample);\n\n            s->mv[1][2][1] = s->current_picture.motion_val[1][s->block_index[2]][1] = scale_mv(s->next_picture.motion_val[1][s->block_index[2]][1], v->bfraction, 1, s->quarter_sample);\n\n\n\n            for (i = 1; i < 4; i += 2) {\n\n                s->mv[0][i][0] = s->current_picture.motion_val[0][s->block_index[i]][0] = s->mv[0][i-1][0];\n\n                s->mv[0][i][1] = s->current_picture.motion_val[0][s->block_index[i]][1] = s->mv[0][i-1][1];\n\n                s->mv[1][i][0] = s->current_picture.motion_val[1][s->block_index[i]][0] = s->mv[1][i-1][0];\n\n                s->mv[1][i][1] = s->current_picture.motion_val[1][s->block_index[i]][1] = s->mv[1][i-1][1];\n\n            }\n\n        } else {\n\n            for (i = 1; i < 4; i++) {\n\n                s->mv[0][i][0] = s->current_picture.motion_val[0][s->block_index[i]][0] = s->mv[0][0][0];\n\n                s->mv[0][i][1] = s->current_picture.motion_val[0][s->block_index[i]][1] = s->mv[0][0][1];\n\n                s->mv[1][i][0] = s->current_picture.motion_val[1][s->block_index[i]][0] = s->mv[1][0][0];\n\n                s->mv[1][i][1] = s->current_picture.motion_val[1][s->block_index[i]][1] = s->mv[1][0][1];\n\n            }\n\n        }\n\n    }\n\n\n\n    if (ff_vc1_mbmode_intfrp[0][idx_mbmode][0] == MV_PMODE_INTFR_INTRA) { // intra MB\n\n        for (i = 0; i < 4; i++) {\n\n            s->mv[0][i][0] = s->current_picture.motion_val[0][s->block_index[i]][0] = 0;\n\n            s->mv[0][i][1] = s->current_picture.motion_val[0][s->block_index[i]][1] = 0;\n\n            s->mv[1][i][0] = s->current_picture.motion_val[1][s->block_index[i]][0] = 0;\n\n            s->mv[1][i][1] = s->current_picture.motion_val[1][s->block_index[i]][1] = 0;\n\n        }\n\n        s->current_picture.mb_type[mb_pos] = MB_TYPE_INTRA;\n\n        s->mb_intra = v->is_intra[s->mb_x] = 1;\n\n        for (i = 0; i < 6; i++)\n\n            v->mb_type[0][s->block_index[i]] = 1;\n\n        fieldtx = v->fieldtx_plane[mb_pos] = get_bits1(gb);\n\n        mb_has_coeffs = get_bits1(gb);\n\n        if (mb_has_coeffs)\n\n            cbp = 1 + get_vlc2(&v->s.gb, v->cbpcy_vlc->table, VC1_CBPCY_P_VLC_BITS, 2);\n\n        v->s.ac_pred = v->acpred_plane[mb_pos] = get_bits1(gb);\n\n        GET_MQUANT();\n\n        s->current_picture.qscale_table[mb_pos] = mquant;\n\n        /* Set DC scale - y and c use the same (not sure if necessary here) */\n\n        s->y_dc_scale = s->y_dc_scale_table[mquant];\n\n        s->c_dc_scale = s->c_dc_scale_table[mquant];\n\n        dst_idx = 0;\n\n        for (i = 0; i < 6; i++) {\n\n            s->dc_val[0][s->block_index[i]] = 0;\n\n            dst_idx += i >> 2;\n\n            val = ((cbp >> (5 - i)) & 1);\n\n            v->mb_type[0][s->block_index[i]] = s->mb_intra;\n\n            v->a_avail = v->c_avail = 0;\n\n            if (i == 2 || i == 3 || !s->first_slice_line)\n\n                v->a_avail = v->mb_type[0][s->block_index[i] - s->block_wrap[i]];\n\n            if (i == 1 || i == 3 || s->mb_x)\n\n                v->c_avail = v->mb_type[0][s->block_index[i] - 1];\n\n\n\n            vc1_decode_intra_block(v, s->block[i], i, val, mquant,\n\n                                   (i & 4) ? v->codingset2 : v->codingset);\n\n            if (i > 3 && (s->flags & CODEC_FLAG_GRAY))\n\n                continue;\n\n            v->vc1dsp.vc1_inv_trans_8x8(s->block[i]);\n\n            if (i < 4) {\n\n                stride_y = s->linesize << fieldtx;\n\n                off = (fieldtx) ? ((i & 1) * 8) + ((i & 2) >> 1) * s->linesize : (i & 1) * 8 + 4 * (i & 2) * s->linesize;\n\n            } else {\n\n                stride_y = s->uvlinesize;\n\n                off = 0;\n\n            }\n\n            s->dsp.put_signed_pixels_clamped(s->block[i], s->dest[dst_idx] + off, stride_y);\n\n        }\n\n    } else {\n\n        s->mb_intra = v->is_intra[s->mb_x] = 0;\n\n        if (!direct) {\n\n            if (skipped || !s->mb_intra) {\n\n                bmvtype = decode012(gb);\n\n                switch (bmvtype) {\n\n                case 0:\n\n                    bmvtype = (v->bfraction >= (B_FRACTION_DEN/2)) ? BMV_TYPE_BACKWARD : BMV_TYPE_FORWARD;\n\n                    break;\n\n                case 1:\n\n                    bmvtype = (v->bfraction >= (B_FRACTION_DEN/2)) ? BMV_TYPE_FORWARD : BMV_TYPE_BACKWARD;\n\n                    break;\n\n                case 2:\n\n                    bmvtype  = BMV_TYPE_INTERPOLATED;\n\n                }\n\n            }\n\n\n\n            if (twomv && bmvtype != BMV_TYPE_INTERPOLATED)\n\n                mvsw = get_bits1(gb);\n\n        }\n\n\n\n        if (!skipped) { // inter MB\n\n            mb_has_coeffs = ff_vc1_mbmode_intfrp[0][idx_mbmode][3];\n\n            if (mb_has_coeffs)\n\n                cbp = 1 + get_vlc2(&v->s.gb, v->cbpcy_vlc->table, VC1_CBPCY_P_VLC_BITS, 2);\n\n            if (!direct) {\n\n                if (bmvtype == BMV_TYPE_INTERPOLATED && twomv) {\n\n                    v->fourmvbp = get_vlc2(gb, v->fourmvbp_vlc->table, VC1_4MV_BLOCK_PATTERN_VLC_BITS, 1);\n\n                } else if (bmvtype == BMV_TYPE_INTERPOLATED || twomv) {\n\n                    v->twomvbp = get_vlc2(gb, v->twomvbp_vlc->table, VC1_2MV_BLOCK_PATTERN_VLC_BITS, 1);\n\n                }\n\n            }\n\n\n\n            for (i = 0; i < 6; i++)\n\n                v->mb_type[0][s->block_index[i]] = 0;\n\n            fieldtx = v->fieldtx_plane[mb_pos] = ff_vc1_mbmode_intfrp[0][idx_mbmode][1];\n\n            /* for all motion vector read MVDATA and motion compensate each block */\n\n            dst_idx = 0;\n\n            if (direct) {\n\n                if (twomv) {\n\n                    for (i = 0; i < 4; i++) {\n\n                        vc1_mc_4mv_luma(v, i, 0, 0);\n\n                        vc1_mc_4mv_luma(v, i, 1, 1);\n\n                    }\n\n                    vc1_mc_4mv_chroma4(v, 0, 0, 0);\n\n                    vc1_mc_4mv_chroma4(v, 1, 1, 1);\n\n                } else {\n\n                    vc1_mc_1mv(v, 0);\n\n                    vc1_interp_mc(v);\n\n                }\n\n            } else if (twomv && bmvtype == BMV_TYPE_INTERPOLATED) {\n\n                mvbp = v->fourmvbp;\n\n                for (i = 0; i < 4; i++) {\n\n                    dir = i==1 || i==3;\n\n                    dmv_x = dmv_y = 0;\n\n                    val = ((mvbp >> (3 - i)) & 1);\n\n                    if (val)\n\n                        get_mvdata_interlaced(v, &dmv_x, &dmv_y, 0);\n\n                    j = i > 1 ? 2 : 0;\n\n                    vc1_pred_mv_intfr(v, j, dmv_x, dmv_y, 2, v->range_x, v->range_y, v->mb_type[0], dir);\n\n                    vc1_mc_4mv_luma(v, j, dir, dir);\n\n                    vc1_mc_4mv_luma(v, j+1, dir, dir);\n\n                }\n\n\n\n                vc1_mc_4mv_chroma4(v, 0, 0, 0);\n\n                vc1_mc_4mv_chroma4(v, 1, 1, 1);\n\n            } else if (bmvtype == BMV_TYPE_INTERPOLATED) {\n\n                mvbp = v->twomvbp;\n\n                dmv_x = dmv_y = 0;\n\n                if (mvbp & 2)\n\n                    get_mvdata_interlaced(v, &dmv_x, &dmv_y, 0);\n\n\n\n                vc1_pred_mv_intfr(v, 0, dmv_x, dmv_y, 1, v->range_x, v->range_y, v->mb_type[0], 0);\n\n                vc1_mc_1mv(v, 0);\n\n\n\n                dmv_x = dmv_y = 0;\n\n                if (mvbp & 1)\n\n                    get_mvdata_interlaced(v, &dmv_x, &dmv_y, 0);\n\n\n\n                vc1_pred_mv_intfr(v, 0, dmv_x, dmv_y, 1, v->range_x, v->range_y, v->mb_type[0], 1);\n\n                vc1_interp_mc(v);\n\n            } else if (twomv) {\n\n                dir = bmvtype == BMV_TYPE_BACKWARD;\n\n                dir2 = dir;\n\n                if (mvsw)\n\n                    dir2 = !dir;\n\n                mvbp = v->twomvbp;\n\n                dmv_x = dmv_y = 0;\n\n                if (mvbp & 2)\n\n                    get_mvdata_interlaced(v, &dmv_x, &dmv_y, 0);\n\n                vc1_pred_mv_intfr(v, 0, dmv_x, dmv_y, 2, v->range_x, v->range_y, v->mb_type[0], dir);\n\n\n\n                dmv_x = dmv_y = 0;\n\n                if (mvbp & 1)\n\n                    get_mvdata_interlaced(v, &dmv_x, &dmv_y, 0);\n\n                vc1_pred_mv_intfr(v, 2, dmv_x, dmv_y, 2, v->range_x, v->range_y, v->mb_type[0], dir2);\n\n\n\n                if (mvsw) {\n\n                    for (i = 0; i < 2; i++) {\n\n                        s->mv[dir][i+2][0] = s->mv[dir][i][0] = s->current_picture.motion_val[dir][s->block_index[i+2]][0] = s->current_picture.motion_val[dir][s->block_index[i]][0];\n\n                        s->mv[dir][i+2][1] = s->mv[dir][i][1] = s->current_picture.motion_val[dir][s->block_index[i+2]][1] = s->current_picture.motion_val[dir][s->block_index[i]][1];\n\n                        s->mv[dir2][i+2][0] = s->mv[dir2][i][0] = s->current_picture.motion_val[dir2][s->block_index[i]][0] = s->current_picture.motion_val[dir2][s->block_index[i+2]][0];\n\n                        s->mv[dir2][i+2][1] = s->mv[dir2][i][1] = s->current_picture.motion_val[dir2][s->block_index[i]][1] = s->current_picture.motion_val[dir2][s->block_index[i+2]][1];\n\n                    }\n\n                } else {\n\n                    vc1_pred_mv_intfr(v, 0, 0, 0, 2, v->range_x, v->range_y, v->mb_type[0], !dir);\n\n                    vc1_pred_mv_intfr(v, 2, 0, 0, 2, v->range_x, v->range_y, v->mb_type[0], !dir);\n\n                }\n\n\n\n                vc1_mc_4mv_luma(v, 0, dir, 0);\n\n                vc1_mc_4mv_luma(v, 1, dir, 0);\n\n                vc1_mc_4mv_luma(v, 2, dir2, 0);\n\n                vc1_mc_4mv_luma(v, 3, dir2, 0);\n\n                vc1_mc_4mv_chroma4(v, dir, dir2, 0);\n\n            } else {\n\n                dir = bmvtype == BMV_TYPE_BACKWARD;\n\n\n\n                mvbp = ff_vc1_mbmode_intfrp[0][idx_mbmode][2];\n\n                dmv_x = dmv_y = 0;\n\n                if (mvbp)\n\n                    get_mvdata_interlaced(v, &dmv_x, &dmv_y, 0);\n\n\n\n                vc1_pred_mv_intfr(v, 0, dmv_x, dmv_y, 1, v->range_x, v->range_y, v->mb_type[0], dir);\n\n                v->blk_mv_type[s->block_index[0]] = 1;\n\n                v->blk_mv_type[s->block_index[1]] = 1;\n\n                v->blk_mv_type[s->block_index[2]] = 1;\n\n                v->blk_mv_type[s->block_index[3]] = 1;\n\n                vc1_pred_mv_intfr(v, 0, 0, 0, 2, v->range_x, v->range_y, 0, !dir);\n\n                for (i = 0; i < 2; i++) {\n\n                    s->mv[!dir][i+2][0] = s->mv[!dir][i][0] = s->current_picture.motion_val[!dir][s->block_index[i+2]][0] = s->current_picture.motion_val[!dir][s->block_index[i]][0];\n\n                    s->mv[!dir][i+2][1] = s->mv[!dir][i][1] = s->current_picture.motion_val[!dir][s->block_index[i+2]][1] = s->current_picture.motion_val[!dir][s->block_index[i]][1];\n\n                }\n\n                vc1_mc_1mv(v, dir);\n\n            }\n\n\n\n            if (cbp)\n\n                GET_MQUANT();  // p. 227\n\n            s->current_picture.qscale_table[mb_pos] = mquant;\n\n            if (!v->ttmbf && cbp)\n\n                ttmb = get_vlc2(gb, ff_vc1_ttmb_vlc[v->tt_index].table, VC1_TTMB_VLC_BITS, 2);\n\n            for (i = 0; i < 6; i++) {\n\n                s->dc_val[0][s->block_index[i]] = 0;\n\n                dst_idx += i >> 2;\n\n                val = ((cbp >> (5 - i)) & 1);\n\n                if (!fieldtx)\n\n                    off = (i & 4) ? 0 : ((i & 1) * 8 + (i & 2) * 4 * s->linesize);\n\n                else\n\n                    off = (i & 4) ? 0 : ((i & 1) * 8 + ((i > 1) * s->linesize));\n\n                if (val) {\n\n                    pat = vc1_decode_p_block(v, s->block[i], i, mquant, ttmb,\n\n                                             first_block, s->dest[dst_idx] + off,\n\n                                             (i & 4) ? s->uvlinesize : (s->linesize << fieldtx),\n\n                                             (i & 4) && (s->flags & CODEC_FLAG_GRAY), &block_tt);\n\n                    block_cbp |= pat << (i << 2);\n\n                    if (!v->ttmbf && ttmb < 8)\n\n                        ttmb = -1;\n\n                    first_block = 0;\n\n                }\n\n            }\n\n\n\n        } else { // skipped\n\n            dir = 0;\n\n            for (i = 0; i < 6; i++) {\n\n                v->mb_type[0][s->block_index[i]] = 0;\n\n                s->dc_val[0][s->block_index[i]] = 0;\n\n            }\n\n            s->current_picture.mb_type[mb_pos]      = MB_TYPE_SKIP;\n\n            s->current_picture.qscale_table[mb_pos] = 0;\n\n            v->blk_mv_type[s->block_index[0]] = 0;\n\n            v->blk_mv_type[s->block_index[1]] = 0;\n\n            v->blk_mv_type[s->block_index[2]] = 0;\n\n            v->blk_mv_type[s->block_index[3]] = 0;\n\n\n\n            if (!direct) {\n\n                if (bmvtype == BMV_TYPE_INTERPOLATED) {\n\n                    vc1_pred_mv_intfr(v, 0, 0, 0, 1, v->range_x, v->range_y, v->mb_type[0], 0);\n\n                    vc1_pred_mv_intfr(v, 0, 0, 0, 1, v->range_x, v->range_y, v->mb_type[0], 1);\n\n                } else {\n\n                    dir = bmvtype == BMV_TYPE_BACKWARD;\n\n                    vc1_pred_mv_intfr(v, 0, 0, 0, 1, v->range_x, v->range_y, v->mb_type[0], dir);\n\n                    if (mvsw) {\n\n                        int dir2 = dir;\n\n                        if (mvsw)\n\n                            dir2 = !dir;\n\n                        for (i = 0; i < 2; i++) {\n\n                            s->mv[dir][i+2][0] = s->mv[dir][i][0] = s->current_picture.motion_val[dir][s->block_index[i+2]][0] = s->current_picture.motion_val[dir][s->block_index[i]][0];\n\n                            s->mv[dir][i+2][1] = s->mv[dir][i][1] = s->current_picture.motion_val[dir][s->block_index[i+2]][1] = s->current_picture.motion_val[dir][s->block_index[i]][1];\n\n                            s->mv[dir2][i+2][0] = s->mv[dir2][i][0] = s->current_picture.motion_val[dir2][s->block_index[i]][0] = s->current_picture.motion_val[dir2][s->block_index[i+2]][0];\n\n                            s->mv[dir2][i+2][1] = s->mv[dir2][i][1] = s->current_picture.motion_val[dir2][s->block_index[i]][1] = s->current_picture.motion_val[dir2][s->block_index[i+2]][1];\n\n                        }\n\n                    } else {\n\n                        v->blk_mv_type[s->block_index[0]] = 1;\n\n                        v->blk_mv_type[s->block_index[1]] = 1;\n\n                        v->blk_mv_type[s->block_index[2]] = 1;\n\n                        v->blk_mv_type[s->block_index[3]] = 1;\n\n                        vc1_pred_mv_intfr(v, 0, 0, 0, 2, v->range_x, v->range_y, 0, !dir);\n\n                        for (i = 0; i < 2; i++) {\n\n                            s->mv[!dir][i+2][0] = s->mv[!dir][i][0] = s->current_picture.motion_val[!dir][s->block_index[i+2]][0] = s->current_picture.motion_val[!dir][s->block_index[i]][0];\n\n                            s->mv[!dir][i+2][1] = s->mv[!dir][i][1] = s->current_picture.motion_val[!dir][s->block_index[i+2]][1] = s->current_picture.motion_val[!dir][s->block_index[i]][1];\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n\n\n            vc1_mc_1mv(v, dir);\n\n            if (direct || bmvtype == BMV_TYPE_INTERPOLATED) {\n\n                vc1_interp_mc(v);\n\n            }\n\n        }\n\n    }\n\n    if (s->mb_x == s->mb_width - 1)\n\n        memmove(v->is_intra_base, v->is_intra, sizeof(v->is_intra_base[0]) * s->mb_stride);\n\n    v->cbp[s->mb_x]      = block_cbp;\n\n    v->ttblk[s->mb_x]    = block_tt;\n\n    return 0;\n\n}", "idx": 25485}
{"project": "FFmpeg", "commit_id": "3ea5f64ffff0a51f62922efd2e2bc231b13b2179", "target": 1, "func": "static int execute_code(AVCodecContext * avctx, int c)\n\n{\n\n    AnsiContext *s = avctx->priv_data;\n\n    int ret, i, width, height;\n\n    switch(c) {\n\n    case 'A': //Cursor Up\n\n        s->y = FFMAX(s->y - (s->nb_args > 0 ? s->args[0]*s->font_height : s->font_height), 0);\n\n        break;\n\n    case 'B': //Cursor Down\n\n        s->y = FFMIN(s->y + (s->nb_args > 0 ? s->args[0]*s->font_height : s->font_height), avctx->height - s->font_height);\n\n        break;\n\n    case 'C': //Cursor Right\n\n        s->x = FFMIN(s->x + (s->nb_args > 0 ? s->args[0]*FONT_WIDTH : FONT_WIDTH), avctx->width  - FONT_WIDTH);\n\n        break;\n\n    case 'D': //Cursor Left\n\n        s->x = FFMAX(s->x - (s->nb_args > 0 ? s->args[0]*FONT_WIDTH : FONT_WIDTH), 0);\n\n        break;\n\n    case 'H': //Cursor Position\n\n    case 'f': //Horizontal and Vertical Position\n\n        s->y = s->nb_args > 0 ? av_clip((s->args[0] - 1)*s->font_height, 0, avctx->height - s->font_height) : 0;\n\n        s->x = s->nb_args > 1 ? av_clip((s->args[1] - 1)*FONT_WIDTH,     0, avctx->width  - FONT_WIDTH) : 0;\n\n        break;\n\n    case 'h': //set creen mode\n\n    case 'l': //reset screen mode\n\n        if (s->nb_args < 2)\n\n            s->args[0] = DEFAULT_SCREEN_MODE;\n\n        switch(s->args[0]) {\n\n        case 0: case 1: case 4: case 5: case 13: case 19: //320x200 (25 rows)\n\n            s->font = ff_cga_font;\n\n            s->font_height = 8;\n\n            width  = 40<<3;\n\n            height = 25<<3;\n\n            break;\n\n        case 2: case 3: //640x400 (25 rows)\n\n            s->font = ff_vga16_font;\n\n            s->font_height = 16;\n\n            width  = 80<<3;\n\n            height = 25<<4;\n\n            break;\n\n        case 6: case 14: //640x200 (25 rows)\n\n            s->font = ff_cga_font;\n\n            s->font_height = 8;\n\n            width  = 80<<3;\n\n            height = 25<<3;\n\n            break;\n\n        case 7: //set line wrapping\n\n            break;\n\n        case 15: case 16: //640x350 (43 rows)\n\n            s->font = ff_cga_font;\n\n            s->font_height = 8;\n\n            width  = 80<<3;\n\n            height = 43<<3;\n\n            break;\n\n        case 17: case 18: //640x480 (60 rows)\n\n            s->font = ff_cga_font;\n\n            s->font_height = 8;\n\n            width  = 80<<3;\n\n            height = 60<<4;\n\n            break;\n\n        default:\n\n            avpriv_request_sample(avctx, \"Unsupported screen mode\");\n\n        }\n\n        if (width != avctx->width || height != avctx->height) {\n\n            av_frame_unref(s->frame);\n\n            ret = ff_set_dimensions(avctx, width, height);\n\n            if (ret < 0)\n\n                return ret;\n\n            ret = ff_get_buffer(avctx, s->frame, AV_GET_BUFFER_FLAG_REF);\n\n            if (ret < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n                return ret;\n\n            }\n\n            s->frame->pict_type           = AV_PICTURE_TYPE_I;\n\n            s->frame->palette_has_changed = 1;\n\n            memcpy(s->frame->data[1], ff_cga_palette, 16 * 4);\n\n            erase_screen(avctx);\n\n        } else if (c == 'l') {\n\n            erase_screen(avctx);\n\n        }\n\n        break;\n\n    case 'J': //Erase in Page\n\n        switch (s->args[0]) {\n\n        case 0:\n\n            erase_line(avctx, s->x, avctx->width - s->x);\n\n            if (s->y < avctx->height - s->font_height)\n\n                memset(s->frame->data[0] + (s->y + s->font_height)*s->frame->linesize[0],\n\n                    DEFAULT_BG_COLOR, (avctx->height - s->y - s->font_height)*s->frame->linesize[0]);\n\n            break;\n\n        case 1:\n\n            erase_line(avctx, 0, s->x);\n\n            if (s->y > 0)\n\n                memset(s->frame->data[0], DEFAULT_BG_COLOR, s->y * s->frame->linesize[0]);\n\n            break;\n\n        case 2:\n\n            erase_screen(avctx);\n\n        }\n\n        break;\n\n    case 'K': //Erase in Line\n\n        switch(s->args[0]) {\n\n        case 0:\n\n            erase_line(avctx, s->x, avctx->width - s->x);\n\n            break;\n\n        case 1:\n\n            erase_line(avctx, 0, s->x);\n\n            break;\n\n        case 2:\n\n            erase_line(avctx, 0, avctx->width);\n\n        }\n\n        break;\n\n    case 'm': //Select Graphics Rendition\n\n        if (s->nb_args == 0) {\n\n            s->nb_args = 1;\n\n            s->args[0] = 0;\n\n        }\n\n        for (i = 0; i < FFMIN(s->nb_args, MAX_NB_ARGS); i++) {\n\n            int m = s->args[i];\n\n            if (m == 0) {\n\n                s->attributes = 0;\n\n                s->fg = DEFAULT_FG_COLOR;\n\n                s->bg = DEFAULT_BG_COLOR;\n\n            } else if (m == 1 || m == 2 || m == 4 || m == 5 || m == 7 || m == 8) {\n\n                s->attributes |= 1 << (m - 1);\n\n            } else if (m >= 30 && m <= 38) {\n\n                s->fg = ansi_to_cga[m - 30];\n\n            } else if (m == 39) {\n\n                s->fg = ansi_to_cga[DEFAULT_FG_COLOR];\n\n            } else if (m >= 40 && m <= 47) {\n\n                s->bg = ansi_to_cga[m - 40];\n\n            } else if (m == 49) {\n\n                s->fg = ansi_to_cga[DEFAULT_BG_COLOR];\n\n            } else {\n\n                avpriv_request_sample(avctx, \"Unsupported rendition parameter\");\n\n            }\n\n        }\n\n        break;\n\n    case 'n': //Device Status Report\n\n    case 'R': //report current line and column\n\n        /* ignore */\n\n        break;\n\n    case 's': //Save Cursor Position\n\n        s->sx = s->x;\n\n        s->sy = s->y;\n\n        break;\n\n    case 'u': //Restore Cursor Position\n\n        s->x = av_clip(s->sx, 0, avctx->width  - FONT_WIDTH);\n\n        s->y = av_clip(s->sy, 0, avctx->height - s->font_height);\n\n        break;\n\n    default:\n\n        avpriv_request_sample(avctx, \"Unknown escape code\");\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 25488}
{"project": "FFmpeg", "commit_id": "6c23a85000fd5956a2820495b2a081f65d03b962", "target": 1, "func": "static int compand_drain(AVFilterLink *outlink)\n\n{\n\n    AVFilterContext *ctx = outlink->src;\n\n    CompandContext *s    = ctx->priv;\n\n    const int channels   = outlink->channels;\n\n    AVFrame *frame       = NULL;\n\n    int chan, i, dindex;\n\n\n\n    /* 2048 is to limit output frame size during drain */\n\n    frame = ff_get_audio_buffer(outlink, FFMIN(2048, s->delay_count));\n\n    if (!frame)\n\n        return AVERROR(ENOMEM);\n\n    frame->pts = s->pts;\n\n    s->pts += av_rescale_q(frame->nb_samples,\n\n            (AVRational){ 1, outlink->sample_rate }, outlink->time_base);\n\n\n\n\n    for (chan = 0; chan < channels; chan++) {\n\n        AVFrame *delay_frame = s->delay_frame;\n\n        double *dbuf = (double *)delay_frame->extended_data[chan];\n\n        double *dst = (double *)frame->extended_data[chan];\n\n        ChanParam *cp = &s->channels[chan];\n\n\n\n        dindex = s->delay_index;\n\n        for (i = 0; i < frame->nb_samples; i++) {\n\n            dst[i] = av_clipd(dbuf[dindex] * get_volume(s, cp->volume),\n\n                    -1, 1);\n\n            dindex = MOD(dindex + 1, s->delay_samples);\n\n        }\n\n    }\n\n    s->delay_count -= frame->nb_samples;\n\n    s->delay_index = dindex;\n\n\n\n    return ff_filter_frame(outlink, frame);\n\n}", "idx": 25489}
{"project": "FFmpeg", "commit_id": "0ecca7a49f8e254c12a3a1de048d738bfbb614c6", "target": 1, "func": "int avpicture_layout(const AVPicture* src, int pix_fmt, int width, int height,\n\n                     unsigned char *dest, int dest_size)\n\n{\n\n    PixFmtInfo* pf = &pix_fmt_info[pix_fmt];\n\n    int i, j, w, h, data_planes;\n\n    const unsigned char* s; \n\n    int size = avpicture_get_size(pix_fmt, width, height);\n\n\n\n    if (size > dest_size)\n\n        return -1;\n\n\n\n    if (pf->pixel_type == FF_PIXEL_PACKED || pf->pixel_type == FF_PIXEL_PALETTE) {\n\n        if (pix_fmt == PIX_FMT_YUV422 || \n\n            pix_fmt == PIX_FMT_UYVY422 || \n\n            pix_fmt == PIX_FMT_RGB565 ||\n\n            pix_fmt == PIX_FMT_RGB555)\n\n            w = width * 2;\n\n\telse if (pix_fmt == PIX_FMT_UYVY411)\n\n\t  w = width + width/2;\n\n\telse if (pix_fmt == PIX_FMT_PAL8)\n\n\t  w = width;\n\n\telse\n\n\t  w = width * (pf->depth * pf->nb_channels / 8);\n\n\t  \n\n\tdata_planes = 1;\n\n\th = height;\n\n    } else {\n\n        data_planes = pf->nb_channels;\n\n\tw = (width*pf->depth + 7)/8;\n\n\th = height;\n\n    }\n\n    \n\n    for (i=0; i<data_planes; i++) {\n\n         if (i == 1) {\n\n\t     w = width >> pf->x_chroma_shift;\n\n\t     h = height >> pf->y_chroma_shift;\n\n\t }\n\n         s = src->data[i];\n\n\t for(j=0; j<h; j++) {\n\n\t     memcpy(dest, s, w);\n\n\t     dest += w;\n\n\t     s += src->linesize[i];\n\n\t }\n\n    }\n\n    \n\n    if (pf->pixel_type == FF_PIXEL_PALETTE)\n\n\tmemcpy((unsigned char *)(((size_t)dest + 3) & ~3), src->data[1], 256 * 4);\n\n    \n\n    return size;\n\n}\n", "idx": 25493}
{"project": "FFmpeg", "commit_id": "e3e51f8c14d22ae11684dcfe58df355f0f9e6401", "target": 1, "func": "static int read_access_unit(AVCodecContext *avctx, void* data,\n                            int *got_frame_ptr, AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size;\n    MLPDecodeContext *m = avctx->priv_data;\n    GetBitContext gb;\n    unsigned int length, substr;\n    unsigned int substream_start;\n    unsigned int header_size = 4;\n    unsigned int substr_header_size = 0;\n    uint8_t substream_parity_present[MAX_SUBSTREAMS];\n    uint16_t substream_data_len[MAX_SUBSTREAMS];\n    uint8_t parity_bits;\n    int ret;\n    if (buf_size < 4)\n        return AVERROR_INVALIDDATA;\n    length = (AV_RB16(buf) & 0xfff) * 2;\n    if (length < 4 || length > buf_size)\n        return AVERROR_INVALIDDATA;\n    init_get_bits(&gb, (buf + 4), (length - 4) * 8);\n    m->is_major_sync_unit = 0;\n    if (show_bits_long(&gb, 31) == (0xf8726fba >> 1)) {\n        if (read_major_sync(m, &gb) < 0)\n        m->is_major_sync_unit = 1;\n        header_size += m->major_sync_header_size;\n    if (!m->params_valid) {\n        av_log(m->avctx, AV_LOG_WARNING,\n               \"Stream parameters not seen; skipping frame.\\n\");\n        *got_frame_ptr = 0;\n        return length;\n    substream_start = 0;\n    for (substr = 0; substr < m->num_substreams; substr++) {\n        int extraword_present, checkdata_present, end, nonrestart_substr;\n        extraword_present = get_bits1(&gb);\n        nonrestart_substr = get_bits1(&gb);\n        checkdata_present = get_bits1(&gb);\n        skip_bits1(&gb);\n        end = get_bits(&gb, 12) * 2;\n        substr_header_size += 2;\n        if (extraword_present) {\n            if (m->avctx->codec_id == AV_CODEC_ID_MLP) {\n                av_log(m->avctx, AV_LOG_ERROR, \"There must be no extraword for MLP.\\n\");\n            skip_bits(&gb, 16);\n            substr_header_size += 2;\n        if (!(nonrestart_substr ^ m->is_major_sync_unit)) {\n            av_log(m->avctx, AV_LOG_ERROR, \"Invalid nonrestart_substr.\\n\");\n        if (end + header_size + substr_header_size > length) {\n            av_log(m->avctx, AV_LOG_ERROR,\n                   \"Indicated length of substream %d data goes off end of \"\n                   \"packet.\\n\", substr);\n            end = length - header_size - substr_header_size;\n        if (end < substream_start) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"Indicated end offset of substream %d data \"\n                   \"is smaller than calculated start offset.\\n\",\n                   substr);\n        if (substr > m->max_decoded_substream)\n            continue;\n        substream_parity_present[substr] = checkdata_present;\n        substream_data_len[substr] = end - substream_start;\n        substream_start = end;\n    parity_bits  = ff_mlp_calculate_parity(buf, 4);\n    parity_bits ^= ff_mlp_calculate_parity(buf + header_size, substr_header_size);\n    if ((((parity_bits >> 4) ^ parity_bits) & 0xF) != 0xF) {\n        av_log(avctx, AV_LOG_ERROR, \"Parity check failed.\\n\");\n    buf += header_size + substr_header_size;\n    for (substr = 0; substr <= m->max_decoded_substream; substr++) {\n        SubStream *s = &m->substream[substr];\n        init_get_bits(&gb, buf, substream_data_len[substr] * 8);\n        m->matrix_changed = 0;\n        memset(m->filter_changed, 0, sizeof(m->filter_changed));\n        s->blockpos = 0;\n        do {\n            if (get_bits1(&gb)) {\n                if (get_bits1(&gb)) {\n                    /* A restart header should be present. */\n                    if (read_restart_header(m, &gb, buf, substr) < 0)\n                        goto next_substr;\n                    s->restart_seen = 1;\n                if (!s->restart_seen)\n                    goto next_substr;\n                if (read_decoding_params(m, &gb, substr) < 0)\n                    goto next_substr;\n            if (!s->restart_seen)\n                goto next_substr;\n            if ((ret = read_block_data(m, &gb, substr)) < 0)\n                return ret;\n            if (get_bits_count(&gb) >= substream_data_len[substr] * 8)\n                goto substream_length_mismatch;\n        } while (!get_bits1(&gb));\n        skip_bits(&gb, (-get_bits_count(&gb)) & 15);\n        if (substream_data_len[substr] * 8 - get_bits_count(&gb) >= 32) {\n            int shorten_by;\n            if (get_bits(&gb, 16) != 0xD234)\n                return AVERROR_INVALIDDATA;\n            shorten_by = get_bits(&gb, 16);\n            if      (m->avctx->codec_id == AV_CODEC_ID_TRUEHD && shorten_by  & 0x2000)\n                s->blockpos -= FFMIN(shorten_by & 0x1FFF, s->blockpos);\n            else if (m->avctx->codec_id == AV_CODEC_ID_MLP    && shorten_by != 0xD234)\n                return AVERROR_INVALIDDATA;\n            if (substr == m->max_decoded_substream)\n                av_log(m->avctx, AV_LOG_INFO, \"End of stream indicated.\\n\");\n        if (substream_parity_present[substr]) {\n            uint8_t parity, checksum;\n            if (substream_data_len[substr] * 8 - get_bits_count(&gb) != 16)\n                goto substream_length_mismatch;\n            parity   = ff_mlp_calculate_parity(buf, substream_data_len[substr] - 2);\n            checksum = ff_mlp_checksum8       (buf, substream_data_len[substr] - 2);\n            if ((get_bits(&gb, 8) ^ parity) != 0xa9    )\n                av_log(m->avctx, AV_LOG_ERROR, \"Substream %d parity check failed.\\n\", substr);\n            if ( get_bits(&gb, 8)           != checksum)\n                av_log(m->avctx, AV_LOG_ERROR, \"Substream %d checksum failed.\\n\"    , substr);\n        if (substream_data_len[substr] * 8 != get_bits_count(&gb))\n            goto substream_length_mismatch;\nnext_substr:\n        if (!s->restart_seen)\n            av_log(m->avctx, AV_LOG_ERROR,\n                   \"No restart header present in substream %d.\\n\", substr);\n        buf += substream_data_len[substr];\n    if ((ret = output_data(m, m->max_decoded_substream, data, got_frame_ptr)) < 0)\n        return ret;\n    return length;\nsubstream_length_mismatch:\n    av_log(m->avctx, AV_LOG_ERROR, \"substream %d length mismatch\\n\", substr);\n    return AVERROR_INVALIDDATA;\nerror:\n    m->params_valid = 0;\n    return AVERROR_INVALIDDATA;", "idx": 25497}
{"project": "FFmpeg", "commit_id": "98e42a249e7891d295228ff19892450ba1f09092", "target": 1, "func": "enum AVCodecID av_guess_codec(AVOutputFormat *fmt, const char *short_name,\n\n                              const char *filename, const char *mime_type,\n\n                              enum AVMediaType type)\n\n{\n\n    if (av_match_name(\"segment\", fmt->name) || av_match_name(\"ssegment\", fmt->name)) {\n\n        fmt = av_guess_format(NULL, filename, NULL);\n\n    }\n\n\n\n    if (type == AVMEDIA_TYPE_VIDEO) {\n\n        enum AVCodecID codec_id = AV_CODEC_ID_NONE;\n\n\n\n#if CONFIG_IMAGE2_MUXER\n\n        if (!strcmp(fmt->name, \"image2\") || !strcmp(fmt->name, \"image2pipe\")) {\n\n            codec_id = ff_guess_image2_codec(filename);\n\n        }\n\n#endif\n\n        if (codec_id == AV_CODEC_ID_NONE)\n\n            codec_id = fmt->video_codec;\n\n        return codec_id;\n\n    } else if (type == AVMEDIA_TYPE_AUDIO)\n\n        return fmt->audio_codec;\n\n    else if (type == AVMEDIA_TYPE_SUBTITLE)\n\n        return fmt->subtitle_codec;\n\n    else\n\n        return AV_CODEC_ID_NONE;\n\n}\n", "idx": 25499}
{"project": "FFmpeg", "commit_id": "74ef8b434d8d8ef02bee6a5394da849136ed1bf1", "target": 1, "func": "static int rtsp_read_packet(AVFormatContext *s,\n\n                            AVPacket *pkt)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    RTSPStream *rtsp_st;\n\n    int ret, len;\n\n    uint8_t buf[RTP_MAX_PACKET_LENGTH];\n\n\n\n    /* get next frames from the same RTP packet */\n\n    if (rt->cur_rtp) {\n\n        ret = rtp_parse_packet(rt->cur_rtp, pkt, NULL, 0);\n\n        if (ret == 0) {\n\n            rt->cur_rtp = NULL;\n\n            return 0;\n\n        } else if (ret == 1) {\n\n            return 0;\n\n        } else {\n\n            rt->cur_rtp = NULL;\n\n        }\n\n    }\n\n\n\n    /* read next RTP packet */\n\n redo:\n\n    switch(rt->protocol) {\n\n    default:\n\n    case RTSP_PROTOCOL_RTP_TCP:\n\n        len = tcp_read_packet(s, &rtsp_st, buf, sizeof(buf));\n\n        break;\n\n    case RTSP_PROTOCOL_RTP_UDP:\n\n    case RTSP_PROTOCOL_RTP_UDP_MULTICAST:\n\n        len = udp_read_packet(s, &rtsp_st, buf, sizeof(buf));\n\n        if (rtsp_st->rtp_ctx)\n\n            rtp_check_and_send_back_rr(rtsp_st->rtp_ctx, len);\n\n        break;\n\n    }\n\n    if (len < 0)\n\n        return AVERROR_IO;\n\n    ret = rtp_parse_packet(rtsp_st->rtp_ctx, pkt, buf, len);\n\n    if (ret < 0)\n\n        goto redo;\n\n    if (ret == 1) {\n\n        /* more packets may follow, so we save the RTP context */\n\n        rt->cur_rtp = rtsp_st->rtp_ctx;\n\n    }\n\n    return 0;\n\n}\n", "idx": 25500}
{"project": "FFmpeg", "commit_id": "2d40a09b6e73230b160a505f01ed1acf169e1d9f", "target": 1, "func": "static int libquvi_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    LibQuviContext *qc = s->priv_data;\n\n    return av_read_frame(qc->fmtctx, pkt);\n\n}\n", "idx": 25501}
{"project": "FFmpeg", "commit_id": "e9f4001a30c563a840614048629055769f6f7020", "target": 1, "func": "static int wav_parse_fmt_tag(AVFormatContext *s, int64_t size, AVStream **st)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    int ret;\n\n\n\n    /* parse fmt header */\n\n    *st = av_new_stream(s, 0);\n\n    if (!*st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    ff_get_wav_header(pb, (*st)->codec, size);\n\n    if (ret < 0)\n\n        return ret;\n\n    (*st)->need_parsing = AVSTREAM_PARSE_FULL;\n\n\n\n    av_set_pts_info(*st, 64, 1, (*st)->codec->sample_rate);\n\n\n\n    return 0;\n\n}\n", "idx": 25502}
{"project": "FFmpeg", "commit_id": "ccb8f674995ded871ac725833b5efefce0ad63de", "target": 1, "func": "static int chunk_mux_init(AVFormatContext *s)\n\n{\n\n    WebMChunkContext *wc = s->priv_data;\n\n    AVFormatContext *oc;\n\n    int ret;\n\n\n\n    ret = avformat_alloc_output_context2(&wc->avf, wc->oformat, NULL, NULL);\n\n    if (ret < 0)\n\n        return ret;\n\n    oc = wc->avf;\n\n\n\n    oc->interrupt_callback = s->interrupt_callback;\n\n    oc->max_delay          = s->max_delay;\n\n    av_dict_copy(&oc->metadata, s->metadata, 0);\n\n\n\n    oc->priv_data = av_mallocz(oc->oformat->priv_data_size);\n\n    if (!oc->priv_data) {\n\n        avio_close(oc->pb);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    *(const AVClass**)oc->priv_data = oc->oformat->priv_class;\n\n    av_opt_set_defaults(oc->priv_data);\n\n    av_opt_set_int(oc->priv_data, \"dash\", 1, 0);\n\n    av_opt_set_int(oc->priv_data, \"cluster_time_limit\", wc->chunk_duration, 0);\n\n    av_opt_set_int(oc->priv_data, \"live\", 1, 0);\n\n\n\n    oc->streams = s->streams;\n\n    oc->nb_streams = s->nb_streams;\n\n\n\n    return 0;\n\n}\n", "idx": 25504}
{"project": "FFmpeg", "commit_id": "6c9c8b06b32013c58101f27991eae251bf4eb485", "target": 0, "func": "static int interp(RA144Context *ractx, int16_t *out, int block_num,\n\n                  int copyold, int energy)\n\n{\n\n    int work[10];\n\n    int a = block_num + 1;\n\n    int b = NBLOCKS - a;\n\n    int x;\n\n\n\n    // Interpolate block coefficients from the this frame forth block and\n\n    // last frame forth block\n\n    for (x=0; x<30; x++)\n\n        out[x] = (a * ractx->lpc_coef[0][x] + b * ractx->lpc_coef[1][x])>> 2;\n\n\n\n    if (eval_refl(work, out, ractx)) {\n\n        // The interpolated coefficients are unstable, copy either new or old\n\n        // coefficients\n\n        int_to_int16(out, ractx->lpc_coef[copyold]);\n\n        return rescale_rms(ractx->lpc_refl_rms[copyold], energy);\n\n    } else {\n\n        return rescale_rms(rms(work), energy);\n\n    }\n\n}\n", "idx": 25513}
{"project": "FFmpeg", "commit_id": "3b64e3ea45c580c5e158c086f2eb7c65635fc33b", "target": 0, "func": "int ff_framesync_request_frame(FFFrameSync *fs, AVFilterLink *outlink)\n\n{\n\n    AVFilterContext *ctx = outlink->src;\n\n    int input, ret;\n\n\n\n    if ((ret = ff_framesync_process_frame(fs, 0)) < 0)\n\n        return ret;\n\n    if (ret > 0)\n\n        return 0;\n\n    if (fs->eof)\n\n        return AVERROR_EOF;\n\n    input = fs->in_request;\n\n    ret = ff_request_frame(ctx->inputs[input]);\n\n    if (ret == AVERROR_EOF) {\n\n        if ((ret = ff_framesync_add_frame(fs, input, NULL)) < 0)\n\n            return ret;\n\n        if ((ret = ff_framesync_process_frame(fs, 0)) < 0)\n\n            return ret;\n\n        ret = 0;\n\n    }\n\n    return ret;\n\n}\n", "idx": 25524}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "AVFrame *avcodec_alloc_frame(void)\n\n{\n\n    AVFrame *frame = av_mallocz(sizeof(AVFrame));\n\n\n\n    if (frame == NULL)\n\n        return NULL;\n\n\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    avcodec_get_frame_defaults(frame);\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n\n\n    return frame;\n\n}\n", "idx": 25526}
{"project": "FFmpeg", "commit_id": "84a6bc23570c17ce91071e41431103f709c0d595", "target": 0, "func": "static Jpeg2000TgtNode *ff_jpeg2000_tag_tree_init(int w, int h)\n\n{\n\n    int pw = w, ph = h;\n\n    Jpeg2000TgtNode *res, *t, *t2;\n\n    int32_t tt_size;\n\n\n\n    tt_size = tag_tree_size(w, h);\n\n    if (tt_size == -1)\n\n        return NULL;\n\n\n\n    t = res = av_mallocz_array(tt_size, sizeof(*t));\n\n    if (!res)\n\n        return NULL;\n\n\n\n    while (w > 1 || h > 1) {\n\n        int i, j;\n\n        pw = w;\n\n        ph = h;\n\n\n\n        w  = (w + 1) >> 1;\n\n        h  = (h + 1) >> 1;\n\n        t2 = t + pw * ph;\n\n\n\n        for (i = 0; i < ph; i++)\n\n            for (j = 0; j < pw; j++)\n\n                t[i * pw + j].parent = &t2[(i >> 1) * w + (j >> 1)];\n\n\n\n        t = t2;\n\n    }\n\n    t[0].parent = NULL;\n\n    return res;\n\n}\n", "idx": 25527}
{"project": "FFmpeg", "commit_id": "d371c3c2e2830d9783465ecfe1ab7d93351083b7", "target": 1, "func": "static int source_config_props(AVFilterLink *outlink)\n\n{\n\n    AVFilterContext *ctx = outlink->src;\n\n    Frei0rContext *s = ctx->priv;\n\n\n\n    if (av_image_check_size(s->w, s->h, 0, ctx) < 0)\n\n        return AVERROR(EINVAL);\n\n    outlink->w = s->w;\n\n    outlink->h = s->h;\n\n    outlink->time_base = s->time_base;\n\n\n\n\n\n    if (!(s->instance = s->construct(outlink->w, outlink->h))) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Impossible to load frei0r instance\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    return set_params(ctx, s->params);\n\n}", "idx": 25528}
{"project": "FFmpeg", "commit_id": "ed1a6878564a97e67e5fe3a25bc099208cfed024", "target": 1, "func": "static int add_hfyu_left_prediction_int16_c(uint16_t *dst, const uint16_t *src, unsigned mask, int w, int acc){\n\n    int i;\n\n\n\n    for(i=0; i<w-1; i++){\n\n        acc+= src[i];\n\n        dst[i]= acc & mask;\n\n        i++;\n\n        acc+= src[i];\n\n        dst[i]= acc & mask;\n\n    }\n\n\n\n    for(; i<w; i++){\n\n        acc+= src[i];\n\n        dst[i]= acc & mask;\n\n    }\n\n\n\n    return acc;\n\n}\n", "idx": 25530}
{"project": "FFmpeg", "commit_id": "7800b09ece52490dda4c46fbd8e93f92e8438428", "target": 0, "func": "static int planarRgb16ToRgb16Wrapper(SwsContext *c, const uint8_t *src[],\n\n                                     int srcStride[], int srcSliceY, int srcSliceH,\n\n                                     uint8_t *dst[], int dstStride[])\n\n{\n\n    const uint16_t *src102[] = { (uint16_t *)src[1], (uint16_t *)src[0], (uint16_t *)src[2] };\n\n    const uint16_t *src201[] = { (uint16_t *)src[2], (uint16_t *)src[0], (uint16_t *)src[1] };\n\n    int stride102[] = { srcStride[1], srcStride[0], srcStride[2] };\n\n    int stride201[] = { srcStride[2], srcStride[0], srcStride[1] };\n\n    const AVPixFmtDescriptor *src_format = av_pix_fmt_desc_get(c->srcFormat);\n\n    const AVPixFmtDescriptor *dst_format = av_pix_fmt_desc_get(c->dstFormat);\n\n    int bits_per_sample = src_format->comp[0].depth_minus1 + 1;\n\n    int swap = 0;\n\n    if ( HAVE_BIGENDIAN && !(src_format->flags & AV_PIX_FMT_FLAG_BE) ||\n\n        !HAVE_BIGENDIAN &&   src_format->flags & AV_PIX_FMT_FLAG_BE)\n\n        swap++;\n\n    if ( HAVE_BIGENDIAN && !(dst_format->flags & AV_PIX_FMT_FLAG_BE) ||\n\n        !HAVE_BIGENDIAN &&   dst_format->flags & AV_PIX_FMT_FLAG_BE)\n\n        swap += 2;\n\n\n\n    if ((src_format->flags & (AV_PIX_FMT_FLAG_PLANAR | AV_PIX_FMT_FLAG_RGB)) !=\n\n        (AV_PIX_FMT_FLAG_PLANAR | AV_PIX_FMT_FLAG_RGB)) {\n\n        av_log(c, AV_LOG_ERROR, \"unsupported planar RGB conversion %s -> %s\\n\",\n\n               src_format->name, dst_format->name);\n\n        return srcSliceH;\n\n    }\n\n    switch (c->dstFormat) {\n\n    case AV_PIX_FMT_BGR48LE:\n\n    case AV_PIX_FMT_BGR48BE:\n\n        gbr16ptopacked16(src102, stride102,\n\n                         dst[0] + srcSliceY * dstStride[0], dstStride[0],\n\n                         srcSliceH, 0, swap, bits_per_sample, c->srcW);\n\n        break;\n\n    case AV_PIX_FMT_RGB48LE:\n\n    case AV_PIX_FMT_RGB48BE:\n\n        gbr16ptopacked16(src201, stride201,\n\n                         dst[0] + srcSliceY * dstStride[0], dstStride[0],\n\n                         srcSliceH, 0, swap, bits_per_sample, c->srcW);\n\n        break;\n\n    case AV_PIX_FMT_RGBA64LE:\n\n    case AV_PIX_FMT_RGBA64BE:\n\n         gbr16ptopacked16(src201, stride201,\n\n                          dst[0] + srcSliceY * dstStride[0], dstStride[0],\n\n                          srcSliceH, 1, swap, bits_per_sample, c->srcW);\n\n        break;\n\n    case AV_PIX_FMT_BGRA64LE:\n\n    case AV_PIX_FMT_BGRA64BE:\n\n        gbr16ptopacked16(src102, stride102,\n\n                         dst[0] + srcSliceY * dstStride[0], dstStride[0],\n\n                         srcSliceH, 1, swap, bits_per_sample, c->srcW);\n\n        break;\n\n    default:\n\n        av_log(c, AV_LOG_ERROR,\n\n               \"unsupported planar RGB conversion %s -> %s\\n\",\n\n               src_format->name, dst_format->name);\n\n    }\n\n\n\n    return srcSliceH;\n\n}\n", "idx": 25533}
{"project": "FFmpeg", "commit_id": "e45a2872fafe631c14aee9f79d0963d68c4fc1fd", "target": 0, "func": "void put_pixels16_altivec(uint8_t *block, const uint8_t *pixels, int line_size, int h)\n\n{\n\nPOWERPC_TBL_DECLARE(altivec_put_pixels16_num, 1);\n\n#ifdef ALTIVEC_USE_REFERENCE_C_CODE\n\n    int i;\n\n\n\nPOWERPC_TBL_START_COUNT(altivec_put_pixels16_num, 1);\n\n\n\n    for(i=0; i<h; i++) {\n\n      *((uint32_t*)(block )) = (((const struct unaligned_32 *) (pixels))->l);\n\n      *((uint32_t*)(block+4)) = (((const struct unaligned_32 *) (pixels+4))->l);\n\n      *((uint32_t*)(block+8)) = (((const struct unaligned_32 *) (pixels+8))->l);\n\n      *((uint32_t*)(block+12)) = (((const struct unaligned_32 *) (pixels+12))->l);\n\n      pixels+=line_size;\n\n      block +=line_size;\n\n    }\n\n\n\nPOWERPC_TBL_STOP_COUNT(altivec_put_pixels16_num, 1);\n\n\n\n#else /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n    register vector unsigned char pixelsv1, pixelsv2;\n\n    register vector unsigned char perm = vec_lvsl(0, pixels);\n\n    int i;\n\n\n\nPOWERPC_TBL_START_COUNT(altivec_put_pixels16_num, 1);\n\n\n\n    for(i=0; i<h; i++) {\n\n      pixelsv1 = vec_ld(0, (unsigned char*)pixels);\n\n      pixelsv2 = vec_ld(16, (unsigned char*)pixels);\n\n      vec_st(vec_perm(pixelsv1, pixelsv2, perm),\n\n             0, (unsigned char*)block);\n\n      pixels+=line_size;\n\n      block +=line_size;\n\n    }\n\n\n\nPOWERPC_TBL_STOP_COUNT(altivec_put_pixels16_num, 1);\n\n\n\n#endif /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n}\n", "idx": 25534}
{"project": "FFmpeg", "commit_id": "4c7b023d56e09a78a587d036db1b64bf7c493b3d", "target": 0, "func": "static int nvdec_vp9_start_frame(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)\n\n{\n\n    VP9SharedContext *h = avctx->priv_data;\n\n    const AVPixFmtDescriptor *pixdesc = av_pix_fmt_desc_get(avctx->sw_pix_fmt);\n\n\n\n    NVDECContext      *ctx = avctx->internal->hwaccel_priv_data;\n\n    CUVIDPICPARAMS     *pp = &ctx->pic_params;\n\n    CUVIDVP9PICPARAMS *ppc = &pp->CodecSpecific.vp9;\n\n    FrameDecodeData *fdd;\n\n    NVDECFrame *cf;\n\n    AVFrame *cur_frame = h->frames[CUR_FRAME].tf.f;\n\n\n\n    int ret, i;\n\n\n\n    ret = ff_nvdec_start_frame(avctx, cur_frame);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    fdd = (FrameDecodeData*)cur_frame->private_ref->data;\n\n    cf  = (NVDECFrame*)fdd->hwaccel_priv;\n\n\n\n    *pp = (CUVIDPICPARAMS) {\n\n        .PicWidthInMbs     = (cur_frame->width  + 15) / 16,\n\n        .FrameHeightInMbs  = (cur_frame->height + 15) / 16,\n\n        .CurrPicIdx        = cf->idx,\n\n\n\n        .CodecSpecific.vp9 = {\n\n            .width                    = cur_frame->width,\n\n            .height                   = cur_frame->height,\n\n\n\n            .LastRefIdx               = get_ref_idx(h->refs[h->h.refidx[0]].f),\n\n            .GoldenRefIdx             = get_ref_idx(h->refs[h->h.refidx[1]].f),\n\n            .AltRefIdx                = get_ref_idx(h->refs[h->h.refidx[2]].f),\n\n\n\n            .profile                  = h->h.profile,\n\n            .frameContextIdx          = h->h.framectxid,\n\n            .frameType                = !h->h.keyframe,\n\n            .showFrame                = !h->h.invisible,\n\n            .errorResilient           = h->h.errorres,\n\n            .frameParallelDecoding    = h->h.parallelmode,\n\n            .subSamplingX             = pixdesc->log2_chroma_w,\n\n            .subSamplingY             = pixdesc->log2_chroma_h,\n\n            .intraOnly                = h->h.intraonly,\n\n            .allow_high_precision_mv  = h->h.keyframe ? 0 : h->h.highprecisionmvs,\n\n            .refreshEntropyProbs      = h->h.refreshctx,\n\n\n\n            .bitDepthMinus8Luma       = pixdesc->comp[0].depth - 8,\n\n            .bitDepthMinus8Chroma     = pixdesc->comp[1].depth - 8,\n\n\n\n            .loopFilterLevel          = h->h.filter.level,\n\n            .loopFilterSharpness      = h->h.filter.sharpness,\n\n            .modeRefLfEnabled         = h->h.lf_delta.enabled,\n\n\n\n            .log2_tile_columns        = h->h.tiling.log2_tile_cols,\n\n            .log2_tile_rows           = h->h.tiling.log2_tile_rows,\n\n\n\n            .segmentEnabled           = h->h.segmentation.enabled,\n\n            .segmentMapUpdate         = h->h.segmentation.update_map,\n\n            .segmentMapTemporalUpdate = h->h.segmentation.temporal,\n\n            .segmentFeatureMode       = h->h.segmentation.absolute_vals,\n\n\n\n            .qpYAc                    = h->h.yac_qi,\n\n            .qpYDc                    = h->h.ydc_qdelta,\n\n            .qpChDc                   = h->h.uvdc_qdelta,\n\n            .qpChAc                   = h->h.uvac_qdelta,\n\n\n\n            .resetFrameContext        = h->h.resetctx,\n\n            .mcomp_filter_type        = h->h.filtermode ^ (h->h.filtermode <= 1),\n\n\n\n            .frameTagSize             = h->h.uncompressed_header_size,\n\n            .offsetToDctParts         = h->h.compressed_header_size,\n\n\n\n            .refFrameSignBias[0]      = 0,\n\n        }\n\n    };\n\n\n\n    for (i = 0; i < 2; i++)\n\n        ppc->mbModeLfDelta[i] = h->h.lf_delta.mode[i];\n\n\n\n    for (i = 0; i < 4; i++)\n\n        ppc->mbRefLfDelta[i] = h->h.lf_delta.ref[i];\n\n\n\n    for (i = 0; i < 7; i++)\n\n        ppc->mb_segment_tree_probs[i] = h->h.segmentation.prob[i];\n\n\n\n    for (i = 0; i < 3; i++) {\n\n        ppc->activeRefIdx[i] = h->h.refidx[i];\n\n        ppc->segment_pred_probs[i] = h->h.segmentation.pred_prob[i];\n\n        ppc->refFrameSignBias[i + 1] = h->h.signbias[i];\n\n    }\n\n\n\n    for (i = 0; i < 8; i++) {\n\n        ppc->segmentFeatureEnable[i][0] = h->h.segmentation.feat[i].q_enabled;\n\n        ppc->segmentFeatureEnable[i][1] = h->h.segmentation.feat[i].lf_enabled;\n\n        ppc->segmentFeatureEnable[i][2] = h->h.segmentation.feat[i].ref_enabled;\n\n        ppc->segmentFeatureEnable[i][3] = h->h.segmentation.feat[i].skip_enabled;\n\n\n\n        ppc->segmentFeatureData[i][0] = h->h.segmentation.feat[i].q_val;\n\n        ppc->segmentFeatureData[i][1] = h->h.segmentation.feat[i].lf_val;\n\n        ppc->segmentFeatureData[i][2] = h->h.segmentation.feat[i].ref_val;\n\n        ppc->segmentFeatureData[i][3] = 0;\n\n    }\n\n\n\n    switch (avctx->colorspace) {\n\n    default:\n\n    case AVCOL_SPC_UNSPECIFIED:\n\n        ppc->colorSpace = 0;\n\n        break;\n\n    case AVCOL_SPC_BT470BG:\n\n        ppc->colorSpace = 1;\n\n        break;\n\n    case AVCOL_SPC_BT709:\n\n        ppc->colorSpace = 2;\n\n        break;\n\n    case AVCOL_SPC_SMPTE170M:\n\n        ppc->colorSpace = 3;\n\n        break;\n\n    case AVCOL_SPC_SMPTE240M:\n\n        ppc->colorSpace = 4;\n\n        break;\n\n    case AVCOL_SPC_BT2020_NCL:\n\n        ppc->colorSpace = 5;\n\n        break;\n\n    case AVCOL_SPC_RESERVED:\n\n        ppc->colorSpace = 6;\n\n        break;\n\n    case AVCOL_SPC_RGB:\n\n        ppc->colorSpace = 7;\n\n        break;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25545}
{"project": "FFmpeg", "commit_id": "7457da3698c641212bb921cfb0aa0e7853fdda48", "target": 1, "func": "static int draw_text(AVFilterContext *ctx, AVFilterBufferRef *picref,\n\n                     int width, int height)\n\n{\n\n    DrawTextContext *dtext = ctx->priv;\n\n    uint32_t code = 0, prev_code = 0;\n\n    int x = 0, y = 0, i = 0, ret;\n\n    int max_text_line_w = 0, len;\n\n    int box_w, box_h;\n\n    char *text = dtext->text;\n\n    uint8_t *p;\n\n    int y_min = 32000, y_max = -32000;\n\n    int x_min = 32000, x_max = -32000;\n\n    FT_Vector delta;\n\n    Glyph *glyph = NULL, *prev_glyph = NULL;\n\n    Glyph dummy = { 0 };\n\n\n\n    time_t now = time(0);\n\n    struct tm ltime;\n\n    uint8_t *buf = dtext->expanded_text;\n\n    int buf_size = dtext->expanded_text_size;\n\n\n\n    if(dtext->basetime != AV_NOPTS_VALUE)\n\n        now= picref->pts*av_q2d(ctx->inputs[0]->time_base) + dtext->basetime/1000000;\n\n\n\n    if (!buf) {\n\n        buf_size = 2*strlen(dtext->text)+1;\n\n        buf = av_malloc(buf_size);\n\n    }\n\n\n\n#if HAVE_LOCALTIME_R\n\n    localtime_r(&now, &ltime);\n\n#else\n\n    if(strchr(dtext->text, '%'))\n\n        ltime= *localtime(&now);\n\n#endif\n\n\n\n    do {\n\n        *buf = 1;\n\n        if (strftime(buf, buf_size, dtext->text, &ltime) != 0 || *buf == 0)\n\n            break;\n\n        buf_size *= 2;\n\n    } while ((buf = av_realloc(buf, buf_size)));\n\n\n\n    if (dtext->tc_opt_string) {\n\n        char tcbuf[AV_TIMECODE_STR_SIZE];\n\n        av_timecode_make_string(&dtext->tc, tcbuf, dtext->frame_id++);\n\n\n        buf = av_asprintf(\"%s%s\", dtext->text, tcbuf);\n\n    }\n\n\n\n    if (!buf)\n\n        return AVERROR(ENOMEM);\n\n    text = dtext->expanded_text = buf;\n\n    dtext->expanded_text_size = buf_size;\n\n    if ((len = strlen(text)) > dtext->nb_positions) {\n\n        if (!(dtext->positions =\n\n              av_realloc(dtext->positions, len*sizeof(*dtext->positions))))\n\n            return AVERROR(ENOMEM);\n\n        dtext->nb_positions = len;\n\n    }\n\n\n\n    x = 0;\n\n    y = 0;\n\n\n\n    /* load and cache glyphs */\n\n    for (i = 0, p = text; *p; i++) {\n\n        GET_UTF8(code, *p++, continue;);\n\n\n\n        /* get glyph */\n\n        dummy.code = code;\n\n        glyph = av_tree_find(dtext->glyphs, &dummy, glyph_cmp, NULL);\n\n        if (!glyph) {\n\n            load_glyph(ctx, &glyph, code);\n\n        }\n\n\n\n        y_min = FFMIN(glyph->bbox.yMin, y_min);\n\n        y_max = FFMAX(glyph->bbox.yMax, y_max);\n\n        x_min = FFMIN(glyph->bbox.xMin, x_min);\n\n        x_max = FFMAX(glyph->bbox.xMax, x_max);\n\n    }\n\n    dtext->max_glyph_h = y_max - y_min;\n\n    dtext->max_glyph_w = x_max - x_min;\n\n\n\n    /* compute and save position for each glyph */\n\n    glyph = NULL;\n\n    for (i = 0, p = text; *p; i++) {\n\n        GET_UTF8(code, *p++, continue;);\n\n\n\n        /* skip the \\n in the sequence \\r\\n */\n\n        if (prev_code == '\\r' && code == '\\n')\n\n            continue;\n\n\n\n        prev_code = code;\n\n        if (is_newline(code)) {\n\n            max_text_line_w = FFMAX(max_text_line_w, x);\n\n            y += dtext->max_glyph_h;\n\n            x = 0;\n\n            continue;\n\n        }\n\n\n\n        /* get glyph */\n\n        prev_glyph = glyph;\n\n        dummy.code = code;\n\n        glyph = av_tree_find(dtext->glyphs, &dummy, glyph_cmp, NULL);\n\n\n\n        /* kerning */\n\n        if (dtext->use_kerning && prev_glyph && glyph->code) {\n\n            FT_Get_Kerning(dtext->face, prev_glyph->code, glyph->code,\n\n                           ft_kerning_default, &delta);\n\n            x += delta.x >> 6;\n\n        }\n\n\n\n        /* save position */\n\n        dtext->positions[i].x = x + glyph->bitmap_left;\n\n        dtext->positions[i].y = y - glyph->bitmap_top + y_max;\n\n        if (code == '\\t') x  = (x / dtext->tabsize + 1)*dtext->tabsize;\n\n        else              x += glyph->advance;\n\n    }\n\n\n\n    max_text_line_w = FFMAX(x, max_text_line_w);\n\n\n\n    dtext->var_values[VAR_TW] = dtext->var_values[VAR_TEXT_W] = max_text_line_w;\n\n    dtext->var_values[VAR_TH] = dtext->var_values[VAR_TEXT_H] = y + dtext->max_glyph_h;\n\n\n\n    dtext->var_values[VAR_MAX_GLYPH_W] = dtext->max_glyph_w;\n\n    dtext->var_values[VAR_MAX_GLYPH_H] = dtext->max_glyph_h;\n\n    dtext->var_values[VAR_MAX_GLYPH_A] = dtext->var_values[VAR_ASCENT ] = y_max;\n\n    dtext->var_values[VAR_MAX_GLYPH_D] = dtext->var_values[VAR_DESCENT] = y_min;\n\n\n\n    dtext->var_values[VAR_LINE_H] = dtext->var_values[VAR_LH] = dtext->max_glyph_h;\n\n\n\n    dtext->x = dtext->var_values[VAR_X] = av_expr_eval(dtext->x_pexpr, dtext->var_values, &dtext->prng);\n\n    dtext->y = dtext->var_values[VAR_Y] = av_expr_eval(dtext->y_pexpr, dtext->var_values, &dtext->prng);\n\n    dtext->x = dtext->var_values[VAR_X] = av_expr_eval(dtext->x_pexpr, dtext->var_values, &dtext->prng);\n\n    dtext->draw = av_expr_eval(dtext->draw_pexpr, dtext->var_values, &dtext->prng);\n\n\n\n    if(!dtext->draw)\n\n        return 0;\n\n\n\n    box_w = FFMIN(width - 1 , max_text_line_w);\n\n    box_h = FFMIN(height - 1, y + dtext->max_glyph_h);\n\n\n\n    /* draw box */\n\n    if (dtext->draw_box)\n\n        ff_blend_rectangle(&dtext->dc, &dtext->boxcolor,\n\n                           picref->data, picref->linesize, width, height,\n\n                           dtext->x, dtext->y, box_w, box_h);\n\n\n\n    if (dtext->shadowx || dtext->shadowy) {\n\n        if ((ret = draw_glyphs(dtext, picref, width, height, dtext->shadowcolor.rgba,\n\n                               &dtext->shadowcolor, dtext->shadowx, dtext->shadowy)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    if ((ret = draw_glyphs(dtext, picref, width, height, dtext->fontcolor.rgba,\n\n                           &dtext->fontcolor, 0, 0)) < 0)\n\n        return ret;\n\n\n\n    return 0;\n\n}", "idx": 25553}
{"project": "FFmpeg", "commit_id": "bd5c860fdbc33d19d2ff0f6d1f06de07c17560dd", "target": 1, "func": "static int av_thread_message_queue_recv_locked(AVThreadMessageQueue *mq,\n\n                                               void *msg,\n\n                                               unsigned flags)\n\n{\n\n    while (!mq->err_recv && av_fifo_size(mq->fifo) < mq->elsize) {\n\n        if ((flags & AV_THREAD_MESSAGE_NONBLOCK))\n\n            return AVERROR(EAGAIN);\n\n        pthread_cond_wait(&mq->cond, &mq->lock);\n\n    }\n\n    if (av_fifo_size(mq->fifo) < mq->elsize)\n\n        return mq->err_recv;\n\n    av_fifo_generic_read(mq->fifo, msg, mq->elsize, NULL);\n\n    pthread_cond_signal(&mq->cond);\n\n    return 0;\n\n}\n", "idx": 25554}
{"project": "FFmpeg", "commit_id": "f57b00e89749b559da7cd99a4b630c90617e17d4", "target": 1, "func": "static const ID3v2EMFunc *get_extra_meta_func(const char *tag, int isv34)\n\n{\n\n    int i = 0;\n\n    while (ff_id3v2_extra_meta_funcs[i].tag3) {\n\n        if (!memcmp(tag,\n\n                    (isv34 ?\n\n                        ff_id3v2_extra_meta_funcs[i].tag4 :\n\n                        ff_id3v2_extra_meta_funcs[i].tag3),\n\n                    (isv34 ? 4 : 3)))\n\n            return &ff_id3v2_extra_meta_funcs[i];\n\n        i++;\n\n    }\n\n    return NULL;\n\n}\n", "idx": 25557}
{"project": "FFmpeg", "commit_id": "cefa5999534de75686607891b4c06f5b8bd99991", "target": 1, "func": "void ff_snow_vertical_compose97i_mmx(IDWTELEM *b0, IDWTELEM *b1, IDWTELEM *b2, IDWTELEM *b3, IDWTELEM *b4, IDWTELEM *b5, int width){\n\n    long i = width;\n\n    while(i & 15)\n\n    {\n\n        i--;\n\n        b4[i] -= (W_DM*(b3[i] + b5[i])+W_DO)>>W_DS;\n\n        b3[i] -= (W_CM*(b2[i] + b4[i])+W_CO)>>W_CS;\n\n        b2[i] += (W_BM*(b1[i] + b3[i])+4*b2[i]+W_BO)>>W_BS;\n\n        b1[i] += (W_AM*(b0[i] + b2[i])+W_AO)>>W_AS;\n\n    }\n\n    i+=i;\n\n    asm volatile(\n\n        \"jmp 2f                                      \\n\\t\"\n\n        \"1:                                          \\n\\t\"\n\n\n\n        snow_vertical_compose_mmx_load(\"%4\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_add(\"%6\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_move(\"mm0\",\"mm2\",\"mm4\",\"mm6\",\"mm1\",\"mm3\",\"mm5\",\"mm7\")\n\n        snow_vertical_compose_sra(\"1\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_r2r_add(\"mm1\",\"mm3\",\"mm5\",\"mm7\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n\n\n        \"pcmpeqw %%mm1, %%mm1                        \\n\\t\"\n\n        \"psllw $15, %%mm1                            \\n\\t\"\n\n        \"psrlw $14, %%mm1                            \\n\\t\"\n\n\n\n        snow_vertical_compose_r2r_add(\"mm1\",\"mm1\",\"mm1\",\"mm1\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_sra(\"2\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_load(\"%5\",\"mm1\",\"mm3\",\"mm5\",\"mm7\")\n\n        snow_vertical_compose_r2r_sub(\"mm0\",\"mm2\",\"mm4\",\"mm6\",\"mm1\",\"mm3\",\"mm5\",\"mm7\")\n\n        snow_vertical_compose_mmx_store(\"%5\",\"mm1\",\"mm3\",\"mm5\",\"mm7\")\n\n        snow_vertical_compose_mmx_load(\"%4\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_add(\"%3\",\"mm1\",\"mm3\",\"mm5\",\"mm7\")\n\n        snow_vertical_compose_r2r_sub(\"mm1\",\"mm3\",\"mm5\",\"mm7\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_store(\"%4\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        \"pcmpeqw %%mm7, %%mm7                        \\n\\t\"\n\n        \"pcmpeqw %%mm5, %%mm5                        \\n\\t\"\n\n        \"psllw $15, %%mm7                            \\n\\t\"\n\n        \"psrlw $13, %%mm5                            \\n\\t\"\n\n        \"paddw %%mm7, %%mm5                          \\n\\t\"\n\n        snow_vertical_compose_r2r_add(\"mm5\",\"mm5\",\"mm5\",\"mm5\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        \"movq   (%2,%%\"REG_d\"), %%mm1         \\n\\t\"\n\n        \"movq  8(%2,%%\"REG_d\"), %%mm3         \\n\\t\"\n\n        \"paddw %%mm7, %%mm1                          \\n\\t\"\n\n        \"paddw %%mm7, %%mm3                          \\n\\t\"\n\n        \"pavgw %%mm1, %%mm0                          \\n\\t\"\n\n        \"pavgw %%mm3, %%mm2                          \\n\\t\"\n\n        \"movq 16(%2,%%\"REG_d\"), %%mm1         \\n\\t\"\n\n        \"movq 24(%2,%%\"REG_d\"), %%mm3         \\n\\t\"\n\n        \"paddw %%mm7, %%mm1                          \\n\\t\"\n\n        \"paddw %%mm7, %%mm3                          \\n\\t\"\n\n        \"pavgw %%mm1, %%mm4                          \\n\\t\"\n\n        \"pavgw %%mm3, %%mm6                          \\n\\t\"\n\n        snow_vertical_compose_r2r_sub(\"mm7\",\"mm7\",\"mm7\",\"mm7\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_sra(\"1\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_add(\"%3\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n\n\n        snow_vertical_compose_sra(\"2\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_add(\"%3\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_store(\"%3\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_add(\"%1\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_move(\"mm0\",\"mm2\",\"mm4\",\"mm6\",\"mm1\",\"mm3\",\"mm5\",\"mm7\")\n\n        snow_vertical_compose_sra(\"1\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_r2r_add(\"mm1\",\"mm3\",\"mm5\",\"mm7\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_add(\"%2\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_store(\"%2\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n\n\n        \"2:                                          \\n\\t\"\n\n        \"sub $32, %%\"REG_d\"                          \\n\\t\"\n\n        \"jge 1b                                      \\n\\t\"\n\n        :\"+d\"(i)\n\n        :\"r\"(b0),\"r\"(b1),\"r\"(b2),\"r\"(b3),\"r\"(b4),\"r\"(b5));\n\n}\n", "idx": 25561}
{"project": "FFmpeg", "commit_id": "bd5c860fdbc33d19d2ff0f6d1f06de07c17560dd", "target": 1, "func": "void av_thread_message_flush(AVThreadMessageQueue *mq)\n\n{\n\n#if HAVE_THREADS\n\n    int used, off;\n\n    void *free_func = mq->free_func;\n\n\n\n    pthread_mutex_lock(&mq->lock);\n\n    used = av_fifo_size(mq->fifo);\n\n    if (free_func)\n\n        for (off = 0; off < used; off += mq->elsize)\n\n            av_fifo_generic_peek_at(mq->fifo, mq, off, mq->elsize, free_func_wrap);\n\n    av_fifo_drain(mq->fifo, used);\n\n    pthread_cond_broadcast(&mq->cond);\n\n    pthread_mutex_unlock(&mq->lock);\n\n#endif /* HAVE_THREADS */\n\n}\n", "idx": 25563}
{"project": "FFmpeg", "commit_id": "4e59c8ecf1433b85b539c5e89bb68cfe8b839866", "target": 1, "func": "int av_open_input_stream(AVFormatContext **ic_ptr,\n\n                         AVIOContext *pb, const char *filename,\n\n                         AVInputFormat *fmt, AVFormatParameters *ap)\n\n{\n\n    int err;\n\n    AVDictionary *opts;\n\n    AVFormatContext *ic;\n\n    AVFormatParameters default_ap;\n\n\n\n    if(!ap){\n\n        ap=&default_ap;\n\n        memset(ap, 0, sizeof(default_ap));\n\n    }\n\n    opts = convert_format_parameters(ap);\n\n\n\n    if(!ap->prealloced_context)\n\n        ic = avformat_alloc_context();\n\n    else\n\n        ic = *ic_ptr;\n\n    if (!ic) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    if (pb && fmt && fmt->flags & AVFMT_NOFILE)\n\n        av_log(ic, AV_LOG_WARNING, \"Custom AVIOContext makes no sense and \"\n\n                                   \"will be ignored with AVFMT_NOFILE format.\\n\");\n\n    else\n\n        ic->pb = pb;\n\n\n\n    err = avformat_open_input(&ic, filename, fmt, &opts);\n\n    ic->pb = ic->pb ? ic->pb : pb; // don't leak custom pb if it wasn't set above\n\n\n\n    *ic_ptr = ic;\n\nfail:\n\n    av_dict_free(&opts);\n\n    return err;\n\n}\n", "idx": 25564}
{"project": "FFmpeg", "commit_id": "ac87c273a646eb8feba8e47f15da4934d119f650", "target": 1, "func": "int av_buffersrc_add_ref(AVFilterContext *buffer_filter,\n\n                         AVFilterBufferRef *picref, int flags)\n\n{\n\n    BufferSourceContext *c = buffer_filter->priv;\n\n    AVFilterBufferRef *buf;\n\n    int ret;\n\n\n\n    if (!picref) {\n\n        c->eof = 1;\n\n        return 0;\n\n    } else if (c->eof)\n\n        return AVERROR(EINVAL);\n\n\n\n    if (!av_fifo_space(c->fifo) &&\n\n        (ret = av_fifo_realloc2(c->fifo, av_fifo_size(c->fifo) +\n\n                                         sizeof(buf))) < 0)\n\n        return ret;\n\n\n\n    if (!(flags & AV_BUFFERSRC_FLAG_NO_CHECK_FORMAT)) {\n\n        ret = check_format_change(buffer_filter, picref);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n    if (flags & AV_BUFFERSRC_FLAG_NO_COPY)\n\n        buf = picref;\n\n    else\n\n        buf = copy_buffer_ref(buffer_filter, picref);\n\n\n\n\n\n    if ((ret = av_fifo_generic_write(c->fifo, &buf, sizeof(buf), NULL)) < 0) {\n\n        if (buf != picref)\n\n            avfilter_unref_buffer(buf);\n\n        return ret;\n\n    }\n\n    c->nb_failed_requests = 0;\n\n\n\n    return 0;\n\n}", "idx": 25566}
{"project": "FFmpeg", "commit_id": "51b0694bc051cda2bfed048a35e694d1047c6ef0", "target": 0, "func": "const DVprofile* ff_dv_frame_profile2(AVCodecContext* codec, const DVprofile *sys,\n\n                                  const uint8_t* frame, unsigned buf_size)\n\n{\n\n   int i;\n\n\n\n   int dsf = (frame[3] & 0x80) >> 7;\n\n\n\n   int stype = frame[80*5 + 48 + 3] & 0x1f;\n\n\n\n   /* 576i50 25Mbps 4:1:1 is a special case */\n\n   if (dsf == 1 && stype == 0 && frame[4] & 0x07 /* the APT field */) {\n\n       return &dv_profiles[2];\n\n   }\n\n\n\n   if(codec && codec->codec_tag==AV_RL32(\"dvsd\") &&  codec->width==720 && codec->height==576)\n\n       return &dv_profiles[1];\n\n\n\n   for (i=0; i<FF_ARRAY_ELEMS(dv_profiles); i++)\n\n       if (dsf == dv_profiles[i].dsf && stype == dv_profiles[i].video_stype)\n\n           return &dv_profiles[i];\n\n\n\n   /* check if old sys matches and assumes corrupted input */\n\n   if (sys && buf_size == sys->frame_size)\n\n       return sys;\n\n\n\n   return NULL;\n\n}\n", "idx": 25577}
{"project": "FFmpeg", "commit_id": "a8bdf2405c6027f45a899eaaa6ba74e97c1c2701", "target": 1, "func": "static av_cold int libgsm_encode_init(AVCodecContext *avctx) {\n\n    if (avctx->channels > 1) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Mono required for GSM, got %d channels\\n\",\n\n               avctx->channels);\n\n        return -1;\n\n\n\n\n    if (avctx->sample_rate != 8000) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Sample rate 8000Hz required for GSM, got %dHz\\n\",\n\n               avctx->sample_rate);\n\n        if (avctx->strict_std_compliance > FF_COMPLIANCE_UNOFFICIAL)\n\n            return -1;\n\n\n    if (avctx->bit_rate != 13000 /* Official */ &&\n\n        avctx->bit_rate != 13200 /* Very common */ &&\n\n        avctx->bit_rate != 0 /* Unknown; a.o. mov does not set bitrate when decoding */ ) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Bitrate 13000bps required for GSM, got %dbps\\n\",\n\n               avctx->bit_rate);\n\n        if (avctx->strict_std_compliance > FF_COMPLIANCE_UNOFFICIAL)\n\n            return -1;\n\n\n\n\n    avctx->priv_data = gsm_create();\n\n\n\n    switch(avctx->codec_id) {\n\n    case CODEC_ID_GSM:\n\n        avctx->frame_size = GSM_FRAME_SIZE;\n\n        avctx->block_align = GSM_BLOCK_SIZE;\n\n        break;\n\n    case CODEC_ID_GSM_MS: {\n\n        int one = 1;\n\n        gsm_option(avctx->priv_data, GSM_OPT_WAV49, &one);\n\n        avctx->frame_size = 2*GSM_FRAME_SIZE;\n\n        avctx->block_align = GSM_MS_BLOCK_SIZE;\n\n\n\n\n\n    avctx->coded_frame= avcodec_alloc_frame();\n\n\n\n\n\n\n\n    return 0;\n", "idx": 25589}
{"project": "FFmpeg", "commit_id": "bcd7bf7eeb09a395cc01698842d1b8be9af483fc", "target": 0, "func": "static void avc_wgt_4x2_msa(uint8_t *data,\n\n                            int32_t stride,\n\n                            int32_t log2_denom,\n\n                            int32_t src_weight,\n\n                            int32_t offset_in)\n\n{\n\n    uint32_t data0, data1;\n\n    v16u8 zero = { 0 };\n\n    v16u8 src0, src1;\n\n    v4i32 res0, res1;\n\n    v8i16 temp0, temp1;\n\n    v16u8 vec0, vec1;\n\n    v8i16 wgt, denom, offset;\n\n\n\n    offset_in <<= (log2_denom);\n\n\n\n    if (log2_denom) {\n\n        offset_in += (1 << (log2_denom - 1));\n\n    }\n\n\n\n    wgt = __msa_fill_h(src_weight);\n\n    offset = __msa_fill_h(offset_in);\n\n    denom = __msa_fill_h(log2_denom);\n\n\n\n    data0 = LOAD_WORD(data);\n\n    data1 = LOAD_WORD(data + stride);\n\n\n\n    src0 = (v16u8) __msa_fill_w(data0);\n\n    src1 = (v16u8) __msa_fill_w(data1);\n\n\n\n    ILVR_B_2VECS_UB(src0, src1, zero, zero, vec0, vec1);\n\n\n\n    temp0 = wgt * (v8i16) vec0;\n\n    temp1 = wgt * (v8i16) vec1;\n\n\n\n    temp0 = __msa_adds_s_h(temp0, offset);\n\n    temp1 = __msa_adds_s_h(temp1, offset);\n\n\n\n    temp0 = __msa_maxi_s_h(temp0, 0);\n\n    temp1 = __msa_maxi_s_h(temp1, 0);\n\n\n\n    temp0 = __msa_srl_h(temp0, denom);\n\n    temp1 = __msa_srl_h(temp1, denom);\n\n\n\n    temp0 = (v8i16) __msa_sat_u_h((v8u16) temp0, 7);\n\n    temp1 = (v8i16) __msa_sat_u_h((v8u16) temp1, 7);\n\n\n\n    res0 = (v4i32) __msa_pckev_b((v16i8) temp0, (v16i8) temp0);\n\n    res1 = (v4i32) __msa_pckev_b((v16i8) temp1, (v16i8) temp1);\n\n\n\n    data0 = __msa_copy_u_w(res0, 0);\n\n    data1 = __msa_copy_u_w(res1, 0);\n\n\n\n    STORE_WORD(data, data0);\n\n    data += stride;\n\n    STORE_WORD(data, data1);\n\n}\n", "idx": 25590}
{"project": "FFmpeg", "commit_id": "b9fa32082c71013e90eab9e9997967d2939cf4a6", "target": 1, "func": "void ff_imdct_calc_3dn2(MDCTContext *s, FFTSample *output,\n\n                        const FFTSample *input, FFTSample *tmp)\n\n{\n\n    long n8, n4, n2, n;\n\n    x86_reg k;\n\n    const uint16_t *revtab = s->fft.revtab;\n\n    const FFTSample *tcos = s->tcos;\n\n    const FFTSample *tsin = s->tsin;\n\n    const FFTSample *in1, *in2;\n\n    FFTComplex *z = (FFTComplex *)tmp;\n\n\n\n    n = 1 << s->nbits;\n\n    n2 = n >> 1;\n\n    n4 = n >> 2;\n\n    n8 = n >> 3;\n\n\n\n    /* pre rotation */\n\n    in1 = input;\n\n    in2 = input + n2 - 1;\n\n    for(k = 0; k < n4; k++) {\n\n        // FIXME a single block is faster, but gcc 2.95 and 3.4.x on 32bit can't compile it\n\n        asm volatile(\n\n            \"movd       %0, %%mm0 \\n\\t\"\n\n            \"movd       %2, %%mm1 \\n\\t\"\n\n            \"punpckldq  %1, %%mm0 \\n\\t\"\n\n            \"punpckldq  %3, %%mm1 \\n\\t\"\n\n            \"movq    %%mm0, %%mm2 \\n\\t\"\n\n            \"pfmul   %%mm1, %%mm0 \\n\\t\"\n\n            \"pswapd  %%mm1, %%mm1 \\n\\t\"\n\n            \"pfmul   %%mm1, %%mm2 \\n\\t\"\n\n            \"pfpnacc %%mm2, %%mm0 \\n\\t\"\n\n            ::\"m\"(in2[-2*k]), \"m\"(in1[2*k]),\n\n              \"m\"(tcos[k]), \"m\"(tsin[k])\n\n        );\n\n        asm volatile(\n\n            \"movq    %%mm0, %0    \\n\\t\"\n\n            :\"=m\"(z[revtab[k]])\n\n        );\n\n    }\n\n\n\n    ff_fft_calc(&s->fft, z);\n\n\n\n    /* post rotation + reordering */\n\n    for(k = 0; k < n4; k++) {\n\n        asm volatile(\n\n            \"movq       %0, %%mm0 \\n\\t\"\n\n            \"movd       %1, %%mm1 \\n\\t\"\n\n            \"punpckldq  %2, %%mm1 \\n\\t\"\n\n            \"movq    %%mm0, %%mm2 \\n\\t\"\n\n            \"pfmul   %%mm1, %%mm0 \\n\\t\"\n\n            \"pswapd  %%mm1, %%mm1 \\n\\t\"\n\n            \"pfmul   %%mm1, %%mm2 \\n\\t\"\n\n            \"pfpnacc %%mm2, %%mm0 \\n\\t\"\n\n            \"movq    %%mm0, %0    \\n\\t\"\n\n            :\"+m\"(z[k])\n\n            :\"m\"(tcos[k]), \"m\"(tsin[k])\n\n        );\n\n    }\n\n\n\n    k = n-8;\n\n    asm volatile(\"movd %0, %%mm7\" ::\"r\"(1<<31));\n\n    asm volatile(\n\n        \"1: \\n\\t\"\n\n        \"movq    (%4,%0), %%mm0 \\n\\t\" // z[n8+k]\n\n        \"neg %0 \\n\\t\"\n\n        \"pswapd -8(%4,%0), %%mm1 \\n\\t\" // z[n8-1-k]\n\n        \"movq      %%mm0, %%mm2 \\n\\t\"\n\n        \"pxor      %%mm7, %%mm2 \\n\\t\"\n\n        \"punpckldq %%mm1, %%mm2 \\n\\t\"\n\n        \"pswapd    %%mm2, %%mm3 \\n\\t\"\n\n        \"punpckhdq %%mm1, %%mm0 \\n\\t\"\n\n        \"pswapd    %%mm0, %%mm4 \\n\\t\"\n\n        \"pxor      %%mm7, %%mm0 \\n\\t\"\n\n        \"pxor      %%mm7, %%mm4 \\n\\t\"\n\n        \"movq      %%mm3, -8(%3,%0) \\n\\t\" // output[n-2-2*k] = { z[n8-1-k].im, -z[n8+k].re }\n\n        \"movq      %%mm4, -8(%2,%0) \\n\\t\" // output[n2-2-2*k]= { -z[n8-1-k].re, z[n8+k].im }\n\n        \"neg %0 \\n\\t\"\n\n        \"movq      %%mm0, (%1,%0) \\n\\t\"   // output[2*k]     = { -z[n8+k].im, z[n8-1-k].re }\n\n        \"movq      %%mm2, (%2,%0) \\n\\t\"   // output[n2+2*k]  = { -z[n8+k].re, z[n8-1-k].im }\n\n        \"sub $8, %0 \\n\\t\"\n\n        \"jge 1b \\n\\t\"\n\n        :\"+r\"(k)\n\n        :\"r\"(output), \"r\"(output+n2), \"r\"(output+n), \"r\"(z+n8)\n\n        :\"memory\"\n\n    );\n\n    asm volatile(\"femms\");\n\n}\n", "idx": 25592}
{"project": "FFmpeg", "commit_id": "8be23d424feea50d4ee892cdbdd6abd9a807709f", "target": 0, "func": "static av_cold int roq_decode_init(AVCodecContext *avctx)\n\n{\n\n    RoqContext *s = avctx->priv_data;\n\n\n\n    s->avctx = avctx;\n\n\n\n    if (avctx->width % 16 || avctx->height % 16) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Dimensions must be a multiple of 16\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    s->width = avctx->width;\n\n    s->height = avctx->height;\n\n\n\n    s->last_frame    = av_frame_alloc();\n\n    s->current_frame = av_frame_alloc();\n\n    if (!s->current_frame || !s->last_frame) {\n\n        av_frame_free(&s->current_frame);\n\n        av_frame_free(&s->last_frame);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    avctx->pix_fmt = AV_PIX_FMT_YUV444P;\n\n\n\n    return 0;\n\n}\n", "idx": 25593}
{"project": "FFmpeg", "commit_id": "6796a1dd8c14843b77925cb83a3ef88706ae1dd0", "target": 0, "func": "void ff_put_h264_qpel8_mc01_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_vt_qrt_8w_msa(src - (stride * 2), stride, dst, stride, 8, 0);\n\n}\n", "idx": 25594}
{"project": "FFmpeg", "commit_id": "8b00ab0113a8ca40429e0a06331be83996963a9e", "target": 0, "func": "int attribute_align_arg avcodec_open(AVCodecContext *avctx, AVCodec *codec)\n\n{\n\n    int ret = 0;\n\n\n\n    /* If there is a user-supplied mutex locking routine, call it. */\n\n    if (ff_lockmgr_cb) {\n\n        if ((*ff_lockmgr_cb)(&codec_mutex, AV_LOCK_OBTAIN))\n\n            return -1;\n\n    }\n\n\n\n    entangled_thread_counter++;\n\n    if(entangled_thread_counter != 1){\n\n        av_log(avctx, AV_LOG_ERROR, \"insufficient thread locking around avcodec_open/close()\\n\");\n\n        ret = -1;\n\n        goto end;\n\n    }\n\n\n\n    if(avctx->codec || !codec) {\n\n        ret = AVERROR(EINVAL);\n\n        goto end;\n\n    }\n\n\n\n    if (codec->priv_data_size > 0) {\n\n      if(!avctx->priv_data){\n\n        avctx->priv_data = av_mallocz(codec->priv_data_size);\n\n        if (!avctx->priv_data) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto end;\n\n        }\n\n        if(codec->priv_class){ //this can be droped once all user apps use   avcodec_get_context_defaults3()\n\n            *(AVClass**)avctx->priv_data= codec->priv_class;\n\n            av_opt_set_defaults(avctx->priv_data);\n\n        }\n\n      }\n\n    } else {\n\n        avctx->priv_data = NULL;\n\n    }\n\n\n\n    if(avctx->coded_width && avctx->coded_height)\n\n        avcodec_set_dimensions(avctx, avctx->coded_width, avctx->coded_height);\n\n    else if(avctx->width && avctx->height)\n\n        avcodec_set_dimensions(avctx, avctx->width, avctx->height);\n\n\n\n    if ((avctx->coded_width || avctx->coded_height || avctx->width || avctx->height)\n\n        && (  av_image_check_size(avctx->coded_width, avctx->coded_height, 0, avctx) < 0\n\n           || av_image_check_size(avctx->width,       avctx->height,       0, avctx) < 0)) {\n\n        av_log(avctx, AV_LOG_WARNING, \"ignoring invalid width/height values\\n\");\n\n        avcodec_set_dimensions(avctx, 0, 0);\n\n    }\n\n\n\n    /* if the decoder init function was already called previously,\n\n       free the already allocated subtitle_header before overwriting it */\n\n    if (codec->decode)\n\n        av_freep(&avctx->subtitle_header);\n\n\n\n#define SANE_NB_CHANNELS 128U\n\n    if (avctx->channels > SANE_NB_CHANNELS) {\n\n        ret = AVERROR(EINVAL);\n\n        goto free_and_end;\n\n    }\n\n\n\n    avctx->codec = codec;\n\n    if ((avctx->codec_type == AVMEDIA_TYPE_UNKNOWN || avctx->codec_type == codec->type) &&\n\n        avctx->codec_id == CODEC_ID_NONE) {\n\n        avctx->codec_type = codec->type;\n\n        avctx->codec_id   = codec->id;\n\n    }\n\n    if (avctx->codec_id != codec->id || (avctx->codec_type != codec->type\n\n                           && avctx->codec_type != AVMEDIA_TYPE_ATTACHMENT)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"codec type or id mismatches\\n\");\n\n        ret = AVERROR(EINVAL);\n\n        goto free_and_end;\n\n    }\n\n    avctx->frame_number = 0;\n\n\n\n    if (HAVE_THREADS && !avctx->thread_opaque) {\n\n        ret = ff_thread_init(avctx);\n\n        if (ret < 0) {\n\n            goto free_and_end;\n\n        }\n\n    }\n\n\n\n    if (avctx->codec->max_lowres < avctx->lowres) {\n\n        av_log(avctx, AV_LOG_ERROR, \"The maximum value for lowres supported by the decoder is %d\\n\",\n\n               avctx->codec->max_lowres);\n\n        ret = AVERROR(EINVAL);\n\n        goto free_and_end;\n\n    }\n\n    if (avctx->codec->sample_fmts && avctx->codec->encode) {\n\n        int i;\n\n        for (i = 0; avctx->codec->sample_fmts[i] != AV_SAMPLE_FMT_NONE; i++)\n\n            if (avctx->sample_fmt == avctx->codec->sample_fmts[i])\n\n                break;\n\n        if (avctx->codec->sample_fmts[i] == AV_SAMPLE_FMT_NONE) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Specified sample_fmt is not supported.\\n\");\n\n            ret = AVERROR(EINVAL);\n\n            goto free_and_end;\n\n        }\n\n    }\n\n\n\n    if(avctx->codec->init && !(avctx->active_thread_type&FF_THREAD_FRAME)){\n\n        ret = avctx->codec->init(avctx);\n\n        if (ret < 0) {\n\n            goto free_and_end;\n\n        }\n\n    }\n\nend:\n\n    entangled_thread_counter--;\n\n\n\n    /* Release any user-supplied mutex. */\n\n    if (ff_lockmgr_cb) {\n\n        (*ff_lockmgr_cb)(&codec_mutex, AV_LOCK_RELEASE);\n\n    }\n\n    return ret;\n\nfree_and_end:\n\n    av_freep(&avctx->priv_data);\n\n    avctx->codec= NULL;\n\n    goto end;\n\n}\n", "idx": 25595}
{"project": "FFmpeg", "commit_id": "3deb4b54a24f8cddce463d9f5751b01efeb976af", "target": 0, "func": "static int synth_superframe(AVCodecContext *ctx, AVFrame *frame,\n\n                            int *got_frame_ptr)\n\n{\n\n    WMAVoiceContext *s = ctx->priv_data;\n\n    GetBitContext *gb = &s->gb, s_gb;\n\n    int n, res, n_samples = 480;\n\n    double lsps[MAX_FRAMES][MAX_LSPS];\n\n    const double *mean_lsf = s->lsps == 16 ?\n\n        wmavoice_mean_lsf16[s->lsp_def_mode] : wmavoice_mean_lsf10[s->lsp_def_mode];\n\n    float excitation[MAX_SIGNAL_HISTORY + MAX_SFRAMESIZE + 12];\n\n    float synth[MAX_LSPS + MAX_SFRAMESIZE];\n\n    float *samples;\n\n\n\n    memcpy(synth,      s->synth_history,\n\n           s->lsps             * sizeof(*synth));\n\n    memcpy(excitation, s->excitation_history,\n\n           s->history_nsamples * sizeof(*excitation));\n\n\n\n    if (s->sframe_cache_size > 0) {\n\n        gb = &s_gb;\n\n        init_get_bits(gb, s->sframe_cache, s->sframe_cache_size);\n\n        s->sframe_cache_size = 0;\n\n    }\n\n\n\n    if ((res = check_bits_for_superframe(gb, s)) == 1) {\n\n        *got_frame_ptr = 0;\n\n        return 1;\n\n    } else if (res < 0)\n\n        return res;\n\n\n\n    /* First bit is speech/music bit, it differentiates between WMAVoice\n\n     * speech samples (the actual codec) and WMAVoice music samples, which\n\n     * are really WMAPro-in-WMAVoice-superframes. I've never seen those in\n\n     * the wild yet. */\n\n    if (!get_bits1(gb)) {\n\n        avpriv_request_sample(ctx, \"WMAPro-in-WMAVoice\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    /* (optional) nr. of samples in superframe; always <= 480 and >= 0 */\n\n    if (get_bits1(gb)) {\n\n        if ((n_samples = get_bits(gb, 12)) > 480) {\n\n            av_log(ctx, AV_LOG_ERROR,\n\n                   \"Superframe encodes >480 samples (%d), not allowed\\n\",\n\n                   n_samples);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n    /* Parse LSPs, if global for the superframe (can also be per-frame). */\n\n    if (s->has_residual_lsps) {\n\n        double prev_lsps[MAX_LSPS], a1[MAX_LSPS * 2], a2[MAX_LSPS * 2];\n\n\n\n        for (n = 0; n < s->lsps; n++)\n\n            prev_lsps[n] = s->prev_lsps[n] - mean_lsf[n];\n\n\n\n        if (s->lsps == 10) {\n\n            dequant_lsp10r(gb, lsps[2], prev_lsps, a1, a2, s->lsp_q_mode);\n\n        } else /* s->lsps == 16 */\n\n            dequant_lsp16r(gb, lsps[2], prev_lsps, a1, a2, s->lsp_q_mode);\n\n\n\n        for (n = 0; n < s->lsps; n++) {\n\n            lsps[0][n]  = mean_lsf[n] + (a1[n]           - a2[n * 2]);\n\n            lsps[1][n]  = mean_lsf[n] + (a1[s->lsps + n] - a2[n * 2 + 1]);\n\n            lsps[2][n] += mean_lsf[n];\n\n        }\n\n        for (n = 0; n < 3; n++)\n\n            stabilize_lsps(lsps[n], s->lsps);\n\n    }\n\n\n\n    /* get output buffer */\n\n    frame->nb_samples = 480;\n\n    if ((res = ff_get_buffer(ctx, frame, 0)) < 0)\n\n        return res;\n\n    frame->nb_samples = n_samples;\n\n    samples = (float *)frame->data[0];\n\n\n\n    /* Parse frames, optionally preceded by per-frame (independent) LSPs. */\n\n    for (n = 0; n < 3; n++) {\n\n        if (!s->has_residual_lsps) {\n\n            int m;\n\n\n\n            if (s->lsps == 10) {\n\n                dequant_lsp10i(gb, lsps[n]);\n\n            } else /* s->lsps == 16 */\n\n                dequant_lsp16i(gb, lsps[n]);\n\n\n\n            for (m = 0; m < s->lsps; m++)\n\n                lsps[n][m] += mean_lsf[m];\n\n            stabilize_lsps(lsps[n], s->lsps);\n\n        }\n\n\n\n        if ((res = synth_frame(ctx, gb, n,\n\n                               &samples[n * MAX_FRAMESIZE],\n\n                               lsps[n], n == 0 ? s->prev_lsps : lsps[n - 1],\n\n                               &excitation[s->history_nsamples + n * MAX_FRAMESIZE],\n\n                               &synth[s->lsps + n * MAX_FRAMESIZE]))) {\n\n            *got_frame_ptr = 0;\n\n            return res;\n\n        }\n\n    }\n\n\n\n    /* Statistics? FIXME - we don't check for length, a slight overrun\n\n     * will be caught by internal buffer padding, and anything else\n\n     * will be skipped, not read. */\n\n    if (get_bits1(gb)) {\n\n        res = get_bits(gb, 4);\n\n        skip_bits(gb, 10 * (res + 1));\n\n    }\n\n\n\n    *got_frame_ptr = 1;\n\n\n\n    /* Update history */\n\n    memcpy(s->prev_lsps,           lsps[2],\n\n           s->lsps             * sizeof(*s->prev_lsps));\n\n    memcpy(s->synth_history,      &synth[MAX_SFRAMESIZE],\n\n           s->lsps             * sizeof(*synth));\n\n    memcpy(s->excitation_history, &excitation[MAX_SFRAMESIZE],\n\n           s->history_nsamples * sizeof(*excitation));\n\n    if (s->do_apf)\n\n        memmove(s->zero_exc_pf,       &s->zero_exc_pf[MAX_SFRAMESIZE],\n\n                s->history_nsamples * sizeof(*s->zero_exc_pf));\n\n\n\n    return 0;\n\n}\n", "idx": 25596}
{"project": "FFmpeg", "commit_id": "5029a406334ad0eaf92130e23d596e405a8a5aa0", "target": 1, "func": "static void free_picture(MpegEncContext *s, Picture *pic){\n\n    int i;\n\n\n\n    if(pic->data[0] && pic->type!=FF_BUFFER_TYPE_SHARED){\n\n        free_frame_buffer(s, pic);\n\n    }\n\n\n\n    av_freep(&pic->mb_var);\n\n    av_freep(&pic->mc_mb_var);\n\n    av_freep(&pic->mb_mean);\n\n    av_freep(&pic->mbskip_table);\n\n    av_freep(&pic->qscale_table);\n\n    av_freep(&pic->mb_type_base);\n\n    av_freep(&pic->dct_coeff);\n\n    av_freep(&pic->pan_scan);\n\n    pic->mb_type= NULL;\n\n    for(i=0; i<2; i++){\n\n        av_freep(&pic->motion_val_base[i]);\n\n        av_freep(&pic->ref_index[i]);\n\n    }\n\n\n\n    if(pic->type == FF_BUFFER_TYPE_SHARED){\n\n        for(i=0; i<4; i++){\n\n            pic->base[i]=\n\n            pic->data[i]= NULL;\n\n        }\n\n        pic->type= 0;\n\n    }\n\n}\n", "idx": 25598}
{"project": "FFmpeg", "commit_id": "4533d2d67f28860304cdaa8aa0b3db85f368810e", "target": 1, "func": "static int mov_read_close(AVFormatContext *s)\n\n{\n\n    int i;\n\n    MOVContext *mov = s->priv_data;\n\n    for(i=0; i<mov->total_streams; i++)\n\n        mov_free_stream_context(mov->streams[i]);\n\n    for(i=0; i<s->nb_streams; i++)\n\n        av_free(s->streams[i]);\n\n    return 0;\n\n}\n", "idx": 25601}
{"project": "FFmpeg", "commit_id": "7caee063a0b71a2b9bdd21f508bb39b6b7a83ceb", "target": 1, "func": "static int aac_decode_frame(AVCodecContext *avccontext, void *data,\n\n                            int *data_size, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    AACContext *ac = avccontext->priv_data;\n\n    ChannelElement *che = NULL, *che_prev = NULL;\n\n    GetBitContext gb;\n\n    enum RawDataBlockType elem_type, elem_type_prev = TYPE_END;\n\n    int err, elem_id, data_size_tmp;\n\n    int buf_consumed;\n\n    int samples = 1024, multiplier;\n\n    int buf_offset;\n\n\n\n    init_get_bits(&gb, buf, buf_size * 8);\n\n\n\n    if (show_bits(&gb, 12) == 0xfff) {\n\n        if (parse_adts_frame_header(ac, &gb) < 0) {\n\n            av_log(avccontext, AV_LOG_ERROR, \"Error decoding AAC frame header.\\n\");\n\n            return -1;\n\n        }\n\n        if (ac->m4ac.sampling_index > 12) {\n\n            av_log(ac->avccontext, AV_LOG_ERROR, \"invalid sampling rate index %d\\n\", ac->m4ac.sampling_index);\n\n            return -1;\n\n        }\n\n    }\n\n\n\n\n    // parse\n\n    while ((elem_type = get_bits(&gb, 3)) != TYPE_END) {\n\n        elem_id = get_bits(&gb, 4);\n\n\n\n        if (elem_type < TYPE_DSE && !(che=get_che(ac, elem_type, elem_id))) {\n\n            av_log(ac->avccontext, AV_LOG_ERROR, \"channel element %d.%d is not allocated\\n\", elem_type, elem_id);\n\n            return -1;\n\n        }\n\n\n\n        switch (elem_type) {\n\n\n\n        case TYPE_SCE:\n\n            err = decode_ics(ac, &che->ch[0], &gb, 0, 0);\n\n            break;\n\n\n\n        case TYPE_CPE:\n\n            err = decode_cpe(ac, &gb, che);\n\n            break;\n\n\n\n        case TYPE_CCE:\n\n            err = decode_cce(ac, &gb, che);\n\n            break;\n\n\n\n        case TYPE_LFE:\n\n            err = decode_ics(ac, &che->ch[0], &gb, 0, 0);\n\n            break;\n\n\n\n        case TYPE_DSE:\n\n            err = skip_data_stream_element(ac, &gb);\n\n            break;\n\n\n\n        case TYPE_PCE: {\n\n            enum ChannelPosition new_che_pos[4][MAX_ELEM_ID];\n\n            memset(new_che_pos, 0, 4 * MAX_ELEM_ID * sizeof(new_che_pos[0][0]));\n\n            if ((err = decode_pce(ac, new_che_pos, &gb)))\n\n                break;\n\n            if (ac->output_configured > OC_TRIAL_PCE)\n\n                av_log(avccontext, AV_LOG_ERROR,\n\n                       \"Not evaluating a further program_config_element as this construct is dubious at best.\\n\");\n\n            else\n\n                err = output_configure(ac, ac->che_pos, new_che_pos, 0, OC_TRIAL_PCE);\n\n            break;\n\n        }\n\n\n\n        case TYPE_FIL:\n\n            if (elem_id == 15)\n\n                elem_id += get_bits(&gb, 8) - 1;\n\n            if (get_bits_left(&gb) < 8 * elem_id) {\n\n                    av_log(avccontext, AV_LOG_ERROR, overread_err);\n\n                    return -1;\n\n            }\n\n            while (elem_id > 0)\n\n                elem_id -= decode_extension_payload(ac, &gb, elem_id, che_prev, elem_type_prev);\n\n            err = 0; /* FIXME */\n\n            break;\n\n\n\n        default:\n\n            err = -1; /* should not happen, but keeps compiler happy */\n\n            break;\n\n        }\n\n\n\n        che_prev       = che;\n\n        elem_type_prev = elem_type;\n\n\n\n        if (err)\n\n            return err;\n\n\n\n        if (get_bits_left(&gb) < 3) {\n\n            av_log(avccontext, AV_LOG_ERROR, overread_err);\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    spectral_to_sample(ac);\n\n\n\n    multiplier = (ac->m4ac.sbr == 1) ? ac->m4ac.ext_sample_rate > ac->m4ac.sample_rate : 0;\n\n    samples <<= multiplier;\n\n    if (ac->output_configured < OC_LOCKED) {\n\n        avccontext->sample_rate = ac->m4ac.sample_rate << multiplier;\n\n        avccontext->frame_size = samples;\n\n    }\n\n\n\n    data_size_tmp = samples * avccontext->channels * sizeof(int16_t);\n\n    if (*data_size < data_size_tmp) {\n\n        av_log(avccontext, AV_LOG_ERROR,\n\n               \"Output buffer too small (%d) or trying to output too many samples (%d) for this frame.\\n\",\n\n               *data_size, data_size_tmp);\n\n        return -1;\n\n    }\n\n    *data_size = data_size_tmp;\n\n\n\n    ac->dsp.float_to_int16_interleave(data, (const float **)ac->output_data, samples, avccontext->channels);\n\n\n\n    if (ac->output_configured)\n\n        ac->output_configured = OC_LOCKED;\n\n\n\n    buf_consumed = (get_bits_count(&gb) + 7) >> 3;\n\n    for (buf_offset = buf_consumed; buf_offset < buf_size; buf_offset++)\n\n        if (buf[buf_offset])\n\n            break;\n\n\n\n    return buf_size > buf_offset ? buf_consumed : buf_size;\n\n}", "idx": 25603}
{"project": "FFmpeg", "commit_id": "6df5f6ae51ca3e9f3af760066bc7b3423677a8b4", "target": 1, "func": "static inline void dv_guess_qnos(EncBlockInfo* blks, int* qnos)\n\n{\n\n    int size[5];\n\n    int i, j, k, a, prev, a2;\n\n    EncBlockInfo* b;\n\n\n\n    size[4]= 1<<24;\n\n    do {\n\n       b = blks;\n\n       for (i=0; i<5; i++) {\n\n          if (!qnos[i])\n\n              continue;\n\n\n\n          qnos[i]--;\n\n          size[i] = 0;\n\n          for (j=0; j<6; j++, b++) {\n\n             for (a=0; a<4; a++) {\n\n                if (b->area_q[a] != dv_quant_shifts[qnos[i] + dv_quant_offset[b->cno]][a]) {\n\n                    b->bit_size[a] = 1; // 4 areas 4 bits for EOB :)\n\n                    b->area_q[a]++;\n\n                    prev= b->prev[a];\n\n                    for (k= b->next[prev] ; k<mb_area_start[a+1]; k= b->next[k]) {\n\n                       b->mb[k] >>= 1;\n\n                       if (b->mb[k]) {\n\n                           b->bit_size[a] += dv_rl2vlc_size(k - prev - 1, b->mb[k]);\n\n                           prev= k;\n\n                       } else {\n\n                           if(b->next[k] >= mb_area_start[a+1] && b->next[k]<64){\n\n                                for(a2=a+1; b->next[k] >= mb_area_start[a2+1]; a2++);\n\n                                assert(a2<4);\n\n                                assert(b->mb[b->next[k]]);\n\n                                b->bit_size[a2] += dv_rl2vlc_size(b->next[k] - prev - 1, b->mb[b->next[k]])\n\n                                                  -dv_rl2vlc_size(b->next[k] -    k - 1, b->mb[b->next[k]]);\n\n                           }\n\n                           b->next[prev] = b->next[k];\n\n                       }\n\n                    }\n\n                    b->prev[a+1]= prev;\n\n                }\n\n                size[i] += b->bit_size[a];\n\n             }\n\n          }\n\n          if(vs_total_ac_bits >= size[0] + size[1] + size[2] + size[3] + size[4])\n\n                return;\n\n       }\n\n    } while (qnos[0]|qnos[1]|qnos[2]|qnos[3]|qnos[4]);\n\n\n\n\n\n    for(a=2; a==2 || vs_total_ac_bits < size[0]; a+=a){\n\n        b = blks;\n\n        size[0] = 5*6*4; //EOB\n\n        for (j=0; j<6*5; j++, b++) {\n\n            prev= b->prev[0];\n\n            for (k= b->next[prev]; k<64; k= b->next[k]) {\n\n                if(b->mb[k] < a && b->mb[k] > -a){\n\n                    b->next[prev] = b->next[k];\n\n                }else{\n\n                    size[0] += dv_rl2vlc_size(k - prev - 1, b->mb[k]);\n\n                    prev= k;\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 25604}
{"project": "FFmpeg", "commit_id": "bd8d28e2d2713f0368ee6b7dbb5ec251cbc162ac", "target": 0, "func": "static av_cold int hnm_decode_init(AVCodecContext *avctx)\n\n{\n\n    Hnm4VideoContext *hnm = avctx->priv_data;\n\n\n\n    if (avctx->extradata_size < 1) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Extradata missing, decoder requires version number\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    hnm->version   = avctx->extradata[0];\n\n    avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n    hnm->width     = avctx->width;\n\n    hnm->height    = avctx->height;\n\n    hnm->buffer1   = av_mallocz(avctx->width * avctx->height);\n\n    hnm->buffer2   = av_mallocz(avctx->width * avctx->height);\n\n    hnm->processed = av_mallocz(avctx->width * avctx->height);\n\n\n\n    if (!hnm->buffer1 || !hnm->buffer2 || !hnm->processed) {\n\n        av_log(avctx, AV_LOG_ERROR, \"av_mallocz() failed\\n\");\n\n        av_freep(&hnm->buffer1);\n\n        av_freep(&hnm->buffer2);\n\n        av_freep(&hnm->processed);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    hnm->current  = hnm->buffer1;\n\n    hnm->previous = hnm->buffer2;\n\n\n\n    return 0;\n\n}\n", "idx": 25605}
{"project": "FFmpeg", "commit_id": "3b55429d5692dd782d8b3ce6a19819305157d1b8", "target": 1, "func": "static int tqi_decode_frame(AVCodecContext *avctx,\n\n                            void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    const uint8_t *buf_end = buf+buf_size;\n\n    TqiContext *t = avctx->priv_data;\n\n    MpegEncContext *s = &t->s;\n\n\n\n    s->width  = AV_RL16(&buf[0]);\n\n    s->height = AV_RL16(&buf[2]);\n\n    tqi_calculate_qtable(s, buf[4]);\n\n    buf += 8;\n\n\n\n    if (t->frame.data[0])\n\n        avctx->release_buffer(avctx, &t->frame);\n\n\n\n    if (s->avctx->width!=s->width || s->avctx->height!=s->height)\n\n        avcodec_set_dimensions(s->avctx, s->width, s->height);\n\n\n\n    if(avctx->get_buffer(avctx, &t->frame) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    av_fast_malloc(&t->bitstream_buf, &t->bitstream_buf_size, (buf_end-buf) + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    if (!t->bitstream_buf)\n\n        return AVERROR(ENOMEM);\n\n    s->dsp.bswap_buf(t->bitstream_buf, (const uint32_t*)buf, (buf_end-buf)/4);\n\n    init_get_bits(&s->gb, t->bitstream_buf, 8*(buf_end-buf));\n\n\n\n    s->last_dc[0] = s->last_dc[1] = s->last_dc[2] = 0;\n\n    for (s->mb_y=0; s->mb_y<(avctx->height+15)/16; s->mb_y++)\n\n    for (s->mb_x=0; s->mb_x<(avctx->width+15)/16; s->mb_x++)\n\n    {\n\n        if(tqi_decode_mb(s, t->block) < 0)\n\n            break;\n\n        tqi_idct_put(t, t->block);\n\n    }\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame*)data = t->frame;\n\n    return buf_size;\n\n}\n", "idx": 25609}
{"project": "FFmpeg", "commit_id": "caedd51e56e2ad47991a1b8bddcfaa8f7094a060", "target": 1, "func": "static int mxf_compute_sample_count(MXFContext *mxf, int stream_index, uint64_t *sample_count)\n\n{\n\n    int i, total = 0, size = 0;\n\n    AVStream *st = mxf->fc->streams[stream_index];\n\n    MXFTrack *track = st->priv_data;\n\n    AVRational time_base = av_inv_q(track->edit_rate);\n\n    AVRational sample_rate = av_inv_q(st->time_base);\n\n    const MXFSamplesPerFrame *spf = NULL;\n\n\n\n    if ((sample_rate.num / sample_rate.den) == 48000)\n\n        spf = ff_mxf_get_samples_per_frame(mxf->fc, time_base);\n\n    if (!spf) {\n\n        int remainder = (sample_rate.num * time_base.num) % (time_base.den * sample_rate.den);\n\n        *sample_count = av_q2d(av_mul_q((AVRational){mxf->current_edit_unit, 1},\n\n                                        av_mul_q(sample_rate, time_base)));\n\n        if (remainder)\n\n            av_log(mxf->fc, AV_LOG_WARNING,\n\n                   \"seeking detected on stream #%d with time base (%d/%d) and sample rate (%d/%d), audio pts won't be accurate.\\n\",\n\n                   stream_index, time_base.num, time_base.den, sample_rate.num, sample_rate.den);\n\n        return 0;\n\n    }\n\n\n\n    while (spf->samples_per_frame[size]) {\n\n        total += spf->samples_per_frame[size];\n\n        size++;\n\n    }\n\n\n\n    av_assert2(size);\n\n\n\n    *sample_count = (mxf->current_edit_unit / size) * total;\n\n    for (i = 0; i < mxf->current_edit_unit % size; i++) {\n\n        *sample_count += spf->samples_per_frame[i];\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25610}
{"project": "FFmpeg", "commit_id": "8978c743fb1d1f5a0d6dbdd83ff05817f8a41230", "target": 1, "func": "static void sbr_dequant(SpectralBandReplication *sbr, int id_aac)\n\n{\n\n    int k, e;\n\n    int ch;\n\n\n\n    if (id_aac == TYPE_CPE && sbr->bs_coupling) {\n\n        float alpha      = sbr->data[0].bs_amp_res ?  1.0f :  0.5f;\n\n        float pan_offset = sbr->data[0].bs_amp_res ? 12.0f : 24.0f;\n\n        for (e = 1; e <= sbr->data[0].bs_num_env; e++) {\n\n            for (k = 0; k < sbr->n[sbr->data[0].bs_freq_res[e]]; k++) {\n\n                float temp1 = exp2f(sbr->data[0].env_facs[e][k] * alpha + 7.0f);\n\n                float temp2 = exp2f((pan_offset - sbr->data[1].env_facs[e][k]) * alpha);\n\n                float fac   = temp1 / (1.0f + temp2);\n\n                sbr->data[0].env_facs[e][k] = fac;\n\n                sbr->data[1].env_facs[e][k] = fac * temp2;\n\n            }\n\n        }\n\n        for (e = 1; e <= sbr->data[0].bs_num_noise; e++) {\n\n            for (k = 0; k < sbr->n_q; k++) {\n\n                float temp1 = exp2f(NOISE_FLOOR_OFFSET - sbr->data[0].noise_facs[e][k] + 1);\n\n                float temp2 = exp2f(12 - sbr->data[1].noise_facs[e][k]);\n\n                float fac   = temp1 / (1.0f + temp2);\n\n                sbr->data[0].noise_facs[e][k] = fac;\n\n                sbr->data[1].noise_facs[e][k] = fac * temp2;\n\n            }\n\n        }\n\n    } else { // SCE or one non-coupled CPE\n\n        for (ch = 0; ch < (id_aac == TYPE_CPE) + 1; ch++) {\n\n            float alpha = sbr->data[ch].bs_amp_res ? 1.0f : 0.5f;\n\n            for (e = 1; e <= sbr->data[ch].bs_num_env; e++)\n\n                for (k = 0; k < sbr->n[sbr->data[ch].bs_freq_res[e]]; k++)\n\n                    sbr->data[ch].env_facs[e][k] =\n\n                        exp2f(alpha * sbr->data[ch].env_facs[e][k] + 6.0f);\n\n            for (e = 1; e <= sbr->data[ch].bs_num_noise; e++)\n\n                for (k = 0; k < sbr->n_q; k++)\n\n                    sbr->data[ch].noise_facs[e][k] =\n\n                        exp2f(NOISE_FLOOR_OFFSET - sbr->data[ch].noise_facs[e][k]);\n\n        }\n\n    }\n\n}\n", "idx": 25612}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static inline int16_t logadd(int16_t a, int16_t b)\n\n{\n\n    int16_t c = a - b;\n\n    uint8_t address = FFMIN((ABS(c) >> 1), 255);\n\n\n\n    return ((c >= 0) ? (a + latab[address]) : (b + latab[address]));\n\n}\n", "idx": 25613}
{"project": "FFmpeg", "commit_id": "e65849a70bfb401306038d41ebd8b5750deb3cfd", "target": 1, "func": "static int write_manifest(AVFormatContext *s, int final)\n\n{\n\n    DASHContext *c = s->priv_data;\n\n    AVIOContext *out;\n\n    char temp_filename[1024];\n\n    int ret, i;\n\n    AVDictionaryEntry *title = av_dict_get(s->metadata, \"title\", NULL, 0);\n\n\n\n    snprintf(temp_filename, sizeof(temp_filename), \"%s.tmp\", s->filename);\n\n    ret = avio_open2(&out, temp_filename, AVIO_FLAG_WRITE, &s->interrupt_callback, NULL);\n\n    if (ret < 0) {\n\n        av_log(s, AV_LOG_ERROR, \"Unable to open %s for writing\\n\", temp_filename);\n\n        return ret;\n\n    }\n\n    avio_printf(out, \"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\\n\");\n\n    avio_printf(out, \"<MPD xmlns:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\"\\n\"\n\n                \"\\txmlns=\\\"urn:mpeg:dash:schema:mpd:2011\\\"\\n\"\n\n                \"\\txmlns:xlink=\\\"http://www.w3.org/1999/xlink\\\"\\n\"\n\n                \"\\txsi:schemaLocation=\\\"urn:mpeg:DASH:schema:MPD:2011 http://standards.iso.org/ittf/PubliclyAvailableStandards/MPEG-DASH_schema_files/DASH-MPD.xsd\\\"\\n\"\n\n                \"\\tprofiles=\\\"urn:mpeg:dash:profile:isoff-live:2011\\\"\\n\"\n\n                \"\\ttype=\\\"%s\\\"\\n\", final ? \"static\" : \"dynamic\");\n\n    if (final) {\n\n        avio_printf(out, \"\\tmediaPresentationDuration=\\\"\");\n\n        write_time(out, c->total_duration);\n\n        avio_printf(out, \"\\\"\\n\");\n\n    } else {\n\n        int update_period = c->last_duration / AV_TIME_BASE;\n\n        if (c->use_template && !c->use_timeline)\n\n            update_period = 500;\n\n        avio_printf(out, \"\\tminimumUpdatePeriod=\\\"PT%dS\\\"\\n\", update_period);\n\n        avio_printf(out, \"\\tsuggestedPresentationDelay=\\\"PT%dS\\\"\\n\", c->last_duration / AV_TIME_BASE);\n\n        if (!c->availability_start_time[0] && s->nb_streams > 0 && c->streams[0].nb_segments > 0) {\n\n            time_t t = time(NULL);\n\n            struct tm *ptm, tmbuf;\n\n            ptm = gmtime_r(&t, &tmbuf);\n\n            if (ptm) {\n\n                if (!strftime(c->availability_start_time, sizeof(c->availability_start_time),\n\n                              \"%Y-%m-%dT%H:%M:%S\", ptm))\n\n                    c->availability_start_time[0] = '\\0';\n\n            }\n\n        }\n\n        if (c->availability_start_time[0])\n\n            avio_printf(out, \"\\tavailabilityStartTime=\\\"%s\\\"\\n\", c->availability_start_time);\n\n        if (c->window_size && c->use_template) {\n\n            avio_printf(out, \"\\ttimeShiftBufferDepth=\\\"\");\n\n            write_time(out, c->last_duration * c->window_size);\n\n            avio_printf(out, \"\\\"\\n\");\n\n        }\n\n    }\n\n    avio_printf(out, \"\\tminBufferTime=\\\"\");\n\n    write_time(out, c->last_duration);\n\n    avio_printf(out, \"\\\">\\n\");\n\n    avio_printf(out, \"\\t<ProgramInformation>\\n\");\n\n    if (title) {\n\n        char *escaped = xmlescape(title->value);\n\n        avio_printf(out, \"\\t\\t<Title>%s</Title>\\n\", escaped);\n\n        av_free(escaped);\n\n    }\n\n    avio_printf(out, \"\\t</ProgramInformation>\\n\");\n\n    if (c->window_size && s->nb_streams > 0 && c->streams[0].nb_segments > 0 && !c->use_template) {\n\n        OutputStream *os = &c->streams[0];\n\n        int start_index = FFMAX(os->nb_segments - c->window_size, 0);\n\n        int64_t start_time = av_rescale_q(os->segments[start_index]->time, s->streams[0]->time_base, AV_TIME_BASE_Q);\n\n        avio_printf(out, \"\\t<Period start=\\\"\");\n\n        write_time(out, start_time);\n\n        avio_printf(out, \"\\\">\\n\");\n\n    } else {\n\n        avio_printf(out, \"\\t<Period start=\\\"PT0.0S\\\">\\n\");\n\n    }\n\n\n\n    if (c->has_video) {\n\n        avio_printf(out, \"\\t\\t<AdaptationSet id=\\\"video\\\" segmentAlignment=\\\"true\\\" bitstreamSwitching=\\\"true\\\">\\n\");\n\n        for (i = 0; i < s->nb_streams; i++) {\n\n            AVStream *st = s->streams[i];\n\n            OutputStream *os = &c->streams[i];\n\n            if (s->streams[i]->codec->codec_type != AVMEDIA_TYPE_VIDEO)\n\n                continue;\n\n            avio_printf(out, \"\\t\\t\\t<Representation id=\\\"%d\\\" mimeType=\\\"video/mp4\\\" codecs=\\\"%s\\\"%s width=\\\"%d\\\" height=\\\"%d\\\">\\n\", i, os->codec_str, os->bandwidth_str, st->codec->width, st->codec->height);\n\n            output_segment_list(&c->streams[i], out, c);\n\n            avio_printf(out, \"\\t\\t\\t</Representation>\\n\");\n\n        }\n\n        avio_printf(out, \"\\t\\t</AdaptationSet>\\n\");\n\n    }\n\n    if (c->has_audio) {\n\n        avio_printf(out, \"\\t\\t<AdaptationSet id=\\\"audio\\\" segmentAlignment=\\\"true\\\" bitstreamSwitching=\\\"true\\\">\\n\");\n\n        for (i = 0; i < s->nb_streams; i++) {\n\n            AVStream *st = s->streams[i];\n\n            OutputStream *os = &c->streams[i];\n\n            if (s->streams[i]->codec->codec_type != AVMEDIA_TYPE_AUDIO)\n\n                continue;\n\n            avio_printf(out, \"\\t\\t\\t<Representation id=\\\"%d\\\" mimeType=\\\"audio/mp4\\\" codecs=\\\"%s\\\"%s audioSamplingRate=\\\"%d\\\">\\n\", i, os->codec_str, os->bandwidth_str, st->codec->sample_rate);\n\n            avio_printf(out, \"\\t\\t\\t\\t<AudioChannelConfiguration schemeIdUri=\\\"urn:mpeg:dash:23003:3:audio_channel_configuration:2011\\\" value=\\\"%d\\\" />\\n\", st->codec->channels);\n\n            output_segment_list(&c->streams[i], out, c);\n\n            avio_printf(out, \"\\t\\t\\t</Representation>\\n\");\n\n        }\n\n        avio_printf(out, \"\\t\\t</AdaptationSet>\\n\");\n\n    }\n\n    avio_printf(out, \"\\t</Period>\\n\");\n\n    avio_printf(out, \"</MPD>\\n\");\n\n    avio_flush(out);\n\n    avio_close(out);\n\n    return ff_rename(temp_filename, s->filename, s);\n\n}\n", "idx": 25615}
{"project": "FFmpeg", "commit_id": "a557ae8d52ce1cfaf3be5cdb13728b7b2b9512b9", "target": 1, "func": "static int get_scale_factor(H264SliceContext *sl,\n\n                            int poc, int poc1, int i)\n\n{\n\n    int poc0 = sl->ref_list[0][i].poc;\n\n    int td = av_clip_int8(poc1 - poc0);\n\n    if (td == 0 || sl->ref_list[0][i].parent->long_ref) {\n\n        return 256;\n\n    } else {\n\n        int tb = av_clip_int8(poc - poc0);\n\n        int tx = (16384 + (FFABS(td) >> 1)) / td;\n\n        return av_clip_intp2((tb * tx + 32) >> 6, 10);\n\n    }\n\n}\n", "idx": 25616}
{"project": "FFmpeg", "commit_id": "349b65eee2fd5590b7e511c915dcd2d3aef3960e", "target": 0, "func": "static int get_video_frame(VideoState *is, AVFrame *frame, int64_t *pts, AVPacket *pkt)\n\n{\n\n    int got_picture, i;\n\n\n\n    if (packet_queue_get(&is->videoq, pkt, 1) < 0)\n\n        return -1;\n\n\n\n    if (pkt->data == flush_pkt.data) {\n\n        avcodec_flush_buffers(is->video_st->codec);\n\n\n\n        SDL_LockMutex(is->pictq_mutex);\n\n        // Make sure there are no long delay timers (ideally we should just flush the que but thats harder)\n\n        for (i = 0; i < VIDEO_PICTURE_QUEUE_SIZE; i++) {\n\n            is->pictq[i].skip = 1;\n\n        }\n\n        while (is->pictq_size && !is->videoq.abort_request) {\n\n            SDL_CondWait(is->pictq_cond, is->pictq_mutex);\n\n        }\n\n        is->video_current_pos = -1;\n\n        is->frame_last_pts = AV_NOPTS_VALUE;\n\n        is->frame_last_duration = 0;\n\n        is->frame_timer = (double)av_gettime() / 1000000.0;\n\n        is->frame_last_dropped_pts = AV_NOPTS_VALUE;\n\n        SDL_UnlockMutex(is->pictq_mutex);\n\n\n\n        return 0;\n\n    }\n\n\n\n    avcodec_decode_video2(is->video_st->codec, frame, &got_picture, pkt);\n\n\n\n    if (got_picture) {\n\n        int ret = 1;\n\n\n\n        if (decoder_reorder_pts == -1) {\n\n            *pts = av_frame_get_best_effort_timestamp(frame);\n\n        } else if (decoder_reorder_pts) {\n\n            *pts = frame->pkt_pts;\n\n        } else {\n\n            *pts = frame->pkt_dts;\n\n        }\n\n\n\n        if (*pts == AV_NOPTS_VALUE) {\n\n            *pts = 0;\n\n        }\n\n\n\n        if (((is->av_sync_type == AV_SYNC_AUDIO_MASTER && is->audio_st) || is->av_sync_type == AV_SYNC_EXTERNAL_CLOCK) &&\n\n             (framedrop>0 || (framedrop && is->audio_st))) {\n\n            SDL_LockMutex(is->pictq_mutex);\n\n            if (is->frame_last_pts != AV_NOPTS_VALUE && *pts) {\n\n                double clockdiff = get_video_clock(is) - get_master_clock(is);\n\n                double dpts = av_q2d(is->video_st->time_base) * *pts;\n\n                double ptsdiff = dpts - is->frame_last_pts;\n\n                if (fabs(clockdiff) < AV_NOSYNC_THRESHOLD &&\n\n                     ptsdiff > 0 && ptsdiff < AV_NOSYNC_THRESHOLD &&\n\n                     clockdiff + ptsdiff - is->frame_last_filter_delay < 0) {\n\n                    is->frame_last_dropped_pos = pkt->pos;\n\n                    is->frame_last_dropped_pts = dpts;\n\n                    is->frame_drops_early++;\n\n                    ret = 0;\n\n                }\n\n            }\n\n            SDL_UnlockMutex(is->pictq_mutex);\n\n        }\n\n\n\n        return ret;\n\n    }\n\n    return 0;\n\n}\n", "idx": 25618}
{"project": "FFmpeg", "commit_id": "76d81909ae65f5a771e3a58d6a5d6bb58bfed995", "target": 0, "func": "static int X264_frame(AVCodecContext *ctx, uint8_t *buf,\n\n                      int bufsize, void *data)\n\n{\n\n    X264Context *x4 = ctx->priv_data;\n\n    AVFrame *frame = data;\n\n    x264_nal_t *nal;\n\n    int nnal, i;\n\n    x264_picture_t pic_out;\n\n\n\n    x4->pic.img.i_csp   = X264_CSP_I420;\n\n    x4->pic.img.i_plane = 3;\n\n\n\n    if (frame) {\n\n        for (i = 0; i < 3; i++) {\n\n            x4->pic.img.plane[i]    = frame->data[i];\n\n            x4->pic.img.i_stride[i] = frame->linesize[i];\n\n        }\n\n\n\n        x4->pic.i_pts  = frame->pts;\n\n        x4->pic.i_type = X264_TYPE_AUTO;\n\n    }\n\n\n\n    if (x264_encoder_encode(x4->enc, &nal, &nnal, frame? &x4->pic: NULL, &pic_out) < 0)\n\n        return -1;\n\n\n\n    bufsize = encode_nals(ctx, buf, bufsize, nal, nnal, 0);\n\n    if (bufsize < 0)\n\n        return -1;\n\n\n\n    /* FIXME: dts */\n\n    x4->out_pic.pts = pic_out.i_pts;\n\n\n\n    switch (pic_out.i_type) {\n\n    case X264_TYPE_IDR:\n\n    case X264_TYPE_I:\n\n        x4->out_pic.pict_type = FF_I_TYPE;\n\n        break;\n\n    case X264_TYPE_P:\n\n        x4->out_pic.pict_type = FF_P_TYPE;\n\n        break;\n\n    case X264_TYPE_B:\n\n    case X264_TYPE_BREF:\n\n        x4->out_pic.pict_type = FF_B_TYPE;\n\n        break;\n\n    }\n\n\n\n    x4->out_pic.key_frame = pic_out.i_type == X264_TYPE_IDR;\n\n    x4->out_pic.quality   = (pic_out.i_qpplus1 - 1) * FF_QP2LAMBDA;\n\n\n\n    return bufsize;\n\n}\n", "idx": 25629}
{"project": "FFmpeg", "commit_id": "602dd8f6c4d4f7e1b5f48cc580fd9b694d41d602", "target": 0, "func": "static void fill_buffer(ByteIOContext *s)\n\n{\n\n    int len;\n\n\n\n    /* no need to do anything if EOF already reached */\n\n    if (s->eof_reached)\n\n        return;\n\n\n\n    if(s->update_checksum){\n\n        if(s->buf_end > s->checksum_ptr)\n\n            s->checksum= s->update_checksum(s->checksum, s->checksum_ptr, s->buf_end - s->checksum_ptr);\n\n        s->checksum_ptr= s->buffer;\n\n    }\n\n\n\n    len = s->read_packet(s->opaque, s->buffer, s->buffer_size);\n\n    if (len <= 0) {\n\n        /* do not modify buffer if EOF reached so that a seek back can\n\n           be done without rereading data */\n\n        s->eof_reached = 1;\n\n        if(len<0)\n\n            s->error= len;\n\n    } else {\n\n        s->pos += len;\n\n        s->buf_ptr = s->buffer;\n\n        s->buf_end = s->buffer + len;\n\n    }\n\n}\n", "idx": 25638}
{"project": "FFmpeg", "commit_id": "754ebd1a5b68dd63ccceb50a8a852fe8d0c94354", "target": 0, "func": "static int adx_encode_frame(AVCodecContext *avctx, uint8_t *frame,\n\n                            int buf_size, void *data)\n\n{\n\n    ADXContext *c          = avctx->priv_data;\n\n    const int16_t *samples = data;\n\n    uint8_t *dst           = frame;\n\n    int ch;\n\n\n\n    if (!c->header_parsed) {\n\n        int hdrsize = adx_encode_header(avctx, dst, buf_size);\n\n        dst += hdrsize;\n\n        c->header_parsed = 1;\n\n    }\n\n\n\n    for (ch = 0; ch < avctx->channels; ch++) {\n\n        adx_encode(c, dst, samples + ch, &c->prev[ch], avctx->channels);\n\n        dst += BLOCK_SIZE;\n\n    }\n\n    return dst - frame;\n\n}\n", "idx": 25639}
{"project": "FFmpeg", "commit_id": "43a4276c6964a2ec57e08c3c622bb94d35c0441f", "target": 0, "func": "static int bmp_parse(AVCodecParserContext *s, AVCodecContext *avctx,\n\n                     const uint8_t **poutbuf, int *poutbuf_size,\n\n                     const uint8_t *buf, int buf_size)\n\n{\n\n    BMPParseContext *bpc = s->priv_data;\n\n    uint64_t state = bpc->pc.state64;\n\n    int next = END_NOT_FOUND;\n\n    int i = 0;\n\n\n\n    *poutbuf_size = 0;\n\n\n\nrestart:\n\n    if (bpc->pc.frame_start_found <= 2+4+4) {\n\n        for (; i < buf_size; i++) {\n\n            state = (state << 8) | buf[i];\n\n            if (bpc->pc.frame_start_found == 0) {\n\n                if ((state >> 48) == (('B' << 8) | 'M')) {\n\n                    bpc->fsize = av_bswap32(state >> 16);\n\n                    bpc->pc.frame_start_found = 1;\n\n                }\n\n            } else if (bpc->pc.frame_start_found == 2+4+4) {\n\n//                 unsigned hsize = av_bswap32(state>>32);\n\n                unsigned ihsize = av_bswap32(state);\n\n                if (ihsize < 12 || ihsize > 200) {\n\n                    bpc->pc.frame_start_found = 0;\n\n                    continue;\n\n                }\n\n                bpc->pc.frame_start_found++;\n\n                bpc->remaining_size = bpc->fsize + i - 17;\n\n\n\n                if (bpc->pc.index + i > 17) {\n\n                    next = i - 17;\n\n                    state = 0;\n\n                    break;\n\n                } else {\n\n                    bpc->pc.state64 = 0;\n\n                    goto restart;\n\n                }\n\n            } else if (bpc->pc.frame_start_found)\n\n                bpc->pc.frame_start_found++;\n\n        }\n\n        bpc->pc.state64 = state;\n\n    } else {\n\n        if (bpc->remaining_size) {\n\n            i = FFMIN(bpc->remaining_size, buf_size);\n\n            bpc->remaining_size -= i;\n\n            if (bpc->remaining_size)\n\n                goto flush;\n\n\n\n            bpc->pc.frame_start_found = 0;\n\n            goto restart;\n\n        }\n\n    }\n\n\n\nflush:\n\n    if (ff_combine_frame(&bpc->pc, next, &buf, &buf_size) < 0)\n\n        return buf_size;\n\n\n\n    if (next != END_NOT_FOUND && next < 0)\n\n        bpc->pc.frame_start_found = FFMAX(bpc->pc.frame_start_found - i - 1, 0);\n\n    else\n\n        bpc->pc.frame_start_found = 0;\n\n\n\n    *poutbuf      = buf;\n\n    *poutbuf_size = buf_size;\n\n    return next;\n\n}\n", "idx": 25640}
{"project": "FFmpeg", "commit_id": "570a4a0189946c2c983da41d37fdd67fa13266e7", "target": 0, "func": "static int avi_read_seek(AVFormatContext *s, int stream_index, int64_t timestamp, int flags)\n\n{\n\n    AVIContext *avi = s->priv_data;\n\n    AVStream *st;\n\n    int i, index;\n\n    int64_t pos;\n\n    AVIStream *ast;\n\n\n\n    if (!avi->index_loaded) {\n\n        /* we only load the index on demand */\n\n        avi_load_index(s);\n\n        avi->index_loaded = 1;\n\n    }\n\n    assert(stream_index>= 0);\n\n\n\n    st = s->streams[stream_index];\n\n    ast= st->priv_data;\n\n    index= av_index_search_timestamp(st, timestamp * FFMAX(ast->sample_size, 1), flags);\n\n    if(index<0)\n\n        return -1;\n\n\n\n    /* find the position */\n\n    pos = st->index_entries[index].pos;\n\n    timestamp = st->index_entries[index].timestamp / FFMAX(ast->sample_size, 1);\n\n\n\n    av_dlog(s, \"XX %\"PRId64\" %d %\"PRId64\"\\n\",\n\n            timestamp, index, st->index_entries[index].timestamp);\n\n\n\n    if (CONFIG_DV_DEMUXER && avi->dv_demux) {\n\n        /* One and only one real stream for DV in AVI, and it has video  */\n\n        /* offsets. Calling with other stream indexes should have failed */\n\n        /* the av_index_search_timestamp call above.                     */\n\n        assert(stream_index == 0);\n\n\n\n        /* Feed the DV video stream version of the timestamp to the */\n\n        /* DV demux so it can synthesize correct timestamps.        */\n\n        ff_dv_offset_reset(avi->dv_demux, timestamp);\n\n\n\n        avio_seek(s->pb, pos, SEEK_SET);\n\n        avi->stream_index= -1;\n\n        return 0;\n\n    }\n\n\n\n    for(i = 0; i < s->nb_streams; i++) {\n\n        AVStream *st2 = s->streams[i];\n\n        AVIStream *ast2 = st2->priv_data;\n\n\n\n        ast2->packet_size=\n\n        ast2->remaining= 0;\n\n\n\n        if (ast2->sub_ctx) {\n\n            seek_subtitle(st, st2, timestamp);\n\n            continue;\n\n        }\n\n\n\n        if (st2->nb_index_entries <= 0)\n\n            continue;\n\n\n\n//        assert(st2->codec->block_align);\n\n        assert((int64_t)st2->time_base.num*ast2->rate == (int64_t)st2->time_base.den*ast2->scale);\n\n        index = av_index_search_timestamp(\n\n                st2,\n\n                av_rescale_q(timestamp, st->time_base, st2->time_base) * FFMAX(ast2->sample_size, 1),\n\n                flags | AVSEEK_FLAG_BACKWARD);\n\n        if(index<0)\n\n            index=0;\n\n\n\n        if(!avi->non_interleaved){\n\n            while(index>0 && st2->index_entries[index].pos > pos)\n\n                index--;\n\n            while(index+1 < st2->nb_index_entries && st2->index_entries[index].pos < pos)\n\n                index++;\n\n        }\n\n\n\n        av_dlog(s, \"%\"PRId64\" %d %\"PRId64\"\\n\",\n\n                timestamp, index, st2->index_entries[index].timestamp);\n\n        /* extract the current frame number */\n\n        ast2->frame_offset = st2->index_entries[index].timestamp;\n\n    }\n\n\n\n    /* do the seek */\n\n    avio_seek(s->pb, pos, SEEK_SET);\n\n    avi->stream_index= -1;\n\n    return 0;\n\n}\n", "idx": 25641}
{"project": "FFmpeg", "commit_id": "c31a5b23b4cd566724743685e5ea158b0c818647", "target": 0, "func": "static int opt_streamid(const char *opt, const char *arg)\n\n{\n\n    int idx;\n\n    char *p;\n\n    char idx_str[16];\n\n\n\n    av_strlcpy(idx_str, arg, sizeof(idx_str));\n\n    p = strchr(idx_str, ':');\n\n    if (!p) {\n\n        fprintf(stderr,\n\n                \"Invalid value '%s' for option '%s', required syntax is 'index:value'\\n\",\n\n                arg, opt);\n\n        ffmpeg_exit(1);\n\n    }\n\n    *p++ = '\\0';\n\n    idx = parse_number_or_die(opt, idx_str, OPT_INT, 0, INT_MAX);\n\n    streamid_map = grow_array(streamid_map, sizeof(*streamid_map), &nb_streamid_map, idx+1);\n\n    streamid_map[idx] = parse_number_or_die(opt, p, OPT_INT, 0, INT_MAX);\n\n    return 0;\n\n}\n", "idx": 25642}
{"project": "FFmpeg", "commit_id": "662234a9a22f1cd0f0ac83b8bb1ffadedca90c0a", "target": 0, "func": "static void avc_luma_midv_qrt_16w_msa(const uint8_t *src, int32_t src_stride,\n\n                                      uint8_t *dst, int32_t dst_stride,\n\n                                      int32_t height, uint8_t vert_offset)\n\n{\n\n    uint32_t multiple8_cnt;\n\n\n\n    for (multiple8_cnt = 2; multiple8_cnt--;) {\n\n        avc_luma_midv_qrt_8w_msa(src, src_stride, dst, dst_stride, height,\n\n                                 vert_offset);\n\n\n\n        src += 8;\n\n        dst += 8;\n\n    }\n\n}\n", "idx": 25643}
{"project": "FFmpeg", "commit_id": "c7d5049c98ee4a0c9c0b6c085892a875b6302f2f", "target": 0, "func": "int mpeg4_decode_picture_header(MpegEncContext * s)\n\n{\n\n    int time_incr, startcode, state, v;\n\n\n\n redo:\n\n    /* search next start code */\n\n    align_get_bits(&s->gb);\n\n    state = 0xff;\n\n    for(;;) {\n\n        v = get_bits(&s->gb, 8);\n\n        if (state == 0x000001) {\n\n            state = ((state << 8) | v) & 0xffffff;\n\n            startcode = state;\n\n            break;\n\n        }\n\n        state = ((state << 8) | v) & 0xffffff;\n\n        if( get_bits_count(&s->gb) > s->gb.size*8){\n\n            printf(\"no VOP startcode found\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n//printf(\"startcode %X %d\\n\", startcode, get_bits_count(&s->gb));\n\n    if (startcode == 0x120) { // Video Object Layer\n\n        int width, height, vo_ver_id;\n\n\n\n        /* vol header */\n\n        skip_bits(&s->gb, 1); /* random access */\n\n        skip_bits(&s->gb, 8); /* vo_type */\n\n        if (get_bits1(&s->gb) != 0) { /* is_ol_id */\n\n            vo_ver_id = get_bits(&s->gb, 4); /* vo_ver_id */\n\n            skip_bits(&s->gb, 3); /* vo_priority */\n\n        } else {\n\n            vo_ver_id = 1;\n\n        }\n\n        \n\n        s->aspect_ratio_info= get_bits(&s->gb, 4);\n\n\tif(s->aspect_ratio_info == EXTENDET_PAR){\n\n            skip_bits(&s->gb, 8); //par_width\n\n            skip_bits(&s->gb, 8); // par_height\n\n        }\n\n        if(get_bits1(&s->gb)){ /* vol control parameter */\n\n            printf(\"vol control parameter not supported\\n\");\n\n            return -1;   \n\n        }\n\n        s->shape = get_bits(&s->gb, 2); /* vol shape */\n\n        if(s->shape != RECT_SHAPE) printf(\"only rectangular vol supported\\n\");\n\n        if(s->shape == GRAY_SHAPE && vo_ver_id != 1){\n\n            printf(\"Gray shape not supported\\n\");\n\n            skip_bits(&s->gb, 4);  //video_object_layer_shape_extension\n\n        }\n\n\n\n        skip_bits1(&s->gb);   /* marker */\n\n        \n\n        s->time_increment_resolution = get_bits(&s->gb, 16);\n\n        s->time_increment_bits = av_log2(s->time_increment_resolution - 1) + 1;\n\n        if (s->time_increment_bits < 1)\n\n            s->time_increment_bits = 1;\n\n        skip_bits1(&s->gb);   /* marker */\n\n\n\n        if (get_bits1(&s->gb) != 0) {   /* fixed_vop_rate  */\n\n            skip_bits(&s->gb, s->time_increment_bits);\n\n        }\n\n\n\n        if (s->shape != BIN_ONLY_SHAPE) {\n\n            if (s->shape == RECT_SHAPE) {\n\n                skip_bits1(&s->gb);   /* marker */\n\n                width = get_bits(&s->gb, 13);\n\n                skip_bits1(&s->gb);   /* marker */\n\n                height = get_bits(&s->gb, 13);\n\n                skip_bits1(&s->gb);   /* marker */\n\n                if(width && height){ /* they should be non zero but who knows ... */\n\n                    s->width = width;\n\n                    s->height = height;\n\n//                    printf(\"%d %d\\n\", width, height);\n\n                }\n\n            }\n\n            \n\n            if(get_bits1(&s->gb)) printf(\"interlaced not supported\\n\");   /* interlaced */\n\n            if(!get_bits1(&s->gb)) printf(\"OBMC not supported\\n\");   /* OBMC Disable */\n\n            if (vo_ver_id == 1) {\n\n                s->vol_sprite_usage = get_bits1(&s->gb); /* vol_sprite_usage */\n\n            } else {\n\n                s->vol_sprite_usage = get_bits(&s->gb, 2); /* vol_sprite_usage */\n\n            }\n\n            if(s->vol_sprite_usage==STATIC_SPRITE) printf(\"Static Sprites not supported\\n\");\n\n            if(s->vol_sprite_usage==STATIC_SPRITE || s->vol_sprite_usage==GMC_SPRITE){\n\n                if(s->vol_sprite_usage==STATIC_SPRITE){\n\n                    s->sprite_width = get_bits(&s->gb, 13);\n\n                    skip_bits1(&s->gb); /* marker */\n\n                    s->sprite_height= get_bits(&s->gb, 13);\n\n                    skip_bits1(&s->gb); /* marker */\n\n                    s->sprite_left  = get_bits(&s->gb, 13);\n\n                    skip_bits1(&s->gb); /* marker */\n\n                    s->sprite_top   = get_bits(&s->gb, 13);\n\n                    skip_bits1(&s->gb); /* marker */\n\n                }\n\n                s->num_sprite_warping_points= get_bits(&s->gb, 6);\n\n                s->sprite_warping_accuracy = get_bits(&s->gb, 2);\n\n                s->sprite_brightness_change= get_bits1(&s->gb);\n\n                if(s->vol_sprite_usage==STATIC_SPRITE)\n\n                    s->low_latency_sprite= get_bits1(&s->gb);            \n\n            }\n\n            // FIXME sadct disable bit if verid!=1 && shape not rect\n\n            \n\n            if (get_bits1(&s->gb) == 1) {   /* not_8_bit */\n\n                s->quant_precision = get_bits(&s->gb, 4); /* quant_precision */\n\n                if(get_bits(&s->gb, 4)!=8) printf(\"N-bit not supported\\n\"); /* bits_per_pixel */\n\n            } else {\n\n                s->quant_precision = 5;\n\n            }\n\n            \n\n            // FIXME a bunch of grayscale shape things\n\n            if(get_bits1(&s->gb)) printf(\"Quant-Type not supported\\n\");  /* vol_quant_type */ //FIXME\n\n            if(vo_ver_id != 1)\n\n                 s->quarter_sample= get_bits1(&s->gb);\n\n            else s->quarter_sample=0;\n\n\n\n            if(!get_bits1(&s->gb)) printf(\"Complexity estimation not supported\\n\");\n\n#if 0\n\n            if(get_bits1(&s->gb)) printf(\"resync disable\\n\");\n\n#else\n\n            skip_bits1(&s->gb);   /* resync_marker_disabled */\n\n#endif\n\n            s->data_partioning= get_bits1(&s->gb);\n\n            if(s->data_partioning){\n\n                printf(\"data partitioning not supported\\n\");\n\n                skip_bits1(&s->gb); // reversible vlc\n\n            }\n\n            \n\n            if(vo_ver_id != 1) {\n\n                s->new_pred= get_bits1(&s->gb);\n\n                if(s->new_pred){\n\n                    printf(\"new pred not supported\\n\");\n\n                    skip_bits(&s->gb, 2); /* requested upstream message type */\n\n                    skip_bits1(&s->gb); /* newpred segment type */\n\n                }\n\n                s->reduced_res_vop= get_bits1(&s->gb);\n\n                if(s->reduced_res_vop) printf(\"reduced resolution VOP not supported\\n\");\n\n            }\n\n            else{\n\n                s->new_pred=0;\n\n                s->reduced_res_vop= 0;\n\n            }\n\n\n\n            s->scalability= get_bits1(&s->gb);\n\n            if (s->scalability) {\n\n                printf(\"bad scalability!!!\\n\");\n\n                return -1;\n\n            }\n\n        }\n\n//printf(\"end Data %X %d\\n\", show_bits(&s->gb, 32), get_bits_count(&s->gb)&0x7);\n\n        goto redo;\n\n    } else if (startcode == 0x1b2) { //userdata\n\n        char buf[256];\n\n        int i;\n\n        int e;\n\n        int ver, build;\n\n\n\n//printf(\"user Data %X\\n\", show_bits(&s->gb, 32));\n\n        buf[0]= show_bits(&s->gb, 8);\n\n        for(i=1; i<256; i++){\n\n            buf[i]= show_bits(&s->gb, 16)&0xFF;\n\n            if(buf[i]==0) break;\n\n            skip_bits(&s->gb, 8);\n\n        }\n\n        buf[255]=0;\n\n        e=sscanf(buf, \"DivX%dBuild%d\", &ver, &build);\n\n        if(e==2){\n\n            s->divx_version= ver;\n\n            s->divx_build= build;\n\n            if(s->picture_number==0){\n\n                printf(\"This file was encoded with DivX%d Build%d\\n\", ver, build);\n\n                if(ver==500 && build==413){ //most likely all version are indeed totally buggy but i dunno for sure ...\n\n                    printf(\"WARNING: this version of DivX is not MPEG4 compatible, trying to workaround these bugs...\\n\");\n\n                }else{\n\n                    printf(\"hmm, i havnt seen that version of divx yet, lets assume they fixed these bugs ...\\n\"\n\n                           \"using mpeg4 decoder, if it fails contact the developers (of ffmpeg)\\n\");\n\n                }\n\n            }\n\n        }\n\n//printf(\"User Data: %s\\n\", buf);\n\n        goto redo;\n\n    } else if (startcode != 0x1b6) { //VOP\n\n        goto redo;\n\n    }\n\n\n\n    s->pict_type = get_bits(&s->gb, 2) + 1;\t/* pict type: I = 0 , P = 1 */\n\n//printf(\"pic: %d\\n\", s->pict_type); \n\n    time_incr=0;\n\n    while (get_bits1(&s->gb) != 0) \n\n        time_incr++;\n\n\n\n    check_marker(&s->gb, \"before time_increment\");\n\n    s->time_increment= get_bits(&s->gb, s->time_increment_bits);\n\n    if(s->pict_type!=B_TYPE){\n\n        s->time_base+= time_incr;\n\n        s->last_non_b_time[1]= s->last_non_b_time[0];\n\n        s->last_non_b_time[0]= s->time_base*s->time_increment_resolution + s->time_increment;\n\n    }else{\n\n        s->time= (s->last_non_b_time[1]/s->time_increment_resolution + time_incr)*s->time_increment_resolution;\n\n        s->time+= s->time_increment;\n\n    }\n\n\n\n    if(check_marker(&s->gb, \"before vop_coded\")==0 && s->picture_number==0){\n\n        printf(\"hmm, seems the headers arnt complete, trying to guess time_increment_bits\\n\");\n\n        for(s->time_increment_bits++ ;s->time_increment_bits<16; s->time_increment_bits++){\n\n            if(get_bits1(&s->gb)) break;\n\n        }\n\n        printf(\"my guess is %d bits ;)\\n\",s->time_increment_bits);\n\n    }\n\n    /* vop coded */\n\n    if (get_bits1(&s->gb) != 1)\n\n        goto redo;\n\n//printf(\"time %d %d %d || %d %d %d\\n\", s->time_increment_bits, s->time_increment, s->time_base,\n\n//s->time, s->last_non_b_time[0], s->last_non_b_time[1]);  \n\n    if (s->shape != BIN_ONLY_SHAPE && ( s->pict_type == P_TYPE\n\n                          || (s->pict_type == S_TYPE && s->vol_sprite_usage==GMC_SPRITE))) {\n\n        /* rounding type for motion estimation */\n\n\ts->no_rounding = get_bits1(&s->gb);\n\n    } else {\n\n\ts->no_rounding = 0;\n\n    }\n\n//FIXME reduced res stuff\n\n\n\n     if (s->shape != RECT_SHAPE) {\n\n         if (s->vol_sprite_usage != 1 || s->pict_type != I_TYPE) {\n\n             int width, height, hor_spat_ref, ver_spat_ref;\n\n \n\n             width = get_bits(&s->gb, 13);\n\n             skip_bits1(&s->gb);   /* marker */\n\n             height = get_bits(&s->gb, 13);\n\n             skip_bits1(&s->gb);   /* marker */\n\n             hor_spat_ref = get_bits(&s->gb, 13); /* hor_spat_ref */\n\n             skip_bits1(&s->gb);   /* marker */\n\n             ver_spat_ref = get_bits(&s->gb, 13); /* ver_spat_ref */\n\n         }\n\n         skip_bits1(&s->gb); /* change_CR_disable */\n\n \n\n         if (get_bits1(&s->gb) != 0) {\n\n             skip_bits(&s->gb, 8); /* constant_alpha_value */\n\n         }\n\n     }\n\n//FIXME complexity estimation stuff\n\n     \n\n     if (s->shape != BIN_ONLY_SHAPE) {\n\n         skip_bits(&s->gb, 3); /* intra dc VLC threshold */\n\n         //FIXME interlaced specific bits\n\n     }\n\n\n\n     if(s->pict_type == S_TYPE && (s->vol_sprite_usage==STATIC_SPRITE || s->vol_sprite_usage==GMC_SPRITE)){\n\n         if(s->num_sprite_warping_points){\n\n             mpeg4_decode_sprite_trajectory(s);\n\n         }\n\n         if(s->sprite_brightness_change) printf(\"sprite_brightness_change not supported\\n\");\n\n         if(s->vol_sprite_usage==STATIC_SPRITE) printf(\"static sprite not supported\\n\");\n\n     }\n\n\n\n     if (s->shape != BIN_ONLY_SHAPE) {\n\n         /* note: we do not use quant_precision to avoid problem if no\n\n            MPEG4 vol header as it is found on some old opendivx\n\n            movies */\n\n         s->qscale = get_bits(&s->gb, 5);\n\n         if(s->qscale==0){\n\n             printf(\"Error, header damaged or not MPEG4 header (qscale=0)\\n\");\n\n             return -1; // makes no sense to continue, as there is nothing left from the image then\n\n         }\n\n  \n\n         if (s->pict_type != I_TYPE) {\n\n             s->f_code = get_bits(&s->gb, 3);\t/* fcode_for */\n\n             if(s->f_code==0){\n\n                 printf(\"Error, header damaged or not MPEG4 header (f_code=0)\\n\");\n\n                 return -1; // makes no sense to continue, as the MV decoding will break very quickly\n\n             }\n\n         }\n\n         if (s->pict_type == B_TYPE) {\n\n             s->b_code = get_bits(&s->gb, 3);\n\n//printf(\"b-code %d\\n\", s->b_code);\n\n         }\n\n//printf(\"quant:%d fcode:%d\\n\", s->qscale, s->f_code);\n\n\n\n         if(!s->scalability){\n\n             if (s->shape!=RECT_SHAPE && s->pict_type!=I_TYPE) {\n\n                 skip_bits1(&s->gb); // vop shape coding type\n\n             }\n\n         }\n\n     }\n\n     s->picture_number++; // better than pic number==0 allways ;)\n\n     return 0;\n\n}\n", "idx": 25644}
{"project": "FFmpeg", "commit_id": "13a099799e89a76eb921ca452e1b04a7a28a9855", "target": 0, "func": "static void RENAME(yuv2rgb32_1)(SwsContext *c, const uint16_t *buf0,\n\n                                const uint16_t *ubuf0, const uint16_t *ubuf1,\n\n                                const uint16_t *vbuf0, const uint16_t *vbuf1,\n\n                                const uint16_t *abuf0, uint8_t *dest,\n\n                                int dstW, int uvalpha, enum PixelFormat dstFormat,\n\n                                int flags, int y)\n\n{\n\n    const uint16_t *buf1= buf0; //FIXME needed for RGB1/BGR1\n\n\n\n    if (uvalpha < 2048) { // note this is not correct (shifts chrominance by 0.5 pixels) but it is a bit faster\n\n        if (CONFIG_SWSCALE_ALPHA && c->alpPixBuf) {\n\n            __asm__ volatile(\n\n                \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n                \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n                \"push %%\"REG_BP\"                        \\n\\t\"\n\n                YSCALEYUV2RGB1(%%REGBP, %5)\n\n                YSCALEYUV2RGB1_ALPHA(%%REGBP)\n\n                WRITEBGR32(%%REGb, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)\n\n                \"pop %%\"REG_BP\"                         \\n\\t\"\n\n                \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n                :: \"c\" (buf0), \"d\" (abuf0), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n                   \"a\" (&c->redDither)\n\n            );\n\n        } else {\n\n            __asm__ volatile(\n\n                \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n                \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n                \"push %%\"REG_BP\"                        \\n\\t\"\n\n                YSCALEYUV2RGB1(%%REGBP, %5)\n\n                \"pcmpeqd %%mm7, %%mm7                   \\n\\t\"\n\n                WRITEBGR32(%%REGb, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)\n\n                \"pop %%\"REG_BP\"                         \\n\\t\"\n\n                \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n                :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n                   \"a\" (&c->redDither)\n\n            );\n\n        }\n\n    } else {\n\n        if (CONFIG_SWSCALE_ALPHA && c->alpPixBuf) {\n\n            __asm__ volatile(\n\n                \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n                \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n                \"push %%\"REG_BP\"                        \\n\\t\"\n\n                YSCALEYUV2RGB1b(%%REGBP, %5)\n\n                YSCALEYUV2RGB1_ALPHA(%%REGBP)\n\n                WRITEBGR32(%%REGb, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)\n\n                \"pop %%\"REG_BP\"                         \\n\\t\"\n\n                \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n                :: \"c\" (buf0), \"d\" (abuf0), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n                   \"a\" (&c->redDither)\n\n            );\n\n        } else {\n\n            __asm__ volatile(\n\n                \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n                \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n                \"push %%\"REG_BP\"                        \\n\\t\"\n\n                YSCALEYUV2RGB1b(%%REGBP, %5)\n\n                \"pcmpeqd %%mm7, %%mm7                   \\n\\t\"\n\n                WRITEBGR32(%%REGb, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)\n\n                \"pop %%\"REG_BP\"                         \\n\\t\"\n\n                \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n                :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n                   \"a\" (&c->redDither)\n\n            );\n\n        }\n\n    }\n\n}\n", "idx": 25645}
{"project": "FFmpeg", "commit_id": "68f593b48433842f3407586679fe07f3e5199ab9", "target": 0, "func": "static int decode_frame(AVCodecContext *avctx, void *data, int *data_size, uint8_t *buf, int buf_size){\n\n    HYuvContext *s = avctx->priv_data;\n\n    const int width= s->width;\n\n    const int width2= s->width>>1;\n\n    const int height= s->height;\n\n    int fake_ystride, fake_ustride, fake_vstride;\n\n    AVFrame * const p= &s->picture;\n\n\n\n    AVFrame *picture = data;\n\n\n\n    *data_size = 0;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0)\n\n        return 0;\n\n\n\n    bswap_buf((uint32_t*)s->bitstream_buffer, (uint32_t*)buf, buf_size/4);\n\n    \n\n    init_get_bits(&s->gb, s->bitstream_buffer, buf_size);\n\n\n\n    p->reference= 0;\n\n    if(avctx->get_buffer(avctx, p) < 0){\n\n        fprintf(stderr, \"get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    fake_ystride= s->interlaced ? p->linesize[0]*2  : p->linesize[0];\n\n    fake_ustride= s->interlaced ? p->linesize[1]*2  : p->linesize[1];\n\n    fake_vstride= s->interlaced ? p->linesize[2]*2  : p->linesize[2];\n\n    \n\n    s->last_slice_end= 0;\n\n        \n\n    if(s->bitstream_bpp<24){\n\n        int y, cy;\n\n        int lefty, leftu, leftv;\n\n        int lefttopy, lefttopu, lefttopv;\n\n        \n\n        if(s->yuy2){\n\n            p->data[0][3]= get_bits(&s->gb, 8);\n\n            p->data[0][2]= get_bits(&s->gb, 8);\n\n            p->data[0][1]= get_bits(&s->gb, 8);\n\n            p->data[0][0]= get_bits(&s->gb, 8);\n\n            \n\n            fprintf(stderr, \"YUY2 output isnt implemenetd yet\\n\");\n\n            return -1;\n\n        }else{\n\n        \n\n            leftv= p->data[2][0]= get_bits(&s->gb, 8);\n\n            lefty= p->data[0][1]= get_bits(&s->gb, 8);\n\n            leftu= p->data[1][0]= get_bits(&s->gb, 8);\n\n                   p->data[0][0]= get_bits(&s->gb, 8);\n\n        \n\n            switch(s->predictor){\n\n            case LEFT:\n\n            case PLANE:\n\n                decode_422_bitstream(s, width-2);\n\n                lefty= add_left_prediction(p->data[0] + 2, s->temp[0], width-2, lefty);\n\n                if(!(s->flags&CODEC_FLAG_GRAY)){\n\n                    leftu= add_left_prediction(p->data[1] + 1, s->temp[1], width2-1, leftu);\n\n                    leftv= add_left_prediction(p->data[2] + 1, s->temp[2], width2-1, leftv);\n\n                }\n\n\n\n                for(cy=y=1; y<s->height; y++,cy++){\n\n                    uint8_t *ydst, *udst, *vdst;\n\n                    \n\n                    if(s->bitstream_bpp==12){\n\n                        decode_gray_bitstream(s, width);\n\n                    \n\n                        ydst= p->data[0] + p->linesize[0]*y;\n\n\n\n                        lefty= add_left_prediction(ydst, s->temp[0], width, lefty);\n\n                        if(s->predictor == PLANE){\n\n                            if(y>s->interlaced)\n\n                                s->dsp.add_bytes(ydst, ydst - fake_ystride, width);\n\n                        }\n\n                        y++;\n\n                        if(y>=s->height) break;\n\n                    }\n\n                    \n\n                    draw_slice(s, y);\n\n                    \n\n                    ydst= p->data[0] + p->linesize[0]*y;\n\n                    udst= p->data[1] + p->linesize[1]*cy;\n\n                    vdst= p->data[2] + p->linesize[2]*cy;\n\n                    \n\n                    decode_422_bitstream(s, width);\n\n                    lefty= add_left_prediction(ydst, s->temp[0], width, lefty);\n\n                    if(!(s->flags&CODEC_FLAG_GRAY)){\n\n                        leftu= add_left_prediction(udst, s->temp[1], width2, leftu);\n\n                        leftv= add_left_prediction(vdst, s->temp[2], width2, leftv);\n\n                    }\n\n                    if(s->predictor == PLANE){\n\n                        if(cy>s->interlaced){\n\n                            s->dsp.add_bytes(ydst, ydst - fake_ystride, width);\n\n                            if(!(s->flags&CODEC_FLAG_GRAY)){\n\n                                s->dsp.add_bytes(udst, udst - fake_ustride, width2);\n\n                                s->dsp.add_bytes(vdst, vdst - fake_vstride, width2);\n\n                            }\n\n                        }\n\n                    }\n\n                }\n\n                draw_slice(s, height);\n\n                \n\n                break;\n\n            case MEDIAN:\n\n                /* first line except first 2 pixels is left predicted */\n\n                decode_422_bitstream(s, width-2);\n\n                lefty= add_left_prediction(p->data[0] + 2, s->temp[0], width-2, lefty);\n\n                if(!(s->flags&CODEC_FLAG_GRAY)){\n\n                    leftu= add_left_prediction(p->data[1] + 1, s->temp[1], width2-1, leftu);\n\n                    leftv= add_left_prediction(p->data[2] + 1, s->temp[2], width2-1, leftv);\n\n                }\n\n                \n\n                cy=y=1;\n\n                \n\n                /* second line is left predicted for interlaced case */\n\n                if(s->interlaced){\n\n                    decode_422_bitstream(s, width);\n\n                    lefty= add_left_prediction(p->data[0] + p->linesize[0], s->temp[0], width, lefty);\n\n                    if(!(s->flags&CODEC_FLAG_GRAY)){\n\n                        leftu= add_left_prediction(p->data[1] + p->linesize[2], s->temp[1], width2, leftu);\n\n                        leftv= add_left_prediction(p->data[2] + p->linesize[1], s->temp[2], width2, leftv);\n\n                    }\n\n                    y++; cy++;\n\n                }\n\n\n\n                /* next 4 pixels are left predicted too */\n\n                decode_422_bitstream(s, 4);\n\n                lefty= add_left_prediction(p->data[0] + fake_ystride, s->temp[0], 4, lefty);\n\n                if(!(s->flags&CODEC_FLAG_GRAY)){\n\n                    leftu= add_left_prediction(p->data[1] + fake_ustride, s->temp[1], 2, leftu);\n\n                    leftv= add_left_prediction(p->data[2] + fake_vstride, s->temp[2], 2, leftv);\n\n                }\n\n\n\n                /* next line except the first 4 pixels is median predicted */\n\n                lefttopy= p->data[0][3];\n\n                decode_422_bitstream(s, width-4);\n\n                add_median_prediction(p->data[0] + fake_ystride+4, p->data[0]+4, s->temp[0], width-4, &lefty, &lefttopy);\n\n                if(!(s->flags&CODEC_FLAG_GRAY)){\n\n                    lefttopu= p->data[1][1];\n\n                    lefttopv= p->data[2][1];\n\n                    add_median_prediction(p->data[1] + fake_ustride+2, p->data[1]+2, s->temp[1], width2-2, &leftu, &lefttopu);\n\n                    add_median_prediction(p->data[2] + fake_vstride+2, p->data[2]+2, s->temp[2], width2-2, &leftv, &lefttopv);\n\n                }\n\n                y++; cy++;\n\n                \n\n                for(; y<height; y++,cy++){\n\n                    uint8_t *ydst, *udst, *vdst;\n\n\n\n                    if(s->bitstream_bpp==12){\n\n                        while(2*cy > y){\n\n                            decode_gray_bitstream(s, width);\n\n                            ydst= p->data[0] + p->linesize[0]*y;\n\n                            add_median_prediction(ydst, ydst - fake_ystride, s->temp[0], width, &lefty, &lefttopy);\n\n                            y++;\n\n                        }\n\n                        if(y>=height) break;\n\n                    }\n\n                    draw_slice(s, y);\n\n\n\n                    decode_422_bitstream(s, width);\n\n\n\n                    ydst= p->data[0] + p->linesize[0]*y;\n\n                    udst= p->data[1] + p->linesize[1]*cy;\n\n                    vdst= p->data[2] + p->linesize[2]*cy;\n\n\n\n                    add_median_prediction(ydst, ydst - fake_ystride, s->temp[0], width, &lefty, &lefttopy);\n\n                    if(!(s->flags&CODEC_FLAG_GRAY)){\n\n                        add_median_prediction(udst, udst - fake_ustride, s->temp[1], width2, &leftu, &lefttopu);\n\n                        add_median_prediction(vdst, vdst - fake_vstride, s->temp[2], width2, &leftv, &lefttopv);\n\n                    }\n\n                }\n\n\n\n                draw_slice(s, height);\n\n                break;\n\n            }\n\n        }\n\n    }else{\n\n        int y;\n\n        int leftr, leftg, leftb;\n\n        const int last_line= (height-1)*p->linesize[0];\n\n        \n\n        if(s->bitstream_bpp==32){\n\n                   p->data[0][last_line+3]= get_bits(&s->gb, 8);\n\n            leftr= p->data[0][last_line+2]= get_bits(&s->gb, 8);\n\n            leftg= p->data[0][last_line+1]= get_bits(&s->gb, 8);\n\n            leftb= p->data[0][last_line+0]= get_bits(&s->gb, 8);\n\n        }else{\n\n            leftr= p->data[0][last_line+2]= get_bits(&s->gb, 8);\n\n            leftg= p->data[0][last_line+1]= get_bits(&s->gb, 8);\n\n            leftb= p->data[0][last_line+0]= get_bits(&s->gb, 8);\n\n            skip_bits(&s->gb, 8);\n\n        }\n\n        \n\n        if(s->bgr32){\n\n            switch(s->predictor){\n\n            case LEFT:\n\n            case PLANE:\n\n                decode_bgr_bitstream(s, width-1);\n\n                add_left_prediction_bgr32(p->data[0] + last_line+4, s->temp[0], width-1, &leftr, &leftg, &leftb);\n\n\n\n                for(y=s->height-2; y>=0; y--){ //yes its stored upside down\n\n                    decode_bgr_bitstream(s, width);\n\n                    \n\n                    add_left_prediction_bgr32(p->data[0] + p->linesize[0]*y, s->temp[0], width, &leftr, &leftg, &leftb);\n\n                    if(s->predictor == PLANE){\n\n                        if((y&s->interlaced)==0){\n\n                            s->dsp.add_bytes(p->data[0] + p->linesize[0]*y, \n\n                                             p->data[0] + p->linesize[0]*y + fake_ystride, fake_ystride);\n\n                        }\n\n                    }\n\n                }\n\n                draw_slice(s, height); // just 1 large slice as this isnt possible in reverse order\n\n                break;\n\n            default:\n\n                fprintf(stderr, \"prediction type not supported!\\n\");\n\n            }\n\n        }else{\n\n\n\n            fprintf(stderr, \"BGR24 output isnt implemenetd yet\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n    emms_c();\n\n    \n\n    *picture= *p;\n\n    \n\n    avctx->release_buffer(avctx, p);\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    \n\n    return (get_bits_count(&s->gb)+7)>>3;\n\n}\n", "idx": 25646}
{"project": "FFmpeg", "commit_id": "1bc64c2814d409d3cc129c27c493ee915bebdc4a", "target": 1, "func": "int attribute_align_arg avcodec_decode_audio4(AVCodecContext *avctx,\n                                              AVFrame *frame,\n                                              int *got_frame_ptr,\n                                              AVPacket *avpkt)\n{\n    int planar, channels;\n    int ret = 0;\n    *got_frame_ptr = 0;\n    avctx->pkt = avpkt;\n    if (!avpkt->data && avpkt->size) {\n        av_log(avctx, AV_LOG_ERROR, \"invalid packet: NULL data, size != 0\\n\");\n        return AVERROR(EINVAL);\n    }\n    apply_param_change(avctx, avpkt);\n    if ((avctx->codec->capabilities & CODEC_CAP_DELAY) || avpkt->size) {\n        ret = avctx->codec->decode(avctx, frame, got_frame_ptr, avpkt);\n        if (ret >= 0 && *got_frame_ptr) {\n            avctx->frame_number++;\n            frame->pkt_dts = avpkt->dts;\n            if (frame->format == AV_SAMPLE_FMT_NONE)\n                frame->format = avctx->sample_fmt;\n        }\n    }\n    /* many decoders assign whole AVFrames, thus overwriting extended_data;\n     * make sure it's set correctly; assume decoders that actually use\n     * extended_data are doing it correctly */\n    planar   = av_sample_fmt_is_planar(frame->format);\n    channels = av_get_channel_layout_nb_channels(frame->channel_layout);\n    if (!(planar && channels > AV_NUM_DATA_POINTERS))\n        frame->extended_data = frame->data;\n    return ret;\n}", "idx": 25649}
{"project": "FFmpeg", "commit_id": "9ea242962c4093a5523deef124a98193bbb36730", "target": 1, "func": "int ff_j2k_init_component(Jpeg2000Component *comp, Jpeg2000CodingStyle *codsty, Jpeg2000QuantStyle *qntsty, int cbps, int dx, int dy)\n\n{\n\n    int reslevelno, bandno, gbandno = 0, ret, i, j, csize = 1;\n\n\n\n    if (ret=ff_j2k_dwt_init(&comp->dwt, comp->coord, codsty->nreslevels-1, codsty->transform))\n\n        return ret;\n\n    for (i = 0; i < 2; i++)\n\n        csize *= comp->coord[i][1] - comp->coord[i][0];\n\n\n\n    comp->data = av_malloc(csize * sizeof(int));\n\n    if (!comp->data)\n\n        return AVERROR(ENOMEM);\n\n    comp->reslevel = av_malloc(codsty->nreslevels * sizeof(Jpeg2000ResLevel));\n\n\n\n    if (!comp->reslevel)\n\n        return AVERROR(ENOMEM);\n\n    for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) {\n\n        int declvl = codsty->nreslevels - reslevelno;\n\n        Jpeg2000ResLevel *reslevel = comp->reslevel + reslevelno;\n\n\n\n        for (i = 0; i < 2; i++)\n\n            for (j = 0; j < 2; j++)\n\n                reslevel->coord[i][j] =\n\n                    ff_jpeg2000_ceildivpow2(comp->coord[i][j], declvl - 1);\n\n\n\n        if (reslevelno == 0)\n\n            reslevel->nbands = 1;\n\n        else\n\n            reslevel->nbands = 3;\n\n\n\n        if (reslevel->coord[0][1] == reslevel->coord[0][0])\n\n            reslevel->num_precincts_x = 0;\n\n        else\n\n            reslevel->num_precincts_x = ff_jpeg2000_ceildivpow2(reslevel->coord[0][1], codsty->log2_prec_width)\n\n                                        - (reslevel->coord[0][0] >> codsty->log2_prec_width);\n\n\n\n        if (reslevel->coord[1][1] == reslevel->coord[1][0])\n\n            reslevel->num_precincts_y = 0;\n\n        else\n\n            reslevel->num_precincts_y = ff_jpeg2000_ceildivpow2(reslevel->coord[1][1], codsty->log2_prec_height)\n\n                                        - (reslevel->coord[1][0] >> codsty->log2_prec_height);\n\n\n\n        reslevel->band = av_malloc(reslevel->nbands * sizeof(Jpeg2000Band));\n\n        if (!reslevel->band)\n\n            return AVERROR(ENOMEM);\n\n        for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) {\n\n            Jpeg2000Band *band = reslevel->band + bandno;\n\n            int cblkno, precx, precy, precno;\n\n            int x0, y0, x1, y1;\n\n            int xi0, yi0, xi1, yi1;\n\n            int cblkperprecw, cblkperprech;\n\n\n\n            if (qntsty->quantsty != JPEG2000_QSTY_NONE) {\n\n                static const uint8_t lut_gain[2][4] = {{0, 0, 0, 0}, {0, 1, 1, 2}};\n\n                int numbps;\n\n\n\n                numbps = cbps + lut_gain[codsty->transform][bandno + reslevelno>0];\n\n                band->stepsize = SHL(2048 + qntsty->mant[gbandno], 2 + numbps - qntsty->expn[gbandno]);\n\n            } else\n\n                band->stepsize = 1 << 13;\n\n\n\n            if (reslevelno == 0) {  // the same everywhere\n\n                band->codeblock_width = 1 << FFMIN(codsty->log2_cblk_width, codsty->log2_prec_width-1);\n\n                band->codeblock_height = 1 << FFMIN(codsty->log2_cblk_height, codsty->log2_prec_height-1);\n\n                for (i = 0; i < 2; i++)\n\n                    for (j = 0; j < 2; j++)\n\n                        band->coord[i][j] = ff_jpeg2000_ceildivpow2(comp->coord[i][j], declvl-1);\n\n            } else{\n\n                band->codeblock_width = 1 << FFMIN(codsty->log2_cblk_width, codsty->log2_prec_width);\n\n                band->codeblock_height = 1 << FFMIN(codsty->log2_cblk_height, codsty->log2_prec_height);\n\n\n\n                for (i = 0; i < 2; i++)\n\n                    for (j = 0; j < 2; j++)\n\n                        band->coord[i][j] = ff_jpeg2000_ceildivpow2(comp->coord[i][j] - (((bandno+1>>i)&1) << declvl-1), declvl);\n\n            }\n\n            band->cblknx = ff_jpeg2000_ceildiv(band->coord[0][1], band->codeblock_width)  - band->coord[0][0] / band->codeblock_width;\n\n            band->cblkny = ff_jpeg2000_ceildiv(band->coord[1][1], band->codeblock_height) - band->coord[1][0] / band->codeblock_height;\n\n\n\n            for (j = 0; j < 2; j++)\n\n                band->coord[0][j] = ff_jpeg2000_ceildiv(band->coord[0][j], dx);\n\n            for (j = 0; j < 2; j++)\n\n                band->coord[1][j] = ff_jpeg2000_ceildiv(band->coord[1][j], dy);\n\n\n\n            band->cblknx = ff_jpeg2000_ceildiv(band->cblknx, dx);\n\n            band->cblkny = ff_jpeg2000_ceildiv(band->cblkny, dy);\n\n\n\n            band->cblk = av_malloc(sizeof(Jpeg2000Cblk) * band->cblknx * band->cblkny);\n\n            if (!band->cblk)\n\n                return AVERROR(ENOMEM);\n\n            band->prec = av_malloc(sizeof(Jpeg2000Cblk) * reslevel->num_precincts_x * reslevel->num_precincts_y);\n\n            if (!band->prec)\n\n                return AVERROR(ENOMEM);\n\n\n\n            for (cblkno = 0; cblkno < band->cblknx * band->cblkny; cblkno++) {\n\n                Jpeg2000Cblk *cblk = band->cblk + cblkno;\n\n                cblk->zero = 0;\n\n                cblk->lblock = 3;\n\n                cblk->length = 0;\n\n                cblk->lengthinc = 0;\n\n                cblk->npasses = 0;\n\n            }\n\n\n\n            y0 = band->coord[1][0];\n\n            y1 = ((band->coord[1][0] + (1<<codsty->log2_prec_height)) & ~((1<<codsty->log2_prec_height)-1)) - y0;\n\n            yi0 = 0;\n\n            yi1 = ff_jpeg2000_ceildivpow2(y1 - y0, codsty->log2_cblk_height) << codsty->log2_cblk_height;\n\n            yi1 = FFMIN(yi1, band->cblkny);\n\n            cblkperprech = 1<<(codsty->log2_prec_height - codsty->log2_cblk_height);\n\n            for (precy = 0, precno = 0; precy < reslevel->num_precincts_y; precy++) {\n\n                for (precx = 0; precx < reslevel->num_precincts_x; precx++, precno++) {\n\n                    band->prec[precno].yi0 = yi0;\n\n                    band->prec[precno].yi1 = yi1;\n\n                }\n\n                yi1 += cblkperprech;\n\n                yi0 = yi1 - cblkperprech;\n\n                yi1 = FFMIN(yi1, band->cblkny);\n\n            }\n\n            x0 = band->coord[0][0];\n\n            x1 = ((band->coord[0][0] + (1<<codsty->log2_prec_width)) & ~((1<<codsty->log2_prec_width)-1)) - x0;\n\n            xi0 = 0;\n\n            xi1 = ff_jpeg2000_ceildivpow2(x1 - x0, codsty->log2_cblk_width) << codsty->log2_cblk_width;\n\n            xi1 = FFMIN(xi1, band->cblknx);\n\n\n\n            cblkperprecw = 1<<(codsty->log2_prec_width - codsty->log2_cblk_width);\n\n            for (precx = 0, precno = 0; precx < reslevel->num_precincts_x; precx++) {\n\n                for (precy = 0; precy < reslevel->num_precincts_y; precy++, precno = 0) {\n\n                    Jpeg2000Prec *prec = band->prec + precno;\n\n                    prec->xi0 = xi0;\n\n                    prec->xi1 = xi1;\n\n                    prec->cblkincl = ff_j2k_tag_tree_init(prec->xi1 - prec->xi0,\n\n                                                          prec->yi1 - prec->yi0);\n\n                    prec->zerobits = ff_j2k_tag_tree_init(prec->xi1 - prec->xi0,\n\n                                                          prec->yi1 - prec->yi0);\n\n                    if (!prec->cblkincl || !prec->zerobits)\n\n                        return AVERROR(ENOMEM);\n\n\n\n                }\n\n                xi1 += cblkperprecw;\n\n                xi0 = xi1 - cblkperprecw;\n\n                xi1 = FFMIN(xi1, band->cblknx);\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 25650}
{"project": "FFmpeg", "commit_id": "d64066f6e88c827e33002b2c7740efd62cd5ba7f", "target": 1, "func": "static int read_frame_internal(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    AVStream *st;\n\n    int len, ret, i;\n\n\n\n    av_init_packet(pkt);\n\n\n\n    for(;;) {\n\n        /* select current input stream component */\n\n        st = s->cur_st;\n\n        if (st) {\n\n            if (!st->need_parsing || !st->parser) {\n\n                /* no parsing needed: we just output the packet as is */\n\n                /* raw data support */\n\n                *pkt = st->cur_pkt; st->cur_pkt.data= NULL;\n\n                compute_pkt_fields(s, st, NULL, pkt);\n\n                s->cur_st = NULL;\n\n                if ((s->iformat->flags & AVFMT_GENERIC_INDEX) &&\n\n                    (pkt->flags & AV_PKT_FLAG_KEY) && pkt->dts != AV_NOPTS_VALUE) {\n\n                    ff_reduce_index(s, st->index);\n\n                    av_add_index_entry(st, pkt->pos, pkt->dts, 0, 0, AVINDEX_KEYFRAME);\n\n                }\n\n                break;\n\n            } else if (st->cur_len > 0 && st->discard < AVDISCARD_ALL) {\n\n                len = av_parser_parse2(st->parser, st->codec, &pkt->data, &pkt->size,\n\n                                       st->cur_ptr, st->cur_len,\n\n                                       st->cur_pkt.pts, st->cur_pkt.dts,\n\n                                       st->cur_pkt.pos);\n\n                st->cur_pkt.pts = AV_NOPTS_VALUE;\n\n                st->cur_pkt.dts = AV_NOPTS_VALUE;\n\n                /* increment read pointer */\n\n                st->cur_ptr += len;\n\n                st->cur_len -= len;\n\n\n\n                /* return packet if any */\n\n                if (pkt->size) {\n\n                got_packet:\n\n                    pkt->duration = 0;\n\n                    pkt->stream_index = st->index;\n\n                    pkt->pts = st->parser->pts;\n\n                    pkt->dts = st->parser->dts;\n\n                    pkt->pos = st->parser->pos;\n\n                    if(pkt->data == st->cur_pkt.data && pkt->size == st->cur_pkt.size){\n\n                        s->cur_st = NULL;\n\n                        pkt->destruct= st->cur_pkt.destruct;\n\n                        st->cur_pkt.destruct= NULL;\n\n                        st->cur_pkt.data    = NULL;\n\n                        assert(st->cur_len == 0);\n\n                    }else{\n\n                        pkt->destruct = NULL;\n\n                    }\n\n                    compute_pkt_fields(s, st, st->parser, pkt);\n\n\n\n                    if((s->iformat->flags & AVFMT_GENERIC_INDEX) && pkt->flags & AV_PKT_FLAG_KEY){\n\n                        int64_t pos= (st->parser->flags & PARSER_FLAG_COMPLETE_FRAMES) ? pkt->pos : st->parser->frame_offset;\n\n                        ff_reduce_index(s, st->index);\n\n                        av_add_index_entry(st, pos, pkt->dts,\n\n                                           0, 0, AVINDEX_KEYFRAME);\n\n                    }\n\n\n\n                    break;\n\n                }\n\n            } else {\n\n                /* free packet */\n\n                av_free_packet(&st->cur_pkt);\n\n                s->cur_st = NULL;\n\n            }\n\n        } else {\n\n            AVPacket cur_pkt;\n\n            /* read next packet */\n\n            ret = av_read_packet(s, &cur_pkt);\n\n            if (ret < 0) {\n\n                if (ret == AVERROR(EAGAIN))\n\n                    return ret;\n\n                /* return the last frames, if any */\n\n                for(i = 0; i < s->nb_streams; i++) {\n\n                    st = s->streams[i];\n\n                    if (st->parser && st->need_parsing) {\n\n                        av_parser_parse2(st->parser, st->codec,\n\n                                        &pkt->data, &pkt->size,\n\n                                        NULL, 0,\n\n                                        AV_NOPTS_VALUE, AV_NOPTS_VALUE,\n\n                                        AV_NOPTS_VALUE);\n\n                        if (pkt->size)\n\n                            goto got_packet;\n\n                    }\n\n                }\n\n                /* no more packets: really terminate parsing */\n\n                return ret;\n\n            }\n\n            st = s->streams[cur_pkt.stream_index];\n\n            st->cur_pkt= cur_pkt;\n\n\n\n            if(st->cur_pkt.pts != AV_NOPTS_VALUE &&\n\n               st->cur_pkt.dts != AV_NOPTS_VALUE &&\n\n               st->cur_pkt.pts < st->cur_pkt.dts){\n\n                av_log(s, AV_LOG_WARNING, \"Invalid timestamps stream=%d, pts=%\"PRId64\", dts=%\"PRId64\", size=%d\\n\",\n\n                    st->cur_pkt.stream_index,\n\n                    st->cur_pkt.pts,\n\n                    st->cur_pkt.dts,\n\n                    st->cur_pkt.size);\n\n//                av_free_packet(&st->cur_pkt);\n\n//                return -1;\n\n            }\n\n\n\n            if(s->debug & FF_FDEBUG_TS)\n\n                av_log(s, AV_LOG_DEBUG, \"av_read_packet stream=%d, pts=%\"PRId64\", dts=%\"PRId64\", size=%d, duration=%d, flags=%d\\n\",\n\n                    st->cur_pkt.stream_index,\n\n                    st->cur_pkt.pts,\n\n                    st->cur_pkt.dts,\n\n                    st->cur_pkt.size,\n\n                    st->cur_pkt.duration,\n\n                    st->cur_pkt.flags);\n\n\n\n            s->cur_st = st;\n\n            st->cur_ptr = st->cur_pkt.data;\n\n            st->cur_len = st->cur_pkt.size;\n\n            if (st->need_parsing && !st->parser && !(s->flags & AVFMT_FLAG_NOPARSE)) {\n\n                st->parser = av_parser_init(st->codec->codec_id);\n\n                if (!st->parser) {\n\n                    av_log(s, AV_LOG_WARNING, \"parser not found for codec \"\n\n                           \"%s, packets or times may be invalid.\\n\",\n\n                           avcodec_get_name(st->codec->codec_id));\n\n                    /* no parser available: just output the raw packets */\n\n                    st->need_parsing = AVSTREAM_PARSE_NONE;\n\n                }else if(st->need_parsing == AVSTREAM_PARSE_HEADERS){\n\n                    st->parser->flags |= PARSER_FLAG_COMPLETE_FRAMES;\n\n                }else if(st->need_parsing == AVSTREAM_PARSE_FULL_ONCE){\n\n                    st->parser->flags |= PARSER_FLAG_ONCE;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    if(s->debug & FF_FDEBUG_TS)\n\n        av_log(s, AV_LOG_DEBUG, \"read_frame_internal stream=%d, pts=%\"PRId64\", dts=%\"PRId64\", size=%d, duration=%d, flags=%d\\n\",\n\n            pkt->stream_index,\n\n            pkt->pts,\n\n            pkt->dts,\n\n            pkt->size,\n\n            pkt->duration,\n\n            pkt->flags);\n\n\n\n    return 0;\n\n}\n", "idx": 25652}
{"project": "FFmpeg", "commit_id": "552adf1dd3a38fb7a1a6109dd2b517d63290f20e", "target": 1, "func": "static int read_filter_params(MLPDecodeContext *m, GetBitContext *gbp,\n\n                              unsigned int substr, unsigned int channel,\n\n                              unsigned int filter)\n\n{\n\n    SubStream *s = &m->substream[substr];\n\n    FilterParams *fp = &s->channel_params[channel].filter_params[filter];\n\n    const int max_order = filter ? MAX_IIR_ORDER : MAX_FIR_ORDER;\n\n    const char fchar = filter ? 'I' : 'F';\n\n    int i, order;\n\n\n\n    // Filter is 0 for FIR, 1 for IIR.\n\n    av_assert0(filter < 2);\n\n\n\n    if (m->filter_changed[channel][filter]++ > 1) {\n\n        av_log(m->avctx, AV_LOG_ERROR, \"Filters may change only once per access unit.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    order = get_bits(gbp, 4);\n\n    if (order > max_order) {\n\n        av_log(m->avctx, AV_LOG_ERROR,\n\n               \"%cIR filter order %d is greater than maximum %d.\\n\",\n\n               fchar, order, max_order);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    fp->order = order;\n\n\n\n    if (order > 0) {\n\n        int32_t *fcoeff = s->channel_params[channel].coeff[filter];\n\n        int coeff_bits, coeff_shift;\n\n\n\n        fp->shift = get_bits(gbp, 4);\n\n\n\n        coeff_bits  = get_bits(gbp, 5);\n\n        coeff_shift = get_bits(gbp, 3);\n\n        if (coeff_bits < 1 || coeff_bits > 16) {\n\n            av_log(m->avctx, AV_LOG_ERROR,\n\n                   \"%cIR filter coeff_bits must be between 1 and 16.\\n\",\n\n                   fchar);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (coeff_bits + coeff_shift > 16) {\n\n            av_log(m->avctx, AV_LOG_ERROR,\n\n                   \"Sum of coeff_bits and coeff_shift for %cIR filter must be 16 or less.\\n\",\n\n                   fchar);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        for (i = 0; i < order; i++)\n\n            fcoeff[i] = get_sbits(gbp, coeff_bits) * (1 << coeff_shift);\n\n\n\n        if (get_bits1(gbp)) {\n\n            int state_bits, state_shift;\n\n\n\n            if (filter == FIR) {\n\n                av_log(m->avctx, AV_LOG_ERROR,\n\n                       \"FIR filter has state data specified.\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            state_bits  = get_bits(gbp, 4);\n\n            state_shift = get_bits(gbp, 4);\n\n\n\n            /* TODO: Check validity of state data. */\n\n\n\n            for (i = 0; i < order; i++)\n\n                fp->state[i] = state_bits ? get_sbits(gbp, state_bits) << state_shift : 0;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25656}
{"project": "FFmpeg", "commit_id": "63a99622876ff79a07862167f243a7d3823b7315", "target": 1, "func": "static int filter_frame(AVFilterLink *inlink, AVFilterBufferRef *inpicref)\n\n{\n\n    IlContext *il = inlink->dst->priv;\n\n    AVFilterLink *outlink = inlink->dst->outputs[0];\n\n    AVFilterBufferRef *out;\n\n    int ret;\n\n\n\n    out = ff_get_video_buffer(outlink, AV_PERM_WRITE, outlink->w, outlink->h);\n\n    if (!out) {\n\n        avfilter_unref_bufferp(&inpicref);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    avfilter_copy_buffer_ref_props(out, inpicref);\n\n\n\n    interleave(out->data[0], inpicref->data[0],\n\n               il->width, inlink->h,\n\n               out->linesize[0], inpicref->linesize[0],\n\n               il->luma_mode, il->luma_swap);\n\n\n\n    if (il->nb_planes > 2) {\n\n        interleave(out->data[1], inpicref->data[1],\n\n                   il->chroma_width, il->chroma_height,\n\n                   out->linesize[1], inpicref->linesize[1],\n\n                   il->chroma_mode, il->chroma_swap);\n\n        interleave(out->data[2], inpicref->data[2],\n\n                   il->chroma_width, il->chroma_height,\n\n                   out->linesize[2], inpicref->linesize[2],\n\n                   il->chroma_mode, il->chroma_swap);\n\n    }\n\n    if (il->nb_planes == 2 && il->nb_planes == 4) {\n\n        int comp = il->nb_planes - 1;\n\n        interleave(out->data[comp], inpicref->data[comp],\n\n                   il->width, inlink->h,\n\n                   out->linesize[comp], inpicref->linesize[comp],\n\n                   il->alpha_mode, il->alpha_swap);\n\n    }\n\n\n\n    ret = ff_filter_frame(outlink, out);\n\n    avfilter_unref_bufferp(&inpicref);\n\n    return ret;\n\n}\n", "idx": 25657}
{"project": "FFmpeg", "commit_id": "dae7ff04160901a30a35af05f2f149b289c4f0b1", "target": 1, "func": "decode_lpc(WmallDecodeCtx *s)\n\n{\n\n    int ch, i, cbits;\n\n    s->lpc_order = get_bits(&s->gb, 5) + 1;\n\n    s->lpc_scaling = get_bits(&s->gb, 4);\n\n    s->lpc_intbits = get_bits(&s->gb, 3) + 1;\n\n    cbits = s->lpc_scaling + s->lpc_intbits;\n\n    for(ch = 0; ch < s->num_channels; ch++) {\n\n\tfor(i = 0; i < s->lpc_order; i++) {\n\n\t    s->lpc_coefs[ch][i] = get_sbits(&s->gb, cbits);\n\n\t}\n\n    }\n\n}\n", "idx": 25658}
{"project": "FFmpeg", "commit_id": "e403e4bdbea08af0c4a068eb560b577d1b64cf7a", "target": 1, "func": "static double get_scene_score(AVFilterContext *ctx, AVFrame *crnt, AVFrame *next)\n\n{\n\n    FrameRateContext *s = ctx->priv;\n\n    double ret = 0;\n\n\n\n    ff_dlog(ctx, \"get_scene_score()\\n\");\n\n\n\n    if (crnt->height == next->height &&\n\n        crnt->width  == next->width) {\n\n        int64_t sad;\n\n        double mafd, diff;\n\n\n\n        ff_dlog(ctx, \"get_scene_score() process\\n\");\n\n        if (s->bitdepth == 8)\n\n            sad = scene_sad8(s, crnt->data[0], crnt->linesize[0], next->data[0], next->linesize[0], crnt->height);\n\n        else\n\n            sad = scene_sad16(s, (const uint16_t*)crnt->data[0], crnt->linesize[0] >> 1, (const uint16_t*)next->data[0], next->linesize[0] >> 1, crnt->height);\n\n\n\n        mafd = (double)sad * 100.0 / (crnt->height * crnt->width) / (1 << s->bitdepth);\n\n        diff = fabs(mafd - s->prev_mafd);\n\n        ret  = av_clipf(FFMIN(mafd, diff), 0, 100.0);\n\n        s->prev_mafd = mafd;\n\n    }\n\n    ff_dlog(ctx, \"get_scene_score() result is:%f\\n\", ret);\n\n    return ret;\n\n}\n", "idx": 25659}
{"project": "FFmpeg", "commit_id": "1e90317b655699a2877478e335e998fb5e4b79d8", "target": 0, "func": "int main(int argc,char* argv[]){\n\n    int i, j;\n\n    uint64_t sse=0;\n\n    uint64_t dev;\n\n    FILE *f[2];\n\n    uint8_t buf[2][SIZE];\n\n    uint64_t psnr;\n\n    int len= argc<4 ? 1 : atoi(argv[3]);\n\n    int64_t max= (1<<(8*len))-1;\n\n    int shift= argc<5 ? 0 : atoi(argv[4]);\n\n    int skip_bytes = argc<6 ? 0 : atoi(argv[5]);\n\n\n\n    if(argc<3){\n\n        printf(\"tiny_psnr <file1> <file2> [<elem size> [<shift> [<skip bytes>]]]\\n\");\n\n        printf(\"For WAV files use the following:\\n\");\n\n        printf(\"./tiny_psnr file1.wav file2.wav 2 0 44 to skip the header.\\n\");\n\n        return -1;\n\n    }\n\n\n\n    f[0]= fopen(argv[1], \"rb\");\n\n    f[1]= fopen(argv[2], \"rb\");\n\n    if(!f[0] || !f[1]){\n\n        fprintf(stderr, \"Could not open input files.\\n\");\n\n        return -1;\n\n    }\n\n    fseek(f[shift<0], shift < 0 ? -shift : shift, SEEK_SET);\n\n\n\n    fseek(f[0],skip_bytes,SEEK_CUR);\n\n    fseek(f[1],skip_bytes,SEEK_CUR);\n\n\n\n    for(i=0;;){\n\n        if( fread(buf[0], SIZE, 1, f[0]) != 1) break;\n\n        if( fread(buf[1], SIZE, 1, f[1]) != 1) break;\n\n\n\n        for(j=0; j<SIZE; i++,j++){\n\n            int64_t a= buf[0][j];\n\n            int64_t b= buf[1][j];\n\n            if(len==2){\n\n                a= (int16_t)(a | (buf[0][++j]<<8));\n\n                b= (int16_t)(b | (buf[1][  j]<<8));\n\n            }\n\n            sse += (a-b) * (a-b);\n\n        }\n\n    }\n\n\n\n    if(!i) i=1;\n\n    dev= int_sqrt( ((sse/i)*F*F) + (((sse%i)*F*F) + i/2)/i );\n\n    if(sse)\n\n        psnr= ((2*log16(max<<16) + log16(i) - log16(sse))*284619LL*F + (1<<31)) / (1LL<<32);\n\n    else\n\n        psnr= 100*F-1; //floating point free infinity :)\n\n\n\n    printf(\"stddev:%3d.%02d PSNR:%2d.%02d bytes:%d\\n\",\n\n        (int)(dev/F), (int)(dev%F),\n\n        (int)(psnr/F), (int)(psnr%F),\n\n        i*len);\n\n    return 0;\n\n}\n", "idx": 25660}
{"project": "FFmpeg", "commit_id": "7140761481e4296723a592019a0244ebe6c1a8cf", "target": 1, "func": "static int celt_header(AVFormatContext *s, int idx)\n\n{\n\n    struct ogg *ogg = s->priv_data;\n\n    struct ogg_stream *os = ogg->streams + idx;\n\n    AVStream *st = s->streams[idx];\n\n    struct oggcelt_private *priv = os->private;\n\n    uint8_t *p = os->buf + os->pstart;\n\n\n\n    if (os->psize == 60 &&\n\n        !memcmp(p, ff_celt_codec.magic, ff_celt_codec.magicsize)) {\n\n        /* Main header */\n\n\n\n        uint32_t version, sample_rate, nb_channels;\n\n        uint32_t overlap, extra_headers;\n\n\n\n        priv = av_malloc(sizeof(struct oggcelt_private));\n\n        if (!priv)\n\n            return AVERROR(ENOMEM);\n\n        if (ff_alloc_extradata(st->codecpar, 2 * sizeof(uint32_t)) < 0) {\n\n            av_free(priv);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        version          = AV_RL32(p + 28);\n\n        /* unused header size field skipped */\n\n        sample_rate      = AV_RL32(p + 36);\n\n        nb_channels      = AV_RL32(p + 40);\n\n        overlap          = AV_RL32(p + 48);\n\n        /* unused bytes per packet field skipped */\n\n        extra_headers    = AV_RL32(p + 56);\n\n        st->codecpar->codec_type     = AVMEDIA_TYPE_AUDIO;\n\n        st->codecpar->codec_id       = AV_CODEC_ID_CELT;\n\n        st->codecpar->sample_rate    = sample_rate;\n\n        st->codecpar->channels       = nb_channels;\n\n        if (sample_rate)\n\n            avpriv_set_pts_info(st, 64, 1, sample_rate);\n\n        priv->extra_headers_left  = 1 + extra_headers;\n\n        av_free(os->private);\n\n        os->private = priv;\n\n        AV_WL32(st->codecpar->extradata + 0, overlap);\n\n        AV_WL32(st->codecpar->extradata + 4, version);\n\n        return 1;\n\n    } else if (priv && priv->extra_headers_left) {\n\n        /* Extra headers (vorbiscomment) */\n\n\n\n        ff_vorbis_stream_comment(s, st, p, os->psize);\n\n        priv->extra_headers_left--;\n\n        return 1;\n\n    } else {\n\n        return 0;\n\n    }\n\n}\n", "idx": 25662}
{"project": "FFmpeg", "commit_id": "d68542f019c89e7938297a18da282e3a892718aa", "target": 0, "func": "static int decode_group3_1d_line(AVCodecContext *avctx, GetBitContext *gb,\n\n                                 int pix_left, int *runs)\n\n{\n\n    int mode = 0, run = 0;\n\n    unsigned int t;\n\n    for(;;){\n\n        t = get_vlc2(gb, ccitt_vlc[mode].table, 9, 2);\n\n        run += t;\n\n        if(t < 64){\n\n            pix_left -= run;\n\n            *runs++ = run;\n\n            if(pix_left <= 0){\n\n                if(!pix_left)\n\n                    break;\n\n                runs[-1] = 0;\n\n                av_log(avctx, AV_LOG_ERROR, \"Run went out of bounds\\n\");\n\n                return -1;\n\n            }\n\n            run = 0;\n\n            mode = !mode;\n\n        }else if((int)t == -1){\n\n            av_log(avctx, AV_LOG_ERROR, \"Incorrect code\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n    *runs++ = 0;\n\n    return 0;\n\n}\n", "idx": 25664}
{"project": "FFmpeg", "commit_id": "0b42631641d998e509cde6fa344edc6ab5cb4ac8", "target": 0, "func": "static int get_qcx(Jpeg2000DecoderContext *s, int n, Jpeg2000QuantStyle *q)\n\n{\n\n    int i, x;\n\n\n\n    if (s->buf_end - s->buf < 1)\n\n        return AVERROR(EINVAL);\n\n\n\n    x = bytestream_get_byte(&s->buf); // Sqcd\n\n\n\n    q->nguardbits = x >> 5;\n\n    q->quantsty   = x & 0x1f;\n\n\n\n    if (q->quantsty == JPEG2000_QSTY_NONE) {\n\n        n -= 3;\n\n        if (s->buf_end - s->buf < n || 32*3 < n)\n\n            return AVERROR(EINVAL);\n\n        for (i = 0; i < n; i++)\n\n            q->expn[i] = bytestream_get_byte(&s->buf) >> 3;\n\n    } else if (q->quantsty == JPEG2000_QSTY_SI) {\n\n        if (s->buf_end - s->buf < 2)\n\n            return AVERROR(EINVAL);\n\n        x          = bytestream_get_be16(&s->buf);\n\n        q->expn[0] = x >> 11;\n\n        q->mant[0] = x & 0x7ff;\n\n        for (i = 1; i < 32 * 3; i++) {\n\n            int curexpn = FFMAX(0, q->expn[0] - (i - 1) / 3);\n\n            q->expn[i] = curexpn;\n\n            q->mant[i] = q->mant[0];\n\n        }\n\n    } else {\n\n        n = (n - 3) >> 1;\n\n        if (s->buf_end - s->buf < 2 * n || 32*3 < n)\n\n            return AVERROR(EINVAL);\n\n        for (i = 0; i < n; i++) {\n\n            x          = bytestream_get_be16(&s->buf);\n\n            q->expn[i] = x >> 11;\n\n            q->mant[i] = x & 0x7ff;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 25665}
{"project": "FFmpeg", "commit_id": "be8d812c9635f31f69c30dff9ebf565a07a7dab7", "target": 1, "func": "static void ready_residue(vorbis_enc_residue *rc, vorbis_enc_context *venc)\n\n{\n\n    int i;\n\n    assert(rc->type == 2);\n\n    rc->maxes = av_mallocz(sizeof(float[2]) * rc->classifications);\n\n    for (i = 0; i < rc->classifications; i++) {\n\n        int j;\n\n        vorbis_enc_codebook * cb;\n\n        for (j = 0; j < 8; j++)\n\n            if (rc->books[i][j] != -1)\n\n                break;\n\n        if (j == 8) // zero\n\n            continue;\n\n        cb = &venc->codebooks[rc->books[i][j]];\n\n        assert(cb->ndimentions >= 2);\n\n        assert(cb->lookup);\n\n\n\n        for (j = 0; j < cb->nentries; j++) {\n\n            float a;\n\n            if (!cb->lens[j])\n\n                continue;\n\n            a = fabs(cb->dimentions[j * cb->ndimentions]);\n\n            if (a > rc->maxes[i][0])\n\n                rc->maxes[i][0] = a;\n\n            a = fabs(cb->dimentions[j * cb->ndimentions + 1]);\n\n            if (a > rc->maxes[i][1])\n\n                rc->maxes[i][1] = a;\n\n        }\n\n    }\n\n    // small bias\n\n    for (i = 0; i < rc->classifications; i++) {\n\n        rc->maxes[i][0] += 0.8;\n\n        rc->maxes[i][1] += 0.8;\n\n    }\n\n}\n", "idx": 25667}
{"project": "FFmpeg", "commit_id": "f61bece684d9685b07895508e6c1c733b5564ccf", "target": 0, "func": "static av_cold int initFilter(int16_t **outFilter, int32_t **filterPos,\n\n                              int *outFilterSize, int xInc, int srcW,\n\n                              int dstW, int filterAlign, int one,\n\n                              int flags, int cpu_flags,\n\n                              SwsVector *srcFilter, SwsVector *dstFilter,\n\n                              double param[2], int is_horizontal)\n\n{\n\n    int i;\n\n    int filterSize;\n\n    int filter2Size;\n\n    int minFilterSize;\n\n    int64_t *filter    = NULL;\n\n    int64_t *filter2   = NULL;\n\n    const int64_t fone = 1LL << 54;\n\n    int ret            = -1;\n\n\n\n    emms_c(); // FIXME should not be required but IS (even for non-MMX versions)\n\n\n\n    // NOTE: the +3 is for the MMX(+1) / SSE(+3) scaler which reads over the end\n\n    FF_ALLOC_OR_GOTO(NULL, *filterPos, (dstW + 3) * sizeof(**filterPos), fail);\n\n\n\n    if (FFABS(xInc - 0x10000) < 10) { // unscaled\n\n        int i;\n\n        filterSize = 1;\n\n        FF_ALLOCZ_OR_GOTO(NULL, filter,\n\n                          dstW * sizeof(*filter) * filterSize, fail);\n\n\n\n        for (i = 0; i < dstW; i++) {\n\n            filter[i * filterSize] = fone;\n\n            (*filterPos)[i]        = i;\n\n        }\n\n    } else if (flags & SWS_POINT) { // lame looking point sampling mode\n\n        int i;\n\n        int xDstInSrc;\n\n        filterSize = 1;\n\n        FF_ALLOC_OR_GOTO(NULL, filter,\n\n                         dstW * sizeof(*filter) * filterSize, fail);\n\n\n\n        xDstInSrc = xInc / 2 - 0x8000;\n\n        for (i = 0; i < dstW; i++) {\n\n            int xx = (xDstInSrc - ((filterSize - 1) << 15) + (1 << 15)) >> 16;\n\n\n\n            (*filterPos)[i] = xx;\n\n            filter[i]       = fone;\n\n            xDstInSrc      += xInc;\n\n        }\n\n    } else if ((xInc <= (1 << 16) && (flags & SWS_AREA)) ||\n\n               (flags & SWS_FAST_BILINEAR)) { // bilinear upscale\n\n        int i;\n\n        int xDstInSrc;\n\n        filterSize = 2;\n\n        FF_ALLOC_OR_GOTO(NULL, filter,\n\n                         dstW * sizeof(*filter) * filterSize, fail);\n\n\n\n        xDstInSrc = xInc / 2 - 0x8000;\n\n        for (i = 0; i < dstW; i++) {\n\n            int xx = (xDstInSrc - ((filterSize - 1) << 15) + (1 << 15)) >> 16;\n\n            int j;\n\n\n\n            (*filterPos)[i] = xx;\n\n            // bilinear upscale / linear interpolate / area averaging\n\n            for (j = 0; j < filterSize; j++) {\n\n                int64_t coeff = fone - FFABS((xx << 16) - xDstInSrc) *\n\n                                (fone >> 16);\n\n                if (coeff < 0)\n\n                    coeff = 0;\n\n                filter[i * filterSize + j] = coeff;\n\n                xx++;\n\n            }\n\n            xDstInSrc += xInc;\n\n        }\n\n    } else {\n\n        int64_t xDstInSrc;\n\n        int sizeFactor;\n\n\n\n        if (flags & SWS_BICUBIC)\n\n            sizeFactor = 4;\n\n        else if (flags & SWS_X)\n\n            sizeFactor = 8;\n\n        else if (flags & SWS_AREA)\n\n            sizeFactor = 1;     // downscale only, for upscale it is bilinear\n\n        else if (flags & SWS_GAUSS)\n\n            sizeFactor = 8;     // infinite ;)\n\n        else if (flags & SWS_LANCZOS)\n\n            sizeFactor = param[0] != SWS_PARAM_DEFAULT ? ceil(2 * param[0]) : 6;\n\n        else if (flags & SWS_SINC)\n\n            sizeFactor = 20;    // infinite ;)\n\n        else if (flags & SWS_SPLINE)\n\n            sizeFactor = 20;    // infinite ;)\n\n        else if (flags & SWS_BILINEAR)\n\n            sizeFactor = 2;\n\n        else {\n\n            sizeFactor = 0;     // GCC warning killer\n\n            assert(0);\n\n        }\n\n\n\n        if (xInc <= 1 << 16)\n\n            filterSize = 1 + sizeFactor;    // upscale\n\n        else\n\n            filterSize = 1 + (sizeFactor * srcW + dstW - 1) / dstW;\n\n\n\n        filterSize = FFMIN(filterSize, srcW - 2);\n\n        filterSize = FFMAX(filterSize, 1);\n\n\n\n        FF_ALLOC_OR_GOTO(NULL, filter,\n\n                         dstW * sizeof(*filter) * filterSize, fail);\n\n\n\n        xDstInSrc = xInc - 0x10000;\n\n        for (i = 0; i < dstW; i++) {\n\n            int xx = (xDstInSrc - ((filterSize - 2) << 16)) / (1 << 17);\n\n            int j;\n\n            (*filterPos)[i] = xx;\n\n            for (j = 0; j < filterSize; j++) {\n\n                int64_t d = (FFABS(((int64_t)xx << 17) - xDstInSrc)) << 13;\n\n                double floatd;\n\n                int64_t coeff;\n\n\n\n                if (xInc > 1 << 16)\n\n                    d = d * dstW / srcW;\n\n                floatd = d * (1.0 / (1 << 30));\n\n\n\n                if (flags & SWS_BICUBIC) {\n\n                    int64_t B = (param[0] != SWS_PARAM_DEFAULT ? param[0] :   0) * (1 << 24);\n\n                    int64_t C = (param[1] != SWS_PARAM_DEFAULT ? param[1] : 0.6) * (1 << 24);\n\n\n\n                    if (d >= 1LL << 31) {\n\n                        coeff = 0.0;\n\n                    } else {\n\n                        int64_t dd  = (d  * d) >> 30;\n\n                        int64_t ddd = (dd * d) >> 30;\n\n\n\n                        if (d < 1LL << 30)\n\n                            coeff =  (12 * (1 << 24) -  9 * B - 6 * C) * ddd +\n\n                                    (-18 * (1 << 24) + 12 * B + 6 * C) *  dd +\n\n                                      (6 * (1 << 24) -  2 * B)         * (1 << 30);\n\n                        else\n\n                            coeff =      (-B -  6 * C) * ddd +\n\n                                      (6 * B + 30 * C) * dd  +\n\n                                    (-12 * B - 48 * C) * d   +\n\n                                      (8 * B + 24 * C) * (1 << 30);\n\n                    }\n\n                    coeff *= fone >> (30 + 24);\n\n                }\n\n#if 0\n\n                else if (flags & SWS_X) {\n\n                    double p  = param ? param * 0.01 : 0.3;\n\n                    coeff     = d ? sin(d * M_PI) / (d * M_PI) : 1.0;\n\n                    coeff    *= pow(2.0, -p * d * d);\n\n                }\n\n#endif\n\n                else if (flags & SWS_X) {\n\n                    double A = param[0] != SWS_PARAM_DEFAULT ? param[0] : 1.0;\n\n                    double c;\n\n\n\n                    if (floatd < 1.0)\n\n                        c = cos(floatd * M_PI);\n\n                    else\n\n                        c = -1.0;\n\n                    if (c < 0.0)\n\n                        c = -pow(-c, A);\n\n                    else\n\n                        c = pow(c, A);\n\n                    coeff = (c * 0.5 + 0.5) * fone;\n\n                } else if (flags & SWS_AREA) {\n\n                    int64_t d2 = d - (1 << 29);\n\n                    if (d2 * xInc < -(1LL << (29 + 16)))\n\n                        coeff = 1.0 * (1LL << (30 + 16));\n\n                    else if (d2 * xInc < (1LL << (29 + 16)))\n\n                        coeff = -d2 * xInc + (1LL << (29 + 16));\n\n                    else\n\n                        coeff = 0.0;\n\n                    coeff *= fone >> (30 + 16);\n\n                } else if (flags & SWS_GAUSS) {\n\n                    double p = param[0] != SWS_PARAM_DEFAULT ? param[0] : 3.0;\n\n                    coeff = (pow(2.0, -p * floatd * floatd)) * fone;\n\n                } else if (flags & SWS_SINC) {\n\n                    coeff = (d ? sin(floatd * M_PI) / (floatd * M_PI) : 1.0) * fone;\n\n                } else if (flags & SWS_LANCZOS) {\n\n                    double p = param[0] != SWS_PARAM_DEFAULT ? param[0] : 3.0;\n\n                    coeff = (d ? sin(floatd * M_PI) * sin(floatd * M_PI / p) /\n\n                             (floatd * floatd * M_PI * M_PI / p) : 1.0) * fone;\n\n                    if (floatd > p)\n\n                        coeff = 0;\n\n                } else if (flags & SWS_BILINEAR) {\n\n                    coeff = (1 << 30) - d;\n\n                    if (coeff < 0)\n\n                        coeff = 0;\n\n                    coeff *= fone >> 30;\n\n                } else if (flags & SWS_SPLINE) {\n\n                    double p = -2.196152422706632;\n\n                    coeff = getSplineCoeff(1.0, 0.0, p, -p - 1.0, floatd) * fone;\n\n                } else {\n\n                    coeff = 0.0; // GCC warning killer\n\n                    assert(0);\n\n                }\n\n\n\n                filter[i * filterSize + j] = coeff;\n\n                xx++;\n\n            }\n\n            xDstInSrc += 2 * xInc;\n\n        }\n\n    }\n\n\n\n    /* apply src & dst Filter to filter -> filter2\n\n     * av_free(filter);\n\n     */\n\n    assert(filterSize > 0);\n\n    filter2Size = filterSize;\n\n    if (srcFilter)\n\n        filter2Size += srcFilter->length - 1;\n\n    if (dstFilter)\n\n        filter2Size += dstFilter->length - 1;\n\n    assert(filter2Size > 0);\n\n    FF_ALLOCZ_OR_GOTO(NULL, filter2, filter2Size * dstW * sizeof(*filter2), fail);\n\n\n\n    for (i = 0; i < dstW; i++) {\n\n        int j, k;\n\n\n\n        if (srcFilter) {\n\n            for (k = 0; k < srcFilter->length; k++) {\n\n                for (j = 0; j < filterSize; j++)\n\n                    filter2[i * filter2Size + k + j] +=\n\n                        srcFilter->coeff[k] * filter[i * filterSize + j];\n\n            }\n\n        } else {\n\n            for (j = 0; j < filterSize; j++)\n\n                filter2[i * filter2Size + j] = filter[i * filterSize + j];\n\n        }\n\n        // FIXME dstFilter\n\n\n\n        (*filterPos)[i] += (filterSize - 1) / 2 - (filter2Size - 1) / 2;\n\n    }\n\n    av_freep(&filter);\n\n\n\n    /* try to reduce the filter-size (step1 find size and shift left) */\n\n    // Assume it is near normalized (*0.5 or *2.0 is OK but * 0.001 is not).\n\n    minFilterSize = 0;\n\n    for (i = dstW - 1; i >= 0; i--) {\n\n        int min = filter2Size;\n\n        int j;\n\n        int64_t cutOff = 0.0;\n\n\n\n        /* get rid of near zero elements on the left by shifting left */\n\n        for (j = 0; j < filter2Size; j++) {\n\n            int k;\n\n            cutOff += FFABS(filter2[i * filter2Size]);\n\n\n\n            if (cutOff > SWS_MAX_REDUCE_CUTOFF * fone)\n\n                break;\n\n\n\n            /* preserve monotonicity because the core can't handle the\n\n             * filter otherwise */\n\n            if (i < dstW - 1 && (*filterPos)[i] >= (*filterPos)[i + 1])\n\n                break;\n\n\n\n            // move filter coefficients left\n\n            for (k = 1; k < filter2Size; k++)\n\n                filter2[i * filter2Size + k - 1] = filter2[i * filter2Size + k];\n\n            filter2[i * filter2Size + k - 1] = 0;\n\n            (*filterPos)[i]++;\n\n        }\n\n\n\n        cutOff = 0;\n\n        /* count near zeros on the right */\n\n        for (j = filter2Size - 1; j > 0; j--) {\n\n            cutOff += FFABS(filter2[i * filter2Size + j]);\n\n\n\n            if (cutOff > SWS_MAX_REDUCE_CUTOFF * fone)\n\n                break;\n\n            min--;\n\n        }\n\n\n\n        if (min > minFilterSize)\n\n            minFilterSize = min;\n\n    }\n\n\n\n    if (HAVE_ALTIVEC && cpu_flags & AV_CPU_FLAG_ALTIVEC) {\n\n        // we can handle the special case 4, so we don't want to go the full 8\n\n        if (minFilterSize < 5)\n\n            filterAlign = 4;\n\n\n\n        /* We really don't want to waste our time doing useless computation, so\n\n         * fall back on the scalar C code for very small filters.\n\n         * Vectorizing is worth it only if you have a decent-sized vector. */\n\n        if (minFilterSize < 3)\n\n            filterAlign = 1;\n\n    }\n\n\n\n    if (INLINE_MMX(cpu_flags)) {\n\n        // special case for unscaled vertical filtering\n\n        if (minFilterSize == 1 && filterAlign == 2)\n\n            filterAlign = 1;\n\n    }\n\n\n\n    assert(minFilterSize > 0);\n\n    filterSize = (minFilterSize + (filterAlign - 1)) & (~(filterAlign - 1));\n\n    assert(filterSize > 0);\n\n    filter = av_malloc(filterSize * dstW * sizeof(*filter));\n\n    if (filterSize >= MAX_FILTER_SIZE * 16 /\n\n                      ((flags & SWS_ACCURATE_RND) ? APCK_SIZE : 16) || !filter)\n\n        goto fail;\n\n    *outFilterSize = filterSize;\n\n\n\n    if (flags & SWS_PRINT_INFO)\n\n        av_log(NULL, AV_LOG_VERBOSE,\n\n               \"SwScaler: reducing / aligning filtersize %d -> %d\\n\",\n\n               filter2Size, filterSize);\n\n    /* try to reduce the filter-size (step2 reduce it) */\n\n    for (i = 0; i < dstW; i++) {\n\n        int j;\n\n\n\n        for (j = 0; j < filterSize; j++) {\n\n            if (j >= filter2Size)\n\n                filter[i * filterSize + j] = 0;\n\n            else\n\n                filter[i * filterSize + j] = filter2[i * filter2Size + j];\n\n            if ((flags & SWS_BITEXACT) && j >= minFilterSize)\n\n                filter[i * filterSize + j] = 0;\n\n        }\n\n    }\n\n\n\n    // FIXME try to align filterPos if possible\n\n\n\n    // fix borders\n\n    if (is_horizontal) {\n\n        for (i = 0; i < dstW; i++) {\n\n            int j;\n\n            if ((*filterPos)[i] < 0) {\n\n                // move filter coefficients left to compensate for filterPos\n\n                for (j = 1; j < filterSize; j++) {\n\n                    int left = FFMAX(j + (*filterPos)[i], 0);\n\n                    filter[i * filterSize + left] += filter[i * filterSize + j];\n\n                    filter[i * filterSize + j]     = 0;\n\n                }\n\n                (*filterPos)[i] = 0;\n\n            }\n\n\n\n            if ((*filterPos)[i] + filterSize > srcW) {\n\n                int shift = (*filterPos)[i] + filterSize - srcW;\n\n                // move filter coefficients right to compensate for filterPos\n\n                for (j = filterSize - 2; j >= 0; j--) {\n\n                    int right = FFMIN(j + shift, filterSize - 1);\n\n                    filter[i * filterSize + right] += filter[i * filterSize + j];\n\n                    filter[i * filterSize + j]      = 0;\n\n                }\n\n                (*filterPos)[i] = srcW - filterSize;\n\n            }\n\n        }\n\n    }\n\n\n\n    // Note the +1 is for the MMX scaler which reads over the end\n\n    /* align at 16 for AltiVec (needed by hScale_altivec_real) */\n\n    FF_ALLOCZ_OR_GOTO(NULL, *outFilter,\n\n                      *outFilterSize * (dstW + 3) * sizeof(int16_t), fail);\n\n\n\n    /* normalize & store in outFilter */\n\n    for (i = 0; i < dstW; i++) {\n\n        int j;\n\n        int64_t error = 0;\n\n        int64_t sum   = 0;\n\n\n\n        for (j = 0; j < filterSize; j++) {\n\n            sum += filter[i * filterSize + j];\n\n        }\n\n        sum = (sum + one / 2) / one;\n\n        for (j = 0; j < *outFilterSize; j++) {\n\n            int64_t v = filter[i * filterSize + j] + error;\n\n            int intV  = ROUNDED_DIV(v, sum);\n\n            (*outFilter)[i * (*outFilterSize) + j] = intV;\n\n            error                                  = v - intV * sum;\n\n        }\n\n    }\n\n\n\n    (*filterPos)[dstW + 0] =\n\n    (*filterPos)[dstW + 1] =\n\n    (*filterPos)[dstW + 2] = (*filterPos)[dstW - 1]; /* the MMX/SSE scaler will\n\n                                                      * read over the end */\n\n    for (i = 0; i < *outFilterSize; i++) {\n\n        int k = (dstW - 1) * (*outFilterSize) + i;\n\n        (*outFilter)[k + 1 * (*outFilterSize)] =\n\n        (*outFilter)[k + 2 * (*outFilterSize)] =\n\n        (*outFilter)[k + 3 * (*outFilterSize)] = (*outFilter)[k];\n\n    }\n\n\n\n    ret = 0;\n\n\n\nfail:\n\n    av_free(filter);\n\n    av_free(filter2);\n\n    return ret;\n\n}\n", "idx": 25671}
{"project": "FFmpeg", "commit_id": "204cb29b3c84a74cbcd059d353c70c8bdc567d98", "target": 1, "func": "static av_cold int shorten_decode_close(AVCodecContext *avctx)\n\n{\n\n    ShortenContext *s = avctx->priv_data;\n\n    int i;\n\n\n\n    for (i = 0; i < s->channels; i++) {\n\n        s->decoded[i] -= s->nwrap;\n\n        av_freep(&s->decoded[i]);\n\n        av_freep(&s->offset[i]);\n\n    }\n\n    av_freep(&s->bitstream);\n\n    av_freep(&s->coeffs);\n\n\n\n    return 0;\n\n}\n", "idx": 25672}
{"project": "FFmpeg", "commit_id": "aa74810fc6b9afe21c9be3725e3d078d10633670", "target": 1, "func": "int ff_init_vlc_sparse(VLC *vlc, int nb_bits, int nb_codes,\n\n                       const void *bits, int bits_wrap, int bits_size,\n\n                       const void *codes, int codes_wrap, int codes_size,\n\n                       const void *symbols, int symbols_wrap, int symbols_size,\n\n                       int flags)\n\n{\n\n    VLCcode *buf;\n\n    int i, j, ret;\n\n\n\n    vlc->bits = nb_bits;\n\n    if (flags & INIT_VLC_USE_NEW_STATIC) {\n\n        VLC dyn_vlc = *vlc;\n\n\n\n        if (vlc->table_size)\n\n            return 0;\n\n\n\n        ret = ff_init_vlc_sparse(&dyn_vlc, nb_bits, nb_codes,\n\n                                 bits, bits_wrap, bits_size,\n\n                                 codes, codes_wrap, codes_size,\n\n                                 symbols, symbols_wrap, symbols_size,\n\n                                 flags & ~INIT_VLC_USE_NEW_STATIC);\n\n        av_assert0(ret >= 0);\n\n        av_assert0(dyn_vlc.table_size <= vlc->table_allocated);\n\n        if (dyn_vlc.table_size < vlc->table_allocated)\n\n            av_log(NULL, AV_LOG_ERROR, \"needed %d had %d\\n\", dyn_vlc.table_size, vlc->table_allocated);\n\n        memcpy(vlc->table, dyn_vlc.table, dyn_vlc.table_size * sizeof(*vlc->table));\n\n        vlc->table_size = dyn_vlc.table_size;\n\n        ff_free_vlc(&dyn_vlc);\n\n        return 0;\n\n    } else {\n\n        vlc->table           = NULL;\n\n        vlc->table_allocated = 0;\n\n        vlc->table_size      = 0;\n\n    }\n\n\n\n    av_dlog(NULL, \"build table nb_codes=%d\\n\", nb_codes);\n\n\n\n    buf = av_malloc((nb_codes + 1) * sizeof(VLCcode));\n\n\n\n\n\n    av_assert0(symbols_size <= 2 || !symbols);\n\n    j = 0;\n\n#define COPY(condition)\\\n\n    for (i = 0; i < nb_codes; i++) {                                        \\\n\n        GET_DATA(buf[j].bits, bits, i, bits_wrap, bits_size);               \\\n\n        if (!(condition))                                                   \\\n\n            continue;                                                       \\\n\n        if (buf[j].bits > 3*nb_bits || buf[j].bits>32) {                    \\\n\n            av_log(NULL, AV_LOG_ERROR, \"Too long VLC (%d) in init_vlc\\n\", buf[j].bits);\\\n\n            av_free(buf);                                                   \\\n\n            return -1;                                                      \\\n\n        }                                                                   \\\n\n        GET_DATA(buf[j].code, codes, i, codes_wrap, codes_size);            \\\n\n        if (buf[j].code >= (1LL<<buf[j].bits)) {                            \\\n\n            av_log(NULL, AV_LOG_ERROR, \"Invalid code in init_vlc\\n\");       \\\n\n            av_free(buf);                                                   \\\n\n            return -1;                                                      \\\n\n        }                                                                   \\\n\n        if (flags & INIT_VLC_LE)                                            \\\n\n            buf[j].code = bitswap_32(buf[j].code);                          \\\n\n        else                                                                \\\n\n            buf[j].code <<= 32 - buf[j].bits;                               \\\n\n        if (symbols)                                                        \\\n\n            GET_DATA(buf[j].symbol, symbols, i, symbols_wrap, symbols_size) \\\n\n        else                                                                \\\n\n            buf[j].symbol = i;                                              \\\n\n        j++;                                                                \\\n\n    }\n\n    COPY(buf[j].bits > nb_bits);\n\n    // qsort is the slowest part of init_vlc, and could probably be improved or avoided\n\n    qsort(buf, j, sizeof(VLCcode), compare_vlcspec);\n\n    COPY(buf[j].bits && buf[j].bits <= nb_bits);\n\n    nb_codes = j;\n\n\n\n    ret = build_table(vlc, nb_bits, nb_codes, buf, flags);\n\n\n\n    av_free(buf);\n\n    if (ret < 0) {\n\n        av_freep(&vlc->table);\n\n        return ret;\n\n    }\n\n    return 0;\n\n}", "idx": 25673}
{"project": "FFmpeg", "commit_id": "7dabc78ce13e3baa37292f42df2364b4ccd2aa78", "target": 0, "func": "AVRational av_d2q(double d, int max)\n\n{\n\n    AVRational a;\n\n    int exponent;\n\n    int64_t den;\n\n    if (isnan(d))\n\n        return (AVRational) { 0,0 };\n\n    if (fabs(d) > INT_MAX + 3LL)\n\n        return (AVRational) { d < 0 ? -1 : 1, 0 };\n\n    frexp(d, &exponent);\n\n    exponent = FFMAX(exponent-1, 0);\n\n    den = 1LL << (61 - exponent);\n\n    // (int64_t)rint() and llrint() do not work with gcc on ia64 and sparc64\n\n    av_reduce(&a.num, &a.den, floor(d * den + 0.5), den, max);\n\n    if ((!a.num || !a.den) && d && max>0 && max<INT_MAX)\n\n        av_reduce(&a.num, &a.den, floor(d * den + 0.5), den, INT_MAX);\n\n\n\n    return a;\n\n}\n", "idx": 25677}
{"project": "FFmpeg", "commit_id": "ce1ebb31a9a0e556a89cd7681082af19fbc1cced", "target": 0, "func": "static unsigned tget(GetByteContext *gb, int type, int le)\n\n{\n\n    switch (type) {\n\n    case TIFF_BYTE : return bytestream2_get_byteu(gb);\n\n    case TIFF_SHORT: return tget_short(gb, le);\n\n    case TIFF_LONG : return tget_long(gb, le);\n\n    default        : return UINT_MAX;\n\n    }\n\n}\n", "idx": 25678}
{"project": "FFmpeg", "commit_id": "a7ba3244131d96d9ab7a99ef30dc7276efd05cc7", "target": 1, "func": "static int rtp_parse_mp4_au(PayloadContext *data, const uint8_t *buf)\n\n{\n\n    int au_headers_length, au_header_size, i;\n\n    GetBitContext getbitcontext;\n\n\n\n    /* decode the first 2 bytes where the AUHeader sections are stored\n\n       length in bits */\n\n    au_headers_length = AV_RB16(buf);\n\n\n\n    if (au_headers_length > RTP_MAX_PACKET_LENGTH)\n\n      return -1;\n\n\n\n    data->au_headers_length_bytes = (au_headers_length + 7) / 8;\n\n\n\n    /* skip AU headers length section (2 bytes) */\n\n    buf += 2;\n\n\n\n    init_get_bits(&getbitcontext, buf, data->au_headers_length_bytes * 8);\n\n\n\n    /* XXX: Wrong if optionnal additional sections are present (cts, dts etc...) */\n\n    au_header_size = data->sizelength + data->indexlength;\n\n    if (au_header_size <= 0 || (au_headers_length % au_header_size != 0))\n\n        return -1;\n\n\n\n    data->nb_au_headers = au_headers_length / au_header_size;\n\n    if (!data->au_headers || data->au_headers_allocated < data->nb_au_headers) {\n\n        av_free(data->au_headers);\n\n        data->au_headers = av_malloc(sizeof(struct AUHeaders) * data->nb_au_headers);\n\n        if (!data->au_headers)\n\n            return AVERROR(ENOMEM);\n\n        data->au_headers_allocated = data->nb_au_headers;\n\n    }\n\n\n\n    /* XXX: We handle multiple AU Section as only one (need to fix this for interleaving)\n\n       In my test, the FAAD decoder does not behave correctly when sending each AU one by one\n\n       but does when sending the whole as one big packet...  */\n\n    data->au_headers[0].size = 0;\n\n    data->au_headers[0].index = 0;\n\n    for (i = 0; i < data->nb_au_headers; ++i) {\n\n        data->au_headers[0].size += get_bits_long(&getbitcontext, data->sizelength);\n\n        data->au_headers[0].index = get_bits_long(&getbitcontext, data->indexlength);\n\n    }\n\n\n\n    data->nb_au_headers = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 25683}
{"project": "FFmpeg", "commit_id": "2da0d70d5eebe42f9fcd27ee554419ebe2a5da06", "target": 1, "func": "static inline void RENAME(palToUV)(uint8_t *dstU, uint8_t *dstV, uint8_t *src1, uint8_t *src2, int width, uint32_t *pal)\n\n{\n\n\tint i;\n\n        assert(src1 == src2);\n\n\tfor(i=0; i<width; i++)\n\n\t{\n\n\t\tint p= pal[src1[i]];\n\n\n\n\t\tdstU[i]= p>>8;\n\n\t\tdstV[i]= p>>16;\n\n\t}\n\n}\n", "idx": 25684}
{"project": "FFmpeg", "commit_id": "7782cb207a09f4acf0b2a935ca81076b117660a2", "target": 1, "func": "static void targa_decode_rle(AVCodecContext *avctx, TargaContext *s, const uint8_t *src, uint8_t *dst, int w, int h, int stride, int bpp)\n\n{\n\n    int i, x, y;\n\n    int depth = (bpp + 1) >> 3;\n\n    int type, count;\n\n    int diff;\n\n\n\n    diff = stride - w * depth;\n\n    x = y = 0;\n\n    while(y < h){\n\n        type = *src++;\n\n        count = (type & 0x7F) + 1;\n\n        type &= 0x80;\n\n        if((x + count > w) && (x + count + 1 > (h - y) * w)){\n\n            av_log(avctx, AV_LOG_ERROR, \"Packet went out of bounds: position (%i,%i) size %i\\n\", x, y, count);\n\n            return;\n\n        }\n\n        for(i = 0; i < count; i++){\n\n            switch(depth){\n\n            case 1:\n\n                *dst = *src;\n\n                break;\n\n            case 2:\n\n                *((uint16_t*)dst) = AV_RL16(src);\n\n                break;\n\n            case 3:\n\n                dst[0] = src[0];\n\n                dst[1] = src[1];\n\n                dst[2] = src[2];\n\n                break;\n\n            case 4:\n\n                *((uint32_t*)dst) = AV_RL32(src);\n\n                break;\n\n            }\n\n            dst += depth;\n\n            if(!type)\n\n                src += depth;\n\n\n\n            x++;\n\n            if(x == w){\n\n                x = 0;\n\n                y++;\n\n                dst += diff;\n\n            }\n\n        }\n\n        if(type)\n\n            src += depth;\n\n    }\n\n}\n", "idx": 25689}
{"project": "FFmpeg", "commit_id": "e1631f8ebe9a8f2a9cca85d60160b9be94eb63f3", "target": 1, "func": "static int aasc_decode_frame(AVCodecContext *avctx,\n                              void *data, int *data_size,\n                              AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size;\n    AascContext *s = avctx->priv_data;\n    int compr, i, stride, psize;\n    s->frame.reference = 3;\n    s->frame.buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE;\n    if (avctx->reget_buffer(avctx, &s->frame)) {\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n        return -1;\n    compr = AV_RL32(buf);\n    buf += 4;\n    buf_size -= 4;\n    psize = avctx->bits_per_coded_sample / 8;\n    switch (avctx->codec_tag) {\n    case MKTAG('A', 'A', 'S', '4'):\n        bytestream2_init(&s->gb, buf - 4, buf_size + 4);\n        ff_msrle_decode(avctx, (AVPicture*)&s->frame, 8, &s->gb);\n        break;\n    case MKTAG('A', 'A', 'S', 'C'):\n    switch(compr){\n    case 0:\n        stride = (avctx->width * psize + psize) & ~psize;\n        for(i = avctx->height - 1; i >= 0; i--){\n            if(avctx->width * psize > buf_size){\n                av_log(avctx, AV_LOG_ERROR, \"Next line is beyond buffer bounds\\n\");\n                break;\n            memcpy(s->frame.data[0] + i*s->frame.linesize[0], buf, avctx->width * psize);\n            buf += stride;\n            buf_size -= stride;\n        break;\n    case 1:\n        bytestream2_init(&s->gb, buf, buf_size);\n        ff_msrle_decode(avctx, (AVPicture*)&s->frame, 8, &s->gb);\n        break;\n    default:\n        av_log(avctx, AV_LOG_ERROR, \"Unknown compression type %d\\n\", compr);\n        return -1;\n        break;\n    default:\n        av_log(avctx, AV_LOG_ERROR, \"Unknown FourCC: %X\\n\", avctx->codec_tag);\n        return -1;\n    if (avctx->pix_fmt == AV_PIX_FMT_PAL8)\n        memcpy(s->frame.data[1], s->palette, s->palette_size);\n    *data_size = sizeof(AVFrame);\n    *(AVFrame*)data = s->frame;\n    /* report that the buffer was completely consumed */\n    return buf_size;", "idx": 25690}
{"project": "FFmpeg", "commit_id": "1181d93231e9b807965724587d363c1cfd5a1d0d", "target": 0, "func": "void ff_avg_h264_qpel4_mc13_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_hv_qrt_and_aver_dst_4x4_msa(src + stride - 2,\n\n                                         src - (stride * 2),\n\n                                         stride, dst, stride);\n\n}\n", "idx": 25693}
{"project": "FFmpeg", "commit_id": "a6af5da7a2f817d52ea00e2aa93ccf5804afa3e0", "target": 0, "func": "static int resample(SwrContext *s, AudioData *out_param, int out_count,\n\n                             const AudioData * in_param, int in_count){\n\n    AudioData in, out, tmp;\n\n    int ret_sum=0;\n\n    int border=0;\n\n\n\n    av_assert1(s->in_buffer.ch_count == in_param->ch_count);\n\n    av_assert1(s->in_buffer.planar   == in_param->planar);\n\n    av_assert1(s->in_buffer.fmt      == in_param->fmt);\n\n\n\n    tmp=out=*out_param;\n\n    in =  *in_param;\n\n\n\n    do{\n\n        int ret, size, consumed;\n\n        if(!s->resample_in_constraint && s->in_buffer_count){\n\n            buf_set(&tmp, &s->in_buffer, s->in_buffer_index);\n\n            ret= s->resampler->multiple_resample(s->resample, &out, out_count, &tmp, s->in_buffer_count, &consumed);\n\n            out_count -= ret;\n\n            ret_sum += ret;\n\n            buf_set(&out, &out, ret);\n\n            s->in_buffer_count -= consumed;\n\n            s->in_buffer_index += consumed;\n\n\n\n            if(!in_count)\n\n                break;\n\n            if(s->in_buffer_count <= border){\n\n                buf_set(&in, &in, -s->in_buffer_count);\n\n                in_count += s->in_buffer_count;\n\n                s->in_buffer_count=0;\n\n                s->in_buffer_index=0;\n\n                border = 0;\n\n            }\n\n        }\n\n\n\n        if((s->flushed || in_count) && !s->in_buffer_count){\n\n            s->in_buffer_index=0;\n\n            ret= s->resampler->multiple_resample(s->resample, &out, out_count, &in, in_count, &consumed);\n\n            out_count -= ret;\n\n            ret_sum += ret;\n\n            buf_set(&out, &out, ret);\n\n            in_count -= consumed;\n\n            buf_set(&in, &in, consumed);\n\n        }\n\n\n\n        //TODO is this check sane considering the advanced copy avoidance below\n\n        size= s->in_buffer_index + s->in_buffer_count + in_count;\n\n        if(   size > s->in_buffer.count\n\n           && s->in_buffer_count + in_count <= s->in_buffer_index){\n\n            buf_set(&tmp, &s->in_buffer, s->in_buffer_index);\n\n            copy(&s->in_buffer, &tmp, s->in_buffer_count);\n\n            s->in_buffer_index=0;\n\n        }else\n\n            if((ret=swri_realloc_audio(&s->in_buffer, size)) < 0)\n\n                return ret;\n\n\n\n        if(in_count){\n\n            int count= in_count;\n\n            if(s->in_buffer_count && s->in_buffer_count+2 < count && out_count) count= s->in_buffer_count+2;\n\n\n\n            buf_set(&tmp, &s->in_buffer, s->in_buffer_index + s->in_buffer_count);\n\n            copy(&tmp, &in, /*in_*/count);\n\n            s->in_buffer_count += count;\n\n            in_count -= count;\n\n            border += count;\n\n            buf_set(&in, &in, count);\n\n            s->resample_in_constraint= 0;\n\n            if(s->in_buffer_count != count || in_count)\n\n                continue;\n\n        }\n\n        break;\n\n    }while(1);\n\n\n\n    s->resample_in_constraint= !!out_count;\n\n\n\n    return ret_sum;\n\n}\n", "idx": 25694}
{"project": "FFmpeg", "commit_id": "a2f680c7bc7642c687aeb4e14d00ac74833c7a09", "target": 0, "func": "int ff_mjpeg_decode_sof(MJpegDecodeContext *s)\n\n{\n\n    int len, nb_components, i, width, height, pix_fmt_id;\n\n\n\n    s->cur_scan = 0;\n\n    s->upscale_h = s->upscale_v = 0;\n\n\n\n    /* XXX: verify len field validity */\n\n    len     = get_bits(&s->gb, 16);\n\n    s->bits = get_bits(&s->gb, 8);\n\n\n\n    if (s->pegasus_rct)\n\n        s->bits = 9;\n\n    if (s->bits == 9 && !s->pegasus_rct)\n\n        s->rct  = 1;    // FIXME ugly\n\n\n\n    if (s->bits != 8 && !s->lossless) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"only 8 bits/component accepted\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(s->lossless && s->avctx->lowres){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"lowres is not possible with lossless jpeg\\n\");\n\n        return -1;\n\n    }\n\n\n\n    height = get_bits(&s->gb, 16);\n\n    width  = get_bits(&s->gb, 16);\n\n\n\n    // HACK for odd_height.mov\n\n    if (s->interlaced && s->width == width && s->height == height + 1)\n\n        height= s->height;\n\n\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"sof0: picture: %dx%d\\n\", width, height);\n\n    if (av_image_check_size(width, height, 0, s->avctx))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    nb_components = get_bits(&s->gb, 8);\n\n    if (nb_components <= 0 ||\n\n        nb_components > MAX_COMPONENTS)\n\n        return -1;\n\n    if (s->interlaced && (s->bottom_field == !s->interlace_polarity)) {\n\n        if (nb_components != s->nb_components) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"nb_components changing in interlaced picture\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n    if (s->ls && !(s->bits <= 8 || nb_components == 1)) {\n\n        av_log_missing_feature(s->avctx,\n\n                               \"For JPEG-LS anything except <= 8 bits/component\"\n\n                               \" or 16-bit gray\", 0);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n    s->nb_components = nb_components;\n\n    s->h_max         = 1;\n\n    s->v_max         = 1;\n\n    memset(s->h_count, 0, sizeof(s->h_count));\n\n    memset(s->v_count, 0, sizeof(s->v_count));\n\n    for (i = 0; i < nb_components; i++) {\n\n        /* component id */\n\n        s->component_id[i] = get_bits(&s->gb, 8) - 1;\n\n        s->h_count[i]      = get_bits(&s->gb, 4);\n\n        s->v_count[i]      = get_bits(&s->gb, 4);\n\n        /* compute hmax and vmax (only used in interleaved case) */\n\n        if (s->h_count[i] > s->h_max)\n\n            s->h_max = s->h_count[i];\n\n        if (s->v_count[i] > s->v_max)\n\n            s->v_max = s->v_count[i];\n\n        if (!s->h_count[i] || !s->v_count[i]) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"h/v_count is 0\\n\");\n\n            return -1;\n\n        }\n\n        s->quant_index[i] = get_bits(&s->gb, 8);\n\n        if (s->quant_index[i] >= 4)\n\n            return AVERROR_INVALIDDATA;\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"component %d %d:%d id: %d quant:%d\\n\",\n\n               i, s->h_count[i], s->v_count[i],\n\n               s->component_id[i], s->quant_index[i]);\n\n    }\n\n\n\n    if (s->ls && (s->h_max > 1 || s->v_max > 1)) {\n\n        av_log_missing_feature(s->avctx, \"Subsampling in JPEG-LS\", 0);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if (s->v_max == 1 && s->h_max == 1 && s->lossless==1 && nb_components==3)\n\n        s->rgb = 1;\n\n\n\n    /* if different size, realloc/alloc picture */\n\n    /* XXX: also check h_count and v_count */\n\n    if (width != s->width || height != s->height) {\n\n        av_freep(&s->qscale_table);\n\n\n\n        s->width      = width;\n\n        s->height     = height;\n\n        s->interlaced = 0;\n\n\n\n        /* test interlaced mode */\n\n        if (s->first_picture   &&\n\n            s->org_height != 0 &&\n\n            s->height < ((s->org_height * 3) / 4)) {\n\n            s->interlaced                    = 1;\n\n            s->bottom_field                  = s->interlace_polarity;\n\n            s->picture_ptr->interlaced_frame = 1;\n\n            s->picture_ptr->top_field_first  = !s->interlace_polarity;\n\n            height *= 2;\n\n        }\n\n\n\n        avcodec_set_dimensions(s->avctx, width, height);\n\n\n\n        s->qscale_table  = av_mallocz((s->width + 15) / 16);\n\n        s->first_picture = 0;\n\n    }\n\n\n\n    if (s->interlaced && (s->bottom_field == !s->interlace_polarity)) {\n\n        if (s->progressive) {\n\n            av_log_ask_for_sample(s->avctx, \"progressively coded interlaced pictures not supported\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    } else{\n\n    /* XXX: not complete test ! */\n\n    pix_fmt_id = (s->h_count[0] << 28) | (s->v_count[0] << 24) |\n\n                 (s->h_count[1] << 20) | (s->v_count[1] << 16) |\n\n                 (s->h_count[2] << 12) | (s->v_count[2] <<  8) |\n\n                 (s->h_count[3] <<  4) |  s->v_count[3];\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"pix fmt id %x\\n\", pix_fmt_id);\n\n    /* NOTE we do not allocate pictures large enough for the possible\n\n     * padding of h/v_count being 4 */\n\n    if (!(pix_fmt_id & 0xD0D0D0D0))\n\n        pix_fmt_id -= (pix_fmt_id & 0xF0F0F0F0) >> 1;\n\n    if (!(pix_fmt_id & 0x0D0D0D0D))\n\n        pix_fmt_id -= (pix_fmt_id & 0x0F0F0F0F) >> 1;\n\n\n\n    switch (pix_fmt_id) {\n\n    case 0x11111100:\n\n        if (s->rgb)\n\n            s->avctx->pix_fmt = AV_PIX_FMT_BGR24;\n\n        else {\n\n            if (s->component_id[0] == 'Q' && s->component_id[1] == 'F' && s->component_id[2] == 'A') {\n\n                s->avctx->pix_fmt = AV_PIX_FMT_GBR24P;\n\n            } else {\n\n            s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P;\n\n            s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;\n\n            }\n\n        }\n\n        av_assert0(s->nb_components == 3);\n\n        break;\n\n    case 0x12121100:\n\n    case 0x22122100:\n\n        s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P;\n\n        s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;\n\n        s->upscale_v = 2;\n\n        s->upscale_h = (pix_fmt_id == 0x22122100);\n\n        s->chroma_height = s->height;\n\n        break;\n\n    case 0x21211100:\n\n    case 0x22211200:\n\n        s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P;\n\n        s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;\n\n        s->upscale_v = (pix_fmt_id == 0x22211200);\n\n        s->upscale_h = 2;\n\n        s->chroma_height = s->height;\n\n        break;\n\n    case 0x22221100:\n\n        s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV444P : AV_PIX_FMT_YUVJ444P;\n\n        s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;\n\n        s->upscale_v = 2;\n\n        s->upscale_h = 2;\n\n        s->chroma_height = s->height / 2;\n\n        break;\n\n    case 0x11000000:\n\n        if(s->bits <= 8)\n\n            s->avctx->pix_fmt = AV_PIX_FMT_GRAY8;\n\n        else\n\n            s->avctx->pix_fmt = AV_PIX_FMT_GRAY16;\n\n        break;\n\n    case 0x12111100:\n\n    case 0x22211100:\n\n    case 0x22112100:\n\n        s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV440P : AV_PIX_FMT_YUVJ440P;\n\n        s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;\n\n        s->upscale_h = (pix_fmt_id == 0x22211100) * 2 + (pix_fmt_id == 0x22112100);\n\n        s->chroma_height = s->height / 2;\n\n        break;\n\n    case 0x21111100:\n\n        s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV422P : AV_PIX_FMT_YUVJ422P;\n\n        s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;\n\n        break;\n\n    case 0x22121100:\n\n    case 0x22111200:\n\n        s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV422P : AV_PIX_FMT_YUVJ422P;\n\n        s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;\n\n        s->upscale_v = (pix_fmt_id == 0x22121100) + 1;\n\n        break;\n\n    case 0x22111100:\n\n        s->avctx->pix_fmt = s->cs_itu601 ? AV_PIX_FMT_YUV420P : AV_PIX_FMT_YUVJ420P;\n\n        s->avctx->color_range = s->cs_itu601 ? AVCOL_RANGE_MPEG : AVCOL_RANGE_JPEG;\n\n        break;\n\n    default:\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Unhandled pixel format 0x%x\\n\", pix_fmt_id);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n    if ((s->upscale_h || s->upscale_v) && s->avctx->lowres) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"lowres not supported for weird subsampling\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n    if (s->ls) {\n\n        s->upscale_h = s->upscale_v = 0;\n\n        if (s->nb_components > 1)\n\n            s->avctx->pix_fmt = AV_PIX_FMT_RGB24;\n\n        else if (s->bits <= 8)\n\n            s->avctx->pix_fmt = AV_PIX_FMT_GRAY8;\n\n        else\n\n            s->avctx->pix_fmt = AV_PIX_FMT_GRAY16;\n\n    }\n\n\n\n    if (s->picture_ptr->data[0])\n\n        s->avctx->release_buffer(s->avctx, s->picture_ptr);\n\n\n\n    if (s->avctx->get_buffer(s->avctx, s->picture_ptr) < 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n    s->picture_ptr->pict_type = AV_PICTURE_TYPE_I;\n\n    s->picture_ptr->key_frame = 1;\n\n    s->got_picture            = 1;\n\n\n\n    for (i = 0; i < 3; i++)\n\n        s->linesize[i] = s->picture_ptr->linesize[i] << s->interlaced;\n\n\n\n    av_dlog(s->avctx, \"%d %d %d %d %d %d\\n\",\n\n            s->width, s->height, s->linesize[0], s->linesize[1],\n\n            s->interlaced, s->avctx->height);\n\n\n\n    if (len != (8 + (3 * nb_components)))\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"decode_sof0: error, len(%d) mismatch\\n\", len);\n\n    }\n\n\n\n    /* totally blank picture as progressive JPEG will only add details to it */\n\n    if (s->progressive) {\n\n        int bw = (width  + s->h_max * 8 - 1) / (s->h_max * 8);\n\n        int bh = (height + s->v_max * 8 - 1) / (s->v_max * 8);\n\n        for (i = 0; i < s->nb_components; i++) {\n\n            int size = bw * bh * s->h_count[i] * s->v_count[i];\n\n            av_freep(&s->blocks[i]);\n\n            av_freep(&s->last_nnz[i]);\n\n            s->blocks[i]       = av_malloc(size * sizeof(**s->blocks));\n\n            s->last_nnz[i]     = av_mallocz(size * sizeof(**s->last_nnz));\n\n            s->block_stride[i] = bw * s->h_count[i];\n\n        }\n\n        memset(s->coefs_finished, 0, sizeof(s->coefs_finished));\n\n    }\n\n    return 0;\n\n}\n", "idx": 25695}
{"project": "FFmpeg", "commit_id": "6a63ff19b6a7fe3bc32c7fb4a62fca8f65786432", "target": 0, "func": "static int mov_read_stts(MOVContext *c, ByteIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st = c->fc->streams[c->fc->nb_streams-1];\n\n    MOVStreamContext *sc = st->priv_data;\n\n    unsigned int i, entries;\n\n    int64_t duration=0;\n\n    int64_t total_sample_count=0;\n\n\n\n    get_byte(pb); /* version */\n\n    get_be24(pb); /* flags */\n\n    entries = get_be32(pb);\n\n\n\n    dprintf(c->fc, \"track[%i].stts.entries = %i\\n\", c->fc->nb_streams-1, entries);\n\n\n\n    if(entries >= UINT_MAX / sizeof(*sc->stts_data))\n\n        return -1;\n\n    sc->stts_data = av_malloc(entries * sizeof(*sc->stts_data));\n\n    if (!sc->stts_data)\n\n        return AVERROR(ENOMEM);\n\n    sc->stts_count = entries;\n\n\n\n    for(i=0; i<entries; i++) {\n\n        int sample_duration;\n\n        int sample_count;\n\n\n\n        sample_count=get_be32(pb);\n\n        sample_duration = get_be32(pb);\n\n        sc->stts_data[i].count= sample_count;\n\n        sc->stts_data[i].duration= sample_duration;\n\n\n\n        dprintf(c->fc, \"sample_count=%d, sample_duration=%d\\n\",sample_count,sample_duration);\n\n\n\n        duration+=(int64_t)sample_duration*sample_count;\n\n        total_sample_count+=sample_count;\n\n    }\n\n\n\n    st->nb_frames= total_sample_count;\n\n    if(duration)\n\n        st->duration= duration;\n\n    return 0;\n\n}\n", "idx": 25703}
{"project": "FFmpeg", "commit_id": "7cc84d241ba6ef8e27e4d057176a4ad385ad3d59", "target": 1, "func": "static int decode_i_picture_secondary_header(VC9Context *v)\n\n{\n\n    int status;\n\n#if HAS_ADVANCED_PROFILE\n\n    if (v->profile > PROFILE_MAIN)\n\n    {\n\n        v->s.ac_pred = get_bits(&v->s.gb, 1);\n\n        if (v->postprocflag) v->postproc = get_bits(&v->s.gb, 1);\n\n        /* 7.1.1.34 + 8.5.2 */\n\n        if (v->overlap && v->pq<9)\n\n        {\n\n            v->condover = get_bits(&v->s.gb, 1);\n\n            if (v->condover)\n\n            {\n\n                v->condover = 2+get_bits(&v->s.gb, 1);\n\n                if (v->condover == 3)\n\n                {\n\n                    status = bitplane_decoding(&v->over_flags_plane, v);\n\n                    if (status < 0) return -1;\n\n#  if TRACE\n\n                    av_log(v->s.avctx, AV_LOG_DEBUG, \"Overflags plane encoding: \"\n\n                           \"Imode: %i, Invert: %i\\n\", status>>1, status&1);\n\n#  endif\n\n                }\n\n            }\n\n        }\n\n    }\n\n#endif\n\n\n\n    /* Epilog (AC/DC syntax) should be done in caller */\n\n    return 0;\n\n}\n", "idx": 25718}
{"project": "FFmpeg", "commit_id": "4ed899f2c5848b75b61d13ad42942ecc2a4386f9", "target": 1, "func": "static AVStream *get_subtitle_pkt(AVFormatContext *s, AVStream *next_st,\n\n                                  AVPacket *pkt)\n\n{\n\n    AVIStream *ast, *next_ast = next_st->priv_data;\n\n    int64_t ts, next_ts, ts_min = INT64_MAX;\n\n    AVStream *st, *sub_st = NULL;\n\n    int i;\n\n\n\n    next_ts = av_rescale_q(next_ast->frame_offset, next_st->time_base,\n\n                           AV_TIME_BASE_Q);\n\n\n\n    for (i=0; i<s->nb_streams; i++) {\n\n        st  = s->streams[i];\n\n        ast = st->priv_data;\n\n        if (st->discard < AVDISCARD_ALL && ast->sub_pkt.data) {\n\n            ts = av_rescale_q(ast->sub_pkt.dts, st->time_base, AV_TIME_BASE_Q);\n\n            if (ts <= next_ts && ts < ts_min) {\n\n                ts_min = ts;\n\n                sub_st = st;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (sub_st) {\n\n        ast = sub_st->priv_data;\n\n        *pkt = ast->sub_pkt;\n\n        pkt->stream_index = sub_st->index;\n\n        if (av_read_packet(ast->sub_ctx, &ast->sub_pkt) < 0)\n\n            ast->sub_pkt.data = NULL;\n\n    }\n\n    return sub_st;\n\n}\n", "idx": 25720}
{"project": "FFmpeg", "commit_id": "daa1ea049a9445b7bed03963cb789497065dd1eb", "target": 0, "func": "void dsputil_init_mmx(DSPContext* c, AVCodecContext *avctx)\n\n{\n\n    mm_flags = mm_support();\n\n\n\n    if (avctx->dsp_mask) {\n\n        if (avctx->dsp_mask & FF_MM_FORCE)\n\n            mm_flags |= (avctx->dsp_mask & 0xffff);\n\n        else\n\n            mm_flags &= ~(avctx->dsp_mask & 0xffff);\n\n    }\n\n\n\n#if 0\n\n    av_log(avctx, AV_LOG_INFO, \"libavcodec: CPU flags:\");\n\n    if (mm_flags & MM_MMX)\n\n        av_log(avctx, AV_LOG_INFO, \" mmx\");\n\n    if (mm_flags & MM_MMXEXT)\n\n        av_log(avctx, AV_LOG_INFO, \" mmxext\");\n\n    if (mm_flags & MM_3DNOW)\n\n        av_log(avctx, AV_LOG_INFO, \" 3dnow\");\n\n    if (mm_flags & MM_SSE)\n\n        av_log(avctx, AV_LOG_INFO, \" sse\");\n\n    if (mm_flags & MM_SSE2)\n\n        av_log(avctx, AV_LOG_INFO, \" sse2\");\n\n    av_log(avctx, AV_LOG_INFO, \"\\n\");\n\n#endif\n\n\n\n    if (mm_flags & MM_MMX) {\n\n        const int idct_algo= avctx->idct_algo;\n\n\n\n        if(avctx->lowres==0){\n\n            if(idct_algo==FF_IDCT_AUTO || idct_algo==FF_IDCT_SIMPLEMMX){\n\n                c->idct_put= ff_simple_idct_put_mmx;\n\n                c->idct_add= ff_simple_idct_add_mmx;\n\n                c->idct    = ff_simple_idct_mmx;\n\n                c->idct_permutation_type= FF_SIMPLE_IDCT_PERM;\n\n#ifdef CONFIG_GPL\n\n            }else if(idct_algo==FF_IDCT_LIBMPEG2MMX){\n\n                if(mm_flags & MM_MMXEXT){\n\n                    c->idct_put= ff_libmpeg2mmx2_idct_put;\n\n                    c->idct_add= ff_libmpeg2mmx2_idct_add;\n\n                    c->idct    = ff_mmxext_idct;\n\n                }else{\n\n                    c->idct_put= ff_libmpeg2mmx_idct_put;\n\n                    c->idct_add= ff_libmpeg2mmx_idct_add;\n\n                    c->idct    = ff_mmx_idct;\n\n                }\n\n                c->idct_permutation_type= FF_LIBMPEG2_IDCT_PERM;\n\n#endif\n\n            }else if((ENABLE_VP3_DECODER || ENABLE_VP5_DECODER || ENABLE_VP6_DECODER || ENABLE_THEORA_DECODER) &&\n\n                     idct_algo==FF_IDCT_VP3){\n\n                if(mm_flags & MM_SSE2){\n\n                    c->idct_put= ff_vp3_idct_put_sse2;\n\n                    c->idct_add= ff_vp3_idct_add_sse2;\n\n                    c->idct    = ff_vp3_idct_sse2;\n\n                    c->idct_permutation_type= FF_TRANSPOSE_IDCT_PERM;\n\n                }else{\n\n                    c->idct_put= ff_vp3_idct_put_mmx;\n\n                    c->idct_add= ff_vp3_idct_add_mmx;\n\n                    c->idct    = ff_vp3_idct_mmx;\n\n                    c->idct_permutation_type= FF_PARTTRANS_IDCT_PERM;\n\n                }\n\n            }else if(idct_algo==FF_IDCT_CAVS){\n\n                    c->idct_permutation_type= FF_TRANSPOSE_IDCT_PERM;\n\n            }else if(idct_algo==FF_IDCT_XVIDMMX){\n\n                if(mm_flags & MM_SSE2){\n\n                    c->idct_put= ff_idct_xvid_sse2_put;\n\n                    c->idct_add= ff_idct_xvid_sse2_add;\n\n                    c->idct    = ff_idct_xvid_sse2;\n\n                    c->idct_permutation_type= FF_SSE2_IDCT_PERM;\n\n                }else if(mm_flags & MM_MMXEXT){\n\n                    c->idct_put= ff_idct_xvid_mmx2_put;\n\n                    c->idct_add= ff_idct_xvid_mmx2_add;\n\n                    c->idct    = ff_idct_xvid_mmx2;\n\n                }else{\n\n                    c->idct_put= ff_idct_xvid_mmx_put;\n\n                    c->idct_add= ff_idct_xvid_mmx_add;\n\n                    c->idct    = ff_idct_xvid_mmx;\n\n                }\n\n            }\n\n        }\n\n\n\n        c->put_pixels_clamped = put_pixels_clamped_mmx;\n\n        c->put_signed_pixels_clamped = put_signed_pixels_clamped_mmx;\n\n        c->add_pixels_clamped = add_pixels_clamped_mmx;\n\n        c->clear_blocks = clear_blocks_mmx;\n\n\n\n#define SET_HPEL_FUNCS(PFX, IDX, SIZE, CPU) \\\n\n        c->PFX ## _pixels_tab[IDX][0] = PFX ## _pixels ## SIZE ## _ ## CPU; \\\n\n        c->PFX ## _pixels_tab[IDX][1] = PFX ## _pixels ## SIZE ## _x2_ ## CPU; \\\n\n        c->PFX ## _pixels_tab[IDX][2] = PFX ## _pixels ## SIZE ## _y2_ ## CPU; \\\n\n        c->PFX ## _pixels_tab[IDX][3] = PFX ## _pixels ## SIZE ## _xy2_ ## CPU\n\n\n\n        SET_HPEL_FUNCS(put, 0, 16, mmx);\n\n        SET_HPEL_FUNCS(put_no_rnd, 0, 16, mmx);\n\n        SET_HPEL_FUNCS(avg, 0, 16, mmx);\n\n        SET_HPEL_FUNCS(avg_no_rnd, 0, 16, mmx);\n\n        SET_HPEL_FUNCS(put, 1, 8, mmx);\n\n        SET_HPEL_FUNCS(put_no_rnd, 1, 8, mmx);\n\n        SET_HPEL_FUNCS(avg, 1, 8, mmx);\n\n        SET_HPEL_FUNCS(avg_no_rnd, 1, 8, mmx);\n\n\n\n        c->gmc= gmc_mmx;\n\n\n\n        c->add_bytes= add_bytes_mmx;\n\n        c->add_bytes_l2= add_bytes_l2_mmx;\n\n\n\n        c->draw_edges = draw_edges_mmx;\n\n\n\n        if (ENABLE_ANY_H263) {\n\n            c->h263_v_loop_filter= h263_v_loop_filter_mmx;\n\n            c->h263_h_loop_filter= h263_h_loop_filter_mmx;\n\n        }\n\n        if ((ENABLE_VP3_DECODER || ENABLE_THEORA_DECODER) &&\n\n            !(avctx->flags & CODEC_FLAG_BITEXACT)) {\n\n            c->vp3_v_loop_filter= ff_vp3_v_loop_filter_mmx;\n\n            c->vp3_h_loop_filter= ff_vp3_h_loop_filter_mmx;\n\n        }\n\n        c->put_h264_chroma_pixels_tab[0]= put_h264_chroma_mc8_mmx_rnd;\n\n        c->put_h264_chroma_pixels_tab[1]= put_h264_chroma_mc4_mmx;\n\n        c->put_no_rnd_h264_chroma_pixels_tab[0]= put_h264_chroma_mc8_mmx_nornd;\n\n\n\n        c->h264_idct_dc_add=\n\n        c->h264_idct_add= ff_h264_idct_add_mmx;\n\n        c->h264_idct8_dc_add=\n\n        c->h264_idct8_add= ff_h264_idct8_add_mmx;\n\n        if (mm_flags & MM_SSE2)\n\n            c->h264_idct8_add= ff_h264_idct8_add_sse2;\n\n\n\n        if (mm_flags & MM_MMXEXT) {\n\n            c->prefetch = prefetch_mmx2;\n\n\n\n            c->put_pixels_tab[0][1] = put_pixels16_x2_mmx2;\n\n            c->put_pixels_tab[0][2] = put_pixels16_y2_mmx2;\n\n\n\n            c->avg_pixels_tab[0][0] = avg_pixels16_mmx2;\n\n            c->avg_pixels_tab[0][1] = avg_pixels16_x2_mmx2;\n\n            c->avg_pixels_tab[0][2] = avg_pixels16_y2_mmx2;\n\n\n\n            c->put_pixels_tab[1][1] = put_pixels8_x2_mmx2;\n\n            c->put_pixels_tab[1][2] = put_pixels8_y2_mmx2;\n\n\n\n            c->avg_pixels_tab[1][0] = avg_pixels8_mmx2;\n\n            c->avg_pixels_tab[1][1] = avg_pixels8_x2_mmx2;\n\n            c->avg_pixels_tab[1][2] = avg_pixels8_y2_mmx2;\n\n\n\n            c->h264_idct_dc_add= ff_h264_idct_dc_add_mmx2;\n\n            c->h264_idct8_dc_add= ff_h264_idct8_dc_add_mmx2;\n\n\n\n            if(!(avctx->flags & CODEC_FLAG_BITEXACT)){\n\n                c->put_no_rnd_pixels_tab[0][1] = put_no_rnd_pixels16_x2_mmx2;\n\n                c->put_no_rnd_pixels_tab[0][2] = put_no_rnd_pixels16_y2_mmx2;\n\n                c->put_no_rnd_pixels_tab[1][1] = put_no_rnd_pixels8_x2_mmx2;\n\n                c->put_no_rnd_pixels_tab[1][2] = put_no_rnd_pixels8_y2_mmx2;\n\n                c->avg_pixels_tab[0][3] = avg_pixels16_xy2_mmx2;\n\n                c->avg_pixels_tab[1][3] = avg_pixels8_xy2_mmx2;\n\n            }\n\n\n\n#define SET_QPEL_FUNCS(PFX, IDX, SIZE, CPU) \\\n\n            c->PFX ## _pixels_tab[IDX][ 0] = PFX ## SIZE ## _mc00_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][ 1] = PFX ## SIZE ## _mc10_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][ 2] = PFX ## SIZE ## _mc20_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][ 3] = PFX ## SIZE ## _mc30_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][ 4] = PFX ## SIZE ## _mc01_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][ 5] = PFX ## SIZE ## _mc11_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][ 6] = PFX ## SIZE ## _mc21_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][ 7] = PFX ## SIZE ## _mc31_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][ 8] = PFX ## SIZE ## _mc02_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][ 9] = PFX ## SIZE ## _mc12_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][10] = PFX ## SIZE ## _mc22_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][11] = PFX ## SIZE ## _mc32_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][12] = PFX ## SIZE ## _mc03_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][13] = PFX ## SIZE ## _mc13_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][14] = PFX ## SIZE ## _mc23_ ## CPU; \\\n\n            c->PFX ## _pixels_tab[IDX][15] = PFX ## SIZE ## _mc33_ ## CPU\n\n\n\n            SET_QPEL_FUNCS(put_qpel, 0, 16, mmx2);\n\n            SET_QPEL_FUNCS(put_qpel, 1, 8, mmx2);\n\n            SET_QPEL_FUNCS(put_no_rnd_qpel, 0, 16, mmx2);\n\n            SET_QPEL_FUNCS(put_no_rnd_qpel, 1, 8, mmx2);\n\n            SET_QPEL_FUNCS(avg_qpel, 0, 16, mmx2);\n\n            SET_QPEL_FUNCS(avg_qpel, 1, 8, mmx2);\n\n\n\n            SET_QPEL_FUNCS(put_h264_qpel, 0, 16, mmx2);\n\n            SET_QPEL_FUNCS(put_h264_qpel, 1, 8, mmx2);\n\n            SET_QPEL_FUNCS(put_h264_qpel, 2, 4, mmx2);\n\n            SET_QPEL_FUNCS(avg_h264_qpel, 0, 16, mmx2);\n\n            SET_QPEL_FUNCS(avg_h264_qpel, 1, 8, mmx2);\n\n            SET_QPEL_FUNCS(avg_h264_qpel, 2, 4, mmx2);\n\n\n\n            SET_QPEL_FUNCS(put_2tap_qpel, 0, 16, mmx2);\n\n            SET_QPEL_FUNCS(put_2tap_qpel, 1, 8, mmx2);\n\n            SET_QPEL_FUNCS(avg_2tap_qpel, 0, 16, mmx2);\n\n            SET_QPEL_FUNCS(avg_2tap_qpel, 1, 8, mmx2);\n\n\n\n            c->avg_h264_chroma_pixels_tab[0]= avg_h264_chroma_mc8_mmx2_rnd;\n\n            c->avg_h264_chroma_pixels_tab[1]= avg_h264_chroma_mc4_mmx2;\n\n            c->avg_h264_chroma_pixels_tab[2]= avg_h264_chroma_mc2_mmx2;\n\n            c->put_h264_chroma_pixels_tab[2]= put_h264_chroma_mc2_mmx2;\n\n            c->h264_v_loop_filter_luma= h264_v_loop_filter_luma_mmx2;\n\n            c->h264_h_loop_filter_luma= h264_h_loop_filter_luma_mmx2;\n\n            c->h264_v_loop_filter_chroma= h264_v_loop_filter_chroma_mmx2;\n\n            c->h264_h_loop_filter_chroma= h264_h_loop_filter_chroma_mmx2;\n\n            c->h264_v_loop_filter_chroma_intra= h264_v_loop_filter_chroma_intra_mmx2;\n\n            c->h264_h_loop_filter_chroma_intra= h264_h_loop_filter_chroma_intra_mmx2;\n\n            c->h264_loop_filter_strength= h264_loop_filter_strength_mmx2;\n\n\n\n            c->weight_h264_pixels_tab[0]= ff_h264_weight_16x16_mmx2;\n\n            c->weight_h264_pixels_tab[1]= ff_h264_weight_16x8_mmx2;\n\n            c->weight_h264_pixels_tab[2]= ff_h264_weight_8x16_mmx2;\n\n            c->weight_h264_pixels_tab[3]= ff_h264_weight_8x8_mmx2;\n\n            c->weight_h264_pixels_tab[4]= ff_h264_weight_8x4_mmx2;\n\n            c->weight_h264_pixels_tab[5]= ff_h264_weight_4x8_mmx2;\n\n            c->weight_h264_pixels_tab[6]= ff_h264_weight_4x4_mmx2;\n\n            c->weight_h264_pixels_tab[7]= ff_h264_weight_4x2_mmx2;\n\n\n\n            c->biweight_h264_pixels_tab[0]= ff_h264_biweight_16x16_mmx2;\n\n            c->biweight_h264_pixels_tab[1]= ff_h264_biweight_16x8_mmx2;\n\n            c->biweight_h264_pixels_tab[2]= ff_h264_biweight_8x16_mmx2;\n\n            c->biweight_h264_pixels_tab[3]= ff_h264_biweight_8x8_mmx2;\n\n            c->biweight_h264_pixels_tab[4]= ff_h264_biweight_8x4_mmx2;\n\n            c->biweight_h264_pixels_tab[5]= ff_h264_biweight_4x8_mmx2;\n\n            c->biweight_h264_pixels_tab[6]= ff_h264_biweight_4x4_mmx2;\n\n            c->biweight_h264_pixels_tab[7]= ff_h264_biweight_4x2_mmx2;\n\n\n\n            if (ENABLE_CAVS_DECODER)\n\n                ff_cavsdsp_init_mmx2(c, avctx);\n\n\n\n            if (ENABLE_VC1_DECODER || ENABLE_WMV3_DECODER)\n\n                ff_vc1dsp_init_mmx(c, avctx);\n\n\n\n            c->add_png_paeth_prediction= add_png_paeth_prediction_mmx2;\n\n        } else if (mm_flags & MM_3DNOW) {\n\n            c->prefetch = prefetch_3dnow;\n\n\n\n            c->put_pixels_tab[0][1] = put_pixels16_x2_3dnow;\n\n            c->put_pixels_tab[0][2] = put_pixels16_y2_3dnow;\n\n\n\n            c->avg_pixels_tab[0][0] = avg_pixels16_3dnow;\n\n            c->avg_pixels_tab[0][1] = avg_pixels16_x2_3dnow;\n\n            c->avg_pixels_tab[0][2] = avg_pixels16_y2_3dnow;\n\n\n\n            c->put_pixels_tab[1][1] = put_pixels8_x2_3dnow;\n\n            c->put_pixels_tab[1][2] = put_pixels8_y2_3dnow;\n\n\n\n            c->avg_pixels_tab[1][0] = avg_pixels8_3dnow;\n\n            c->avg_pixels_tab[1][1] = avg_pixels8_x2_3dnow;\n\n            c->avg_pixels_tab[1][2] = avg_pixels8_y2_3dnow;\n\n\n\n            if(!(avctx->flags & CODEC_FLAG_BITEXACT)){\n\n                c->put_no_rnd_pixels_tab[0][1] = put_no_rnd_pixels16_x2_3dnow;\n\n                c->put_no_rnd_pixels_tab[0][2] = put_no_rnd_pixels16_y2_3dnow;\n\n                c->put_no_rnd_pixels_tab[1][1] = put_no_rnd_pixels8_x2_3dnow;\n\n                c->put_no_rnd_pixels_tab[1][2] = put_no_rnd_pixels8_y2_3dnow;\n\n                c->avg_pixels_tab[0][3] = avg_pixels16_xy2_3dnow;\n\n                c->avg_pixels_tab[1][3] = avg_pixels8_xy2_3dnow;\n\n            }\n\n\n\n            SET_QPEL_FUNCS(put_qpel, 0, 16, 3dnow);\n\n            SET_QPEL_FUNCS(put_qpel, 1, 8, 3dnow);\n\n            SET_QPEL_FUNCS(put_no_rnd_qpel, 0, 16, 3dnow);\n\n            SET_QPEL_FUNCS(put_no_rnd_qpel, 1, 8, 3dnow);\n\n            SET_QPEL_FUNCS(avg_qpel, 0, 16, 3dnow);\n\n            SET_QPEL_FUNCS(avg_qpel, 1, 8, 3dnow);\n\n\n\n            SET_QPEL_FUNCS(put_h264_qpel, 0, 16, 3dnow);\n\n            SET_QPEL_FUNCS(put_h264_qpel, 1, 8, 3dnow);\n\n            SET_QPEL_FUNCS(put_h264_qpel, 2, 4, 3dnow);\n\n            SET_QPEL_FUNCS(avg_h264_qpel, 0, 16, 3dnow);\n\n            SET_QPEL_FUNCS(avg_h264_qpel, 1, 8, 3dnow);\n\n            SET_QPEL_FUNCS(avg_h264_qpel, 2, 4, 3dnow);\n\n\n\n            SET_QPEL_FUNCS(put_2tap_qpel, 0, 16, 3dnow);\n\n            SET_QPEL_FUNCS(put_2tap_qpel, 1, 8, 3dnow);\n\n            SET_QPEL_FUNCS(avg_2tap_qpel, 0, 16, 3dnow);\n\n            SET_QPEL_FUNCS(avg_2tap_qpel, 1, 8, 3dnow);\n\n\n\n            c->avg_h264_chroma_pixels_tab[0]= avg_h264_chroma_mc8_3dnow_rnd;\n\n            c->avg_h264_chroma_pixels_tab[1]= avg_h264_chroma_mc4_3dnow;\n\n\n\n            if (ENABLE_CAVS_DECODER)\n\n                ff_cavsdsp_init_3dnow(c, avctx);\n\n        }\n\n\n\n\n\n#define H264_QPEL_FUNCS(x, y, CPU)\\\n\n            c->put_h264_qpel_pixels_tab[0][x+y*4] = put_h264_qpel16_mc##x##y##_##CPU;\\\n\n            c->put_h264_qpel_pixels_tab[1][x+y*4] = put_h264_qpel8_mc##x##y##_##CPU;\\\n\n            c->avg_h264_qpel_pixels_tab[0][x+y*4] = avg_h264_qpel16_mc##x##y##_##CPU;\\\n\n            c->avg_h264_qpel_pixels_tab[1][x+y*4] = avg_h264_qpel8_mc##x##y##_##CPU;\n\n        if((mm_flags & MM_SSE2) && !(mm_flags & MM_3DNOW)){\n\n            // these functions are slower than mmx on AMD, but faster on Intel\n\n/* FIXME works in most codecs, but crashes svq1 due to unaligned chroma\n\n            c->put_pixels_tab[0][0] = put_pixels16_sse2;\n\n            c->avg_pixels_tab[0][0] = avg_pixels16_sse2;\n\n*/\n\n            H264_QPEL_FUNCS(0, 0, sse2);\n\n        }\n\n        if(mm_flags & MM_SSE2){\n\n            H264_QPEL_FUNCS(0, 1, sse2);\n\n            H264_QPEL_FUNCS(0, 2, sse2);\n\n            H264_QPEL_FUNCS(0, 3, sse2);\n\n            H264_QPEL_FUNCS(1, 1, sse2);\n\n            H264_QPEL_FUNCS(1, 2, sse2);\n\n            H264_QPEL_FUNCS(1, 3, sse2);\n\n            H264_QPEL_FUNCS(2, 1, sse2);\n\n            H264_QPEL_FUNCS(2, 2, sse2);\n\n            H264_QPEL_FUNCS(2, 3, sse2);\n\n            H264_QPEL_FUNCS(3, 1, sse2);\n\n            H264_QPEL_FUNCS(3, 2, sse2);\n\n            H264_QPEL_FUNCS(3, 3, sse2);\n\n        }\n\n#ifdef HAVE_SSSE3\n\n        if(mm_flags & MM_SSSE3){\n\n            H264_QPEL_FUNCS(1, 0, ssse3);\n\n            H264_QPEL_FUNCS(1, 1, ssse3);\n\n            H264_QPEL_FUNCS(1, 2, ssse3);\n\n            H264_QPEL_FUNCS(1, 3, ssse3);\n\n            H264_QPEL_FUNCS(2, 0, ssse3);\n\n            H264_QPEL_FUNCS(2, 1, ssse3);\n\n            H264_QPEL_FUNCS(2, 2, ssse3);\n\n            H264_QPEL_FUNCS(2, 3, ssse3);\n\n            H264_QPEL_FUNCS(3, 0, ssse3);\n\n            H264_QPEL_FUNCS(3, 1, ssse3);\n\n            H264_QPEL_FUNCS(3, 2, ssse3);\n\n            H264_QPEL_FUNCS(3, 3, ssse3);\n\n            c->put_no_rnd_h264_chroma_pixels_tab[0]= put_h264_chroma_mc8_ssse3_nornd;\n\n            c->put_h264_chroma_pixels_tab[0]= put_h264_chroma_mc8_ssse3_rnd;\n\n            c->avg_h264_chroma_pixels_tab[0]= avg_h264_chroma_mc8_ssse3_rnd;\n\n            c->put_h264_chroma_pixels_tab[1]= put_h264_chroma_mc4_ssse3;\n\n            c->avg_h264_chroma_pixels_tab[1]= avg_h264_chroma_mc4_ssse3;\n\n            c->add_png_paeth_prediction= add_png_paeth_prediction_ssse3;\n\n        }\n\n#endif\n\n\n\n#ifdef CONFIG_SNOW_DECODER\n\n        if(mm_flags & MM_SSE2 & 0){\n\n            c->horizontal_compose97i = ff_snow_horizontal_compose97i_sse2;\n\n#ifdef HAVE_7REGS\n\n            c->vertical_compose97i = ff_snow_vertical_compose97i_sse2;\n\n#endif\n\n            c->inner_add_yblock = ff_snow_inner_add_yblock_sse2;\n\n        }\n\n        else{\n\n            if(mm_flags & MM_MMXEXT){\n\n            c->horizontal_compose97i = ff_snow_horizontal_compose97i_mmx;\n\n#ifdef HAVE_7REGS\n\n            c->vertical_compose97i = ff_snow_vertical_compose97i_mmx;\n\n#endif\n\n            }\n\n            c->inner_add_yblock = ff_snow_inner_add_yblock_mmx;\n\n        }\n\n#endif\n\n\n\n        if(mm_flags & MM_3DNOW){\n\n            c->vorbis_inverse_coupling = vorbis_inverse_coupling_3dnow;\n\n            c->vector_fmul = vector_fmul_3dnow;\n\n            if(!(avctx->flags & CODEC_FLAG_BITEXACT)){\n\n                c->float_to_int16 = float_to_int16_3dnow;\n\n                c->float_to_int16_interleave = float_to_int16_interleave_3dnow;\n\n            }\n\n        }\n\n        if(mm_flags & MM_3DNOWEXT){\n\n            c->vector_fmul_reverse = vector_fmul_reverse_3dnow2;\n\n            c->vector_fmul_window = vector_fmul_window_3dnow2;\n\n            if(!(avctx->flags & CODEC_FLAG_BITEXACT)){\n\n                c->float_to_int16_interleave = float_to_int16_interleave_3dn2;\n\n            }\n\n        }\n\n        if(mm_flags & MM_SSE){\n\n            c->vorbis_inverse_coupling = vorbis_inverse_coupling_sse;\n\n            c->ac3_downmix = ac3_downmix_sse;\n\n            c->vector_fmul = vector_fmul_sse;\n\n            c->vector_fmul_reverse = vector_fmul_reverse_sse;\n\n            c->vector_fmul_add_add = vector_fmul_add_add_sse;\n\n            c->vector_fmul_window = vector_fmul_window_sse;\n\n            c->int32_to_float_fmul_scalar = int32_to_float_fmul_scalar_sse;\n\n            c->float_to_int16 = float_to_int16_sse;\n\n            c->float_to_int16_interleave = float_to_int16_interleave_sse;\n\n        }\n\n        if(mm_flags & MM_3DNOW)\n\n            c->vector_fmul_add_add = vector_fmul_add_add_3dnow; // faster than sse\n\n        if(mm_flags & MM_SSE2){\n\n            c->int32_to_float_fmul_scalar = int32_to_float_fmul_scalar_sse2;\n\n            c->float_to_int16 = float_to_int16_sse2;\n\n            c->float_to_int16_interleave = float_to_int16_interleave_sse2;\n\n            c->add_int16 = add_int16_sse2;\n\n            c->sub_int16 = sub_int16_sse2;\n\n            c->scalarproduct_int16 = scalarproduct_int16_sse2;\n\n        }\n\n    }\n\n\n\n    if (ENABLE_ENCODERS)\n\n        dsputilenc_init_mmx(c, avctx);\n\n\n\n#if 0\n\n    // for speed testing\n\n    get_pixels = just_return;\n\n    put_pixels_clamped = just_return;\n\n    add_pixels_clamped = just_return;\n\n\n\n    pix_abs16x16 = just_return;\n\n    pix_abs16x16_x2 = just_return;\n\n    pix_abs16x16_y2 = just_return;\n\n    pix_abs16x16_xy2 = just_return;\n\n\n\n    put_pixels_tab[0] = just_return;\n\n    put_pixels_tab[1] = just_return;\n\n    put_pixels_tab[2] = just_return;\n\n    put_pixels_tab[3] = just_return;\n\n\n\n    put_no_rnd_pixels_tab[0] = just_return;\n\n    put_no_rnd_pixels_tab[1] = just_return;\n\n    put_no_rnd_pixels_tab[2] = just_return;\n\n    put_no_rnd_pixels_tab[3] = just_return;\n\n\n\n    avg_pixels_tab[0] = just_return;\n\n    avg_pixels_tab[1] = just_return;\n\n    avg_pixels_tab[2] = just_return;\n\n    avg_pixels_tab[3] = just_return;\n\n\n\n    avg_no_rnd_pixels_tab[0] = just_return;\n\n    avg_no_rnd_pixels_tab[1] = just_return;\n\n    avg_no_rnd_pixels_tab[2] = just_return;\n\n    avg_no_rnd_pixels_tab[3] = just_return;\n\n\n\n    //av_fdct = just_return;\n\n    //ff_idct = just_return;\n\n#endif\n\n}\n", "idx": 25722}
{"project": "FFmpeg", "commit_id": "2da0d70d5eebe42f9fcd27ee554419ebe2a5da06", "target": 1, "func": "static inline void RENAME(rgb15ToY)(uint8_t *dst, uint8_t *src, int width)\n\n{\n\n\tint i;\n\n\tfor(i=0; i<width; i++)\n\n\t{\n\n\t\tint d= ((uint16_t*)src)[i];\n\n\t\tint r= d&0x1F;\n\n\t\tint g= (d>>5)&0x1F;\n\n\t\tint b= (d>>10)&0x1F;\n\n\n\n\t\tdst[i]= ((RY*r + GY*g + BY*b)>>(RGB2YUV_SHIFT-3)) + 16;\n\n\t}\n\n}\n", "idx": 25727}
{"project": "FFmpeg", "commit_id": "24947d4988012f1f0fd467c83418615adc11c3e8", "target": 1, "func": "static void render_line(int x0, uint8_t y0, int x1, int y1, float *buf)\n\n{\n\n    int dy  = y1 - y0;\n\n    int adx = x1 - x0;\n\n    int ady = FFABS(dy);\n\n    int sy  = dy < 0 ? -1 : 1;\n\n    buf[x0] = ff_vorbis_floor1_inverse_db_table[y0];\n\n    if (ady*2 <= adx) { // optimized common case\n\n        render_line_unrolled(x0, y0, x1, sy, ady, adx, buf);\n\n    } else {\n\n        int base  = dy / adx;\n\n        int x     = x0;\n\n        uint8_t y = y0;\n\n        int err   = -adx;\n\n        ady -= FFABS(base) * adx;\n\n        while (++x < x1) {\n\n            y += base;\n\n            err += ady;\n\n            if (err >= 0) {\n\n                err -= adx;\n\n                y   += sy;\n\n            }\n\n            buf[x] = ff_vorbis_floor1_inverse_db_table[y];\n\n        }\n\n    }\n\n}\n", "idx": 25729}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static void RENAME(uyvytoyuv420)(uint8_t *ydst, uint8_t *udst, uint8_t *vdst, const uint8_t *src,\n\n                                      long width, long height,\n\n                                      long lumStride, long chromStride, long srcStride)\n\n{\n\n    long y;\n\n    const long chromWidth= -((-width)>>1);\n\n\n\n    for (y=0; y<height; y++) {\n\n        RENAME(extract_even)(src+1, ydst, width);\n\n        if(y&1) {\n\n            RENAME(extract_even2avg)(src-srcStride, src, udst, vdst, chromWidth);\n\n            udst+= chromStride;\n\n            vdst+= chromStride;\n\n        }\n\n\n\n        src += srcStride;\n\n        ydst+= lumStride;\n\n    }\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__(\n\n            EMMS\"       \\n\\t\"\n\n            SFENCE\"     \\n\\t\"\n\n            ::: \"memory\"\n\n        );\n\n#endif\n\n}\n", "idx": 25730}
{"project": "FFmpeg", "commit_id": "757248ea3cd917a7755cb15f817a9b1f15578718", "target": 0, "func": "static int bayer_to_yv12_wrapper(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,\n\n                                 int srcSliceH, uint8_t* dst[], int dstStride[])\n\n{\n\n    const uint8_t *srcPtr= src[0];\n\n    uint8_t *dstY= dst[0];\n\n    uint8_t *dstU= dst[1];\n\n    uint8_t *dstV= dst[2];\n\n    int i;\n\n    void (*copy)       (const uint8_t *src, int src_stride, uint8_t *dstY, uint8_t *dstU, uint8_t *dstV, int luma_stride, int width, int32_t *rgb2yuv);\n\n    void (*interpolate)(const uint8_t *src, int src_stride, uint8_t *dstY, uint8_t *dstU, uint8_t *dstV, int luma_stride, int width, int32_t *rgb2yuv);\n\n\n\n    switch(c->srcFormat) {\n\n#define CASE(pixfmt, prefix) \\\n\n    case pixfmt: copy        = bayer_##prefix##_to_yv12_copy; \\\n\n                 interpolate = bayer_##prefix##_to_yv12_interpolate; \\\n\n                 break;\n\n    CASE(AV_PIX_FMT_BAYER_BGGR8,    bggr8)\n\n    CASE(AV_PIX_FMT_BAYER_BGGR16LE, bggr16le)\n\n    CASE(AV_PIX_FMT_BAYER_BGGR16BE, bggr16be)\n\n    CASE(AV_PIX_FMT_BAYER_RGGB8,    rggb8)\n\n    CASE(AV_PIX_FMT_BAYER_RGGB16LE, rggb16le)\n\n    CASE(AV_PIX_FMT_BAYER_RGGB16BE, rggb16be)\n\n    CASE(AV_PIX_FMT_BAYER_GBRG8,    gbrg8)\n\n    CASE(AV_PIX_FMT_BAYER_GBRG16LE, gbrg16le)\n\n    CASE(AV_PIX_FMT_BAYER_GBRG16BE, gbrg16be)\n\n    CASE(AV_PIX_FMT_BAYER_GRBG8,    grbg8)\n\n    CASE(AV_PIX_FMT_BAYER_GRBG16LE, grbg16le)\n\n    CASE(AV_PIX_FMT_BAYER_GRBG16BE, grbg16be)\n\n#undef CASE\n\n    default: return 0;\n\n    }\n\n\n\n    copy(srcPtr, srcStride[0], dstY, dstU, dstV, dstStride[0], c->srcW, c->input_rgb2yuv_table);\n\n    srcPtr += 2 * srcStride[0];\n\n    dstY   += 2 * dstStride[0];\n\n    dstU   +=     dstStride[1];\n\n    dstV   +=     dstStride[1];\n\n\n\n    for (i = 2; i < srcSliceH - 2; i += 2) {\n\n        interpolate(srcPtr, srcStride[0], dstY, dstU, dstV, dstStride[0], c->srcW, c->input_rgb2yuv_table);\n\n        srcPtr += 2 * srcStride[0];\n\n        dstY   += 2 * dstStride[0];\n\n        dstU   +=     dstStride[1];\n\n        dstV   +=     dstStride[1];\n\n    }\n\n\n\n    copy(srcPtr, srcStride[0], dstY, dstU, dstV, dstStride[0], c->srcW, c->input_rgb2yuv_table);\n\n    return srcSliceH;\n\n}\n", "idx": 25731}
{"project": "FFmpeg", "commit_id": "e398990eb87785e20e065cd3f14d1dbb69df4392", "target": 0, "func": "static int msrle_decode_8_16_24_32(AVCodecContext *avctx, AVPicture *pic,\n\n                                   int depth, GetByteContext *gb)\n\n{\n\n    uint8_t *output, *output_end;\n\n    int p1, p2, line=avctx->height - 1, pos=0, i;\n\n    uint16_t pix16;\n\n    uint32_t pix32;\n\n    unsigned int width= FFABS(pic->linesize[0]) / (depth >> 3);\n\n\n\n    output     = pic->data[0] + (avctx->height - 1) * pic->linesize[0];\n\n    output_end = pic->data[0] +  avctx->height      * pic->linesize[0];\n\n    while (bytestream2_get_bytes_left(gb) > 0) {\n\n        p1 = bytestream2_get_byteu(gb);\n\n        if(p1 == 0) { //Escape code\n\n            p2 = bytestream2_get_byte(gb);\n\n            if(p2 == 0) { //End-of-line\n\n                if (--line < 0) {\n\n                    if (bytestream2_get_be16(gb) == 1) { // end-of-picture\n\n                        return 0;\n\n                    } else {\n\n                        av_log(avctx, AV_LOG_ERROR,\n\n                               \"Next line is beyond picture bounds (%d bytes left)\\n\",\n\n                               bytestream2_get_bytes_left(gb));\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                }\n\n                output = pic->data[0] + line * pic->linesize[0];\n\n                pos = 0;\n\n                continue;\n\n            } else if(p2 == 1) { //End-of-picture\n\n                return 0;\n\n            } else if(p2 == 2) { //Skip\n\n                p1 = bytestream2_get_byte(gb);\n\n                p2 = bytestream2_get_byte(gb);\n\n                line -= p2;\n\n                pos += p1;\n\n                if (line < 0 || pos >= width){\n\n                    av_log(avctx, AV_LOG_ERROR, \"Skip beyond picture bounds\\n\");\n\n                    return -1;\n\n                }\n\n                output = pic->data[0] + line * pic->linesize[0] + pos * (depth >> 3);\n\n                continue;\n\n            }\n\n            // Copy data\n\n            if ((pic->linesize[0] > 0 && output + p2 * (depth >> 3) > output_end) ||\n\n                (pic->linesize[0] < 0 && output + p2 * (depth >> 3) < output_end)) {\n\n                bytestream2_skip(gb, 2 * (depth >> 3));\n\n                continue;\n\n            } else if (bytestream2_get_bytes_left(gb) < p2 * (depth >> 3)) {\n\n                av_log(avctx, AV_LOG_ERROR, \"bytestream overrun\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            if ((depth == 8) || (depth == 24)) {\n\n                for(i = 0; i < p2 * (depth >> 3); i++) {\n\n                    *output++ = bytestream2_get_byteu(gb);\n\n                }\n\n                // RLE8 copy is actually padded - and runs are not!\n\n                if(depth == 8 && (p2 & 1)) {\n\n                    bytestream2_skip(gb, 1);\n\n                }\n\n            } else if (depth == 16) {\n\n                for(i = 0; i < p2; i++) {\n\n                    *(uint16_t*)output = bytestream2_get_le16u(gb);\n\n                    output += 2;\n\n                }\n\n            } else if (depth == 32) {\n\n                for(i = 0; i < p2; i++) {\n\n                    *(uint32_t*)output = bytestream2_get_le32u(gb);\n\n                    output += 4;\n\n                }\n\n            }\n\n            pos += p2;\n\n        } else { //run of pixels\n\n            uint8_t pix[3]; //original pixel\n\n            if ((pic->linesize[0] > 0 && output + p1 * (depth >> 3) > output_end) ||\n\n                (pic->linesize[0] < 0 && output + p1 * (depth >> 3) < output_end))\n\n                continue;\n\n\n\n            switch(depth){\n\n            case  8:\n\n                pix[0] = bytestream2_get_byte(gb);\n\n                for(i = 0; i < p1; i++)\n\n                        *output++ = pix[0];\n\n                break;\n\n            case 16:\n\n                pix16  = bytestream2_get_le16(gb);\n\n                for(i = 0; i < p1; i++) {\n\n                        *(uint16_t*)output = pix16;\n\n                        output += 2;\n\n                }\n\n                break;\n\n            case 24:\n\n                pix[0] = bytestream2_get_byte(gb);\n\n                pix[1] = bytestream2_get_byte(gb);\n\n                pix[2] = bytestream2_get_byte(gb);\n\n                for(i = 0; i < p1; i++) {\n\n                        *output++ = pix[0];\n\n                        *output++ = pix[1];\n\n                        *output++ = pix[2];\n\n                }\n\n                break;\n\n            case 32:\n\n                pix32  = bytestream2_get_le32(gb);\n\n                for(i = 0; i < p1; i++) {\n\n                        *(uint32_t*)output = pix32;\n\n                        output += 4;\n\n                }\n\n                break;\n\n            }\n\n            pos += p1;\n\n        }\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_WARNING, \"MS RLE warning: no end-of-picture code\\n\");\n\n    return 0;\n\n}\n", "idx": 25732}
{"project": "FFmpeg", "commit_id": "e72662e131e5099e34d5a7519c5690d2fff7b83f", "target": 0, "func": "static int vaapi_encode_h264_init_picture_params(AVCodecContext *avctx,\n\n                                                 VAAPIEncodePicture *pic)\n\n{\n\n    VAAPIEncodeContext                *ctx = avctx->priv_data;\n\n    VAEncSequenceParameterBufferH264 *vseq = ctx->codec_sequence_params;\n\n    VAEncPictureParameterBufferH264  *vpic = pic->codec_picture_params;\n\n    VAAPIEncodeH264Context           *priv = ctx->priv_data;\n\n    int i;\n\n\n\n    if (pic->type == PICTURE_TYPE_IDR) {\n\n        av_assert0(pic->display_order == pic->encode_order);\n\n        vpic->frame_num = 0;\n\n        priv->next_frame_num = 1;\n\n        priv->cpb_delay = 0;\n\n    } else {\n\n        vpic->frame_num = priv->next_frame_num;\n\n        if (pic->type != PICTURE_TYPE_B) {\n\n            // nal_ref_idc != 0\n\n            ++priv->next_frame_num;\n\n        }\n\n        ++priv->cpb_delay;\n\n    }\n\n    priv->dpb_delay = pic->display_order - pic->encode_order + 1;\n\n\n\n    vpic->frame_num = vpic->frame_num &\n\n        ((1 << (4 + vseq->seq_fields.bits.log2_max_frame_num_minus4)) - 1);\n\n\n\n    vpic->CurrPic.picture_id          = pic->recon_surface;\n\n    vpic->CurrPic.frame_idx           = vpic->frame_num;\n\n    vpic->CurrPic.flags               = 0;\n\n    vpic->CurrPic.TopFieldOrderCnt    = pic->display_order;\n\n    vpic->CurrPic.BottomFieldOrderCnt = pic->display_order;\n\n\n\n    for (i = 0; i < pic->nb_refs; i++) {\n\n        VAAPIEncodePicture *ref = pic->refs[i];\n\n        av_assert0(ref && ref->encode_order < pic->encode_order);\n\n        vpic->ReferenceFrames[i].picture_id = ref->recon_surface;\n\n        vpic->ReferenceFrames[i].frame_idx  = ref->encode_order;\n\n        vpic->ReferenceFrames[i].flags = VA_PICTURE_H264_SHORT_TERM_REFERENCE;\n\n        vpic->ReferenceFrames[i].TopFieldOrderCnt    = ref->display_order;\n\n        vpic->ReferenceFrames[i].BottomFieldOrderCnt = ref->display_order;\n\n    }\n\n    for (; i < FF_ARRAY_ELEMS(vpic->ReferenceFrames); i++) {\n\n        vpic->ReferenceFrames[i].picture_id = VA_INVALID_ID;\n\n        vpic->ReferenceFrames[i].flags = VA_PICTURE_H264_INVALID;\n\n    }\n\n\n\n    vpic->coded_buf = pic->output_buffer;\n\n\n\n    vpic->pic_fields.bits.idr_pic_flag = (pic->type == PICTURE_TYPE_IDR);\n\n    vpic->pic_fields.bits.reference_pic_flag = (pic->type != PICTURE_TYPE_B);\n\n\n\n    pic->nb_slices = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 25733}
{"project": "FFmpeg", "commit_id": "fbd6c97f9ca858140df16dd07200ea0d4bdc1a83", "target": 1, "func": "static BufferPoolEntry *get_pool(AVBufferPool *pool)\n\n{\n\n    BufferPoolEntry *cur = NULL, *last = NULL;\n\n\n\n    do {\n\n        FFSWAP(BufferPoolEntry*, cur, last);\n\n        cur = avpriv_atomic_ptr_cas((void * volatile *)&pool->pool, last, NULL);\n\n        if (!cur)\n\n            return NULL;\n\n    } while (cur != last);\n\n\n\n    return cur;\n\n}\n", "idx": 25737}
{"project": "FFmpeg", "commit_id": "74b1bf632f125a795e66e5fd0a060b9c7c55b7a3", "target": 1, "func": "static void switch_buffer(MPADecodeContext *s, int *pos, int *end_pos,\n\n                          int *end_pos2)\n\n{\n\n    if (s->in_gb.buffer && *pos >= s->gb.size_in_bits) {\n\n        s->gb           = s->in_gb;\n\n        s->in_gb.buffer = NULL;\n\n        assert((get_bits_count(&s->gb) & 7) == 0);\n\n        skip_bits_long(&s->gb, *pos - *end_pos);\n\n        *end_pos2 =\n\n        *end_pos  = *end_pos2 + get_bits_count(&s->gb) - *pos;\n\n        *pos      = get_bits_count(&s->gb);\n\n    }\n\n}\n", "idx": 25738}
{"project": "FFmpeg", "commit_id": "2d40a09b6e73230b160a505f01ed1acf169e1d9f", "target": 1, "func": "static int libquvi_close(AVFormatContext *s)\n\n{\n\n    LibQuviContext *qc = s->priv_data;\n\n    if (qc->fmtctx)\n\n        avformat_close_input(&qc->fmtctx);\n\n    return 0;\n\n}\n", "idx": 25739}
{"project": "FFmpeg", "commit_id": "ea4f8aabab2a5a7ebd232b45557c11c4c59c332b", "target": 1, "func": "static int prepare_sdp_description(FFStream *stream, uint8_t **pbuffer,\n\n                                   struct in_addr my_ip)\n\n{\n\n    AVFormatContext *avc;\n\n    AVStream avs[MAX_STREAMS];\n\n    int i;\n\n\n\n    avc =  avformat_alloc_context();\n\n    if (avc == NULL) {\n\n        return -1;\n\n    }\n\n    av_metadata_set2(&avc->metadata, \"title\",\n\n                     stream->title[0] ? stream->title : \"No Title\", 0);\n\n    avc->nb_streams = stream->nb_streams;\n\n    if (stream->is_multicast) {\n\n        snprintf(avc->filename, 1024, \"rtp://%s:%d?multicast=1?ttl=%d\",\n\n                 inet_ntoa(stream->multicast_ip),\n\n                 stream->multicast_port, stream->multicast_ttl);\n\n    } else {\n\n        snprintf(avc->filename, 1024, \"rtp://0.0.0.0\");\n\n    }\n\n\n\n    for(i = 0; i < stream->nb_streams; i++) {\n\n        avc->streams[i] = &avs[i];\n\n        avc->streams[i]->codec = stream->streams[i]->codec;\n\n    }\n\n    *pbuffer = av_mallocz(2048);\n\n    avf_sdp_create(&avc, 1, *pbuffer, 2048);\n\n\n    av_free(avc);\n\n\n\n    return strlen(*pbuffer);\n\n}", "idx": 25742}
{"project": "FFmpeg", "commit_id": "e3d2500fe498289a878b956f6efb4995438c9515", "target": 1, "func": "static void RENAME(SwScale_YV12slice)(unsigned char* srcptr[],int stride[], int srcSliceY ,\n\n\t\t\t     int srcSliceH, uint8_t* dstptr[], int dststride, int dstbpp,\n\n\t\t\t     int srcW, int srcH, int dstW, int dstH){\n\n\n\n\n\nunsigned int lumXInc= (srcW << 16) / dstW;\n\nunsigned int lumYInc= (srcH << 16) / dstH;\n\nunsigned int chrXInc;\n\nunsigned int chrYInc;\n\n\n\nstatic int dstY;\n\n\n\n// used to detect a size change\n\nstatic int oldDstW= -1;\n\nstatic int oldSrcW= -1;\n\nstatic int oldDstH= -1;\n\nstatic int oldSrcH= -1;\n\nstatic int oldFlags=-1;\n\n\n\nstatic int lastInLumBuf;\n\nstatic int lastInChrBuf;\n\n\n\nint chrDstW, chrDstH;\n\n\n\nstatic int lumBufIndex=0;\n\nstatic int chrBufIndex=0;\n\n\n\nstatic int firstTime=1;\n\n\n\nint widthAlign= dstbpp==12 ? 16 : 8;\n\nif(((dstW + widthAlign-1)&(~(widthAlign-1))) > dststride)\n\n{\n\n\tdstW&= ~(widthAlign-1);\n\n\tif(firstTime)\n\n\t\tfprintf(stderr, \"SwScaler: Warning: dstStride is not a multiple of %d!\\n\"\n\n\t\t\t\t\"SwScaler: ->lowering width to compensate, new width=%d\\n\"\n\n\t\t\t\t\"SwScaler: ->cannot do aligned memory acesses anymore\\n\",\n\n\t\t\t\twidthAlign, dstW);\n\n}\n\n\n\n//printf(\"%d %d %d %d\\n\", srcW, srcH, dstW, dstH);\n\n//printf(\"%d %d %d %d\\n\", lumXInc, lumYInc, srcSliceY, srcSliceH);\n\n\n\n#ifdef HAVE_MMX2\n\ncanMMX2BeUsed= (lumXInc <= 0x10000 && (dstW&31)==0 && (srcW&15)==0) ? 1 : 0;\n\nif(!canMMX2BeUsed && lumXInc <= 0x10000 && (srcW&15)==0 && sws_flags==SWS_FAST_BILINEAR)\n\n{\n\n\tif(firstTime) //FIXME only if verbose ?\n\n\t\tfprintf(stderr, \"SwScaler: output Width is not a multiple of 32 -> no MMX2 scaler\\n\");\n\n}\n\n#endif\n\n\n\nif(firstTime)\n\n{\n\n#if defined (DITHER1XBPP) && defined (HAVE_MMX)\n\n\tchar *dither= \" dithered\";\n\n#else\n\n\tchar *dither= \"\";\n\n#endif\n\n\tif(sws_flags==SWS_FAST_BILINEAR)\n\n\t\tfprintf(stderr, \"SwScaler: FAST_BILINEAR scaler \");\n\n\telse if(sws_flags==SWS_BILINEAR)\n\n\t\tfprintf(stderr, \"SwScaler: BILINEAR scaler \");\n\n\telse if(sws_flags==SWS_BICUBIC)\n\n\t\tfprintf(stderr, \"SwScaler: BICUBIC scaler \");\n\n\telse\n\n\t\tfprintf(stderr, \"SwScaler: ehh flags invalid?! \");\n\n\n\n\tif(dstbpp==15)\n\n\t\tfprintf(stderr, \"with%s BGR15 output \", dither);\n\n\telse if(dstbpp==16)\n\n\t\tfprintf(stderr, \"with%s BGR16 output \", dither);\n\n\telse if(dstbpp==24)\n\n\t\tfprintf(stderr, \"with BGR24 output \");\n\n\telse if(dstbpp==32)\n\n\t\tfprintf(stderr, \"with BGR32 output \");\n\n\telse if(dstbpp==12)\n\n\t\tfprintf(stderr, \"with YV12 output \");\n\n\telse\n\n\t\tfprintf(stderr, \"without output \");\n\n\n\n#ifdef HAVE_MMX2\n\n\t\tfprintf(stderr, \"using MMX2\\n\");\n\n#elif defined (HAVE_3DNOW)\n\n\t\tfprintf(stderr, \"using 3DNOW\\n\");\n\n#elif defined (HAVE_MMX)\n\n\t\tfprintf(stderr, \"using MMX\\n\");\n\n#elif defined (ARCH_X86)\n\n\t\tfprintf(stderr, \"using X86 ASM2\\n\");\n\n#else\n\n\t\tfprintf(stderr, \"using C\\n\");\n\n#endif\n\n}\n\n\n\n\n\n// match pixel 0 of the src to pixel 0 of dst and match pixel n-2 of src to pixel n-2 of dst\n\n// n-2 is the last chrominance sample available\n\n// this is not perfect, but noone shuld notice the difference, the more correct variant\n\n// would be like the vertical one, but that would require some special code for the\n\n// first and last pixel\n\nif(sws_flags==SWS_FAST_BILINEAR)\n\n{\n\n\tif(canMMX2BeUsed) \tlumXInc+= 20;\n\n\telse\t\t\tlumXInc = ((srcW-2)<<16)/(dstW-2) - 20;\n\n}\n\n\n\nif(fullUVIpol && !(dstbpp==12)) \tchrXInc= lumXInc>>1, chrDstW= dstW;\n\nelse\t\t\t\t\tchrXInc= lumXInc,    chrDstW= dstW>>1;\n\n\n\nif(dstbpp==12)\tchrYInc= lumYInc,    chrDstH= dstH>>1;\n\nelse\t\tchrYInc= lumYInc>>1, chrDstH= dstH;\n\n\n\n  // force calculation of the horizontal interpolation of the first line\n\n\n\n  if(srcSliceY ==0){\n\n//\tprintf(\"dstW %d, srcw %d, mmx2 %d\\n\", dstW, srcW, canMMX2BeUsed);\n\n\tlumBufIndex=0;\n\n\tchrBufIndex=0;\n\n\tdstY=0;\n\n\n\n\t//precalculate horizontal scaler filter coefficients\n\n\tif(oldDstW!=dstW || oldSrcW!=srcW || oldFlags!=sws_flags)\n\n\t{\n\n#ifdef HAVE_MMX\n\n\t\tconst int filterAlign=4;\n\n#else\n\n\t\tconst int filterAlign=1;\n\n#endif\n\n\t\toldDstW= dstW; oldSrcW= srcW; oldFlags= sws_flags;\n\n\n\n\t\tif(sws_flags != SWS_FAST_BILINEAR)\n\n\t\t{\n\n\t\t\tRENAME(initFilter)(hLumFilter, hLumFilterPos, &hLumFilterSize, lumXInc,\n\n\t\t\t\t\t   srcW   , dstW   , filterAlign, 1<<14);\n\n\t\t\tRENAME(initFilter)(hChrFilter, hChrFilterPos, &hChrFilterSize, chrXInc,\n\n\t\t\t\t\t   srcW>>1, chrDstW, filterAlign, 1<<14);\n\n\t\t}\n\n\n\n#ifdef HAVE_MMX2\n\n// cant downscale !!!\n\n\t\tif(canMMX2BeUsed && sws_flags == SWS_FAST_BILINEAR)\n\n\t\t{\n\n\t\t\tinitMMX2HScaler(dstW   , lumXInc, funnyYCode);\n\n\t\t\tinitMMX2HScaler(chrDstW, chrXInc, funnyUVCode);\n\n\t\t}\n\n#endif\n\n\t} // Init Horizontal stuff\n\n\n\n\tif(oldDstH!=dstH || oldSrcH!=srcH || oldFlags!=sws_flags)\n\n\t{\n\n\t\tint i;\n\n\t\toldDstH= dstH; oldSrcH= srcH; oldFlags= sws_flags; //FIXME swsflags conflict with x check\n\n\n\n\t\t// deallocate pixbufs\n\n\t\tfor(i=0; i<vLumBufSize; i++) free(lumPixBuf[i]);\n\n\t\tfor(i=0; i<vChrBufSize; i++) free(chrPixBuf[i]);\n\n\n\n\t\tRENAME(initFilter)(vLumFilter, vLumFilterPos, &vLumFilterSize, lumYInc,\n\n\t\t\t\tsrcH   , dstH,    1, (1<<12)-4);\n\n\t\tRENAME(initFilter)(vChrFilter, vChrFilterPos, &vChrFilterSize, chrYInc,\n\n\t\t\t\tsrcH>>1, chrDstH, 1, (1<<12)-4);\n\n\n\n\t\t// Calculate Buffer Sizes so that they wont run out while handling these damn slices\n\n\t\tvLumBufSize= vLumFilterSize; vChrBufSize= vChrFilterSize;\n\n\t\tfor(i=0; i<dstH; i++)\n\n\t\t{\n\n\t\t\tint chrI= i*chrDstH / dstH;\n\n\t\t\tint nextSlice= MAX(vLumFilterPos[i   ] + vLumFilterSize - 1,\n\n\t\t\t\t\t ((vChrFilterPos[chrI] + vChrFilterSize - 1)<<1));\n\n\t\t\tnextSlice&= ~1; // Slices start at even boundaries\n\n\t\t\tif(vLumFilterPos[i   ] + vLumBufSize < nextSlice)\n\n\t\t\t\tvLumBufSize= nextSlice - vLumFilterPos[i   ];\n\n\t\t\tif(vChrFilterPos[chrI] + vChrBufSize < (nextSlice>>1))\n\n\t\t\t\tvChrBufSize= (nextSlice>>1) - vChrFilterPos[chrI];\n\n\t\t}\n\n\n\n\t\t// allocate pixbufs (we use dynamic allocation because otherwise we would need to\n\n\t\t// allocate several megabytes to handle all possible cases)\n\n\t\tfor(i=0; i<vLumBufSize; i++)\n\n\t\t\tlumPixBuf[i]= lumPixBuf[i+vLumBufSize]= (uint16_t*)memalign(8, 4000);\n\n\t\tfor(i=0; i<vChrBufSize; i++)\n\n\t\t\tchrPixBuf[i]= chrPixBuf[i+vChrBufSize]= (uint16_t*)memalign(8, 8000);\n\n\n\n\t\t//try to avoid drawing green stuff between the right end and the stride end\n\n\t\tfor(i=0; i<vLumBufSize; i++) memset(lumPixBuf[i], 0, 4000);\n\n\t\tfor(i=0; i<vChrBufSize; i++) memset(chrPixBuf[i], 64, 8000);\n\n\n\n#ifdef HAVE_MMX\n\n\t\t// pack filter data for mmx code\n\n\t\tfor(i=0; i<vLumFilterSize*dstH; i++)\n\n\t\t\tlumMmxFilter[4*i]=lumMmxFilter[4*i+1]=lumMmxFilter[4*i+2]=lumMmxFilter[4*i+3]=\n\n\t\t\t\tvLumFilter[i];\n\n\n\n\t\tfor(i=0; i<vChrFilterSize*chrDstH; i++)\n\n\t\t\tchrMmxFilter[4*i]=chrMmxFilter[4*i+1]=chrMmxFilter[4*i+2]=chrMmxFilter[4*i+3]=\n\n\t\t\t\tvChrFilter[i];\n\n#endif\n\n\t}\n\n\n\n\tlastInLumBuf= -1;\n\n\tlastInChrBuf= -1;\n\n  } // if(firstLine)\n\n\n\n\tfor(;dstY < dstH; dstY++){\n\n\t\tunsigned char *dest =dstptr[0]+dststride*dstY;\n\n\t\tunsigned char *uDest=dstptr[1]+(dststride>>1)*(dstY>>1);\n\n\t\tunsigned char *vDest=dstptr[2]+(dststride>>1)*(dstY>>1);\n\n\t\tconst int chrDstY= dstbpp==12 ? (dstY>>1) : dstY;\n\n\n\n\t\tconst int firstLumSrcY= vLumFilterPos[dstY]; //First line needed as input\n\n\t\tconst int firstChrSrcY= vChrFilterPos[chrDstY]; //First line needed as input\n\n\t\tconst int lastLumSrcY= firstLumSrcY + vLumFilterSize -1; // Last line needed as input\n\n\t\tconst int lastChrSrcY= firstChrSrcY + vChrFilterSize -1; // Last line needed as input\n\n\n\n\t\tif(sws_flags == SWS_FAST_BILINEAR)\n\n\t\t{\n\n\t\t\t//handle holes\n\n\t\t\tif(firstLumSrcY > lastInLumBuf) lastInLumBuf= firstLumSrcY-1;\n\n\t\t\tif(firstChrSrcY > lastInChrBuf) lastInChrBuf= firstChrSrcY-1;\n\n\t\t}\n\n\n\n\t\tASSERT(firstLumSrcY >= lastInLumBuf - vLumBufSize + 1)\n\n\t\tASSERT(firstChrSrcY >= lastInChrBuf - vChrBufSize + 1)\n\n\n\n\t\t// Do we have enough lines in this slice to output the dstY line\n\n\t\tif(lastLumSrcY < srcSliceY + srcSliceH && lastChrSrcY < ((srcSliceY + srcSliceH)>>1))\n\n\t\t{\n\n\t\t\t//Do horizontal scaling\n\n\t\t\twhile(lastInLumBuf < lastLumSrcY)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *src= srcptr[0]+(lastInLumBuf + 1 - srcSliceY)*stride[0];\n\n\t\t\t\tlumBufIndex++;\n\n\t\t\t\tASSERT(lumBufIndex < 2*vLumBufSize)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY < srcSliceH)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY >= 0)\n\n//\t\t\t\tprintf(\"%d %d\\n\", lumBufIndex, vLumBufSize);\n\n\t\t\t\tRENAME(hyscale)(lumPixBuf[ lumBufIndex ], dstW, src, srcW, lumXInc);\n\n\t\t\t\tlastInLumBuf++;\n\n\t\t\t}\n\n\t\t\twhile(lastInChrBuf < lastChrSrcY)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *src1= srcptr[1]+(lastInChrBuf + 1 - (srcSliceY>>1))*stride[1];\n\n\t\t\t\tuint8_t *src2= srcptr[2]+(lastInChrBuf + 1 - (srcSliceY>>1))*stride[2];\n\n\t\t\t\tchrBufIndex++;\n\n\t\t\t\tASSERT(chrBufIndex < 2*vChrBufSize)\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) < (srcSliceH>>1))\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) >= 0)\n\n\t\t\t\tRENAME(hcscale)(chrPixBuf[ chrBufIndex ], chrDstW, src1, src2, srcW>>1, chrXInc);\n\n\t\t\t\tlastInChrBuf++;\n\n\t\t\t}\n\n\t\t\t//wrap buf index around to stay inside the ring buffer\n\n\t\t\tif(lumBufIndex >= vLumBufSize ) lumBufIndex-= vLumBufSize;\n\n\t\t\tif(chrBufIndex >= vChrBufSize ) chrBufIndex-= vChrBufSize;\n\n\t\t}\n\n\t\telse // not enough lines left in this slice -> load the rest in the buffer\n\n\t\t{\n\n/*\t\tprintf(\"%d %d Last:%d %d LastInBuf:%d %d Index:%d %d Y:%d FSize: %d %d BSize: %d %d\\n\",\n\n\t\t\tfirstChrSrcY,firstLumSrcY,lastChrSrcY,lastLumSrcY,\n\n\t\t\tlastInChrBuf,lastInLumBuf,chrBufIndex,lumBufIndex,dstY,vChrFilterSize,vLumFilterSize,\n\n\t\t\tvChrBufSize, vLumBufSize);\n\n*/\n\n\t\t\t//Do horizontal scaling\n\n\t\t\twhile(lastInLumBuf+1 < srcSliceY + srcSliceH)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *src= srcptr[0]+(lastInLumBuf + 1 - srcSliceY)*stride[0];\n\n\t\t\t\tlumBufIndex++;\n\n\t\t\t\tASSERT(lumBufIndex < 2*vLumBufSize)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY < srcSliceH)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY >= 0)\n\n\t\t\t\tRENAME(hyscale)(lumPixBuf[ lumBufIndex ], dstW, src, srcW, lumXInc);\n\n\t\t\t\tlastInLumBuf++;\n\n\t\t\t}\n\n\t\t\twhile(lastInChrBuf+1 < ((srcSliceY + srcSliceH)>>1))\n\n\t\t\t{\n\n\t\t\t\tuint8_t *src1= srcptr[1]+(lastInChrBuf + 1 - (srcSliceY>>1))*stride[1];\n\n\t\t\t\tuint8_t *src2= srcptr[2]+(lastInChrBuf + 1 - (srcSliceY>>1))*stride[2];\n\n\t\t\t\tchrBufIndex++;\n\n\t\t\t\tASSERT(chrBufIndex < 2*vChrBufSize)\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) < (srcSliceH>>1))\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) >= 0)\n\n\t\t\t\tRENAME(hcscale)(chrPixBuf[ chrBufIndex ], chrDstW, src1, src2, srcW>>1, chrXInc);\n\n\t\t\t\tlastInChrBuf++;\n\n\t\t\t}\n\n\t\t\t//wrap buf index around to stay inside the ring buffer\n\n\t\t\tif(lumBufIndex >= vLumBufSize ) lumBufIndex-= vLumBufSize;\n\n\t\t\tif(chrBufIndex >= vChrBufSize ) chrBufIndex-= vChrBufSize;\n\n\t\t\tbreak; //we cant output a dstY line so lets try with the next slice\n\n\t\t}\n\n\n\n#ifdef HAVE_MMX\n\n\t\tb5Dither= dither8[dstY&1];\n\n\t\tg6Dither= dither4[dstY&1];\n\n\t\tg5Dither= dither8[dstY&1];\n\n\t\tr5Dither= dither8[(dstY+1)&1];\n\n#endif\n\n\n\n\t\tif(dstbpp==12) //YV12\n\n\t\t{\n\n\t\t\tif(dstY&1) uDest=vDest= NULL; //FIXME split functions in lumi / chromi\n\n\t\t\tif(vLumFilterSize == 1 && vChrFilterSize == 1) // Unscaled YV12\n\n\t\t\t{\n\n\t\t\t\tint16_t *lumBuf = lumPixBuf[0];\n\n\t\t\t\tint16_t *chrBuf= chrPixBuf[0];\n\n\t\t\t\tRENAME(yuv2yuv1)(lumBuf, chrBuf, dest, uDest, vDest, dstW);\n\n\t\t\t}\n\n\t\t\telse //General YV12\n\n\t\t\t{\n\n\t\t\t\tint16_t **lumSrcPtr= lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n\t\t\t\tint16_t **chrSrcPtr= chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n\t\t\t\tRENAME(yuv2yuvX)(\n\n\t\t\t\t\tvLumFilter+dstY*vLumFilterSize     , lumSrcPtr, vLumFilterSize,\n\n\t\t\t\t\tvChrFilter+(dstY>>1)*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\t\tdest, uDest, vDest, dstW,\n\n\t\t\t\t\tlumMmxFilter+dstY*vLumFilterSize*4, chrMmxFilter+(dstY>>1)*vChrFilterSize*4);\n\n\t\t\t}\n\n\t\t}\n\n\t\telse\n\n\t\t{\n\n\t\t\tint16_t **lumSrcPtr= lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n\t\t\tint16_t **chrSrcPtr= chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n\n\n\t\t\tASSERT(lumSrcPtr + vLumFilterSize - 1 < lumPixBuf + vLumBufSize*2);\n\n\t\t\tASSERT(chrSrcPtr + vChrFilterSize - 1 < chrPixBuf + vChrBufSize*2);\n\n\t\t\tif(vLumFilterSize == 1 && vChrFilterSize == 2) //Unscaled RGB\n\n\t\t\t{\n\n\t\t\t\tint chrAlpha= vChrFilter[2*dstY+1];\n\n\n\n\t\t\t\tRENAME(yuv2rgb1)(*lumSrcPtr, *chrSrcPtr, *(chrSrcPtr+1),\n\n\t\t\t\t\t\t dest, dstW, chrAlpha, dstbpp);\n\n\t\t\t}\n\n\t\t\telse if(vLumFilterSize == 2 && vChrFilterSize == 2) //BiLinear Upscale RGB\n\n\t\t\t{\n\n\t\t\t\tint lumAlpha= vLumFilter[2*dstY+1];\n\n\t\t\t\tint chrAlpha= vChrFilter[2*dstY+1];\n\n\n\n\t\t\t\tRENAME(yuv2rgb2)(*lumSrcPtr, *(lumSrcPtr+1), *chrSrcPtr, *(chrSrcPtr+1),\n\n\t\t\t\t\t\t dest, dstW, lumAlpha, chrAlpha, dstbpp);\n\n\t\t\t}\n\n\t\t\telse //General RGB\n\n\t\t\t{\n\n\t\t\t\tRENAME(yuv2rgbX)(\n\n\t\t\t\t\tvLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n\t\t\t\t\tvChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\t\tdest, dstW, dstbpp,\n\n\t\t\t\t\tlumMmxFilter+dstY*vLumFilterSize*4, chrMmxFilter+dstY*vChrFilterSize*4);\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\n\n#ifdef HAVE_MMX\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\tfirstTime=0;\n\n}", "idx": 25743}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "void ff_mpeg1_encode_picture_header(MpegEncContext *s, int picture_number)\n\n{\n\n    AVFrameSideData *side_data;\n\n    mpeg1_encode_sequence_header(s);\n\n\n\n    /* mpeg1 picture header */\n\n    put_header(s, PICTURE_START_CODE);\n\n    /* temporal reference */\n\n\n\n    // RAL: s->picture_number instead of s->fake_picture_number\n\n    put_bits(&s->pb, 10,\n\n             (s->picture_number - s->gop_picture_number) & 0x3ff);\n\n    put_bits(&s->pb, 3, s->pict_type);\n\n\n\n    s->vbv_delay_ptr = s->pb.buf + put_bits_count(&s->pb) / 8;\n\n    put_bits(&s->pb, 16, 0xFFFF);               /* vbv_delay */\n\n\n\n    // RAL: Forward f_code also needed for B-frames\n\n    if (s->pict_type == AV_PICTURE_TYPE_P ||\n\n        s->pict_type == AV_PICTURE_TYPE_B) {\n\n        put_bits(&s->pb, 1, 0);                 /* half pel coordinates */\n\n        if (s->codec_id == AV_CODEC_ID_MPEG1VIDEO)\n\n            put_bits(&s->pb, 3, s->f_code);     /* forward_f_code */\n\n        else\n\n            put_bits(&s->pb, 3, 7);             /* forward_f_code */\n\n    }\n\n\n\n    // RAL: Backward f_code necessary for B-frames\n\n    if (s->pict_type == AV_PICTURE_TYPE_B) {\n\n        put_bits(&s->pb, 1, 0);                 /* half pel coordinates */\n\n        if (s->codec_id == AV_CODEC_ID_MPEG1VIDEO)\n\n            put_bits(&s->pb, 3, s->b_code);     /* backward_f_code */\n\n        else\n\n            put_bits(&s->pb, 3, 7);             /* backward_f_code */\n\n    }\n\n\n\n    put_bits(&s->pb, 1, 0);                     /* extra bit picture */\n\n\n\n    s->frame_pred_frame_dct = 1;\n\n    if (s->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n        put_header(s, EXT_START_CODE);\n\n        put_bits(&s->pb, 4, 8);                 /* pic ext */\n\n        if (s->pict_type == AV_PICTURE_TYPE_P ||\n\n            s->pict_type == AV_PICTURE_TYPE_B) {\n\n            put_bits(&s->pb, 4, s->f_code);\n\n            put_bits(&s->pb, 4, s->f_code);\n\n        } else {\n\n            put_bits(&s->pb, 8, 255);\n\n        }\n\n        if (s->pict_type == AV_PICTURE_TYPE_B) {\n\n            put_bits(&s->pb, 4, s->b_code);\n\n            put_bits(&s->pb, 4, s->b_code);\n\n        } else {\n\n            put_bits(&s->pb, 8, 255);\n\n        }\n\n        put_bits(&s->pb, 2, s->intra_dc_precision);\n\n\n\n        assert(s->picture_structure == PICT_FRAME);\n\n        put_bits(&s->pb, 2, s->picture_structure);\n\n        if (s->progressive_sequence)\n\n            put_bits(&s->pb, 1, 0);             /* no repeat */\n\n        else\n\n            put_bits(&s->pb, 1, s->current_picture_ptr->f.top_field_first);\n\n        /* XXX: optimize the generation of this flag with entropy measures */\n\n        s->frame_pred_frame_dct = s->progressive_sequence;\n\n\n\n        put_bits(&s->pb, 1, s->frame_pred_frame_dct);\n\n        put_bits(&s->pb, 1, s->concealment_motion_vectors);\n\n        put_bits(&s->pb, 1, s->q_scale_type);\n\n        put_bits(&s->pb, 1, s->intra_vlc_format);\n\n        put_bits(&s->pb, 1, s->alternate_scan);\n\n        put_bits(&s->pb, 1, s->repeat_first_field);\n\n        s->progressive_frame = s->progressive_sequence;\n\n        /* chroma_420_type */\n\n        put_bits(&s->pb, 1, s->chroma_format ==\n\n                            CHROMA_420 ? s->progressive_frame : 0);\n\n        put_bits(&s->pb, 1, s->progressive_frame);\n\n        put_bits(&s->pb, 1, 0);                 /* composite_display_flag */\n\n    }\n\n    if (s->scan_offset) {\n\n        int i;\n\n\n\n        put_header(s, USER_START_CODE);\n\n        for (i = 0; i < sizeof(svcd_scan_offset_placeholder); i++)\n\n            put_bits(&s->pb, 8, svcd_scan_offset_placeholder[i]);\n\n    }\n\n    side_data = av_frame_get_side_data(&s->current_picture_ptr->f,\n\n                                       AV_FRAME_DATA_STEREO3D);\n\n    if (side_data) {\n\n        AVStereo3D *stereo = (AVStereo3D *)side_data->data;\n\n        uint8_t fpa_type;\n\n\n\n        switch (stereo->type) {\n\n        case AV_STEREO3D_SIDEBYSIDE:\n\n            fpa_type = 0x03;\n\n            break;\n\n        case AV_STEREO3D_TOPBOTTOM:\n\n            fpa_type = 0x04;\n\n            break;\n\n        case AV_STEREO3D_2D:\n\n            fpa_type = 0x08;\n\n            break;\n\n        case AV_STEREO3D_SIDEBYSIDE_QUINCUNX:\n\n            fpa_type = 0x23;\n\n            break;\n\n        default:\n\n            fpa_type = 0;\n\n            break;\n\n        }\n\n\n\n        if (fpa_type != 0) {\n\n            put_header(s, USER_START_CODE);\n\n            put_bits(&s->pb, 8, 'J');   // S3D_video_format_signaling_identifier\n\n            put_bits(&s->pb, 8, 'P');\n\n            put_bits(&s->pb, 8, '3');\n\n            put_bits(&s->pb, 8, 'D');\n\n            put_bits(&s->pb, 8, 0x03);  // S3D_video_format_length\n\n\n\n            put_bits(&s->pb, 1, 1);     // reserved_bit\n\n            put_bits(&s->pb, 7, fpa_type); // S3D_video_format_type\n\n            put_bits(&s->pb, 8, 0x04);  // reserved_data[0]\n\n            put_bits(&s->pb, 8, 0xFF);  // reserved_data[1]\n\n        }\n\n    }\n\n\n\n    s->mb_y = 0;\n\n    ff_mpeg1_encode_slice_header(s);\n\n}\n", "idx": 25744}
{"project": "FFmpeg", "commit_id": "816577716bc6170bccfea3b9e865618b69a4b426", "target": 1, "func": "static int dvdsub_decode(AVCodecContext *avctx,\n\n                         void *data, int *data_size,\n\n                         AVPacket *avpkt)\n\n{\n\n    DVDSubContext *ctx = avctx->priv_data;\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    AVSubtitle *sub = data;\n\n    int is_menu;\n\n\n\n    if (ctx->buf) {\n\n        int ret = append_to_cached_buf(avctx, buf, buf_size);\n\n        if (ret < 0) {\n\n            *data_size = 0;\n\n            return ret;\n\n        }\n\n        buf = ctx->buf;\n\n        buf_size = ctx->buf_size;\n\n    }\n\n\n\n    is_menu = decode_dvd_subtitles(ctx, sub, buf, buf_size);\n\n    if (is_menu == AVERROR(EAGAIN)) {\n\n        *data_size = 0;\n\n        return append_to_cached_buf(avctx, buf, buf_size);\n\n    }\n\n\n\n    if (is_menu < 0) {\n\n    no_subtitle:\n\n        reset_rects(sub);\n\n        *data_size = 0;\n\n\n\n        return buf_size;\n\n    }\n\n    if (!is_menu && find_smallest_bounding_rectangle(sub) == 0)\n\n        goto no_subtitle;\n\n\n\n    if (ctx->forced_subs_only && !(sub->rects[0]->flags & AV_SUBTITLE_FLAG_FORCED))\n\n        goto no_subtitle;\n\n\n\n#if defined(DEBUG)\n\n    {\n\n    char ppm_name[32];\n\n\n\n    snprintf(ppm_name, sizeof(ppm_name), \"/tmp/%05d.ppm\", ctx->sub_id++);\n\n    av_dlog(NULL, \"start=%d ms end =%d ms\\n\",\n\n            sub->start_display_time,\n\n            sub->end_display_time);\n\n    ppm_save(ppm_name, sub->rects[0]->pict.data[0],\n\n             sub->rects[0]->w, sub->rects[0]->h, (uint32_t*) sub->rects[0]->pict.data[1]);\n\n    }\n\n#endif\n\n\n\n    av_freep(&ctx->buf);\n\n    ctx->buf_size = 0;\n\n    *data_size = 1;\n\n    return buf_size;\n\n}\n", "idx": 25745}
{"project": "FFmpeg", "commit_id": "4ffe5e2aa5241f8da9afd2c8fbc854dcc916c5f9", "target": 1, "func": "static int read_old_huffman_tables(HYuvContext *s){\n\n#if 1\n\n    GetBitContext gb;\n\n    int i;\n\n\n\n    init_get_bits(&gb, classic_shift_luma, sizeof(classic_shift_luma)*8);\n\n    if(read_len_table(s->len[0], &gb)<0)\n\n        return -1;\n\n    init_get_bits(&gb, classic_shift_chroma, sizeof(classic_shift_chroma)*8);\n\n    if(read_len_table(s->len[1], &gb)<0)\n\n        return -1;\n\n\n\n    for(i=0; i<256; i++) s->bits[0][i] = classic_add_luma  [i];\n\n    for(i=0; i<256; i++) s->bits[1][i] = classic_add_chroma[i];\n\n\n\n    if(s->bitstream_bpp >= 24){\n\n        memcpy(s->bits[1], s->bits[0], 256*sizeof(uint32_t));\n\n        memcpy(s->len[1] , s->len [0], 256*sizeof(uint8_t));\n\n    }\n\n    memcpy(s->bits[2], s->bits[1], 256*sizeof(uint32_t));\n\n    memcpy(s->len[2] , s->len [1], 256*sizeof(uint8_t));\n\n\n\n    for(i=0; i<3; i++){\n\n        ff_free_vlc(&s->vlc[i]);\n\n        init_vlc(&s->vlc[i], VLC_BITS, 256, s->len[i], 1, 1, s->bits[i], 4, 4, 0);\n\n    }\n\n\n\n    generate_joint_tables(s);\n\n\n\n    return 0;\n\n#else\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"v1 huffyuv is not supported \\n\");\n\n    return -1;\n\n#endif\n\n}\n", "idx": 25748}
{"project": "FFmpeg", "commit_id": "9bcbb250e23959075765edd3cb4c1fcb46736d7d", "target": 0, "func": "static inline void RENAME(hcscale_fast)(SwsContext *c, int16_t *dst1, int16_t *dst2,\n\n                                        int dstWidth, const uint8_t *src1,\n\n                                        const uint8_t *src2, int srcW, int xInc)\n\n{\n\n    int32_t *filterPos = c->hChrFilterPos;\n\n    int16_t *filter    = c->hChrFilter;\n\n    void    *mmx2FilterCode= c->chrMmx2FilterCode;\n\n    int i;\n\n#if defined(PIC)\n\n    DECLARE_ALIGNED(8, uint64_t, ebxsave);\n\n#endif\n\n\n\n    __asm__ volatile(\n\n#if defined(PIC)\n\n        \"mov          %%\"REG_b\", %7         \\n\\t\"\n\n#endif\n\n        \"pxor             %%mm7, %%mm7      \\n\\t\"\n\n        \"mov                 %0, %%\"REG_c\"  \\n\\t\"\n\n        \"mov                 %1, %%\"REG_D\"  \\n\\t\"\n\n        \"mov                 %2, %%\"REG_d\"  \\n\\t\"\n\n        \"mov                 %3, %%\"REG_b\"  \\n\\t\"\n\n        \"xor          %%\"REG_a\", %%\"REG_a\"  \\n\\t\" // i\n\n        PREFETCH\"   (%%\"REG_c\")             \\n\\t\"\n\n        PREFETCH\" 32(%%\"REG_c\")             \\n\\t\"\n\n        PREFETCH\" 64(%%\"REG_c\")             \\n\\t\"\n\n\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        \"xor          %%\"REG_a\", %%\"REG_a\"  \\n\\t\" // i\n\n        \"mov                 %5, %%\"REG_c\"  \\n\\t\" // src\n\n        \"mov                 %6, %%\"REG_D\"  \\n\\t\" // buf2\n\n        PREFETCH\"   (%%\"REG_c\")             \\n\\t\"\n\n        PREFETCH\" 32(%%\"REG_c\")             \\n\\t\"\n\n        PREFETCH\" 64(%%\"REG_c\")             \\n\\t\"\n\n\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n\n\n#if defined(PIC)\n\n        \"mov %7, %%\"REG_b\"    \\n\\t\"\n\n#endif\n\n        :: \"m\" (src1), \"m\" (dst1), \"m\" (filter), \"m\" (filterPos),\n\n           \"m\" (mmx2FilterCode), \"m\" (src2), \"m\"(dst2)\n\n#if defined(PIC)\n\n          ,\"m\" (ebxsave)\n\n#endif\n\n        : \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S, \"%\"REG_D\n\n#if !defined(PIC)\n\n         ,\"%\"REG_b\n\n#endif\n\n    );\n\n\n\n    for (i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--) {\n\n        dst1[i] = src1[srcW-1]*128;\n\n        dst2[i] = src2[srcW-1]*128;\n\n    }\n\n}\n", "idx": 25750}
{"project": "FFmpeg", "commit_id": "a67304d05f11b2377bf157a356d7ebb00f3e06dd", "target": 0, "func": "void av_md5_update(AVMD5 *ctx, const uint8_t *src, int len)\n\n{\n\n    const uint8_t *end;\n\n    int j;\n\n\n\n    j = ctx->len & 63;\n\n    ctx->len += len;\n\n\n\n    if (j) {\n\n        int cnt = FFMIN(len, 64 - j);\n\n        memcpy(ctx->block + j, src, cnt);\n\n        src += cnt;\n\n        len -= cnt;\n\n        if (j + cnt < 64)\n\n            return;\n\n        body(ctx->ABCD, (uint32_t *)ctx->block);\n\n    }\n\n\n\n    end = src + (len & ~63);\n\n    if (HAVE_BIGENDIAN || (!HAVE_FAST_UNALIGNED && ((intptr_t)src & 3))) {\n\n       while (src < end) {\n\n           memcpy(ctx->block, src, 64);\n\n           body(ctx->ABCD, (uint32_t *) ctx->block);\n\n           src += 64;\n\n        }\n\n    } else {\n\n        while (src < end) {\n\n            body(ctx->ABCD, (uint32_t *)src);\n\n            src += 64;\n\n        }\n\n    }\n\n    len &= 63;\n\n    if (len > 0)\n\n        memcpy(ctx->block, src, len);\n\n}\n", "idx": 25759}
{"project": "FFmpeg", "commit_id": "ca16618b01abfde44b4eaf92dc89b01aa1b4a91e", "target": 0, "func": "static int xan_decode_init(AVCodecContext *avctx)\n\n{\n\n    XanContext *s = avctx->priv_data;\n\n    int i;\n\n\n\n    s->avctx = avctx;\n\n\n\n    if ((avctx->codec->id == CODEC_ID_XAN_WC3) && \n\n        (s->avctx->palctrl == NULL)) {\n\n        av_log(avctx, AV_LOG_ERROR, \" WC3 Xan video: palette expected.\\n\");\n\n        return -1;\n\n    }\n\n\n\n    avctx->pix_fmt = PIX_FMT_PAL8;\n\n    avctx->has_b_frames = 0;\n\n    dsputil_init(&s->dsp, avctx);\n\n\n\n    /* initialize the RGB -> YUV tables */\n\n    for (i = 0; i < 256; i++) {\n\n        y_r_table[i] = Y_R * i;\n\n        y_g_table[i] = Y_G * i;\n\n        y_b_table[i] = Y_B * i;\n\n\n\n        u_r_table[i] = U_R * i;\n\n        u_g_table[i] = U_G * i;\n\n        u_b_table[i] = U_B * i;\n\n\n\n        v_r_table[i] = V_R * i;\n\n        v_g_table[i] = V_G * i;\n\n        v_b_table[i] = V_B * i;\n\n    }\n\n\n\n    if(avcodec_check_dimensions(avctx, avctx->width, avctx->height))\n\n        return -1;\n\n    \n\n    s->buffer1 = av_malloc(avctx->width * avctx->height);\n\n    s->buffer2 = av_malloc(avctx->width * avctx->height);\n\n    if (!s->buffer1 || !s->buffer2)\n\n        return -1;\n\n\n\n    return 0;\n\n}\n", "idx": 25770}
{"project": "FFmpeg", "commit_id": "0ce3a0f9d9523a9bcad4c6d451ca5bbd7a4f420d", "target": 1, "func": "static void restore_median_il(uint8_t *src, int step, int stride,\n\n                              int width, int height, int slices, int rmode)\n\n{\n\n    int i, j, slice;\n\n    int A, B, C;\n\n    uint8_t *bsrc;\n\n    int slice_start, slice_height;\n\n    const int cmask   = ~(rmode ? 3 : 1);\n\n    const int stride2 = stride << 1;\n\n\n\n    for (slice = 0; slice < slices; slice++) {\n\n        slice_start    = ((slice * height) / slices) & cmask;\n\n        slice_height   = ((((slice + 1) * height) / slices) & cmask) -\n\n                         slice_start;\n\n        slice_height >>= 1;\n\n\n\n\n\n        bsrc = src + slice_start * stride;\n\n\n\n        // first line - left neighbour prediction\n\n        bsrc[0] += 0x80;\n\n        A        = bsrc[0];\n\n        for (i = step; i < width * step; i += step) {\n\n            bsrc[i] += A;\n\n            A        = bsrc[i];\n\n        }\n\n        for (i = 0; i < width * step; i += step) {\n\n            bsrc[stride + i] += A;\n\n            A                 = bsrc[stride + i];\n\n        }\n\n        bsrc += stride2;\n\n        if (slice_height == 1)\n\n\n        // second line - first element has top prediction, the rest uses median\n\n        C        = bsrc[-stride2];\n\n        bsrc[0] += C;\n\n        A        = bsrc[0];\n\n        for (i = step; i < width * step; i += step) {\n\n            B        = bsrc[i - stride2];\n\n            bsrc[i] += mid_pred(A, B, (uint8_t)(A + B - C));\n\n            C        = B;\n\n            A        = bsrc[i];\n\n        }\n\n        for (i = 0; i < width * step; i += step) {\n\n            B                 = bsrc[i - stride];\n\n            bsrc[stride + i] += mid_pred(A, B, (uint8_t)(A + B - C));\n\n            C                 = B;\n\n            A                 = bsrc[stride + i];\n\n        }\n\n        bsrc += stride2;\n\n        // the rest of lines use continuous median prediction\n\n        for (j = 2; j < slice_height; j++) {\n\n            for (i = 0; i < width * step; i += step) {\n\n                B        = bsrc[i - stride2];\n\n                bsrc[i] += mid_pred(A, B, (uint8_t)(A + B - C));\n\n                C        = B;\n\n                A        = bsrc[i];\n\n            }\n\n            for (i = 0; i < width * step; i += step) {\n\n                B                 = bsrc[i - stride];\n\n                bsrc[i + stride] += mid_pred(A, B, (uint8_t)(A + B - C));\n\n                C                 = B;\n\n                A                 = bsrc[i + stride];\n\n            }\n\n            bsrc += stride2;\n\n        }\n\n    }\n\n}", "idx": 25772}
{"project": "FFmpeg", "commit_id": "1acd7d594c15aa491729c837ad3519d3469e620a", "target": 0, "func": "static void FUNCC(pred8x8l_vertical_add)(uint8_t *_pix, const int16_t *_block,\n\n                                         ptrdiff_t stride)\n\n{\n\n    int i;\n\n    pixel *pix = (pixel*)_pix;\n\n    const dctcoef *block = (const dctcoef*)_block;\n\n    stride >>= sizeof(pixel)-1;\n\n    pix -= stride;\n\n    for(i=0; i<8; i++){\n\n        pixel v = pix[0];\n\n        pix[1*stride]= v += block[0];\n\n        pix[2*stride]= v += block[8];\n\n        pix[3*stride]= v += block[16];\n\n        pix[4*stride]= v += block[24];\n\n        pix[5*stride]= v += block[32];\n\n        pix[6*stride]= v += block[40];\n\n        pix[7*stride]= v += block[48];\n\n        pix[8*stride]= v +  block[56];\n\n        pix++;\n\n        block++;\n\n    }\n\n}\n", "idx": 25777}
{"project": "FFmpeg", "commit_id": "7b9fc769e40a7709fa59a54e2a810f76364eee4b", "target": 0, "func": "static int svq1_decode_frame(AVCodecContext *avctx, void *data,\n\n                             int *data_size, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    MpegEncContext *s  = avctx->priv_data;\n\n    uint8_t *current, *previous;\n\n    int result, i, x, y, width, height;\n\n    AVFrame *pict = data;\n\n    svq1_pmv *pmv;\n\n\n\n    /* initialize bit buffer */\n\n    init_get_bits(&s->gb, buf, buf_size * 8);\n\n\n\n    /* decode frame header */\n\n    s->f_code = get_bits(&s->gb, 22);\n\n\n\n    if ((s->f_code & ~0x70) || !(s->f_code & 0x60))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    /* swap some header bytes (why?) */\n\n    if (s->f_code != 0x20) {\n\n        uint32_t *src = (uint32_t *)(buf + 4);\n\n\n\n        if (buf_size < 36)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        for (i = 0; i < 4; i++)\n\n            src[i] = ((src[i] << 16) | (src[i] >> 16)) ^ src[7 - i];\n\n    }\n\n\n\n    result = svq1_decode_frame_header(&s->gb, s);\n\n\n\n    if (result != 0) {\n\n        av_dlog(s->avctx, \"Error in svq1_decode_frame_header %i\\n\", result);\n\n        return result;\n\n    }\n\n    avcodec_set_dimensions(avctx, s->width, s->height);\n\n\n\n    /* FIXME: This avoids some confusion for \"B frames\" without 2 references.\n\n     * This should be removed after libavcodec can handle more flexible\n\n     * picture types & ordering */\n\n    if (s->pict_type == AV_PICTURE_TYPE_B && s->last_picture_ptr == NULL)\n\n        return buf_size;\n\n\n\n    if ((avctx->skip_frame >= AVDISCARD_NONREF &&\n\n         s->pict_type == AV_PICTURE_TYPE_B)    ||\n\n        (avctx->skip_frame >= AVDISCARD_NONKEY &&\n\n         s->pict_type != AV_PICTURE_TYPE_I)    ||\n\n        avctx->skip_frame >= AVDISCARD_ALL)\n\n        return buf_size;\n\n\n\n    if ((result = ff_MPV_frame_start(s, avctx)) < 0)\n\n        return result;\n\n\n\n    pmv = av_malloc((FFALIGN(s->width, 16) / 8 + 3) * sizeof(*pmv));\n\n    if (!pmv)\n\n        return AVERROR(ENOMEM);\n\n\n\n    /* decode y, u and v components */\n\n    for (i = 0; i < 3; i++) {\n\n        int linesize;\n\n        if (i == 0) {\n\n            width    = FFALIGN(s->width,  16);\n\n            height   = FFALIGN(s->height, 16);\n\n            linesize = s->linesize;\n\n        } else {\n\n            if (s->flags & CODEC_FLAG_GRAY)\n\n                break;\n\n            width    = FFALIGN(s->width  / 4, 16);\n\n            height   = FFALIGN(s->height / 4, 16);\n\n            linesize = s->uvlinesize;\n\n        }\n\n\n\n        current = s->current_picture.f.data[i];\n\n\n\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n\n            previous = s->next_picture.f.data[i];\n\n        else\n\n            previous = s->last_picture.f.data[i];\n\n\n\n        if (s->pict_type == AV_PICTURE_TYPE_I) {\n\n            /* keyframe */\n\n            for (y = 0; y < height; y += 16) {\n\n                for (x = 0; x < width; x += 16) {\n\n                    result = svq1_decode_block_intra(&s->gb, &current[x],\n\n                                                     linesize);\n\n                    if (result != 0) {\n\n                        av_log(s->avctx, AV_LOG_INFO,\n\n                               \"Error in svq1_decode_block %i (keyframe)\\n\",\n\n                               result);\n\n                        goto err;\n\n                    }\n\n                }\n\n                current += 16 * linesize;\n\n            }\n\n        } else {\n\n            /* delta frame */\n\n            memset(pmv, 0, ((width / 8) + 3) * sizeof(svq1_pmv));\n\n\n\n            for (y = 0; y < height; y += 16) {\n\n                for (x = 0; x < width; x += 16) {\n\n                    result = svq1_decode_delta_block(s, &s->gb, &current[x],\n\n                                                     previous, linesize,\n\n                                                     pmv, x, y);\n\n                    if (result != 0) {\n\n                        av_dlog(s->avctx,\n\n                                \"Error in svq1_decode_delta_block %i\\n\",\n\n                                result);\n\n                        goto err;\n\n                    }\n\n                }\n\n\n\n                pmv[0].x     =\n\n                    pmv[0].y = 0;\n\n\n\n                current += 16 * linesize;\n\n            }\n\n        }\n\n    }\n\n\n\n    *pict = s->current_picture.f;\n\n\n\n    ff_MPV_frame_end(s);\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    result     = buf_size;\n\n\n\nerr:\n\n    av_free(pmv);\n\n    return result;\n\n}\n", "idx": 25778}
{"project": "FFmpeg", "commit_id": "a443a2530d00b7019269202ac0f5ca8ba0a021c7", "target": 1, "func": "static int rm_read_header(AVFormatContext *s, AVFormatParameters *ap)\n{\n    RMContext *rm = s->priv_data;\n    AVStream *st;\n    ByteIOContext *pb = &s->pb;\n    unsigned int tag, v;\n    int tag_size, size, codec_data_size, i;\n    int64_t codec_pos;\n    unsigned int h263_hack_version, start_time, duration;\n    char buf[128];\n    int flags = 0;\n    tag = get_le32(pb);\n    if (tag == MKTAG('.', 'r', 'a', 0xfd)) {\n        /* very old .ra format */\n        return rm_read_header_old(s, ap);\n    } else if (tag != MKTAG('.', 'R', 'M', 'F')) {\n        return AVERROR_IO;\n    get_be32(pb); /* header size */\n    get_be16(pb);\n    get_be32(pb);\n    get_be32(pb); /* number of headers */\n    for(;;) {\n        if (url_feof(pb))\n            goto fail;\n        tag = get_le32(pb);\n        tag_size = get_be32(pb);\n        get_be16(pb);\n#if 0\n        printf(\"tag=%c%c%c%c (%08x) size=%d\\n\",\n               (tag) & 0xff,\n               (tag >> 8) & 0xff,\n               (tag >> 16) & 0xff,\n               (tag >> 24) & 0xff,\n               tag,\n               tag_size);\n#endif\n        if (tag_size < 10 && tag != MKTAG('D', 'A', 'T', 'A'))\n            goto fail;\n        switch(tag) {\n        case MKTAG('P', 'R', 'O', 'P'):\n            /* file header */\n            get_be32(pb); /* max bit rate */\n            get_be32(pb); /* avg bit rate */\n            get_be32(pb); /* max packet size */\n            get_be32(pb); /* avg packet size */\n            get_be32(pb); /* nb packets */\n            get_be32(pb); /* duration */\n            get_be32(pb); /* preroll */\n            get_be32(pb); /* index offset */\n            get_be32(pb); /* data offset */\n            get_be16(pb); /* nb streams */\n            flags = get_be16(pb); /* flags */\n            break;\n        case MKTAG('C', 'O', 'N', 'T'):\n            get_str(pb, s->title, sizeof(s->title));\n            get_str(pb, s->author, sizeof(s->author));\n            get_str(pb, s->copyright, sizeof(s->copyright));\n            get_str(pb, s->comment, sizeof(s->comment));\n            break;\n        case MKTAG('M', 'D', 'P', 'R'):\n            st = av_new_stream(s, 0);\n            if (!st)\n                goto fail;\n            st->id = get_be16(pb);\n            get_be32(pb); /* max bit rate */\n            st->codec->bit_rate = get_be32(pb); /* bit rate */\n            get_be32(pb); /* max packet size */\n            get_be32(pb); /* avg packet size */\n            start_time = get_be32(pb); /* start time */\n            get_be32(pb); /* preroll */\n            duration = get_be32(pb); /* duration */\n            st->start_time = start_time;\n            st->duration = duration;\n            get_str8(pb, buf, sizeof(buf)); /* desc */\n            get_str8(pb, buf, sizeof(buf)); /* mimetype */\n            codec_data_size = get_be32(pb);\n            codec_pos = url_ftell(pb);\n            st->codec->codec_type = CODEC_TYPE_DATA;\n            av_set_pts_info(st, 64, 1, 1000);\n            v = get_be32(pb);\n            if (v == MKTAG(0xfd, 'a', 'r', '.')) {\n                /* ra type header */\n                rm_read_audio_stream_info(s, st, 0);\n            } else {\n                int fps, fps2;\n                if (get_le32(pb) != MKTAG('V', 'I', 'D', 'O')) {\n                fail1:\n                    av_log(st->codec, AV_LOG_ERROR, \"Unsupported video codec\\n\");\n                    goto skip;\n                st->codec->codec_tag = get_le32(pb);\n//                av_log(NULL, AV_LOG_DEBUG, \"%X %X\\n\", st->codec->codec_tag, MKTAG('R', 'V', '2', '0'));\n                if (   st->codec->codec_tag != MKTAG('R', 'V', '1', '0')\n                    && st->codec->codec_tag != MKTAG('R', 'V', '2', '0')\n                    && st->codec->codec_tag != MKTAG('R', 'V', '3', '0')\n                    && st->codec->codec_tag != MKTAG('R', 'V', '4', '0'))\n                    goto fail1;\n                st->codec->width = get_be16(pb);\n                st->codec->height = get_be16(pb);\n                st->codec->time_base.num= 1;\n                fps= get_be16(pb);\n                st->codec->codec_type = CODEC_TYPE_VIDEO;\n                get_be32(pb);\n                fps2= get_be16(pb);\n                get_be16(pb);\n                st->codec->extradata_size= codec_data_size - (url_ftell(pb) - codec_pos);\n                st->codec->extradata= av_mallocz(st->codec->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE);\n                get_buffer(pb, st->codec->extradata, st->codec->extradata_size);\n//                av_log(NULL, AV_LOG_DEBUG, \"fps= %d fps2= %d\\n\", fps, fps2);\n                st->codec->time_base.den = fps * st->codec->time_base.num;\n                /* modification of h263 codec version (!) */\n#ifdef WORDS_BIGENDIAN\n                h263_hack_version = ((uint32_t*)st->codec->extradata)[1];\n#else\n                h263_hack_version = bswap_32(((uint32_t*)st->codec->extradata)[1]);\n#endif\n                st->codec->sub_id = h263_hack_version;\n                switch((h263_hack_version>>28)){\n                case 1: st->codec->codec_id = CODEC_ID_RV10; break;\n                case 2: st->codec->codec_id = CODEC_ID_RV20; break;\n                case 3: st->codec->codec_id = CODEC_ID_RV30; break;\n                case 4: st->codec->codec_id = CODEC_ID_RV40; break;\n                default: goto fail1;\nskip:\n            /* skip codec info */\n            size = url_ftell(pb) - codec_pos;\n            url_fskip(pb, codec_data_size - size);\n            break;\n        case MKTAG('D', 'A', 'T', 'A'):\n            goto header_end;\n        default:\n            /* unknown tag: skip it */\n            url_fskip(pb, tag_size - 10);\n            break;\n header_end:\n    rm->nb_packets = get_be32(pb); /* number of packets */\n    if (!rm->nb_packets && (flags & 4))\n        rm->nb_packets = 3600 * 25;\n    get_be32(pb); /* next data header */\n    return 0;\n fail:\n    for(i=0;i<s->nb_streams;i++) {\n        av_free(s->streams[i]);\n    return AVERROR_IO;", "idx": 25780}
{"project": "FFmpeg", "commit_id": "c37de519202ac2e5f20141673081b0e6b57ab983", "target": 1, "func": "int ff_vorbis_len2vlc(uint8_t *bits, uint32_t *codes, unsigned num)\n\n{\n\n    uint32_t exit_at_level[33] = { 404 };\n\n    unsigned i, j, p, code;\n\n\n\n    for (p = 0; (bits[p] == 0) && (p < num); ++p)\n\n        ;\n\n    if (p == num)\n\n        return 0;\n\n\n\n    codes[p] = 0;\n\n    if (bits[p] > 32)\n\n        return AVERROR_INVALIDDATA;\n\n    for (i = 0; i < bits[p]; ++i)\n\n        exit_at_level[i+1] = 1 << i;\n\n\n\n    ++p;\n\n\n\n    for (i = p; (bits[i] == 0) && (i < num); ++i)\n\n        ;\n\n    if (i == num)\n\n        return 0;\n\n\n\n    for (; p < num; ++p) {\n\n        if (bits[p] > 32)\n\n             return AVERROR_INVALIDDATA;\n\n        if (bits[p] == 0)\n\n             continue;\n\n        // find corresponding exit(node which the tree can grow further from)\n\n        for (i = bits[p]; i > 0; --i)\n\n            if (exit_at_level[i])\n\n                break;\n\n        if (!i) // overspecified tree\n\n             return AVERROR_INVALIDDATA;\n\n        code = exit_at_level[i];\n\n        exit_at_level[i] = 0;\n\n        // construct code (append 0s to end) and introduce new exits\n\n        for (j = i + 1 ;j <= bits[p]; ++j)\n\n            exit_at_level[j] = code + (1 << (j - 1));\n\n        codes[p] = code;\n\n    }\n\n\n\n    //no exits should be left (underspecified tree - ie. unused valid vlcs - not allowed by SPEC)\n\n    for (p = 1; p < 33; p++)\n\n        if (exit_at_level[p])\n\n            return AVERROR_INVALIDDATA;\n\n\n\n    return 0;\n\n}\n", "idx": 25782}
{"project": "FFmpeg", "commit_id": "cba92a2226151abf0e3c24ed594e127203d485b8", "target": 1, "func": "static int vobsub_read_header(AVFormatContext *s)\n\n{\n\n    int i, ret = 0, header_parsed = 0, langidx = 0;\n\n    MpegDemuxContext *vobsub = s->priv_data;\n\n    char *sub_name = NULL;\n\n    size_t fname_len;\n\n    char *ext, *header_str;\n\n    AVBPrint header;\n\n    int64_t delay = 0;\n\n    AVStream *st = NULL;\n\n\n\n    sub_name = av_strdup(s->filename);\n\n    fname_len = strlen(sub_name);\n\n    ext = sub_name - 3 + fname_len;\n\n    if (fname_len < 4 || *(ext - 1) != '.') {\n\n        av_log(s, AV_LOG_ERROR, \"The input index filename is too short \"\n\n               \"to guess the associated .SUB file\\n\");\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto end;\n\n    }\n\n    memcpy(ext, !strncmp(ext, \"IDX\", 3) ? \"SUB\" : \"sub\", 3);\n\n    av_log(s, AV_LOG_VERBOSE, \"IDX/SUB: %s -> %s\\n\", s->filename, sub_name);\n\n    ret = avformat_open_input(&vobsub->sub_ctx, sub_name, &ff_mpegps_demuxer, NULL);\n\n    if (ret < 0) {\n\n        av_log(s, AV_LOG_ERROR, \"Unable to open %s as MPEG subtitles\\n\", sub_name);\n\n        goto end;\n\n    }\n\n\n\n    av_bprint_init(&header, 0, AV_BPRINT_SIZE_UNLIMITED);\n\n    while (!url_feof(s->pb)) {\n\n        char line[2048];\n\n        int len = ff_get_line(s->pb, line, sizeof(line));\n\n\n\n        if (!len)\n\n            break;\n\n\n\n        line[strcspn(line, \"\\r\\n\")] = 0;\n\n\n\n        if (!strncmp(line, \"id:\", 3)) {\n\n            int n, stream_id = 0;\n\n            char id[64] = {0};\n\n\n\n            n = sscanf(line, \"id: %63[^,], index: %u\", id, &stream_id);\n\n            if (n != 2) {\n\n                av_log(s, AV_LOG_WARNING, \"Unable to parse index line '%s', \"\n\n                       \"assuming 'id: und, index: 0'\\n\", line);\n\n                strcpy(id, \"und\");\n\n                stream_id = 0;\n\n            }\n\n\n\n            if (stream_id >= FF_ARRAY_ELEMS(vobsub->q)) {\n\n                av_log(s, AV_LOG_ERROR, \"Maximum number of subtitles streams reached\\n\");\n\n                ret = AVERROR(EINVAL);\n\n                goto end;\n\n            }\n\n\n\n            st = avformat_new_stream(s, NULL);\n\n            if (!st) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto end;\n\n            }\n\n            st->id = stream_id;\n\n            st->codec->codec_type = AVMEDIA_TYPE_SUBTITLE;\n\n            st->codec->codec_id   = AV_CODEC_ID_DVD_SUBTITLE;\n\n            avpriv_set_pts_info(st, 64, 1, 1000);\n\n            av_dict_set(&st->metadata, \"language\", id, 0);\n\n            av_log(s, AV_LOG_DEBUG, \"IDX stream[%d] id=%s\\n\", stream_id, id);\n\n            header_parsed = 1;\n\n\n\n        } else if (st && !strncmp(line, \"timestamp:\", 10)) {\n\n            AVPacket *sub;\n\n            int hh, mm, ss, ms;\n\n            int64_t pos, timestamp;\n\n            const char *p = line + 10;\n\n\n\n            if (!s->nb_streams) {\n\n                av_log(s, AV_LOG_ERROR, \"Timestamp declared before any stream\\n\");\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto end;\n\n            }\n\n\n\n            if (sscanf(p, \"%02d:%02d:%02d:%03d, filepos: %\"SCNx64,\n\n                       &hh, &mm, &ss, &ms, &pos) != 5) {\n\n                av_log(s, AV_LOG_ERROR, \"Unable to parse timestamp line '%s', \"\n\n                       \"abort parsing\\n\", line);\n\n                break;\n\n            }\n\n            timestamp = (hh*3600LL + mm*60LL + ss) * 1000LL + ms + delay;\n\n            timestamp = av_rescale_q(timestamp, av_make_q(1, 1000), st->time_base);\n\n\n\n            sub = ff_subtitles_queue_insert(&vobsub->q[s->nb_streams - 1], \"\", 0, 0);\n\n            if (!sub) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto end;\n\n            }\n\n            sub->pos = pos;\n\n            sub->pts = timestamp;\n\n            sub->stream_index = s->nb_streams - 1;\n\n\n\n        } else if (st && !strncmp(line, \"alt:\", 4)) {\n\n            const char *p = line + 4;\n\n\n\n            while (*p == ' ')\n\n                p++;\n\n            av_dict_set(&st->metadata, \"title\", p, 0);\n\n            av_log(s, AV_LOG_DEBUG, \"IDX stream[%d] name=%s\\n\", st->id, p);\n\n            header_parsed = 1;\n\n\n\n        } else if (!strncmp(line, \"delay:\", 6)) {\n\n            int sign = 1, hh = 0, mm = 0, ss = 0, ms = 0;\n\n            const char *p = line + 6;\n\n\n\n            while (*p == ' ')\n\n                p++;\n\n            if (*p == '-' || *p == '+') {\n\n                sign = *p == '-' ? -1 : 1;\n\n                p++;\n\n            }\n\n            sscanf(p, \"%d:%d:%d:%d\", &hh, &mm, &ss, &ms);\n\n            delay = ((hh*3600LL + mm*60LL + ss) * 1000LL + ms) * sign;\n\n\n\n        } else if (!strncmp(line, \"langidx:\", 8)) {\n\n            const char *p = line + 8;\n\n\n\n            if (sscanf(p, \"%d\", &langidx) != 1)\n\n                av_log(s, AV_LOG_ERROR, \"Invalid langidx specified\\n\");\n\n\n\n        } else if (!header_parsed) {\n\n            if (line[0] && line[0] != '#')\n\n                av_bprintf(&header, \"%s\\n\", line);\n\n        }\n\n    }\n\n\n\n    if (langidx < s->nb_streams)\n\n        s->streams[langidx]->disposition |= AV_DISPOSITION_DEFAULT;\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        vobsub->q[i].sort = SUB_SORT_POS_TS;\n\n        ff_subtitles_queue_finalize(&vobsub->q[i]);\n\n    }\n\n\n\n    if (!av_bprint_is_complete(&header)) {\n\n        av_bprint_finalize(&header, NULL);\n\n        ret = AVERROR(ENOMEM);\n\n        goto end;\n\n    }\n\n    av_bprint_finalize(&header, &header_str);\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVStream *sub_st = s->streams[i];\n\n        sub_st->codec->extradata      = av_strdup(header_str);\n\n        sub_st->codec->extradata_size = header.len;\n\n    }\n\n    av_free(header_str);\n\n\n\nend:\n\n    av_free(sub_name);\n\n    return ret;\n\n}\n", "idx": 25784}
{"project": "FFmpeg", "commit_id": "29d46d7bce1c67852e4c6e22605144eb32b21072", "target": 1, "func": "static void json_print_section_header(WriterContext *wctx)\n\n{\n\n    JSONContext *json = wctx->priv;\n\n    AVBPrint buf;\n\n    const struct section *section = wctx->section[wctx->level];\n\n    const struct section *parent_section = wctx->level ?\n\n        wctx->section[wctx->level-1] : NULL;\n\n\n\n    if (wctx->level && wctx->nb_item[wctx->level-1])\n\n        printf(\",\\n\");\n\n\n\n    if (section->flags & SECTION_FLAG_IS_WRAPPER) {\n\n        printf(\"{\\n\");\n\n        json->indent_level++;\n\n    } else {\n\n        av_bprint_init(&buf, 1, AV_BPRINT_SIZE_UNLIMITED);\n\n        json_escape_str(&buf, section->name, wctx);\n\n        JSON_INDENT();\n\n\n\n        json->indent_level++;\n\n        if (section->flags & SECTION_FLAG_IS_ARRAY) {\n\n            printf(\"\\\"%s\\\": [\\n\", buf.str);\n\n        } else if (!(parent_section->flags & SECTION_FLAG_IS_ARRAY)) {\n\n            printf(\"\\\"%s\\\": {%s\", buf.str, json->item_start_end);\n\n        } else {\n\n            printf(\"{%s\", json->item_start_end);\n\n\n\n            /* this is required so the parser can distinguish between packets and frames */\n\n            if (parent_section->id == SECTION_ID_PACKETS_AND_FRAMES) {\n\n                if (!json->compact)\n\n                    JSON_INDENT();\n\n                printf(\"\\\"type\\\": \\\"%s\\\"%s\", section->name, json->item_sep);\n\n            }\n\n        }\n\n        av_bprint_finalize(&buf, NULL);\n\n    }\n\n}\n", "idx": 25787}
{"project": "FFmpeg", "commit_id": "d5028f61e44b7607b6a547f218f7d85217490a5b", "target": 1, "func": "static av_always_inline int mvd_decode(HEVCContext *s)\n\n{\n\n    int ret = 2;\n\n    int k = 1;\n\n\n\n    while (k < CABAC_MAX_BIN && get_cabac_bypass(&s->HEVClc->cc)) {\n\n        ret += 1 << k;\n\n        k++;\n\n    }\n\n    if (k == CABAC_MAX_BIN)\n\n        av_log(s->avctx, AV_LOG_ERROR, \"CABAC_MAX_BIN : %d\\n\", k);\n\n    while (k--)\n\n        ret += get_cabac_bypass(&s->HEVClc->cc) << k;\n\n    return get_cabac_bypass_sign(&s->HEVClc->cc, -ret);\n\n}\n", "idx": 25788}
{"project": "FFmpeg", "commit_id": "01f0e6a0c9270f1d5bef08459a6f167cf55e0596", "target": 1, "func": "av_cold int ff_vc1_decode_init_alloc_tables(VC1Context *v)\n\n{\n\n    MpegEncContext *s = &v->s;\n\n    int i;\n\n    int mb_height = FFALIGN(s->mb_height, 2);\n\n\n\n    /* Allocate mb bitplanes */\n\n    v->mv_type_mb_plane = av_malloc (s->mb_stride * mb_height);\n\n    v->direct_mb_plane  = av_malloc (s->mb_stride * mb_height);\n\n    v->forward_mb_plane = av_malloc (s->mb_stride * mb_height);\n\n    v->fieldtx_plane    = av_mallocz(s->mb_stride * mb_height);\n\n    v->acpred_plane     = av_malloc (s->mb_stride * mb_height);\n\n    v->over_flags_plane = av_malloc (s->mb_stride * mb_height);\n\n\n\n    v->n_allocated_blks = s->mb_width + 2;\n\n    v->block            = av_malloc(sizeof(*v->block) * v->n_allocated_blks);\n\n    v->cbp_base         = av_malloc(sizeof(v->cbp_base[0]) * 2 * s->mb_stride);\n\n    v->cbp              = v->cbp_base + s->mb_stride;\n\n    v->ttblk_base       = av_malloc(sizeof(v->ttblk_base[0]) * 2 * s->mb_stride);\n\n    v->ttblk            = v->ttblk_base + s->mb_stride;\n\n    v->is_intra_base    = av_mallocz(sizeof(v->is_intra_base[0]) * 2 * s->mb_stride);\n\n    v->is_intra         = v->is_intra_base + s->mb_stride;\n\n    v->luma_mv_base     = av_malloc(sizeof(v->luma_mv_base[0]) * 2 * s->mb_stride);\n\n    v->luma_mv          = v->luma_mv_base + s->mb_stride;\n\n\n\n    /* allocate block type info in that way so it could be used with s->block_index[] */\n\n    v->mb_type_base = av_malloc(s->b8_stride * (mb_height * 2 + 1) + s->mb_stride * (mb_height + 1) * 2);\n\n    v->mb_type[0]   = v->mb_type_base + s->b8_stride + 1;\n\n    v->mb_type[1]   = v->mb_type_base + s->b8_stride * (mb_height * 2 + 1) + s->mb_stride + 1;\n\n    v->mb_type[2]   = v->mb_type[1] + s->mb_stride * (mb_height + 1);\n\n\n\n    /* allocate memory to store block level MV info */\n\n    v->blk_mv_type_base = av_mallocz(     s->b8_stride * (mb_height * 2 + 1) + s->mb_stride * (mb_height + 1) * 2);\n\n    v->blk_mv_type      = v->blk_mv_type_base + s->b8_stride + 1;\n\n    v->mv_f_base        = av_mallocz(2 * (s->b8_stride * (mb_height * 2 + 1) + s->mb_stride * (mb_height + 1) * 2));\n\n    v->mv_f[0]          = v->mv_f_base + s->b8_stride + 1;\n\n    v->mv_f[1]          = v->mv_f[0] + (s->b8_stride * (mb_height * 2 + 1) + s->mb_stride * (mb_height + 1) * 2);\n\n    v->mv_f_next_base   = av_mallocz(2 * (s->b8_stride * (mb_height * 2 + 1) + s->mb_stride * (mb_height + 1) * 2));\n\n    v->mv_f_next[0]     = v->mv_f_next_base + s->b8_stride + 1;\n\n    v->mv_f_next[1]     = v->mv_f_next[0] + (s->b8_stride * (mb_height * 2 + 1) + s->mb_stride * (mb_height + 1) * 2);\n\n\n\n    ff_intrax8_common_init(&v->x8,s);\n\n\n\n    if (s->avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || s->avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n\n        for (i = 0; i < 4; i++)\n\n            if (!(v->sr_rows[i >> 1][i & 1] = av_malloc(v->output_width))) return -1;\n\n    }\n\n\n\n    if (!v->mv_type_mb_plane || !v->direct_mb_plane || !v->acpred_plane || !v->over_flags_plane ||\n\n        !v->block || !v->cbp_base || !v->ttblk_base || !v->is_intra_base || !v->luma_mv_base ||\n\n        !v->mb_type_base) {\n\n        goto error;\n\n    }\n\n\n\n    return 0;\n\n\n\nerror:\n\n    ff_vc1_decode_end(s->avctx);\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 25790}
{"project": "FFmpeg", "commit_id": "efd6b80b402a54923f007378a7dc5397676a8f3a", "target": 1, "func": "int ff_raw_read_partial_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    int ret, size;\n\n\n\n    size = RAW_PACKET_SIZE;\n\n\n\n    if (av_new_packet(pkt, size) < 0)\n\n        return AVERROR(ENOMEM);\n\n\n\n    pkt->pos= avio_tell(s->pb);\n\n    pkt->stream_index = 0;\n\n    ret = ffio_read_partial(s->pb, pkt->data, size);\n\n    if (ret < 0) {\n\n        av_free_packet(pkt);\n\n        return ret;\n\n    }\n\n    pkt->size = ret;\n\n    return ret;\n\n}\n", "idx": 25793}
{"project": "FFmpeg", "commit_id": "b6ee25e300420a3c98b78a1c2e983250ff065038", "target": 1, "func": "static inline struct rgbvec interp_tetrahedral(const LUT3DContext *lut3d,\n\n                                               const struct rgbvec *s)\n\n{\n\n    const struct rgbvec d = {s->r - PREV(s->r), s->g - PREV(s->g), s->b - PREV(s->b)};\n\n    const struct rgbvec c000 = lut3d->lut[PREV(s->r)][PREV(s->g)][PREV(s->b)];\n\n    const struct rgbvec c001 = lut3d->lut[PREV(s->r)][PREV(s->g)][NEXT(s->b)];\n\n    const struct rgbvec c010 = lut3d->lut[PREV(s->r)][NEXT(s->g)][PREV(s->b)];\n\n    const struct rgbvec c011 = lut3d->lut[PREV(s->r)][NEXT(s->g)][NEXT(s->b)];\n\n    const struct rgbvec c100 = lut3d->lut[NEXT(s->r)][PREV(s->g)][PREV(s->b)];\n\n    const struct rgbvec c101 = lut3d->lut[NEXT(s->r)][PREV(s->g)][NEXT(s->b)];\n\n    const struct rgbvec c110 = lut3d->lut[NEXT(s->r)][NEXT(s->g)][PREV(s->b)];\n\n    const struct rgbvec c111 = lut3d->lut[NEXT(s->r)][NEXT(s->g)][NEXT(s->b)];\n\n    struct rgbvec c;\n\n    if (d.r > d.g) {\n\n        if (d.g > d.b) {\n\n            c.r = (1-d.r) * c000.r + (d.r-d.g) * c100.r + (d.g-d.b) * c110.r + (d.b) * c111.r;\n\n            c.g = (1-d.r) * c000.g + (d.r-d.g) * c100.g + (d.g-d.b) * c110.g + (d.b) * c111.g;\n\n            c.b = (1-d.r) * c000.b + (d.r-d.g) * c100.b + (d.g-d.b) * c110.b + (d.b) * c111.b;\n\n        } else if (d.r > d.b) {\n\n            c.r = (1-d.r) * c000.r + (d.r-d.b) * c100.r + (d.b-d.g) * c101.r + (d.g) * c111.r;\n\n            c.g = (1-d.r) * c000.g + (d.r-d.b) * c100.g + (d.b-d.g) * c101.g + (d.g) * c111.g;\n\n            c.b = (1-d.r) * c000.b + (d.r-d.b) * c100.b + (d.b-d.g) * c101.b + (d.g) * c111.b;\n\n        } else {\n\n            c.r = (1-d.b) * c000.r + (d.b-d.r) * c001.r + (d.r-d.g) * c101.r + (d.g) * c111.r;\n\n            c.g = (1-d.b) * c000.g + (d.b-d.r) * c001.g + (d.r-d.g) * c101.g + (d.g) * c111.g;\n\n            c.b = (1-d.b) * c000.b + (d.b-d.r) * c001.b + (d.r-d.g) * c101.b + (d.g) * c111.b;\n\n        }\n\n    } else {\n\n        if (d.b > d.g) {\n\n            c.r = (1-d.b) * c000.r + (d.b-d.g) * c001.r + (d.g-d.r) * c011.r + (d.r) * c111.r;\n\n            c.g = (1-d.b) * c000.g + (d.b-d.g) * c001.g + (d.g-d.r) * c011.g + (d.r) * c111.g;\n\n            c.b = (1-d.b) * c000.b + (d.b-d.g) * c001.b + (d.g-d.r) * c011.b + (d.r) * c111.b;\n\n        } else if (d.b > d.r) {\n\n            c.r = (1-d.g) * c000.r + (d.g-d.b) * c010.r + (d.b-d.r) * c011.r + (d.r) * c111.r;\n\n            c.g = (1-d.g) * c000.g + (d.g-d.b) * c010.g + (d.b-d.r) * c011.g + (d.r) * c111.g;\n\n            c.b = (1-d.g) * c000.b + (d.g-d.b) * c010.b + (d.b-d.r) * c011.b + (d.r) * c111.b;\n\n        } else {\n\n            c.r = (1-d.g) * c000.r + (d.g-d.r) * c010.r + (d.r-d.b) * c110.r + (d.b) * c111.r;\n\n            c.g = (1-d.g) * c000.g + (d.g-d.r) * c010.g + (d.r-d.b) * c110.g + (d.b) * c111.g;\n\n            c.b = (1-d.g) * c000.b + (d.g-d.r) * c010.b + (d.r-d.b) * c110.b + (d.b) * c111.b;\n\n        }\n\n    }\n\n    return c;\n\n}\n", "idx": 25794}
{"project": "FFmpeg", "commit_id": "0d021cc8b30a6f81c27fbeca7f99f1ee7a20acf8", "target": 0, "func": "static av_cold int nvenc_setup_device(AVCodecContext *avctx)\n\n{\n\n    NvencContext *ctx = avctx->priv_data;\n\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n\n\n\n    CUresult cu_res;\n\n    CUcontext cu_context_curr;\n\n\n\n    switch (avctx->codec->id) {\n\n    case AV_CODEC_ID_H264:\n\n        ctx->init_encode_params.encodeGUID = NV_ENC_CODEC_H264_GUID;\n\n        break;\n\n    case AV_CODEC_ID_HEVC:\n\n        ctx->init_encode_params.encodeGUID = NV_ENC_CODEC_HEVC_GUID;\n\n        break;\n\n    default:\n\n        return AVERROR_BUG;\n\n    }\n\n\n\n    ctx->data_pix_fmt = avctx->pix_fmt;\n\n\n\n#if CONFIG_CUDA\n\n    if (avctx->pix_fmt == AV_PIX_FMT_CUDA) {\n\n        AVHWFramesContext *frames_ctx;\n\n        AVCUDADeviceContext *device_hwctx;\n\n\n\n        if (!avctx->hw_frames_ctx) {\n\n            av_log(avctx, AV_LOG_ERROR, \"hw_frames_ctx must be set when using GPU frames as input\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n\n\n        frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n\n        device_hwctx = frames_ctx->device_ctx->hwctx;\n\n        ctx->cu_context = device_hwctx->cuda_ctx;\n\n        ctx->data_pix_fmt = frames_ctx->sw_format;\n\n        return 0;\n\n    }\n\n#endif\n\n\n\n    if (ctx->gpu >= dl_fn->nvenc_device_count) {\n\n        av_log(avctx, AV_LOG_FATAL, \"Requested GPU %d, but only %d GPUs are available!\\n\", ctx->gpu, dl_fn->nvenc_device_count);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    ctx->cu_context = NULL;\n\n    cu_res = dl_fn->cu_ctx_create(&ctx->cu_context_internal, 4, dl_fn->nvenc_devices[ctx->gpu]); // CU_CTX_SCHED_BLOCKING_SYNC=4, avoid CPU spins\n\n\n\n    if (cu_res != CUDA_SUCCESS) {\n\n        av_log(avctx, AV_LOG_FATAL, \"Failed creating CUDA context for NVENC: 0x%x\\n\", (int)cu_res);\n\n        return AVERROR_EXTERNAL;\n\n    }\n\n\n\n    cu_res = dl_fn->cu_ctx_pop_current(&cu_context_curr);\n\n\n\n    if (cu_res != CUDA_SUCCESS) {\n\n        av_log(avctx, AV_LOG_FATAL, \"Failed popping CUDA context: 0x%x\\n\", (int)cu_res);\n\n        return AVERROR_EXTERNAL;\n\n    }\n\n\n\n    ctx->cu_context = ctx->cu_context_internal;\n\n\n\n    return 0;\n\n}\n", "idx": 25795}
{"project": "FFmpeg", "commit_id": "ca488ad480360dfafcb5766f7bfbb567a0638979", "target": 1, "func": "static int read_channel_data(ALSDecContext *ctx, ALSChannelData *cd, int c)\n\n{\n\n    GetBitContext *gb       = &ctx->gb;\n\n    ALSChannelData *current = cd;\n\n    unsigned int channels   = ctx->avctx->channels;\n\n    int entries             = 0;\n\n\n\n    while (entries < channels && !(current->stop_flag = get_bits1(gb))) {\n\n        current->master_channel = get_bits_long(gb, av_ceil_log2(channels));\n\n\n\n        if (current->master_channel >= channels) {\n\n            av_log(ctx->avctx, AV_LOG_ERROR, \"Invalid master channel!\\n\");\n\n            return -1;\n\n        }\n\n\n\n        if (current->master_channel != c) {\n\n            current->time_diff_flag = get_bits1(gb);\n\n            current->weighting[0]   = als_weighting(gb, 1, 16);\n\n            current->weighting[1]   = als_weighting(gb, 2, 14);\n\n            current->weighting[2]   = als_weighting(gb, 1, 16);\n\n\n\n            if (current->time_diff_flag) {\n\n                current->weighting[3] = als_weighting(gb, 1, 16);\n\n                current->weighting[4] = als_weighting(gb, 1, 16);\n\n                current->weighting[5] = als_weighting(gb, 1, 16);\n\n\n\n                current->time_diff_sign  = get_bits1(gb);\n\n                current->time_diff_index = get_bits(gb, ctx->ltp_lag_length - 3) + 3;\n\n            }\n\n        }\n\n\n\n        current++;\n\n        entries++;\n\n    }\n\n\n\n    if (entries == channels) {\n\n        av_log(ctx->avctx, AV_LOG_ERROR, \"Damaged channel data!\\n\");\n\n        return -1;\n\n    }\n\n\n\n    align_get_bits(gb);\n\n    return 0;\n\n}\n", "idx": 25796}
{"project": "FFmpeg", "commit_id": "ea1e630c47e70672a7933c048090601ce09c8195", "target": 1, "func": "static int rv34_decoder_alloc(RV34DecContext *r)\n\n{\n\n    r->intra_types_stride = r->s.mb_width * 4 + 4;\n\n\n\n    r->cbp_chroma       = av_malloc(r->s.mb_stride * r->s.mb_height *\n\n                                    sizeof(*r->cbp_chroma));\n\n    r->cbp_luma         = av_malloc(r->s.mb_stride * r->s.mb_height *\n\n                                    sizeof(*r->cbp_luma));\n\n    r->deblock_coefs    = av_malloc(r->s.mb_stride * r->s.mb_height *\n\n                                    sizeof(*r->deblock_coefs));\n\n    r->intra_types_hist = av_malloc(r->intra_types_stride * 4 * 2 *\n\n                                    sizeof(*r->intra_types_hist));\n\n    r->mb_type          = av_mallocz(r->s.mb_stride * r->s.mb_height *\n\n                                     sizeof(*r->mb_type));\n\n\n\n    if (!(r->cbp_chroma       && r->cbp_luma && r->deblock_coefs &&\n\n          r->intra_types_hist && r->mb_type)) {\n\n        rv34_decoder_free(r);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    r->intra_types = r->intra_types_hist + r->intra_types_stride * 4;\n\n\n\n    return 0;\n\n}\n", "idx": 25798}
{"project": "FFmpeg", "commit_id": "de41d5372faa4ad7ad439e71975fc6f4ea0c0efc", "target": 1, "func": "static int dvbsub_parse(AVCodecParserContext *s,\n\n                        AVCodecContext *avctx,\n\n                        const uint8_t **poutbuf, int *poutbuf_size,\n\n                        const uint8_t *buf, int buf_size)\n\n{\n\n    DVBSubParseContext *pc = s->priv_data;\n\n    uint8_t *p, *p_end;\n\n    int i, len, buf_pos = 0;\n\n\n\n    av_dlog(avctx, \"DVB parse packet pts=%\"PRIx64\", lpts=%\"PRIx64\", cpts=%\"PRIx64\":\\n\",\n\n            s->pts, s->last_pts, s->cur_frame_pts[s->cur_frame_start_index]);\n\n\n\n    for (i=0; i < buf_size; i++)\n\n    {\n\n        av_dlog(avctx, \"%02x \", buf[i]);\n\n        if (i % 16 == 15)\n\n            av_dlog(avctx, \"\\n\");\n\n    }\n\n\n\n    if (i % 16 != 0)\n\n        av_dlog(avctx, \"\\n\");\n\n\n\n    *poutbuf = NULL;\n\n    *poutbuf_size = 0;\n\n\n\n    s->fetch_timestamp = 1;\n\n\n\n    if (s->last_pts != s->pts && s->pts != AV_NOPTS_VALUE) /* Start of a new packet */\n\n    {\n\n        if (pc->packet_index != pc->packet_start)\n\n        {\n\n            av_dlog(avctx, \"Discarding %d bytes\\n\",\n\n                    pc->packet_index - pc->packet_start);\n\n        }\n\n\n\n        pc->packet_start = 0;\n\n        pc->packet_index = 0;\n\n\n\n        if (buf_size < 2 || buf[0] != 0x20 || buf[1] != 0x00) {\n\n            av_dlog(avctx, \"Bad packet header\\n\");\n\n            return -1;\n\n        }\n\n\n\n        buf_pos = 2;\n\n\n\n        pc->in_packet = 1;\n\n    } else {\n\n        if (pc->packet_start != 0)\n\n        {\n\n            if (pc->packet_index != pc->packet_start)\n\n            {\n\n                memmove(pc->packet_buf, pc->packet_buf + pc->packet_start,\n\n                            pc->packet_index - pc->packet_start);\n\n\n\n                pc->packet_index -= pc->packet_start;\n\n                pc->packet_start = 0;\n\n            } else {\n\n                pc->packet_start = 0;\n\n                pc->packet_index = 0;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (buf_size - buf_pos + pc->packet_index > PARSE_BUF_SIZE)\n\n        return -1;\n\n\n\n/* if not currently in a packet, discard data */\n\n    if (pc->in_packet == 0)\n\n        return buf_size;\n\n\n\n    memcpy(pc->packet_buf + pc->packet_index, buf + buf_pos, buf_size - buf_pos);\n\n    pc->packet_index += buf_size - buf_pos;\n\n\n\n    p = pc->packet_buf;\n\n    p_end = pc->packet_buf + pc->packet_index;\n\n\n\n    while (p < p_end)\n\n    {\n\n        if (*p == 0x0f)\n\n        {\n\n            if (p + 6 <= p_end)\n\n            {\n\n                len = AV_RB16(p + 4);\n\n\n\n                if (p + len + 6 <= p_end)\n\n                {\n\n                    *poutbuf_size += len + 6;\n\n\n\n                    p += len + 6;\n\n                } else\n\n                    break;\n\n            } else\n\n                break;\n\n        } else if (*p == 0xff) {\n\n            if (p + 1 < p_end)\n\n            {\n\n                av_dlog(avctx, \"Junk at end of packet\\n\");\n\n            }\n\n            pc->packet_index = p - pc->packet_buf;\n\n            pc->in_packet = 0;\n\n            break;\n\n        } else {\n\n            av_log(avctx, AV_LOG_ERROR, \"Junk in packet\\n\");\n\n\n\n            pc->packet_index = p - pc->packet_buf;\n\n            pc->in_packet = 0;\n\n            break;\n\n        }\n\n    }\n\n\n\n    if (*poutbuf_size > 0)\n\n    {\n\n        *poutbuf = pc->packet_buf;\n\n        pc->packet_start = *poutbuf_size;\n\n    }\n\n\n\n    if (s->pts == AV_NOPTS_VALUE)\n\n        s->pts = s->last_pts;\n\n\n\n    return buf_size;\n\n}\n", "idx": 25799}
{"project": "FFmpeg", "commit_id": "0e0f6bd4a5796f4f668092d7925a31b9b30fedd4", "target": 1, "func": "static void id3v2_parse(AVFormatContext *s, int len, uint8_t version,\n\n                        uint8_t flags, ID3v2ExtraMeta **extra_meta)\n\n{\n\n    int isv34, unsync;\n\n    unsigned tlen;\n\n    char tag[5];\n\n    int64_t next, end = avio_tell(s->pb) + len;\n\n    int taghdrlen;\n\n    const char *reason = NULL;\n\n    AVIOContext pb;\n\n    AVIOContext *pbx;\n\n    unsigned char *buffer = NULL;\n\n    int buffer_size       = 0;\n\n    const ID3v2EMFunc *extra_func = NULL;\n\n    unsigned char *uncompressed_buffer = NULL;\n\n    int uncompressed_buffer_size = 0;\n\n\n\n    av_log(s, AV_LOG_DEBUG, \"id3v2 ver:%d flags:%02X len:%d\\n\", version, flags, len);\n\n\n\n    switch (version) {\n\n    case 2:\n\n        if (flags & 0x40) {\n\n            reason = \"compression\";\n\n            goto error;\n\n        }\n\n        isv34     = 0;\n\n        taghdrlen = 6;\n\n        break;\n\n\n\n    case 3:\n\n    case 4:\n\n        isv34     = 1;\n\n        taghdrlen = 10;\n\n        break;\n\n\n\n    default:\n\n        reason = \"version\";\n\n        goto error;\n\n    }\n\n\n\n    unsync = flags & 0x80;\n\n\n\n    if (isv34 && flags & 0x40) { /* Extended header present, just skip over it */\n\n        int extlen = get_size(s->pb, 4);\n\n        if (version == 4)\n\n            /* In v2.4 the length includes the length field we just read. */\n\n            extlen -= 4;\n\n\n\n        if (extlen < 0) {\n\n            reason = \"invalid extended header length\";\n\n            goto error;\n\n        }\n\n        avio_skip(s->pb, extlen);\n\n        len -= extlen + 4;\n\n        if (len < 0) {\n\n            reason = \"extended header too long.\";\n\n            goto error;\n\n        }\n\n    }\n\n\n\n    while (len >= taghdrlen) {\n\n        unsigned int tflags = 0;\n\n        int tunsync         = 0;\n\n        int tcomp           = 0;\n\n        int tencr           = 0;\n\n        unsigned long dlen;\n\n\n\n        if (isv34) {\n\n            avio_read(s->pb, tag, 4);\n\n            tag[4] = 0;\n\n            if (version == 3) {\n\n                tlen = avio_rb32(s->pb);\n\n            } else\n\n                tlen = get_size(s->pb, 4);\n\n            tflags  = avio_rb16(s->pb);\n\n            tunsync = tflags & ID3v2_FLAG_UNSYNCH;\n\n        } else {\n\n            avio_read(s->pb, tag, 3);\n\n            tag[3] = 0;\n\n            tlen   = avio_rb24(s->pb);\n\n        }\n\n        if (tlen > (1<<28))\n\n            break;\n\n        len -= taghdrlen + tlen;\n\n\n\n        if (len < 0)\n\n            break;\n\n\n\n        next = avio_tell(s->pb) + tlen;\n\n\n\n        if (!tlen) {\n\n            if (tag[0])\n\n                av_log(s, AV_LOG_DEBUG, \"Invalid empty frame %s, skipping.\\n\",\n\n                       tag);\n\n            continue;\n\n        }\n\n\n\n        if (tflags & ID3v2_FLAG_DATALEN) {\n\n            if (tlen < 4)\n\n                break;\n\n            dlen = avio_rb32(s->pb);\n\n            tlen -= 4;\n\n        } else\n\n            dlen = tlen;\n\n\n\n        tcomp = tflags & ID3v2_FLAG_COMPRESSION;\n\n        tencr = tflags & ID3v2_FLAG_ENCRYPTION;\n\n\n\n        /* skip encrypted tags and, if no zlib, compressed tags */\n\n        if (tencr || (!CONFIG_ZLIB && tcomp)) {\n\n            const char *type;\n\n            if (!tcomp)\n\n                type = \"encrypted\";\n\n            else if (!tencr)\n\n                type = \"compressed\";\n\n            else\n\n                type = \"encrypted and compressed\";\n\n\n\n            av_log(s, AV_LOG_WARNING, \"Skipping %s ID3v2 frame %s.\\n\", type, tag);\n\n            avio_skip(s->pb, tlen);\n\n        /* check for text tag or supported special meta tag */\n\n        } else if (tag[0] == 'T' ||\n\n                   (extra_meta &&\n\n                    (extra_func = get_extra_meta_func(tag, isv34)))) {\n\n            pbx = s->pb;\n\n\n\n            if (unsync || tunsync || tcomp) {\n\n                av_fast_malloc(&buffer, &buffer_size, tlen);\n\n                if (!buffer) {\n\n                    av_log(s, AV_LOG_ERROR, \"Failed to alloc %d bytes\\n\", tlen);\n\n                    goto seek;\n\n                }\n\n            }\n\n            if (unsync || tunsync) {\n\n                int64_t end = avio_tell(s->pb) + tlen;\n\n                uint8_t *b;\n\n\n\n                b = buffer;\n\n                while (avio_tell(s->pb) < end && b - buffer < tlen && !s->pb->eof_reached) {\n\n                    *b++ = avio_r8(s->pb);\n\n                    if (*(b - 1) == 0xff && avio_tell(s->pb) < end - 1 &&\n\n                        b - buffer < tlen &&\n\n                        !s->pb->eof_reached ) {\n\n                        uint8_t val = avio_r8(s->pb);\n\n                        *b++ = val ? val : avio_r8(s->pb);\n\n                    }\n\n                }\n\n                ffio_init_context(&pb, buffer, b - buffer, 0, NULL, NULL, NULL,\n\n                                  NULL);\n\n                tlen = b - buffer;\n\n                pbx  = &pb; // read from sync buffer\n\n            }\n\n\n\n#if CONFIG_ZLIB\n\n                if (tcomp) {\n\n                    int err;\n\n\n\n                    av_log(s, AV_LOG_DEBUG, \"Compresssed frame %s tlen=%d dlen=%ld\\n\", tag, tlen, dlen);\n\n\n\n                    av_fast_malloc(&uncompressed_buffer, &uncompressed_buffer_size, dlen);\n\n                    if (!uncompressed_buffer) {\n\n                        av_log(s, AV_LOG_ERROR, \"Failed to alloc %ld bytes\\n\", dlen);\n\n                        goto seek;\n\n                    }\n\n\n\n                    if (!(unsync || tunsync)) {\n\n                        err = avio_read(s->pb, buffer, tlen);\n\n                        if (err < 0) {\n\n                            av_log(s, AV_LOG_ERROR, \"Failed to read compressed tag\\n\");\n\n                            goto seek;\n\n                        }\n\n                        tlen = err;\n\n                    }\n\n\n\n                    err = uncompress(uncompressed_buffer, &dlen, buffer, tlen);\n\n                    if (err != Z_OK) {\n\n                        av_log(s, AV_LOG_ERROR, \"Failed to uncompress tag: %d\\n\", err);\n\n                        goto seek;\n\n                    }\n\n                    ffio_init_context(&pb, uncompressed_buffer, dlen, 0, NULL, NULL, NULL, NULL);\n\n                    tlen = dlen;\n\n                    pbx = &pb; // read from sync buffer\n\n                }\n\n#endif\n\n            if (tag[0] == 'T')\n\n                /* parse text tag */\n\n                read_ttag(s, pbx, tlen, &s->metadata, tag);\n\n            else\n\n                /* parse special meta tag */\n\n                extra_func->read(s, pbx, tlen, tag, extra_meta);\n\n        } else if (!tag[0]) {\n\n            if (tag[1])\n\n                av_log(s, AV_LOG_WARNING, \"invalid frame id, assuming padding\\n\");\n\n            avio_skip(s->pb, tlen);\n\n            break;\n\n        }\n\n        /* Skip to end of tag */\n\nseek:\n\n        avio_seek(s->pb, next, SEEK_SET);\n\n    }\n\n\n\n    /* Footer preset, always 10 bytes, skip over it */\n\n    if (version == 4 && flags & 0x10)\n\n        end += 10;\n\n\n\nerror:\n\n    if (reason)\n\n        av_log(s, AV_LOG_INFO, \"ID3v2.%d tag skipped, cannot handle %s\\n\",\n\n               version, reason);\n\n    avio_seek(s->pb, end, SEEK_SET);\n\n    av_free(buffer);\n\n    av_free(uncompressed_buffer);\n\n    return;\n\n}\n", "idx": 25800}
{"project": "FFmpeg", "commit_id": "f23dc1e1f9ee3a00db951d3dec7d5bfb0e04dae8", "target": 1, "func": "static void decode_band_structure(GetBitContext *gbc, int blk, int eac3,\n\n                                  int ecpl, int start_subband, int end_subband,\n\n                                  const uint8_t *default_band_struct,\n\n                                  uint8_t *band_struct, int *num_subbands,\n\n                                  int *num_bands, uint8_t *band_sizes)\n\n{\n\n    int subbnd, bnd, n_subbands, n_bands;\n\n    uint8_t bnd_sz[22];\n\n\n\n    n_subbands = end_subband - start_subband;\n\n\n\n    /* decode band structure from bitstream or use default */\n\n    if (!eac3 || get_bits1(gbc)) {\n\n        for (subbnd = 0; subbnd < n_subbands - 1; subbnd++) {\n\n            band_struct[subbnd] = get_bits1(gbc);\n\n        }\n\n    } else if (!blk) {\n\n        memcpy(band_struct,\n\n               &default_band_struct[start_subband+1],\n\n               n_subbands-1);\n\n    }\n\n    band_struct[n_subbands-1] = 0;\n\n\n\n    /* calculate number of bands and band sizes based on band structure.\n\n       note that the first 4 subbands in enhanced coupling span only 6 bins\n\n       instead of 12. */\n\n    if (num_bands || band_sizes ) {\n\n        n_bands = n_subbands;\n\n        bnd_sz[0] = ecpl ? 6 : 12;\n\n        for (bnd = 0, subbnd = 1; subbnd < n_subbands; subbnd++) {\n\n            int subbnd_size = (ecpl && subbnd < 4) ? 6 : 12;\n\n            if (band_struct[subbnd-1]) {\n\n                n_bands--;\n\n                bnd_sz[bnd] += subbnd_size;\n\n            } else {\n\n                bnd_sz[++bnd] = subbnd_size;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* set optional output params */\n\n    if (num_subbands)\n\n        *num_subbands = n_subbands;\n\n    if (num_bands)\n\n        *num_bands = n_bands;\n\n    if (band_sizes)\n\n        memcpy(band_sizes, bnd_sz, n_bands);\n\n}\n", "idx": 25801}
{"project": "FFmpeg", "commit_id": "8ab80707841a73ca7708e1e1aa97f3513fff3d35", "target": 0, "func": "int attribute_align_arg avcodec_encode_audio2(AVCodecContext *avctx,\n\n                                              AVPacket *avpkt,\n\n                                              const AVFrame *frame,\n\n                                              int *got_packet_ptr)\n\n{\n\n    AVFrame tmp;\n\n    AVFrame *padded_frame = NULL;\n\n    int ret;\n\n    AVPacket user_pkt = *avpkt;\n\n    int needs_realloc = !user_pkt.data;\n\n\n\n    *got_packet_ptr = 0;\n\n\n\n    if (!(avctx->codec->capabilities & CODEC_CAP_DELAY) && !frame) {\n\n        av_free_packet(avpkt);\n\n        av_init_packet(avpkt);\n\n        return 0;\n\n    }\n\n\n\n    /* ensure that extended_data is properly set */\n\n    if (frame && !frame->extended_data) {\n\n        if (av_sample_fmt_is_planar(avctx->sample_fmt) &&\n\n            avctx->channels > AV_NUM_DATA_POINTERS) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Encoding to a planar sample format, \"\n\n                                        \"with more than %d channels, but extended_data is not set.\\n\",\n\n                   AV_NUM_DATA_POINTERS);\n\n            return AVERROR(EINVAL);\n\n        }\n\n        av_log(avctx, AV_LOG_WARNING, \"extended_data is not set.\\n\");\n\n\n\n        tmp = *frame;\n\n        tmp.extended_data = tmp.data;\n\n        frame = &tmp;\n\n    }\n\n\n\n    /* check for valid frame size */\n\n    if (frame) {\n\n        if (avctx->codec->capabilities & CODEC_CAP_SMALL_LAST_FRAME) {\n\n            if (frame->nb_samples > avctx->frame_size) {\n\n                av_log(avctx, AV_LOG_ERROR, \"more samples than frame size (avcodec_encode_audio2)\\n\");\n\n                return AVERROR(EINVAL);\n\n            }\n\n        } else if (!(avctx->codec->capabilities & CODEC_CAP_VARIABLE_FRAME_SIZE)) {\n\n            if (frame->nb_samples < avctx->frame_size &&\n\n                !avctx->internal->last_audio_frame) {\n\n                ret = pad_last_frame(avctx, &padded_frame, frame);\n\n                if (ret < 0)\n\n                    return ret;\n\n\n\n                frame = padded_frame;\n\n                avctx->internal->last_audio_frame = 1;\n\n            }\n\n\n\n            if (frame->nb_samples != avctx->frame_size) {\n\n                av_log(avctx, AV_LOG_ERROR, \"nb_samples (%d) != frame_size (%d) (avcodec_encode_audio2)\\n\", frame->nb_samples, avctx->frame_size);\n\n                ret = AVERROR(EINVAL);\n\n                goto end;\n\n            }\n\n        }\n\n    }\n\n\n\n    ret = avctx->codec->encode2(avctx, avpkt, frame, got_packet_ptr);\n\n    if (!ret) {\n\n        if (*got_packet_ptr) {\n\n            if (!(avctx->codec->capabilities & CODEC_CAP_DELAY)) {\n\n                if (avpkt->pts == AV_NOPTS_VALUE)\n\n                    avpkt->pts = frame->pts;\n\n                if (!avpkt->duration)\n\n                    avpkt->duration = ff_samples_to_time_base(avctx,\n\n                                                              frame->nb_samples);\n\n            }\n\n            avpkt->dts = avpkt->pts;\n\n        } else {\n\n            avpkt->size = 0;\n\n        }\n\n    }\n\n    if (avpkt->data && avpkt->data == avctx->internal->byte_buffer) {\n\n        needs_realloc = 0;\n\n        if (user_pkt.data) {\n\n            if (user_pkt.size >= avpkt->size) {\n\n                memcpy(user_pkt.data, avpkt->data, avpkt->size);\n\n            } else {\n\n                av_log(avctx, AV_LOG_ERROR, \"Provided packet is too small, needs to be %d\\n\", avpkt->size);\n\n                avpkt->size = user_pkt.size;\n\n                ret = -1;\n\n            }\n\n            avpkt->buf      = user_pkt.buf;\n\n            avpkt->data     = user_pkt.data;\n\n            avpkt->destruct = user_pkt.destruct;\n\n        } else {\n\n            if (av_dup_packet(avpkt) < 0) {\n\n                ret = AVERROR(ENOMEM);\n\n            }\n\n        }\n\n    }\n\n\n\n    if (!ret) {\n\n        if (needs_realloc && avpkt->data) {\n\n            ret = av_buffer_realloc(&avpkt->buf, avpkt->size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (ret >= 0)\n\n                avpkt->data = avpkt->buf->data;\n\n        }\n\n\n\n        avctx->frame_number++;\n\n    }\n\n\n\n    if (ret < 0 || !*got_packet_ptr) {\n\n        av_free_packet(avpkt);\n\n        av_init_packet(avpkt);\n\n        goto end;\n\n    }\n\n\n\n    /* NOTE: if we add any audio encoders which output non-keyframe packets,\n\n     *       this needs to be moved to the encoders, but for now we can do it\n\n     *       here to simplify things */\n\n    avpkt->flags |= AV_PKT_FLAG_KEY;\n\n\n\nend:\n\n    av_frame_free(&padded_frame);\n\n\n\n    return ret;\n\n}\n", "idx": 25807}
{"project": "FFmpeg", "commit_id": "247e658784ead984f96021acb9c95052ba599f26", "target": 0, "func": "static int ftp_get_line(FTPContext *s, char *line, int line_size)\n\n{\n\n    int ch;\n\n    char *q = line;\n\n    int ori_block_flag = s->conn_control_block_flag;\n\n\n\n    for (;;) {\n\n        ch = ftp_getc(s);\n\n        if (ch < 0) {\n\n            s->conn_control_block_flag = ori_block_flag;\n\n            return ch;\n\n        }\n\n        if (ch == '\\n') {\n\n            /* process line */\n\n            if (q > line && q[-1] == '\\r')\n\n                q--;\n\n            *q = '\\0';\n\n\n\n            s->conn_control_block_flag = ori_block_flag;\n\n            return 0;\n\n        } else {\n\n            s->conn_control_block_flag = 0; /* line need to be finished */\n\n            if ((q - line) < line_size - 1)\n\n                *q++ = ch;\n\n        }\n\n    }\n\n}\n", "idx": 25818}
{"project": "FFmpeg", "commit_id": "5b67307a6898d9b1b1b78034d4f4fa79932d91bf", "target": 1, "func": "int avcodec_default_get_buffer(AVCodecContext *s, AVFrame *pic){\n    int i;\n    int w= s->width;\n    int h= s->height;\n    InternalBuffer *buf;\n    int *picture_number;\n    if(pic->data[0]!=NULL) {\n        av_log(s, AV_LOG_ERROR, \"pic->data[0]!=NULL in avcodec_default_get_buffer\\n\");\n        return -1;\n    }\n    if(s->internal_buffer_count >= INTERNAL_BUFFER_SIZE) {\n        av_log(s, AV_LOG_ERROR, \"internal_buffer_count overflow (missing release_buffer?)\\n\");\n        return -1;\n    }\n    if(avcodec_check_dimensions(s,w,h))\n        return -1;\n    if(s->internal_buffer==NULL){\n        s->internal_buffer= av_mallocz(INTERNAL_BUFFER_SIZE*sizeof(InternalBuffer));\n    }\n#if 0\n    s->internal_buffer= av_fast_realloc(\n        s->internal_buffer,\n        &s->internal_buffer_size,\n        sizeof(InternalBuffer)*FFMAX(99,  s->internal_buffer_count+1)/*FIXME*/\n        );\n#endif\n    buf= &((InternalBuffer*)s->internal_buffer)[s->internal_buffer_count];\n    picture_number= &(((InternalBuffer*)s->internal_buffer)[INTERNAL_BUFFER_SIZE-1]).last_pic_num; //FIXME ugly hack\n    (*picture_number)++;\n    if(buf->base[0]){\n        pic->age= *picture_number - buf->last_pic_num;\n        buf->last_pic_num= *picture_number;\n    }else{\n        int h_chroma_shift, v_chroma_shift;\n        int pixel_size, size[3];\n        AVPicture picture;\n        avcodec_get_chroma_sub_sample(s->pix_fmt, &h_chroma_shift, &v_chroma_shift);\n        if(!(s->flags&CODEC_FLAG_EMU_EDGE)){\n            w+= EDGE_WIDTH*2;\n            h+= EDGE_WIDTH*2;\n        }\n        avpicture_fill(&picture, NULL, s->pix_fmt, w, h);\n        pixel_size= picture.linesize[0]*8 / w;\n//av_log(NULL, AV_LOG_ERROR, \"%d %d %d %d\\n\", (int)picture.data[1], w, h, s->pix_fmt);\n        assert(pixel_size>=1);\n            //FIXME next ensures that linesize= 2^x uvlinesize, thats needed because some MC code assumes it\n        if(pixel_size == 3*8)\n            w= ALIGN(w, STRIDE_ALIGN<<h_chroma_shift);\n        else\n            w= ALIGN(pixel_size*w, STRIDE_ALIGN<<(h_chroma_shift+3)) / pixel_size;\n        size[1] = avpicture_fill(&picture, NULL, s->pix_fmt, w, h);\n        size[0] = picture.linesize[0] * h;\n        size[1] -= size[0];\n        if(picture.data[2])\n            size[1]= size[2]= size[1]/2;\n        else\n            size[2]= 0;\n        buf->last_pic_num= -256*256*256*64;\n        memset(buf->base, 0, sizeof(buf->base));\n        memset(buf->data, 0, sizeof(buf->data));\n        for(i=0; i<3 && size[i]; i++){\n            const int h_shift= i==0 ? 0 : h_chroma_shift;\n            const int v_shift= i==0 ? 0 : v_chroma_shift;\n            buf->linesize[i]= picture.linesize[i];\n            buf->base[i]= av_malloc(size[i]+16); //FIXME 16\n            if(buf->base[i]==NULL) return -1;\n            memset(buf->base[i], 128, size[i]);\n            // no edge if EDEG EMU or not planar YUV, we check for PAL8 redundantly to protect against a exploitable bug regression ...\n            if((s->flags&CODEC_FLAG_EMU_EDGE) || (s->pix_fmt == PIX_FMT_PAL8) || !size[2])\n                buf->data[i] = buf->base[i];\n            else\n                buf->data[i] = buf->base[i] + ALIGN((buf->linesize[i]*EDGE_WIDTH>>v_shift) + (EDGE_WIDTH>>h_shift), STRIDE_ALIGN);\n        }\n        pic->age= 256*256*256*64;\n    }\n    pic->type= FF_BUFFER_TYPE_INTERNAL;\n    for(i=0; i<4; i++){\n        pic->base[i]= buf->base[i];\n        pic->data[i]= buf->data[i];\n        pic->linesize[i]= buf->linesize[i];\n    }\n    s->internal_buffer_count++;\n    return 0;\n}", "idx": 25823}
{"project": "FFmpeg", "commit_id": "b7b1509d06d3696d3b944791227fe198ded0654b", "target": 1, "func": "static int tm2_build_huff_table(TM2Context *ctx, TM2Codes *code)\n\n{\n\n    TM2Huff huff;\n\n    int res = 0;\n\n\n\n    huff.val_bits = get_bits(&ctx->gb, 5);\n\n    huff.max_bits = get_bits(&ctx->gb, 5);\n\n    huff.min_bits = get_bits(&ctx->gb, 5);\n\n    huff.nodes = get_bits_long(&ctx->gb, 17);\n\n    huff.num = 0;\n\n\n\n    /* check for correct codes parameters */\n\n    if((huff.val_bits < 1) || (huff.val_bits > 32) ||\n\n       (huff.max_bits < 0) || (huff.max_bits > 32)) {\n\n        av_log(ctx->avctx, AV_LOG_ERROR, \"Incorrect tree parameters - literal length: %i, max code length: %i\\n\",\n\n               huff.val_bits, huff.max_bits);\n\n        return -1;\n\n    }\n\n    if((huff.nodes <= 0) || (huff.nodes > 0x10000)) {\n\n        av_log(ctx->avctx, AV_LOG_ERROR, \"Incorrect number of Huffman tree nodes: %i\\n\", huff.nodes);\n\n        return -1;\n\n    }\n\n    /* one-node tree */\n\n    if(huff.max_bits == 0)\n\n        huff.max_bits = 1;\n\n\n\n    /* allocate space for codes - it is exactly ceil(nodes / 2) entries */\n\n    huff.max_num = (huff.nodes + 1) >> 1;\n\n    huff.nums = av_mallocz(huff.max_num * sizeof(int));\n\n    huff.bits = av_mallocz(huff.max_num * sizeof(uint32_t));\n\n    huff.lens = av_mallocz(huff.max_num * sizeof(int));\n\n\n\n    if(tm2_read_tree(ctx, 0, 0, &huff) == -1)\n\n        res = -1;\n\n\n\n    if(huff.num != huff.max_num) {\n\n        av_log(ctx->avctx, AV_LOG_ERROR, \"Got less codes than expected: %i of %i\\n\",\n\n               huff.num, huff.max_num);\n\n        res = -1;\n\n    }\n\n\n\n    /* convert codes to vlc_table */\n\n    if(res != -1) {\n\n        int i;\n\n\n\n        res = init_vlc(&code->vlc, huff.max_bits, huff.max_num,\n\n                    huff.lens, sizeof(int), sizeof(int),\n\n                    huff.bits, sizeof(uint32_t), sizeof(uint32_t), 0);\n\n        if(res < 0) {\n\n            av_log(ctx->avctx, AV_LOG_ERROR, \"Cannot build VLC table\\n\");\n\n            res = -1;\n\n        } else\n\n            res = 0;\n\n        if(res != -1) {\n\n            code->bits = huff.max_bits;\n\n            code->length = huff.max_num;\n\n            code->recode = av_malloc(code->length * sizeof(int));\n\n            for(i = 0; i < code->length; i++)\n\n                code->recode[i] = huff.nums[i];\n\n        }\n\n    }\n\n    /* free allocated memory */\n\n    av_free(huff.nums);\n\n    av_free(huff.bits);\n\n    av_free(huff.lens);\n\n\n\n    return res;\n\n}\n", "idx": 25824}
{"project": "FFmpeg", "commit_id": "77d98898211eeb0241e8411428b0b364a6231744", "target": 1, "func": "static int pixlet_decode_frame(AVCodecContext *avctx, void *data,\n                               int *got_frame, AVPacket *avpkt)\n{\n    PixletContext *ctx = avctx->priv_data;\n    int i, w, h, width, height, ret, version;\n    AVFrame *p = data;\n    ThreadFrame frame = { .f = data };\n    uint32_t pktsize;\n    bytestream2_init(&ctx->gb, avpkt->data, avpkt->size);\n    pktsize = bytestream2_get_be32(&ctx->gb);\n    if (pktsize <= 44 || pktsize - 4 > bytestream2_get_bytes_left(&ctx->gb)) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid packet size %\"PRIu32\"\\n\", pktsize);\n    }\n    version = bytestream2_get_le32(&ctx->gb);\n    if (version != 1)\n        avpriv_request_sample(avctx, \"Version %d\", version);\n    bytestream2_skip(&ctx->gb, 4);\n    if (bytestream2_get_be32(&ctx->gb) != 1)\n    bytestream2_skip(&ctx->gb, 4);\n    width  = bytestream2_get_be32(&ctx->gb);\n    height = bytestream2_get_be32(&ctx->gb);\n    w = FFALIGN(width,  1 << (NB_LEVELS + 1));\n    h = FFALIGN(height, 1 << (NB_LEVELS + 1));\n    ctx->levels = bytestream2_get_be32(&ctx->gb);\n    if (ctx->levels != NB_LEVELS)\n    ctx->depth = bytestream2_get_be32(&ctx->gb);\n    if (ctx->depth < 8 || ctx->depth > 15) {\n        avpriv_request_sample(avctx, \"Depth %d\", ctx->depth);\n    }\n    ret = ff_set_dimensions(avctx, w, h);\n    if (ret < 0)\n        return ret;\n    avctx->width  = width;\n    avctx->height = height;\n    if (ctx->w != w || ctx->h != h) {\n        free_buffers(avctx);\n        ctx->w = w;\n        ctx->h = h;\n        ret = init_decoder(avctx);\n        if (ret < 0) {\n            free_buffers(avctx);\n            ctx->w = 0;\n            ctx->h = 0;\n            return ret;\n        }\n    }\n    bytestream2_skip(&ctx->gb, 8);\n    p->pict_type = AV_PICTURE_TYPE_I;\n    p->key_frame = 1;\n    p->color_range = AVCOL_RANGE_JPEG;\n    ret = ff_thread_get_buffer(avctx, &frame, 0);\n    if (ret < 0)\n        return ret;\n    for (i = 0; i < 3; i++) {\n        ret = decode_plane(avctx, i, avpkt, frame.f);\n        if (ret < 0)\n            return ret;\n        if (avctx->flags & AV_CODEC_FLAG_GRAY)\n            break;\n    }\n    postprocess_luma(frame.f, ctx->w, ctx->h, ctx->depth);\n    postprocess_chroma(frame.f, ctx->w >> 1, ctx->h >> 1, ctx->depth);\n    *got_frame = 1;\n    return pktsize;\n}", "idx": 25828}
{"project": "FFmpeg", "commit_id": "df640dbbc949d0f4deefaf43e86b8bd50ae997cc", "target": 1, "func": "static void wmv2_idct_row(short * b)\n\n{\n\n    int s1, s2;\n\n    int a0, a1, a2, a3, a4, a5, a6, a7;\n\n\n\n    /* step 1 */\n\n    a1 = W1 * b[1] + W7 * b[7];\n\n    a7 = W7 * b[1] - W1 * b[7];\n\n    a5 = W5 * b[5] + W3 * b[3];\n\n    a3 = W3 * b[5] - W5 * b[3];\n\n    a2 = W2 * b[2] + W6 * b[6];\n\n    a6 = W6 * b[2] - W2 * b[6];\n\n    a0 = W0 * b[0] + W0 * b[4];\n\n    a4 = W0 * b[0] - W0 * b[4];\n\n\n\n    /* step 2 */\n\n    s1 = (181 * (a1 - a5 + a7 - a3) + 128) >> 8; // 1, 3, 5, 7\n\n    s2 = (181 * (a1 - a5 - a7 + a3) + 128) >> 8;\n\n\n\n    /* step 3 */\n\n    b[0] = (a0 + a2 + a1 + a5 + (1 << 7)) >> 8;\n\n    b[1] = (a4 + a6 + s1      + (1 << 7)) >> 8;\n\n    b[2] = (a4 - a6 + s2      + (1 << 7)) >> 8;\n\n    b[3] = (a0 - a2 + a7 + a3 + (1 << 7)) >> 8;\n\n    b[4] = (a0 - a2 - a7 - a3 + (1 << 7)) >> 8;\n\n    b[5] = (a4 - a6 - s2      + (1 << 7)) >> 8;\n\n    b[6] = (a4 + a6 - s1      + (1 << 7)) >> 8;\n\n    b[7] = (a0 + a2 - a1 - a5 + (1 << 7)) >> 8;\n\n}\n", "idx": 25829}
{"project": "FFmpeg", "commit_id": "45b7bd7c53b41bc5ff6fc2158831f2b1b1256113", "target": 1, "func": "int ff_h264_decode_mb_cavlc(H264Context *h){\n\n    MpegEncContext * const s = &h->s;\n\n    int mb_xy;\n\n    int partition_count;\n\n    unsigned int mb_type, cbp;\n\n    int dct8x8_allowed= h->pps.transform_8x8_mode;\n\n    int decode_chroma = h->sps.chroma_format_idc == 1 || h->sps.chroma_format_idc == 2;\n\n    const int pixel_shift = h->pixel_shift;\n\n\n\n    mb_xy = h->mb_xy = s->mb_x + s->mb_y*s->mb_stride;\n\n\n\n    tprintf(s->avctx, \"pic:%d mb:%d/%d\\n\", h->frame_num, s->mb_x, s->mb_y);\n\n    cbp = 0; /* avoid warning. FIXME: find a solution without slowing\n\n                down the code */\n\n    if(h->slice_type_nos != AV_PICTURE_TYPE_I){\n\n        if(s->mb_skip_run==-1)\n\n            s->mb_skip_run= get_ue_golomb(&s->gb);\n\n\n\n        if (s->mb_skip_run--) {\n\n            if(FRAME_MBAFF && (s->mb_y&1) == 0){\n\n                if(s->mb_skip_run==0)\n\n                    h->mb_mbaff = h->mb_field_decoding_flag = get_bits1(&s->gb);\n\n            }\n\n            decode_mb_skip(h);\n\n            return 0;\n\n        }\n\n    }\n\n    if(FRAME_MBAFF){\n\n        if( (s->mb_y&1) == 0 )\n\n            h->mb_mbaff = h->mb_field_decoding_flag = get_bits1(&s->gb);\n\n    }\n\n\n\n    h->prev_mb_skipped= 0;\n\n\n\n    mb_type= get_ue_golomb(&s->gb);\n\n    if(h->slice_type_nos == AV_PICTURE_TYPE_B){\n\n        if(mb_type < 23){\n\n            partition_count= b_mb_type_info[mb_type].partition_count;\n\n            mb_type=         b_mb_type_info[mb_type].type;\n\n        }else{\n\n            mb_type -= 23;\n\n            goto decode_intra_mb;\n\n        }\n\n    }else if(h->slice_type_nos == AV_PICTURE_TYPE_P){\n\n        if(mb_type < 5){\n\n            partition_count= p_mb_type_info[mb_type].partition_count;\n\n            mb_type=         p_mb_type_info[mb_type].type;\n\n        }else{\n\n            mb_type -= 5;\n\n            goto decode_intra_mb;\n\n        }\n\n    }else{\n\n       assert(h->slice_type_nos == AV_PICTURE_TYPE_I);\n\n        if(h->slice_type == AV_PICTURE_TYPE_SI && mb_type)\n\n            mb_type--;\n\ndecode_intra_mb:\n\n        if(mb_type > 25){\n\n            av_log(h->s.avctx, AV_LOG_ERROR, \"mb_type %d in %c slice too large at %d %d\\n\", mb_type, av_get_picture_type_char(h->slice_type), s->mb_x, s->mb_y);\n\n            return -1;\n\n        }\n\n        partition_count=0;\n\n        cbp= i_mb_type_info[mb_type].cbp;\n\n        h->intra16x16_pred_mode= i_mb_type_info[mb_type].pred_mode;\n\n        mb_type= i_mb_type_info[mb_type].type;\n\n    }\n\n\n\n    if(MB_FIELD)\n\n        mb_type |= MB_TYPE_INTERLACED;\n\n\n\n    h->slice_table[ mb_xy ]= h->slice_num;\n\n\n\n    if(IS_INTRA_PCM(mb_type)){\n\n        unsigned int x;\n\n        static const uint16_t mb_sizes[4] = {256,384,512,768};\n\n        const int mb_size = mb_sizes[h->sps.chroma_format_idc]*h->sps.bit_depth_luma >> 3;\n\n\n\n        // We assume these blocks are very rare so we do not optimize it.\n\n        align_get_bits(&s->gb);\n\n\n\n        // The pixels are stored in the same order as levels in h->mb array.\n\n        for(x=0; x < mb_size; x++){\n\n            ((uint8_t*)h->mb)[x]= get_bits(&s->gb, 8);\n\n        }\n\n\n\n        // In deblocking, the quantizer is 0\n\n        s->current_picture.f.qscale_table[mb_xy] = 0;\n\n        // All coeffs are present\n\n        memset(h->non_zero_count[mb_xy], 16, 48);\n\n\n\n        s->current_picture.f.mb_type[mb_xy] = mb_type;\n\n        return 0;\n\n    }\n\n\n\n    if(MB_MBAFF){\n\n        h->ref_count[0] <<= 1;\n\n        h->ref_count[1] <<= 1;\n\n    }\n\n\n\n    fill_decode_neighbors(h, mb_type);\n\n    fill_decode_caches(h, mb_type);\n\n\n\n    //mb_pred\n\n    if(IS_INTRA(mb_type)){\n\n        int pred_mode;\n\n//            init_top_left_availability(h);\n\n        if(IS_INTRA4x4(mb_type)){\n\n            int i;\n\n            int di = 1;\n\n            if(dct8x8_allowed && get_bits1(&s->gb)){\n\n                mb_type |= MB_TYPE_8x8DCT;\n\n                di = 4;\n\n            }\n\n\n\n//                fill_intra4x4_pred_table(h);\n\n            for(i=0; i<16; i+=di){\n\n                int mode= pred_intra_mode(h, i);\n\n\n\n                if(!get_bits1(&s->gb)){\n\n                    const int rem_mode= get_bits(&s->gb, 3);\n\n                    mode = rem_mode + (rem_mode >= mode);\n\n                }\n\n\n\n                if(di==4)\n\n                    fill_rectangle( &h->intra4x4_pred_mode_cache[ scan8[i] ], 2, 2, 8, mode, 1 );\n\n                else\n\n                    h->intra4x4_pred_mode_cache[ scan8[i] ] = mode;\n\n            }\n\n            write_back_intra_pred_mode(h);\n\n            if( ff_h264_check_intra4x4_pred_mode(h) < 0)\n\n                return -1;\n\n        }else{\n\n            h->intra16x16_pred_mode= ff_h264_check_intra_pred_mode(h, h->intra16x16_pred_mode);\n\n            if(h->intra16x16_pred_mode < 0)\n\n                return -1;\n\n        }\n\n        if(decode_chroma){\n\n            pred_mode= ff_h264_check_intra_pred_mode(h, get_ue_golomb_31(&s->gb));\n\n            if(pred_mode < 0)\n\n                return -1;\n\n            h->chroma_pred_mode= pred_mode;\n\n        } else {\n\n            h->chroma_pred_mode = DC_128_PRED8x8;\n\n        }\n\n    }else if(partition_count==4){\n\n        int i, j, sub_partition_count[4], list, ref[2][4];\n\n\n\n        if(h->slice_type_nos == AV_PICTURE_TYPE_B){\n\n            for(i=0; i<4; i++){\n\n                h->sub_mb_type[i]= get_ue_golomb_31(&s->gb);\n\n                if(h->sub_mb_type[i] >=13){\n\n                    av_log(h->s.avctx, AV_LOG_ERROR, \"B sub_mb_type %u out of range at %d %d\\n\", h->sub_mb_type[i], s->mb_x, s->mb_y);\n\n                    return -1;\n\n                }\n\n                sub_partition_count[i]= b_sub_mb_type_info[ h->sub_mb_type[i] ].partition_count;\n\n                h->sub_mb_type[i]=      b_sub_mb_type_info[ h->sub_mb_type[i] ].type;\n\n            }\n\n            if( IS_DIRECT(h->sub_mb_type[0]|h->sub_mb_type[1]|h->sub_mb_type[2]|h->sub_mb_type[3])) {\n\n                ff_h264_pred_direct_motion(h, &mb_type);\n\n                h->ref_cache[0][scan8[4]] =\n\n                h->ref_cache[1][scan8[4]] =\n\n                h->ref_cache[0][scan8[12]] =\n\n                h->ref_cache[1][scan8[12]] = PART_NOT_AVAILABLE;\n\n            }\n\n        }else{\n\n            assert(h->slice_type_nos == AV_PICTURE_TYPE_P); //FIXME SP correct ?\n\n            for(i=0; i<4; i++){\n\n                h->sub_mb_type[i]= get_ue_golomb_31(&s->gb);\n\n                if(h->sub_mb_type[i] >=4){\n\n                    av_log(h->s.avctx, AV_LOG_ERROR, \"P sub_mb_type %u out of range at %d %d\\n\", h->sub_mb_type[i], s->mb_x, s->mb_y);\n\n                    return -1;\n\n                }\n\n                sub_partition_count[i]= p_sub_mb_type_info[ h->sub_mb_type[i] ].partition_count;\n\n                h->sub_mb_type[i]=      p_sub_mb_type_info[ h->sub_mb_type[i] ].type;\n\n            }\n\n        }\n\n\n\n        for(list=0; list<h->list_count; list++){\n\n            int ref_count= IS_REF0(mb_type) ? 1 : h->ref_count[list];\n\n            for(i=0; i<4; i++){\n\n                if(IS_DIRECT(h->sub_mb_type[i])) continue;\n\n                if(IS_DIR(h->sub_mb_type[i], 0, list)){\n\n                    unsigned int tmp;\n\n                    if(ref_count == 1){\n\n                        tmp= 0;\n\n                    }else if(ref_count == 2){\n\n                        tmp= get_bits1(&s->gb)^1;\n\n                    }else{\n\n                        tmp= get_ue_golomb_31(&s->gb);\n\n                        if(tmp>=ref_count){\n\n                            av_log(h->s.avctx, AV_LOG_ERROR, \"ref %u overflow\\n\", tmp);\n\n                            return -1;\n\n                        }\n\n                    }\n\n                    ref[list][i]= tmp;\n\n                }else{\n\n                 //FIXME\n\n                    ref[list][i] = -1;\n\n                }\n\n            }\n\n        }\n\n\n\n        if(dct8x8_allowed)\n\n            dct8x8_allowed = get_dct8x8_allowed(h);\n\n\n\n        for(list=0; list<h->list_count; list++){\n\n            for(i=0; i<4; i++){\n\n                if(IS_DIRECT(h->sub_mb_type[i])) {\n\n                    h->ref_cache[list][ scan8[4*i] ] = h->ref_cache[list][ scan8[4*i]+1 ];\n\n                    continue;\n\n                }\n\n                h->ref_cache[list][ scan8[4*i]   ]=h->ref_cache[list][ scan8[4*i]+1 ]=\n\n                h->ref_cache[list][ scan8[4*i]+8 ]=h->ref_cache[list][ scan8[4*i]+9 ]= ref[list][i];\n\n\n\n                if(IS_DIR(h->sub_mb_type[i], 0, list)){\n\n                    const int sub_mb_type= h->sub_mb_type[i];\n\n                    const int block_width= (sub_mb_type & (MB_TYPE_16x16|MB_TYPE_16x8)) ? 2 : 1;\n\n                    for(j=0; j<sub_partition_count[i]; j++){\n\n                        int mx, my;\n\n                        const int index= 4*i + block_width*j;\n\n                        int16_t (* mv_cache)[2]= &h->mv_cache[list][ scan8[index] ];\n\n                        pred_motion(h, index, block_width, list, h->ref_cache[list][ scan8[index] ], &mx, &my);\n\n                        mx += get_se_golomb(&s->gb);\n\n                        my += get_se_golomb(&s->gb);\n\n                        tprintf(s->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        if(IS_SUB_8X8(sub_mb_type)){\n\n                            mv_cache[ 1 ][0]=\n\n                            mv_cache[ 8 ][0]= mv_cache[ 9 ][0]= mx;\n\n                            mv_cache[ 1 ][1]=\n\n                            mv_cache[ 8 ][1]= mv_cache[ 9 ][1]= my;\n\n                        }else if(IS_SUB_8X4(sub_mb_type)){\n\n                            mv_cache[ 1 ][0]= mx;\n\n                            mv_cache[ 1 ][1]= my;\n\n                        }else if(IS_SUB_4X8(sub_mb_type)){\n\n                            mv_cache[ 8 ][0]= mx;\n\n                            mv_cache[ 8 ][1]= my;\n\n                        }\n\n                        mv_cache[ 0 ][0]= mx;\n\n                        mv_cache[ 0 ][1]= my;\n\n                    }\n\n                }else{\n\n                    uint32_t *p= (uint32_t *)&h->mv_cache[list][ scan8[4*i] ][0];\n\n                    p[0] = p[1]=\n\n                    p[8] = p[9]= 0;\n\n                }\n\n            }\n\n        }\n\n    }else if(IS_DIRECT(mb_type)){\n\n        ff_h264_pred_direct_motion(h, &mb_type);\n\n        dct8x8_allowed &= h->sps.direct_8x8_inference_flag;\n\n    }else{\n\n        int list, mx, my, i;\n\n         //FIXME we should set ref_idx_l? to 0 if we use that later ...\n\n        if(IS_16X16(mb_type)){\n\n            for(list=0; list<h->list_count; list++){\n\n                    unsigned int val;\n\n                    if(IS_DIR(mb_type, 0, list)){\n\n                        if(h->ref_count[list]==1){\n\n                            val= 0;\n\n                        }else if(h->ref_count[list]==2){\n\n                            val= get_bits1(&s->gb)^1;\n\n                        }else{\n\n                            val= get_ue_golomb_31(&s->gb);\n\n                            if(val >= h->ref_count[list]){\n\n                                av_log(h->s.avctx, AV_LOG_ERROR, \"ref %u overflow\\n\", val);\n\n                                return -1;\n\n                            }\n\n                        }\n\n                    fill_rectangle(&h->ref_cache[list][ scan8[0] ], 4, 4, 8, val, 1);\n\n                    }\n\n            }\n\n            for(list=0; list<h->list_count; list++){\n\n                if(IS_DIR(mb_type, 0, list)){\n\n                    pred_motion(h, 0, 4, list, h->ref_cache[list][ scan8[0] ], &mx, &my);\n\n                    mx += get_se_golomb(&s->gb);\n\n                    my += get_se_golomb(&s->gb);\n\n                    tprintf(s->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                    fill_rectangle(h->mv_cache[list][ scan8[0] ], 4, 4, 8, pack16to32(mx,my), 4);\n\n                }\n\n            }\n\n        }\n\n        else if(IS_16X8(mb_type)){\n\n            for(list=0; list<h->list_count; list++){\n\n                    for(i=0; i<2; i++){\n\n                        unsigned int val;\n\n                        if(IS_DIR(mb_type, i, list)){\n\n                            if(h->ref_count[list] == 1){\n\n                                val= 0;\n\n                            }else if(h->ref_count[list] == 2){\n\n                                val= get_bits1(&s->gb)^1;\n\n                            }else{\n\n                                val= get_ue_golomb_31(&s->gb);\n\n                                if(val >= h->ref_count[list]){\n\n                                    av_log(h->s.avctx, AV_LOG_ERROR, \"ref %u overflow\\n\", val);\n\n                                    return -1;\n\n                                }\n\n                            }\n\n                        }else\n\n                            val= LIST_NOT_USED&0xFF;\n\n                        fill_rectangle(&h->ref_cache[list][ scan8[0] + 16*i ], 4, 2, 8, val, 1);\n\n                    }\n\n            }\n\n            for(list=0; list<h->list_count; list++){\n\n                for(i=0; i<2; i++){\n\n                    unsigned int val;\n\n                    if(IS_DIR(mb_type, i, list)){\n\n                        pred_16x8_motion(h, 8*i, list, h->ref_cache[list][scan8[0] + 16*i], &mx, &my);\n\n                        mx += get_se_golomb(&s->gb);\n\n                        my += get_se_golomb(&s->gb);\n\n                        tprintf(s->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        val= pack16to32(mx,my);\n\n                    }else\n\n                        val=0;\n\n                    fill_rectangle(h->mv_cache[list][ scan8[0] + 16*i ], 4, 2, 8, val, 4);\n\n                }\n\n            }\n\n        }else{\n\n            assert(IS_8X16(mb_type));\n\n            for(list=0; list<h->list_count; list++){\n\n                    for(i=0; i<2; i++){\n\n                        unsigned int val;\n\n                        if(IS_DIR(mb_type, i, list)){ //FIXME optimize\n\n                            if(h->ref_count[list]==1){\n\n                                val= 0;\n\n                            }else if(h->ref_count[list]==2){\n\n                                val= get_bits1(&s->gb)^1;\n\n                            }else{\n\n                                val= get_ue_golomb_31(&s->gb);\n\n                                if(val >= h->ref_count[list]){\n\n                                    av_log(h->s.avctx, AV_LOG_ERROR, \"ref %u overflow\\n\", val);\n\n                                    return -1;\n\n                                }\n\n                            }\n\n                        }else\n\n                            val= LIST_NOT_USED&0xFF;\n\n                        fill_rectangle(&h->ref_cache[list][ scan8[0] + 2*i ], 2, 4, 8, val, 1);\n\n                    }\n\n            }\n\n            for(list=0; list<h->list_count; list++){\n\n                for(i=0; i<2; i++){\n\n                    unsigned int val;\n\n                    if(IS_DIR(mb_type, i, list)){\n\n                        pred_8x16_motion(h, i*4, list, h->ref_cache[list][ scan8[0] + 2*i ], &mx, &my);\n\n                        mx += get_se_golomb(&s->gb);\n\n                        my += get_se_golomb(&s->gb);\n\n                        tprintf(s->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        val= pack16to32(mx,my);\n\n                    }else\n\n                        val=0;\n\n                    fill_rectangle(h->mv_cache[list][ scan8[0] + 2*i ], 2, 4, 8, val, 4);\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    if(IS_INTER(mb_type))\n\n        write_back_motion(h, mb_type);\n\n\n\n    if(!IS_INTRA16x16(mb_type)){\n\n        cbp= get_ue_golomb(&s->gb);\n\n\n\n        if(decode_chroma){\n\n            if(cbp > 47){\n\n                av_log(h->s.avctx, AV_LOG_ERROR, \"cbp too large (%u) at %d %d\\n\", cbp, s->mb_x, s->mb_y);\n\n                return -1;\n\n            }\n\n            if(IS_INTRA4x4(mb_type)) cbp= golomb_to_intra4x4_cbp[cbp];\n\n            else                     cbp= golomb_to_inter_cbp   [cbp];\n\n        }else{\n\n            if(cbp > 15){\n\n                av_log(h->s.avctx, AV_LOG_ERROR, \"cbp too large (%u) at %d %d\\n\", cbp, s->mb_x, s->mb_y);\n\n                return -1;\n\n            }\n\n            if(IS_INTRA4x4(mb_type)) cbp= golomb_to_intra4x4_cbp_gray[cbp];\n\n            else                     cbp= golomb_to_inter_cbp_gray[cbp];\n\n        }\n\n    }\n\n\n\n    if(dct8x8_allowed && (cbp&15) && !IS_INTRA(mb_type)){\n\n        mb_type |= MB_TYPE_8x8DCT*get_bits1(&s->gb);\n\n    }\n\n    h->cbp=\n\n    h->cbp_table[mb_xy]= cbp;\n\n    s->current_picture.f.mb_type[mb_xy] = mb_type;\n\n\n\n    if(cbp || IS_INTRA16x16(mb_type)){\n\n        int i4x4, i8x8, chroma_idx;\n\n        int dquant;\n\n        int ret;\n\n        GetBitContext *gb= IS_INTRA(mb_type) ? h->intra_gb_ptr : h->inter_gb_ptr;\n\n        const uint8_t *scan, *scan8x8;\n\n        const int max_qp = 51 + 6*(h->sps.bit_depth_luma-8);\n\n\n\n        if(IS_INTERLACED(mb_type)){\n\n            scan8x8= s->qscale ? h->field_scan8x8_cavlc : h->field_scan8x8_cavlc_q0;\n\n            scan= s->qscale ? h->field_scan : h->field_scan_q0;\n\n        }else{\n\n            scan8x8= s->qscale ? h->zigzag_scan8x8_cavlc : h->zigzag_scan8x8_cavlc_q0;\n\n            scan= s->qscale ? h->zigzag_scan : h->zigzag_scan_q0;\n\n        }\n\n\n\n        dquant= get_se_golomb(&s->gb);\n\n\n\n        s->qscale += dquant;\n\n\n\n        if(((unsigned)s->qscale) > max_qp){\n\n            if(s->qscale<0) s->qscale+= max_qp+1;\n\n            else            s->qscale-= max_qp+1;\n\n            if(((unsigned)s->qscale) > max_qp){\n\n                av_log(h->s.avctx, AV_LOG_ERROR, \"dquant out of range (%d) at %d %d\\n\", dquant, s->mb_x, s->mb_y);\n\n                return -1;\n\n            }\n\n        }\n\n\n\n        h->chroma_qp[0]= get_chroma_qp(h, 0, s->qscale);\n\n        h->chroma_qp[1]= get_chroma_qp(h, 1, s->qscale);\n\n\n\n        if( (ret = decode_luma_residual(h, gb, scan, scan8x8, pixel_shift, mb_type, cbp, 0)) < 0 ){\n\n            return -1;\n\n        }\n\n        h->cbp_table[mb_xy] |= ret << 12;\n\n        if(CHROMA444){\n\n            if( decode_luma_residual(h, gb, scan, scan8x8, pixel_shift, mb_type, cbp, 1) < 0 ){\n\n                return -1;\n\n            }\n\n            if( decode_luma_residual(h, gb, scan, scan8x8, pixel_shift, mb_type, cbp, 2) < 0 ){\n\n                return -1;\n\n            }\n\n        } else if (CHROMA422) {\n\n            if(cbp&0x30){\n\n                for(chroma_idx=0; chroma_idx<2; chroma_idx++)\n\n                    if (decode_residual(h, gb, h->mb + ((256 + 16*16*chroma_idx) << pixel_shift),\n\n                                        CHROMA_DC_BLOCK_INDEX+chroma_idx, chroma422_dc_scan,\n\n                                        NULL, 8) < 0) {\n\n                        return -1;\n\n                    }\n\n            }\n\n\n\n            if(cbp&0x20){\n\n                for(chroma_idx=0; chroma_idx<2; chroma_idx++){\n\n                    const uint32_t *qmul = h->dequant4_coeff[chroma_idx+1+(IS_INTRA( mb_type ) ? 0:3)][h->chroma_qp[chroma_idx]];\n\n                    DCTELEM *mb = h->mb + (16*(16 + 16*chroma_idx) << pixel_shift);\n\n                    for (i8x8 = 0; i8x8 < 2; i8x8++) {\n\n                        for (i4x4 = 0; i4x4 < 4; i4x4++) {\n\n                            const int index = 16 + 16*chroma_idx + 8*i8x8 + i4x4;\n\n                            if (decode_residual(h, gb, mb, index, scan + 1, qmul, 15) < 0)\n\n                                return -1;\n\n                            mb += 16 << pixel_shift;\n\n                        }\n\n                    }\n\n                }\n\n            }else{\n\n                fill_rectangle(&h->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n                fill_rectangle(&h->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n            }\n\n        } else /* yuv420 */ {\n\n            if(cbp&0x30){\n\n                for(chroma_idx=0; chroma_idx<2; chroma_idx++)\n\n                    if( decode_residual(h, gb, h->mb + ((256 + 16*16*chroma_idx) << pixel_shift), CHROMA_DC_BLOCK_INDEX+chroma_idx, chroma_dc_scan, NULL, 4) < 0){\n\n                        return -1;\n\n                    }\n\n            }\n\n\n\n            if(cbp&0x20){\n\n                for(chroma_idx=0; chroma_idx<2; chroma_idx++){\n\n                    const uint32_t *qmul = h->dequant4_coeff[chroma_idx+1+(IS_INTRA( mb_type ) ? 0:3)][h->chroma_qp[chroma_idx]];\n\n                    for(i4x4=0; i4x4<4; i4x4++){\n\n                        const int index= 16 + 16*chroma_idx + i4x4;\n\n                        if( decode_residual(h, gb, h->mb + (16*index << pixel_shift), index, scan + 1, qmul, 15) < 0){\n\n                            return -1;\n\n                        }\n\n                    }\n\n                }\n\n            }else{\n\n                fill_rectangle(&h->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n                fill_rectangle(&h->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n            }\n\n        }\n\n    }else{\n\n        fill_rectangle(&h->non_zero_count_cache[scan8[ 0]], 4, 4, 8, 0, 1);\n\n        fill_rectangle(&h->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n        fill_rectangle(&h->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n    }\n\n    s->current_picture.f.qscale_table[mb_xy] = s->qscale;\n\n    write_back_non_zero_count(h);\n\n\n\n    if(MB_MBAFF){\n\n        h->ref_count[0] >>= 1;\n\n        h->ref_count[1] >>= 1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25832}
{"project": "FFmpeg", "commit_id": "1509d739a036b9838e12f28dac9f09ac37bc3928", "target": 1, "func": "static void d3d11va_frames_uninit(AVHWFramesContext *ctx)\n\n{\n\n    AVD3D11VAFramesContext *frames_hwctx = ctx->hwctx;\n\n    D3D11VAFramesContext *s = ctx->internal->priv;\n\n\n\n    if (frames_hwctx->texture)\n\n        ID3D11Texture2D_Release(frames_hwctx->texture);\n\n\n\n\n    if (s->staging_texture)\n\n        ID3D11Texture2D_Release(s->staging_texture);\n\n\n}", "idx": 25833}
{"project": "FFmpeg", "commit_id": "697400eac07c0614f6b9f2e7615563982dbcbe4a", "target": 0, "func": "static void mov_read_chapters(AVFormatContext *s)\n\n{\n\n    MOVContext *mov = s->priv_data;\n\n    AVStream *st = NULL;\n\n    MOVStreamContext *sc;\n\n    int64_t cur_pos;\n\n    int i;\n\n\n\n    for (i = 0; i < s->nb_streams; i++)\n\n        if (s->streams[i]->id == mov->chapter_track) {\n\n            st = s->streams[i];\n\n            break;\n\n        }\n\n    if (!st) {\n\n        av_log(s, AV_LOG_ERROR, \"Referenced QT chapter track not found\\n\");\n\n        return;\n\n    }\n\n\n\n    st->discard = AVDISCARD_ALL;\n\n    sc = st->priv_data;\n\n    cur_pos = avio_tell(sc->pb);\n\n\n\n    for (i = 0; i < st->nb_index_entries; i++) {\n\n        AVIndexEntry *sample = &st->index_entries[i];\n\n        int64_t end = i+1 < st->nb_index_entries ? st->index_entries[i+1].timestamp : st->duration;\n\n        uint8_t *title;\n\n        uint16_t ch;\n\n        int len, title_len;\n\n\n\n        if (end < sample->timestamp) {\n\n            av_log(s, AV_LOG_WARNING, \"ignoring stream duration which is shorter than chapters\\n\");\n\n            end = AV_NOPTS_VALUE;\n\n        }\n\n\n\n        if (avio_seek(sc->pb, sample->pos, SEEK_SET) != sample->pos) {\n\n            av_log(s, AV_LOG_ERROR, \"Chapter %d not found in file\\n\", i);\n\n            goto finish;\n\n        }\n\n\n\n        // the first two bytes are the length of the title\n\n        len = avio_rb16(sc->pb);\n\n        if (len > sample->size-2)\n\n            continue;\n\n        title_len = 2*len + 1;\n\n        if (!(title = av_mallocz(title_len)))\n\n            goto finish;\n\n\n\n        // The samples could theoretically be in any encoding if there's an encd\n\n        // atom following, but in practice are only utf-8 or utf-16, distinguished\n\n        // instead by the presence of a BOM\n\n        if (!len) {\n\n            title[0] = 0;\n\n        } else {\n\n            ch = avio_rb16(sc->pb);\n\n            if (ch == 0xfeff)\n\n                avio_get_str16be(sc->pb, len, title, title_len);\n\n            else if (ch == 0xfffe)\n\n                avio_get_str16le(sc->pb, len, title, title_len);\n\n            else {\n\n                AV_WB16(title, ch);\n\n                if (len == 1 || len == 2)\n\n                    title[len] = 0;\n\n                else\n\n                    avio_get_str(sc->pb, INT_MAX, title + 2, len - 1);\n\n            }\n\n        }\n\n\n\n        avpriv_new_chapter(s, i, st->time_base, sample->timestamp, end, title);\n\n        av_freep(&title);\n\n    }\n\nfinish:\n\n    avio_seek(sc->pb, cur_pos, SEEK_SET);\n\n}\n", "idx": 25834}
{"project": "FFmpeg", "commit_id": "e856ac23732822ac04fe5dd959cff94c7249c17e", "target": 0, "func": "static int msrle_decode_pal4(AVCodecContext *avctx, AVFrame *pic,\n\n                             GetByteContext *gb)\n\n{\n\n    unsigned char rle_code;\n\n    unsigned char extra_byte, odd_pixel;\n\n    unsigned char stream_byte;\n\n    int pixel_ptr = 0;\n\n    int line = avctx->height - 1;\n\n    int i;\n\n\n\n    while (line >= 0 && pixel_ptr <= avctx->width) {\n\n        if (bytestream2_get_bytes_left(gb) <= 0) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"MS RLE: bytestream overrun, %dx%d left\\n\",\n\n                   avctx->width - pixel_ptr, line);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        rle_code = stream_byte = bytestream2_get_byteu(gb);\n\n        if (rle_code == 0) {\n\n            /* fetch the next byte to see how to handle escape code */\n\n            stream_byte = bytestream2_get_byte(gb);\n\n            if (stream_byte == 0) {\n\n                /* line is done, goto the next one */\n\n                line--;\n\n                pixel_ptr = 0;\n\n            } else if (stream_byte == 1) {\n\n                /* decode is done */\n\n                return 0;\n\n            } else if (stream_byte == 2) {\n\n                /* reposition frame decode coordinates */\n\n                stream_byte = bytestream2_get_byte(gb);\n\n                pixel_ptr += stream_byte;\n\n                stream_byte = bytestream2_get_byte(gb);\n\n                avpriv_request_sample(avctx, \"Unused stream byte %X\", stream_byte);\n\n            } else {\n\n                // copy pixels from encoded stream\n\n                odd_pixel =  stream_byte & 1;\n\n                rle_code = (stream_byte + 1) / 2;\n\n                extra_byte = rle_code & 0x01;\n\n                if (pixel_ptr + 2*rle_code - odd_pixel > avctx->width ||\n\n                    bytestream2_get_bytes_left(gb) < rle_code) {\n\n                    av_log(avctx, AV_LOG_ERROR,\n\n                           \"MS RLE: frame/stream ptr just went out of bounds (copy)\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                for (i = 0; i < rle_code; i++) {\n\n                    if (pixel_ptr >= avctx->width)\n\n                        break;\n\n                    stream_byte = bytestream2_get_byteu(gb);\n\n                    pic->data[0][line * pic->linesize[0] + pixel_ptr] = stream_byte >> 4;\n\n                    pixel_ptr++;\n\n                    if (i + 1 == rle_code && odd_pixel)\n\n                        break;\n\n                    if (pixel_ptr >= avctx->width)\n\n                        break;\n\n                    pic->data[0][line * pic->linesize[0] + pixel_ptr] = stream_byte & 0x0F;\n\n                    pixel_ptr++;\n\n                }\n\n\n\n                // if the RLE code is odd, skip a byte in the stream\n\n                if (extra_byte)\n\n                    bytestream2_skip(gb, 1);\n\n            }\n\n        } else {\n\n            // decode a run of data\n\n            if (pixel_ptr + rle_code > avctx->width + 1) {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"MS RLE: frame ptr just went out of bounds (run) %d %d %d\\n\", pixel_ptr, rle_code, avctx->width);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            stream_byte = bytestream2_get_byte(gb);\n\n            for (i = 0; i < rle_code; i++) {\n\n                if (pixel_ptr >= avctx->width)\n\n                    break;\n\n                if ((i & 1) == 0)\n\n                    pic->data[0][line * pic->linesize[0] + pixel_ptr] = stream_byte >> 4;\n\n                else\n\n                    pic->data[0][line * pic->linesize[0] + pixel_ptr] = stream_byte & 0x0F;\n\n                pixel_ptr++;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* one last sanity check on the way out */\n\n    if (bytestream2_get_bytes_left(gb)) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"MS RLE: ended frame decode with %d bytes left over\\n\",\n\n               bytestream2_get_bytes_left(gb));\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25835}
{"project": "FFmpeg", "commit_id": "3206ea4ba31ebf446a3c4f1220adb895b3272c15", "target": 0, "func": "static void update_initial_durations(AVFormatContext *s, AVStream *st,\n\n                                     int stream_index, int duration)\n\n{\n\n    AVPacketList *pktl = s->internal->packet_buffer ? s->internal->packet_buffer : s->internal->parse_queue;\n\n    int64_t cur_dts    = RELATIVE_TS_BASE;\n\n\n\n    if (st->first_dts != AV_NOPTS_VALUE) {\n\n        if (st->update_initial_durations_done)\n\n            return;\n\n        st->update_initial_durations_done = 1;\n\n        cur_dts = st->first_dts;\n\n        for (; pktl; pktl = get_next_pkt(s, st, pktl)) {\n\n            if (pktl->pkt.stream_index == stream_index) {\n\n                if (pktl->pkt.pts != pktl->pkt.dts  ||\n\n                    pktl->pkt.dts != AV_NOPTS_VALUE ||\n\n                    pktl->pkt.duration)\n\n                    break;\n\n                cur_dts -= duration;\n\n            }\n\n        }\n\n        if (pktl && pktl->pkt.dts != st->first_dts) {\n\n            av_log(s, AV_LOG_DEBUG, \"first_dts %s not matching first dts %s (pts %s, duration %\"PRId64\") in the queue\\n\",\n\n                   av_ts2str(st->first_dts), av_ts2str(pktl->pkt.dts), av_ts2str(pktl->pkt.pts), pktl->pkt.duration);\n\n            return;\n\n        }\n\n        if (!pktl) {\n\n            av_log(s, AV_LOG_DEBUG, \"first_dts %s but no packet with dts in the queue\\n\", av_ts2str(st->first_dts));\n\n            return;\n\n        }\n\n        pktl          = s->internal->packet_buffer ? s->internal->packet_buffer : s->internal->parse_queue;\n\n        st->first_dts = cur_dts;\n\n    } else if (st->cur_dts != RELATIVE_TS_BASE)\n\n        return;\n\n\n\n    for (; pktl; pktl = get_next_pkt(s, st, pktl)) {\n\n        if (pktl->pkt.stream_index != stream_index)\n\n            continue;\n\n        if (pktl->pkt.pts == pktl->pkt.dts  &&\n\n            (pktl->pkt.dts == AV_NOPTS_VALUE || pktl->pkt.dts == st->first_dts) &&\n\n            !pktl->pkt.duration) {\n\n            pktl->pkt.dts = cur_dts;\n\n            if (!st->internal->avctx->has_b_frames)\n\n                pktl->pkt.pts = cur_dts;\n\n//            if (st->codecpar->codec_type != AVMEDIA_TYPE_AUDIO)\n\n                pktl->pkt.duration = duration;\n\n        } else\n\n            break;\n\n        cur_dts = pktl->pkt.dts + pktl->pkt.duration;\n\n    }\n\n    if (!pktl)\n\n        st->cur_dts = cur_dts;\n\n}\n", "idx": 25836}
{"project": "FFmpeg", "commit_id": "6ff3f3e7cec7cd78a01d0bf76cbccfbe68dc0894", "target": 0, "func": "int poll(struct pollfd *fds, nfds_t numfds, int timeout)\n\n{\n\n    fd_set read_set;\n\n    fd_set write_set;\n\n    fd_set exception_set;\n\n    nfds_t i;\n\n    int n;\n\n    int rc;\n\n\n\n#ifdef __MINGW32__\n\n    if (numfds >= FD_SETSIZE) {\n\n        errno = EINVAL;\n\n        return -1;\n\n    }\n\n#endif\n\n\n\n    FD_ZERO(&read_set);\n\n    FD_ZERO(&write_set);\n\n    FD_ZERO(&exception_set);\n\n\n\n    n = -1;\n\n    for(i = 0; i < numfds; i++) {\n\n        if (fds[i].fd < 0)\n\n            continue;\n\n#ifndef __MINGW32__\n\n        if (fds[i].fd >= FD_SETSIZE) {\n\n            errno = EINVAL;\n\n            return -1;\n\n        }\n\n#endif\n\n\n\n        if (fds[i].events & POLLIN)  FD_SET(fds[i].fd, &read_set);\n\n        if (fds[i].events & POLLOUT) FD_SET(fds[i].fd, &write_set);\n\n        if (fds[i].events & POLLERR) FD_SET(fds[i].fd, &exception_set);\n\n\n\n        if (fds[i].fd > n)\n\n            n = fds[i].fd;\n\n    };\n\n\n\n    if (n == -1)\n\n        /* Hey!? Nothing to poll, in fact!!! */\n\n        return 0;\n\n\n\n    if (timeout < 0)\n\n        rc = select(n+1, &read_set, &write_set, &exception_set, NULL);\n\n    else {\n\n        struct timeval    tv;\n\n\n\n        tv.tv_sec = timeout / 1000;\n\n        tv.tv_usec = 1000 * (timeout % 1000);\n\n        rc = select(n+1, &read_set, &write_set, &exception_set, &tv);\n\n    };\n\n\n\n    if (rc < 0)\n\n        return rc;\n\n\n\n    for(i = 0; i < (nfds_t) n; i++) {\n\n        fds[i].revents = 0;\n\n\n\n        if (FD_ISSET(fds[i].fd, &read_set))      fds[i].revents |= POLLIN;\n\n        if (FD_ISSET(fds[i].fd, &write_set))     fds[i].revents |= POLLOUT;\n\n        if (FD_ISSET(fds[i].fd, &exception_set)) fds[i].revents |= POLLERR;\n\n    };\n\n\n\n    return rc;\n\n}\n", "idx": 25837}
{"project": "FFmpeg", "commit_id": "42c41e96ff6dc4fa24d98e1913aff925b8122776", "target": 0, "func": "int av_find_best_stream(AVFormatContext *ic, enum AVMediaType type,\n\n                        int wanted_stream_nb, int related_stream,\n\n                        AVCodec **decoder_ret, int flags)\n\n{\n\n    int i, nb_streams = ic->nb_streams;\n\n    int ret = AVERROR_STREAM_NOT_FOUND, best_count = -1, best_bitrate = -1, best_multiframe = -1, count, bitrate, multiframe;\n\n    unsigned *program = NULL;\n\n    const AVCodec *decoder = NULL, *best_decoder = NULL;\n\n\n\n    if (related_stream >= 0 && wanted_stream_nb < 0) {\n\n        AVProgram *p = av_find_program_from_stream(ic, NULL, related_stream);\n\n        if (p) {\n\n            program    = p->stream_index;\n\n            nb_streams = p->nb_stream_indexes;\n\n        }\n\n    }\n\n    for (i = 0; i < nb_streams; i++) {\n\n        int real_stream_index = program ? program[i] : i;\n\n        AVStream *st          = ic->streams[real_stream_index];\n\n        AVCodecContext *avctx = st->codec;\n\n        if (avctx->codec_type != type)\n\n            continue;\n\n        if (wanted_stream_nb >= 0 && real_stream_index != wanted_stream_nb)\n\n            continue;\n\n        if (wanted_stream_nb != real_stream_index &&\n\n            st->disposition & (AV_DISPOSITION_HEARING_IMPAIRED |\n\n                               AV_DISPOSITION_VISUAL_IMPAIRED))\n\n            continue;\n\n        if (type == AVMEDIA_TYPE_AUDIO && !avctx->channels)\n\n            continue;\n\n        if (decoder_ret) {\n\n            decoder = find_decoder(ic, st, st->codec->codec_id);\n\n            if (!decoder) {\n\n                if (ret < 0)\n\n                    ret = AVERROR_DECODER_NOT_FOUND;\n\n                continue;\n\n            }\n\n        }\n\n        count = st->codec_info_nb_frames;\n\n        bitrate = avctx->bit_rate;\n\n        if (!bitrate)\n\n            bitrate = avctx->rc_max_rate;\n\n        multiframe = FFMIN(5, count);\n\n        if ((best_multiframe >  multiframe) ||\n\n            (best_multiframe == multiframe && best_bitrate >  bitrate) ||\n\n            (best_multiframe == multiframe && best_bitrate == bitrate && best_count >= count))\n\n            continue;\n\n        best_count   = count;\n\n        best_bitrate = bitrate;\n\n        best_multiframe = multiframe;\n\n        ret          = real_stream_index;\n\n        best_decoder = decoder;\n\n        if (program && i == nb_streams - 1 && ret < 0) {\n\n            program    = NULL;\n\n            nb_streams = ic->nb_streams;\n\n            /* no related stream found, try again with everything */\n\n            i = 0;\n\n        }\n\n    }\n\n    if (decoder_ret)\n\n        *decoder_ret = (AVCodec*)best_decoder;\n\n    return ret;\n\n}\n", "idx": 25838}
{"project": "FFmpeg", "commit_id": "28af284cfb44cb198c1b1c01e61c90b10fd9e395", "target": 1, "func": "static void pmt_cb(MpegTSFilter *filter, const uint8_t *section, int section_len)\n\n{\n\n    MpegTSContext *ts = filter->u.section_filter.opaque;\n\n    SectionHeader h1, *h = &h1;\n\n    PESContext *pes;\n\n    AVStream *st;\n\n    const uint8_t *p, *p_end, *desc_list_end, *desc_end;\n\n    int program_info_length, pcr_pid, pid, stream_type;\n\n    int desc_list_len, desc_len, desc_tag;\n\n    int comp_page = 0, anc_page = 0; /* initialize to kill warnings */\n\n    char language[4] = {0}; /* initialize to kill warnings */\n\n\n\n#ifdef DEBUG_SI\n\n    av_log(ts->stream, AV_LOG_DEBUG, \"PMT: len %i\\n\", section_len);\n\n    av_hex_dump_log(ts->stream, AV_LOG_DEBUG, (uint8_t *)section, section_len);\n\n#endif\n\n    p_end = section + section_len - 4;\n\n    p = section;\n\n    if (parse_section_header(h, &p, p_end) < 0)\n\n        return;\n\n#ifdef DEBUG_SI\n\n    av_log(ts->stream, AV_LOG_DEBUG, \"sid=0x%x sec_num=%d/%d\\n\",\n\n           h->id, h->sec_num, h->last_sec_num);\n\n#endif\n\n    if (h->tid != PMT_TID)\n\n        return;\n\n\n\n    clear_program(ts, h->id);\n\n    pcr_pid = get16(&p, p_end) & 0x1fff;\n\n    if (pcr_pid < 0)\n\n        return;\n\n    add_pid_to_pmt(ts, h->id, pcr_pid);\n\n#ifdef DEBUG_SI\n\n    av_log(ts->stream, AV_LOG_DEBUG, \"pcr_pid=0x%x\\n\", pcr_pid);\n\n#endif\n\n    program_info_length = get16(&p, p_end) & 0xfff;\n\n    if (program_info_length < 0)\n\n        return;\n\n    p += program_info_length;\n\n    if (p >= p_end)\n\n        return;\n\n    for(;;) {\n\n        language[0] = 0;\n\n        st = 0;\n\n        stream_type = get8(&p, p_end);\n\n        if (stream_type < 0)\n\n            break;\n\n        pid = get16(&p, p_end) & 0x1fff;\n\n        if (pid < 0)\n\n            break;\n\n        desc_list_len = get16(&p, p_end) & 0xfff;\n\n        if (desc_list_len < 0)\n\n            break;\n\n        desc_list_end = p + desc_list_len;\n\n        if (desc_list_end > p_end)\n\n            break;\n\n        for(;;) {\n\n            desc_tag = get8(&p, desc_list_end);\n\n            if (desc_tag < 0)\n\n                break;\n\n            if (stream_type == STREAM_TYPE_PRIVATE_DATA) {\n\n                if((desc_tag == 0x6A) || (desc_tag == 0x7A)) {\n\n                    /*assume DVB AC-3 Audio*/\n\n                    stream_type = STREAM_TYPE_AUDIO_AC3;\n\n                } else if(desc_tag == 0x7B) {\n\n                    /* DVB DTS audio */\n\n                    stream_type = STREAM_TYPE_AUDIO_DTS;\n\n                }\n\n            }\n\n            desc_len = get8(&p, desc_list_end);\n\n            desc_end = p + desc_len;\n\n            if (desc_end > desc_list_end)\n\n                break;\n\n#ifdef DEBUG_SI\n\n            av_log(ts->stream, AV_LOG_DEBUG, \"tag: 0x%02x len=%d\\n\",\n\n                   desc_tag, desc_len);\n\n#endif\n\n            switch(desc_tag) {\n\n            case DVB_SUBT_DESCID:\n\n                if (stream_type == STREAM_TYPE_PRIVATE_DATA)\n\n                    stream_type = STREAM_TYPE_SUBTITLE_DVB;\n\n\n\n                language[0] = get8(&p, desc_end);\n\n                language[1] = get8(&p, desc_end);\n\n                language[2] = get8(&p, desc_end);\n\n                language[3] = 0;\n\n                get8(&p, desc_end);\n\n                comp_page = get16(&p, desc_end);\n\n                anc_page = get16(&p, desc_end);\n\n\n\n                break;\n\n            case 0x0a: /* ISO 639 language descriptor */\n\n                language[0] = get8(&p, desc_end);\n\n                language[1] = get8(&p, desc_end);\n\n                language[2] = get8(&p, desc_end);\n\n                language[3] = 0;\n\n                break;\n\n            default:\n\n                break;\n\n            }\n\n            p = desc_end;\n\n        }\n\n        p = desc_list_end;\n\n\n\n#ifdef DEBUG_SI\n\n        av_log(ts->stream, AV_LOG_DEBUG, \"stream_type=%d pid=0x%x\\n\",\n\n               stream_type, pid);\n\n#endif\n\n\n\n        /* now create ffmpeg stream */\n\n        switch(stream_type) {\n\n        case STREAM_TYPE_AUDIO_MPEG1:\n\n        case STREAM_TYPE_AUDIO_MPEG2:\n\n        case STREAM_TYPE_VIDEO_MPEG1:\n\n        case STREAM_TYPE_VIDEO_MPEG2:\n\n        case STREAM_TYPE_VIDEO_MPEG4:\n\n        case STREAM_TYPE_VIDEO_H264:\n\n        case STREAM_TYPE_VIDEO_VC1:\n\n        case STREAM_TYPE_AUDIO_AAC:\n\n        case STREAM_TYPE_AUDIO_AC3:\n\n        case STREAM_TYPE_AUDIO_DTS:\n\n        case STREAM_TYPE_SUBTITLE_DVB:\n\n            if(ts->pids[pid]){\n\n                assert(ts->pids[pid]->type == MPEGTS_PES);\n\n                pes= ts->pids[pid]->u.pes_filter.opaque;\n\n                st= pes->st;\n\n            }else{\n\n                pes = add_pes_stream(ts, pid, pcr_pid, stream_type);\n\n                if (pes)\n\n                    st = new_pes_av_stream(pes, 0);\n\n            }\n\n            add_pid_to_pmt(ts, h->id, pid);\n\n            if(st)\n\n                av_program_add_stream_index(ts->stream, h->id, st->index);\n\n            break;\n\n        default:\n\n            /* we ignore the other streams */\n\n            break;\n\n        }\n\n\n\n        if (st) {\n\n            if (language[0] != 0) {\n\n                memcpy(st->language, language, 4);\n\n            }\n\n\n\n            if (stream_type == STREAM_TYPE_SUBTITLE_DVB) {\n\n                st->codec->sub_id = (anc_page << 16) | comp_page;\n\n            }\n\n        }\n\n    }\n\n    /* all parameters are there */\n\n    ts->stop_parse++;\n\n    mpegts_close_filter(ts, filter);\n\n}\n", "idx": 25840}
{"project": "FFmpeg", "commit_id": "c3ab0004ae4dffc32494ae84dd15cfaa909a7884", "target": 1, "func": "static inline void RENAME(yuv2yuvX)(SwsContext *c, const int16_t *lumFilter, const int16_t **lumSrc, int lumFilterSize,\n\n                                    const int16_t *chrFilter, const int16_t **chrSrc, int chrFilterSize, const int16_t **alpSrc,\n\n                                    uint8_t *dest, uint8_t *uDest, uint8_t *vDest, uint8_t *aDest, int dstW, int chrDstW)\n\n{\n\n#if COMPILE_TEMPLATE_MMX\n\n    if(!(c->flags & SWS_BITEXACT)) {\n\n        if (c->flags & SWS_ACCURATE_RND) {\n\n            if (uDest) {\n\n                YSCALEYUV2YV12X_ACCURATE(   \"0\", CHR_MMX_FILTER_OFFSET, uDest, chrDstW)\n\n                YSCALEYUV2YV12X_ACCURATE(AV_STRINGIFY(VOF), CHR_MMX_FILTER_OFFSET, vDest, chrDstW)\n\n            }\n\n            if (CONFIG_SWSCALE_ALPHA && aDest) {\n\n                YSCALEYUV2YV12X_ACCURATE(   \"0\", ALP_MMX_FILTER_OFFSET, aDest, dstW)\n\n            }\n\n\n\n            YSCALEYUV2YV12X_ACCURATE(\"0\", LUM_MMX_FILTER_OFFSET, dest, dstW)\n\n        } else {\n\n            if (uDest) {\n\n                YSCALEYUV2YV12X(   \"0\", CHR_MMX_FILTER_OFFSET, uDest, chrDstW)\n\n                YSCALEYUV2YV12X(AV_STRINGIFY(VOF), CHR_MMX_FILTER_OFFSET, vDest, chrDstW)\n\n            }\n\n            if (CONFIG_SWSCALE_ALPHA && aDest) {\n\n                YSCALEYUV2YV12X(   \"0\", ALP_MMX_FILTER_OFFSET, aDest, dstW)\n\n            }\n\n\n\n            YSCALEYUV2YV12X(\"0\", LUM_MMX_FILTER_OFFSET, dest, dstW)\n\n        }\n\n        return;\n\n    }\n\n#endif\n\n#if COMPILE_TEMPLATE_ALTIVEC\n\n    yuv2yuvX_altivec_real(lumFilter, lumSrc, lumFilterSize,\n\n                          chrFilter, chrSrc, chrFilterSize,\n\n                          dest, uDest, vDest, dstW, chrDstW);\n\n#else //COMPILE_TEMPLATE_ALTIVEC\n\n    yuv2yuvXinC(lumFilter, lumSrc, lumFilterSize,\n\n                chrFilter, chrSrc, chrFilterSize,\n\n                alpSrc, dest, uDest, vDest, aDest, dstW, chrDstW);\n\n#endif //!COMPILE_TEMPLATE_ALTIVEC\n\n}\n", "idx": 25841}
{"project": "FFmpeg", "commit_id": "6c5bd7d785ffb796b8cfbae677ab54755b26a22b", "target": 1, "func": "static inline void vc1_pred_mv_intfr(VC1Context *v, int n, int dmv_x, int dmv_y,\n\n                                     int mvn, int r_x, int r_y, uint8_t* is_intra, int dir)\n\n{\n\n    MpegEncContext *s = &v->s;\n\n    int xy, wrap, off = 0;\n\n    int A[2], B[2], C[2];\n\n    int px, py;\n\n    int a_valid = 0, b_valid = 0, c_valid = 0;\n\n    int field_a, field_b, field_c; // 0: same, 1: opposit\n\n    int total_valid, num_samefield, num_oppfield;\n\n    int pos_c, pos_b, n_adj;\n\n\n\n    wrap = s->b8_stride;\n\n    xy = s->block_index[n];\n\n\n\n    if (s->mb_intra) {\n\n        s->mv[0][n][0] = s->current_picture.motion_val[0][xy][0] = 0;\n\n        s->mv[0][n][1] = s->current_picture.motion_val[0][xy][1] = 0;\n\n        s->current_picture.motion_val[1][xy][0] = 0;\n\n        s->current_picture.motion_val[1][xy][1] = 0;\n\n        if (mvn == 1) { /* duplicate motion data for 1-MV block */\n\n            s->current_picture.motion_val[0][xy + 1][0]        = 0;\n\n            s->current_picture.motion_val[0][xy + 1][1]        = 0;\n\n            s->current_picture.motion_val[0][xy + wrap][0]     = 0;\n\n            s->current_picture.motion_val[0][xy + wrap][1]     = 0;\n\n            s->current_picture.motion_val[0][xy + wrap + 1][0] = 0;\n\n            s->current_picture.motion_val[0][xy + wrap + 1][1] = 0;\n\n            v->luma_mv[s->mb_x][0] = v->luma_mv[s->mb_x][1] = 0;\n\n            s->current_picture.motion_val[1][xy + 1][0]        = 0;\n\n            s->current_picture.motion_val[1][xy + 1][1]        = 0;\n\n            s->current_picture.motion_val[1][xy + wrap][0]     = 0;\n\n            s->current_picture.motion_val[1][xy + wrap][1]     = 0;\n\n            s->current_picture.motion_val[1][xy + wrap + 1][0] = 0;\n\n            s->current_picture.motion_val[1][xy + wrap + 1][1] = 0;\n\n        }\n\n        return;\n\n    }\n\n\n\n    off = ((n == 0) || (n == 1)) ? 1 : -1;\n\n    /* predict A */\n\n    if (s->mb_x || (n == 1) || (n == 3)) {\n\n        if ((v->blk_mv_type[xy]) // current block (MB) has a field MV\n\n            || (!v->blk_mv_type[xy] && !v->blk_mv_type[xy - 1])) { // or both have frame MV\n\n            A[0] = s->current_picture.motion_val[dir][xy - 1][0];\n\n            A[1] = s->current_picture.motion_val[dir][xy - 1][1];\n\n            a_valid = 1;\n\n        } else { // current block has frame mv and cand. has field MV (so average)\n\n            A[0] = (s->current_picture.motion_val[dir][xy - 1][0]\n\n                    + s->current_picture.motion_val[dir][xy - 1 + off * wrap][0] + 1) >> 1;\n\n            A[1] = (s->current_picture.motion_val[dir][xy - 1][1]\n\n                    + s->current_picture.motion_val[dir][xy - 1 + off * wrap][1] + 1) >> 1;\n\n            a_valid = 1;\n\n        }\n\n        if (!(n & 1) && v->is_intra[s->mb_x - 1]) {\n\n            a_valid = 0;\n\n            A[0] = A[1] = 0;\n\n        }\n\n    } else\n\n        A[0] = A[1] = 0;\n\n    /* Predict B and C */\n\n    B[0] = B[1] = C[0] = C[1] = 0;\n\n    if (n == 0 || n == 1 || v->blk_mv_type[xy]) {\n\n        if (!s->first_slice_line) {\n\n            if (!v->is_intra[s->mb_x - s->mb_stride]) {\n\n                b_valid = 1;\n\n                n_adj   = n | 2;\n\n                pos_b   = s->block_index[n_adj] - 2 * wrap;\n\n                if (v->blk_mv_type[pos_b] && v->blk_mv_type[xy]) {\n\n                    n_adj = (n & 2) | (n & 1);\n\n                }\n\n                B[0] = s->current_picture.motion_val[dir][s->block_index[n_adj] - 2 * wrap][0];\n\n                B[1] = s->current_picture.motion_val[dir][s->block_index[n_adj] - 2 * wrap][1];\n\n                if (v->blk_mv_type[pos_b] && !v->blk_mv_type[xy]) {\n\n                    B[0] = (B[0] + s->current_picture.motion_val[dir][s->block_index[n_adj ^ 2] - 2 * wrap][0] + 1) >> 1;\n\n                    B[1] = (B[1] + s->current_picture.motion_val[dir][s->block_index[n_adj ^ 2] - 2 * wrap][1] + 1) >> 1;\n\n                }\n\n            }\n\n            if (s->mb_width > 1) {\n\n                if (!v->is_intra[s->mb_x - s->mb_stride + 1]) {\n\n                    c_valid = 1;\n\n                    n_adj   = 2;\n\n                    pos_c   = s->block_index[2] - 2 * wrap + 2;\n\n                    if (v->blk_mv_type[pos_c] && v->blk_mv_type[xy]) {\n\n                        n_adj = n & 2;\n\n                    }\n\n                    C[0] = s->current_picture.motion_val[dir][s->block_index[n_adj] - 2 * wrap + 2][0];\n\n                    C[1] = s->current_picture.motion_val[dir][s->block_index[n_adj] - 2 * wrap + 2][1];\n\n                    if (v->blk_mv_type[pos_c] && !v->blk_mv_type[xy]) {\n\n                        C[0] = (1 + C[0] + (s->current_picture.motion_val[dir][s->block_index[n_adj ^ 2] - 2 * wrap + 2][0])) >> 1;\n\n                        C[1] = (1 + C[1] + (s->current_picture.motion_val[dir][s->block_index[n_adj ^ 2] - 2 * wrap + 2][1])) >> 1;\n\n                    }\n\n                    if (s->mb_x == s->mb_width - 1) {\n\n                        if (!v->is_intra[s->mb_x - s->mb_stride - 1]) {\n\n                            c_valid = 1;\n\n                            n_adj   = 3;\n\n                            pos_c   = s->block_index[3] - 2 * wrap - 2;\n\n                            if (v->blk_mv_type[pos_c] && v->blk_mv_type[xy]) {\n\n                                n_adj = n | 1;\n\n                            }\n\n                            C[0] = s->current_picture.motion_val[dir][s->block_index[n_adj] - 2 * wrap - 2][0];\n\n                            C[1] = s->current_picture.motion_val[dir][s->block_index[n_adj] - 2 * wrap - 2][1];\n\n                            if (v->blk_mv_type[pos_c] && !v->blk_mv_type[xy]) {\n\n                                C[0] = (1 + C[0] + s->current_picture.motion_val[dir][s->block_index[1] - 2 * wrap - 2][0]) >> 1;\n\n                                C[1] = (1 + C[1] + s->current_picture.motion_val[dir][s->block_index[1] - 2 * wrap - 2][1]) >> 1;\n\n                            }\n\n                        } else\n\n                            c_valid = 0;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    } else {\n\n        pos_b   = s->block_index[1];\n\n        b_valid = 1;\n\n        B[0]    = s->current_picture.motion_val[dir][pos_b][0];\n\n        B[1]    = s->current_picture.motion_val[dir][pos_b][1];\n\n        pos_c   = s->block_index[0];\n\n        c_valid = 1;\n\n        C[0]    = s->current_picture.motion_val[dir][pos_c][0];\n\n        C[1]    = s->current_picture.motion_val[dir][pos_c][1];\n\n    }\n\n\n\n    total_valid = a_valid + b_valid + c_valid;\n\n    // check if predictor A is out of bounds\n\n    if (!s->mb_x && !(n == 1 || n == 3)) {\n\n        A[0] = A[1] = 0;\n\n    }\n\n    // check if predictor B is out of bounds\n\n    if ((s->first_slice_line && v->blk_mv_type[xy]) || (s->first_slice_line && !(n & 2))) {\n\n        B[0] = B[1] = C[0] = C[1] = 0;\n\n    }\n\n    if (!v->blk_mv_type[xy]) {\n\n        if (s->mb_width == 1) {\n\n            px = B[0];\n\n            py = B[1];\n\n        } else {\n\n            if (total_valid >= 2) {\n\n                px = mid_pred(A[0], B[0], C[0]);\n\n                py = mid_pred(A[1], B[1], C[1]);\n\n            } else if (total_valid) {\n\n                if      (a_valid) { px = A[0]; py = A[1]; }\n\n                else if (b_valid) { px = B[0]; py = B[1]; }\n\n                else if (c_valid) { px = C[0]; py = C[1]; }\n\n                else av_assert2(0);\n\n            } else\n\n                px = py = 0;\n\n        }\n\n    } else {\n\n        if (a_valid)\n\n            field_a = (A[1] & 4) ? 1 : 0;\n\n        else\n\n            field_a = 0;\n\n        if (b_valid)\n\n            field_b = (B[1] & 4) ? 1 : 0;\n\n        else\n\n            field_b = 0;\n\n        if (c_valid)\n\n            field_c = (C[1] & 4) ? 1 : 0;\n\n        else\n\n            field_c = 0;\n\n\n\n        num_oppfield  = field_a + field_b + field_c;\n\n        num_samefield = total_valid - num_oppfield;\n\n        if (total_valid == 3) {\n\n            if ((num_samefield == 3) || (num_oppfield == 3)) {\n\n                px = mid_pred(A[0], B[0], C[0]);\n\n                py = mid_pred(A[1], B[1], C[1]);\n\n            } else if (num_samefield >= num_oppfield) {\n\n                /* take one MV from same field set depending on priority\n\n                the check for B may not be necessary */\n\n                px = !field_a ? A[0] : B[0];\n\n                py = !field_a ? A[1] : B[1];\n\n            } else {\n\n                px =  field_a ? A[0] : B[0];\n\n                py =  field_a ? A[1] : B[1];\n\n            }\n\n        } else if (total_valid == 2) {\n\n            if (num_samefield >= num_oppfield) {\n\n                if (!field_a && a_valid) {\n\n                    px = A[0];\n\n                    py = A[1];\n\n                } else if (!field_b && b_valid) {\n\n                    px = B[0];\n\n                    py = B[1];\n\n                } else if (c_valid) {\n\n                    px = C[0];\n\n                    py = C[1];\n\n                } else px = py = 0;\n\n            } else {\n\n                if (field_a && a_valid) {\n\n                    px = A[0];\n\n                    py = A[1];\n\n                } else if (field_b && b_valid) {\n\n                    px = B[0];\n\n                    py = B[1];\n\n                } else if (c_valid) {\n\n                    px = C[0];\n\n                    py = C[1];\n\n                } else px = py = 0;\n\n            }\n\n        } else if (total_valid == 1) {\n\n            px = (a_valid) ? A[0] : ((b_valid) ? B[0] : C[0]);\n\n            py = (a_valid) ? A[1] : ((b_valid) ? B[1] : C[1]);\n\n        } else\n\n            px = py = 0;\n\n    }\n\n\n\n    /* store MV using signed modulus of MV range defined in 4.11 */\n\n    s->mv[dir][n][0] = s->current_picture.motion_val[dir][xy][0] = ((px + dmv_x + r_x) & ((r_x << 1) - 1)) - r_x;\n\n    s->mv[dir][n][1] = s->current_picture.motion_val[dir][xy][1] = ((py + dmv_y + r_y) & ((r_y << 1) - 1)) - r_y;\n\n    if (mvn == 1) { /* duplicate motion data for 1-MV block */\n\n        s->current_picture.motion_val[dir][xy +    1    ][0] = s->current_picture.motion_val[dir][xy][0];\n\n        s->current_picture.motion_val[dir][xy +    1    ][1] = s->current_picture.motion_val[dir][xy][1];\n\n        s->current_picture.motion_val[dir][xy + wrap    ][0] = s->current_picture.motion_val[dir][xy][0];\n\n        s->current_picture.motion_val[dir][xy + wrap    ][1] = s->current_picture.motion_val[dir][xy][1];\n\n        s->current_picture.motion_val[dir][xy + wrap + 1][0] = s->current_picture.motion_val[dir][xy][0];\n\n        s->current_picture.motion_val[dir][xy + wrap + 1][1] = s->current_picture.motion_val[dir][xy][1];\n\n    } else if (mvn == 2) { /* duplicate motion data for 2-Field MV block */\n\n        s->current_picture.motion_val[dir][xy + 1][0] = s->current_picture.motion_val[dir][xy][0];\n\n        s->current_picture.motion_val[dir][xy + 1][1] = s->current_picture.motion_val[dir][xy][1];\n\n        s->mv[dir][n + 1][0] = s->mv[dir][n][0];\n\n        s->mv[dir][n + 1][1] = s->mv[dir][n][1];\n\n    }\n\n}\n", "idx": 25843}
{"project": "FFmpeg", "commit_id": "24cdc39e9dfd2b98e96c96387903bd41313bd0dd", "target": 1, "func": "const AVOption *av_set_string(void *obj, const char *name, const char *val){\n\n    const AVOption *o= av_find_opt(obj, name, NULL, 0, 0);\n\n    if(o && o->offset==0 && o->type == FF_OPT_TYPE_CONST && o->unit){\n\n        return set_all_opt(obj, o->unit, o->default_val);\n\n    }\n\n    if(!o || !val || o->offset<=0)\n\n        return NULL;\n\n    if(o->type != FF_OPT_TYPE_STRING){\n\n        for(;;){\n\n            int i;\n\n            char buf[256];\n\n            int cmd=0;\n\n            double d;\n\n            char *error = NULL;\n\n\n\n            if(*val == '+' || *val == '-')\n\n                cmd= *(val++);\n\n\n\n            for(i=0; i<sizeof(buf)-1 && val[i] && val[i]!='+' && val[i]!='-'; i++)\n\n                buf[i]= val[i];\n\n            buf[i]=0;\n\n            val+= i;\n\n\n\n            d = ff_eval2(buf, const_values, const_names, NULL, NULL, NULL, NULL, NULL, &error);\n\n            if(isnan(d)) {\n\n                const AVOption *o_named= av_find_opt(obj, buf, o->unit, 0, 0);\n\n                if(o_named && o_named->type == FF_OPT_TYPE_CONST)\n\n                    d= o_named->default_val;\n\n                else if(!strcmp(buf, \"default\")) d= o->default_val;\n\n                else if(!strcmp(buf, \"max\"    )) d= o->max;\n\n                else if(!strcmp(buf, \"min\"    )) d= o->min;\n\n                else if(!strcmp(buf, \"none\"   )) d= 0;\n\n                else if(!strcmp(buf, \"all\"    )) d= ~0;\n\n                else {\n\n                    if (!error)\n\n                        av_log(NULL, AV_LOG_ERROR, \"Unable to parse option value \\\"%s\\\": %s\\n\", val, error);\n\n                    return NULL;\n\n                }\n\n            }\n\n            if(o->type == FF_OPT_TYPE_FLAGS){\n\n                if     (cmd=='+') d= av_get_int(obj, name, NULL) | (int64_t)d;\n\n                else if(cmd=='-') d= av_get_int(obj, name, NULL) &~(int64_t)d;\n\n            }else if(cmd=='-')\n\n                d= -d;\n\n\n\n            av_set_number(obj, name, d, 1, 1);\n\n            if(!*val)\n\n                return o;\n\n        }\n\n        return NULL;\n\n    }\n\n\n\n    memcpy(((uint8_t*)obj) + o->offset, val, sizeof(val));\n\n    return o;\n\n}\n", "idx": 25848}
{"project": "FFmpeg", "commit_id": "382a68b0088b06b8df20d0133d767d53d8f161ef", "target": 1, "func": "int ff_h2645_extract_rbsp(const uint8_t *src, int length,\n\n                          H2645NAL *nal, int small_padding)\n\n{\n\n    int i, si, di;\n\n    uint8_t *dst;\n\n    int64_t padding = small_padding ? AV_INPUT_BUFFER_PADDING_SIZE : MAX_MBPAIR_SIZE;\n\n\n\n    nal->skipped_bytes = 0;\n\n#define STARTCODE_TEST                                                  \\\n\n        if (i + 2 < length && src[i + 1] == 0 && src[i + 2] <= 3) {     \\\n\n            if (src[i + 2] != 3 && src[i + 2] != 0) {                   \\\n\n                /* startcode, so we must be past the end */             \\\n\n                length = i;                                             \\\n\n            }                                                           \\\n\n            break;                                                      \\\n\n        }\n\n#if HAVE_FAST_UNALIGNED\n\n#define FIND_FIRST_ZERO                                                 \\\n\n        if (i > 0 && !src[i])                                           \\\n\n            i--;                                                        \\\n\n        while (src[i])                                                  \\\n\n            i++\n\n#if HAVE_FAST_64BIT\n\n    for (i = 0; i + 1 < length; i += 9) {\n\n        if (!((~AV_RN64A(src + i) &\n\n               (AV_RN64A(src + i) - 0x0100010001000101ULL)) &\n\n              0x8000800080008080ULL))\n\n            continue;\n\n        FIND_FIRST_ZERO;\n\n        STARTCODE_TEST;\n\n        i -= 7;\n\n    }\n\n#else\n\n    for (i = 0; i + 1 < length; i += 5) {\n\n        if (!((~AV_RN32A(src + i) &\n\n               (AV_RN32A(src + i) - 0x01000101U)) &\n\n              0x80008080U))\n\n            continue;\n\n        FIND_FIRST_ZERO;\n\n        STARTCODE_TEST;\n\n        i -= 3;\n\n    }\n\n#endif /* HAVE_FAST_64BIT */\n\n#else\n\n    for (i = 0; i + 1 < length; i += 2) {\n\n        if (src[i])\n\n            continue;\n\n        if (i > 0 && src[i - 1] == 0)\n\n            i--;\n\n        STARTCODE_TEST;\n\n    }\n\n#endif /* HAVE_FAST_UNALIGNED */\n\n\n\n    if (i >= length - 1 && small_padding) { // no escaped 0\n\n        nal->data     =\n\n        nal->raw_data = src;\n\n        nal->size     =\n\n        nal->raw_size = length;\n\n        return length;\n\n    }\n\n\n\n    av_fast_malloc(&nal->rbsp_buffer, &nal->rbsp_buffer_size,\n\n                   length + padding);\n\n    if (!nal->rbsp_buffer)\n\n        return AVERROR(ENOMEM);\n\n\n\n    dst = nal->rbsp_buffer;\n\n\n\n    memcpy(dst, src, i);\n\n    si = di = i;\n\n    while (si + 2 < length) {\n\n        // remove escapes (very rare 1:2^22)\n\n        if (src[si + 2] > 3) {\n\n            dst[di++] = src[si++];\n\n            dst[di++] = src[si++];\n\n        } else if (src[si] == 0 && src[si + 1] == 0 && src[si + 2] != 0) {\n\n            if (src[si + 2] == 3) { // escape\n\n                dst[di++] = 0;\n\n                dst[di++] = 0;\n\n                si       += 3;\n\n\n\n                if (nal->skipped_bytes_pos) {\n\n                    nal->skipped_bytes++;\n\n                    if (nal->skipped_bytes_pos_size < nal->skipped_bytes) {\n\n                        nal->skipped_bytes_pos_size *= 2;\n\n                        av_assert0(nal->skipped_bytes_pos_size >= nal->skipped_bytes);\n\n                        av_reallocp_array(&nal->skipped_bytes_pos,\n\n                                nal->skipped_bytes_pos_size,\n\n                                sizeof(*nal->skipped_bytes_pos));\n\n                        if (!nal->skipped_bytes_pos) {\n\n                            nal->skipped_bytes_pos_size = 0;\n\n                            return AVERROR(ENOMEM);\n\n                        }\n\n                    }\n\n                    if (nal->skipped_bytes_pos)\n\n                        nal->skipped_bytes_pos[nal->skipped_bytes-1] = di - 1;\n\n                }\n\n                continue;\n\n            } else // next start code\n\n                goto nsc;\n\n        }\n\n\n\n        dst[di++] = src[si++];\n\n    }\n\n    while (si < length)\n\n        dst[di++] = src[si++];\n\n\n\nnsc:\n\n    memset(dst + di, 0, AV_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n    nal->data = dst;\n\n    nal->size = di;\n\n    nal->raw_data = src;\n\n    nal->raw_size = si;\n\n    return si;\n\n}\n", "idx": 25849}
{"project": "FFmpeg", "commit_id": "b5ef6f8eb452c37b19d973d61548725d7b91113e", "target": 1, "func": "static void choose_pixel_fmt(AVStream *st, AVCodec *codec)\n\n{\n\n    if(codec && codec->pix_fmts){\n\n        const enum PixelFormat *p= codec->pix_fmts;\n\n        if(st->codec->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL){\n\n            if(st->codec->codec_id==CODEC_ID_MJPEG){\n\n                p= (const enum PixelFormat[]){PIX_FMT_YUVJ420P, PIX_FMT_YUVJ422P, PIX_FMT_YUV420P, PIX_FMT_YUV422P, PIX_FMT_NONE};\n\n            }else if(st->codec->codec_id==CODEC_ID_LJPEG){\n\n                p= (const enum PixelFormat[]){PIX_FMT_YUVJ420P, PIX_FMT_YUVJ422P, PIX_FMT_YUVJ444P, PIX_FMT_YUV420P, PIX_FMT_YUV422P, PIX_FMT_YUV444P, PIX_FMT_BGRA, PIX_FMT_NONE};\n\n            }\n\n        }\n\n        for(; *p!=-1; p++){\n\n            if(*p == st->codec->pix_fmt)\n\n                break;\n\n        }\n\n        if (*p == -1) {\n\n\n            av_log(NULL, AV_LOG_WARNING,\n\n                   \"Incompatible pixel format '%s' for codec '%s', auto-selecting format '%s'\\n\",\n\n                   av_pix_fmt_descriptors[st->codec->pix_fmt].name,\n\n                   codec->name,\n\n                   av_pix_fmt_descriptors[codec->pix_fmts[0]].name);\n\n            st->codec->pix_fmt = codec->pix_fmts[0];\n\n        }\n\n    }\n\n}", "idx": 25851}
{"project": "FFmpeg", "commit_id": "d9fe6b926cd619c311e45e0ae352cf09713c482c", "target": 1, "func": "static int matroska_read_header(AVFormatContext *s)\n\n{\n\n    MatroskaDemuxContext *matroska = s->priv_data;\n\n    EbmlList *attachements_list = &matroska->attachments;\n\n    MatroskaAttachement *attachements;\n\n    EbmlList *chapters_list = &matroska->chapters;\n\n    MatroskaChapter *chapters;\n\n    MatroskaTrack *tracks;\n\n    uint64_t max_start = 0;\n\n    int64_t pos;\n\n    Ebml ebml = { 0 };\n\n    AVStream *st;\n\n    int i, j, k, res;\n\n\n\n    matroska->ctx = s;\n\n\n\n    /* First read the EBML header. */\n\n    if (ebml_parse(matroska, ebml_syntax, &ebml)\n\n        || ebml.version > EBML_VERSION       || ebml.max_size > sizeof(uint64_t)\n\n        || ebml.id_length > sizeof(uint32_t) || ebml.doctype_version > 3) {\n\n        av_log(matroska->ctx, AV_LOG_ERROR,\n\n               \"EBML header using unsupported features\\n\"\n\n               \"(EBML version %\"PRIu64\", doctype %s, doc version %\"PRIu64\")\\n\",\n\n               ebml.version, ebml.doctype, ebml.doctype_version);\n\n        ebml_free(ebml_syntax, &ebml);\n\n        return AVERROR_PATCHWELCOME;\n\n    } else if (ebml.doctype_version == 3) {\n\n        av_log(matroska->ctx, AV_LOG_WARNING,\n\n               \"EBML header using unsupported features\\n\"\n\n               \"(EBML version %\"PRIu64\", doctype %s, doc version %\"PRIu64\")\\n\",\n\n               ebml.version, ebml.doctype, ebml.doctype_version);\n\n    }\n\n    for (i = 0; i < FF_ARRAY_ELEMS(matroska_doctypes); i++)\n\n        if (!strcmp(ebml.doctype, matroska_doctypes[i]))\n\n            break;\n\n    if (i >= FF_ARRAY_ELEMS(matroska_doctypes)) {\n\n        av_log(s, AV_LOG_WARNING, \"Unknown EBML doctype '%s'\\n\", ebml.doctype);\n\n    }\n\n    ebml_free(ebml_syntax, &ebml);\n\n\n\n    /* The next thing is a segment. */\n\n    pos = avio_tell(matroska->ctx->pb);\n\n    res = ebml_parse(matroska, matroska_segments, matroska);\n\n    // try resyncing until we find a EBML_STOP type element.\n\n    while (res != 1) {\n\n        res = matroska_resync(matroska, pos);\n\n        if (res < 0)\n\n            return res;\n\n        pos = avio_tell(matroska->ctx->pb);\n\n        res = ebml_parse(matroska, matroska_segment, matroska);\n\n    }\n\n    matroska_execute_seekhead(matroska);\n\n\n\n    if (!matroska->time_scale)\n\n        matroska->time_scale = 1000000;\n\n    if (matroska->duration)\n\n        matroska->ctx->duration = matroska->duration * matroska->time_scale\n\n                                  * 1000 / AV_TIME_BASE;\n\n    av_dict_set(&s->metadata, \"title\", matroska->title, 0);\n\n\n\n    if (matroska->date_utc.size == 8)\n\n        matroska_metadata_creation_time(&s->metadata, AV_RB64(matroska->date_utc.data));\n\n\n\n    tracks = matroska->tracks.elem;\n\n    for (i=0; i < matroska->tracks.nb_elem; i++) {\n\n        MatroskaTrack *track = &tracks[i];\n\n        enum CodecID codec_id = CODEC_ID_NONE;\n\n        EbmlList *encodings_list = &track->encodings;\n\n        MatroskaTrackEncoding *encodings = encodings_list->elem;\n\n        uint8_t *extradata = NULL;\n\n        int extradata_size = 0;\n\n        int extradata_offset = 0;\n\n        uint32_t fourcc = 0;\n\n        AVIOContext b;\n\n\n\n        /* Apply some sanity checks. */\n\n        if (track->type != MATROSKA_TRACK_TYPE_VIDEO &&\n\n            track->type != MATROSKA_TRACK_TYPE_AUDIO &&\n\n            track->type != MATROSKA_TRACK_TYPE_SUBTITLE) {\n\n            av_log(matroska->ctx, AV_LOG_INFO,\n\n                   \"Unknown or unsupported track type %\"PRIu64\"\\n\",\n\n                   track->type);\n\n            continue;\n\n        }\n\n        if (track->codec_id == NULL)\n\n            continue;\n\n\n\n        if (track->type == MATROSKA_TRACK_TYPE_VIDEO) {\n\n            if (!track->default_duration)\n\n                track->default_duration = 1000000000/track->video.frame_rate;\n\n            if (!track->video.display_width)\n\n                track->video.display_width = track->video.pixel_width;\n\n            if (!track->video.display_height)\n\n                track->video.display_height = track->video.pixel_height;\n\n            if (track->video.color_space.size == 4)\n\n                fourcc = AV_RL32(track->video.color_space.data);\n\n        } else if (track->type == MATROSKA_TRACK_TYPE_AUDIO) {\n\n            if (!track->audio.out_samplerate)\n\n                track->audio.out_samplerate = track->audio.samplerate;\n\n        }\n\n        if (encodings_list->nb_elem > 1) {\n\n            av_log(matroska->ctx, AV_LOG_ERROR,\n\n                   \"Multiple combined encodings not supported\");\n\n        } else if (encodings_list->nb_elem == 1) {\n\n            if (encodings[0].type ||\n\n                (encodings[0].compression.algo != MATROSKA_TRACK_ENCODING_COMP_HEADERSTRIP &&\n\n#if CONFIG_ZLIB\n\n                 encodings[0].compression.algo != MATROSKA_TRACK_ENCODING_COMP_ZLIB &&\n\n#endif\n\n#if CONFIG_BZLIB\n\n                 encodings[0].compression.algo != MATROSKA_TRACK_ENCODING_COMP_BZLIB &&\n\n#endif\n\n                 encodings[0].compression.algo != MATROSKA_TRACK_ENCODING_COMP_LZO)) {\n\n                encodings[0].scope = 0;\n\n                av_log(matroska->ctx, AV_LOG_ERROR,\n\n                       \"Unsupported encoding type\");\n\n            } else if (track->codec_priv.size && encodings[0].scope&2) {\n\n                uint8_t *codec_priv = track->codec_priv.data;\n\n                int offset = matroska_decode_buffer(&track->codec_priv.data,\n\n                                                    &track->codec_priv.size,\n\n                                                    track);\n\n                if (offset < 0) {\n\n                    track->codec_priv.data = NULL;\n\n                    track->codec_priv.size = 0;\n\n                    av_log(matroska->ctx, AV_LOG_ERROR,\n\n                           \"Failed to decode codec private data\\n\");\n\n                } else if (offset > 0) {\n\n                    track->codec_priv.data = av_malloc(track->codec_priv.size + offset);\n\n                    memcpy(track->codec_priv.data,\n\n                           encodings[0].compression.settings.data, offset);\n\n                    memcpy(track->codec_priv.data+offset, codec_priv,\n\n                           track->codec_priv.size);\n\n                    track->codec_priv.size += offset;\n\n                }\n\n                if (codec_priv != track->codec_priv.data)\n\n                    av_free(codec_priv);\n\n            }\n\n        }\n\n\n\n        for(j=0; ff_mkv_codec_tags[j].id != CODEC_ID_NONE; j++){\n\n            if(!strncmp(ff_mkv_codec_tags[j].str, track->codec_id,\n\n                        strlen(ff_mkv_codec_tags[j].str))){\n\n                codec_id= ff_mkv_codec_tags[j].id;\n\n                break;\n\n            }\n\n        }\n\n\n\n        st = track->stream = avformat_new_stream(s, NULL);\n\n        if (st == NULL)\n\n            return AVERROR(ENOMEM);\n\n\n\n        if (!strcmp(track->codec_id, \"V_MS/VFW/FOURCC\")\n\n            && track->codec_priv.size >= 40\n\n            && track->codec_priv.data != NULL) {\n\n            track->ms_compat = 1;\n\n            fourcc = AV_RL32(track->codec_priv.data + 16);\n\n            codec_id = ff_codec_get_id(ff_codec_bmp_tags, fourcc);\n\n            extradata_offset = 40;\n\n        } else if (!strcmp(track->codec_id, \"A_MS/ACM\")\n\n                   && track->codec_priv.size >= 14\n\n                   && track->codec_priv.data != NULL) {\n\n            int ret;\n\n            ffio_init_context(&b, track->codec_priv.data, track->codec_priv.size,\n\n                          AVIO_FLAG_READ, NULL, NULL, NULL, NULL);\n\n            ret = ff_get_wav_header(&b, st->codec, track->codec_priv.size);\n\n            if (ret < 0)\n\n                return ret;\n\n            codec_id = st->codec->codec_id;\n\n            extradata_offset = FFMIN(track->codec_priv.size, 18);\n\n        } else if (!strcmp(track->codec_id, \"V_QUICKTIME\")\n\n                   && (track->codec_priv.size >= 86)\n\n                   && (track->codec_priv.data != NULL)) {\n\n            fourcc = AV_RL32(track->codec_priv.data);\n\n            codec_id = ff_codec_get_id(ff_codec_movvideo_tags, fourcc);\n\n        } else if (codec_id == CODEC_ID_PCM_S16BE) {\n\n            switch (track->audio.bitdepth) {\n\n            case  8:  codec_id = CODEC_ID_PCM_U8;     break;\n\n            case 24:  codec_id = CODEC_ID_PCM_S24BE;  break;\n\n            case 32:  codec_id = CODEC_ID_PCM_S32BE;  break;\n\n            }\n\n        } else if (codec_id == CODEC_ID_PCM_S16LE) {\n\n            switch (track->audio.bitdepth) {\n\n            case  8:  codec_id = CODEC_ID_PCM_U8;     break;\n\n            case 24:  codec_id = CODEC_ID_PCM_S24LE;  break;\n\n            case 32:  codec_id = CODEC_ID_PCM_S32LE;  break;\n\n            }\n\n        } else if (codec_id==CODEC_ID_PCM_F32LE && track->audio.bitdepth==64) {\n\n            codec_id = CODEC_ID_PCM_F64LE;\n\n        } else if (codec_id == CODEC_ID_AAC && !track->codec_priv.size) {\n\n            int profile = matroska_aac_profile(track->codec_id);\n\n            int sri = matroska_aac_sri(track->audio.samplerate);\n\n            extradata = av_mallocz(5 + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (extradata == NULL)\n\n                return AVERROR(ENOMEM);\n\n            extradata[0] = (profile << 3) | ((sri&0x0E) >> 1);\n\n            extradata[1] = ((sri&0x01) << 7) | (track->audio.channels<<3);\n\n            if (strstr(track->codec_id, \"SBR\")) {\n\n                sri = matroska_aac_sri(track->audio.out_samplerate);\n\n                extradata[2] = 0x56;\n\n                extradata[3] = 0xE5;\n\n                extradata[4] = 0x80 | (sri<<3);\n\n                extradata_size = 5;\n\n            } else\n\n                extradata_size = 2;\n\n        } else if (codec_id == CODEC_ID_TTA) {\n\n            extradata_size = 30;\n\n            extradata = av_mallocz(extradata_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (extradata == NULL)\n\n                return AVERROR(ENOMEM);\n\n            ffio_init_context(&b, extradata, extradata_size, 1,\n\n                          NULL, NULL, NULL, NULL);\n\n            avio_write(&b, \"TTA1\", 4);\n\n            avio_wl16(&b, 1);\n\n            avio_wl16(&b, track->audio.channels);\n\n            avio_wl16(&b, track->audio.bitdepth);\n\n            avio_wl32(&b, track->audio.out_samplerate);\n\n            avio_wl32(&b, matroska->ctx->duration * track->audio.out_samplerate);\n\n        } else if (codec_id == CODEC_ID_RV10 || codec_id == CODEC_ID_RV20 ||\n\n                   codec_id == CODEC_ID_RV30 || codec_id == CODEC_ID_RV40) {\n\n            extradata_offset = 26;\n\n        } else if (codec_id == CODEC_ID_RA_144) {\n\n            track->audio.out_samplerate = 8000;\n\n            track->audio.channels = 1;\n\n        } else if (codec_id == CODEC_ID_RA_288 || codec_id == CODEC_ID_COOK ||\n\n                   codec_id == CODEC_ID_ATRAC3 || codec_id == CODEC_ID_SIPR) {\n\n            int flavor;\n\n            ffio_init_context(&b, track->codec_priv.data,track->codec_priv.size,\n\n                          0, NULL, NULL, NULL, NULL);\n\n            avio_skip(&b, 22);\n\n            flavor                       = avio_rb16(&b);\n\n            track->audio.coded_framesize = avio_rb32(&b);\n\n            avio_skip(&b, 12);\n\n            track->audio.sub_packet_h    = avio_rb16(&b);\n\n            track->audio.frame_size      = avio_rb16(&b);\n\n            track->audio.sub_packet_size = avio_rb16(&b);\n\n            track->audio.buf = av_malloc(track->audio.frame_size * track->audio.sub_packet_h);\n\n            if (codec_id == CODEC_ID_RA_288) {\n\n                st->codec->block_align = track->audio.coded_framesize;\n\n                track->codec_priv.size = 0;\n\n            } else {\n\n                if (codec_id == CODEC_ID_SIPR && flavor < 4) {\n\n                    const int sipr_bit_rate[4] = { 6504, 8496, 5000, 16000 };\n\n                    track->audio.sub_packet_size = ff_sipr_subpk_size[flavor];\n\n                    st->codec->bit_rate = sipr_bit_rate[flavor];\n\n                }\n\n                st->codec->block_align = track->audio.sub_packet_size;\n\n                extradata_offset = 78;\n\n            }\n\n        }\n\n        track->codec_priv.size -= extradata_offset;\n\n\n\n        if (codec_id == CODEC_ID_NONE)\n\n            av_log(matroska->ctx, AV_LOG_INFO,\n\n                   \"Unknown/unsupported CodecID %s.\\n\", track->codec_id);\n\n\n\n        if (track->time_scale < 0.01)\n\n            track->time_scale = 1.0;\n\n        avpriv_set_pts_info(st, 64, matroska->time_scale*track->time_scale, 1000*1000*1000); /* 64 bit pts in ns */\n\n\n\n        st->codec->codec_id = codec_id;\n\n        st->start_time = 0;\n\n        if (strcmp(track->language, \"und\"))\n\n            av_dict_set(&st->metadata, \"language\", track->language, 0);\n\n        av_dict_set(&st->metadata, \"title\", track->name, 0);\n\n\n\n        if (track->flag_default)\n\n            st->disposition |= AV_DISPOSITION_DEFAULT;\n\n        if (track->flag_forced)\n\n            st->disposition |= AV_DISPOSITION_FORCED;\n\n\n\n        if (!st->codec->extradata) {\n\n            if(extradata){\n\n                st->codec->extradata = extradata;\n\n                st->codec->extradata_size = extradata_size;\n\n            } else if(track->codec_priv.data && track->codec_priv.size > 0){\n\n                st->codec->extradata = av_mallocz(track->codec_priv.size +\n\n                                                  FF_INPUT_BUFFER_PADDING_SIZE);\n\n                if(st->codec->extradata == NULL)\n\n                    return AVERROR(ENOMEM);\n\n                st->codec->extradata_size = track->codec_priv.size;\n\n                memcpy(st->codec->extradata,\n\n                       track->codec_priv.data + extradata_offset,\n\n                       track->codec_priv.size);\n\n            }\n\n        }\n\n\n\n        if (track->type == MATROSKA_TRACK_TYPE_VIDEO) {\n\n            MatroskaTrackPlane *planes = track->operation.combine_planes.elem;\n\n\n\n            st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n            st->codec->codec_tag  = fourcc;\n\n            st->codec->width  = track->video.pixel_width;\n\n            st->codec->height = track->video.pixel_height;\n\n            av_reduce(&st->sample_aspect_ratio.num,\n\n                      &st->sample_aspect_ratio.den,\n\n                      st->codec->height * track->video.display_width,\n\n                      st->codec-> width * track->video.display_height,\n\n                      255);\n\n            st->need_parsing = AVSTREAM_PARSE_HEADERS;\n\n            if (track->default_duration)\n\n                st->avg_frame_rate = av_d2q(1000000000.0/track->default_duration, INT_MAX);\n\n\n\n            /* export stereo mode flag as metadata tag */\n\n            if (track->video.stereo_mode && track->video.stereo_mode < MATROSKA_VIDEO_STEREO_MODE_COUNT)\n\n                av_dict_set(&st->metadata, \"stereo_mode\", matroska_video_stereo_mode[track->video.stereo_mode], 0);\n\n\n\n            /* if we have virtual track, mark the real tracks */\n\n            for (j=0; j < track->operation.combine_planes.nb_elem; j++) {\n\n                char buf[32];\n\n                if (planes[j].type >= MATROSKA_VIDEO_STEREO_PLANE_COUNT)\n\n                    continue;\n\n                snprintf(buf, sizeof(buf), \"%s_%d\",\n\n                         matroska_video_stereo_plane[planes[j].type], i);\n\n                for (k=0; k < matroska->tracks.nb_elem; k++)\n\n                    if (planes[j].uid == tracks[k].uid) {\n\n                        av_dict_set(&s->streams[k]->metadata,\n\n                                    \"stereo_mode\", buf, 0);\n\n                        break;\n\n                    }\n\n            }\n\n        } else if (track->type == MATROSKA_TRACK_TYPE_AUDIO) {\n\n            st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n            st->codec->sample_rate = track->audio.out_samplerate;\n\n            st->codec->channels = track->audio.channels;\n\n            if (st->codec->codec_id != CODEC_ID_AAC)\n\n            st->need_parsing = AVSTREAM_PARSE_HEADERS;\n\n        } else if (track->type == MATROSKA_TRACK_TYPE_SUBTITLE) {\n\n            st->codec->codec_type = AVMEDIA_TYPE_SUBTITLE;\n\n        }\n\n    }\n\n\n\n    attachements = attachements_list->elem;\n\n    for (j=0; j<attachements_list->nb_elem; j++) {\n\n        if (!(attachements[j].filename && attachements[j].mime &&\n\n              attachements[j].bin.data && attachements[j].bin.size > 0)) {\n\n            av_log(matroska->ctx, AV_LOG_ERROR, \"incomplete attachment\\n\");\n\n        } else {\n\n            AVStream *st = avformat_new_stream(s, NULL);\n\n            if (st == NULL)\n\n                break;\n\n            av_dict_set(&st->metadata, \"filename\",attachements[j].filename, 0);\n\n            av_dict_set(&st->metadata, \"mimetype\", attachements[j].mime, 0);\n\n            st->codec->codec_id = CODEC_ID_NONE;\n\n            st->codec->codec_type = AVMEDIA_TYPE_ATTACHMENT;\n\n            st->codec->extradata  = av_malloc(attachements[j].bin.size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if(st->codec->extradata == NULL)\n\n                break;\n\n            st->codec->extradata_size = attachements[j].bin.size;\n\n            memcpy(st->codec->extradata, attachements[j].bin.data, attachements[j].bin.size);\n\n\n\n            for (i=0; ff_mkv_mime_tags[i].id != CODEC_ID_NONE; i++) {\n\n                if (!strncmp(ff_mkv_mime_tags[i].str, attachements[j].mime,\n\n                             strlen(ff_mkv_mime_tags[i].str))) {\n\n                    st->codec->codec_id = ff_mkv_mime_tags[i].id;\n\n                    break;\n\n                }\n\n            }\n\n            attachements[j].stream = st;\n\n        }\n\n    }\n\n\n\n    chapters = chapters_list->elem;\n\n    for (i=0; i<chapters_list->nb_elem; i++)\n\n        if (chapters[i].start != AV_NOPTS_VALUE && chapters[i].uid\n\n            && (max_start==0 || chapters[i].start > max_start)) {\n\n            chapters[i].chapter =\n\n            avpriv_new_chapter(s, chapters[i].uid, (AVRational){1, 1000000000},\n\n                           chapters[i].start, chapters[i].end,\n\n                           chapters[i].title);\n\n            av_dict_set(&chapters[i].chapter->metadata,\n\n                             \"title\", chapters[i].title, 0);\n\n            max_start = chapters[i].start;\n\n        }\n\n\n\n    matroska_add_index_entries(matroska);\n\n\n\n    matroska_convert_tags(s);\n\n\n\n    return 0;\n\n}\n", "idx": 25854}
{"project": "FFmpeg", "commit_id": "0a41faa9a77dc83d8d933e99f1ba902ecd146e79", "target": 1, "func": "av_cold int vp56_free(AVCodecContext *avctx)\n{\n    VP56Context *s = avctx->priv_data;\n    int pt;\n    av_freep(&s->qscale_table);\n    av_freep(&s->above_blocks);\n    av_freep(&s->macroblocks);\n    av_freep(&s->edge_emu_buffer_alloc);\n    if (s->framep[VP56_FRAME_GOLDEN]->data[0])\n        avctx->release_buffer(avctx, s->framep[VP56_FRAME_GOLDEN]);\n    if (s->framep[VP56_FRAME_GOLDEN2]->data[0])\n        avctx->release_buffer(avctx, s->framep[VP56_FRAME_GOLDEN2]);\n    if (s->framep[VP56_FRAME_PREVIOUS]->data[0])\n        avctx->release_buffer(avctx, s->framep[VP56_FRAME_PREVIOUS]);\n    return 0;", "idx": 25855}
{"project": "FFmpeg", "commit_id": "dae7ff04160901a30a35af05f2f149b289c4f0b1", "target": 1, "func": "static void decode_cdlms(WmallDecodeCtx *s)\n\n{\n\n    int c, i;\n\n    int cdlms_send_coef = get_bits1(&s->gb);\n\n\n\n    for(c = 0; c < s->num_channels; c++) {\n\n\ts->cdlms_ttl[c] = get_bits(&s->gb, 3) + 1;\n\n\tfor(i = 0; i < s->cdlms_ttl[c]; i++) {\n\n\t    s->cdlms[c][i].order = (get_bits(&s->gb, 7) + 1) * 8;\n\n\t}\n\n\n\n\tfor(i = 0; i < s->cdlms_ttl[c]; i++) {\n\n\t    s->cdlms[c][i].scaling = get_bits(&s->gb, 4);\n\n\t}\n\n\n\n\tif(cdlms_send_coef) {\n\n\t    for(i = 0; i < s->cdlms_ttl[c]; i++) {\n\n\t\tint cbits, shift_l, shift_r, j;\n\n\t\tcbits = av_log2(s->cdlms[c][i].order);\n\n\t\tif(1 << cbits < s->cdlms[c][i].order)\n\n\t\t    cbits++;\n\n\t\ts->cdlms[c][i].coefsend = get_bits(&s->gb, cbits) + 1;\n\n\n\n\t\tcbits = av_log2(s->cdlms[c][i].scaling + 1);\n\n\t\tif(1 << cbits < s->cdlms[c][i].scaling + 1)\n\n\t\t    cbits++;\n\n\n\n\t\ts->cdlms[c][i].bitsend = get_bits(&s->gb, cbits) + 2;\n\n\t\tshift_l = 32 - s->cdlms[c][i].bitsend;\n\n\t\tshift_r = 32 - 2 - s->cdlms[c][i].scaling;\n\n\t\tfor(j = 0; j < s->cdlms[c][i].coefsend; j++) {\n\n\t\t    s->cdlms[c][i].coefs[j] =\n\n\t\t\t(get_bits(&s->gb, s->cdlms[c][i].bitsend) << shift_l) >> shift_r;\n\n\t\t}\n\n\t    }\n\n\t}\n\n    }\n\n}\n", "idx": 25856}
{"project": "FFmpeg", "commit_id": "b5995856a4236c27f231210bb08d70688e045192", "target": 1, "func": "static void decode_block_params(DiracContext *s, DiracArith arith[8], DiracBlock *block,\n\n                                int stride, int x, int y)\n\n{\n\n    int i;\n\n\n\n    block->ref  = pred_block_mode(block, stride, x, y, DIRAC_REF_MASK_REF1);\n\n    block->ref ^= dirac_get_arith_bit(arith, CTX_PMODE_REF1);\n\n\n\n    if (s->num_refs == 2) {\n\n        block->ref |= pred_block_mode(block, stride, x, y, DIRAC_REF_MASK_REF2);\n\n        block->ref ^= dirac_get_arith_bit(arith, CTX_PMODE_REF2) << 1;\n\n    }\n\n\n\n    if (!block->ref) {\n\n        pred_block_dc(block, stride, x, y);\n\n        for (i = 0; i < 3; i++)\n\n            block->u.dc[i] += dirac_get_arith_int(arith+1+i, CTX_DC_F1, CTX_DC_DATA);\n\n        return;\n\n    }\n\n\n\n    if (s->globalmc_flag) {\n\n        block->ref |= pred_block_mode(block, stride, x, y, DIRAC_REF_MASK_GLOBAL);\n\n        block->ref ^= dirac_get_arith_bit(arith, CTX_GLOBAL_BLOCK) << 2;\n\n    }\n\n\n\n    for (i = 0; i < s->num_refs; i++)\n\n        if (block->ref & (i+1)) {\n\n            if (block->ref & DIRAC_REF_MASK_GLOBAL) {\n\n                global_mv(s, block, x, y, i);\n\n            } else {\n\n                pred_mv(block, stride, x, y, i);\n\n                block->u.mv[i][0] += dirac_get_arith_int(arith + 4 + 2 * i, CTX_MV_F1, CTX_MV_DATA);\n\n                block->u.mv[i][1] += dirac_get_arith_int(arith + 5 + 2 * i, CTX_MV_F1, CTX_MV_DATA);\n\n            }\n\n        }\n\n}\n", "idx": 25857}
{"project": "FFmpeg", "commit_id": "feb13aed794a7f1a1f8395159e9b077351348a34", "target": 1, "func": "static int filter_frame(AVFilterLink *inlink, AVFrame *picref)\n\n{\n\n    AVFilterContext *ctx = inlink->dst;\n\n    SignatureContext *sic = ctx->priv;\n\n    StreamContext *sc = &(sic->streamcontexts[FF_INLINK_IDX(inlink)]);\n\n    FineSignature* fs;\n\n\n\n    static const uint8_t pot3[5] = { 3*3*3*3, 3*3*3, 3*3, 3, 1 };\n\n    /* indexes of words : 210,217,219,274,334  44,175,233,270,273  57,70,103,237,269  100,285,295,337,354  101,102,111,275,296\n\n    s2usw = sorted to unsorted wordvec: 44 is at index 5, 57 at index 10...\n\n    */\n\n    static const unsigned int wordvec[25] = {44,57,70,100,101,102,103,111,175,210,217,219,233,237,269,270,273,274,275,285,295,296,334,337,354};\n\n    static const uint8_t      s2usw[25]   = { 5,10,11, 15, 20, 21, 12, 22,  6,  0,  1,  2,  7, 13, 14,  8,  9,  3, 23, 16, 17, 24,  4, 18, 19};\n\n\n\n    uint8_t wordt2b[5] = { 0, 0, 0, 0, 0 }; /* word ternary to binary */\n\n    uint64_t intpic[32][32];\n\n    uint64_t rowcount;\n\n    uint8_t *p = picref->data[0];\n\n    int inti, intj;\n\n    int *intjlut;\n\n\n\n    uint64_t conflist[DIFFELEM_SIZE];\n\n    int f = 0, g = 0, w = 0;\n\n    int32_t dh1 = 1, dh2 = 1, dw1 = 1, dw2 = 1, a, b;\n\n    int64_t denom;\n\n    int i, j, k, ternary;\n\n    uint64_t blocksum;\n\n    int blocksize;\n\n    int64_t th; /* threshold */\n\n    int64_t sum;\n\n\n\n    int64_t precfactor = (sc->divide) ? 65536 : BLOCK_LCM;\n\n\n\n    /* initialize fs */\n\n    if (sc->curfinesig) {\n\n        fs = av_mallocz(sizeof(FineSignature));\n\n        if (!fs)\n\n            return AVERROR(ENOMEM);\n\n        sc->curfinesig->next = fs;\n\n        fs->prev = sc->curfinesig;\n\n        sc->curfinesig = fs;\n\n    } else {\n\n        fs = sc->curfinesig = sc->finesiglist;\n\n        sc->curcoarsesig1->first = fs;\n\n    }\n\n\n\n    fs->pts = picref->pts;\n\n    fs->index = sc->lastindex++;\n\n\n\n    memset(intpic, 0, sizeof(uint64_t)*32*32);\n\n    intjlut = av_malloc_array(inlink->w, sizeof(int));\n\n    if (!intjlut)\n\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < inlink->w; i++) {\n\n        intjlut[i] = (i*32)/inlink->w;\n\n    }\n\n\n\n    for (i = 0; i < inlink->h; i++) {\n\n        inti = (i*32)/inlink->h;\n\n        for (j = 0; j < inlink->w; j++) {\n\n            intj = intjlut[j];\n\n            intpic[inti][intj] += p[j];\n\n        }\n\n        p += picref->linesize[0];\n\n    }\n\n    av_freep(&intjlut);\n\n\n\n    /* The following calculates a summed area table (intpic) and brings the numbers\n\n     * in intpic to the same denominator.\n\n     * So you only have to handle the numinator in the following sections.\n\n     */\n\n    dh1 = inlink->h / 32;\n\n    if (inlink->h % 32)\n\n        dh2 = dh1 + 1;\n\n    dw1 = inlink->w / 32;\n\n    if (inlink->w % 32)\n\n        dw2 = dw1 + 1;\n\n    denom = (sc->divide) ? dh1 * dh2 * dw1 * dw2 : 1;\n\n\n\n    for (i = 0; i < 32; i++) {\n\n        rowcount = 0;\n\n        a = 1;\n\n        if (dh2 > 1) {\n\n            a = ((inlink->h*(i+1))%32 == 0) ? (inlink->h*(i+1))/32 - 1 : (inlink->h*(i+1))/32;\n\n            a -= ((inlink->h*i)%32 == 0) ? (inlink->h*i)/32 - 1 : (inlink->h*i)/32;\n\n            a = (a == dh1)? dh2 : dh1;\n\n        }\n\n        for (j = 0; j < 32; j++) {\n\n            b = 1;\n\n            if (dw2 > 1) {\n\n                b = ((inlink->w*(j+1))%32 == 0) ? (inlink->w*(j+1))/32 - 1 : (inlink->w*(j+1))/32;\n\n                b -= ((inlink->w*j)%32 == 0) ? (inlink->w*j)/32 - 1 : (inlink->w*j)/32;\n\n                b = (b == dw1)? dw2 : dw1;\n\n            }\n\n            rowcount += intpic[i][j] * a * b * precfactor / denom;\n\n            if (i > 0) {\n\n                intpic[i][j] = intpic[i-1][j] + rowcount;\n\n            } else {\n\n                intpic[i][j] = rowcount;\n\n            }\n\n        }\n\n    }\n\n\n\n    denom = (sc->divide) ? 1 : dh1 * dh2 * dw1 * dw2;\n\n\n\n    for (i = 0; i < ELEMENT_COUNT; i++) {\n\n        const ElemCat* elemcat = elements[i];\n\n        int64_t* elemsignature;\n\n        uint64_t* sortsignature;\n\n\n\n        elemsignature = av_malloc_array(elemcat->elem_count, sizeof(int64_t));\n\n        if (!elemsignature)\n\n            return AVERROR(ENOMEM);\n\n        sortsignature = av_malloc_array(elemcat->elem_count, sizeof(int64_t));\n\n        if (!sortsignature)\n\n            return AVERROR(ENOMEM);\n\n\n\n        for (j = 0; j < elemcat->elem_count; j++) {\n\n            blocksum = 0;\n\n            blocksize = 0;\n\n            for (k = 0; k < elemcat->left_count; k++) {\n\n                blocksum += get_block_sum(sc, intpic, &elemcat->blocks[j*elemcat->block_count+k]);\n\n                blocksize += get_block_size(&elemcat->blocks[j*elemcat->block_count+k]);\n\n            }\n\n            sum = blocksum / blocksize;\n\n            if (elemcat->av_elem) {\n\n                sum -= 128 * precfactor * denom;\n\n            } else {\n\n                blocksum = 0;\n\n                blocksize = 0;\n\n                for (; k < elemcat->block_count; k++) {\n\n                    blocksum += get_block_sum(sc, intpic, &elemcat->blocks[j*elemcat->block_count+k]);\n\n                    blocksize += get_block_size(&elemcat->blocks[j*elemcat->block_count+k]);\n\n                }\n\n                sum -= blocksum / blocksize;\n\n                conflist[g++] = FFABS(sum * 8 / (precfactor * denom));\n\n            }\n\n\n\n            elemsignature[j] = sum;\n\n            sortsignature[j] = FFABS(sum);\n\n        }\n\n\n\n        /* get threshold */\n\n        qsort(sortsignature, elemcat->elem_count, sizeof(uint64_t), (void*) cmp);\n\n        th = sortsignature[(int) (elemcat->elem_count*0.333)];\n\n\n\n        /* ternarize */\n\n        for (j = 0; j < elemcat->elem_count; j++) {\n\n            if (elemsignature[j] < -th) {\n\n                ternary = 0;\n\n            } else if (elemsignature[j] <= th) {\n\n                ternary = 1;\n\n            } else {\n\n                ternary = 2;\n\n            }\n\n            fs->framesig[f/5] += ternary * pot3[f%5];\n\n\n\n            if (f == wordvec[w]) {\n\n                fs->words[s2usw[w]/5] += ternary * pot3[wordt2b[s2usw[w]/5]++];\n\n                if (w < 24)\n\n                    w++;\n\n            }\n\n            f++;\n\n        }\n\n        av_freep(&elemsignature);\n\n        av_freep(&sortsignature);\n\n    }\n\n\n\n    /* confidence */\n\n    qsort(conflist, DIFFELEM_SIZE, sizeof(uint64_t), (void*) cmp);\n\n    fs->confidence = FFMIN(conflist[DIFFELEM_SIZE/2], 255);\n\n\n\n    /* coarsesignature */\n\n    if (sc->coarsecount == 0) {\n\n        if (sc->curcoarsesig2) {\n\n            sc->curcoarsesig1 = av_mallocz(sizeof(CoarseSignature));\n\n            if (!sc->curcoarsesig1)\n\n                return AVERROR(ENOMEM);\n\n            sc->curcoarsesig1->first = fs;\n\n            sc->curcoarsesig2->next = sc->curcoarsesig1;\n\n            sc->coarseend = sc->curcoarsesig1;\n\n        }\n\n    }\n\n    if (sc->coarsecount == 45) {\n\n        sc->midcoarse = 1;\n\n        sc->curcoarsesig2 = av_mallocz(sizeof(CoarseSignature));\n\n        if (!sc->curcoarsesig2)\n\n            return AVERROR(ENOMEM);\n\n        sc->curcoarsesig2->first = fs;\n\n        sc->curcoarsesig1->next = sc->curcoarsesig2;\n\n        sc->coarseend = sc->curcoarsesig2;\n\n    }\n\n    for (i = 0; i < 5; i++) {\n\n        set_bit(sc->curcoarsesig1->data[i], fs->words[i]);\n\n    }\n\n    /* assuming the actual frame is the last */\n\n    sc->curcoarsesig1->last = fs;\n\n    if (sc->midcoarse) {\n\n        for (i = 0; i < 5; i++) {\n\n            set_bit(sc->curcoarsesig2->data[i], fs->words[i]);\n\n        }\n\n        sc->curcoarsesig2->last = fs;\n\n    }\n\n\n\n    sc->coarsecount = (sc->coarsecount+1)%90;\n\n\n\n    /* debug printing finesignature */\n\n    if (av_log_get_level() == AV_LOG_DEBUG) {\n\n        av_log(ctx, AV_LOG_DEBUG, \"input %d, confidence: %d\\n\", FF_INLINK_IDX(inlink), fs->confidence);\n\n\n\n        av_log(ctx, AV_LOG_DEBUG, \"words:\");\n\n        for (i = 0; i < 5; i++) {\n\n            av_log(ctx, AV_LOG_DEBUG, \" %d:\", fs->words[i] );\n\n            av_log(ctx, AV_LOG_DEBUG, \" %d\", fs->words[i] / pot3[0] );\n\n            for (j = 1; j < 5; j++)\n\n                av_log(ctx, AV_LOG_DEBUG, \",%d\", fs->words[i] % pot3[j-1] / pot3[j] );\n\n            av_log(ctx, AV_LOG_DEBUG, \";\");\n\n        }\n\n        av_log(ctx, AV_LOG_DEBUG, \"\\n\");\n\n\n\n        av_log(ctx, AV_LOG_DEBUG, \"framesignature:\");\n\n        for (i = 0; i < SIGELEM_SIZE/5; i++) {\n\n            av_log(ctx, AV_LOG_DEBUG, \" %d\", fs->framesig[i] / pot3[0] );\n\n            for (j = 1; j < 5; j++)\n\n                av_log(ctx, AV_LOG_DEBUG, \",%d\", fs->framesig[i] % pot3[j-1] / pot3[j] );\n\n        }\n\n        av_log(ctx, AV_LOG_DEBUG, \"\\n\");\n\n    }\n\n\n\n    if (FF_INLINK_IDX(inlink) == 0)\n\n        return ff_filter_frame(inlink->dst->outputs[0], picref);\n\n    return 1;\n\n}\n", "idx": 25859}
{"project": "FFmpeg", "commit_id": "68def00a6330e46eea2ee6735fa4ae91317e8f5c", "target": 1, "func": "int ff_rv34_decode_frame(AVCodecContext *avctx,\n                            void *data, int *got_picture_ptr,\n                            AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size;\n    RV34DecContext *r = avctx->priv_data;\n    MpegEncContext *s = &r->s;\n    AVFrame *pict = data;\n    SliceInfo si;\n    int i;\n    int slice_count;\n    const uint8_t *slices_hdr = NULL;\n    int last = 0;\n    /* no supplementary picture */\n    if (buf_size == 0) {\n        /* special case for last picture */\n        if (s->low_delay==0 && s->next_picture_ptr) {\n            *pict = s->next_picture_ptr->f;\n            s->next_picture_ptr = NULL;\n            *got_picture_ptr = 1;\n        }\n        return 0;\n    }\n    if(!avctx->slice_count){\n        slice_count = (*buf++) + 1;\n        slices_hdr = buf + 4;\n        buf += 8 * slice_count;\n        buf_size -= 1 + 8 * slice_count;\n    }else\n        slice_count = avctx->slice_count;\n    //parse first slice header to check whether this frame can be decoded\n    if(get_slice_offset(avctx, slices_hdr, 0) < 0 ||\n       get_slice_offset(avctx, slices_hdr, 0) > buf_size){\n        av_log(avctx, AV_LOG_ERROR, \"Slice offset is invalid\\n\");\n    }\n    init_get_bits(&s->gb, buf+get_slice_offset(avctx, slices_hdr, 0), (buf_size-get_slice_offset(avctx, slices_hdr, 0))*8);\n    if(r->parse_slice_header(r, &r->s.gb, &si) < 0 || si.start){\n        av_log(avctx, AV_LOG_ERROR, \"First slice header is incorrect\\n\");\n    }\n    if ((!s->last_picture_ptr || !s->last_picture_ptr->f.data[0]) &&\n        si.type == AV_PICTURE_TYPE_B) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid decoder state: B-frame without \"\n               \"reference data.\\n\");\n    }\n    if(   (avctx->skip_frame >= AVDISCARD_NONREF && si.type==AV_PICTURE_TYPE_B)\n       || (avctx->skip_frame >= AVDISCARD_NONKEY && si.type!=AV_PICTURE_TYPE_I)\n       ||  avctx->skip_frame >= AVDISCARD_ALL)\n        return avpkt->size;\n    /* first slice */\n    if (si.start == 0) {\n        if (s->mb_num_left > 0) {\n            av_log(avctx, AV_LOG_ERROR, \"New frame but still %d MB left.\\n\",\n                   s->mb_num_left);\n            ff_er_frame_end(s);\n            ff_MPV_frame_end(s);\n        }\n        if (s->width != si.width || s->height != si.height) {\n            int err;\n            av_log(s->avctx, AV_LOG_WARNING, \"Changing dimensions to %dx%d\\n\",\n                   si.width, si.height);\n            s->width  = si.width;\n            s->height = si.height;\n            avcodec_set_dimensions(s->avctx, s->width, s->height);\n            if ((err = ff_MPV_common_frame_size_change(s)) < 0)\n                return err;\n            if ((err = rv34_decoder_realloc(r)) < 0)\n                return err;\n        }\n        s->pict_type = si.type ? si.type : AV_PICTURE_TYPE_I;\n        if (ff_MPV_frame_start(s, s->avctx) < 0)\n            return -1;\n        ff_er_frame_start(s);\n        if (!r->tmp_b_block_base) {\n            int i;\n            r->tmp_b_block_base = av_malloc(s->linesize * 48);\n            for (i = 0; i < 2; i++)\n                r->tmp_b_block_y[i] = r->tmp_b_block_base\n                                      + i * 16 * s->linesize;\n            for (i = 0; i < 4; i++)\n                r->tmp_b_block_uv[i] = r->tmp_b_block_base + 32 * s->linesize\n                                       + (i >> 1) * 8 * s->uvlinesize\n                                       + (i &  1) * 16;\n        }\n        r->cur_pts = si.pts;\n        if (s->pict_type != AV_PICTURE_TYPE_B) {\n            r->last_pts = r->next_pts;\n            r->next_pts = r->cur_pts;\n        } else {\n            int refdist = GET_PTS_DIFF(r->next_pts, r->last_pts);\n            int dist0   = GET_PTS_DIFF(r->cur_pts,  r->last_pts);\n            int dist1   = GET_PTS_DIFF(r->next_pts, r->cur_pts);\n            if(!refdist){\n                r->mv_weight1 = r->mv_weight2 = r->weight1 = r->weight2 = 8192;\n                r->scaled_weight = 0;\n            }else{\n                r->mv_weight1 = (dist0 << 14) / refdist;\n                r->mv_weight2 = (dist1 << 14) / refdist;\n                if((r->mv_weight1|r->mv_weight2) & 511){\n                    r->weight1 = r->mv_weight1;\n                    r->weight2 = r->mv_weight2;\n                    r->scaled_weight = 0;\n                }else{\n                    r->weight1 = r->mv_weight1 >> 9;\n                    r->weight2 = r->mv_weight2 >> 9;\n                    r->scaled_weight = 1;\n                }\n            }\n        }\n        s->mb_x = s->mb_y = 0;\n        ff_thread_finish_setup(s->avctx);\n    } else if (HAVE_THREADS &&\n               (s->avctx->active_thread_type & FF_THREAD_FRAME)) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Decoder needs full frames in frame \"\n               \"multithreading mode (start MB is %d).\\n\", si.start);\n    }\n    for(i = 0; i < slice_count; i++){\n        int offset = get_slice_offset(avctx, slices_hdr, i);\n        int size;\n        if(i+1 == slice_count)\n            size = buf_size - offset;\n        else\n            size = get_slice_offset(avctx, slices_hdr, i+1) - offset;\n        if(offset < 0 || offset > buf_size){\n            av_log(avctx, AV_LOG_ERROR, \"Slice offset is invalid\\n\");\n            break;\n        }\n        r->si.end = s->mb_width * s->mb_height;\n        s->mb_num_left = r->s.mb_x + r->s.mb_y*r->s.mb_width - r->si.start;\n        if(i+1 < slice_count){\n            if (get_slice_offset(avctx, slices_hdr, i+1) < 0 ||\n                get_slice_offset(avctx, slices_hdr, i+1) > buf_size) {\n                av_log(avctx, AV_LOG_ERROR, \"Slice offset is invalid\\n\");\n                break;\n            }\n            init_get_bits(&s->gb, buf+get_slice_offset(avctx, slices_hdr, i+1), (buf_size-get_slice_offset(avctx, slices_hdr, i+1))*8);\n            if(r->parse_slice_header(r, &r->s.gb, &si) < 0){\n                if(i+2 < slice_count)\n                    size = get_slice_offset(avctx, slices_hdr, i+2) - offset;\n                else\n                    size = buf_size - offset;\n            }else\n                r->si.end = si.start;\n        }\n        if (size < 0 || size > buf_size - offset) {\n            av_log(avctx, AV_LOG_ERROR, \"Slice size is invalid\\n\");\n            break;\n        }\n        last = rv34_decode_slice(r, r->si.end, buf + offset, size);\n        if(last)\n            break;\n    }\n    if (s->current_picture_ptr) {\n        if (last) {\n            if(r->loop_filter)\n                r->loop_filter(r, s->mb_height - 1);\n            *got_picture_ptr = finish_frame(avctx, pict);\n        } else if (HAVE_THREADS &&\n                   (s->avctx->active_thread_type & FF_THREAD_FRAME)) {\n            av_log(avctx, AV_LOG_INFO, \"marking unfished frame as finished\\n\");\n            /* always mark the current frame as finished, frame-mt supports\n             * only complete frames */\n            ff_er_frame_end(s);\n            ff_MPV_frame_end(s);\n            s->mb_num_left = 0;\n            ff_thread_report_progress(&s->current_picture_ptr->f, INT_MAX, 0);\n        }\n    }\n    return avpkt->size;\n}", "idx": 25861}
{"project": "FFmpeg", "commit_id": "355e27e24dc88d6ba8f27501a34925d9d937a399", "target": 1, "func": "static int flic_decode_frame_15_16BPP(AVCodecContext *avctx,\n\n                                      void *data, int *got_frame,\n\n                                      const uint8_t *buf, int buf_size)\n\n{\n\n    /* Note, the only difference between the 15Bpp and 16Bpp */\n\n    /* Format is the pixel format, the packets are processed the same. */\n\n    FlicDecodeContext *s = avctx->priv_data;\n\n\n\n    GetByteContext g2;\n\n    int pixel_ptr;\n\n    unsigned char palette_idx1;\n\n\n\n    unsigned int frame_size;\n\n    int num_chunks;\n\n\n\n    unsigned int chunk_size;\n\n    int chunk_type;\n\n\n\n    int i, j, ret;\n\n\n\n    int lines;\n\n    int compressed_lines;\n\n    signed short line_packets;\n\n    int y_ptr;\n\n    int byte_run;\n\n    int pixel_skip;\n\n    int pixel_countdown;\n\n    unsigned char *pixels;\n\n    int pixel;\n\n    unsigned int pixel_limit;\n\n\n\n    bytestream2_init(&g2, buf, buf_size);\n\n\n\n    if ((ret = ff_reget_buffer(avctx, s->frame)) < 0)\n\n        return ret;\n\n\n\n    pixels = s->frame->data[0];\n\n    pixel_limit = s->avctx->height * s->frame->linesize[0];\n\n\n\n    frame_size = bytestream2_get_le32(&g2);\n\n    bytestream2_skip(&g2, 2);  /* skip the magic number */\n\n    num_chunks = bytestream2_get_le16(&g2);\n\n    bytestream2_skip(&g2, 8);  /* skip padding */\n\n    if (frame_size > buf_size)\n\n        frame_size = buf_size;\n\n\n\n\n\n    frame_size -= 16;\n\n\n\n    /* iterate through the chunks */\n\n    while ((frame_size > 0) && (num_chunks > 0) &&\n\n            bytestream2_get_bytes_left(&g2) >= 4) {\n\n        int stream_ptr_after_chunk;\n\n        chunk_size = bytestream2_get_le32(&g2);\n\n        if (chunk_size > frame_size) {\n\n            av_log(avctx, AV_LOG_WARNING,\n\n                   \"Invalid chunk_size = %u > frame_size = %u\\n\", chunk_size, frame_size);\n\n            chunk_size = frame_size;\n\n        }\n\n        stream_ptr_after_chunk = bytestream2_tell(&g2) - 4 + chunk_size;\n\n\n\n        chunk_type = bytestream2_get_le16(&g2);\n\n\n\n\n\n        switch (chunk_type) {\n\n        case FLI_256_COLOR:\n\n        case FLI_COLOR:\n\n            /* For some reason, it seems that non-palettized flics do\n\n             * include one of these chunks in their first frame.\n\n             * Why I do not know, it seems rather extraneous. */\n\n            ff_dlog(avctx,\n\n                    \"Unexpected Palette chunk %d in non-palettized FLC\\n\",\n\n                    chunk_type);\n\n            bytestream2_skip(&g2, chunk_size - 6);\n\n            break;\n\n\n\n        case FLI_DELTA:\n\n        case FLI_DTA_LC:\n\n            y_ptr = 0;\n\n            compressed_lines = bytestream2_get_le16(&g2);\n\n            while (compressed_lines > 0) {\n\n                if (bytestream2_tell(&g2) + 2 > stream_ptr_after_chunk)\n\n                    break;\n\n                line_packets = bytestream2_get_le16(&g2);\n\n                if (line_packets < 0) {\n\n                    line_packets = -line_packets;\n\n                    y_ptr += line_packets * s->frame->linesize[0];\n\n                } else {\n\n                    compressed_lines--;\n\n                    pixel_ptr = y_ptr;\n\n                    CHECK_PIXEL_PTR(0);\n\n                    pixel_countdown = s->avctx->width;\n\n                    for (i = 0; i < line_packets; i++) {\n\n                        /* account for the skip bytes */\n\n                        if (bytestream2_tell(&g2) + 2 > stream_ptr_after_chunk)\n\n                            break;\n\n                        pixel_skip = bytestream2_get_byte(&g2);\n\n                        pixel_ptr += (pixel_skip*2); /* Pixel is 2 bytes wide */\n\n                        pixel_countdown -= pixel_skip;\n\n                        byte_run = sign_extend(bytestream2_get_byte(&g2), 8);\n\n                        if (byte_run < 0) {\n\n                            byte_run = -byte_run;\n\n                            pixel    = bytestream2_get_le16(&g2);\n\n                            CHECK_PIXEL_PTR(2 * byte_run);\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown -= 2) {\n\n                                *((signed short*)(&pixels[pixel_ptr])) = pixel;\n\n                                pixel_ptr += 2;\n\n                            }\n\n                        } else {\n\n                            if (bytestream2_tell(&g2) + 2*byte_run > stream_ptr_after_chunk)\n\n                                break;\n\n                            CHECK_PIXEL_PTR(2 * byte_run);\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown--) {\n\n                                *((signed short*)(&pixels[pixel_ptr])) = bytestream2_get_le16(&g2);\n\n                                pixel_ptr += 2;\n\n                            }\n\n                        }\n\n                    }\n\n\n\n                    y_ptr += s->frame->linesize[0];\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_LC:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unexpected FLI_LC chunk in non-palettized FLC\\n\");\n\n            bytestream2_skip(&g2, chunk_size - 6);\n\n            break;\n\n\n\n        case FLI_BLACK:\n\n            /* set the whole frame to 0x0000 which is black in both 15Bpp and 16Bpp modes. */\n\n            memset(pixels, 0x0000,\n\n                   s->frame->linesize[0] * s->avctx->height);\n\n            break;\n\n\n\n        case FLI_BRUN:\n\n            y_ptr = 0;\n\n            for (lines = 0; lines < s->avctx->height; lines++) {\n\n                pixel_ptr = y_ptr;\n\n                /* disregard the line packets; instead, iterate through all\n\n                 * pixels on a row */\n\n                bytestream2_skip(&g2, 1);\n\n                pixel_countdown = (s->avctx->width * 2);\n\n\n\n                while (pixel_countdown > 0) {\n\n                    if (bytestream2_tell(&g2) + 1 > stream_ptr_after_chunk)\n\n                        break;\n\n                    byte_run = sign_extend(bytestream2_get_byte(&g2), 8);\n\n                    if (byte_run > 0) {\n\n                        palette_idx1 = bytestream2_get_byte(&g2);\n\n                        CHECK_PIXEL_PTR(byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            pixels[pixel_ptr++] = palette_idx1;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d) (linea%d)\\n\",\n\n                                       pixel_countdown, lines);\n\n                        }\n\n                    } else {  /* copy bytes if byte_run < 0 */\n\n                        byte_run = -byte_run;\n\n                        if (bytestream2_tell(&g2) + byte_run > stream_ptr_after_chunk)\n\n                            break;\n\n                        CHECK_PIXEL_PTR(byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            palette_idx1 = bytestream2_get_byte(&g2);\n\n                            pixels[pixel_ptr++] = palette_idx1;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d) at line %d\\n\",\n\n                                       pixel_countdown, lines);\n\n                        }\n\n                    }\n\n                }\n\n\n\n                /* Now FLX is strange, in that it is \"byte\" as opposed to \"pixel\" run length compressed.\n\n                 * This does not give us any good opportunity to perform word endian conversion\n\n                 * during decompression. So if it is required (i.e., this is not a LE target, we do\n\n                 * a second pass over the line here, swapping the bytes.\n\n                 */\n\n#if HAVE_BIGENDIAN\n\n                pixel_ptr = y_ptr;\n\n                pixel_countdown = s->avctx->width;\n\n                while (pixel_countdown > 0) {\n\n                    *((signed short*)(&pixels[pixel_ptr])) = AV_RL16(&buf[pixel_ptr]);\n\n                    pixel_ptr += 2;\n\n                }\n\n#endif\n\n                y_ptr += s->frame->linesize[0];\n\n            }\n\n            break;\n\n\n\n        case FLI_DTA_BRUN:\n\n            y_ptr = 0;\n\n            for (lines = 0; lines < s->avctx->height; lines++) {\n\n                pixel_ptr = y_ptr;\n\n                /* disregard the line packets; instead, iterate through all\n\n                 * pixels on a row */\n\n                bytestream2_skip(&g2, 1);\n\n                pixel_countdown = s->avctx->width; /* Width is in pixels, not bytes */\n\n\n\n                while (pixel_countdown > 0) {\n\n                    if (bytestream2_tell(&g2) + 1 > stream_ptr_after_chunk)\n\n                        break;\n\n                    byte_run = sign_extend(bytestream2_get_byte(&g2), 8);\n\n                    if (byte_run > 0) {\n\n                        pixel    = bytestream2_get_le16(&g2);\n\n                        CHECK_PIXEL_PTR(2 * byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            *((signed short*)(&pixels[pixel_ptr])) = pixel;\n\n                            pixel_ptr += 2;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d)\\n\",\n\n                                       pixel_countdown);\n\n                        }\n\n                    } else {  /* copy pixels if byte_run < 0 */\n\n                        byte_run = -byte_run;\n\n                        if (bytestream2_tell(&g2) + 2 * byte_run > stream_ptr_after_chunk)\n\n                            break;\n\n                        CHECK_PIXEL_PTR(2 * byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            *((signed short*)(&pixels[pixel_ptr])) = bytestream2_get_le16(&g2);\n\n                            pixel_ptr  += 2;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d)\\n\",\n\n                                       pixel_countdown);\n\n                        }\n\n                    }\n\n                }\n\n\n\n                y_ptr += s->frame->linesize[0];\n\n            }\n\n            break;\n\n\n\n        case FLI_COPY:\n\n        case FLI_DTA_COPY:\n\n            /* copy the chunk (uncompressed frame) */\n\n            if (chunk_size - 6 > (unsigned int)(FFALIGN(s->avctx->width, 2) * s->avctx->height)*2) {\n\n                av_log(avctx, AV_LOG_ERROR, \"In chunk FLI_COPY : source data (%d bytes) \" \\\n\n                       \"bigger than image, skipping chunk\\n\", chunk_size - 6);\n\n                bytestream2_skip(&g2, chunk_size - 6);\n\n            } else {\n\n\n\n                for (y_ptr = 0; y_ptr < s->frame->linesize[0] * s->avctx->height;\n\n                     y_ptr += s->frame->linesize[0]) {\n\n\n\n                    pixel_countdown = s->avctx->width;\n\n                    pixel_ptr = 0;\n\n                    while (pixel_countdown > 0) {\n\n                      *((signed short*)(&pixels[y_ptr + pixel_ptr])) = bytestream2_get_le16(&g2);\n\n                      pixel_ptr += 2;\n\n                      pixel_countdown--;\n\n                    }\n\n                    if (s->avctx->width & 1)\n\n                        bytestream2_skip(&g2, 2);\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_MINI:\n\n            /* some sort of a thumbnail? disregard this chunk... */\n\n            bytestream2_skip(&g2, chunk_size - 6);\n\n            break;\n\n\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unrecognized chunk type: %d\\n\", chunk_type);\n\n            break;\n\n        }\n\n\n\n        if (stream_ptr_after_chunk - bytestream2_tell(&g2) >= 0) {\n\n            bytestream2_skip(&g2, stream_ptr_after_chunk - bytestream2_tell(&g2));\n\n        } else {\n\n            av_log(avctx, AV_LOG_ERROR, \"Chunk overread\\n\");\n\n            break;\n\n        }\n\n\n\n        frame_size -= chunk_size;\n\n        num_chunks--;\n\n    }\n\n\n\n    /* by the end of the chunk, the stream ptr should equal the frame\n\n     * size (minus 1, possibly); if it doesn't, issue a warning */\n\n    if ((bytestream2_get_bytes_left(&g2) != 0) && (bytestream2_get_bytes_left(&g2) != 1))\n\n        av_log(avctx, AV_LOG_ERROR, \"Processed FLI chunk where chunk size = %d \" \\\n\n               \"and final chunk ptr = %d\\n\", buf_size, bytestream2_tell(&g2));\n\n\n\n    if ((ret = av_frame_ref(data, s->frame)) < 0)\n\n        return ret;\n\n\n\n    *got_frame = 1;\n\n\n\n    return buf_size;\n\n}", "idx": 25863}
{"project": "FFmpeg", "commit_id": "ca402f32e392590a81a1381dab41c4f9c2c2f98a", "target": 1, "func": "static int w64_read_header(AVFormatContext *s, AVFormatParameters *ap)\n\n{\n\n    int64_t size;\n\n    AVIOContext *pb  = s->pb;\n\n    WAVContext    *wav = s->priv_data;\n\n    AVStream *st;\n\n    uint8_t guid[16];\n\n\n\n    avio_read(pb, guid, 16);\n\n    if (memcmp(guid, guid_riff, 16))\n\n        return -1;\n\n\n\n    if (avio_rl64(pb) < 16 + 8 + 16 + 8 + 16 + 8) /* riff + wave + fmt + sizes */\n\n        return -1;\n\n\n\n    avio_read(pb, guid, 16);\n\n    if (memcmp(guid, guid_wave, 16)) {\n\n        av_log(s, AV_LOG_ERROR, \"could not find wave guid\\n\");\n\n        return -1;\n\n    }\n\n\n\n    size = find_guid(pb, guid_fmt);\n\n    if (size < 0) {\n\n        av_log(s, AV_LOG_ERROR, \"could not find fmt guid\\n\");\n\n        return -1;\n\n    }\n\n\n\n    st = av_new_stream(s, 0);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    /* subtract chunk header size - normal wav file doesn't count it */\n\n    ff_get_wav_header(pb, st->codec, size - 24);\n\n    avio_skip(pb, FFALIGN(size, INT64_C(8)) - size);\n\n\n\n    st->need_parsing = AVSTREAM_PARSE_FULL;\n\n\n\n    av_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n\n\n    size = find_guid(pb, guid_data);\n\n    if (size < 0) {\n\n        av_log(s, AV_LOG_ERROR, \"could not find data guid\\n\");\n\n        return -1;\n\n    }\n\n    wav->data_end = avio_tell(pb) + size - 24;\n\n    wav->w64      = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 25868}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "void rgb15tobgr15(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n\tlong i;\n\n\tlong num_pixels = src_size >> 1;\n\n\n\n\tfor(i=0; i<num_pixels; i++)\n\n\t{\n\n\t    unsigned b,g,r;\n\n\t    register uint16_t rgb;\n\n\t    rgb = src[2*i];\n\n\t    r = rgb&0x1F;\n\n\t    g = (rgb&0x3E0)>>5;\n\n\t    b = (rgb&0x7C00)>>10;\n\n\t    dst[2*i] = (b&0x1F) | ((g&0x1F)<<5) | ((r&0x1F)<<10);\n\n\t}\n\n}\n", "idx": 25869}
{"project": "FFmpeg", "commit_id": "fb90785e98ac405198c0ca9fec133227f6d82826", "target": 1, "func": "static int vp8_decode_frame(AVCodecContext *avctx, void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    VP8Context *s = avctx->priv_data;\n\n    int ret, mb_x, mb_y, i, y, referenced;\n\n    enum AVDiscard skip_thresh;\n\n    AVFrame *av_uninit(curframe), *prev_frame;\n\n\n\n    release_queued_segmaps(s, 0);\n\n\n\n    if ((ret = decode_frame_header(s, avpkt->data, avpkt->size)) < 0)\n\n        return ret;\n\n\n\n    prev_frame = s->framep[VP56_FRAME_CURRENT];\n\n\n\n    referenced = s->update_last || s->update_golden == VP56_FRAME_CURRENT\n\n                                || s->update_altref == VP56_FRAME_CURRENT;\n\n\n\n    skip_thresh = !referenced ? AVDISCARD_NONREF :\n\n                    !s->keyframe ? AVDISCARD_NONKEY : AVDISCARD_ALL;\n\n\n\n    if (avctx->skip_frame >= skip_thresh) {\n\n        s->invisible = 1;\n\n        goto skip_decode;\n\n    }\n\n    s->deblock_filter = s->filter.level && avctx->skip_loop_filter < skip_thresh;\n\n\n\n    // release no longer referenced frames\n\n    for (i = 0; i < 5; i++)\n\n        if (s->frames[i].data[0] &&\n\n            &s->frames[i] != prev_frame &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_PREVIOUS] &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN] &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN2])\n\n            vp8_release_frame(s, &s->frames[i], 1, 0);\n\n\n\n    // find a free buffer\n\n    for (i = 0; i < 5; i++)\n\n        if (&s->frames[i] != prev_frame &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_PREVIOUS] &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN] &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN2]) {\n\n            curframe = s->framep[VP56_FRAME_CURRENT] = &s->frames[i];\n\n            break;\n\n        }\n\n    if (i == 5) {\n\n        av_log(avctx, AV_LOG_FATAL, \"Ran out of free frames!\\n\");\n\n        abort();\n\n    }\n\n    if (curframe->data[0])\n\n        vp8_release_frame(s, curframe, 1, 0);\n\n\n\n    curframe->key_frame = s->keyframe;\n\n    curframe->pict_type = s->keyframe ? AV_PICTURE_TYPE_I : AV_PICTURE_TYPE_P;\n\n    curframe->reference = referenced ? 3 : 0;\n\n    if ((ret = vp8_alloc_frame(s, curframe))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed!\\n\");\n\n        return ret;\n\n    }\n\n\n\n    // check if golden and altref are swapped\n\n    if (s->update_altref != VP56_FRAME_NONE) {\n\n        s->next_framep[VP56_FRAME_GOLDEN2]  = s->framep[s->update_altref];\n\n    } else {\n\n        s->next_framep[VP56_FRAME_GOLDEN2]  = s->framep[VP56_FRAME_GOLDEN2];\n\n    }\n\n    if (s->update_golden != VP56_FRAME_NONE) {\n\n        s->next_framep[VP56_FRAME_GOLDEN]   = s->framep[s->update_golden];\n\n    } else {\n\n        s->next_framep[VP56_FRAME_GOLDEN]   = s->framep[VP56_FRAME_GOLDEN];\n\n    }\n\n    if (s->update_last) {\n\n        s->next_framep[VP56_FRAME_PREVIOUS] = curframe;\n\n    } else {\n\n        s->next_framep[VP56_FRAME_PREVIOUS] = s->framep[VP56_FRAME_PREVIOUS];\n\n    }\n\n    s->next_framep[VP56_FRAME_CURRENT]      = curframe;\n\n\n\n    ff_thread_finish_setup(avctx);\n\n\n\n    // Given that arithmetic probabilities are updated every frame, it's quite likely\n\n    // that the values we have on a random interframe are complete junk if we didn't\n\n    // start decode on a keyframe. So just don't display anything rather than junk.\n\n    if (!s->keyframe && (!s->framep[VP56_FRAME_PREVIOUS] ||\n\n                         !s->framep[VP56_FRAME_GOLDEN] ||\n\n                         !s->framep[VP56_FRAME_GOLDEN2])) {\n\n        av_log(avctx, AV_LOG_WARNING, \"Discarding interframe without a prior keyframe!\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    s->linesize   = curframe->linesize[0];\n\n    s->uvlinesize = curframe->linesize[1];\n\n\n\n    if (!s->edge_emu_buffer)\n\n        s->edge_emu_buffer = av_malloc(21*s->linesize);\n\n\n\n    memset(s->top_nnz, 0, s->mb_width*sizeof(*s->top_nnz));\n\n\n\n    /* Zero macroblock structures for top/top-left prediction from outside the frame. */\n\n    memset(s->macroblocks + s->mb_height*2 - 1, 0, (s->mb_width+1)*sizeof(*s->macroblocks));\n\n\n\n    // top edge of 127 for intra prediction\n\n    if (!(avctx->flags & CODEC_FLAG_EMU_EDGE)) {\n\n        s->top_border[0][15] = s->top_border[0][23] = 127;\n\n        memset(s->top_border[1]-1, 127, s->mb_width*sizeof(*s->top_border)+1);\n\n    }\n\n    memset(s->ref_count, 0, sizeof(s->ref_count));\n\n    if (s->keyframe)\n\n        memset(s->intra4x4_pred_mode_top, DC_PRED, s->mb_width*4);\n\n\n\n#define MARGIN (16 << 2)\n\n    s->mv_min.y = -MARGIN;\n\n    s->mv_max.y = ((s->mb_height - 1) << 6) + MARGIN;\n\n\n\n    for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n\n        VP56RangeCoder *c = &s->coeff_partition[mb_y & (s->num_coeff_partitions-1)];\n\n        VP8Macroblock *mb = s->macroblocks + (s->mb_height - mb_y - 1)*2;\n\n        int mb_xy = mb_y*s->mb_width;\n\n        uint8_t *dst[3] = {\n\n            curframe->data[0] + 16*mb_y*s->linesize,\n\n            curframe->data[1] +  8*mb_y*s->uvlinesize,\n\n            curframe->data[2] +  8*mb_y*s->uvlinesize\n\n        };\n\n\n\n        memset(mb - 1, 0, sizeof(*mb));   // zero left macroblock\n\n        memset(s->left_nnz, 0, sizeof(s->left_nnz));\n\n        AV_WN32A(s->intra4x4_pred_mode_left, DC_PRED*0x01010101);\n\n\n\n        // left edge of 129 for intra prediction\n\n        if (!(avctx->flags & CODEC_FLAG_EMU_EDGE)) {\n\n            for (i = 0; i < 3; i++)\n\n                for (y = 0; y < 16>>!!i; y++)\n\n                    dst[i][y*curframe->linesize[i]-1] = 129;\n\n            if (mb_y == 1) // top left edge is also 129\n\n                s->top_border[0][15] = s->top_border[0][23] = s->top_border[0][31] = 129;\n\n        }\n\n\n\n        s->mv_min.x = -MARGIN;\n\n        s->mv_max.x = ((s->mb_width  - 1) << 6) + MARGIN;\n\n        if (prev_frame && s->segmentation.enabled && !s->segmentation.update_map)\n\n            ff_thread_await_progress(prev_frame, mb_y, 0);\n\n\n\n        for (mb_x = 0; mb_x < s->mb_width; mb_x++, mb_xy++, mb++) {\n\n            /* Prefetch the current frame, 4 MBs ahead */\n\n            s->dsp.prefetch(dst[0] + (mb_x&3)*4*s->linesize + 64, s->linesize, 4);\n\n            s->dsp.prefetch(dst[1] + (mb_x&7)*s->uvlinesize + 64, dst[2] - dst[1], 2);\n\n\n\n            decode_mb_mode(s, mb, mb_x, mb_y, curframe->ref_index[0] + mb_xy,\n\n                           prev_frame && prev_frame->ref_index[0] ? prev_frame->ref_index[0] + mb_xy : NULL);\n\n\n\n            prefetch_motion(s, mb, mb_x, mb_y, mb_xy, VP56_FRAME_PREVIOUS);\n\n\n\n            if (!mb->skip)\n\n                decode_mb_coeffs(s, c, mb, s->top_nnz[mb_x], s->left_nnz);\n\n\n\n            if (mb->mode <= MODE_I4x4)\n\n                intra_predict(s, dst, mb, mb_x, mb_y);\n\n            else\n\n                inter_predict(s, dst, mb, mb_x, mb_y);\n\n\n\n            prefetch_motion(s, mb, mb_x, mb_y, mb_xy, VP56_FRAME_GOLDEN);\n\n\n\n            if (!mb->skip) {\n\n                idct_mb(s, dst, mb);\n\n            } else {\n\n                AV_ZERO64(s->left_nnz);\n\n                AV_WN64(s->top_nnz[mb_x], 0);   // array of 9, so unaligned\n\n\n\n                // Reset DC block predictors if they would exist if the mb had coefficients\n\n                if (mb->mode != MODE_I4x4 && mb->mode != VP8_MVMODE_SPLIT) {\n\n                    s->left_nnz[8]      = 0;\n\n                    s->top_nnz[mb_x][8] = 0;\n\n                }\n\n            }\n\n\n\n            if (s->deblock_filter)\n\n                filter_level_for_mb(s, mb, &s->filter_strength[mb_x]);\n\n\n\n            prefetch_motion(s, mb, mb_x, mb_y, mb_xy, VP56_FRAME_GOLDEN2);\n\n\n\n            dst[0] += 16;\n\n            dst[1] += 8;\n\n            dst[2] += 8;\n\n            s->mv_min.x -= 64;\n\n            s->mv_max.x -= 64;\n\n        }\n\n        if (s->deblock_filter) {\n\n            if (s->filter.simple)\n\n                filter_mb_row_simple(s, curframe, mb_y);\n\n            else\n\n                filter_mb_row(s, curframe, mb_y);\n\n        }\n\n        s->mv_min.y -= 64;\n\n        s->mv_max.y -= 64;\n\n\n\n        ff_thread_report_progress(curframe, mb_y, 0);\n\n    }\n\n\n\n    ff_thread_report_progress(curframe, INT_MAX, 0);\n\nskip_decode:\n\n    // if future frames don't use the updated probabilities,\n\n    // reset them to the values we saved\n\n    if (!s->update_probabilities)\n\n        s->prob[0] = s->prob[1];\n\n\n\n    memcpy(&s->framep[0], &s->next_framep[0], sizeof(s->framep[0]) * 4);\n\n\n\n    if (!s->invisible) {\n\n        *(AVFrame*)data = *curframe;\n\n        *data_size = sizeof(AVFrame);\n\n    }\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 25870}
{"project": "FFmpeg", "commit_id": "ccce2248bf56692fc7bd436ca2c9acca772d486a", "target": 1, "func": "static void vp7_luma_dc_wht_c(int16_t block[4][4][16], int16_t dc[16])\n\n{\n\n    int i, a1, b1, c1, d1;\n\n    int16_t tmp[16];\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        a1 = (dc[i * 4 + 0] + dc[i * 4 + 2]) * 23170;\n\n        b1 = (dc[i * 4 + 0] - dc[i * 4 + 2]) * 23170;\n\n        c1 = dc[i * 4 + 1] * 12540 - dc[i * 4 + 3] * 30274;\n\n        d1 = dc[i * 4 + 1] * 30274 + dc[i * 4 + 3] * 12540;\n\n        tmp[i * 4 + 0] = (a1 + d1) >> 14;\n\n        tmp[i * 4 + 3] = (a1 - d1) >> 14;\n\n        tmp[i * 4 + 1] = (b1 + c1) >> 14;\n\n        tmp[i * 4 + 2] = (b1 - c1) >> 14;\n\n    }\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        a1 = (tmp[i + 0] + tmp[i + 8]) * 23170;\n\n        b1 = (tmp[i + 0] - tmp[i + 8]) * 23170;\n\n        c1 = tmp[i + 4] * 12540 - tmp[i + 12] * 30274;\n\n        d1 = tmp[i + 4] * 30274 + tmp[i + 12] * 12540;\n\n        AV_ZERO64(dc + i * 4);\n\n        block[0][i][0] = (a1 + d1 + 0x20000) >> 18;\n\n        block[3][i][0] = (a1 - d1 + 0x20000) >> 18;\n\n        block[1][i][0] = (b1 + c1 + 0x20000) >> 18;\n\n        block[2][i][0] = (b1 - c1 + 0x20000) >> 18;\n\n    }\n\n}\n", "idx": 25873}
{"project": "FFmpeg", "commit_id": "d3088e0fd8749788818cb5df92abaa3b12e409e1", "target": 1, "func": "static void generate_noise(G723_1_Context *p)\n\n{\n\n    int i, j, idx, t;\n\n    int off[SUBFRAMES];\n\n    int signs[SUBFRAMES / 2 * 11], pos[SUBFRAMES / 2 * 11];\n\n    int tmp[SUBFRAME_LEN * 2];\n\n    int16_t *vector_ptr;\n\n    int64_t sum;\n\n    int b0, c, delta, x, shift;\n\n\n\n    p->pitch_lag[0] = cng_rand(&p->cng_random_seed, 21) + 123;\n\n    p->pitch_lag[1] = cng_rand(&p->cng_random_seed, 19) + 123;\n\n\n\n    for (i = 0; i < SUBFRAMES; i++) {\n\n        p->subframe[i].ad_cb_gain = cng_rand(&p->cng_random_seed, 50) + 1;\n\n        p->subframe[i].ad_cb_lag  = cng_adaptive_cb_lag[i];\n\n    }\n\n\n\n    for (i = 0; i < SUBFRAMES / 2; i++) {\n\n        t = cng_rand(&p->cng_random_seed, 1 << 13);\n\n        off[i * 2]     =   t       & 1;\n\n        off[i * 2 + 1] = ((t >> 1) & 1) + SUBFRAME_LEN;\n\n        t >>= 2;\n\n        for (j = 0; j < 11; j++) {\n\n            signs[i * 11 + j] = (t & 1) * 2 - 1 << 14;\n\n            t >>= 1;\n\n        }\n\n    }\n\n\n\n    idx = 0;\n\n    for (i = 0; i < SUBFRAMES; i++) {\n\n        for (j = 0; j < SUBFRAME_LEN / 2; j++)\n\n            tmp[j] = j;\n\n        t = SUBFRAME_LEN / 2;\n\n        for (j = 0; j < pulses[i]; j++, idx++) {\n\n            int idx2 = cng_rand(&p->cng_random_seed, t);\n\n\n\n            pos[idx]  = tmp[idx2] * 2 + off[i];\n\n            tmp[idx2] = tmp[--t];\n\n        }\n\n    }\n\n\n\n    vector_ptr = p->audio + LPC_ORDER;\n\n    memcpy(vector_ptr, p->prev_excitation,\n\n           PITCH_MAX * sizeof(*p->excitation));\n\n    for (i = 0; i < SUBFRAMES; i += 2) {\n\n        ff_g723_1_gen_acb_excitation(vector_ptr, vector_ptr,\n\n                                     p->pitch_lag[i >> 1], &p->subframe[i],\n\n                                     p->cur_rate);\n\n        ff_g723_1_gen_acb_excitation(vector_ptr + SUBFRAME_LEN,\n\n                                     vector_ptr + SUBFRAME_LEN,\n\n                                     p->pitch_lag[i >> 1], &p->subframe[i + 1],\n\n                                     p->cur_rate);\n\n\n\n        t = 0;\n\n        for (j = 0; j < SUBFRAME_LEN * 2; j++)\n\n            t |= FFABS(vector_ptr[j]);\n\n        t = FFMIN(t, 0x7FFF);\n\n        if (!t) {\n\n            shift = 0;\n\n        } else {\n\n            shift = -10 + av_log2(t);\n\n            if (shift < -2)\n\n                shift = -2;\n\n        }\n\n        sum = 0;\n\n        if (shift < 0) {\n\n           for (j = 0; j < SUBFRAME_LEN * 2; j++) {\n\n               t      = vector_ptr[j] << -shift;\n\n               sum   += t * t;\n\n               tmp[j] = t;\n\n           }\n\n        } else {\n\n           for (j = 0; j < SUBFRAME_LEN * 2; j++) {\n\n               t      = vector_ptr[j] >> shift;\n\n               sum   += t * t;\n\n               tmp[j] = t;\n\n           }\n\n        }\n\n\n\n        b0 = 0;\n\n        for (j = 0; j < 11; j++)\n\n            b0 += tmp[pos[(i / 2) * 11 + j]] * signs[(i / 2) * 11 + j];\n\n        b0 = b0 * 2 * 2979LL + (1 << 29) >> 30; // approximated division by 11\n\n\n\n        c = p->cur_gain * (p->cur_gain * SUBFRAME_LEN >> 5);\n\n        if (shift * 2 + 3 >= 0)\n\n            c >>= shift * 2 + 3;\n\n        else\n\n            c <<= -(shift * 2 + 3);\n\n        c = (av_clipl_int32(sum << 1) - c) * 2979LL >> 15;\n\n\n\n        delta = b0 * b0 * 2 - c;\n\n        if (delta <= 0) {\n\n            x = -b0;\n\n        } else {\n\n            delta = square_root(delta);\n\n            x     = delta - b0;\n\n            t     = delta + b0;\n\n            if (FFABS(t) < FFABS(x))\n\n                x = -t;\n\n        }\n\n        shift++;\n\n        if (shift < 0)\n\n           x >>= -shift;\n\n        else\n\n           x <<= shift;\n\n        x = av_clip(x, -10000, 10000);\n\n\n\n        for (j = 0; j < 11; j++) {\n\n            idx = (i / 2) * 11 + j;\n\n            vector_ptr[pos[idx]] = av_clip_int16(vector_ptr[pos[idx]] +\n\n                                                 (x * signs[idx] >> 15));\n\n        }\n\n\n\n        /* copy decoded data to serve as a history for the next decoded subframes */\n\n        memcpy(vector_ptr + PITCH_MAX, vector_ptr,\n\n               sizeof(*vector_ptr) * SUBFRAME_LEN * 2);\n\n        vector_ptr += SUBFRAME_LEN * 2;\n\n    }\n\n    /* Save the excitation for the next frame */\n\n    memcpy(p->prev_excitation, p->audio + LPC_ORDER + FRAME_LEN,\n\n           PITCH_MAX * sizeof(*p->excitation));\n\n}\n", "idx": 25874}
{"project": "FFmpeg", "commit_id": "fd2982a0a01942091b2f08e17486ff4562f675a6", "target": 0, "func": "int av_read_pause(AVFormatContext *s)\n\n{\n\n    if (s->iformat->read_pause)\n\n        return s->iformat->read_pause(s);\n\n    if (s->pb && s->pb->read_pause)\n\n        return av_url_read_fpause(s->pb, 1);\n\n    return AVERROR(ENOSYS);\n\n}\n", "idx": 25877}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static int _get_transform_coeffs(uint8_t *exps, uint8_t *bap, float chcoeff,\n\n        float *samples, int start, int end, int dith_flag, GetBitContext *gb,\n\n        dither_state *state)\n\n{\n\n    int16_t mantissa;\n\n    int i;\n\n    int gcode;\n\n    mant_group l3_grp, l5_grp, l11_grp;\n\n\n\n    for (i = 0; i < 3; i++)\n\n        l3_grp.gcodes[i] = l5_grp.gcodes[i] = l11_grp.gcodes[i] = -1;\n\n    l3_grp.gcptr = l5_grp.gcptr = 3;\n\n    l11_grp.gcptr = 2;\n\n\n\n    i = 0;\n\n    while (i < start)\n\n        samples[i++] = 0;\n\n\n\n    for (i = start; i < end; i++) {\n\n        switch (bap[i]) {\n\n            case 0:\n\n                if (!dith_flag)\n\n                    mantissa = 0;\n\n                else\n\n                    mantissa = dither_int16(state);\n\n                samples[i] = to_float(exps[i], mantissa) * chcoeff;\n\n                break;\n\n\n\n            case 1:\n\n                if (l3_grp.gcptr > 2) {\n\n                    gcode = get_bits(gb, qntztab[1]);\n\n                    if (gcode > 26)\n\n                        return -1;\n\n                    l3_grp.gcodes[0] = gcode / 9;\n\n                    l3_grp.gcodes[1] = (gcode % 9) / 3;\n\n                    l3_grp.gcodes[2] = (gcode % 9) % 3;\n\n                    l3_grp.gcptr = 0;\n\n                }\n\n                mantissa = l3_q_tab[l3_grp.gcodes[l3_grp.gcptr++]];\n\n                samples[i] = to_float(exps[i], mantissa) * chcoeff;\n\n                break;\n\n\n\n            case 2:\n\n                if (l5_grp.gcptr > 2) {\n\n                    gcode = get_bits(gb, qntztab[2]);\n\n                    if (gcode > 124)\n\n                        return -1;\n\n                    l5_grp.gcodes[0] = gcode / 25;\n\n                    l5_grp.gcodes[1] = (gcode % 25) / 5;\n\n                    l5_grp.gcodes[2] = (gcode % 25) % 5;\n\n                    l5_grp.gcptr = 0;\n\n                }\n\n                mantissa = l5_q_tab[l5_grp.gcodes[l5_grp.gcptr++]];\n\n                samples[i] = to_float(exps[i], mantissa) * chcoeff;\n\n                break;\n\n\n\n            case 3:\n\n                mantissa = get_bits(gb, qntztab[3]);\n\n                if (mantissa > 6)\n\n                    return -1;\n\n                mantissa = l7_q_tab[mantissa];\n\n                samples[i] = to_float(exps[i], mantissa);\n\n                break;\n\n\n\n            case 4:\n\n                if (l11_grp.gcptr > 1) {\n\n                    gcode = get_bits(gb, qntztab[4]);\n\n                    if (gcode > 120)\n\n                        return -1;\n\n                    l11_grp.gcodes[0] = gcode / 11;\n\n                    l11_grp.gcodes[1] = gcode % 11;\n\n                }\n\n                mantissa = l11_q_tab[l11_grp.gcodes[l11_grp.gcptr++]];\n\n                samples[i] = to_float(exps[i], mantissa) * chcoeff;\n\n                break;\n\n\n\n            case 5:\n\n                mantissa = get_bits(gb, qntztab[5]);\n\n                if (mantissa > 14)\n\n                    return -1;\n\n                mantissa = l15_q_tab[mantissa];\n\n                samples[i] = to_float(exps[i], mantissa) * chcoeff;\n\n                break;\n\n\n\n            default:\n\n                mantissa = get_bits(gb, qntztab[bap[i]]) << (16 - qntztab[bap[i]]);\n\n                samples[i] = to_float(exps[i], mantissa) * chcoeff;\n\n                break;\n\n        }\n\n    }\n\n\n\n    i = end;\n\n    while (i < 256)\n\n        samples[i++] = 0;\n\n\n\n    return 0;\n\n}\n", "idx": 25881}
{"project": "FFmpeg", "commit_id": "0493e42eb2f9fbf42d0aee0b48a84f81f19fb7fa", "target": 0, "func": "static void DEF(avg, pixels8_y2)(uint8_t *block, const uint8_t *pixels, ptrdiff_t line_size, int h)\n\n{\n\n    MOVQ_BFE(mm6);\n\n    __asm__ volatile(\n\n        \"lea    (%3, %3), %%\"REG_a\"     \\n\\t\"\n\n        \"movq   (%1), %%mm0             \\n\\t\"\n\n        \".p2align 3                     \\n\\t\"\n\n        \"1:                             \\n\\t\"\n\n        \"movq   (%1, %3), %%mm1         \\n\\t\"\n\n        \"movq   (%1, %%\"REG_a\"), %%mm2  \\n\\t\"\n\n        PAVGBP(%%mm1, %%mm0, %%mm4,   %%mm2, %%mm1, %%mm5)\n\n        \"movq   (%2), %%mm3             \\n\\t\"\n\n        PAVGB_MMX(%%mm3, %%mm4, %%mm0, %%mm6)\n\n        \"movq   (%2, %3), %%mm3         \\n\\t\"\n\n        PAVGB_MMX(%%mm3, %%mm5, %%mm1, %%mm6)\n\n        \"movq   %%mm0, (%2)             \\n\\t\"\n\n        \"movq   %%mm1, (%2, %3)         \\n\\t\"\n\n        \"add    %%\"REG_a\", %1           \\n\\t\"\n\n        \"add    %%\"REG_a\", %2           \\n\\t\"\n\n\n\n        \"movq   (%1, %3), %%mm1         \\n\\t\"\n\n        \"movq   (%1, %%\"REG_a\"), %%mm0  \\n\\t\"\n\n        PAVGBP(%%mm1, %%mm2, %%mm4,   %%mm0, %%mm1, %%mm5)\n\n        \"movq   (%2), %%mm3             \\n\\t\"\n\n        PAVGB_MMX(%%mm3, %%mm4, %%mm2, %%mm6)\n\n        \"movq   (%2, %3), %%mm3         \\n\\t\"\n\n        PAVGB_MMX(%%mm3, %%mm5, %%mm1, %%mm6)\n\n        \"movq   %%mm2, (%2)             \\n\\t\"\n\n        \"movq   %%mm1, (%2, %3)         \\n\\t\"\n\n        \"add    %%\"REG_a\", %1           \\n\\t\"\n\n        \"add    %%\"REG_a\", %2           \\n\\t\"\n\n\n\n        \"subl   $4, %0                  \\n\\t\"\n\n        \"jnz    1b                      \\n\\t\"\n\n        :\"+g\"(h), \"+S\"(pixels), \"+D\"(block)\n\n        :\"r\"((x86_reg)line_size)\n\n        :REG_a, \"memory\");\n\n}\n", "idx": 25882}
{"project": "FFmpeg", "commit_id": "d5128fce38646d3f64c55feda42084888ba0e87e", "target": 1, "func": "static void decode_array_0000(APEContext *ctx, GetBitContext *gb,\n\n                              int32_t *out, APERice *rice, int blockstodecode)\n\n{\n\n    int i;\n\n    int ksummax, ksummin;\n\n\n\n    rice->ksum = 0;\n\n    for (i = 0; i < 5; i++) {\n\n        out[i] = get_rice_ook(&ctx->gb, 10);\n\n        rice->ksum += out[i];\n\n    }\n\n    rice->k = av_log2(rice->ksum / 10) + 1;\n\n\n\n    for (; i < 64; i++) {\n\n        out[i] = get_rice_ook(&ctx->gb, rice->k);\n\n        rice->ksum += out[i];\n\n        rice->k = av_log2(rice->ksum / ((i + 1) * 2)) + 1;\n\n\n\n    }\n\n    ksummax = 1 << rice->k + 7;\n\n    ksummin = rice->k ? (1 << rice->k + 6) : 0;\n\n    for (; i < blockstodecode; i++) {\n\n        out[i] = get_rice_ook(&ctx->gb, rice->k);\n\n        rice->ksum += out[i] - out[i - 64];\n\n        while (rice->ksum < ksummin) {\n\n            rice->k--;\n\n            ksummin = rice->k ? ksummin >> 1 : 0;\n\n            ksummax >>= 1;\n\n        }\n\n        while (rice->ksum >= ksummax) {\n\n            rice->k++;\n\n            if (rice->k > 24)\n\n\n            ksummax <<= 1;\n\n            ksummin = ksummin ? ksummin << 1 : 128;\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < blockstodecode; i++) {\n\n        if (out[i] & 1)\n\n            out[i] = (out[i] >> 1) + 1;\n\n        else\n\n            out[i] = -(out[i] >> 1);\n\n    }\n\n}", "idx": 25883}
{"project": "FFmpeg", "commit_id": "aac8b76983e340bc744d3542d676f72efa3b474f", "target": 0, "func": "static void filter_mb_edgeh( H264Context *h, uint8_t *pix, int stride, int16_t bS[4], int qp ) {\n\n    int i, d;\n\n    const int index_a = qp + h->slice_alpha_c0_offset;\n\n    const int alpha = (alpha_table+52)[index_a];\n\n    const int beta  = (beta_table+52)[qp + h->slice_beta_offset];\n\n    const int pix_next  = stride;\n\n\n\n    if( bS[0] < 4 ) {\n\n        int8_t tc[4];\n\n        for(i=0; i<4; i++)\n\n            tc[i] = bS[i] ? (tc0_table+52)[index_a][bS[i] - 1] : -1;\n\n        h->s.dsp.h264_v_loop_filter_luma(pix, stride, alpha, beta, tc);\n\n    } else {\n\n        h->s.dsp.h264_v_loop_filter_luma_intra(pix, stride, alpha, beta);\n\n    }\n\n}\n", "idx": 25884}
{"project": "FFmpeg", "commit_id": "53ea595eec984e3109310e8bb7ff4b5786d91057", "target": 1, "func": "static int mov_seek_stream(AVFormatContext *s, AVStream *st, int64_t timestamp, int flags)\n\n{\n\n    MOVStreamContext *sc = st->priv_data;\n\n    int sample, time_sample;\n\n    int i;\n\n\n\n    sample = av_index_search_timestamp(st, timestamp, flags);\n\n    av_log(s, AV_LOG_TRACE, \"stream %d, timestamp %\"PRId64\", sample %d\\n\", st->index, timestamp, sample);\n\n    if (sample < 0 && st->nb_index_entries && timestamp < st->index_entries[0].timestamp)\n\n        sample = 0;\n\n    if (sample < 0) /* not sure what to do */\n\n        return AVERROR_INVALIDDATA;\n\n    sc->current_sample = sample;\n\n    av_log(s, AV_LOG_TRACE, \"stream %d, found sample %d\\n\", st->index, sc->current_sample);\n\n    /* adjust ctts index */\n\n    if (sc->ctts_data) {\n\n        time_sample = 0;\n\n        for (i = 0; i < sc->ctts_count; i++) {\n\n            int next = time_sample + sc->ctts_data[i].count;\n\n            if (next > sc->current_sample) {\n\n                sc->ctts_index = i;\n\n                sc->ctts_sample = sc->current_sample - time_sample;\n\n                break;\n\n            }\n\n            time_sample = next;\n\n        }\n\n    }\n\n\n\n    /* adjust stsd index */\n\n    time_sample = 0;\n\n    for (i = 0; i < sc->stsc_count; i++) {\n\n        int next = time_sample + mov_get_stsc_samples(sc, i);\n\n        if (next > sc->current_sample) {\n\n            sc->stsc_index = i;\n\n            sc->stsc_sample = sc->current_sample - time_sample;\n\n            break;\n\n        }\n\n        time_sample = next;\n\n    }\n\n\n\n    return sample;\n\n}\n", "idx": 25887}
{"project": "FFmpeg", "commit_id": "7cc84d241ba6ef8e27e4d057176a4ad385ad3d59", "target": 1, "func": "static int advanced_decode_i_mbs(VC9Context *v)\n\n{\n\n    MpegEncContext *s = &v->s;\n\n    GetBitContext *gb = &v->s.gb;\n\n    int mqdiff, mquant, current_mb = 0, over_flags_mb = 0;\n\n\n\n    for (s->mb_y=0; s->mb_y<s->mb_height; s->mb_y++)\n\n    {\n\n        for (s->mb_x=0; s->mb_x<s->mb_width; s->mb_x++)\n\n        {\n\n            if (v->ac_pred_plane.is_raw)\n\n                s->ac_pred = get_bits(gb, 1);\n\n            else\n\n                s->ac_pred = v->ac_pred_plane.data[current_mb];\n\n            if (v->condover == 3 && v->over_flags_plane.is_raw)\n\n                over_flags_mb = get_bits(gb, 1);\n\n            GET_MQUANT();\n\n\n\n            /* TODO: lots */\n\n        }\n\n        current_mb++;\n\n    }\n\n    return 0;\n\n}\n", "idx": 25888}
{"project": "FFmpeg", "commit_id": "44f1698a3824836d32708ae93e78ac1f2310a07e", "target": 1, "func": "static void imdct12(int *out, int *in)\n\n{\n\n    int in0, in1, in2, in3, in4, in5, t1, t2;\n\n    in0= in[0*3]<<5;\n\n    in1= (in[1*3] + in[0*3])<<5;\n\n    in2= (in[2*3] + in[1*3])<<5;\n\n    in3= (in[3*3] + in[2*3])<<5;\n\n    in4= (in[4*3] + in[3*3])<<5;\n\n    in5= (in[5*3] + in[4*3])<<5;\n\n    in5 += in3;\n\n    in3 += in1;\n\n\n\n    in2= MULH(2*in2, C3);\n\n    in3= MULH(2*in3, C3);\n\n    \n\n    t1 = in0 - in4;\n\n    t2 = MULL(in1 - in5, icos36[4]);\n\n\n\n    out[ 7]= \n\n    out[10]= t1 + t2;\n\n    out[ 1]=\n\n    out[ 4]= t1 - t2;\n\n\n\n    in0 += in4>>1;\n\n    in4 = in0 + in2;\n\n    in1 += in5>>1;\n\n    in5 = MULL(in1 + in3, icos36[1]);    \n\n    out[ 8]= \n\n    out[ 9]= in4 + in5;\n\n    out[ 2]=\n\n    out[ 3]= in4 - in5;\n\n    \n\n    in0 -= in2;\n\n    in1 = MULL(in1 - in3, icos36[7]);\n\n    out[ 0]=\n\n    out[ 5]= in0 - in1;\n\n    out[ 6]=\n\n    out[11]= in0 + in1;    \n\n}\n", "idx": 25889}
{"project": "FFmpeg", "commit_id": "428098165de4c3edfe42c1b7f00627d287015863", "target": 1, "func": "static int altivec_uyvy_rgb32 (SwsContext *c,\n\n\t\t\t       unsigned char **in, int *instrides,\n\n\t\t\t       int srcSliceY,\tint srcSliceH,\n\n\t\t\t       unsigned char **oplanes, int *outstrides)\n\n{\n\n  int w = c->srcW;\n\n  int h = srcSliceH;\n\n  int i,j;\n\n  vector unsigned char uyvy;\n\n  vector signed   short Y,U,V;\n\n  vector signed   short R0,G0,B0,R1,G1,B1;\n\n  vector unsigned char  R,G,B;\n\n  vector unsigned char *out;\n\n  ubyte *img;\n\n\n\n  img = in[0];\n\n  out = (vector unsigned char *)(oplanes[0]+srcSliceY*outstrides[0]);\n\n\n\n  for (i=0;i<h;i++) {\n\n    for (j=0;j<w/16;j++) {\n\n      uyvy = vec_ld (0, img);\n\n      U = (vector signed short)\n\n\tvec_perm (uyvy, (vector unsigned char)AVV(0), demux_u);\n\n\n\n      V = (vector signed short)\n\n\tvec_perm (uyvy, (vector unsigned char)AVV(0), demux_v);\n\n\n\n      Y = (vector signed short)\n\n\tvec_perm (uyvy, (vector unsigned char)AVV(0), demux_y);\n\n\n\n      cvtyuvtoRGB (c, Y,U,V,&R0,&G0,&B0);\n\n\n\n      uyvy = vec_ld (16, img);\n\n      U = (vector signed short)\n\n\tvec_perm (uyvy, (vector unsigned char)AVV(0), demux_u);\n\n\n\n      V = (vector signed short)\n\n\tvec_perm (uyvy, (vector unsigned char)AVV(0), demux_v);\n\n\n\n      Y = (vector signed short)\n\n\tvec_perm (uyvy, (vector unsigned char)AVV(0), demux_y);\n\n\n\n      cvtyuvtoRGB (c, Y,U,V,&R1,&G1,&B1);\n\n\n\n      R  = vec_packclp (R0,R1);\n\n      G  = vec_packclp (G0,G1);\n\n      B  = vec_packclp (B0,B1);\n\n\n\n      //      vec_mstbgr24 (R,G,B, out);\n\n      out_rgba (R,G,B,out);\n\n\n\n      img += 32;\n\n    }\n\n  }\n\n  return srcSliceH;\n\n}\n", "idx": 25890}
{"project": "FFmpeg", "commit_id": "38d553322891c8e47182f05199d19888422167dc", "target": 1, "func": "static void start_frame(AVFilterLink *inlink, AVFilterBufferRef *picref)\n\n{\n\n    PixdescTestContext *priv = inlink->dst->priv;\n\n    AVFilterLink *outlink    = inlink->dst->outputs[0];\n\n    AVFilterBufferRef *outpicref;\n\n    int i;\n\n\n\n    outlink->out_buf = avfilter_get_video_buffer(outlink, AV_PERM_WRITE,\n\n                                                outlink->w, outlink->h);\n\n    outpicref = outlink->out_buf;\n\n    avfilter_copy_buffer_ref_props(outpicref, picref);\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        int h = outlink->h;\n\n        h = i == 1 || i == 2 ? h>>priv->pix_desc->log2_chroma_h : h;\n\n        if (outpicref->data[i]) {\n\n            uint8_t *data = outpicref->data[i] +\n\n                (outpicref->linesize[i] > 0 ? 0 : outpicref->linesize[i] * (h-1));\n\n            memset(data, 0, FFABS(outpicref->linesize[i]) * h);\n\n        }\n\n    }\n\n\n\n    /* copy palette */\n\n    if (priv->pix_desc->flags & PIX_FMT_PAL)\n\n        memcpy(outpicref->data[1], outpicref->data[1], 256*4);\n\n\n\n    avfilter_start_frame(outlink, avfilter_ref_buffer(outpicref, ~0));\n\n}\n", "idx": 25894}
{"project": "FFmpeg", "commit_id": "fc49f22c3b735db5aaac5f98e40b7124a2be13b8", "target": 1, "func": "void av_noreturn exit_program(int ret)\n\n{\n\n    int i, j;\n\n\n\n    for (i = 0; i < nb_filtergraphs; i++) {\n\n        avfilter_graph_free(&filtergraphs[i]->graph);\n\n        for (j = 0; j < filtergraphs[i]->nb_inputs; j++)\n\n            av_freep(&filtergraphs[i]->inputs[j]);\n\n        av_freep(&filtergraphs[i]->inputs);\n\n        for (j = 0; j < filtergraphs[i]->nb_outputs; j++)\n\n            av_freep(&filtergraphs[i]->outputs[j]);\n\n        av_freep(&filtergraphs[i]->outputs);\n\n        av_freep(&filtergraphs[i]);\n\n    }\n\n    av_freep(&filtergraphs);\n\n\n\n    /* close files */\n\n    for (i = 0; i < nb_output_files; i++) {\n\n        AVFormatContext *s = output_files[i]->ctx;\n\n        if (!(s->oformat->flags & AVFMT_NOFILE) && s->pb)\n\n            avio_close(s->pb);\n\n        avformat_free_context(s);\n\n        av_dict_free(&output_files[i]->opts);\n\n        av_freep(&output_files[i]);\n\n    }\n\n    for (i = 0; i < nb_output_streams; i++) {\n\n        AVBitStreamFilterContext *bsfc = output_streams[i]->bitstream_filters;\n\n        while (bsfc) {\n\n            AVBitStreamFilterContext *next = bsfc->next;\n\n            av_bitstream_filter_close(bsfc);\n\n            bsfc = next;\n\n        }\n\n        output_streams[i]->bitstream_filters = NULL;\n\n\n\n        if (output_streams[i]->output_frame) {\n\n            AVFrame *frame = output_streams[i]->output_frame;\n\n            if (frame->extended_data != frame->data)\n\n                av_freep(&frame->extended_data);\n\n            av_freep(&frame);\n\n        }\n\n        av_freep(&output_streams[i]->filtered_frame);\n\n        av_freep(&output_streams[i]);\n\n    }\n\n    for (i = 0; i < nb_input_files; i++) {\n\n        avformat_close_input(&input_files[i]->ctx);\n\n        av_freep(&input_files[i]);\n\n    }\n\n    for (i = 0; i < nb_input_streams; i++) {\n\n        av_freep(&input_streams[i]->decoded_frame);\n\n        av_dict_free(&input_streams[i]->opts);\n\n        free_buffer_pool(input_streams[i]);\n\n        av_freep(&input_streams[i]->filters);\n\n        av_freep(&input_streams[i]);\n\n    }\n\n\n\n    if (vstats_file)\n\n        fclose(vstats_file);\n\n    av_free(vstats_filename);\n\n\n\n    av_freep(&input_streams);\n\n    av_freep(&input_files);\n\n    av_freep(&output_streams);\n\n    av_freep(&output_files);\n\n\n\n    uninit_opts();\n\n    av_freep(&audio_buf);\n\n    allocated_audio_buf_size = 0;\n\n    av_freep(&async_buf);\n\n    allocated_async_buf_size = 0;\n\n\n\n    avfilter_uninit();\n\n    avformat_network_deinit();\n\n\n\n    if (received_sigterm) {\n\n        av_log(NULL, AV_LOG_INFO, \"Received signal %d: terminating.\\n\",\n\n               (int) received_sigterm);\n\n        exit (255);\n\n    }\n\n\n\n    exit(ret); /* not all OS-es handle main() return value */\n\n}\n", "idx": 25895}
{"project": "FFmpeg", "commit_id": "229843aa359ae0c9519977d7fa952688db63f559", "target": 0, "func": "static int mov_read_aclr(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    int ret = 0;\n\n    int length = 0;\n\n    uint64_t original_size;\n\n    if (c->fc->nb_streams >= 1) {\n\n        AVCodecContext *codec = c->fc->streams[c->fc->nb_streams-1]->codec;\n\n        if (codec->codec_id == AV_CODEC_ID_H264)\n\n            return 0;\n\n        if (atom.size == 16) {\n\n            original_size = codec->extradata_size;\n\n            ret = mov_realloc_extradata(codec, atom);\n\n            if (!ret) {\n\n                length =  mov_read_atom_into_extradata(c, pb, atom, codec, codec->extradata + original_size);\n\n                if (length == atom.size) {\n\n                    const uint8_t range_value = codec->extradata[original_size + 19];\n\n                    switch (range_value) {\n\n                    case 1:\n\n                        codec->color_range = AVCOL_RANGE_MPEG;\n\n                        break;\n\n                    case 2:\n\n                        codec->color_range = AVCOL_RANGE_JPEG;\n\n                        break;\n\n                    default:\n\n                        av_log(c, AV_LOG_WARNING, \"ignored unknown aclr value (%d)\\n\", range_value);\n\n                        break;\n\n                    }\n\n                    av_dlog(c, \"color_range: %d\\n\", codec->color_range);\n\n                } else {\n\n                  /* For some reason the whole atom was not added to the extradata */\n\n                  av_log(c, AV_LOG_ERROR, \"aclr not decoded - incomplete atom\\n\");\n\n                }\n\n            } else {\n\n                av_log(c, AV_LOG_ERROR, \"aclr not decoded - unable to add atom to extradata\\n\");\n\n            }\n\n        } else {\n\n            av_log(c, AV_LOG_WARNING, \"aclr not decoded - unexpected size %\"PRId64\"\\n\", atom.size);\n\n        }\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 25897}
{"project": "FFmpeg", "commit_id": "e9266a2be04ea505285e32e411ef6120e9cbeba4", "target": 0, "func": "static av_always_inline void filter_level_for_mb(VP8Context *s, VP8Macroblock *mb, VP8FilterStrength *f )\n\n{\n\n    int interior_limit, filter_level;\n\n\n\n    if (s->segmentation.enabled) {\n\n        filter_level = s->segmentation.filter_level[s->segment];\n\n        if (!s->segmentation.absolute_vals)\n\n            filter_level += s->filter.level;\n\n    } else\n\n        filter_level = s->filter.level;\n\n\n\n    if (s->lf_delta.enabled) {\n\n        filter_level += s->lf_delta.ref[mb->ref_frame];\n\n        filter_level += s->lf_delta.mode[mb->mode];\n\n    }\n\n\n\n/* Like av_clip for inputs 0 and max, where max is equal to (2^n-1) */\n\n#define POW2CLIP(x,max) (((x) & ~max) ? (-(x))>>31 & max : (x));\n\n    filter_level = POW2CLIP(filter_level, 63);\n\n\n\n    interior_limit = filter_level;\n\n    if (s->filter.sharpness) {\n\n        interior_limit >>= s->filter.sharpness > 4 ? 2 : 1;\n\n        interior_limit = FFMIN(interior_limit, 9 - s->filter.sharpness);\n\n    }\n\n    interior_limit = FFMAX(interior_limit, 1);\n\n\n\n    f->filter_level = filter_level;\n\n    f->inner_limit = interior_limit;\n\n    f->inner_filter = !mb->skip || mb->mode == MODE_I4x4 || mb->mode == VP8_MVMODE_SPLIT;\n\n}\n", "idx": 25898}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "void rgb15tobgr16(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n\tlong i;\n\n\tlong num_pixels = src_size >> 1;\n\n\n\n\tfor(i=0; i<num_pixels; i++)\n\n\t{\n\n\t    unsigned b,g,r;\n\n\t    register uint16_t rgb;\n\n\t    rgb = src[2*i];\n\n\t    r = rgb&0x1F;\n\n\t    g = (rgb&0x3E0)>>5;\n\n\t    b = (rgb&0x7C00)>>10;\n\n\t    dst[2*i] = (b&0x1F) | ((g&0x3F)<<5) | ((r&0x1F)<<11);\n\n\t}\n\n}\n", "idx": 25899}
{"project": "FFmpeg", "commit_id": "39bb30f6640fe1faf4bbc779a79786028febc95d", "target": 1, "func": "static int mxf_read_index_table_segment(MXFIndexTableSegment *segment, ByteIOContext *pb, int tag)\n\n{\n\n    switch(tag) {\n\n    case 0x3F05: dprintf(NULL, \"EditUnitByteCount %d\\n\", get_be32(pb)); break;\n\n    case 0x3F06: dprintf(NULL, \"IndexSID %d\\n\", get_be32(pb)); break;\n\n    case 0x3F07: dprintf(NULL, \"BodySID %d\\n\", get_be32(pb)); break;\n\n    case 0x3F0B: dprintf(NULL, \"IndexEditRate %d/%d\\n\", get_be32(pb), get_be32(pb)); break;\n\n    case 0x3F0C: dprintf(NULL, \"IndexStartPosition %lld\\n\", get_be64(pb)); break;\n\n    case 0x3F0D: dprintf(NULL, \"IndexDuration %lld\\n\", get_be64(pb)); break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 25901}
{"project": "FFmpeg", "commit_id": "13a099799e89a76eb921ca452e1b04a7a28a9855", "target": 0, "func": "static void yuv2nv12X_c(SwsContext *c, const int16_t *lumFilter,\n\n                        const int16_t **lumSrc, int lumFilterSize,\n\n                        const int16_t *chrFilter, const int16_t **chrUSrc,\n\n                        const int16_t **chrVSrc, int chrFilterSize,\n\n                        const int16_t **alpSrc, uint8_t *dest, uint8_t *uDest,\n\n                        uint8_t *vDest, uint8_t *aDest,\n\n                        int dstW, int chrDstW)\n\n{\n\n    enum PixelFormat dstFormat = c->dstFormat;\n\n\n\n    //FIXME Optimize (just quickly written not optimized..)\n\n    int i;\n\n    for (i=0; i<dstW; i++) {\n\n        int val=1<<18;\n\n        int j;\n\n        for (j=0; j<lumFilterSize; j++)\n\n            val += lumSrc[j][i] * lumFilter[j];\n\n\n\n        dest[i]= av_clip_uint8(val>>19);\n\n    }\n\n\n\n    if (!uDest)\n\n        return;\n\n\n\n    if (dstFormat == PIX_FMT_NV12)\n\n        for (i=0; i<chrDstW; i++) {\n\n            int u=1<<18;\n\n            int v=1<<18;\n\n            int j;\n\n            for (j=0; j<chrFilterSize; j++) {\n\n                u += chrUSrc[j][i] * chrFilter[j];\n\n                v += chrVSrc[j][i] * chrFilter[j];\n\n            }\n\n\n\n            uDest[2*i]= av_clip_uint8(u>>19);\n\n            uDest[2*i+1]= av_clip_uint8(v>>19);\n\n        }\n\n    else\n\n        for (i=0; i<chrDstW; i++) {\n\n            int u=1<<18;\n\n            int v=1<<18;\n\n            int j;\n\n            for (j=0; j<chrFilterSize; j++) {\n\n                u += chrUSrc[j][i] * chrFilter[j];\n\n                v += chrVSrc[j][i] * chrFilter[j];\n\n            }\n\n\n\n            uDest[2*i]= av_clip_uint8(v>>19);\n\n            uDest[2*i+1]= av_clip_uint8(u>>19);\n\n        }\n\n}\n", "idx": 25905}
{"project": "FFmpeg", "commit_id": "9243ec4a508c81a621e941bb7e012e2d45d93659", "target": 1, "func": "static int rv10_decode_packet(AVCodecContext *avctx,\n\n                             const uint8_t *buf, int buf_size, int buf_size2)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int mb_count, mb_pos, left, start_mb_x;\n\n\n\n    init_get_bits(&s->gb, buf, buf_size*8);\n\n    if(s->codec_id ==CODEC_ID_RV10)\n\n        mb_count = rv10_decode_picture_header(s);\n\n    else\n\n        mb_count = rv20_decode_picture_header(s);\n\n    if (mb_count < 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"HEADER ERROR\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (s->mb_x >= s->mb_width ||\n\n        s->mb_y >= s->mb_height) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"POS ERROR %d %d\\n\", s->mb_x, s->mb_y);\n\n        return -1;\n\n    }\n\n    mb_pos = s->mb_y * s->mb_width + s->mb_x;\n\n    left = s->mb_width * s->mb_height - mb_pos;\n\n    if (mb_count > left) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"COUNT ERROR\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if ((s->mb_x == 0 && s->mb_y == 0) || s->current_picture_ptr==NULL) {\n\n        if(s->current_picture_ptr){ //FIXME write parser so we always have complete frames?\n\n            ff_er_frame_end(s);\n\n            ff_MPV_frame_end(s);\n\n            s->mb_x= s->mb_y = s->resync_mb_x = s->resync_mb_y= 0;\n\n        }\n\n        if(ff_MPV_frame_start(s, avctx) < 0)\n\n            return -1;\n\n        ff_er_frame_start(s);\n\n    } else {\n\n        if (s->current_picture_ptr->f.pict_type != s->pict_type) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Slice type mismatch\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    av_dlog(avctx, \"qscale=%d\\n\", s->qscale);\n\n\n\n    /* default quantization values */\n\n    if(s->codec_id== CODEC_ID_RV10){\n\n        if(s->mb_y==0) s->first_slice_line=1;\n\n    }else{\n\n        s->first_slice_line=1;\n\n        s->resync_mb_x= s->mb_x;\n\n    }\n\n    start_mb_x= s->mb_x;\n\n    s->resync_mb_y= s->mb_y;\n\n    if(s->h263_aic){\n\n        s->y_dc_scale_table=\n\n        s->c_dc_scale_table= ff_aic_dc_scale_table;\n\n    }else{\n\n        s->y_dc_scale_table=\n\n        s->c_dc_scale_table= ff_mpeg1_dc_scale_table;\n\n    }\n\n\n\n    if(s->modified_quant)\n\n        s->chroma_qscale_table= ff_h263_chroma_qscale_table;\n\n\n\n    ff_set_qscale(s, s->qscale);\n\n\n\n    s->rv10_first_dc_coded[0] = 0;\n\n    s->rv10_first_dc_coded[1] = 0;\n\n    s->rv10_first_dc_coded[2] = 0;\n\n    s->block_wrap[0]=\n\n    s->block_wrap[1]=\n\n    s->block_wrap[2]=\n\n    s->block_wrap[3]= s->b8_stride;\n\n    s->block_wrap[4]=\n\n    s->block_wrap[5]= s->mb_stride;\n\n    ff_init_block_index(s);\n\n    /* decode each macroblock */\n\n\n\n    for(s->mb_num_left= mb_count; s->mb_num_left>0; s->mb_num_left--) {\n\n        int ret;\n\n        ff_update_block_index(s);\n\n        av_dlog(avctx, \"**mb x=%d y=%d\\n\", s->mb_x, s->mb_y);\n\n\n\n        s->mv_dir = MV_DIR_FORWARD;\n\n        s->mv_type = MV_TYPE_16X16;\n\n        ret=ff_h263_decode_mb(s, s->block);\n\n\n\n        if (ret != SLICE_ERROR && s->gb.size_in_bits < get_bits_count(&s->gb) && 8*buf_size2 >= get_bits_count(&s->gb)){\n\n            av_log(avctx, AV_LOG_DEBUG, \"update size from %d to %d\\n\", s->gb.size_in_bits, 8*buf_size2);\n\n            s->gb.size_in_bits= 8*buf_size2;\n\n            ret= SLICE_OK;\n\n        }\n\n\n\n        if (ret == SLICE_ERROR || s->gb.size_in_bits < get_bits_count(&s->gb)) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"ERROR at MB %d %d\\n\", s->mb_x, s->mb_y);\n\n            return -1;\n\n        }\n\n        if(s->pict_type != AV_PICTURE_TYPE_B)\n\n            ff_h263_update_motion_val(s);\n\n        ff_MPV_decode_mb(s, s->block);\n\n        if(s->loop_filter)\n\n            ff_h263_loop_filter(s);\n\n\n\n        if (++s->mb_x == s->mb_width) {\n\n            s->mb_x = 0;\n\n            s->mb_y++;\n\n            ff_init_block_index(s);\n\n        }\n\n        if(s->mb_x == s->resync_mb_x)\n\n            s->first_slice_line=0;\n\n        if(ret == SLICE_END) break;\n\n    }\n\n\n\n    ff_er_add_slice(s, start_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, ER_MB_END);\n\n\n\n    return s->gb.size_in_bits;\n\n}\n", "idx": 25907}
{"project": "FFmpeg", "commit_id": "6179dc8aa7e5fc5358b9614306f93f1adadf22a4", "target": 1, "func": "static void gmc1_motion(MpegEncContext *s,\n\n                        uint8_t *dest_y, uint8_t *dest_cb, uint8_t *dest_cr,\n\n                        uint8_t **ref_picture)\n\n{\n\n    uint8_t *ptr;\n\n    int src_x, src_y, motion_x, motion_y;\n\n    ptrdiff_t offset, linesize, uvlinesize;\n\n    int emu = 0;\n\n\n\n    motion_x   = s->sprite_offset[0][0];\n\n    motion_y   = s->sprite_offset[0][1];\n\n    src_x      = s->mb_x * 16 + (motion_x >> (s->sprite_warping_accuracy + 1));\n\n    src_y      = s->mb_y * 16 + (motion_y >> (s->sprite_warping_accuracy + 1));\n\n    motion_x <<= (3 - s->sprite_warping_accuracy);\n\n    motion_y <<= (3 - s->sprite_warping_accuracy);\n\n    src_x      = av_clip(src_x, -16, s->width);\n\n    if (src_x == s->width)\n\n        motion_x = 0;\n\n    src_y = av_clip(src_y, -16, s->height);\n\n    if (src_y == s->height)\n\n        motion_y = 0;\n\n\n\n    linesize   = s->linesize;\n\n    uvlinesize = s->uvlinesize;\n\n\n\n    ptr = ref_picture[0] + src_y * linesize + src_x;\n\n\n\n    if ((unsigned)src_x >= FFMAX(s->h_edge_pos - 17, 0) ||\n\n        (unsigned)src_y >= FFMAX(s->v_edge_pos - 17, 0)) {\n\n        s->vdsp.emulated_edge_mc(s->sc.edge_emu_buffer, ptr,\n\n                                 linesize, linesize,\n\n                                 17, 17,\n\n                                 src_x, src_y,\n\n                                 s->h_edge_pos, s->v_edge_pos);\n\n        ptr = s->sc.edge_emu_buffer;\n\n    }\n\n\n\n    if ((motion_x | motion_y) & 7) {\n\n        s->mdsp.gmc1(dest_y, ptr, linesize, 16,\n\n                     motion_x & 15, motion_y & 15, 128 - s->no_rounding);\n\n        s->mdsp.gmc1(dest_y + 8, ptr + 8, linesize, 16,\n\n                     motion_x & 15, motion_y & 15, 128 - s->no_rounding);\n\n    } else {\n\n        int dxy;\n\n\n\n        dxy = ((motion_x >> 3) & 1) | ((motion_y >> 2) & 2);\n\n        if (s->no_rounding) {\n\n            s->hdsp.put_no_rnd_pixels_tab[0][dxy](dest_y, ptr, linesize, 16);\n\n        } else {\n\n            s->hdsp.put_pixels_tab[0][dxy](dest_y, ptr, linesize, 16);\n\n        }\n\n    }\n\n\n\n    if (CONFIG_GRAY && s->avctx->flags & AV_CODEC_FLAG_GRAY)\n\n        return;\n\n\n\n    motion_x   = s->sprite_offset[1][0];\n\n    motion_y   = s->sprite_offset[1][1];\n\n    src_x      = s->mb_x * 8 + (motion_x >> (s->sprite_warping_accuracy + 1));\n\n    src_y      = s->mb_y * 8 + (motion_y >> (s->sprite_warping_accuracy + 1));\n\n    motion_x <<= (3 - s->sprite_warping_accuracy);\n\n    motion_y <<= (3 - s->sprite_warping_accuracy);\n\n    src_x      = av_clip(src_x, -8, s->width >> 1);\n\n    if (src_x == s->width >> 1)\n\n        motion_x = 0;\n\n    src_y = av_clip(src_y, -8, s->height >> 1);\n\n    if (src_y == s->height >> 1)\n\n        motion_y = 0;\n\n\n\n    offset = (src_y * uvlinesize) + src_x;\n\n    ptr    = ref_picture[1] + offset;\n\n    if ((unsigned)src_x >= FFMAX((s->h_edge_pos >> 1) - 9, 0) ||\n\n        (unsigned)src_y >= FFMAX((s->v_edge_pos >> 1) - 9, 0)) {\n\n        s->vdsp.emulated_edge_mc(s->sc.edge_emu_buffer, ptr,\n\n                                 uvlinesize, uvlinesize,\n\n                                 9, 9,\n\n                                 src_x, src_y,\n\n                                 s->h_edge_pos >> 1, s->v_edge_pos >> 1);\n\n        ptr = s->sc.edge_emu_buffer;\n\n        emu = 1;\n\n    }\n\n    s->mdsp.gmc1(dest_cb, ptr, uvlinesize, 8,\n\n                 motion_x & 15, motion_y & 15, 128 - s->no_rounding);\n\n\n\n    ptr = ref_picture[2] + offset;\n\n    if (emu) {\n\n        s->vdsp.emulated_edge_mc(s->sc.edge_emu_buffer, ptr,\n\n                                 uvlinesize, uvlinesize,\n\n                                 9, 9,\n\n                                 src_x, src_y,\n\n                                 s->h_edge_pos >> 1, s->v_edge_pos >> 1);\n\n        ptr = s->sc.edge_emu_buffer;\n\n    }\n\n    s->mdsp.gmc1(dest_cr, ptr, uvlinesize, 8,\n\n                 motion_x & 15, motion_y & 15, 128 - s->no_rounding);\n\n}\n", "idx": 25912}
{"project": "FFmpeg", "commit_id": "0e15b7b0dde44130069739bfb98c29e74c72be86", "target": 0, "func": "static void gxf_write_padding(ByteIOContext *pb, offset_t to_pad)\n\n{\n\n    while (to_pad--) {\n\n        put_byte(pb, 0);\n\n    }\n\n}\n", "idx": 25914}
{"project": "FFmpeg", "commit_id": "3941df546276b190cc9362fd093e6721e8e52f50", "target": 0, "func": "static int aea_read_header(AVFormatContext *s)\n\n{\n\n    AVStream *st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    /* Parse the amount of channels and skip to pos 2048(0x800) */\n\n    avio_skip(s->pb, 264);\n\n    st->codec->channels = avio_r8(s->pb);\n\n    avio_skip(s->pb, 1783);\n\n\n\n\n\n    st->codec->codec_type     = AVMEDIA_TYPE_AUDIO;\n\n    st->codec->codec_id       = AV_CODEC_ID_ATRAC1;\n\n    st->codec->sample_rate    = 44100;\n\n    st->codec->bit_rate       = 292000;\n\n\n\n    if (st->codec->channels != 1 && st->codec->channels != 2) {\n\n        av_log(s,AV_LOG_ERROR,\"Channels %d not supported!\\n\",st->codec->channels);\n\n        return -1;\n\n    }\n\n\n\n    st->codec->channel_layout = (st->codec->channels == 1) ? AV_CH_LAYOUT_MONO : AV_CH_LAYOUT_STEREO;\n\n\n\n    st->codec->block_align = AT1_SU_SIZE * st->codec->channels;\n\n    return 0;\n\n}\n", "idx": 25915}
{"project": "FFmpeg", "commit_id": "43abef9fde0cf87153cc9031cad61f75b02cfa01", "target": 0, "func": "static int rpl_read_header(AVFormatContext *s, AVFormatParameters *ap)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    RPLContext *rpl = s->priv_data;\n\n    AVStream *vst = NULL, *ast = NULL;\n\n    int total_audio_size;\n\n    int error = 0;\n\n\n\n    uint32_t i;\n\n\n\n    int32_t audio_format, chunk_catalog_offset, number_of_chunks;\n\n    AVRational fps;\n\n\n\n    char line[RPL_LINE_LENGTH];\n\n\n\n    // The header for RPL/ARMovie files is 21 lines of text\n\n    // containing the various header fields.  The fields are always\n\n    // in the same order, and other text besides the first\n\n    // number usually isn't important.\n\n    // (The spec says that there exists some significance\n\n    // for the text in a few cases; samples needed.)\n\n    error |= read_line(pb, line, sizeof(line));      // ARMovie\n\n    error |= read_line(pb, line, sizeof(line));      // movie name\n\n    av_dict_set(&s->metadata, \"title\"    , line, 0);\n\n    error |= read_line(pb, line, sizeof(line));      // date/copyright\n\n    av_dict_set(&s->metadata, \"copyright\", line, 0);\n\n    error |= read_line(pb, line, sizeof(line));      // author and other\n\n    av_dict_set(&s->metadata, \"author\"   , line, 0);\n\n\n\n    // video headers\n\n    vst = avformat_new_stream(s, NULL);\n\n    if (!vst)\n\n        return AVERROR(ENOMEM);\n\n    vst->codec->codec_type      = AVMEDIA_TYPE_VIDEO;\n\n    vst->codec->codec_tag       = read_line_and_int(pb, &error);  // video format\n\n    vst->codec->width           = read_line_and_int(pb, &error);  // video width\n\n    vst->codec->height          = read_line_and_int(pb, &error);  // video height\n\n    vst->codec->bits_per_coded_sample = read_line_and_int(pb, &error);  // video bits per sample\n\n    error |= read_line(pb, line, sizeof(line));                   // video frames per second\n\n    fps = read_fps(line, &error);\n\n    avpriv_set_pts_info(vst, 32, fps.den, fps.num);\n\n\n\n    // Figure out the video codec\n\n    switch (vst->codec->codec_tag) {\n\n#if 0\n\n        case 122:\n\n            vst->codec->codec_id = CODEC_ID_ESCAPE122;\n\n            break;\n\n#endif\n\n        case 124:\n\n            vst->codec->codec_id = CODEC_ID_ESCAPE124;\n\n            // The header is wrong here, at least sometimes\n\n            vst->codec->bits_per_coded_sample = 16;\n\n            break;\n\n        case 130:\n\n            vst->codec->codec_id = CODEC_ID_ESCAPE130;\n\n            break;\n\n        default:\n\n            av_log(s, AV_LOG_WARNING,\n\n                   \"RPL video format %i not supported yet!\\n\",\n\n                   vst->codec->codec_tag);\n\n            vst->codec->codec_id = CODEC_ID_NONE;\n\n    }\n\n\n\n    // Audio headers\n\n\n\n    // ARMovie supports multiple audio tracks; I don't have any\n\n    // samples, though. This code will ignore additional tracks.\n\n    audio_format = read_line_and_int(pb, &error);  // audio format ID\n\n    if (audio_format) {\n\n        ast = avformat_new_stream(s, NULL);\n\n        if (!ast)\n\n            return AVERROR(ENOMEM);\n\n        ast->codec->codec_type      = AVMEDIA_TYPE_AUDIO;\n\n        ast->codec->codec_tag       = audio_format;\n\n        ast->codec->sample_rate     = read_line_and_int(pb, &error);  // audio bitrate\n\n        ast->codec->channels        = read_line_and_int(pb, &error);  // number of audio channels\n\n        ast->codec->bits_per_coded_sample = read_line_and_int(pb, &error);  // audio bits per sample\n\n        // At least one sample uses 0 for ADPCM, which is really 4 bits\n\n        // per sample.\n\n        if (ast->codec->bits_per_coded_sample == 0)\n\n            ast->codec->bits_per_coded_sample = 4;\n\n\n\n        ast->codec->bit_rate = ast->codec->sample_rate *\n\n                               ast->codec->bits_per_coded_sample *\n\n                               ast->codec->channels;\n\n\n\n        ast->codec->codec_id = CODEC_ID_NONE;\n\n        switch (audio_format) {\n\n            case 1:\n\n                if (ast->codec->bits_per_coded_sample == 16) {\n\n                    // 16-bit audio is always signed\n\n                    ast->codec->codec_id = CODEC_ID_PCM_S16LE;\n\n                    break;\n\n                }\n\n                // There are some other formats listed as legal per the spec;\n\n                // samples needed.\n\n                break;\n\n            case 101:\n\n                if (ast->codec->bits_per_coded_sample == 8) {\n\n                    // The samples with this kind of audio that I have\n\n                    // are all unsigned.\n\n                    ast->codec->codec_id = CODEC_ID_PCM_U8;\n\n                    break;\n\n                } else if (ast->codec->bits_per_coded_sample == 4) {\n\n                    ast->codec->codec_id = CODEC_ID_ADPCM_IMA_EA_SEAD;\n\n                    break;\n\n                }\n\n                break;\n\n        }\n\n        if (ast->codec->codec_id == CODEC_ID_NONE) {\n\n            av_log(s, AV_LOG_WARNING,\n\n                   \"RPL audio format %i not supported yet!\\n\",\n\n                   audio_format);\n\n        }\n\n        avpriv_set_pts_info(ast, 32, 1, ast->codec->bit_rate);\n\n    } else {\n\n        for (i = 0; i < 3; i++)\n\n            error |= read_line(pb, line, sizeof(line));\n\n    }\n\n\n\n    rpl->frames_per_chunk = read_line_and_int(pb, &error);  // video frames per chunk\n\n    if (rpl->frames_per_chunk > 1 && vst->codec->codec_tag != 124)\n\n        av_log(s, AV_LOG_WARNING,\n\n               \"Don't know how to split frames for video format %i. \"\n\n               \"Video stream will be broken!\\n\", vst->codec->codec_tag);\n\n\n\n    number_of_chunks = read_line_and_int(pb, &error);  // number of chunks in the file\n\n    // The number in the header is actually the index of the last chunk.\n\n    number_of_chunks++;\n\n\n\n    error |= read_line(pb, line, sizeof(line));  // \"even\" chunk size in bytes\n\n    error |= read_line(pb, line, sizeof(line));  // \"odd\" chunk size in bytes\n\n    chunk_catalog_offset =                       // offset of the \"chunk catalog\"\n\n        read_line_and_int(pb, &error);           //   (file index)\n\n    error |= read_line(pb, line, sizeof(line));  // offset to \"helpful\" sprite\n\n    error |= read_line(pb, line, sizeof(line));  // size of \"helpful\" sprite\n\n    error |= read_line(pb, line, sizeof(line));  // offset to key frame list\n\n\n\n    // Read the index\n\n    avio_seek(pb, chunk_catalog_offset, SEEK_SET);\n\n    total_audio_size = 0;\n\n    for (i = 0; i < number_of_chunks; i++) {\n\n        int64_t offset, video_size, audio_size;\n\n        error |= read_line(pb, line, sizeof(line));\n\n        if (3 != sscanf(line, \"%\"PRId64\" , %\"PRId64\" ; %\"PRId64,\n\n                        &offset, &video_size, &audio_size))\n\n            error = -1;\n\n        av_add_index_entry(vst, offset, i * rpl->frames_per_chunk,\n\n                           video_size, rpl->frames_per_chunk, 0);\n\n        if (ast)\n\n            av_add_index_entry(ast, offset + video_size, total_audio_size,\n\n                               audio_size, audio_size * 8, 0);\n\n        total_audio_size += audio_size * 8;\n\n    }\n\n\n\n    if (error) return AVERROR(EIO);\n\n\n\n    return 0;\n\n}\n", "idx": 25926}
{"project": "FFmpeg", "commit_id": "ac94b8bcc6cdba000ada0c84b4c287f7f37f2384", "target": 0, "func": "static int adpcm_decode_frame(AVCodecContext *avctx,\n\n                            void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    ADPCMDecodeContext *c = avctx->priv_data;\n\n    ADPCMChannelStatus *cs;\n\n    int n, m, channel, i;\n\n    int block_predictor[2];\n\n    short *samples;\n\n    short *samples_end;\n\n    const uint8_t *src;\n\n    int st; /* stereo */\n\n\n\n    /* DK3 ADPCM accounting variables */\n\n    unsigned char last_byte = 0;\n\n    unsigned char nibble;\n\n    int decode_top_nibble_next = 0;\n\n    int diff_channel;\n\n\n\n    /* EA ADPCM state variables */\n\n    uint32_t samples_in_chunk;\n\n    int32_t previous_left_sample, previous_right_sample;\n\n    int32_t current_left_sample, current_right_sample;\n\n    int32_t next_left_sample, next_right_sample;\n\n    int32_t coeff1l, coeff2l, coeff1r, coeff2r;\n\n    uint8_t shift_left, shift_right;\n\n    int count1, count2;\n\n    int coeff[2][2], shift[2];//used in EA MAXIS ADPCM\n\n\n\n    if (!buf_size)\n\n        return 0;\n\n\n\n    //should protect all 4bit ADPCM variants\n\n    //8 is needed for CODEC_ID_ADPCM_IMA_WAV with 2 channels\n\n    //\n\n    if(*data_size/4 < buf_size + 8)\n\n        return -1;\n\n\n\n    samples = data;\n\n    samples_end= samples + *data_size/2;\n\n    *data_size= 0;\n\n    src = buf;\n\n\n\n    st = avctx->channels == 2 ? 1 : 0;\n\n\n\n    switch(avctx->codec->id) {\n\n    case CODEC_ID_ADPCM_IMA_QT:\n\n        n = buf_size - 2*avctx->channels;\n\n        for (channel = 0; channel < avctx->channels; channel++) {\n\n            int16_t predictor;\n\n            int step_index;\n\n            cs = &(c->status[channel]);\n\n            /* (pppppp) (piiiiiii) */\n\n\n\n            /* Bits 15-7 are the _top_ 9 bits of the 16-bit initial predictor value */\n\n            predictor = AV_RB16(src);\n\n            step_index = predictor & 0x7F;\n\n            predictor &= 0xFF80;\n\n\n\n            src += 2;\n\n\n\n            if (cs->step_index == step_index) {\n\n                int diff = (int)predictor - cs->predictor;\n\n                if (diff < 0)\n\n                    diff = - diff;\n\n                if (diff > 0x7f)\n\n                    goto update;\n\n            } else {\n\n            update:\n\n                cs->step_index = step_index;\n\n                cs->predictor = predictor;\n\n            }\n\n\n\n            if (cs->step_index > 88){\n\n                av_log(avctx, AV_LOG_ERROR, \"ERROR: step_index = %i\\n\", cs->step_index);\n\n                cs->step_index = 88;\n\n            }\n\n\n\n            samples = (short*)data + channel;\n\n\n\n            for(m=32; n>0 && m>0; n--, m--) { /* in QuickTime, IMA is encoded by chuncks of 34 bytes (=64 samples) */\n\n                *samples = adpcm_ima_qt_expand_nibble(cs, src[0] & 0x0F, 3);\n\n                samples += avctx->channels;\n\n                *samples = adpcm_ima_qt_expand_nibble(cs, src[0] >> 4  , 3);\n\n                samples += avctx->channels;\n\n                src ++;\n\n            }\n\n        }\n\n        if (st)\n\n            samples--;\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_WAV:\n\n        if (avctx->block_align != 0 && buf_size > avctx->block_align)\n\n            buf_size = avctx->block_align;\n\n\n\n//        samples_per_block= (block_align-4*chanels)*8 / (bits_per_sample * chanels) + 1;\n\n\n\n        for(i=0; i<avctx->channels; i++){\n\n            cs = &(c->status[i]);\n\n            cs->predictor = *samples++ = (int16_t)bytestream_get_le16(&src);\n\n\n\n            cs->step_index = *src++;\n\n            if (cs->step_index > 88){\n\n                av_log(avctx, AV_LOG_ERROR, \"ERROR: step_index = %i\\n\", cs->step_index);\n\n                cs->step_index = 88;\n\n            }\n\n            if (*src++) av_log(avctx, AV_LOG_ERROR, \"unused byte should be null but is %d!!\\n\", src[-1]); /* unused */\n\n        }\n\n\n\n        while(src < buf + buf_size){\n\n            for(m=0; m<4; m++){\n\n                for(i=0; i<=st; i++)\n\n                    *samples++ = adpcm_ima_expand_nibble(&c->status[i], src[4*i] & 0x0F, 3);\n\n                for(i=0; i<=st; i++)\n\n                    *samples++ = adpcm_ima_expand_nibble(&c->status[i], src[4*i] >> 4  , 3);\n\n                src++;\n\n            }\n\n            src += 4*st;\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_4XM:\n\n        cs = &(c->status[0]);\n\n        c->status[0].predictor= (int16_t)bytestream_get_le16(&src);\n\n        if(st){\n\n            c->status[1].predictor= (int16_t)bytestream_get_le16(&src);\n\n        }\n\n        c->status[0].step_index= (int16_t)bytestream_get_le16(&src);\n\n        if(st){\n\n            c->status[1].step_index= (int16_t)bytestream_get_le16(&src);\n\n        }\n\n        if (cs->step_index < 0) cs->step_index = 0;\n\n        if (cs->step_index > 88) cs->step_index = 88;\n\n\n\n        m= (buf_size - (src - buf))>>st;\n\n        for(i=0; i<m; i++) {\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0], src[i] & 0x0F, 4);\n\n            if (st)\n\n                *samples++ = adpcm_ima_expand_nibble(&c->status[1], src[i+m] & 0x0F, 4);\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0], src[i] >> 4, 4);\n\n            if (st)\n\n                *samples++ = adpcm_ima_expand_nibble(&c->status[1], src[i+m] >> 4, 4);\n\n        }\n\n\n\n        src += m<<st;\n\n\n\n        break;\n\n    case CODEC_ID_ADPCM_MS:\n\n        if (avctx->block_align != 0 && buf_size > avctx->block_align)\n\n            buf_size = avctx->block_align;\n\n        n = buf_size - 7 * avctx->channels;\n\n        if (n < 0)\n\n            return -1;\n\n        block_predictor[0] = av_clip(*src++, 0, 6);\n\n        block_predictor[1] = 0;\n\n        if (st)\n\n            block_predictor[1] = av_clip(*src++, 0, 6);\n\n        c->status[0].idelta = (int16_t)bytestream_get_le16(&src);\n\n        if (st){\n\n            c->status[1].idelta = (int16_t)bytestream_get_le16(&src);\n\n        }\n\n        c->status[0].coeff1 = ff_adpcm_AdaptCoeff1[block_predictor[0]];\n\n        c->status[0].coeff2 = ff_adpcm_AdaptCoeff2[block_predictor[0]];\n\n        c->status[1].coeff1 = ff_adpcm_AdaptCoeff1[block_predictor[1]];\n\n        c->status[1].coeff2 = ff_adpcm_AdaptCoeff2[block_predictor[1]];\n\n\n\n        c->status[0].sample1 = bytestream_get_le16(&src);\n\n        if (st) c->status[1].sample1 = bytestream_get_le16(&src);\n\n        c->status[0].sample2 = bytestream_get_le16(&src);\n\n        if (st) c->status[1].sample2 = bytestream_get_le16(&src);\n\n\n\n        *samples++ = c->status[0].sample2;\n\n        if (st) *samples++ = c->status[1].sample2;\n\n        *samples++ = c->status[0].sample1;\n\n        if (st) *samples++ = c->status[1].sample1;\n\n        for(;n>0;n--) {\n\n            *samples++ = adpcm_ms_expand_nibble(&c->status[0 ], src[0] >> 4  );\n\n            *samples++ = adpcm_ms_expand_nibble(&c->status[st], src[0] & 0x0F);\n\n            src ++;\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_DK4:\n\n        if (avctx->block_align != 0 && buf_size > avctx->block_align)\n\n            buf_size = avctx->block_align;\n\n\n\n        c->status[0].predictor  = (int16_t)bytestream_get_le16(&src);\n\n        c->status[0].step_index = *src++;\n\n        src++;\n\n        *samples++ = c->status[0].predictor;\n\n        if (st) {\n\n            c->status[1].predictor  = (int16_t)bytestream_get_le16(&src);\n\n            c->status[1].step_index = *src++;\n\n            src++;\n\n            *samples++ = c->status[1].predictor;\n\n        }\n\n        while (src < buf + buf_size) {\n\n            uint8_t v = *src++;\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0 ], v >> 4  , 3);\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st], v & 0x0F, 3);\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_DK3:\n\n        if (avctx->block_align != 0 && buf_size > avctx->block_align)\n\n            buf_size = avctx->block_align;\n\n\n\n        if(buf_size + 16 > (samples_end - samples)*3/8)\n\n            return -1;\n\n\n\n        c->status[0].predictor  = (int16_t)AV_RL16(src + 10);\n\n        c->status[1].predictor  = (int16_t)AV_RL16(src + 12);\n\n        c->status[0].step_index = src[14];\n\n        c->status[1].step_index = src[15];\n\n        /* sign extend the predictors */\n\n        src += 16;\n\n        diff_channel = c->status[1].predictor;\n\n\n\n        /* the DK3_GET_NEXT_NIBBLE macro issues the break statement when\n\n         * the buffer is consumed */\n\n        while (1) {\n\n\n\n            /* for this algorithm, c->status[0] is the sum channel and\n\n             * c->status[1] is the diff channel */\n\n\n\n            /* process the first predictor of the sum channel */\n\n            DK3_GET_NEXT_NIBBLE();\n\n            adpcm_ima_expand_nibble(&c->status[0], nibble, 3);\n\n\n\n            /* process the diff channel predictor */\n\n            DK3_GET_NEXT_NIBBLE();\n\n            adpcm_ima_expand_nibble(&c->status[1], nibble, 3);\n\n\n\n            /* process the first pair of stereo PCM samples */\n\n            diff_channel = (diff_channel + c->status[1].predictor) / 2;\n\n            *samples++ = c->status[0].predictor + c->status[1].predictor;\n\n            *samples++ = c->status[0].predictor - c->status[1].predictor;\n\n\n\n            /* process the second predictor of the sum channel */\n\n            DK3_GET_NEXT_NIBBLE();\n\n            adpcm_ima_expand_nibble(&c->status[0], nibble, 3);\n\n\n\n            /* process the second pair of stereo PCM samples */\n\n            diff_channel = (diff_channel + c->status[1].predictor) / 2;\n\n            *samples++ = c->status[0].predictor + c->status[1].predictor;\n\n            *samples++ = c->status[0].predictor - c->status[1].predictor;\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_ISS:\n\n        c->status[0].predictor  = (int16_t)AV_RL16(src + 0);\n\n        c->status[0].step_index = src[2];\n\n        src += 4;\n\n        if(st) {\n\n            c->status[1].predictor  = (int16_t)AV_RL16(src + 0);\n\n            c->status[1].step_index = src[2];\n\n            src += 4;\n\n        }\n\n\n\n        while (src < buf + buf_size) {\n\n            uint8_t v1, v2;\n\n            uint8_t v = *src++;\n\n            /* nibbles are swapped for mono */\n\n            if (st) {\n\n                v1 = v >> 4;\n\n                v2 = v & 0x0F;\n\n            } else {\n\n                v2 = v >> 4;\n\n                v1 = v & 0x0F;\n\n            }\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0 ], v1, 3);\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st], v2, 3);\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_WS:\n\n        while (src < buf + buf_size) {\n\n            uint8_t v = *src++;\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0],  v >> 4  , 3);\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st], v & 0x0F, 3);\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_XA:\n\n        while (buf_size >= 128) {\n\n            xa_decode(samples, src, &c->status[0], &c->status[1],\n\n                avctx->channels);\n\n            src += 128;\n\n            samples += 28 * 8;\n\n            buf_size -= 128;\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_EA_EACS:\n\n        samples_in_chunk = bytestream_get_le32(&src) >> (1-st);\n\n\n\n        if (samples_in_chunk > buf_size-4-(8<<st)) {\n\n            src += buf_size - 4;\n\n            break;\n\n        }\n\n\n\n        for (i=0; i<=st; i++)\n\n            c->status[i].step_index = bytestream_get_le32(&src);\n\n        for (i=0; i<=st; i++)\n\n            c->status[i].predictor  = bytestream_get_le32(&src);\n\n\n\n        for (; samples_in_chunk; samples_in_chunk--, src++) {\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0],  *src>>4,   3);\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st], *src&0x0F, 3);\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_EA_SEAD:\n\n        for (; src < buf+buf_size; src++) {\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0], src[0] >> 4, 6);\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st],src[0]&0x0F, 6);\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_EA:\n\n        /* Each EA ADPCM frame has a 12-byte header followed by 30-byte pieces,\n\n           each coding 28 stereo samples. */\n\n        if (buf_size < 12) {\n\n            av_log(avctx, AV_LOG_ERROR, \"frame too small\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n        samples_in_chunk = AV_RL32(src);\n\n        if (samples_in_chunk / 28 > (buf_size - 12) / 30) {\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid frame\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n        src += 4;\n\n        current_left_sample   = (int16_t)bytestream_get_le16(&src);\n\n        previous_left_sample  = (int16_t)bytestream_get_le16(&src);\n\n        current_right_sample  = (int16_t)bytestream_get_le16(&src);\n\n        previous_right_sample = (int16_t)bytestream_get_le16(&src);\n\n\n\n        for (count1 = 0; count1 < samples_in_chunk/28;count1++) {\n\n            coeff1l = ea_adpcm_table[ *src >> 4       ];\n\n            coeff2l = ea_adpcm_table[(*src >> 4  ) + 4];\n\n            coeff1r = ea_adpcm_table[*src & 0x0F];\n\n            coeff2r = ea_adpcm_table[(*src & 0x0F) + 4];\n\n            src++;\n\n\n\n            shift_left  = (*src >> 4  ) + 8;\n\n            shift_right = (*src & 0x0F) + 8;\n\n            src++;\n\n\n\n            for (count2 = 0; count2 < 28; count2++) {\n\n                next_left_sample  = (int32_t)((*src & 0xF0) << 24) >> shift_left;\n\n                next_right_sample = (int32_t)((*src & 0x0F) << 28) >> shift_right;\n\n                src++;\n\n\n\n                next_left_sample = (next_left_sample +\n\n                    (current_left_sample * coeff1l) +\n\n                    (previous_left_sample * coeff2l) + 0x80) >> 8;\n\n                next_right_sample = (next_right_sample +\n\n                    (current_right_sample * coeff1r) +\n\n                    (previous_right_sample * coeff2r) + 0x80) >> 8;\n\n\n\n                previous_left_sample = current_left_sample;\n\n                current_left_sample = av_clip_int16(next_left_sample);\n\n                previous_right_sample = current_right_sample;\n\n                current_right_sample = av_clip_int16(next_right_sample);\n\n                *samples++ = (unsigned short)current_left_sample;\n\n                *samples++ = (unsigned short)current_right_sample;\n\n            }\n\n        }\n\n\n\n        if (src - buf == buf_size - 2)\n\n            src += 2; // Skip terminating 0x0000\n\n\n\n        break;\n\n    case CODEC_ID_ADPCM_EA_MAXIS_XA:\n\n        for(channel = 0; channel < avctx->channels; channel++) {\n\n            for (i=0; i<2; i++)\n\n                coeff[channel][i] = ea_adpcm_table[(*src >> 4) + 4*i];\n\n            shift[channel] = (*src & 0x0F) + 8;\n\n            src++;\n\n        }\n\n        for (count1 = 0; count1 < (buf_size - avctx->channels) / avctx->channels; count1++) {\n\n            for(i = 4; i >= 0; i-=4) { /* Pairwise samples LL RR (st) or LL LL (mono) */\n\n                for(channel = 0; channel < avctx->channels; channel++) {\n\n                    int32_t sample = (int32_t)(((*(src+channel) >> i) & 0x0F) << 0x1C) >> shift[channel];\n\n                    sample = (sample +\n\n                             c->status[channel].sample1 * coeff[channel][0] +\n\n                             c->status[channel].sample2 * coeff[channel][1] + 0x80) >> 8;\n\n                    c->status[channel].sample2 = c->status[channel].sample1;\n\n                    c->status[channel].sample1 = av_clip_int16(sample);\n\n                    *samples++ = c->status[channel].sample1;\n\n                }\n\n            }\n\n            src+=avctx->channels;\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_EA_R1:\n\n    case CODEC_ID_ADPCM_EA_R2:\n\n    case CODEC_ID_ADPCM_EA_R3: {\n\n        /* channel numbering\n\n           2chan: 0=fl, 1=fr\n\n           4chan: 0=fl, 1=rl, 2=fr, 3=rr\n\n           6chan: 0=fl, 1=c,  2=fr, 3=rl,  4=rr, 5=sub */\n\n        const int big_endian = avctx->codec->id == CODEC_ID_ADPCM_EA_R3;\n\n        int32_t previous_sample, current_sample, next_sample;\n\n        int32_t coeff1, coeff2;\n\n        uint8_t shift;\n\n        unsigned int channel;\n\n        uint16_t *samplesC;\n\n        const uint8_t *srcC;\n\n        const uint8_t *src_end = buf + buf_size;\n\n\n\n        samples_in_chunk = (big_endian ? bytestream_get_be32(&src)\n\n                                       : bytestream_get_le32(&src)) / 28;\n\n        if (samples_in_chunk > UINT32_MAX/(28*avctx->channels) ||\n\n            28*samples_in_chunk*avctx->channels > samples_end-samples) {\n\n            src += buf_size - 4;\n\n            break;\n\n        }\n\n\n\n        for (channel=0; channel<avctx->channels; channel++) {\n\n            int32_t offset = (big_endian ? bytestream_get_be32(&src)\n\n                                         : bytestream_get_le32(&src))\n\n                           + (avctx->channels-channel-1) * 4;\n\n\n\n            if ((offset < 0) || (offset >= src_end - src - 4)) break;\n\n            srcC  = src + offset;\n\n            samplesC = samples + channel;\n\n\n\n            if (avctx->codec->id == CODEC_ID_ADPCM_EA_R1) {\n\n                current_sample  = (int16_t)bytestream_get_le16(&srcC);\n\n                previous_sample = (int16_t)bytestream_get_le16(&srcC);\n\n            } else {\n\n                current_sample  = c->status[channel].predictor;\n\n                previous_sample = c->status[channel].prev_sample;\n\n            }\n\n\n\n            for (count1=0; count1<samples_in_chunk; count1++) {\n\n                if (*srcC == 0xEE) {  /* only seen in R2 and R3 */\n\n                    srcC++;\n\n                    if (srcC > src_end - 30*2) break;\n\n                    current_sample  = (int16_t)bytestream_get_be16(&srcC);\n\n                    previous_sample = (int16_t)bytestream_get_be16(&srcC);\n\n\n\n                    for (count2=0; count2<28; count2++) {\n\n                        *samplesC = (int16_t)bytestream_get_be16(&srcC);\n\n                        samplesC += avctx->channels;\n\n                    }\n\n                } else {\n\n                    coeff1 = ea_adpcm_table[ *srcC>>4     ];\n\n                    coeff2 = ea_adpcm_table[(*srcC>>4) + 4];\n\n                    shift = (*srcC++ & 0x0F) + 8;\n\n\n\n                    if (srcC > src_end - 14) break;\n\n                    for (count2=0; count2<28; count2++) {\n\n                        if (count2 & 1)\n\n                            next_sample = (int32_t)((*srcC++ & 0x0F) << 28) >> shift;\n\n                        else\n\n                            next_sample = (int32_t)((*srcC   & 0xF0) << 24) >> shift;\n\n\n\n                        next_sample += (current_sample  * coeff1) +\n\n                                       (previous_sample * coeff2);\n\n                        next_sample = av_clip_int16(next_sample >> 8);\n\n\n\n                        previous_sample = current_sample;\n\n                        current_sample  = next_sample;\n\n                        *samplesC = current_sample;\n\n                        samplesC += avctx->channels;\n\n                    }\n\n                }\n\n            }\n\n\n\n            if (avctx->codec->id != CODEC_ID_ADPCM_EA_R1) {\n\n                c->status[channel].predictor   = current_sample;\n\n                c->status[channel].prev_sample = previous_sample;\n\n            }\n\n        }\n\n\n\n        src = src + buf_size - (4 + 4*avctx->channels);\n\n        samples += 28 * samples_in_chunk * avctx->channels;\n\n        break;\n\n    }\n\n    case CODEC_ID_ADPCM_EA_XAS:\n\n        if (samples_end-samples < 32*4*avctx->channels\n\n            || buf_size < (4+15)*4*avctx->channels) {\n\n            src += buf_size;\n\n            break;\n\n        }\n\n        for (channel=0; channel<avctx->channels; channel++) {\n\n            int coeff[2][4], shift[4];\n\n            short *s2, *s = &samples[channel];\n\n            for (n=0; n<4; n++, s+=32*avctx->channels) {\n\n                for (i=0; i<2; i++)\n\n                    coeff[i][n] = ea_adpcm_table[(src[0]&0x0F)+4*i];\n\n                shift[n] = (src[2]&0x0F) + 8;\n\n                for (s2=s, i=0; i<2; i++, src+=2, s2+=avctx->channels)\n\n                    s2[0] = (src[0]&0xF0) + (src[1]<<8);\n\n            }\n\n\n\n            for (m=2; m<32; m+=2) {\n\n                s = &samples[m*avctx->channels + channel];\n\n                for (n=0; n<4; n++, src++, s+=32*avctx->channels) {\n\n                    for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) {\n\n                        int level = (int32_t)((*src & (0xF0>>i)) << (24+i)) >> shift[n];\n\n                        int pred  = s2[-1*avctx->channels] * coeff[0][n]\n\n                                  + s2[-2*avctx->channels] * coeff[1][n];\n\n                        s2[0] = av_clip_int16((level + pred + 0x80) >> 8);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        samples += 32*4*avctx->channels;\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_AMV:\n\n    case CODEC_ID_ADPCM_IMA_SMJPEG:\n\n        c->status[0].predictor = (int16_t)bytestream_get_le16(&src);\n\n        c->status[0].step_index = bytestream_get_le16(&src);\n\n\n\n        if (avctx->codec->id == CODEC_ID_ADPCM_IMA_AMV)\n\n            src+=4;\n\n\n\n        while (src < buf + buf_size) {\n\n            char hi, lo;\n\n            lo = *src & 0x0F;\n\n            hi = *src >> 4;\n\n\n\n            if (avctx->codec->id == CODEC_ID_ADPCM_IMA_AMV)\n\n                FFSWAP(char, hi, lo);\n\n\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0],\n\n                lo, 3);\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0],\n\n                hi, 3);\n\n            src++;\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_CT:\n\n        while (src < buf + buf_size) {\n\n            uint8_t v = *src++;\n\n            *samples++ = adpcm_ct_expand_nibble(&c->status[0 ], v >> 4  );\n\n            *samples++ = adpcm_ct_expand_nibble(&c->status[st], v & 0x0F);\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_SBPRO_4:\n\n    case CODEC_ID_ADPCM_SBPRO_3:\n\n    case CODEC_ID_ADPCM_SBPRO_2:\n\n        if (!c->status[0].step_index) {\n\n            /* the first byte is a raw sample */\n\n            *samples++ = 128 * (*src++ - 0x80);\n\n            if (st)\n\n              *samples++ = 128 * (*src++ - 0x80);\n\n            c->status[0].step_index = 1;\n\n        }\n\n        if (avctx->codec->id == CODEC_ID_ADPCM_SBPRO_4) {\n\n            while (src < buf + buf_size) {\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n\n                    src[0] >> 4, 4, 0);\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[st],\n\n                    src[0] & 0x0F, 4, 0);\n\n                src++;\n\n            }\n\n        } else if (avctx->codec->id == CODEC_ID_ADPCM_SBPRO_3) {\n\n            while (src < buf + buf_size && samples + 2 < samples_end) {\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n\n                     src[0] >> 5        , 3, 0);\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n\n                    (src[0] >> 2) & 0x07, 3, 0);\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n\n                    src[0] & 0x03, 2, 0);\n\n                src++;\n\n            }\n\n        } else {\n\n            while (src < buf + buf_size && samples + 3 < samples_end) {\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n\n                     src[0] >> 6        , 2, 2);\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[st],\n\n                    (src[0] >> 4) & 0x03, 2, 2);\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n\n                    (src[0] >> 2) & 0x03, 2, 2);\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[st],\n\n                    src[0] & 0x03, 2, 2);\n\n                src++;\n\n            }\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_SWF:\n\n    {\n\n        GetBitContext gb;\n\n        const int *table;\n\n        int k0, signmask, nb_bits, count;\n\n        int size = buf_size*8;\n\n\n\n        init_get_bits(&gb, buf, size);\n\n\n\n        //read bits & initial values\n\n        nb_bits = get_bits(&gb, 2)+2;\n\n        //av_log(NULL,AV_LOG_INFO,\"nb_bits: %d\\n\", nb_bits);\n\n        table = swf_index_tables[nb_bits-2];\n\n        k0 = 1 << (nb_bits-2);\n\n        signmask = 1 << (nb_bits-1);\n\n\n\n        while (get_bits_count(&gb) <= size - 22*avctx->channels) {\n\n            for (i = 0; i < avctx->channels; i++) {\n\n                *samples++ = c->status[i].predictor = get_sbits(&gb, 16);\n\n                c->status[i].step_index = get_bits(&gb, 6);\n\n            }\n\n\n\n            for (count = 0; get_bits_count(&gb) <= size - nb_bits*avctx->channels && count < 4095; count++) {\n\n                int i;\n\n\n\n                for (i = 0; i < avctx->channels; i++) {\n\n                    // similar to IMA adpcm\n\n                    int delta = get_bits(&gb, nb_bits);\n\n                    int step = ff_adpcm_step_table[c->status[i].step_index];\n\n                    long vpdiff = 0; // vpdiff = (delta+0.5)*step/4\n\n                    int k = k0;\n\n\n\n                    do {\n\n                        if (delta & k)\n\n                            vpdiff += step;\n\n                        step >>= 1;\n\n                        k >>= 1;\n\n                    } while(k);\n\n                    vpdiff += step;\n\n\n\n                    if (delta & signmask)\n\n                        c->status[i].predictor -= vpdiff;\n\n                    else\n\n                        c->status[i].predictor += vpdiff;\n\n\n\n                    c->status[i].step_index += table[delta & (~signmask)];\n\n\n\n                    c->status[i].step_index = av_clip(c->status[i].step_index, 0, 88);\n\n                    c->status[i].predictor = av_clip_int16(c->status[i].predictor);\n\n\n\n                    *samples++ = c->status[i].predictor;\n\n                    if (samples >= samples_end) {\n\n                        av_log(avctx, AV_LOG_ERROR, \"allocated output buffer is too small\\n\");\n\n                        return -1;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        src += buf_size;\n\n        break;\n\n    }\n\n    case CODEC_ID_ADPCM_YAMAHA:\n\n        while (src < buf + buf_size) {\n\n            uint8_t v = *src++;\n\n            *samples++ = adpcm_yamaha_expand_nibble(&c->status[0 ], v & 0x0F);\n\n            *samples++ = adpcm_yamaha_expand_nibble(&c->status[st], v >> 4  );\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_THP:\n\n    {\n\n        int table[2][16];\n\n        unsigned int samplecnt;\n\n        int prev[2][2];\n\n        int ch;\n\n\n\n        if (buf_size < 80) {\n\n            av_log(avctx, AV_LOG_ERROR, \"frame too small\\n\");\n\n            return -1;\n\n        }\n\n\n\n        src+=4;\n\n        samplecnt = bytestream_get_be32(&src);\n\n\n\n        for (i = 0; i < 32; i++)\n\n            table[0][i] = (int16_t)bytestream_get_be16(&src);\n\n\n\n        /* Initialize the previous sample.  */\n\n        for (i = 0; i < 4; i++)\n\n            prev[0][i] = (int16_t)bytestream_get_be16(&src);\n\n\n\n        if (samplecnt >= (samples_end - samples) /  (st + 1)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"allocated output buffer is too small\\n\");\n\n            return -1;\n\n        }\n\n\n\n        for (ch = 0; ch <= st; ch++) {\n\n            samples = (unsigned short *) data + ch;\n\n\n\n            /* Read in every sample for this channel.  */\n\n            for (i = 0; i < samplecnt / 14; i++) {\n\n                int index = (*src >> 4) & 7;\n\n                unsigned int exp = 28 - (*src++ & 15);\n\n                int factor1 = table[ch][index * 2];\n\n                int factor2 = table[ch][index * 2 + 1];\n\n\n\n                /* Decode 14 samples.  */\n\n                for (n = 0; n < 14; n++) {\n\n                    int32_t sampledat;\n\n                    if(n&1) sampledat=  *src++    <<28;\n\n                    else    sampledat= (*src&0xF0)<<24;\n\n\n\n                    sampledat = ((prev[ch][0]*factor1\n\n                                + prev[ch][1]*factor2) >> 11) + (sampledat>>exp);\n\n                    *samples = av_clip_int16(sampledat);\n\n                    prev[ch][1] = prev[ch][0];\n\n                    prev[ch][0] = *samples++;\n\n\n\n                    /* In case of stereo, skip one sample, this sample\n\n                       is for the other channel.  */\n\n                    samples += st;\n\n                }\n\n            }\n\n        }\n\n\n\n        /* In the previous loop, in case stereo is used, samples is\n\n           increased exactly one time too often.  */\n\n        samples -= st;\n\n        break;\n\n    }\n\n\n\n    default:\n\n        return -1;\n\n    }\n\n    *data_size = (uint8_t *)samples - (uint8_t *)data;\n\n    return src - buf;\n\n}\n", "idx": 25936}
{"project": "FFmpeg", "commit_id": "50cbe09d8ced75422571d29bbec1f35a33a0d3ed", "target": 0, "func": "static int smacker_decode_header_tree(SmackVContext *smk, GetBitContext *gb, int **recodes, int *last, int size)\n\n{\n\n    int res;\n\n    HuffContext huff;\n\n    HuffContext tmp1, tmp2;\n\n    VLC vlc[2] = { { 0 } };\n\n    int escapes[3];\n\n    DBCtx ctx;\n\n    int err = 0;\n\n\n\n    if(size >= UINT_MAX>>4){ // (((size + 3) >> 2) + 3) << 2 must not overflow\n\n        av_log(smk->avctx, AV_LOG_ERROR, \"size too large\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    tmp1.length = 256;\n\n    tmp1.maxlength = 0;\n\n    tmp1.current = 0;\n\n    tmp1.bits = av_mallocz(256 * 4);\n\n    tmp1.lengths = av_mallocz(256 * sizeof(int));\n\n    tmp1.values = av_mallocz(256 * sizeof(int));\n\n\n\n    tmp2.length = 256;\n\n    tmp2.maxlength = 0;\n\n    tmp2.current = 0;\n\n    tmp2.bits = av_mallocz(256 * 4);\n\n    tmp2.lengths = av_mallocz(256 * sizeof(int));\n\n    tmp2.values = av_mallocz(256 * sizeof(int));\n\n\n\n    if(get_bits1(gb)) {\n\n        smacker_decode_tree(gb, &tmp1, 0, 0);\n\n        skip_bits1(gb);\n\n        if(tmp1.current > 1) {\n\n            res = init_vlc(&vlc[0], SMKTREE_BITS, tmp1.length,\n\n                        tmp1.lengths, sizeof(int), sizeof(int),\n\n                        tmp1.bits, sizeof(uint32_t), sizeof(uint32_t), INIT_VLC_LE);\n\n            if(res < 0) {\n\n                av_log(smk->avctx, AV_LOG_ERROR, \"Cannot build VLC table\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    }\n\n    if (!vlc[0].table) {\n\n        av_log(smk->avctx, AV_LOG_ERROR, \"Skipping low bytes tree\\n\");\n\n    }\n\n    if(get_bits1(gb)){\n\n        smacker_decode_tree(gb, &tmp2, 0, 0);\n\n        skip_bits1(gb);\n\n        if(tmp2.current > 1) {\n\n            res = init_vlc(&vlc[1], SMKTREE_BITS, tmp2.length,\n\n                        tmp2.lengths, sizeof(int), sizeof(int),\n\n                        tmp2.bits, sizeof(uint32_t), sizeof(uint32_t), INIT_VLC_LE);\n\n            if(res < 0) {\n\n                av_log(smk->avctx, AV_LOG_ERROR, \"Cannot build VLC table\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    }\n\n    if (!vlc[1].table) {\n\n        av_log(smk->avctx, AV_LOG_ERROR, \"Skipping high bytes tree\\n\");\n\n    }\n\n\n\n    escapes[0]  = get_bits(gb, 16);\n\n    escapes[1]  = get_bits(gb, 16);\n\n    escapes[2]  = get_bits(gb, 16);\n\n\n\n    last[0] = last[1] = last[2] = -1;\n\n\n\n    ctx.escapes[0] = escapes[0];\n\n    ctx.escapes[1] = escapes[1];\n\n    ctx.escapes[2] = escapes[2];\n\n    ctx.v1 = &vlc[0];\n\n    ctx.v2 = &vlc[1];\n\n    ctx.recode1 = tmp1.values;\n\n    ctx.recode2 = tmp2.values;\n\n    ctx.last = last;\n\n\n\n    huff.length = ((size + 3) >> 2) + 3;\n\n    huff.maxlength = 0;\n\n    huff.current = 0;\n\n    huff.values = av_mallocz(huff.length * sizeof(int));\n\n\n\n    if (smacker_decode_bigtree(gb, &huff, &ctx) < 0)\n\n        err = -1;\n\n    skip_bits1(gb);\n\n    if(ctx.last[0] == -1) ctx.last[0] = huff.current++;\n\n    if(ctx.last[1] == -1) ctx.last[1] = huff.current++;\n\n    if(ctx.last[2] == -1) ctx.last[2] = huff.current++;\n\n    if(huff.current > huff.length){\n\n        ctx.last[0] = ctx.last[1] = ctx.last[2] = 1;\n\n        av_log(smk->avctx, AV_LOG_ERROR, \"bigtree damaged\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    *recodes = huff.values;\n\n\n\n    if(vlc[0].table)\n\n        ff_free_vlc(&vlc[0]);\n\n    if(vlc[1].table)\n\n        ff_free_vlc(&vlc[1]);\n\n    av_free(tmp1.bits);\n\n    av_free(tmp1.lengths);\n\n    av_free(tmp1.values);\n\n    av_free(tmp2.bits);\n\n    av_free(tmp2.lengths);\n\n    av_free(tmp2.values);\n\n\n\n    return err;\n\n}\n", "idx": 25937}
{"project": "FFmpeg", "commit_id": "e6c90ce94f1b07f50cea2babf7471af455cca0ff", "target": 0, "func": "int ff_h264_decode_slice_header(H264Context *h, H264SliceContext *sl, H264Context *h0)\n\n{\n\n    unsigned int first_mb_in_slice;\n\n    unsigned int pps_id;\n\n    int ret;\n\n    unsigned int slice_type, tmp, i, j;\n\n    int default_ref_list_done = 0;\n\n    int last_pic_structure, last_pic_droppable;\n\n    int needs_reinit = 0;\n\n    int field_pic_flag, bottom_field_flag;\n\n\n\n    h->qpel_put = h->h264qpel.put_h264_qpel_pixels_tab;\n\n    h->qpel_avg = h->h264qpel.avg_h264_qpel_pixels_tab;\n\n\n\n    first_mb_in_slice = get_ue_golomb(&h->gb);\n\n\n\n    if (first_mb_in_slice == 0) { // FIXME better field boundary detection\n\n        if (h0->current_slice && h->cur_pic_ptr && FIELD_PICTURE(h)) {\n\n            ff_h264_field_end(h, sl, 1);\n\n        }\n\n\n\n        h0->current_slice = 0;\n\n        if (!h0->first_field) {\n\n            if (h->cur_pic_ptr && !h->droppable) {\n\n                ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n\n                                          h->picture_structure == PICT_BOTTOM_FIELD);\n\n            }\n\n            h->cur_pic_ptr = NULL;\n\n        }\n\n    }\n\n\n\n    slice_type = get_ue_golomb_31(&h->gb);\n\n    if (slice_type > 9) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"slice type %d too large at %d %d\\n\",\n\n               slice_type, h->mb_x, h->mb_y);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (slice_type > 4) {\n\n        slice_type -= 5;\n\n        sl->slice_type_fixed = 1;\n\n    } else\n\n        sl->slice_type_fixed = 0;\n\n\n\n    slice_type = golomb_to_pict_type[slice_type];\n\n    if (slice_type == AV_PICTURE_TYPE_I ||\n\n        (h0->current_slice != 0 && slice_type == h0->last_slice_type)) {\n\n        default_ref_list_done = 1;\n\n    }\n\n    sl->slice_type     = slice_type;\n\n    sl->slice_type_nos = slice_type & 3;\n\n\n\n    if (h->nal_unit_type  == NAL_IDR_SLICE &&\n\n        sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"A non-intra slice in an IDR NAL unit.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    // to make a few old functions happy, it's wrong though\n\n    h->pict_type = sl->slice_type;\n\n\n\n    pps_id = get_ue_golomb(&h->gb);\n\n    if (pps_id >= MAX_PPS_COUNT) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"pps_id %u out of range\\n\", pps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (!h0->pps_buffers[pps_id]) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"non-existing PPS %u referenced\\n\",\n\n               pps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    h->pps = *h0->pps_buffers[pps_id];\n\n\n\n    if (!h0->sps_buffers[h->pps.sps_id]) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"non-existing SPS %u referenced\\n\",\n\n               h->pps.sps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (h->pps.sps_id != h->sps.sps_id ||\n\n        h0->sps_buffers[h->pps.sps_id]->new) {\n\n        h0->sps_buffers[h->pps.sps_id]->new = 0;\n\n\n\n        h->sps = *h0->sps_buffers[h->pps.sps_id];\n\n\n\n        if (h->bit_depth_luma    != h->sps.bit_depth_luma ||\n\n            h->chroma_format_idc != h->sps.chroma_format_idc) {\n\n            h->bit_depth_luma    = h->sps.bit_depth_luma;\n\n            h->chroma_format_idc = h->sps.chroma_format_idc;\n\n            needs_reinit         = 1;\n\n        }\n\n        if ((ret = ff_h264_set_parameter_from_sps(h)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    h->avctx->profile = ff_h264_get_profile(&h->sps);\n\n    h->avctx->level   = h->sps.level_idc;\n\n    h->avctx->refs    = h->sps.ref_frame_count;\n\n\n\n    if (h->mb_width  != h->sps.mb_width ||\n\n        h->mb_height != h->sps.mb_height * (2 - h->sps.frame_mbs_only_flag))\n\n        needs_reinit = 1;\n\n\n\n    h->mb_width  = h->sps.mb_width;\n\n    h->mb_height = h->sps.mb_height * (2 - h->sps.frame_mbs_only_flag);\n\n    h->mb_num    = h->mb_width * h->mb_height;\n\n    h->mb_stride = h->mb_width + 1;\n\n\n\n    h->b_stride = h->mb_width * 4;\n\n\n\n    h->chroma_y_shift = h->sps.chroma_format_idc <= 1; // 400 uses yuv420p\n\n\n\n    h->width  = 16 * h->mb_width;\n\n    h->height = 16 * h->mb_height;\n\n\n\n    ret = init_dimensions(h);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (h->sps.video_signal_type_present_flag) {\n\n        h->avctx->color_range = h->sps.full_range ? AVCOL_RANGE_JPEG\n\n                                                  : AVCOL_RANGE_MPEG;\n\n        if (h->sps.colour_description_present_flag) {\n\n            if (h->avctx->colorspace != h->sps.colorspace)\n\n                needs_reinit = 1;\n\n            h->avctx->color_primaries = h->sps.color_primaries;\n\n            h->avctx->color_trc       = h->sps.color_trc;\n\n            h->avctx->colorspace      = h->sps.colorspace;\n\n        }\n\n    }\n\n\n\n    if (h->context_initialized && needs_reinit) {\n\n        if (h != h0) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"changing width %d -> %d / height %d -> %d on \"\n\n                   \"slice %d\\n\",\n\n                   h->width, h->avctx->coded_width,\n\n                   h->height, h->avctx->coded_height,\n\n                   h0->current_slice + 1);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        ff_h264_flush_change(h);\n\n\n\n        if ((ret = get_pixel_format(h)) < 0)\n\n            return ret;\n\n        h->avctx->pix_fmt = ret;\n\n\n\n        av_log(h->avctx, AV_LOG_INFO, \"Reinit context to %dx%d, \"\n\n               \"pix_fmt: %d\\n\", h->width, h->height, h->avctx->pix_fmt);\n\n\n\n        if ((ret = h264_slice_header_init(h, 1)) < 0) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"h264_slice_header_init() failed\\n\");\n\n            return ret;\n\n        }\n\n    }\n\n    if (!h->context_initialized) {\n\n        if (h != h0) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"Cannot (re-)initialize context during parallel decoding.\\n\");\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n\n\n        if ((ret = get_pixel_format(h)) < 0)\n\n            return ret;\n\n        h->avctx->pix_fmt = ret;\n\n\n\n        if ((ret = h264_slice_header_init(h, 0)) < 0) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"h264_slice_header_init() failed\\n\");\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    if (h == h0 && h->dequant_coeff_pps != pps_id) {\n\n        h->dequant_coeff_pps = pps_id;\n\n        h264_init_dequant_tables(h);\n\n    }\n\n\n\n    h->frame_num = get_bits(&h->gb, h->sps.log2_max_frame_num);\n\n\n\n    h->mb_mbaff        = 0;\n\n    h->mb_aff_frame    = 0;\n\n    last_pic_structure = h0->picture_structure;\n\n    last_pic_droppable = h0->droppable;\n\n    h->droppable       = h->nal_ref_idc == 0;\n\n    if (h->sps.frame_mbs_only_flag) {\n\n        h->picture_structure = PICT_FRAME;\n\n    } else {\n\n        field_pic_flag = get_bits1(&h->gb);\n\n        if (field_pic_flag) {\n\n            bottom_field_flag = get_bits1(&h->gb);\n\n            h->picture_structure = PICT_TOP_FIELD + bottom_field_flag;\n\n        } else {\n\n            h->picture_structure = PICT_FRAME;\n\n            h->mb_aff_frame      = h->sps.mb_aff;\n\n        }\n\n    }\n\n    h->mb_field_decoding_flag = h->picture_structure != PICT_FRAME;\n\n\n\n    if (h0->current_slice != 0) {\n\n        if (last_pic_structure != h->picture_structure ||\n\n            last_pic_droppable != h->droppable) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"Changing field mode (%d -> %d) between slices is not allowed\\n\",\n\n                   last_pic_structure, h->picture_structure);\n\n            h->picture_structure = last_pic_structure;\n\n            h->droppable         = last_pic_droppable;\n\n            return AVERROR_INVALIDDATA;\n\n        } else if (!h0->cur_pic_ptr) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"unset cur_pic_ptr on slice %d\\n\",\n\n                   h0->current_slice + 1);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    } else {\n\n        /* Shorten frame num gaps so we don't have to allocate reference\n\n         * frames just to throw them away */\n\n        if (h->frame_num != h->prev_frame_num) {\n\n            int unwrap_prev_frame_num = h->prev_frame_num;\n\n            int max_frame_num         = 1 << h->sps.log2_max_frame_num;\n\n\n\n            if (unwrap_prev_frame_num > h->frame_num)\n\n                unwrap_prev_frame_num -= max_frame_num;\n\n\n\n            if ((h->frame_num - unwrap_prev_frame_num) > h->sps.ref_frame_count) {\n\n                unwrap_prev_frame_num = (h->frame_num - h->sps.ref_frame_count) - 1;\n\n                if (unwrap_prev_frame_num < 0)\n\n                    unwrap_prev_frame_num += max_frame_num;\n\n\n\n                h->prev_frame_num = unwrap_prev_frame_num;\n\n            }\n\n        }\n\n\n\n        /* See if we have a decoded first field looking for a pair...\n\n         * Here, we're using that to see if we should mark previously\n\n         * decode frames as \"finished\".\n\n         * We have to do that before the \"dummy\" in-between frame allocation,\n\n         * since that can modify s->current_picture_ptr. */\n\n        if (h0->first_field) {\n\n            assert(h0->cur_pic_ptr);\n\n            assert(h0->cur_pic_ptr->f.buf[0]);\n\n            assert(h0->cur_pic_ptr->reference != DELAYED_PIC_REF);\n\n\n\n            /* figure out if we have a complementary field pair */\n\n            if (!FIELD_PICTURE(h) || h->picture_structure == last_pic_structure) {\n\n                /* Previous field is unmatched. Don't display it, but let it\n\n                 * remain for reference if marked as such. */\n\n                if (!last_pic_droppable && last_pic_structure != PICT_FRAME) {\n\n                    ff_thread_report_progress(&h0->cur_pic_ptr->tf, INT_MAX,\n\n                                              last_pic_structure == PICT_TOP_FIELD);\n\n                }\n\n            } else {\n\n                if (h0->cur_pic_ptr->frame_num != h->frame_num) {\n\n                    /* This and previous field were reference, but had\n\n                     * different frame_nums. Consider this field first in\n\n                     * pair. Throw away previous field except for reference\n\n                     * purposes. */\n\n                    if (!last_pic_droppable && last_pic_structure != PICT_FRAME) {\n\n                        ff_thread_report_progress(&h0->cur_pic_ptr->tf, INT_MAX,\n\n                                                  last_pic_structure == PICT_TOP_FIELD);\n\n                    }\n\n                } else {\n\n                    /* Second field in complementary pair */\n\n                    if (!((last_pic_structure   == PICT_TOP_FIELD &&\n\n                           h->picture_structure == PICT_BOTTOM_FIELD) ||\n\n                          (last_pic_structure   == PICT_BOTTOM_FIELD &&\n\n                           h->picture_structure == PICT_TOP_FIELD))) {\n\n                        av_log(h->avctx, AV_LOG_ERROR,\n\n                               \"Invalid field mode combination %d/%d\\n\",\n\n                               last_pic_structure, h->picture_structure);\n\n                        h->picture_structure = last_pic_structure;\n\n                        h->droppable         = last_pic_droppable;\n\n                        return AVERROR_INVALIDDATA;\n\n                    } else if (last_pic_droppable != h->droppable) {\n\n                        avpriv_request_sample(h->avctx,\n\n                                              \"Found reference and non-reference fields in the same frame, which\");\n\n                        h->picture_structure = last_pic_structure;\n\n                        h->droppable         = last_pic_droppable;\n\n                        return AVERROR_PATCHWELCOME;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n\n\n        while (h->frame_num != h->prev_frame_num &&\n\n               h->frame_num != (h->prev_frame_num + 1) % (1 << h->sps.log2_max_frame_num)) {\n\n            H264Picture *prev = h->short_ref_count ? h->short_ref[0] : NULL;\n\n            av_log(h->avctx, AV_LOG_DEBUG, \"Frame num gap %d %d\\n\",\n\n                   h->frame_num, h->prev_frame_num);\n\n            ret = h264_frame_start(h);\n\n            if (ret < 0) {\n\n                h0->first_field = 0;\n\n                return ret;\n\n            }\n\n\n\n            h->prev_frame_num++;\n\n            h->prev_frame_num        %= 1 << h->sps.log2_max_frame_num;\n\n            h->cur_pic_ptr->frame_num = h->prev_frame_num;\n\n            ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX, 0);\n\n            ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX, 1);\n\n            ret = ff_generate_sliding_window_mmcos(h, 1);\n\n            if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n\n                return ret;\n\n            ret = ff_h264_execute_ref_pic_marking(h, h->mmco, h->mmco_index);\n\n            if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n\n                return ret;\n\n            /* Error concealment: If a ref is missing, copy the previous ref\n\n             * in its place.\n\n             * FIXME: Avoiding a memcpy would be nice, but ref handling makes\n\n             * many assumptions about there being no actual duplicates.\n\n             * FIXME: This does not copy padding for out-of-frame motion\n\n             * vectors.  Given we are concealing a lost frame, this probably\n\n             * is not noticeable by comparison, but it should be fixed. */\n\n            if (h->short_ref_count) {\n\n                if (prev) {\n\n                    av_image_copy(h->short_ref[0]->f.data,\n\n                                  h->short_ref[0]->f.linesize,\n\n                                  (const uint8_t **)prev->f.data,\n\n                                  prev->f.linesize,\n\n                                  h->avctx->pix_fmt,\n\n                                  h->mb_width  * 16,\n\n                                  h->mb_height * 16);\n\n                    h->short_ref[0]->poc = prev->poc + 2;\n\n                }\n\n                h->short_ref[0]->frame_num = h->prev_frame_num;\n\n            }\n\n        }\n\n\n\n        /* See if we have a decoded first field looking for a pair...\n\n         * We're using that to see whether to continue decoding in that\n\n         * frame, or to allocate a new one. */\n\n        if (h0->first_field) {\n\n            assert(h0->cur_pic_ptr);\n\n            assert(h0->cur_pic_ptr->f.buf[0]);\n\n            assert(h0->cur_pic_ptr->reference != DELAYED_PIC_REF);\n\n\n\n            /* figure out if we have a complementary field pair */\n\n            if (!FIELD_PICTURE(h) || h->picture_structure == last_pic_structure) {\n\n                /* Previous field is unmatched. Don't display it, but let it\n\n                 * remain for reference if marked as such. */\n\n                h0->cur_pic_ptr = NULL;\n\n                h0->first_field = FIELD_PICTURE(h);\n\n            } else {\n\n                if (h0->cur_pic_ptr->frame_num != h->frame_num) {\n\n                    /* This and the previous field had different frame_nums.\n\n                     * Consider this field first in pair. Throw away previous\n\n                     * one except for reference purposes. */\n\n                    h0->first_field = 1;\n\n                    h0->cur_pic_ptr = NULL;\n\n                } else {\n\n                    /* Second field in complementary pair */\n\n                    h0->first_field = 0;\n\n                }\n\n            }\n\n        } else {\n\n            /* Frame or first field in a potentially complementary pair */\n\n            h0->first_field = FIELD_PICTURE(h);\n\n        }\n\n\n\n        if (!FIELD_PICTURE(h) || h0->first_field) {\n\n            if (h264_frame_start(h) < 0) {\n\n                h0->first_field = 0;\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        } else {\n\n            release_unused_pictures(h, 0);\n\n        }\n\n    }\n\n    if (h != h0 && (ret = clone_slice(h, h0)) < 0)\n\n        return ret;\n\n\n\n    h->cur_pic_ptr->frame_num = h->frame_num; // FIXME frame_num cleanup\n\n\n\n    assert(h->mb_num == h->mb_width * h->mb_height);\n\n    if (first_mb_in_slice << FIELD_OR_MBAFF_PICTURE(h) >= h->mb_num ||\n\n        first_mb_in_slice >= h->mb_num) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"first_mb_in_slice overflow\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    h->resync_mb_x = h->mb_x =  first_mb_in_slice % h->mb_width;\n\n    h->resync_mb_y = h->mb_y = (first_mb_in_slice / h->mb_width) <<\n\n                               FIELD_OR_MBAFF_PICTURE(h);\n\n    if (h->picture_structure == PICT_BOTTOM_FIELD)\n\n        h->resync_mb_y = h->mb_y = h->mb_y + 1;\n\n    assert(h->mb_y < h->mb_height);\n\n\n\n    if (h->picture_structure == PICT_FRAME) {\n\n        h->curr_pic_num = h->frame_num;\n\n        h->max_pic_num  = 1 << h->sps.log2_max_frame_num;\n\n    } else {\n\n        h->curr_pic_num = 2 * h->frame_num + 1;\n\n        h->max_pic_num  = 1 << (h->sps.log2_max_frame_num + 1);\n\n    }\n\n\n\n    if (h->nal_unit_type == NAL_IDR_SLICE)\n\n        get_ue_golomb(&h->gb); /* idr_pic_id */\n\n\n\n    if (h->sps.poc_type == 0) {\n\n        h->poc_lsb = get_bits(&h->gb, h->sps.log2_max_poc_lsb);\n\n\n\n        if (h->pps.pic_order_present == 1 && h->picture_structure == PICT_FRAME)\n\n            h->delta_poc_bottom = get_se_golomb(&h->gb);\n\n    }\n\n\n\n    if (h->sps.poc_type == 1 && !h->sps.delta_pic_order_always_zero_flag) {\n\n        h->delta_poc[0] = get_se_golomb(&h->gb);\n\n\n\n        if (h->pps.pic_order_present == 1 && h->picture_structure == PICT_FRAME)\n\n            h->delta_poc[1] = get_se_golomb(&h->gb);\n\n    }\n\n\n\n    ff_init_poc(h, h->cur_pic_ptr->field_poc, &h->cur_pic_ptr->poc);\n\n\n\n    if (h->pps.redundant_pic_cnt_present)\n\n        h->redundant_pic_count = get_ue_golomb(&h->gb);\n\n\n\n    ret = ff_set_ref_count(h, sl);\n\n    if (ret < 0)\n\n        return ret;\n\n    else if (ret == 1)\n\n        default_ref_list_done = 0;\n\n\n\n    if (!default_ref_list_done)\n\n        ff_h264_fill_default_ref_list(h, sl);\n\n\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n       ret = ff_h264_decode_ref_pic_list_reordering(h, sl);\n\n       if (ret < 0) {\n\n           sl->ref_count[1] = sl->ref_count[0] = 0;\n\n           return ret;\n\n       }\n\n    }\n\n\n\n    if ((h->pps.weighted_pred && sl->slice_type_nos == AV_PICTURE_TYPE_P) ||\n\n        (h->pps.weighted_bipred_idc == 1 &&\n\n         sl->slice_type_nos == AV_PICTURE_TYPE_B))\n\n        ff_pred_weight_table(h, sl);\n\n    else if (h->pps.weighted_bipred_idc == 2 &&\n\n             sl->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n        implicit_weight_table(h, sl, -1);\n\n    } else {\n\n        sl->use_weight = 0;\n\n        for (i = 0; i < 2; i++) {\n\n            sl->luma_weight_flag[i]   = 0;\n\n            sl->chroma_weight_flag[i] = 0;\n\n        }\n\n    }\n\n\n\n    // If frame-mt is enabled, only update mmco tables for the first slice\n\n    // in a field. Subsequent slices can temporarily clobber h->mmco_index\n\n    // or h->mmco, which will cause ref list mix-ups and decoding errors\n\n    // further down the line. This may break decoding if the first slice is\n\n    // corrupt, thus we only do this if frame-mt is enabled.\n\n    if (h->nal_ref_idc) {\n\n        ret = ff_h264_decode_ref_pic_marking(h0, &h->gb,\n\n                                             !(h->avctx->active_thread_type & FF_THREAD_FRAME) ||\n\n                                             h0->current_slice == 0);\n\n        if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (FRAME_MBAFF(h)) {\n\n        ff_h264_fill_mbaff_ref_list(h, sl);\n\n\n\n        if (h->pps.weighted_bipred_idc == 2 && sl->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n            implicit_weight_table(h, sl, 0);\n\n            implicit_weight_table(h, sl, 1);\n\n        }\n\n    }\n\n\n\n    if (sl->slice_type_nos == AV_PICTURE_TYPE_B && !sl->direct_spatial_mv_pred)\n\n        ff_h264_direct_dist_scale_factor(h, sl);\n\n    ff_h264_direct_ref_list_init(h, sl);\n\n\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I && h->pps.cabac) {\n\n        tmp = get_ue_golomb_31(&h->gb);\n\n        if (tmp > 2) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"cabac_init_idc %u overflow\\n\", tmp);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        h->cabac_init_idc = tmp;\n\n    }\n\n\n\n    sl->last_qscale_diff = 0;\n\n    tmp = h->pps.init_qp + get_se_golomb(&h->gb);\n\n    if (tmp > 51 + 6 * (h->sps.bit_depth_luma - 8)) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"QP %u out of range\\n\", tmp);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    sl->qscale       = tmp;\n\n    sl->chroma_qp[0] = get_chroma_qp(h, 0, sl->qscale);\n\n    sl->chroma_qp[1] = get_chroma_qp(h, 1, sl->qscale);\n\n    // FIXME qscale / qp ... stuff\n\n    if (sl->slice_type == AV_PICTURE_TYPE_SP)\n\n        get_bits1(&h->gb); /* sp_for_switch_flag */\n\n    if (sl->slice_type == AV_PICTURE_TYPE_SP ||\n\n        sl->slice_type == AV_PICTURE_TYPE_SI)\n\n        get_se_golomb(&h->gb); /* slice_qs_delta */\n\n\n\n    h->deblocking_filter     = 1;\n\n    h->slice_alpha_c0_offset = 0;\n\n    h->slice_beta_offset     = 0;\n\n    if (h->pps.deblocking_filter_parameters_present) {\n\n        tmp = get_ue_golomb_31(&h->gb);\n\n        if (tmp > 2) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"deblocking_filter_idc %u out of range\\n\", tmp);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        h->deblocking_filter = tmp;\n\n        if (h->deblocking_filter < 2)\n\n            h->deblocking_filter ^= 1;  // 1<->0\n\n\n\n        if (h->deblocking_filter) {\n\n            h->slice_alpha_c0_offset = get_se_golomb(&h->gb) * 2;\n\n            h->slice_beta_offset     = get_se_golomb(&h->gb) * 2;\n\n            if (h->slice_alpha_c0_offset >  12 ||\n\n                h->slice_alpha_c0_offset < -12 ||\n\n                h->slice_beta_offset >  12     ||\n\n                h->slice_beta_offset < -12) {\n\n                av_log(h->avctx, AV_LOG_ERROR,\n\n                       \"deblocking filter parameters %d %d out of range\\n\",\n\n                       h->slice_alpha_c0_offset, h->slice_beta_offset);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (h->avctx->skip_loop_filter >= AVDISCARD_ALL ||\n\n        (h->avctx->skip_loop_filter >= AVDISCARD_NONKEY &&\n\n         sl->slice_type_nos != AV_PICTURE_TYPE_I) ||\n\n        (h->avctx->skip_loop_filter >= AVDISCARD_BIDIR  &&\n\n         sl->slice_type_nos == AV_PICTURE_TYPE_B) ||\n\n        (h->avctx->skip_loop_filter >= AVDISCARD_NONREF &&\n\n         h->nal_ref_idc == 0))\n\n        h->deblocking_filter = 0;\n\n\n\n    if (h->deblocking_filter == 1 && h0->max_contexts > 1) {\n\n        if (h->avctx->flags2 & CODEC_FLAG2_FAST) {\n\n            /* Cheat slightly for speed:\n\n             * Do not bother to deblock across slices. */\n\n            h->deblocking_filter = 2;\n\n        } else {\n\n            h0->max_contexts = 1;\n\n            if (!h0->single_decode_warning) {\n\n                av_log(h->avctx, AV_LOG_INFO,\n\n                       \"Cannot parallelize deblocking type 1, decoding such frames in sequential order\\n\");\n\n                h0->single_decode_warning = 1;\n\n            }\n\n            if (h != h0) {\n\n                av_log(h->avctx, AV_LOG_ERROR,\n\n                       \"Deblocking switched inside frame.\\n\");\n\n                return 1;\n\n            }\n\n        }\n\n    }\n\n    sl->qp_thresh = 15 -\n\n                   FFMIN(h->slice_alpha_c0_offset, h->slice_beta_offset) -\n\n                   FFMAX3(0,\n\n                          h->pps.chroma_qp_index_offset[0],\n\n                          h->pps.chroma_qp_index_offset[1]) +\n\n                   6 * (h->sps.bit_depth_luma - 8);\n\n\n\n    h0->last_slice_type = slice_type;\n\n    sl->slice_num       = ++h0->current_slice;\n\n    if (sl->slice_num >= MAX_SLICES) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"Too many slices, increase MAX_SLICES and recompile\\n\");\n\n    }\n\n\n\n    for (j = 0; j < 2; j++) {\n\n        int id_list[16];\n\n        int *ref2frm = sl->ref2frm[sl->slice_num & (MAX_SLICES - 1)][j];\n\n        for (i = 0; i < 16; i++) {\n\n            id_list[i] = 60;\n\n            if (j < sl->list_count && i < sl->ref_count[j] &&\n\n                sl->ref_list[j][i].f.buf[0]) {\n\n                int k;\n\n                AVBuffer *buf = sl->ref_list[j][i].f.buf[0]->buffer;\n\n                for (k = 0; k < h->short_ref_count; k++)\n\n                    if (h->short_ref[k]->f.buf[0]->buffer == buf) {\n\n                        id_list[i] = k;\n\n                        break;\n\n                    }\n\n                for (k = 0; k < h->long_ref_count; k++)\n\n                    if (h->long_ref[k] && h->long_ref[k]->f.buf[0]->buffer == buf) {\n\n                        id_list[i] = h->short_ref_count + k;\n\n                        break;\n\n                    }\n\n            }\n\n        }\n\n\n\n        ref2frm[0] =\n\n        ref2frm[1] = -1;\n\n        for (i = 0; i < 16; i++)\n\n            ref2frm[i + 2] = 4 * id_list[i] + (sl->ref_list[j][i].reference & 3);\n\n        ref2frm[18 + 0] =\n\n        ref2frm[18 + 1] = -1;\n\n        for (i = 16; i < 48; i++)\n\n            ref2frm[i + 4] = 4 * id_list[(i - 16) >> 1] +\n\n                             (sl->ref_list[j][i].reference & 3);\n\n    }\n\n\n\n    if (h->avctx->debug & FF_DEBUG_PICT_INFO) {\n\n        av_log(h->avctx, AV_LOG_DEBUG,\n\n               \"slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\\n\",\n\n               sl->slice_num,\n\n               (h->picture_structure == PICT_FRAME ? \"F\" : h->picture_structure == PICT_TOP_FIELD ? \"T\" : \"B\"),\n\n               first_mb_in_slice,\n\n               av_get_picture_type_char(sl->slice_type),\n\n               sl->slice_type_fixed ? \" fix\" : \"\",\n\n               h->nal_unit_type == NAL_IDR_SLICE ? \" IDR\" : \"\",\n\n               pps_id, h->frame_num,\n\n               h->cur_pic_ptr->field_poc[0],\n\n               h->cur_pic_ptr->field_poc[1],\n\n               sl->ref_count[0], sl->ref_count[1],\n\n               sl->qscale,\n\n               h->deblocking_filter,\n\n               h->slice_alpha_c0_offset, h->slice_beta_offset,\n\n               sl->use_weight,\n\n               sl->use_weight == 1 && sl->use_weight_chroma ? \"c\" : \"\",\n\n               sl->slice_type == AV_PICTURE_TYPE_B ? (sl->direct_spatial_mv_pred ? \"SPAT\" : \"TEMP\") : \"\");\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25938}
{"project": "FFmpeg", "commit_id": "a66099192159d02b1a1c1820ddb24c7cea271a44", "target": 0, "func": "static int64_t mpegts_get_dts(AVFormatContext *s, int stream_index,\n\n                              int64_t *ppos, int64_t pos_limit)\n\n{\n\n    MpegTSContext *ts = s->priv_data;\n\n    int64_t pos;\n\n    int pos47 = ts->pos47_full % ts->raw_packet_size;\n\n    pos = ((*ppos  + ts->raw_packet_size - 1 - pos47) / ts->raw_packet_size) * ts->raw_packet_size + pos47;\n\n    ff_read_frame_flush(s);\n\n    if (avio_seek(s->pb, pos, SEEK_SET) < 0)\n\n        return AV_NOPTS_VALUE;\n\n    while(pos < pos_limit) {\n\n        int ret;\n\n        AVPacket pkt;\n\n        av_init_packet(&pkt);\n\n        ret= av_read_frame(s, &pkt);\n\n        if(ret < 0)\n\n            return AV_NOPTS_VALUE;\n\n        av_free_packet(&pkt);\n\n        if(pkt.dts != AV_NOPTS_VALUE && pkt.pos >= 0){\n\n            ff_reduce_index(s, pkt.stream_index);\n\n            av_add_index_entry(s->streams[pkt.stream_index], pkt.pos, pkt.dts, 0, 0, AVINDEX_KEYFRAME /* FIXME keyframe? */);\n\n            if(pkt.stream_index == stream_index){\n\n                *ppos= pkt.pos;\n\n                return pkt.dts;\n\n            }\n\n        }\n\n        pos = pkt.pos;\n\n    }\n\n\n\n    return AV_NOPTS_VALUE;\n\n}\n", "idx": 25941}
{"project": "FFmpeg", "commit_id": "68bd11f5de271a1a674f196a9e8ca2e7fe40ab6e", "target": 1, "func": "static int rv10_decode_frame(AVCodecContext *avctx, \n\n                             void *data, int *data_size,\n\n                             UINT8 *buf, int buf_size)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int i, mb_count, mb_pos, left;\n\n    DCTELEM block[6][64];\n\n    AVPicture *pict = data; \n\n\n\n#ifdef DEBUG\n\n    printf(\"*****frame %d size=%d\\n\", avctx->frame_number, buf_size);\n\n#endif\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0) {\n\n        *data_size = 0;\n\n        return 0;\n\n    }\n\n\n\n    init_get_bits(&s->gb, buf, buf_size);\n\n\n\n    mb_count = rv10_decode_picture_header(s);\n\n    if (mb_count < 0) {\n\n#ifdef DEBUG\n\n        printf(\"HEADER ERROR\\n\");\n\n#endif\n\n        return -1;\n\n    }\n\n    \n\n    if (s->mb_x >= s->mb_width ||\n\n        s->mb_y >= s->mb_height) {\n\n#ifdef DEBUG\n\n        printf(\"POS ERROR %d %d\\n\", s->mb_x, s->mb_y);\n\n#endif\n\n        return -1;\n\n    }\n\n    mb_pos = s->mb_y * s->mb_width + s->mb_x;\n\n    left = s->mb_width * s->mb_height - mb_pos;\n\n    if (mb_count > left) {\n\n#ifdef DEBUG\n\n        printf(\"COUNT ERROR\\n\");\n\n#endif\n\n        return -1;\n\n    }\n\n\n\n    if (s->mb_x == 0 && s->mb_y == 0) {\n\n        MPV_frame_start(s, avctx);\n\n    }\n\n\n\n#ifdef DEBUG\n\n    printf(\"qscale=%d\\n\", s->qscale);\n\n#endif\n\n\n\n    /* default quantization values */\n\n    s->y_dc_scale = 8;\n\n    s->c_dc_scale = 8;\n\n    s->rv10_first_dc_coded[0] = 0;\n\n    s->rv10_first_dc_coded[1] = 0;\n\n    s->rv10_first_dc_coded[2] = 0;\n\n\n\n    s->block_wrap[0]=\n\n    s->block_wrap[1]=\n\n    s->block_wrap[2]=\n\n    s->block_wrap[3]= s->mb_width*2 + 2;\n\n    s->block_wrap[4]=\n\n    s->block_wrap[5]= s->mb_width + 2;\n\n    s->block_index[0]= s->block_wrap[0]*(s->mb_y*2 + 1) - 1 + s->mb_x*2;\n\n    s->block_index[1]= s->block_wrap[0]*(s->mb_y*2 + 1)     + s->mb_x*2;\n\n    s->block_index[2]= s->block_wrap[0]*(s->mb_y*2 + 2) - 1 + s->mb_x*2;\n\n    s->block_index[3]= s->block_wrap[0]*(s->mb_y*2 + 2)     + s->mb_x*2;\n\n    s->block_index[4]= s->block_wrap[4]*(s->mb_y + 1)                    + s->block_wrap[0]*(s->mb_height*2 + 2) + s->mb_x;\n\n    s->block_index[5]= s->block_wrap[4]*(s->mb_y + 1 + s->mb_height + 2) + s->block_wrap[0]*(s->mb_height*2 + 2) + s->mb_x;\n\n    /* decode each macroblock */\n\n    for(i=0;i<mb_count;i++) {\n\n        s->block_index[0]+=2;\n\n        s->block_index[1]+=2;\n\n        s->block_index[2]+=2;\n\n        s->block_index[3]+=2;\n\n        s->block_index[4]++;\n\n        s->block_index[5]++;\n\n#ifdef DEBUG\n\n        printf(\"**mb x=%d y=%d\\n\", s->mb_x, s->mb_y);\n\n#endif\n\n        \n\n        memset(block, 0, sizeof(block));\n\n        s->mv_dir = MV_DIR_FORWARD;\n\n        s->mv_type = MV_TYPE_16X16; \n\n        if (h263_decode_mb(s, block) < 0) {\n\n#ifdef DEBUG\n\n            printf(\"ERROR\\n\");\n\n#endif\n\n            return -1;\n\n        }\n\n        MPV_decode_mb(s, block);\n\n        if (++s->mb_x == s->mb_width) {\n\n            s->mb_x = 0;\n\n            s->mb_y++;\n\n            s->block_index[0]= s->block_wrap[0]*(s->mb_y*2 + 1) - 1;\n\n            s->block_index[1]= s->block_wrap[0]*(s->mb_y*2 + 1);\n\n            s->block_index[2]= s->block_wrap[0]*(s->mb_y*2 + 2) - 1;\n\n            s->block_index[3]= s->block_wrap[0]*(s->mb_y*2 + 2);\n\n            s->block_index[4]= s->block_wrap[4]*(s->mb_y + 1)                    + s->block_wrap[0]*(s->mb_height*2 + 2);\n\n            s->block_index[5]= s->block_wrap[4]*(s->mb_y + 1 + s->mb_height + 2) + s->block_wrap[0]*(s->mb_height*2 + 2);\n\n        }\n\n    }\n\n\n\n    if (s->mb_x == 0 &&\n\n        s->mb_y == s->mb_height) {\n\n        MPV_frame_end(s);\n\n        \n\n        pict->data[0] = s->current_picture[0];\n\n        pict->data[1] = s->current_picture[1];\n\n        pict->data[2] = s->current_picture[2];\n\n        pict->linesize[0] = s->linesize;\n\n        pict->linesize[1] = s->uvlinesize;\n\n        pict->linesize[2] = s->uvlinesize;\n\n        \n\n        avctx->quality = s->qscale;\n\n        *data_size = sizeof(AVPicture);\n\n    } else {\n\n        *data_size = 0;\n\n    }\n\n    return buf_size;\n\n}\n", "idx": 25943}
{"project": "FFmpeg", "commit_id": "dd1e6b2a139a9eea61aefe24fc3295499e70d04b", "target": 0, "func": "static int http_open(URLContext *h, const char *uri, int flags)\n\n{\n\n    HTTPContext *s = h->priv_data;\n\n\n\n    h->is_streamed = 1;\n\n\n\n    s->filesize = -1;\n\n    av_strlcpy(s->location, uri, sizeof(s->location));\n\n\n\n    if (s->headers) {\n\n        int len = strlen(s->headers);\n\n        if (len < 2 || strcmp(\"\\r\\n\", s->headers + len - 2))\n\n            av_log(h, AV_LOG_WARNING, \"No trailing CRLF found in HTTP header.\\n\");\n\n    }\n\n\n\n    return http_open_cnx(h);\n\n}\n", "idx": 25945}
{"project": "FFmpeg", "commit_id": "bf2bc926f04dcdde0a22c137d08a0bb546e0179e", "target": 1, "func": "static int standard_decode_picture_primary_header(VC9Context *v)\n\n{\n\n    GetBitContext *gb = &v->s.gb;\n\n    int status = 0;\n\n\n\n    if (v->finterpflag) v->interpfrm = get_bits(gb, 1);\n\n    skip_bits(gb, 2); //framecnt unused\n\n    if (v->rangered) v->rangeredfrm = get_bits(gb, 1);\n\n    v->s.pict_type = get_bits(gb, 1);\n\n    if (v->s.avctx->max_b_frames)\n\n    {\n\n        if (!v->s.pict_type)\n\n        {\n\n            if (get_bits(gb, 1)) v->s.pict_type = I_TYPE;\n\n            else v->s.pict_type = B_TYPE;\n\n        }\n\n        else v->s.pict_type = P_TYPE;\n\n    }\n\n    else v->s.pict_type++;\n\n\n\n    switch (v->s.pict_type)\n\n    {\n\n    case I_TYPE: status = decode_i_picture_header(v); break;\n\n    case P_TYPE: status = decode_p_picture_primary_header(v); break;\n\n    case BI_TYPE:\n\n    case B_TYPE: status = decode_b_picture_primary_header(v); break;\n\n    }\n\n\n\n    if (status == FRAME_SKIPED)\n\n    {\n\n      av_log(v->s.avctx, AV_LOG_INFO, \"Skipping frame...\\n\");\n\n      return status;\n\n    }\n\n    return 0;\n\n}\n", "idx": 25947}
{"project": "FFmpeg", "commit_id": "a18456a2032e49385447a1d0d2f146f65fe9a5e1", "target": 0, "func": "static FFServerIPAddressACL* parse_dynamic_acl(FFServerStream *stream, HTTPContext *c)\n\n{\n\n    FILE* f;\n\n    char line[1024];\n\n    char  cmd[1024];\n\n    FFServerIPAddressACL *acl = NULL;\n\n    int line_num = 0;\n\n    const char *p;\n\n\n\n    f = fopen(stream->dynamic_acl, \"r\");\n\n    if (!f) {\n\n        perror(stream->dynamic_acl);\n\n        return NULL;\n\n    }\n\n\n\n    acl = av_mallocz(sizeof(FFServerIPAddressACL));\n\n\n\n    /* Build ACL */\n\n    for(;;) {\n\n        if (fgets(line, sizeof(line), f) == NULL)\n\n            break;\n\n        line_num++;\n\n        p = line;\n\n        while (av_isspace(*p))\n\n            p++;\n\n        if (*p == '\\0' || *p == '#')\n\n            continue;\n\n        ffserver_get_arg(cmd, sizeof(cmd), &p);\n\n\n\n        if (!av_strcasecmp(cmd, \"ACL\"))\n\n            ffserver_parse_acl_row(NULL, NULL, acl, p, stream->dynamic_acl, line_num);\n\n    }\n\n    fclose(f);\n\n    return acl;\n\n}\n", "idx": 25948}
{"project": "FFmpeg", "commit_id": "3ee8eefbf2623e1e337df7d962412b0703336431", "target": 1, "func": "int attribute_align_arg sws_scale(struct SwsContext *c,\n\n                                  const uint8_t * const srcSlice[],\n\n                                  const int srcStride[], int srcSliceY,\n\n                                  int srcSliceH, uint8_t *const dst[],\n\n                                  const int dstStride[])\n\n{\n\n    int i, ret;\n\n    const uint8_t *src2[4] = { srcSlice[0], srcSlice[1], srcSlice[2], srcSlice[3] };\n\n    uint8_t *dst2[4] = { dst[0], dst[1], dst[2], dst[3] };\n\n    uint8_t *rgb0_tmp = NULL;\n\n\n\n    // do not mess up sliceDir if we have a \"trailing\" 0-size slice\n\n    if (srcSliceH == 0)\n\n        return 0;\n\n\n\n    if (!check_image_pointers(srcSlice, c->srcFormat, srcStride)) {\n\n        av_log(c, AV_LOG_ERROR, \"bad src image pointers\\n\");\n\n        return 0;\n\n    }\n\n    if (!check_image_pointers((const uint8_t* const*)dst, c->dstFormat, dstStride)) {\n\n        av_log(c, AV_LOG_ERROR, \"bad dst image pointers\\n\");\n\n        return 0;\n\n    }\n\n\n\n    if (c->sliceDir == 0 && srcSliceY != 0 && srcSliceY + srcSliceH != c->srcH) {\n\n        av_log(c, AV_LOG_ERROR, \"Slices start in the middle!\\n\");\n\n        return 0;\n\n    }\n\n    if (c->sliceDir == 0) {\n\n        if (srcSliceY == 0) c->sliceDir = 1; else c->sliceDir = -1;\n\n    }\n\n\n\n    if (usePal(c->srcFormat)) {\n\n        for (i = 0; i < 256; i++) {\n\n            int p, r, g, b, y, u, v, a = 0xff;\n\n            if (c->srcFormat == AV_PIX_FMT_PAL8) {\n\n                p = ((const uint32_t *)(srcSlice[1]))[i];\n\n                a = (p >> 24) & 0xFF;\n\n                r = (p >> 16) & 0xFF;\n\n                g = (p >>  8) & 0xFF;\n\n                b =  p        & 0xFF;\n\n            } else if (c->srcFormat == AV_PIX_FMT_RGB8) {\n\n                r = ( i >> 5     ) * 36;\n\n                g = ((i >> 2) & 7) * 36;\n\n                b = ( i       & 3) * 85;\n\n            } else if (c->srcFormat == AV_PIX_FMT_BGR8) {\n\n                b = ( i >> 6     ) * 85;\n\n                g = ((i >> 3) & 7) * 36;\n\n                r = ( i       & 7) * 36;\n\n            } else if (c->srcFormat == AV_PIX_FMT_RGB4_BYTE) {\n\n                r = ( i >> 3     ) * 255;\n\n                g = ((i >> 1) & 3) * 85;\n\n                b = ( i       & 1) * 255;\n\n            } else if (c->srcFormat == AV_PIX_FMT_GRAY8 || c->srcFormat == AV_PIX_FMT_GRAY8A) {\n\n                r = g = b = i;\n\n            } else {\n\n                av_assert1(c->srcFormat == AV_PIX_FMT_BGR4_BYTE);\n\n                b = ( i >> 3     ) * 255;\n\n                g = ((i >> 1) & 3) * 85;\n\n                r = ( i       & 1) * 255;\n\n            }\n\n#define RGB2YUV_SHIFT 15\n\n#define BY ( (int) (0.114 * 219 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define BV (-(int) (0.081 * 224 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define BU ( (int) (0.500 * 224 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define GY ( (int) (0.587 * 219 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define GV (-(int) (0.419 * 224 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define GU (-(int) (0.331 * 224 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define RY ( (int) (0.299 * 219 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define RV ( (int) (0.500 * 224 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define RU (-(int) (0.169 * 224 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n\n\n            y = av_clip_uint8((RY * r + GY * g + BY * b + ( 33 << (RGB2YUV_SHIFT - 1))) >> RGB2YUV_SHIFT);\n\n            u = av_clip_uint8((RU * r + GU * g + BU * b + (257 << (RGB2YUV_SHIFT - 1))) >> RGB2YUV_SHIFT);\n\n            v = av_clip_uint8((RV * r + GV * g + BV * b + (257 << (RGB2YUV_SHIFT - 1))) >> RGB2YUV_SHIFT);\n\n            c->pal_yuv[i]= y + (u<<8) + (v<<16) + (a<<24);\n\n\n\n            switch (c->dstFormat) {\n\n            case AV_PIX_FMT_BGR32:\n\n#if !HAVE_BIGENDIAN\n\n            case AV_PIX_FMT_RGB24:\n\n#endif\n\n                c->pal_rgb[i]=  r + (g<<8) + (b<<16) + (a<<24);\n\n                break;\n\n            case AV_PIX_FMT_BGR32_1:\n\n#if HAVE_BIGENDIAN\n\n            case AV_PIX_FMT_BGR24:\n\n#endif\n\n                c->pal_rgb[i]= a + (r<<8) + (g<<16) + (b<<24);\n\n                break;\n\n            case AV_PIX_FMT_RGB32_1:\n\n#if HAVE_BIGENDIAN\n\n            case AV_PIX_FMT_RGB24:\n\n#endif\n\n                c->pal_rgb[i]= a + (b<<8) + (g<<16) + (r<<24);\n\n                break;\n\n            case AV_PIX_FMT_RGB32:\n\n#if !HAVE_BIGENDIAN\n\n            case AV_PIX_FMT_BGR24:\n\n#endif\n\n            default:\n\n                c->pal_rgb[i]=  b + (g<<8) + (r<<16) + (a<<24);\n\n            }\n\n        }\n\n    }\n\n\n\n    if (c->src0Alpha && !c->dst0Alpha && isALPHA(c->dstFormat)) {\n\n        uint8_t *base;\n\n        int x,y;\n\n        rgb0_tmp = av_malloc(FFABS(srcStride[0]) * srcSliceH + 32);\n\n        base = srcStride[0] < 0 ? rgb0_tmp - srcStride[0] * (srcSliceH-1) : rgb0_tmp;\n\n        for (y=0; y<srcSliceH; y++){\n\n            memcpy(base + srcStride[0]*y, src2[0] + srcStride[0]*y, 4*c->srcW);\n\n            for (x=c->src0Alpha-1; x<4*c->srcW; x+=4) {\n\n                base[ srcStride[0]*y + x] = 0xFF;\n\n            }\n\n        }\n\n        src2[0] = base;\n\n    }\n\n\n\n    // copy strides, so they can safely be modified\n\n    if (c->sliceDir == 1) {\n\n        // slices go from top to bottom\n\n        int srcStride2[4] = { srcStride[0], srcStride[1], srcStride[2],\n\n                              srcStride[3] };\n\n        int dstStride2[4] = { dstStride[0], dstStride[1], dstStride[2],\n\n                              dstStride[3] };\n\n\n\n        reset_ptr(src2, c->srcFormat);\n\n        reset_ptr((void*)dst2, c->dstFormat);\n\n\n\n        /* reset slice direction at end of frame */\n\n        if (srcSliceY + srcSliceH == c->srcH)\n\n            c->sliceDir = 0;\n\n\n\n        ret = c->swScale(c, src2, srcStride2, srcSliceY, srcSliceH, dst2,\n\n                          dstStride2);\n\n    } else {\n\n        // slices go from bottom to top => we flip the image internally\n\n        int srcStride2[4] = { -srcStride[0], -srcStride[1], -srcStride[2],\n\n                              -srcStride[3] };\n\n        int dstStride2[4] = { -dstStride[0], -dstStride[1], -dstStride[2],\n\n                              -dstStride[3] };\n\n\n\n        src2[0] += (srcSliceH - 1) * srcStride[0];\n\n        if (!usePal(c->srcFormat))\n\n            src2[1] += ((srcSliceH >> c->chrSrcVSubSample) - 1) * srcStride[1];\n\n        src2[2] += ((srcSliceH >> c->chrSrcVSubSample) - 1) * srcStride[2];\n\n        src2[3] += (srcSliceH - 1) * srcStride[3];\n\n        dst2[0] += ( c->dstH                         - 1) * dstStride[0];\n\n        dst2[1] += ((c->dstH >> c->chrDstVSubSample) - 1) * dstStride[1];\n\n        dst2[2] += ((c->dstH >> c->chrDstVSubSample) - 1) * dstStride[2];\n\n        dst2[3] += ( c->dstH                         - 1) * dstStride[3];\n\n\n\n        reset_ptr(src2, c->srcFormat);\n\n        reset_ptr((void*)dst2, c->dstFormat);\n\n\n\n        /* reset slice direction at end of frame */\n\n        if (!srcSliceY)\n\n            c->sliceDir = 0;\n\n\n\n        ret = c->swScale(c, src2, srcStride2, c->srcH-srcSliceY-srcSliceH,\n\n                          srcSliceH, dst2, dstStride2);\n\n    }\n\n\n\n    av_free(rgb0_tmp);\n\n    return ret;\n\n}\n", "idx": 25949}
{"project": "FFmpeg", "commit_id": "9d66aa2c8fa60fe4a570021175ce66316baeb746", "target": 1, "func": "static av_cold int MPA_encode_init(AVCodecContext *avctx)\n\n{\n\n    MpegAudioContext *s = avctx->priv_data;\n\n    int freq = avctx->sample_rate;\n\n    int bitrate = avctx->bit_rate;\n\n    int channels = avctx->channels;\n\n    int i, v, table;\n\n    float a;\n\n\n\n    if (channels <= 0 || channels > 2){\n\n        av_log(avctx, AV_LOG_ERROR, \"encoding %d channel(s) is not allowed in mp2\\n\", channels);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    bitrate = bitrate / 1000;\n\n    s->nb_channels = channels;\n\n    avctx->frame_size = MPA_FRAME_SIZE;\n\n    avctx->delay      = 512 - 32 + 1;\n\n\n\n    /* encoding freq */\n\n    s->lsf = 0;\n\n    for(i=0;i<3;i++) {\n\n        if (avpriv_mpa_freq_tab[i] == freq)\n\n            break;\n\n        if ((avpriv_mpa_freq_tab[i] / 2) == freq) {\n\n            s->lsf = 1;\n\n            break;\n\n        }\n\n    }\n\n    if (i == 3){\n\n        av_log(avctx, AV_LOG_ERROR, \"Sampling rate %d is not allowed in mp2\\n\", freq);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    s->freq_index = i;\n\n\n\n    /* encoding bitrate & frequency */\n\n    for(i=0;i<15;i++) {\n\n        if (avpriv_mpa_bitrate_tab[s->lsf][1][i] == bitrate)\n\n            break;\n\n    }\n\n    if (i == 15){\n\n        av_log(avctx, AV_LOG_ERROR, \"bitrate %d is not allowed in mp2\\n\", bitrate);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    s->bitrate_index = i;\n\n\n\n    /* compute total header size & pad bit */\n\n\n\n    a = (float)(bitrate * 1000 * MPA_FRAME_SIZE) / (freq * 8.0);\n\n    s->frame_size = ((int)a) * 8;\n\n\n\n    /* frame fractional size to compute padding */\n\n    s->frame_frac = 0;\n\n    s->frame_frac_incr = (int)((a - floor(a)) * 65536.0);\n\n\n\n    /* select the right allocation table */\n\n    table = ff_mpa_l2_select_table(bitrate, s->nb_channels, freq, s->lsf);\n\n\n\n    /* number of used subbands */\n\n    s->sblimit = ff_mpa_sblimit_table[table];\n\n    s->alloc_table = ff_mpa_alloc_tables[table];\n\n\n\n    av_dlog(avctx, \"%d kb/s, %d Hz, frame_size=%d bits, table=%d, padincr=%x\\n\",\n\n            bitrate, freq, s->frame_size, table, s->frame_frac_incr);\n\n\n\n    for(i=0;i<s->nb_channels;i++)\n\n        s->samples_offset[i] = 0;\n\n\n\n    for(i=0;i<257;i++) {\n\n        int v;\n\n        v = ff_mpa_enwindow[i];\n\n#if WFRAC_BITS != 16\n\n        v = (v + (1 << (16 - WFRAC_BITS - 1))) >> (16 - WFRAC_BITS);\n\n#endif\n\n        s->filter_bank[i] = v;\n\n        if ((i & 63) != 0)\n\n            v = -v;\n\n        if (i != 0)\n\n            s->filter_bank[512 - i] = v;\n\n    }\n\n\n\n    for(i=0;i<64;i++) {\n\n        v = (int)(exp2((3 - i) / 3.0) * (1 << 20));\n\n        if (v <= 0)\n\n            v = 1;\n\n        s->scale_factor_table[i] = v;\n\n#if USE_FLOATS\n\n        s->scale_factor_inv_table[i] = exp2(-(3 - i) / 3.0) / (float)(1 << 20);\n\n#else\n\n#define P 15\n\n        s->scale_factor_shift[i] = 21 - P - (i / 3);\n\n        s->scale_factor_mult[i] = (1 << P) * exp2((i % 3) / 3.0);\n\n#endif\n\n    }\n\n    for(i=0;i<128;i++) {\n\n        v = i - 64;\n\n        if (v <= -3)\n\n            v = 0;\n\n        else if (v < 0)\n\n            v = 1;\n\n        else if (v == 0)\n\n            v = 2;\n\n        else if (v < 3)\n\n            v = 3;\n\n        else\n\n            v = 4;\n\n        s->scale_diff_table[i] = v;\n\n    }\n\n\n\n    for(i=0;i<17;i++) {\n\n        v = ff_mpa_quant_bits[i];\n\n        if (v < 0)\n\n            v = -v;\n\n        else\n\n            v = v * 3;\n\n        s->total_quant_bits[i] = 12 * v;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25950}
{"project": "FFmpeg", "commit_id": "a66dcfeedc68c080965cf78e1e0694967acef5af", "target": 1, "func": "static av_cold int vc1_decode_init(AVCodecContext *avctx)\n{\n    VC1Context *v = avctx->priv_data;\n    MpegEncContext *s = &v->s;\n    GetBitContext gb;\n    int ret;\n    /* save the container output size for WMImage */\n    v->output_width  = avctx->width;\n    v->output_height = avctx->height;\n    if (!avctx->extradata_size || !avctx->extradata)\n        return -1;\n    if (!(avctx->flags & CODEC_FLAG_GRAY))\n        avctx->pix_fmt = ff_get_format(avctx, avctx->codec->pix_fmts);\n    else\n        avctx->pix_fmt = AV_PIX_FMT_GRAY8;\n    v->s.avctx = avctx;\n    if ((ret = ff_vc1_init_common(v)) < 0)\n        return ret;\n    // ensure static VLC tables are initialized\n    if ((ret = ff_msmpeg4_decode_init(avctx)) < 0)\n        return ret;\n    if ((ret = ff_vc1_decode_init_alloc_tables(v)) < 0)\n        return ret;\n    // Hack to ensure the above functions will be called\n    // again once we know all necessary settings.\n    // That this is necessary might indicate a bug.\n    ff_vc1_decode_end(avctx);\n    ff_blockdsp_init(&s->bdsp, avctx);\n    ff_h264chroma_init(&v->h264chroma, 8);\n    ff_qpeldsp_init(&s->qdsp);\n    if (avctx->codec_id == AV_CODEC_ID_WMV3 || avctx->codec_id == AV_CODEC_ID_WMV3IMAGE) {\n        int count = 0;\n        // looks like WMV3 has a sequence header stored in the extradata\n        // advanced sequence header may be before the first frame\n        // the last byte of the extradata is a version number, 1 for the\n        // samples we can decode\n        init_get_bits(&gb, avctx->extradata, avctx->extradata_size*8);\n        if ((ret = ff_vc1_decode_sequence_header(avctx, v, &gb)) < 0)\n          return ret;\n        count = avctx->extradata_size*8 - get_bits_count(&gb);\n        if (count > 0) {\n            av_log(avctx, AV_LOG_INFO, \"Extra data: %i bits left, value: %X\\n\",\n                   count, get_bits(&gb, count));\n        } else if (count < 0) {\n            av_log(avctx, AV_LOG_INFO, \"Read %i bits in overflow\\n\", -count);\n        }\n    } else { // VC1/WVC1/WVP2\n        const uint8_t *start = avctx->extradata;\n        uint8_t *end = avctx->extradata + avctx->extradata_size;\n        const uint8_t *next;\n        int size, buf2_size;\n        uint8_t *buf2 = NULL;\n        int seq_initialized = 0, ep_initialized = 0;\n        if (avctx->extradata_size < 16) {\n            av_log(avctx, AV_LOG_ERROR, \"Extradata size too small: %i\\n\", avctx->extradata_size);\n            return -1;\n        }\n        buf2  = av_mallocz(avctx->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE);\n        start = find_next_marker(start, end); // in WVC1 extradata first byte is its size, but can be 0 in mkv\n        next  = start;\n        for (; next < end; start = next) {\n            next = find_next_marker(start + 4, end);\n            size = next - start - 4;\n            if (size <= 0)\n                continue;\n            buf2_size = vc1_unescape_buffer(start + 4, size, buf2);\n            init_get_bits(&gb, buf2, buf2_size * 8);\n            switch (AV_RB32(start)) {\n            case VC1_CODE_SEQHDR:\n                if ((ret = ff_vc1_decode_sequence_header(avctx, v, &gb)) < 0) {\n                    av_free(buf2);\n                    return ret;\n                }\n                seq_initialized = 1;\n                break;\n            case VC1_CODE_ENTRYPOINT:\n                if ((ret = ff_vc1_decode_entry_point(avctx, v, &gb)) < 0) {\n                    av_free(buf2);\n                    return ret;\n                }\n                ep_initialized = 1;\n                break;\n            }\n        }\n        av_free(buf2);\n        if (!seq_initialized || !ep_initialized) {\n            av_log(avctx, AV_LOG_ERROR, \"Incomplete extradata\\n\");\n            return -1;\n        }\n        v->res_sprite = (avctx->codec_id == AV_CODEC_ID_VC1IMAGE);\n    }\n    v->sprite_output_frame = av_frame_alloc();\n    if (!v->sprite_output_frame)\n    avctx->profile = v->profile;\n    if (v->profile == PROFILE_ADVANCED)\n        avctx->level = v->level;\n    avctx->has_b_frames = !!avctx->max_b_frames;\n    if (v->color_prim == 1 || v->color_prim == 5 || v->color_prim == 6)\n        avctx->color_primaries = v->color_prim;\n    if (v->transfer_char == 1 || v->transfer_char == 7)\n        avctx->color_trc = v->transfer_char;\n    if (v->matrix_coef == 1 || v->matrix_coef == 6 || v->matrix_coef == 7)\n        avctx->colorspace = v->matrix_coef;\n    s->mb_width  = (avctx->coded_width  + 15) >> 4;\n    s->mb_height = (avctx->coded_height + 15) >> 4;\n    if (v->profile == PROFILE_ADVANCED || v->res_fasttx) {\n        ff_vc1_init_transposed_scantables(v);\n    } else {\n        memcpy(v->zz_8x8, ff_wmv1_scantable, 4*64);\n        v->left_blk_sh = 3;\n        v->top_blk_sh  = 0;\n    }\n    if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n        v->sprite_width  = avctx->coded_width;\n        v->sprite_height = avctx->coded_height;\n        avctx->coded_width  = avctx->width  = v->output_width;\n        avctx->coded_height = avctx->height = v->output_height;\n        // prevent 16.16 overflows\n        if (v->sprite_width  > 1 << 14 ||\n            v->sprite_height > 1 << 14 ||\n            v->output_width  > 1 << 14 ||\n            v->output_height > 1 << 14) return -1;\n        if ((v->sprite_width&1) || (v->sprite_height&1)) {\n            avpriv_request_sample(avctx, \"odd sprites support\");\n            return AVERROR_PATCHWELCOME;\n        }\n    }\n    return 0;\n}", "idx": 25952}
{"project": "FFmpeg", "commit_id": "4d388c0cd05dd4de545e8ea333ab4de7d67ad12d", "target": 1, "func": "int ff_h264_fill_default_ref_list(H264Context *h)\n\n{\n\n    int i, len;\n\n\n\n    if (h->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n        Picture *sorted[32];\n\n        int cur_poc, list;\n\n        int lens[2];\n\n\n\n        if (FIELD_PICTURE(h))\n\n            cur_poc = h->cur_pic_ptr->field_poc[h->picture_structure == PICT_BOTTOM_FIELD];\n\n        else\n\n            cur_poc = h->cur_pic_ptr->poc;\n\n\n\n        for (list = 0; list < 2; list++) {\n\n            len  = add_sorted(sorted,       h->short_ref, h->short_ref_count, cur_poc, 1 ^ list);\n\n            len += add_sorted(sorted + len, h->short_ref, h->short_ref_count, cur_poc, 0 ^ list);\n\n            assert(len <= 32);\n\n            len  = build_def_list(h->default_ref_list[list],       sorted,      len, 0, h->picture_structure);\n\n            len += build_def_list(h->default_ref_list[list] + len, h->long_ref, 16,  1, h->picture_structure);\n\n            assert(len <= 32);\n\n\n\n            if (len < h->ref_count[list])\n\n                memset(&h->default_ref_list[list][len], 0, sizeof(Picture) * (h->ref_count[list] - len));\n\n            lens[list] = len;\n\n        }\n\n\n\n        if (lens[0] == lens[1] && lens[1] > 1) {\n\n            for (i = 0; i < lens[0] &&\n\n                        h->default_ref_list[0][i].f.buf[0]->buffer ==\n\n                        h->default_ref_list[1][i].f.buf[0]->buffer; i++);\n\n            if (i == lens[0]) {\n\n                Picture tmp;\n\n                COPY_PICTURE(&tmp, &h->default_ref_list[1][0]);\n\n                COPY_PICTURE(&h->default_ref_list[1][0], &h->default_ref_list[1][1]);\n\n                COPY_PICTURE(&h->default_ref_list[1][1], &tmp);\n\n            }\n\n        }\n\n    } else {\n\n        len  = build_def_list(h->default_ref_list[0],       h->short_ref, h->short_ref_count, 0, h->picture_structure);\n\n        len += build_def_list(h->default_ref_list[0] + len, h-> long_ref, 16,                 1, h->picture_structure);\n\n        assert(len <= 32);\n\n        if (len < h->ref_count[0])\n\n            memset(&h->default_ref_list[0][len], 0, sizeof(Picture) * (h->ref_count[0] - len));\n\n    }\n\n#ifdef TRACE\n\n    for (i = 0; i < h->ref_count[0]; i++) {\n\n        tprintf(h->avctx, \"List0: %s fn:%d 0x%p\\n\",\n\n                (h->default_ref_list[0][i].long_ref ? \"LT\" : \"ST\"),\n\n                h->default_ref_list[0][i].pic_id,\n\n                h->default_ref_list[0][i].f.data[0]);\n\n    }\n\n    if (h->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n        for (i = 0; i < h->ref_count[1]; i++) {\n\n            tprintf(h->avctx, \"List1: %s fn:%d 0x%p\\n\",\n\n                    (h->default_ref_list[1][i].long_ref ? \"LT\" : \"ST\"),\n\n                    h->default_ref_list[1][i].pic_id,\n\n                    h->default_ref_list[1][i].f.data[0]);\n\n        }\n\n    }\n\n#endif\n\n    return 0;\n\n}\n", "idx": 25953}
{"project": "FFmpeg", "commit_id": "b4356e4118b6cbe3a6ed81d16369acc5ff40ad05", "target": 1, "func": "static void start_frame(AVFilterLink *link, AVFilterBufferRef *picref)\n\n{\n\n    AVFilterContext *ctx = link->dst;\n\n    CropContext *crop = ctx->priv;\n\n    AVFilterBufferRef *ref2;\n\n    int i;\n\n\n\n    picref->video->w = crop->w;\n\n    picref->video->h = crop->h;\n\n\n\n    ref2 = avfilter_ref_buffer(picref, ~0);\n\n\n\n    crop->var_values[VAR_T] = picref->pts == AV_NOPTS_VALUE ?\n\n        NAN : picref->pts * av_q2d(link->time_base);\n\n    crop->var_values[VAR_POS] = picref->pos == -1 ? NAN : picref->pos;\n\n    crop->var_values[VAR_X] = av_expr_eval(crop->x_pexpr, crop->var_values, NULL);\n\n    crop->var_values[VAR_Y] = av_expr_eval(crop->y_pexpr, crop->var_values, NULL);\n\n    crop->var_values[VAR_X] = av_expr_eval(crop->x_pexpr, crop->var_values, NULL);\n\n\n\n    normalize_double(&crop->x, crop->var_values[VAR_X]);\n\n    normalize_double(&crop->y, crop->var_values[VAR_Y]);\n\n\n\n    if (crop->x < 0) crop->x = 0;\n\n    if (crop->y < 0) crop->y = 0;\n\n    if ((unsigned)crop->x + (unsigned)crop->w > link->w) crop->x = link->w - crop->w;\n\n    if ((unsigned)crop->y + (unsigned)crop->h > link->h) crop->y = link->h - crop->h;\n\n    crop->x &= ~((1 << crop->hsub) - 1);\n\n    crop->y &= ~((1 << crop->vsub) - 1);\n\n\n\n\n    av_log(ctx, AV_LOG_DEBUG,\n\n           \"n:%d t:%f x:%d y:%d x+w:%d y+h:%d\\n\",\n\n           (int)crop->var_values[VAR_N], crop->var_values[VAR_T], crop->x, crop->y, crop->x+crop->w, crop->y+crop->h);\n\n\n\n\n    ref2->data[0] += crop->y * ref2->linesize[0];\n\n    ref2->data[0] += crop->x * crop->max_step[0];\n\n\n\n    if (!(av_pix_fmt_descriptors[link->format].flags & PIX_FMT_PAL)) {\n\n        for (i = 1; i < 3; i ++) {\n\n            if (ref2->data[i]) {\n\n                ref2->data[i] += (crop->y >> crop->vsub) * ref2->linesize[i];\n\n                ref2->data[i] += (crop->x * crop->max_step[i]) >> crop->hsub;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* alpha plane */\n\n    if (ref2->data[3]) {\n\n        ref2->data[3] += crop->y * ref2->linesize[3];\n\n        ref2->data[3] += crop->x * crop->max_step[3];\n\n    }\n\n\n\n    avfilter_start_frame(link->dst->outputs[0], ref2);\n\n}", "idx": 25954}
{"project": "FFmpeg", "commit_id": "3ee8ca9b0894df3aaf5086c643283cb58ef9763d", "target": 0, "func": "void ff_ass_init(AVSubtitle *sub)\n\n{\n\n    memset(sub, 0, sizeof(*sub));\n\n}\n", "idx": 25966}
{"project": "FFmpeg", "commit_id": "61ee2ca7758672128e30b3e87908b6845e006d71", "target": 1, "func": "static void guess_palette(DVDSubContext* ctx,\n\n                          uint32_t *rgba_palette,\n\n                          uint32_t subtitle_color)\n\n{\n\n    static const uint8_t level_map[4][4] = {\n\n        // this configuration (full range, lowest to highest) in tests\n\n        // seemed most common, so assume this\n\n        {0xff},\n\n        {0x00, 0xff},\n\n        {0x00, 0x80, 0xff},\n\n        {0x00, 0x55, 0xaa, 0xff},\n\n    };\n\n    uint8_t color_used[16] = { 0 };\n\n    int nb_opaque_colors, i, level, j, r, g, b;\n\n    uint8_t *colormap = ctx->colormap, *alpha = ctx->alpha;\n\n\n\n    if(ctx->has_palette) {\n\n        for(i = 0; i < 4; i++)\n\n            rgba_palette[i] = (ctx->palette[colormap[i]] & 0x00ffffff)\n\n                              | ((alpha[i] * 17U) << 24);\n\n        return;\n\n    }\n\n\n\n    for(i = 0; i < 4; i++)\n\n        rgba_palette[i] = 0;\n\n\n\n    nb_opaque_colors = 0;\n\n    for(i = 0; i < 4; i++) {\n\n        if (alpha[i] != 0 && !color_used[colormap[i]]) {\n\n            color_used[colormap[i]] = 1;\n\n            nb_opaque_colors++;\n\n        }\n\n    }\n\n\n\n    if (nb_opaque_colors == 0)\n\n        return;\n\n\n\n    j = 0;\n\n    memset(color_used, 0, 16);\n\n    for(i = 0; i < 4; i++) {\n\n        if (alpha[i] != 0) {\n\n            if (!color_used[colormap[i]])  {\n\n                level = level_map[nb_opaque_colors - 1][j];\n\n                r = (((subtitle_color >> 16) & 0xff) * level) >> 8;\n\n                g = (((subtitle_color >> 8) & 0xff) * level) >> 8;\n\n                b = (((subtitle_color >> 0) & 0xff) * level) >> 8;\n\n                rgba_palette[i] = b | (g << 8) | (r << 16) | ((alpha[i] * 17) << 24);\n\n                color_used[colormap[i]] = (i + 1);\n\n                j++;\n\n            } else {\n\n                rgba_palette[i] = (rgba_palette[color_used[colormap[i]] - 1] & 0x00ffffff) |\n\n                                    ((alpha[i] * 17) << 24);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 25979}
{"project": "FFmpeg", "commit_id": "f4bd9fe326ad1315a74206939ae56df93b940a09", "target": 1, "func": "int ff_generate_sliding_window_mmcos(H264Context *h, int first_slice)\n\n{\n\n    MMCO mmco_temp[MAX_MMCO_COUNT], *mmco = first_slice ? h->mmco : mmco_temp;\n\n    int mmco_index = 0, i;\n\n\n\n    assert(h->long_ref_count + h->short_ref_count <= h->sps.ref_frame_count);\n\n\n\n    if (h->short_ref_count &&\n\n        h->long_ref_count + h->short_ref_count == h->sps.ref_frame_count &&\n\n        !(FIELD_PICTURE(h) && !h->first_field && h->cur_pic_ptr->reference)) {\n\n        mmco[0].opcode        = MMCO_SHORT2UNUSED;\n\n        mmco[0].short_pic_num = h->short_ref[h->short_ref_count - 1]->frame_num;\n\n        mmco_index            = 1;\n\n        if (FIELD_PICTURE(h)) {\n\n            mmco[0].short_pic_num *= 2;\n\n            mmco[1].opcode         = MMCO_SHORT2UNUSED;\n\n            mmco[1].short_pic_num  = mmco[0].short_pic_num + 1;\n\n            mmco_index             = 2;\n\n        }\n\n    }\n\n\n\n    if (first_slice) {\n\n        h->mmco_index = mmco_index;\n\n    } else if (!first_slice && mmco_index >= 0 &&\n\n               (mmco_index != h->mmco_index ||\n\n                (i = check_opcodes(h->mmco, mmco_temp, mmco_index)))) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"Inconsistent MMCO state between slices [%d, %d, %d]\\n\",\n\n               mmco_index, h->mmco_index, i);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    return 0;\n\n}\n", "idx": 25981}
{"project": "FFmpeg", "commit_id": "0ecca7a49f8e254c12a3a1de048d738bfbb614c6", "target": 1, "func": "ImgReSampleContext *img_resample_full_init(int owidth, int oheight,\n\n                                      int iwidth, int iheight,\n\n                                      int topBand, int bottomBand,\n\n        int leftBand, int rightBand,\n\n        int padtop, int padbottom,\n\n        int padleft, int padright)\n\n{\n\n    ImgReSampleContext *s;\n\n\n\n    s = av_mallocz(sizeof(ImgReSampleContext));\n\n    if (!s)\n\n\n\n\n    s->line_buf = av_mallocz(owidth * (LINE_BUF_HEIGHT + NB_TAPS));\n\n    if (!s->line_buf) \n\n        goto fail;\n\n    \n\n    s->owidth = owidth;\n\n    s->oheight = oheight;\n\n    s->iwidth = iwidth;\n\n    s->iheight = iheight;\n\n  \n\n    s->topBand = topBand;\n\n    s->bottomBand = bottomBand;\n\n    s->leftBand = leftBand;\n\n    s->rightBand = rightBand;\n\n    \n\n    s->padtop = padtop;\n\n    s->padbottom = padbottom;\n\n    s->padleft = padleft;\n\n    s->padright = padright;\n\n\n\n    s->pad_owidth = owidth - (padleft + padright);\n\n    s->pad_oheight = oheight - (padtop + padbottom);\n\n\n\n    s->h_incr = ((iwidth - leftBand - rightBand) * POS_FRAC) / s->pad_owidth;\n\n    s->v_incr = ((iheight - topBand - bottomBand) * POS_FRAC) / s->pad_oheight; \n\n\n\n    av_build_filter(&s->h_filters[0][0], (float) s->pad_owidth  / \n\n            (float) (iwidth - leftBand - rightBand), NB_TAPS, NB_PHASES, 1<<FILTER_BITS, 0);\n\n    av_build_filter(&s->v_filters[0][0], (float) s->pad_oheight / \n\n            (float) (iheight - topBand - bottomBand), NB_TAPS, NB_PHASES, 1<<FILTER_BITS, 0);\n\n\n\n    return s;\n\nfail:\n\n    av_free(s);\n\n\n}", "idx": 25983}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "static inline void idct4col_add(uint8_t *dest, int line_size, const DCTELEM *col)\n\n{\n\n    int c0, c1, c2, c3, a0, a1, a2, a3;\n\n    const uint8_t *cm = ff_cropTbl + MAX_NEG_CROP;\n\n\n\n    a0 = col[8*0];\n\n    a1 = col[8*1];\n\n    a2 = col[8*2];\n\n    a3 = col[8*3];\n\n    c0 = (a0 + a2)*C3 + (1 << (C_SHIFT - 1));\n\n    c2 = (a0 - a2)*C3 + (1 << (C_SHIFT - 1));\n\n    c1 = a1 * C1 + a3 * C2;\n\n    c3 = a1 * C2 - a3 * C1;\n\n    dest[0] = cm[dest[0] + ((c0 + c1) >> C_SHIFT)];\n\n    dest += line_size;\n\n    dest[0] = cm[dest[0] + ((c2 + c3) >> C_SHIFT)];\n\n    dest += line_size;\n\n    dest[0] = cm[dest[0] + ((c2 - c3) >> C_SHIFT)];\n\n    dest += line_size;\n\n    dest[0] = cm[dest[0] + ((c0 - c1) >> C_SHIFT)];\n\n}\n", "idx": 25988}
{"project": "FFmpeg", "commit_id": "c89e428ed8c2c31396af2d18cab4342b7d82958f", "target": 0, "func": "void ff_slice_buffer_init(slice_buffer *buf, int line_count,\n\n                          int max_allocated_lines, int line_width,\n\n                          IDWTELEM *base_buffer)\n\n{\n\n    int i;\n\n\n\n    buf->base_buffer = base_buffer;\n\n    buf->line_count  = line_count;\n\n    buf->line_width  = line_width;\n\n    buf->data_count  = max_allocated_lines;\n\n    buf->line        = av_mallocz(sizeof(IDWTELEM *) * line_count);\n\n    buf->data_stack  = av_malloc(sizeof(IDWTELEM *) * max_allocated_lines);\n\n\n\n    for (i = 0; i < max_allocated_lines; i++)\n\n        buf->data_stack[i] = av_malloc(sizeof(IDWTELEM) * line_width);\n\n\n\n    buf->data_stack_top = max_allocated_lines - 1;\n\n}\n", "idx": 25998}
{"project": "FFmpeg", "commit_id": "be4dfbf7b71e44a53ca8da882a081e35ea134c83", "target": 0, "func": "int ffurl_get_file_handle(URLContext *h)\n\n{\n\n    if (!h->prot->url_get_file_handle)\n\n        return -1;\n\n    return h->prot->url_get_file_handle(h);\n\n}\n", "idx": 26009}
{"project": "FFmpeg", "commit_id": "507dce2536fea4b78a9f4973f77e1fa20cfe1b81", "target": 0, "func": "av_cold void ff_rv40dsp_init(RV34DSPContext *c, DSPContext* dsp) {\n\n\n\n    ff_rv34dsp_init(c, dsp);\n\n\n\n    c->put_pixels_tab[0][ 0] = dsp->put_h264_qpel_pixels_tab[0][0];\n\n    c->put_pixels_tab[0][ 1] = put_rv40_qpel16_mc10_c;\n\n    c->put_pixels_tab[0][ 2] = dsp->put_h264_qpel_pixels_tab[0][2];\n\n    c->put_pixels_tab[0][ 3] = put_rv40_qpel16_mc30_c;\n\n    c->put_pixels_tab[0][ 4] = put_rv40_qpel16_mc01_c;\n\n    c->put_pixels_tab[0][ 5] = put_rv40_qpel16_mc11_c;\n\n    c->put_pixels_tab[0][ 6] = put_rv40_qpel16_mc21_c;\n\n    c->put_pixels_tab[0][ 7] = put_rv40_qpel16_mc31_c;\n\n    c->put_pixels_tab[0][ 8] = dsp->put_h264_qpel_pixels_tab[0][8];\n\n    c->put_pixels_tab[0][ 9] = put_rv40_qpel16_mc12_c;\n\n    c->put_pixels_tab[0][10] = put_rv40_qpel16_mc22_c;\n\n    c->put_pixels_tab[0][11] = put_rv40_qpel16_mc32_c;\n\n    c->put_pixels_tab[0][12] = put_rv40_qpel16_mc03_c;\n\n    c->put_pixels_tab[0][13] = put_rv40_qpel16_mc13_c;\n\n    c->put_pixels_tab[0][14] = put_rv40_qpel16_mc23_c;\n\n    c->put_pixels_tab[0][15] = ff_put_rv40_qpel16_mc33_c;\n\n    c->avg_pixels_tab[0][ 0] = dsp->avg_h264_qpel_pixels_tab[0][0];\n\n    c->avg_pixels_tab[0][ 1] = avg_rv40_qpel16_mc10_c;\n\n    c->avg_pixels_tab[0][ 2] = dsp->avg_h264_qpel_pixels_tab[0][2];\n\n    c->avg_pixels_tab[0][ 3] = avg_rv40_qpel16_mc30_c;\n\n    c->avg_pixels_tab[0][ 4] = avg_rv40_qpel16_mc01_c;\n\n    c->avg_pixels_tab[0][ 5] = avg_rv40_qpel16_mc11_c;\n\n    c->avg_pixels_tab[0][ 6] = avg_rv40_qpel16_mc21_c;\n\n    c->avg_pixels_tab[0][ 7] = avg_rv40_qpel16_mc31_c;\n\n    c->avg_pixels_tab[0][ 8] = dsp->avg_h264_qpel_pixels_tab[0][8];\n\n    c->avg_pixels_tab[0][ 9] = avg_rv40_qpel16_mc12_c;\n\n    c->avg_pixels_tab[0][10] = avg_rv40_qpel16_mc22_c;\n\n    c->avg_pixels_tab[0][11] = avg_rv40_qpel16_mc32_c;\n\n    c->avg_pixels_tab[0][12] = avg_rv40_qpel16_mc03_c;\n\n    c->avg_pixels_tab[0][13] = avg_rv40_qpel16_mc13_c;\n\n    c->avg_pixels_tab[0][14] = avg_rv40_qpel16_mc23_c;\n\n    c->avg_pixels_tab[0][15] = ff_avg_rv40_qpel16_mc33_c;\n\n    c->put_pixels_tab[1][ 0] = dsp->put_h264_qpel_pixels_tab[1][0];\n\n    c->put_pixels_tab[1][ 1] = put_rv40_qpel8_mc10_c;\n\n    c->put_pixels_tab[1][ 2] = dsp->put_h264_qpel_pixels_tab[1][2];\n\n    c->put_pixels_tab[1][ 3] = put_rv40_qpel8_mc30_c;\n\n    c->put_pixels_tab[1][ 4] = put_rv40_qpel8_mc01_c;\n\n    c->put_pixels_tab[1][ 5] = put_rv40_qpel8_mc11_c;\n\n    c->put_pixels_tab[1][ 6] = put_rv40_qpel8_mc21_c;\n\n    c->put_pixels_tab[1][ 7] = put_rv40_qpel8_mc31_c;\n\n    c->put_pixels_tab[1][ 8] = dsp->put_h264_qpel_pixels_tab[1][8];\n\n    c->put_pixels_tab[1][ 9] = put_rv40_qpel8_mc12_c;\n\n    c->put_pixels_tab[1][10] = put_rv40_qpel8_mc22_c;\n\n    c->put_pixels_tab[1][11] = put_rv40_qpel8_mc32_c;\n\n    c->put_pixels_tab[1][12] = put_rv40_qpel8_mc03_c;\n\n    c->put_pixels_tab[1][13] = put_rv40_qpel8_mc13_c;\n\n    c->put_pixels_tab[1][14] = put_rv40_qpel8_mc23_c;\n\n    c->put_pixels_tab[1][15] = ff_put_rv40_qpel8_mc33_c;\n\n    c->avg_pixels_tab[1][ 0] = dsp->avg_h264_qpel_pixels_tab[1][0];\n\n    c->avg_pixels_tab[1][ 1] = avg_rv40_qpel8_mc10_c;\n\n    c->avg_pixels_tab[1][ 2] = dsp->avg_h264_qpel_pixels_tab[1][2];\n\n    c->avg_pixels_tab[1][ 3] = avg_rv40_qpel8_mc30_c;\n\n    c->avg_pixels_tab[1][ 4] = avg_rv40_qpel8_mc01_c;\n\n    c->avg_pixels_tab[1][ 5] = avg_rv40_qpel8_mc11_c;\n\n    c->avg_pixels_tab[1][ 6] = avg_rv40_qpel8_mc21_c;\n\n    c->avg_pixels_tab[1][ 7] = avg_rv40_qpel8_mc31_c;\n\n    c->avg_pixels_tab[1][ 8] = dsp->avg_h264_qpel_pixels_tab[1][8];\n\n    c->avg_pixels_tab[1][ 9] = avg_rv40_qpel8_mc12_c;\n\n    c->avg_pixels_tab[1][10] = avg_rv40_qpel8_mc22_c;\n\n    c->avg_pixels_tab[1][11] = avg_rv40_qpel8_mc32_c;\n\n    c->avg_pixels_tab[1][12] = avg_rv40_qpel8_mc03_c;\n\n    c->avg_pixels_tab[1][13] = avg_rv40_qpel8_mc13_c;\n\n    c->avg_pixels_tab[1][14] = avg_rv40_qpel8_mc23_c;\n\n    c->avg_pixels_tab[1][15] = ff_avg_rv40_qpel8_mc33_c;\n\n\n\n    c->put_chroma_pixels_tab[0] = put_rv40_chroma_mc8_c;\n\n    c->put_chroma_pixels_tab[1] = put_rv40_chroma_mc4_c;\n\n    c->avg_chroma_pixels_tab[0] = avg_rv40_chroma_mc8_c;\n\n    c->avg_chroma_pixels_tab[1] = avg_rv40_chroma_mc4_c;\n\n\n\n    c->rv40_weight_pixels_tab[0][0] = rv40_weight_func_rnd_16;\n\n    c->rv40_weight_pixels_tab[0][1] = rv40_weight_func_rnd_8;\n\n    c->rv40_weight_pixels_tab[1][0] = rv40_weight_func_nornd_16;\n\n    c->rv40_weight_pixels_tab[1][1] = rv40_weight_func_nornd_8;\n\n\n\n    c->rv40_weak_loop_filter[0]     = rv40_h_weak_loop_filter;\n\n    c->rv40_weak_loop_filter[1]     = rv40_v_weak_loop_filter;\n\n    c->rv40_strong_loop_filter[0]   = rv40_h_strong_loop_filter;\n\n    c->rv40_strong_loop_filter[1]   = rv40_v_strong_loop_filter;\n\n    c->rv40_loop_filter_strength[0] = rv40_h_loop_filter_strength;\n\n    c->rv40_loop_filter_strength[1] = rv40_v_loop_filter_strength;\n\n\n\n    if (ARCH_X86)\n\n        ff_rv40dsp_init_x86(c, dsp);\n\n    if (HAVE_NEON)\n\n        ff_rv40dsp_init_neon(c, dsp);\n\n}\n", "idx": 26011}
{"project": "FFmpeg", "commit_id": "f7f88018393b96ae410041e9a0fc51f4c082002e", "target": 0, "func": "static int decode_nal_units(HEVCContext *s, const uint8_t *buf, int length)\n\n{\n\n    int i, consumed, ret = 0;\n\n\n\n    s->ref = NULL;\n\n    s->eos = 0;\n\n\n\n    /* split the input packet into NAL units, so we know the upper bound on the\n\n     * number of slices in the frame */\n\n    s->nb_nals = 0;\n\n    while (length >= 4) {\n\n        HEVCNAL *nal;\n\n        int extract_length = 0;\n\n\n\n        if (s->is_nalff) {\n\n            int i;\n\n            for (i = 0; i < s->nal_length_size; i++)\n\n                extract_length = (extract_length << 8) | buf[i];\n\n            buf    += s->nal_length_size;\n\n            length -= s->nal_length_size;\n\n\n\n            if (extract_length > length) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"Invalid NAL unit size.\\n\");\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n        } else {\n\n            if (buf[2] == 0) {\n\n                length--;\n\n                buf++;\n\n                continue;\n\n            }\n\n            if (buf[0] != 0 || buf[1] != 0 || buf[2] != 1) {\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n\n\n            buf    += 3;\n\n            length -= 3;\n\n        }\n\n\n\n        if (!s->is_nalff)\n\n            extract_length = length;\n\n\n\n        if (s->nals_allocated < s->nb_nals + 1) {\n\n            int new_size = s->nals_allocated + 1;\n\n            HEVCNAL *tmp = av_realloc_array(s->nals, new_size, sizeof(*tmp));\n\n            if (!tmp) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto fail;\n\n            }\n\n            s->nals = tmp;\n\n            memset(s->nals + s->nals_allocated, 0, (new_size - s->nals_allocated) * sizeof(*tmp));\n\n            av_reallocp_array(&s->skipped_bytes_nal, new_size, sizeof(*s->skipped_bytes_nal));\n\n            av_reallocp_array(&s->skipped_bytes_pos_size_nal, new_size, sizeof(*s->skipped_bytes_pos_size_nal));\n\n            av_reallocp_array(&s->skipped_bytes_pos_nal, new_size, sizeof(*s->skipped_bytes_pos_nal));\n\n            s->skipped_bytes_pos_size_nal[s->nals_allocated] = 1024; // initial buffer size\n\n            s->skipped_bytes_pos_nal[s->nals_allocated] = av_malloc_array(s->skipped_bytes_pos_size_nal[s->nals_allocated], sizeof(*s->skipped_bytes_pos));\n\n            s->nals_allocated = new_size;\n\n        }\n\n        s->skipped_bytes_pos_size = s->skipped_bytes_pos_size_nal[s->nb_nals];\n\n        s->skipped_bytes_pos = s->skipped_bytes_pos_nal[s->nb_nals];\n\n        nal = &s->nals[s->nb_nals];\n\n\n\n        consumed = extract_rbsp(s, buf, extract_length, nal);\n\n\n\n        s->skipped_bytes_nal[s->nb_nals] = s->skipped_bytes;\n\n        s->skipped_bytes_pos_size_nal[s->nb_nals] = s->skipped_bytes_pos_size;\n\n        s->skipped_bytes_pos_nal[s->nb_nals++] = s->skipped_bytes_pos;\n\n\n\n\n\n        if (consumed < 0) {\n\n            ret = consumed;\n\n            goto fail;\n\n        }\n\n\n\n        ret = init_get_bits8(&s->HEVClc->gb, nal->data, nal->size);\n\n        if (ret < 0)\n\n            goto fail;\n\n        hls_nal_unit(s);\n\n\n\n        if (s->nal_unit_type == NAL_EOS_NUT || s->nal_unit_type == NAL_EOB_NUT)\n\n            s->eos = 1;\n\n\n\n        buf    += consumed;\n\n        length -= consumed;\n\n    }\n\n\n\n    /* parse the NAL units */\n\n    for (i = 0; i < s->nb_nals; i++) {\n\n        int ret;\n\n        s->skipped_bytes = s->skipped_bytes_nal[i];\n\n        s->skipped_bytes_pos = s->skipped_bytes_pos_nal[i];\n\n\n\n        ret = decode_nal_unit(s, s->nals[i].data, s->nals[i].size);\n\n        if (ret < 0) {\n\n            av_log(s->avctx, AV_LOG_WARNING, \"Error parsing NAL unit #%d.\\n\", i);\n\n            if (s->avctx->err_recognition & AV_EF_EXPLODE)\n\n                goto fail;\n\n        }\n\n    }\n\n\n\nfail:\n\n    if (s->ref && s->threads_type == FF_THREAD_FRAME)\n\n        ff_thread_report_progress(&s->ref->tf, INT_MAX, 0);\n\n\n\n    return ret;\n\n}\n", "idx": 26012}
{"project": "FFmpeg", "commit_id": "2e988fd689642899927707a084bf40dc1326dc90", "target": 0, "func": "static void ttafilter_init(TTAContext *s, TTAFilter *c, int32_t shift) {\n\n    memset(c, 0, sizeof(TTAFilter));\n\n    if (s->pass) {\n\n        int i;\n\n        for (i = 0; i < 8; i++)\n\n            c->qm[i] = sign_extend(s->crc_pass[i], 8);\n\n    }\n\n    c->shift = shift;\n\n   c->round = shift_1[shift-1];\n\n//    c->round = 1 << (shift - 1);\n\n}\n", "idx": 26023}
{"project": "FFmpeg", "commit_id": "95b192de5d05f3e1542e7b2378cdefbc195f5185", "target": 0, "func": "static inline int vc1_pred_dc(MpegEncContext *s, int overlap, int pq, int n,\n\n                              int a_avail, int c_avail,\n\n                              int16_t **dc_val_ptr, int *dir_ptr)\n\n{\n\n    int a, b, c, wrap, pred;\n\n    int16_t *dc_val;\n\n    int mb_pos = s->mb_x + s->mb_y * s->mb_stride;\n\n    int q1, q2 = 0;\n\n\n\n    wrap = s->block_wrap[n];\n\n    dc_val = s->dc_val[0] + s->block_index[n];\n\n\n\n    /* B A\n\n     * C X\n\n     */\n\n    c = dc_val[ - 1];\n\n    b = dc_val[ - 1 - wrap];\n\n    a = dc_val[ - wrap];\n\n    /* scale predictors if needed */\n\n    q1 = s->current_picture.f.qscale_table[mb_pos];\n\n    if (c_avail && (n != 1 && n != 3)) {\n\n        q2 = s->current_picture.f.qscale_table[mb_pos - 1];\n\n        if (q2 && q2 != q1)\n\n            c = (c * s->y_dc_scale_table[q2] * ff_vc1_dqscale[s->y_dc_scale_table[q1] - 1] + 0x20000) >> 18;\n\n    }\n\n    if (a_avail && (n != 2 && n != 3)) {\n\n        q2 = s->current_picture.f.qscale_table[mb_pos - s->mb_stride];\n\n        if (q2 && q2 != q1)\n\n            a = (a * s->y_dc_scale_table[q2] * ff_vc1_dqscale[s->y_dc_scale_table[q1] - 1] + 0x20000) >> 18;\n\n    }\n\n    if (a_avail && c_avail && (n != 3)) {\n\n        int off = mb_pos;\n\n        if (n != 1)\n\n            off--;\n\n        if (n != 2)\n\n            off -= s->mb_stride;\n\n        q2 = s->current_picture.f.qscale_table[off];\n\n        if (q2 && q2 != q1)\n\n            b = (b * s->y_dc_scale_table[q2] * ff_vc1_dqscale[s->y_dc_scale_table[q1] - 1] + 0x20000) >> 18;\n\n    }\n\n\n\n    if (a_avail && c_avail) {\n\n        if (abs(a - b) <= abs(b - c)) {\n\n            pred     = c;\n\n            *dir_ptr = 1; // left\n\n        } else {\n\n            pred     = a;\n\n            *dir_ptr = 0; // top\n\n        }\n\n    } else if (a_avail) {\n\n        pred     = a;\n\n        *dir_ptr = 0; // top\n\n    } else if (c_avail) {\n\n        pred     = c;\n\n        *dir_ptr = 1; // left\n\n    } else {\n\n        pred     = 0;\n\n        *dir_ptr = 1; // left\n\n    }\n\n\n\n    /* update predictor */\n\n    *dc_val_ptr = &dc_val[0];\n\n    return pred;\n\n}\n", "idx": 26028}
{"project": "FFmpeg", "commit_id": "f2e9a0ecbef5027f9532c49ffcdfc11d199f6150", "target": 1, "func": "static av_cold int qsv_decode_close(AVCodecContext *avctx)\n{\n    QSVOtherContext *s = avctx->priv_data;\n    ff_qsv_decode_close(&s->qsv);\n    qsv_clear_buffers(s);\n    av_fifo_free(s->packet_fifo);\n    return 0;\n}", "idx": 26030}
{"project": "FFmpeg", "commit_id": "c83002a4f8042ccfa0688a9a18e8fa0369c1fda8", "target": 1, "func": "int ff_ass_split_override_codes(const ASSCodesCallbacks *callbacks, void *priv,\n\n                                const char *buf)\n\n{\n\n    const char *text = NULL;\n\n    char new_line[2];\n\n    int text_len = 0;\n\n\n\n    while (*buf) {\n\n        if (text && callbacks->text &&\n\n            (sscanf(buf, \"\\\\%1[nN]\", new_line) == 1 ||\n\n             !strncmp(buf, \"{\\\\\", 2))) {\n\n            callbacks->text(priv, text, text_len);\n\n            text = NULL;\n\n        }\n\n        if (sscanf(buf, \"\\\\%1[nN]\", new_line) == 1) {\n\n            if (callbacks->new_line)\n\n                callbacks->new_line(priv, new_line[0] == 'N');\n\n            buf += 2;\n\n        } else if (!strncmp(buf, \"{\\\\\", 2)) {\n\n            buf++;\n\n            while (*buf == '\\\\') {\n\n                char style[2], c[2], sep[2], c_num[2] = \"0\", tmp[128] = {0};\n\n                unsigned int color = 0xFFFFFFFF;\n\n                int len, size = -1, an = -1, alpha = -1;\n\n                int x1, y1, x2, y2, t1 = -1, t2 = -1;\n\n                if (sscanf(buf, \"\\\\%1[bisu]%1[01\\\\}]%n\", style, c, &len) > 1) {\n\n                    int close = c[0] == '0' ? 1 : c[0] == '1' ? 0 : -1;\n\n                    len += close != -1;\n\n                    if (callbacks->style)\n\n                        callbacks->style(priv, style[0], close);\n\n                } else if (sscanf(buf, \"\\\\c%1[\\\\}]%n\", sep, &len) > 0 ||\n\n                           sscanf(buf, \"\\\\c&H%X&%1[\\\\}]%n\", &color, sep, &len) > 1 ||\n\n                           sscanf(buf, \"\\\\%1[1234]c%1[\\\\}]%n\", c_num, sep, &len) > 1 ||\n\n                           sscanf(buf, \"\\\\%1[1234]c&H%X&%1[\\\\}]%n\", c_num, &color, sep, &len) > 2) {\n\n                    if (callbacks->color)\n\n                        callbacks->color(priv, color, c_num[0] - '0');\n\n                } else if (sscanf(buf, \"\\\\alpha%1[\\\\}]%n\", sep, &len) > 0 ||\n\n                           sscanf(buf, \"\\\\alpha&H%2X&%1[\\\\}]%n\", &alpha, sep, &len) > 1 ||\n\n                           sscanf(buf, \"\\\\%1[1234]a%1[\\\\}]%n\", c_num, sep, &len) > 1 ||\n\n                           sscanf(buf, \"\\\\%1[1234]a&H%2X&%1[\\\\}]%n\", c_num, &alpha, sep, &len) > 2) {\n\n                    if (callbacks->alpha)\n\n                        callbacks->alpha(priv, alpha, c_num[0] - '0');\n\n                } else if (sscanf(buf, \"\\\\fn%1[\\\\}]%n\", sep, &len) > 0 ||\n\n                           sscanf(buf, \"\\\\fn%127[^\\\\}]%1[\\\\}]%n\", tmp, sep, &len) > 1) {\n\n                    if (callbacks->font_name)\n\n                        callbacks->font_name(priv, tmp[0] ? tmp : NULL);\n\n                } else if (sscanf(buf, \"\\\\fs%1[\\\\}]%n\", sep, &len) > 0 ||\n\n                           sscanf(buf, \"\\\\fs%u%1[\\\\}]%n\", &size, sep, &len) > 1) {\n\n                    if (callbacks->font_size)\n\n                        callbacks->font_size(priv, size);\n\n                } else if (sscanf(buf, \"\\\\a%1[\\\\}]%n\", sep, &len) > 0 ||\n\n                           sscanf(buf, \"\\\\a%2u%1[\\\\}]%n\", &an, sep, &len) > 1 ||\n\n                           sscanf(buf, \"\\\\an%1[\\\\}]%n\", sep, &len) > 0 ||\n\n                           sscanf(buf, \"\\\\an%1u%1[\\\\}]%n\", &an, sep, &len) > 1) {\n\n                    if (an != -1 && buf[2] != 'n')\n\n                        an = (an&3) + (an&4 ? 6 : an&8 ? 3 : 0);\n\n                    if (callbacks->alignment)\n\n                        callbacks->alignment(priv, an);\n\n                } else if (sscanf(buf, \"\\\\r%1[\\\\}]%n\", sep, &len) > 0 ||\n\n                           sscanf(buf, \"\\\\r%127[^\\\\}]%1[\\\\}]%n\", tmp, sep, &len) > 1) {\n\n                    if (callbacks->cancel_overrides)\n\n                        callbacks->cancel_overrides(priv, tmp);\n\n                } else if (sscanf(buf, \"\\\\move(%d,%d,%d,%d)%1[\\\\}]%n\", &x1, &y1, &x2, &y2, sep, &len) > 4 ||\n\n                           sscanf(buf, \"\\\\move(%d,%d,%d,%d,%d,%d)%1[\\\\}]%n\", &x1, &y1, &x2, &y2, &t1, &t2, sep, &len) > 6) {\n\n                    if (callbacks->move)\n\n                        callbacks->move(priv, x1, y1, x2, y2, t1, t2);\n\n                } else if (sscanf(buf, \"\\\\pos(%d,%d)%1[\\\\}]%n\", &x1, &y1, sep, &len) > 2) {\n\n                    if (callbacks->move)\n\n                        callbacks->move(priv, x1, y1, x1, y1, -1, -1);\n\n                } else if (sscanf(buf, \"\\\\org(%d,%d)%1[\\\\}]%n\", &x1, &y1, sep, &len) > 2) {\n\n                    if (callbacks->origin)\n\n                        callbacks->origin(priv, x1, y1);\n\n                } else {\n\n                    len = strcspn(buf+1, \"\\\\}\") + 2;  /* skip unknown code */\n\n                }\n\n                buf += len - 1;\n\n            }\n\n            if (*buf++ != '}')\n\n                return AVERROR_INVALIDDATA;\n\n        } else {\n\n            if (!text) {\n\n                text = buf;\n\n                text_len = 1;\n\n            } else\n\n                text_len++;\n\n            buf++;\n\n        }\n\n    }\n\n    if (text && callbacks->text)\n\n        callbacks->text(priv, text, text_len);\n\n    if (callbacks->end)\n\n        callbacks->end(priv);\n\n    return 0;\n\n}\n", "idx": 26031}
{"project": "FFmpeg", "commit_id": "ab2940691ba76e1a9b0ce608db0dfc45021d741e", "target": 0, "func": "int avio_get_str(AVIOContext *s, int maxlen, char *buf, int buflen)\n\n{\n\n    int i;\n\n\n\n    // reserve 1 byte for terminating 0\n\n    buflen = FFMIN(buflen - 1, maxlen);\n\n    for (i = 0; i < buflen; i++)\n\n        if (!(buf[i] = avio_r8(s)))\n\n            return i + 1;\n\n    if (buflen)\n\n        buf[i] = 0;\n\n    for (; i < maxlen; i++)\n\n        if (!avio_r8(s))\n\n            return i + 1;\n\n    return maxlen;\n\n}\n", "idx": 26032}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static int RENAME(swScale)(SwsContext *c, const uint8_t* src[], int srcStride[], int srcSliceY,\n\n                           int srcSliceH, uint8_t* dst[], int dstStride[])\n\n{\n\n    /* load a few things into local vars to make the code more readable? and faster */\n\n    const int srcW= c->srcW;\n\n    const int dstW= c->dstW;\n\n    const int dstH= c->dstH;\n\n    const int chrDstW= c->chrDstW;\n\n    const int chrSrcW= c->chrSrcW;\n\n    const int lumXInc= c->lumXInc;\n\n    const int chrXInc= c->chrXInc;\n\n    const enum PixelFormat dstFormat= c->dstFormat;\n\n    const int flags= c->flags;\n\n    int16_t *vLumFilterPos= c->vLumFilterPos;\n\n    int16_t *vChrFilterPos= c->vChrFilterPos;\n\n    int16_t *hLumFilterPos= c->hLumFilterPos;\n\n    int16_t *hChrFilterPos= c->hChrFilterPos;\n\n    int16_t *vLumFilter= c->vLumFilter;\n\n    int16_t *vChrFilter= c->vChrFilter;\n\n    int16_t *hLumFilter= c->hLumFilter;\n\n    int16_t *hChrFilter= c->hChrFilter;\n\n    int32_t *lumMmxFilter= c->lumMmxFilter;\n\n    int32_t *chrMmxFilter= c->chrMmxFilter;\n\n    int32_t av_unused *alpMmxFilter= c->alpMmxFilter;\n\n    const int vLumFilterSize= c->vLumFilterSize;\n\n    const int vChrFilterSize= c->vChrFilterSize;\n\n    const int hLumFilterSize= c->hLumFilterSize;\n\n    const int hChrFilterSize= c->hChrFilterSize;\n\n    int16_t **lumPixBuf= c->lumPixBuf;\n\n    int16_t **chrPixBuf= c->chrPixBuf;\n\n    int16_t **alpPixBuf= c->alpPixBuf;\n\n    const int vLumBufSize= c->vLumBufSize;\n\n    const int vChrBufSize= c->vChrBufSize;\n\n    uint8_t *formatConvBuffer= c->formatConvBuffer;\n\n    const int chrSrcSliceY= srcSliceY >> c->chrSrcVSubSample;\n\n    const int chrSrcSliceH= -((-srcSliceH) >> c->chrSrcVSubSample);\n\n    int lastDstY;\n\n    uint32_t *pal=c->pal_yuv;\n\n\n\n    /* vars which will change and which we need to store back in the context */\n\n    int dstY= c->dstY;\n\n    int lumBufIndex= c->lumBufIndex;\n\n    int chrBufIndex= c->chrBufIndex;\n\n    int lastInLumBuf= c->lastInLumBuf;\n\n    int lastInChrBuf= c->lastInChrBuf;\n\n\n\n    if (isPacked(c->srcFormat)) {\n\n        src[0]=\n\n        src[1]=\n\n        src[2]=\n\n        src[3]= src[0];\n\n        srcStride[0]=\n\n        srcStride[1]=\n\n        srcStride[2]=\n\n        srcStride[3]= srcStride[0];\n\n    }\n\n    srcStride[1]<<= c->vChrDrop;\n\n    srcStride[2]<<= c->vChrDrop;\n\n\n\n    DEBUG_BUFFERS(\"swScale() %p[%d] %p[%d] %p[%d] %p[%d] -> %p[%d] %p[%d] %p[%d] %p[%d]\\n\",\n\n                  src[0], srcStride[0], src[1], srcStride[1], src[2], srcStride[2], src[3], srcStride[3],\n\n                  dst[0], dstStride[0], dst[1], dstStride[1], dst[2], dstStride[2], dst[3], dstStride[3]);\n\n    DEBUG_BUFFERS(\"srcSliceY: %d srcSliceH: %d dstY: %d dstH: %d\\n\",\n\n                   srcSliceY,    srcSliceH,    dstY,    dstH);\n\n    DEBUG_BUFFERS(\"vLumFilterSize: %d vLumBufSize: %d vChrFilterSize: %d vChrBufSize: %d\\n\",\n\n                   vLumFilterSize,    vLumBufSize,    vChrFilterSize,    vChrBufSize);\n\n\n\n    if (dstStride[0]%8 !=0 || dstStride[1]%8 !=0 || dstStride[2]%8 !=0 || dstStride[3]%8 != 0) {\n\n        static int warnedAlready=0; //FIXME move this into the context perhaps\n\n        if (flags & SWS_PRINT_INFO && !warnedAlready) {\n\n            av_log(c, AV_LOG_WARNING, \"Warning: dstStride is not aligned!\\n\"\n\n                   \"         ->cannot do aligned memory accesses anymore\\n\");\n\n            warnedAlready=1;\n\n        }\n\n    }\n\n\n\n    /* Note the user might start scaling the picture in the middle so this\n\n       will not get executed. This is not really intended but works\n\n       currently, so people might do it. */\n\n    if (srcSliceY ==0) {\n\n        lumBufIndex=-1;\n\n        chrBufIndex=-1;\n\n        dstY=0;\n\n        lastInLumBuf= -1;\n\n        lastInChrBuf= -1;\n\n    }\n\n\n\n    lastDstY= dstY;\n\n\n\n    for (;dstY < dstH; dstY++) {\n\n        unsigned char *dest =dst[0]+dstStride[0]*dstY;\n\n        const int chrDstY= dstY>>c->chrDstVSubSample;\n\n        unsigned char *uDest=dst[1]+dstStride[1]*chrDstY;\n\n        unsigned char *vDest=dst[2]+dstStride[2]*chrDstY;\n\n        unsigned char *aDest=(CONFIG_SWSCALE_ALPHA && alpPixBuf) ? dst[3]+dstStride[3]*dstY : NULL;\n\n\n\n        const int firstLumSrcY= vLumFilterPos[dstY]; //First line needed as input\n\n        const int firstLumSrcY2= vLumFilterPos[FFMIN(dstY | ((1<<c->chrDstVSubSample) - 1), dstH-1)];\n\n        const int firstChrSrcY= vChrFilterPos[chrDstY]; //First line needed as input\n\n        int lastLumSrcY= firstLumSrcY + vLumFilterSize -1; // Last line needed as input\n\n        int lastLumSrcY2=firstLumSrcY2+ vLumFilterSize -1; // Last line needed as input\n\n        int lastChrSrcY= firstChrSrcY + vChrFilterSize -1; // Last line needed as input\n\n        int enough_lines;\n\n\n\n        //handle holes (FAST_BILINEAR & weird filters)\n\n        if (firstLumSrcY > lastInLumBuf) lastInLumBuf= firstLumSrcY-1;\n\n        if (firstChrSrcY > lastInChrBuf) lastInChrBuf= firstChrSrcY-1;\n\n        assert(firstLumSrcY >= lastInLumBuf - vLumBufSize + 1);\n\n        assert(firstChrSrcY >= lastInChrBuf - vChrBufSize + 1);\n\n\n\n        DEBUG_BUFFERS(\"dstY: %d\\n\", dstY);\n\n        DEBUG_BUFFERS(\"\\tfirstLumSrcY: %d lastLumSrcY: %d lastInLumBuf: %d\\n\",\n\n                         firstLumSrcY,    lastLumSrcY,    lastInLumBuf);\n\n        DEBUG_BUFFERS(\"\\tfirstChrSrcY: %d lastChrSrcY: %d lastInChrBuf: %d\\n\",\n\n                         firstChrSrcY,    lastChrSrcY,    lastInChrBuf);\n\n\n\n        // Do we have enough lines in this slice to output the dstY line\n\n        enough_lines = lastLumSrcY2 < srcSliceY + srcSliceH && lastChrSrcY < -((-srcSliceY - srcSliceH)>>c->chrSrcVSubSample);\n\n\n\n        if (!enough_lines) {\n\n            lastLumSrcY = srcSliceY + srcSliceH - 1;\n\n            lastChrSrcY = chrSrcSliceY + chrSrcSliceH - 1;\n\n            DEBUG_BUFFERS(\"buffering slice: lastLumSrcY %d lastChrSrcY %d\\n\",\n\n                                            lastLumSrcY, lastChrSrcY);\n\n        }\n\n\n\n        //Do horizontal scaling\n\n        while(lastInLumBuf < lastLumSrcY) {\n\n            const uint8_t *src1= src[0]+(lastInLumBuf + 1 - srcSliceY)*srcStride[0];\n\n            const uint8_t *src2= src[3]+(lastInLumBuf + 1 - srcSliceY)*srcStride[3];\n\n            lumBufIndex++;\n\n            assert(lumBufIndex < 2*vLumBufSize);\n\n            assert(lastInLumBuf + 1 - srcSliceY < srcSliceH);\n\n            assert(lastInLumBuf + 1 - srcSliceY >= 0);\n\n            RENAME(hyscale)(c, lumPixBuf[ lumBufIndex ], dstW, src1, srcW, lumXInc,\n\n                            hLumFilter, hLumFilterPos, hLumFilterSize,\n\n                            formatConvBuffer,\n\n                            pal, 0);\n\n            if (CONFIG_SWSCALE_ALPHA && alpPixBuf)\n\n                RENAME(hyscale)(c, alpPixBuf[ lumBufIndex ], dstW, src2, srcW, lumXInc,\n\n                                hLumFilter, hLumFilterPos, hLumFilterSize,\n\n                                formatConvBuffer,\n\n                                pal, 1);\n\n            lastInLumBuf++;\n\n            DEBUG_BUFFERS(\"\\t\\tlumBufIndex %d: lastInLumBuf: %d\\n\",\n\n                               lumBufIndex,    lastInLumBuf);\n\n        }\n\n        while(lastInChrBuf < lastChrSrcY) {\n\n            const uint8_t *src1= src[1]+(lastInChrBuf + 1 - chrSrcSliceY)*srcStride[1];\n\n            const uint8_t *src2= src[2]+(lastInChrBuf + 1 - chrSrcSliceY)*srcStride[2];\n\n            chrBufIndex++;\n\n            assert(chrBufIndex < 2*vChrBufSize);\n\n            assert(lastInChrBuf + 1 - chrSrcSliceY < (chrSrcSliceH));\n\n            assert(lastInChrBuf + 1 - chrSrcSliceY >= 0);\n\n            //FIXME replace parameters through context struct (some at least)\n\n\n\n            if (c->needs_hcscale)\n\n                RENAME(hcscale)(c, chrPixBuf[ chrBufIndex ], chrDstW, src1, src2, chrSrcW, chrXInc,\n\n                                hChrFilter, hChrFilterPos, hChrFilterSize,\n\n                                formatConvBuffer,\n\n                                pal);\n\n            lastInChrBuf++;\n\n            DEBUG_BUFFERS(\"\\t\\tchrBufIndex %d: lastInChrBuf: %d\\n\",\n\n                               chrBufIndex,    lastInChrBuf);\n\n        }\n\n        //wrap buf index around to stay inside the ring buffer\n\n        if (lumBufIndex >= vLumBufSize) lumBufIndex-= vLumBufSize;\n\n        if (chrBufIndex >= vChrBufSize) chrBufIndex-= vChrBufSize;\n\n        if (!enough_lines)\n\n            break; //we can't output a dstY line so let's try with the next slice\n\n\n\n#if COMPILE_TEMPLATE_MMX\n\n        c->blueDither= ff_dither8[dstY&1];\n\n        if (c->dstFormat == PIX_FMT_RGB555 || c->dstFormat == PIX_FMT_BGR555)\n\n            c->greenDither= ff_dither8[dstY&1];\n\n        else\n\n            c->greenDither= ff_dither4[dstY&1];\n\n        c->redDither= ff_dither8[(dstY+1)&1];\n\n#endif\n\n        if (dstY < dstH-2) {\n\n            const int16_t **lumSrcPtr= (const int16_t **) lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n            const int16_t **chrSrcPtr= (const int16_t **) chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n            const int16_t **alpSrcPtr= (CONFIG_SWSCALE_ALPHA && alpPixBuf) ? (const int16_t **) alpPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize : NULL;\n\n#if COMPILE_TEMPLATE_MMX\n\n            int i;\n\n            if (flags & SWS_ACCURATE_RND) {\n\n                int s= APCK_SIZE / 8;\n\n                for (i=0; i<vLumFilterSize; i+=2) {\n\n                    *(const void**)&lumMmxFilter[s*i              ]= lumSrcPtr[i  ];\n\n                    *(const void**)&lumMmxFilter[s*i+APCK_PTR2/4  ]= lumSrcPtr[i+(vLumFilterSize>1)];\n\n                              lumMmxFilter[s*i+APCK_COEF/4  ]=\n\n                              lumMmxFilter[s*i+APCK_COEF/4+1]= vLumFilter[dstY*vLumFilterSize + i    ]\n\n                        + (vLumFilterSize>1 ? vLumFilter[dstY*vLumFilterSize + i + 1]<<16 : 0);\n\n                    if (CONFIG_SWSCALE_ALPHA && alpPixBuf) {\n\n                        *(const void**)&alpMmxFilter[s*i              ]= alpSrcPtr[i  ];\n\n                        *(const void**)&alpMmxFilter[s*i+APCK_PTR2/4  ]= alpSrcPtr[i+(vLumFilterSize>1)];\n\n                                  alpMmxFilter[s*i+APCK_COEF/4  ]=\n\n                                  alpMmxFilter[s*i+APCK_COEF/4+1]= lumMmxFilter[s*i+APCK_COEF/4  ];\n\n                    }\n\n                }\n\n                for (i=0; i<vChrFilterSize; i+=2) {\n\n                    *(const void**)&chrMmxFilter[s*i              ]= chrSrcPtr[i  ];\n\n                    *(const void**)&chrMmxFilter[s*i+APCK_PTR2/4  ]= chrSrcPtr[i+(vChrFilterSize>1)];\n\n                              chrMmxFilter[s*i+APCK_COEF/4  ]=\n\n                              chrMmxFilter[s*i+APCK_COEF/4+1]= vChrFilter[chrDstY*vChrFilterSize + i    ]\n\n                        + (vChrFilterSize>1 ? vChrFilter[chrDstY*vChrFilterSize + i + 1]<<16 : 0);\n\n                }\n\n            } else {\n\n                for (i=0; i<vLumFilterSize; i++) {\n\n                    lumMmxFilter[4*i+0]= (int32_t)lumSrcPtr[i];\n\n                    lumMmxFilter[4*i+1]= (uint64_t)lumSrcPtr[i] >> 32;\n\n                    lumMmxFilter[4*i+2]=\n\n                    lumMmxFilter[4*i+3]=\n\n                        ((uint16_t)vLumFilter[dstY*vLumFilterSize + i])*0x10001;\n\n                    if (CONFIG_SWSCALE_ALPHA && alpPixBuf) {\n\n                        alpMmxFilter[4*i+0]= (int32_t)alpSrcPtr[i];\n\n                        alpMmxFilter[4*i+1]= (uint64_t)alpSrcPtr[i] >> 32;\n\n                        alpMmxFilter[4*i+2]=\n\n                        alpMmxFilter[4*i+3]= lumMmxFilter[4*i+2];\n\n                    }\n\n                }\n\n                for (i=0; i<vChrFilterSize; i++) {\n\n                    chrMmxFilter[4*i+0]= (int32_t)chrSrcPtr[i];\n\n                    chrMmxFilter[4*i+1]= (uint64_t)chrSrcPtr[i] >> 32;\n\n                    chrMmxFilter[4*i+2]=\n\n                    chrMmxFilter[4*i+3]=\n\n                        ((uint16_t)vChrFilter[chrDstY*vChrFilterSize + i])*0x10001;\n\n                }\n\n            }\n\n#endif\n\n            if (dstFormat == PIX_FMT_NV12 || dstFormat == PIX_FMT_NV21) {\n\n                const int chrSkipMask= (1<<c->chrDstVSubSample)-1;\n\n                if (dstY&chrSkipMask) uDest= NULL; //FIXME split functions in lumi / chromi\n\n                c->yuv2nv12X(c,\n\n                             vLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n                             vChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                             dest, uDest, dstW, chrDstW, dstFormat);\n\n            } else if (isPlanarYUV(dstFormat) || dstFormat==PIX_FMT_GRAY8) { //YV12 like\n\n                const int chrSkipMask= (1<<c->chrDstVSubSample)-1;\n\n                if ((dstY&chrSkipMask) || isGray(dstFormat)) uDest=vDest= NULL; //FIXME split functions in lumi / chromi\n\n                if (is16BPS(dstFormat) || isNBPS(dstFormat)) {\n\n                    yuv2yuvX16inC(\n\n                                  vLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n                                  vChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                  alpSrcPtr, (uint16_t *) dest, (uint16_t *) uDest, (uint16_t *) vDest, (uint16_t *) aDest, dstW, chrDstW,\n\n                                  dstFormat);\n\n                } else if (vLumFilterSize == 1 && vChrFilterSize == 1) { // unscaled YV12\n\n                    const int16_t *lumBuf = lumSrcPtr[0];\n\n                    const int16_t *chrBuf= chrSrcPtr[0];\n\n                    const int16_t *alpBuf= (CONFIG_SWSCALE_ALPHA && alpPixBuf) ? alpSrcPtr[0] : NULL;\n\n                    c->yuv2yuv1(c, lumBuf, chrBuf, alpBuf, dest, uDest, vDest, aDest, dstW, chrDstW);\n\n                } else { //General YV12\n\n                    c->yuv2yuvX(c,\n\n                                vLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n                                vChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                alpSrcPtr, dest, uDest, vDest, aDest, dstW, chrDstW);\n\n                }\n\n            } else {\n\n                assert(lumSrcPtr + vLumFilterSize - 1 < lumPixBuf + vLumBufSize*2);\n\n                assert(chrSrcPtr + vChrFilterSize - 1 < chrPixBuf + vChrBufSize*2);\n\n                if (vLumFilterSize == 1 && vChrFilterSize == 2) { //unscaled RGB\n\n                    int chrAlpha= vChrFilter[2*dstY+1];\n\n                    if(flags & SWS_FULL_CHR_H_INT) {\n\n                        yuv2rgbXinC_full(c, //FIXME write a packed1_full function\n\n                                         vLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n                                         vChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                         alpSrcPtr, dest, dstW, dstY);\n\n                    } else {\n\n                        c->yuv2packed1(c, *lumSrcPtr, *chrSrcPtr, *(chrSrcPtr+1),\n\n                                       alpPixBuf ? *alpSrcPtr : NULL,\n\n                                       dest, dstW, chrAlpha, dstFormat, flags, dstY);\n\n                    }\n\n                } else if (vLumFilterSize == 2 && vChrFilterSize == 2) { //bilinear upscale RGB\n\n                    int lumAlpha= vLumFilter[2*dstY+1];\n\n                    int chrAlpha= vChrFilter[2*dstY+1];\n\n                    lumMmxFilter[2]=\n\n                    lumMmxFilter[3]= vLumFilter[2*dstY   ]*0x10001;\n\n                    chrMmxFilter[2]=\n\n                    chrMmxFilter[3]= vChrFilter[2*chrDstY]*0x10001;\n\n                    if(flags & SWS_FULL_CHR_H_INT) {\n\n                        yuv2rgbXinC_full(c, //FIXME write a packed2_full function\n\n                                         vLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n                                         vChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                         alpSrcPtr, dest, dstW, dstY);\n\n                    } else {\n\n                        c->yuv2packed2(c, *lumSrcPtr, *(lumSrcPtr+1), *chrSrcPtr, *(chrSrcPtr+1),\n\n                                       alpPixBuf ? *alpSrcPtr : NULL, alpPixBuf ? *(alpSrcPtr+1) : NULL,\n\n                                       dest, dstW, lumAlpha, chrAlpha, dstY);\n\n                    }\n\n                } else { //general RGB\n\n                    if(flags & SWS_FULL_CHR_H_INT) {\n\n                        yuv2rgbXinC_full(c,\n\n                                         vLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n                                         vChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                         alpSrcPtr, dest, dstW, dstY);\n\n                    } else {\n\n                        c->yuv2packedX(c,\n\n                                       vLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n                                       vChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                       alpSrcPtr, dest, dstW, dstY);\n\n                    }\n\n                }\n\n            }\n\n        } else { // hmm looks like we can't use MMX here without overwriting this array's tail\n\n            const int16_t **lumSrcPtr= (const int16_t **)lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n            const int16_t **chrSrcPtr= (const int16_t **)chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n            const int16_t **alpSrcPtr= (CONFIG_SWSCALE_ALPHA && alpPixBuf) ? (const int16_t **)alpPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize : NULL;\n\n            if (dstFormat == PIX_FMT_NV12 || dstFormat == PIX_FMT_NV21) {\n\n                const int chrSkipMask= (1<<c->chrDstVSubSample)-1;\n\n                if (dstY&chrSkipMask) uDest= NULL; //FIXME split functions in lumi / chromi\n\n                yuv2nv12XinC(\n\n                             vLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n                             vChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                             dest, uDest, dstW, chrDstW, dstFormat);\n\n            } else if (isPlanarYUV(dstFormat) || dstFormat==PIX_FMT_GRAY8) { //YV12\n\n                const int chrSkipMask= (1<<c->chrDstVSubSample)-1;\n\n                if ((dstY&chrSkipMask) || isGray(dstFormat)) uDest=vDest= NULL; //FIXME split functions in lumi / chromi\n\n                if (is16BPS(dstFormat) || isNBPS(dstFormat)) {\n\n                    yuv2yuvX16inC(\n\n                                  vLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n                                  vChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                  alpSrcPtr, (uint16_t *) dest, (uint16_t *) uDest, (uint16_t *) vDest, (uint16_t *) aDest, dstW, chrDstW,\n\n                                  dstFormat);\n\n                } else {\n\n                    yuv2yuvXinC(\n\n                                vLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n                                vChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                alpSrcPtr, dest, uDest, vDest, aDest, dstW, chrDstW);\n\n                }\n\n            } else {\n\n                assert(lumSrcPtr + vLumFilterSize - 1 < lumPixBuf + vLumBufSize*2);\n\n                assert(chrSrcPtr + vChrFilterSize - 1 < chrPixBuf + vChrBufSize*2);\n\n                if(flags & SWS_FULL_CHR_H_INT) {\n\n                    yuv2rgbXinC_full(c,\n\n                                     vLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n                                     vChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                     alpSrcPtr, dest, dstW, dstY);\n\n                } else {\n\n                    yuv2packedXinC(c,\n\n                                   vLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n                                   vChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                   alpSrcPtr, dest, dstW, dstY);\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    if ((dstFormat == PIX_FMT_YUVA420P) && !alpPixBuf)\n\n        fillPlane(dst[3], dstStride[3], dstW, dstY-lastDstY, lastDstY, 255);\n\n\n\n#if COMPILE_TEMPLATE_MMX\n\n    if (flags & SWS_CPU_CAPS_MMX2 )  __asm__ volatile(\"sfence\":::\"memory\");\n\n    /* On K6 femms is faster than emms. On K7 femms is directly mapped to emms. */\n\n    if (flags & SWS_CPU_CAPS_3DNOW)  __asm__ volatile(\"femms\" :::\"memory\");\n\n    else                             __asm__ volatile(\"emms\"  :::\"memory\");\n\n#endif\n\n    /* store changed local vars back in the context */\n\n    c->dstY= dstY;\n\n    c->lumBufIndex= lumBufIndex;\n\n    c->chrBufIndex= chrBufIndex;\n\n    c->lastInLumBuf= lastInLumBuf;\n\n    c->lastInChrBuf= lastInChrBuf;\n\n\n\n    return dstY - lastDstY;\n\n}\n", "idx": 26033}
{"project": "FFmpeg", "commit_id": "d90c5bf10559554d6f9cd1dfb90767b991b76d5d", "target": 1, "func": "static inline int wv_unpack_mono(WavpackFrameContext *s, GetBitContext *gb,\n\n                                 void *dst, const int type)\n\n{\n\n    int i, j, count = 0;\n\n    int last, t;\n\n    int A, S, T;\n\n    int pos                  = s->pos;\n\n    uint32_t crc             = s->sc.crc;\n\n    uint32_t crc_extra_bits  = s->extra_sc.crc;\n\n    int16_t *dst16           = dst;\n\n    int32_t *dst32           = dst;\n\n    float *dstfl             = dst;\n\n\n\n    s->one = s->zero = s->zeroes = 0;\n\n    do {\n\n        T = wv_get_value(s, gb, 0, &last);\n\n        S = 0;\n\n        if (last)\n\n            break;\n\n        for (i = 0; i < s->terms; i++) {\n\n            t = s->decorr[i].value;\n\n            if (t > 8) {\n\n                if (t & 1)\n\n                    A =  2U * s->decorr[i].samplesA[0] - s->decorr[i].samplesA[1];\n\n                else\n\n                    A = (int)(3U * s->decorr[i].samplesA[0] - s->decorr[i].samplesA[1]) >> 1;\n\n                s->decorr[i].samplesA[1] = s->decorr[i].samplesA[0];\n\n                j                        = 0;\n\n            } else {\n\n                A = s->decorr[i].samplesA[pos];\n\n                j = (pos + t) & 7;\n\n            }\n\n            if (type != AV_SAMPLE_FMT_S16P)\n\n                S = T + ((s->decorr[i].weightA * (int64_t)A + 512) >> 10);\n\n            else\n\n                S = T + ((s->decorr[i].weightA * A + 512) >> 10);\n\n            if (A && T)\n\n                s->decorr[i].weightA -= ((((T ^ A) >> 30) & 2) - 1) * s->decorr[i].delta;\n\n            s->decorr[i].samplesA[j] = T = S;\n\n        }\n\n        pos = (pos + 1) & 7;\n\n        crc = crc * 3 + S;\n\n\n\n        if (type == AV_SAMPLE_FMT_FLTP) {\n\n            *dstfl++ = wv_get_value_float(s, &crc_extra_bits, S);\n\n        } else if (type == AV_SAMPLE_FMT_S32P) {\n\n            *dst32++ = wv_get_value_integer(s, &crc_extra_bits, S);\n\n        } else {\n\n            *dst16++ = wv_get_value_integer(s, &crc_extra_bits, S);\n\n        }\n\n        count++;\n\n    } while (!last && count < s->samples);\n\n\n\n    wv_reset_saved_context(s);\n\n\n\n    if (last && count < s->samples) {\n\n        int size = av_get_bytes_per_sample(type);\n\n        memset((uint8_t*)dst + count*size, 0, (s->samples-count)*size);\n\n    }\n\n\n\n    if (s->avctx->err_recognition & AV_EF_CRCCHECK) {\n\n        int ret = wv_check_crc(s, crc, crc_extra_bits);\n\n        if (ret < 0 && s->avctx->err_recognition & AV_EF_EXPLODE)\n\n            return ret;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26034}
{"project": "FFmpeg", "commit_id": "05b7a635dc1e5266fb367ce8b0019a0830317879", "target": 1, "func": "static void sample_queue_push(HintSampleQueue *queue, uint8_t *data, int size,\n\n                              int sample)\n\n{\n\n    /* No need to keep track of smaller samples, since describing them\n\n     * with immediates is more efficient. */\n\n    if (size <= 14)\n\n        return;\n\n    if (!queue->samples || queue->len >= queue->size) {\n\n        HintSample *samples;\n\n        samples = av_realloc(queue->samples, sizeof(HintSample) * (queue->size + 10));\n\n        if (!samples)\n\n            return;\n\n        queue->size += 10;\n\n        queue->samples = samples;\n\n    }\n\n    queue->samples[queue->len].data = data;\n\n    queue->samples[queue->len].size = size;\n\n    queue->samples[queue->len].sample_number = sample;\n\n    queue->samples[queue->len].offset   = 0;\n\n    queue->samples[queue->len].own_data = 0;\n\n    queue->len++;\n\n}\n", "idx": 26036}
{"project": "FFmpeg", "commit_id": "d0d8a9b1384ba3cd465d6ef3439f3979d4518b4b", "target": 1, "func": "void ff_mov_close_hinting(MOVTrack *track) {\n\n    AVFormatContext* rtp_ctx = track->rtp_ctx;\n\n    uint8_t *ptr;\n\n\n\n    av_freep(&track->enc);\n\n    sample_queue_free(&track->sample_queue);\n\n    if (!rtp_ctx)\n\n        return;\n\n    if (rtp_ctx->pb) {\n\n        av_write_trailer(rtp_ctx);\n\n        url_close_dyn_buf(rtp_ctx->pb, &ptr);\n\n        av_free(ptr);\n\n    }\n\n    av_metadata_free(&rtp_ctx->streams[0]->metadata);\n\n    av_metadata_free(&rtp_ctx->metadata);\n\n\n    av_free(rtp_ctx->streams[0]);\n\n    av_freep(&rtp_ctx);\n\n}", "idx": 26037}
{"project": "FFmpeg", "commit_id": "2453f40602dd6f5fa670954ee733a4155675f645", "target": 1, "func": "static void compute_scale_factors(unsigned char scale_code[SBLIMIT],\n\n                                  unsigned char scale_factors[SBLIMIT][3],\n\n                                  int sb_samples[3][12][SBLIMIT],\n\n                                  int sblimit)\n\n{\n\n    int *p, vmax, v, n, i, j, k, code;\n\n    int index, d1, d2;\n\n    unsigned char *sf = &scale_factors[0][0];\n\n\n\n    for(j=0;j<sblimit;j++) {\n\n        for(i=0;i<3;i++) {\n\n            /* find the max absolute value */\n\n            p = &sb_samples[i][0][j];\n\n            vmax = abs(*p);\n\n            for(k=1;k<12;k++) {\n\n                p += SBLIMIT;\n\n                v = abs(*p);\n\n                if (v > vmax)\n\n                    vmax = v;\n\n            }\n\n            /* compute the scale factor index using log 2 computations */\n\n            if (vmax > 0) {\n\n                n = av_log2(vmax);\n\n                /* n is the position of the MSB of vmax. now\n\n                   use at most 2 compares to find the index */\n\n                index = (21 - n) * 3 - 3;\n\n                if (index >= 0) {\n\n                    while (vmax <= scale_factor_table[index+1])\n\n                        index++;\n\n                } else {\n\n                    index = 0; /* very unlikely case of overflow */\n\n                }\n\n            } else {\n\n                index = 62; /* value 63 is not allowed */\n\n            }\n\n\n\n#if 0\n\n            printf(\"%2d:%d in=%x %x %d\\n\",\n\n                   j, i, vmax, scale_factor_table[index], index);\n\n#endif\n\n            /* store the scale factor */\n\n            assert(index >=0 && index <= 63);\n\n            sf[i] = index;\n\n        }\n\n\n\n        /* compute the transmission factor : look if the scale factors\n\n           are close enough to each other */\n\n        d1 = scale_diff_table[sf[0] - sf[1] + 64];\n\n        d2 = scale_diff_table[sf[1] - sf[2] + 64];\n\n\n\n        /* handle the 25 cases */\n\n        switch(d1 * 5 + d2) {\n\n        case 0*5+0:\n\n        case 0*5+4:\n\n        case 3*5+4:\n\n        case 4*5+0:\n\n        case 4*5+4:\n\n            code = 0;\n\n            break;\n\n        case 0*5+1:\n\n        case 0*5+2:\n\n        case 4*5+1:\n\n        case 4*5+2:\n\n            code = 3;\n\n            sf[2] = sf[1];\n\n            break;\n\n        case 0*5+3:\n\n        case 4*5+3:\n\n            code = 3;\n\n            sf[1] = sf[2];\n\n            break;\n\n        case 1*5+0:\n\n        case 1*5+4:\n\n        case 2*5+4:\n\n            code = 1;\n\n            sf[1] = sf[0];\n\n            break;\n\n        case 1*5+1:\n\n        case 1*5+2:\n\n        case 2*5+0:\n\n        case 2*5+1:\n\n        case 2*5+2:\n\n            code = 2;\n\n            sf[1] = sf[2] = sf[0];\n\n            break;\n\n        case 2*5+3:\n\n        case 3*5+3:\n\n            code = 2;\n\n            sf[0] = sf[1] = sf[2];\n\n            break;\n\n        case 3*5+0:\n\n        case 3*5+1:\n\n        case 3*5+2:\n\n            code = 2;\n\n            sf[0] = sf[2] = sf[1];\n\n            break;\n\n        case 1*5+3:\n\n            code = 2;\n\n            if (sf[0] > sf[2])\n\n              sf[0] = sf[2];\n\n            sf[1] = sf[2] = sf[0];\n\n            break;\n\n        default:\n\n            assert(0); //cannot happen\n\n            code = 0;           /* kill warning */\n\n        }\n\n\n\n#if 0\n\n        printf(\"%d: %2d %2d %2d %d %d -> %d\\n\", j,\n\n               sf[0], sf[1], sf[2], d1, d2, code);\n\n#endif\n\n        scale_code[j] = code;\n\n        sf += 3;\n\n    }\n\n}\n", "idx": 26038}
{"project": "FFmpeg", "commit_id": "ce3bcaeda1dec8bdc25d4daf5a8358feafe5d124", "target": 1, "func": "static inline int mpeg4_decode_block(MpegEncContext * s, DCTELEM * block,\n\n                              int n, int coded, int intra)\n\n{\n\n    int level, i, last, run;\n\n    int dc_pred_dir;\n\n    RLTable * rl;\n\n    RL_VLC_ELEM * rl_vlc;\n\n    const UINT8 * scan_table;\n\n    int qmul, qadd;\n\n\n\n    if(intra) {\n\n\t/* DC coef */\n\n        if(s->partitioned_frame){\n\n            level = s->dc_val[0][ s->block_index[n] ];\n\n            if(n<4) level= (level + (s->y_dc_scale>>1))/s->y_dc_scale; //FIXME optimizs\n\n            else    level= (level + (s->c_dc_scale>>1))/s->c_dc_scale;\n\n            dc_pred_dir= (s->pred_dir_table[s->mb_x + s->mb_y*s->mb_width]<<n)&32;\n\n        }else{\n\n            level = mpeg4_decode_dc(s, n, &dc_pred_dir);\n\n            if (level < 0)\n\n                return -1;\n\n        }\n\n        block[0] = level;\n\n        i = 0;\n\n        if (!coded) \n\n            goto not_coded;\n\n        rl = &rl_intra;\n\n        rl_vlc = rl_intra.rl_vlc[0];\n\n        if (s->ac_pred) {\n\n            if (dc_pred_dir == 0) \n\n                scan_table = s->intra_v_scantable.permutated; /* left */\n\n            else\n\n                scan_table = s->intra_h_scantable.permutated; /* top */\n\n        } else {\n\n            scan_table = s->intra_scantable.permutated;\n\n        }\n\n        qmul=1;\n\n        qadd=0;\n\n    } else {\n\n        i = -1;\n\n        if (!coded) {\n\n            s->block_last_index[n] = i;\n\n            return 0;\n\n        }\n\n        rl = &rl_inter;\n\n   \n\n        scan_table = s->intra_scantable.permutated;\n\n\n\n        if(s->mpeg_quant){\n\n            qmul=1;\n\n            qadd=0;\n\n            rl_vlc = rl_inter.rl_vlc[0];        \n\n        }else{\n\n            qmul = s->qscale << 1;\n\n            qadd = (s->qscale - 1) | 1;\n\n            rl_vlc = rl_inter.rl_vlc[s->qscale];\n\n        }\n\n    }\n\n  {\n\n    OPEN_READER(re, &s->gb);\n\n    for(;;) {\n\n        UPDATE_CACHE(re, &s->gb);\n\n        GET_RL_VLC(level, run, re, &s->gb, rl_vlc, TEX_VLC_BITS, 2);\n\n        if (level==0) {\n\n            int cache;\n\n            cache= GET_CACHE(re, &s->gb);\n\n            /* escape */\n\n            if (cache&0x80000000) {\n\n                if (cache&0x40000000) {\n\n                    /* third escape */\n\n                    SKIP_CACHE(re, &s->gb, 2);\n\n                    last=  SHOW_UBITS(re, &s->gb, 1); SKIP_CACHE(re, &s->gb, 1);\n\n                    run=   SHOW_UBITS(re, &s->gb, 6); LAST_SKIP_CACHE(re, &s->gb, 6);\n\n                    SKIP_COUNTER(re, &s->gb, 2+1+6);\n\n                    UPDATE_CACHE(re, &s->gb);\n\n\n\n                    if(SHOW_UBITS(re, &s->gb, 1)==0){\n\n                        fprintf(stderr, \"1. marker bit missing in 3. esc\\n\");\n\n                        return -1;\n\n                    }; SKIP_CACHE(re, &s->gb, 1);\n\n                    \n\n                    level= SHOW_SBITS(re, &s->gb, 12); SKIP_CACHE(re, &s->gb, 12);\n\n \n\n                    if(SHOW_UBITS(re, &s->gb, 1)==0){\n\n                        fprintf(stderr, \"2. marker bit missing in 3. esc\\n\");\n\n                        return -1;\n\n                    }; LAST_SKIP_CACHE(re, &s->gb, 1);\n\n                    \n\n                    SKIP_COUNTER(re, &s->gb, 1+12+1);\n\n                    \n\n                    if(level*s->qscale>1024 || level*s->qscale<-1024){\n\n                        fprintf(stderr, \"|level| overflow in 3. esc, qp=%d\\n\", s->qscale);\n\n                        return -1;\n\n                    }\n\n#if 1 \n\n                    {\n\n                        const int abs_level= ABS(level);\n\n                        if(abs_level<=MAX_LEVEL && run<=MAX_RUN && ((s->workaround_bugs&FF_BUG_AC_VLC)==0)){\n\n                            const int run1= run - rl->max_run[last][abs_level] - 1;\n\n                            if(abs_level <= rl->max_level[last][run]){\n\n                                fprintf(stderr, \"illegal 3. esc, vlc encoding possible\\n\");\n\n                                return -1;\n\n                            }\n\n                            if(abs_level <= rl->max_level[last][run]*2){\n\n                                fprintf(stderr, \"illegal 3. esc, esc 1 encoding possible\\n\");\n\n                                return -1;\n\n                            }\n\n                            if(run1 >= 0 && abs_level <= rl->max_level[last][run1]){\n\n                                fprintf(stderr, \"illegal 3. esc, esc 2 encoding possible\\n\");\n\n                                return -1;\n\n                            }\n\n                        }\n\n                    }\n\n#endif\n\n\t\t    if (level>0) level= level * qmul + qadd;\n\n                    else         level= level * qmul - qadd;\n\n\n\n                    i+= run + 1;\n\n                    if(last) i+=192;\n\n                } else {\n\n                    /* second escape */\n\n#if MIN_CACHE_BITS < 20\n\n                    LAST_SKIP_BITS(re, &s->gb, 2);\n\n                    UPDATE_CACHE(re, &s->gb);\n\n#else\n\n                    SKIP_BITS(re, &s->gb, 2);\n\n#endif\n\n                    GET_RL_VLC(level, run, re, &s->gb, rl_vlc, TEX_VLC_BITS, 2);\n\n                    i+= run + rl->max_run[run>>7][level/qmul] +1; //FIXME opt indexing\n\n                    level = (level ^ SHOW_SBITS(re, &s->gb, 1)) - SHOW_SBITS(re, &s->gb, 1);\n\n                    LAST_SKIP_BITS(re, &s->gb, 1);\n\n                }\n\n            } else {\n\n                /* first escape */\n\n#if MIN_CACHE_BITS < 19\n\n                LAST_SKIP_BITS(re, &s->gb, 1);\n\n                UPDATE_CACHE(re, &s->gb);\n\n#else\n\n                SKIP_BITS(re, &s->gb, 1);\n\n#endif\n\n                GET_RL_VLC(level, run, re, &s->gb, rl_vlc, TEX_VLC_BITS, 2);\n\n                i+= run;\n\n                level = level + rl->max_level[run>>7][(run-1)&63] * qmul;//FIXME opt indexing\n\n                level = (level ^ SHOW_SBITS(re, &s->gb, 1)) - SHOW_SBITS(re, &s->gb, 1);\n\n                LAST_SKIP_BITS(re, &s->gb, 1);\n\n            }\n\n        } else {\n\n            i+= run;\n\n            level = (level ^ SHOW_SBITS(re, &s->gb, 1)) - SHOW_SBITS(re, &s->gb, 1);\n\n            LAST_SKIP_BITS(re, &s->gb, 1);\n\n        }\n\n        if (i > 62){\n\n            i-= 192;\n\n            if(i&(~63)){\n\n                fprintf(stderr, \"ac-tex damaged at %d %d\\n\", s->mb_x, s->mb_y);\n\n                return -1;\n\n            }\n\n\n\n            block[scan_table[i]] = level;\n\n            break;\n\n        }\n\n\n\n        block[scan_table[i]] = level;\n\n    }\n\n    CLOSE_READER(re, &s->gb);\n\n  }\n\n not_coded:\n\n    if (s->mb_intra) {\n\n        mpeg4_pred_ac(s, block, n, dc_pred_dir);\n\n        if (s->ac_pred) {\n\n            i = 63; /* XXX: not optimal */\n\n        }\n\n    }\n\n    s->block_last_index[n] = i;\n\n    return 0;\n\n}\n", "idx": 26040}
{"project": "FFmpeg", "commit_id": "42d73f7f6bea0ee0f64a3ad4882860ce5b923a11", "target": 1, "func": "static int parse_vtrk(AVFormatContext *s,\n\n                      FourxmDemuxContext *fourxm, uint8_t *buf, int size)\n\n{\n\n    AVStream *st;\n\n    /* check that there is enough data */\n\n    if (size != vtrk_SIZE) {\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* allocate a new AVStream */\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avpriv_set_pts_info(st, 60, 1, fourxm->fps);\n\n\n\n    fourxm->video_stream_index = st->index;\n\n\n\n    st->codec->codec_type     = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id       = AV_CODEC_ID_4XM;\n\n    st->codec->extradata_size = 4;\n\n    st->codec->extradata      = av_malloc(4);\n\n    AV_WL32(st->codec->extradata, AV_RL32(buf + 16));\n\n    st->codec->width  = AV_RL32(buf + 36);\n\n    st->codec->height = AV_RL32(buf + 40);\n\n\n\n    return 0;\n\n}\n", "idx": 26043}
{"project": "FFmpeg", "commit_id": "37216b99e090a88d98be57a8aab14a8316b96a71", "target": 0, "func": "int ff_mpeg4audio_get_config(MPEG4AudioConfig *c, const uint8_t *buf, int buf_size)\n\n{\n\n    GetBitContext gb;\n\n    int specific_config_bitindex;\n\n\n\n    init_get_bits(&gb, buf, buf_size*8);\n\n    c->object_type = get_object_type(&gb);\n\n    c->sample_rate = get_sample_rate(&gb, &c->sampling_index);\n\n    c->chan_config = get_bits(&gb, 4);\n\n    if (c->chan_config < FF_ARRAY_ELEMS(ff_mpeg4audio_channels))\n\n        c->channels = ff_mpeg4audio_channels[c->chan_config];\n\n    c->sbr = -1;\n\n    if (c->object_type == AOT_SBR || (c->object_type == AOT_PS &&\n\n        // check for W6132 Annex YYYY draft MP3onMP4\n\n        !(show_bits(&gb, 3) & 0x03 && !(show_bits(&gb, 9) & 0x3F)))) {\n\n        c->ext_object_type = AOT_SBR;\n\n        c->sbr = 1;\n\n        c->ext_sample_rate = get_sample_rate(&gb, &c->ext_sampling_index);\n\n        c->object_type = get_object_type(&gb);\n\n        if (c->object_type == AOT_ER_BSAC)\n\n            c->ext_chan_config = get_bits(&gb, 4);\n\n    } else {\n\n        c->ext_object_type = AOT_NULL;\n\n        c->ext_sample_rate = 0;\n\n    }\n\n    specific_config_bitindex = get_bits_count(&gb);\n\n\n\n    if (c->object_type == AOT_ALS) {\n\n        skip_bits(&gb, 5);\n\n        if (show_bits_long(&gb, 24) != MKBETAG('\\0','A','L','S'))\n\n            skip_bits_long(&gb, 24);\n\n\n\n        specific_config_bitindex = get_bits_count(&gb);\n\n\n\n        if (parse_config_ALS(&gb, c))\n\n            return -1;\n\n    }\n\n\n\n    if (c->ext_object_type != AOT_SBR) {\n\n        int bits_left = buf_size*8 - get_bits_count(&gb);\n\n        for (; bits_left > 15; bits_left--) {\n\n            if (show_bits(&gb, 11) == 0x2b7) { // sync extension\n\n                get_bits(&gb, 11);\n\n                c->ext_object_type = get_object_type(&gb);\n\n                if (c->ext_object_type == AOT_SBR && (c->sbr = get_bits1(&gb)) == 1)\n\n                    c->ext_sample_rate = get_sample_rate(&gb, &c->ext_sampling_index);\n\n                break;\n\n            } else\n\n                get_bits1(&gb); // skip 1 bit\n\n        }\n\n    }\n\n    return specific_config_bitindex;\n\n}\n", "idx": 26047}
{"project": "FFmpeg", "commit_id": "97bb456b6b787bb36e2785072e604ba0db9a43df", "target": 0, "func": "void ff_hevc_luma_mv_mvp_mode(HEVCContext *s, int x0, int y0, int nPbW,\n\n                              int nPbH, int log2_cb_size, int part_idx,\n\n                              int merge_idx, MvField *mv,\n\n                              int mvp_lx_flag, int LX)\n\n{\n\n    HEVCLocalContext *lc = s->HEVClc;\n\n    MvField *tab_mvf = s->ref->tab_mvf;\n\n    int isScaledFlag_L0 = 0;\n\n    int availableFlagLXA0 = 1;\n\n    int availableFlagLXB0 = 1;\n\n    int numMVPCandLX = 0;\n\n    int min_pu_width = s->sps->min_pu_width;\n\n\n\n    int xA0, yA0;\n\n    int is_available_a0;\n\n    int xA1, yA1;\n\n    int is_available_a1;\n\n    int xB0, yB0;\n\n    int is_available_b0;\n\n    int xB1, yB1;\n\n    int is_available_b1;\n\n    int xB2, yB2;\n\n    int is_available_b2;\n\n\n\n    Mv mvpcand_list[2] = { { 0 } };\n\n    Mv mxA;\n\n    Mv mxB;\n\n    int ref_idx_curr = 0;\n\n    int ref_idx = 0;\n\n    int pred_flag_index_l0;\n\n    int pred_flag_index_l1;\n\n\n\n    const int cand_bottom_left = lc->na.cand_bottom_left;\n\n    const int cand_left        = lc->na.cand_left;\n\n    const int cand_up_left     = lc->na.cand_up_left;\n\n    const int cand_up          = lc->na.cand_up;\n\n    const int cand_up_right    = lc->na.cand_up_right_sap;\n\n    ref_idx_curr       = LX;\n\n    ref_idx            = mv->ref_idx[LX];\n\n    pred_flag_index_l0 = LX;\n\n    pred_flag_index_l1 = !LX;\n\n\n\n    // left bottom spatial candidate\n\n    xA0 = x0 - 1;\n\n    yA0 = y0 + nPbH;\n\n\n\n    is_available_a0 = AVAILABLE(cand_bottom_left, A0) &&\n\n                      yA0 < s->sps->height &&\n\n                      PRED_BLOCK_AVAILABLE(A0);\n\n\n\n    //left spatial merge candidate\n\n    xA1    = x0 - 1;\n\n    yA1    = y0 + nPbH - 1;\n\n\n\n    is_available_a1 = AVAILABLE(cand_left, A1);\n\n    if (is_available_a0 || is_available_a1)\n\n        isScaledFlag_L0 = 1;\n\n\n\n    if (is_available_a0) {\n\n        if (MP_MX(A0, pred_flag_index_l0, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n        if (MP_MX(A0, pred_flag_index_l1, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n    }\n\n\n\n    if (is_available_a1) {\n\n        if (MP_MX(A1, pred_flag_index_l0, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n        if (MP_MX(A1, pred_flag_index_l1, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n    }\n\n\n\n    if (is_available_a0) {\n\n        if (MP_MX_LT(A0, pred_flag_index_l0, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n        if (MP_MX_LT(A0, pred_flag_index_l1, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n    }\n\n\n\n    if (is_available_a1) {\n\n        if (MP_MX_LT(A1, pred_flag_index_l0, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n        if (MP_MX_LT(A1, pred_flag_index_l1, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n    }\n\n    availableFlagLXA0 = 0;\n\n\n\nb_candidates:\n\n    // B candidates\n\n    // above right spatial merge candidate\n\n    xB0    = x0 + nPbW;\n\n    yB0    = y0 - 1;\n\n\n\n    is_available_b0 =  AVAILABLE(cand_up_right, B0) &&\n\n                       xB0 < s->sps->width &&\n\n                       PRED_BLOCK_AVAILABLE(B0);\n\n\n\n    // above spatial merge candidate\n\n    xB1    = x0 + nPbW - 1;\n\n    yB1    = y0 - 1;\n\n    is_available_b1 = AVAILABLE(cand_up, B1);\n\n\n\n    // above left spatial merge candidate\n\n    xB2 = x0 - 1;\n\n    yB2 = y0 - 1;\n\n    is_available_b2 = AVAILABLE(cand_up_left, B2);\n\n\n\n    // above right spatial merge candidate\n\n    if (is_available_b0) {\n\n        if (MP_MX(B0, pred_flag_index_l0, mxB)) {\n\n            goto scalef;\n\n        }\n\n        if (MP_MX(B0, pred_flag_index_l1, mxB)) {\n\n            goto scalef;\n\n        }\n\n    }\n\n\n\n    // above spatial merge candidate\n\n    if (is_available_b1) {\n\n        if (MP_MX(B1, pred_flag_index_l0, mxB)) {\n\n            goto scalef;\n\n        }\n\n        if (MP_MX(B1, pred_flag_index_l1, mxB)) {\n\n            goto scalef;\n\n        }\n\n    }\n\n\n\n    // above left spatial merge candidate\n\n    if (is_available_b2) {\n\n        if (MP_MX(B2, pred_flag_index_l0, mxB)) {\n\n            goto scalef;\n\n        }\n\n        if (MP_MX(B2, pred_flag_index_l1, mxB)) {\n\n            goto scalef;\n\n        }\n\n    }\n\n    availableFlagLXB0 = 0;\n\n\n\nscalef:\n\n    if (!isScaledFlag_L0) {\n\n        if (availableFlagLXB0) {\n\n            availableFlagLXA0 = 1;\n\n            mxA = mxB;\n\n        }\n\n        availableFlagLXB0 = 0;\n\n\n\n        // XB0 and L1\n\n        if (is_available_b0) {\n\n            availableFlagLXB0 = MP_MX_LT(B0, pred_flag_index_l0, mxB);\n\n            if (!availableFlagLXB0)\n\n                availableFlagLXB0 = MP_MX_LT(B0, pred_flag_index_l1, mxB);\n\n        }\n\n\n\n        if (is_available_b1 && !availableFlagLXB0) {\n\n            availableFlagLXB0 = MP_MX_LT(B1, pred_flag_index_l0, mxB);\n\n            if (!availableFlagLXB0)\n\n                availableFlagLXB0 = MP_MX_LT(B1, pred_flag_index_l1, mxB);\n\n        }\n\n\n\n        if (is_available_b2 && !availableFlagLXB0) {\n\n            availableFlagLXB0 = MP_MX_LT(B2, pred_flag_index_l0, mxB);\n\n            if (!availableFlagLXB0)\n\n                availableFlagLXB0 = MP_MX_LT(B2, pred_flag_index_l1, mxB);\n\n        }\n\n    }\n\n\n\n    if (availableFlagLXA0)\n\n        mvpcand_list[numMVPCandLX++] = mxA;\n\n\n\n    if (availableFlagLXB0 && (!availableFlagLXA0 || mxA.x != mxB.x || mxA.y != mxB.y))\n\n        mvpcand_list[numMVPCandLX++] = mxB;\n\n\n\n    //temporal motion vector prediction candidate\n\n    if (numMVPCandLX < 2 && s->sh.slice_temporal_mvp_enabled_flag &&\n\n        mvp_lx_flag == numMVPCandLX) {\n\n        Mv mv_col;\n\n        int available_col = temporal_luma_motion_vector(s, x0, y0, nPbW,\n\n                                                        nPbH, ref_idx,\n\n                                                        &mv_col, LX);\n\n        if (available_col)\n\n            mvpcand_list[numMVPCandLX++] = mv_col;\n\n    }\n\n\n\n    mv->mv[LX] = mvpcand_list[mvp_lx_flag];\n\n}\n", "idx": 26048}
{"project": "FFmpeg", "commit_id": "6f3e4e1712260ef8c5b4754d781ccd80bcfa1d0c", "target": 1, "func": "static int vc1_decode_intra_block(VC1Context *v, DCTELEM block[64], int n, int coded, int mquant, int codingset)\n\n{\n\n    GetBitContext *gb = &v->s.gb;\n\n    MpegEncContext *s = &v->s;\n\n    int dc_pred_dir = 0; /* Direction of the DC prediction used */\n\n    int run_diff, i;\n\n    int16_t *dc_val;\n\n    int16_t *ac_val, *ac_val2;\n\n    int dcdiff;\n\n    int mb_pos = s->mb_x + s->mb_y * s->mb_stride;\n\n    int a_avail = v->a_avail, c_avail = v->c_avail;\n\n    int use_pred = s->ac_pred;\n\n    int scale;\n\n    int q1, q2 = 0;\n\n\n\n    /* XXX: Guard against dumb values of mquant */\n\n    mquant = (mquant < 1) ? 0 : ( (mquant>31) ? 31 : mquant );\n\n\n\n    /* Set DC scale - y and c use the same */\n\n    s->y_dc_scale = s->y_dc_scale_table[mquant];\n\n    s->c_dc_scale = s->c_dc_scale_table[mquant];\n\n\n\n    /* Get DC differential */\n\n    if (n < 4) {\n\n        dcdiff = get_vlc2(&s->gb, ff_msmp4_dc_luma_vlc[s->dc_table_index].table, DC_VLC_BITS, 3);\n\n    } else {\n\n        dcdiff = get_vlc2(&s->gb, ff_msmp4_dc_chroma_vlc[s->dc_table_index].table, DC_VLC_BITS, 3);\n\n    }\n\n    if (dcdiff < 0){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Illegal DC VLC\\n\");\n\n        return -1;\n\n    }\n\n    if (dcdiff)\n\n    {\n\n        if (dcdiff == 119 /* ESC index value */)\n\n        {\n\n            /* TODO: Optimize */\n\n            if (mquant == 1) dcdiff = get_bits(gb, 10);\n\n            else if (mquant == 2) dcdiff = get_bits(gb, 9);\n\n            else dcdiff = get_bits(gb, 8);\n\n        }\n\n        else\n\n        {\n\n            if (mquant == 1)\n\n                dcdiff = (dcdiff<<2) + get_bits(gb, 2) - 3;\n\n            else if (mquant == 2)\n\n                dcdiff = (dcdiff<<1) + get_bits(gb, 1) - 1;\n\n        }\n\n        if (get_bits(gb, 1))\n\n            dcdiff = -dcdiff;\n\n    }\n\n\n\n    /* Prediction */\n\n    dcdiff += vc1_pred_dc(&v->s, v->overlap, mquant, n, a_avail, c_avail, &dc_val, &dc_pred_dir);\n\n    *dc_val = dcdiff;\n\n\n\n    /* Store the quantized DC coeff, used for prediction */\n\n\n\n    if (n < 4) {\n\n        block[0] = dcdiff * s->y_dc_scale;\n\n    } else {\n\n        block[0] = dcdiff * s->c_dc_scale;\n\n    }\n\n    /* Skip ? */\n\n    run_diff = 0;\n\n    i = 0;\n\n\n\n    //AC Decoding\n\n    i = 1;\n\n\n\n    /* check if AC is needed at all and adjust direction if needed */\n\n    if(!a_avail) dc_pred_dir = 1;\n\n    if(!c_avail) dc_pred_dir = 0;\n\n    if(!a_avail && !c_avail) use_pred = 0;\n\n    ac_val = s->ac_val[0][0] + s->block_index[n] * 16;\n\n    ac_val2 = ac_val;\n\n\n\n    scale = mquant * 2 + v->halfpq;\n\n\n\n    if(dc_pred_dir) //left\n\n        ac_val -= 16;\n\n    else //top\n\n        ac_val -= 16 * s->block_wrap[n];\n\n\n\n    q1 = s->current_picture.qscale_table[mb_pos];\n\n    if(dc_pred_dir && c_avail) q2 = s->current_picture.qscale_table[mb_pos - 1];\n\n    if(!dc_pred_dir && a_avail) q2 = s->current_picture.qscale_table[mb_pos - s->mb_stride];\n\n    if(n && n<4) q2 = q1;\n\n\n\n    if(coded) {\n\n        int last = 0, skip, value;\n\n        const int8_t *zz_table;\n\n        int k;\n\n\n\n        zz_table = vc1_simple_progressive_8x8_zz;\n\n\n\n        while (!last) {\n\n            vc1_decode_ac_coeff(v, &last, &skip, &value, codingset);\n\n            i += skip;\n\n            if(i > 63)\n\n                break;\n\n            block[zz_table[i++]] = value;\n\n        }\n\n\n\n        /* apply AC prediction if needed */\n\n        if(use_pred) {\n\n            /* scale predictors if needed*/\n\n            if(q2 && q1!=q2) {\n\n                q1 = q1 * 2 + ((q1 == v->pq) ? v->halfpq : 0) - 1;\n\n                q2 = q2 * 2 + ((q2 == v->pq) ? v->halfpq : 0) - 1;\n\n\n\n                if(dc_pred_dir) { //left\n\n                    for(k = 1; k < 8; k++)\n\n                        block[k << 3] += (ac_val[k] * q2 * vc1_dqscale[q1 - 1] + 0x20000) >> 18;\n\n                } else { //top\n\n                    for(k = 1; k < 8; k++)\n\n                        block[k] += (ac_val[k + 8] * q2 * vc1_dqscale[q1 - 1] + 0x20000) >> 18;\n\n                }\n\n            } else {\n\n                if(dc_pred_dir) { //left\n\n                    for(k = 1; k < 8; k++)\n\n                        block[k << 3] += ac_val[k];\n\n                } else { //top\n\n                    for(k = 1; k < 8; k++)\n\n                        block[k] += ac_val[k + 8];\n\n                }\n\n            }\n\n        }\n\n        /* save AC coeffs for further prediction */\n\n        for(k = 1; k < 8; k++) {\n\n            ac_val2[k] = block[k << 3];\n\n            ac_val2[k + 8] = block[k];\n\n        }\n\n\n\n        /* scale AC coeffs */\n\n        for(k = 1; k < 64; k++)\n\n            if(block[k]) {\n\n                block[k] *= scale;\n\n                if(!v->pquantizer)\n\n                    block[k] += (block[k] < 0) ? -mquant : mquant;\n\n            }\n\n\n\n        if(use_pred) i = 63;\n\n    } else { // no AC coeffs\n\n        int k;\n\n\n\n        memset(ac_val2, 0, 16 * 2);\n\n        if(dc_pred_dir) {//left\n\n            if(use_pred) {\n\n                memcpy(ac_val2, ac_val, 8 * 2);\n\n                if(q2 && q1!=q2) {\n\n                    q1 = q1 * 2 + ((q1 == v->pq) ? v->halfpq : 0) - 1;\n\n                    q2 = q2 * 2 + ((q2 == v->pq) ? v->halfpq : 0) - 1;\n\n                    for(k = 1; k < 8; k++)\n\n                        ac_val2[k] = (ac_val2[k] * q2 * vc1_dqscale[q1 - 1] + 0x20000) >> 18;\n\n                }\n\n            }\n\n        } else {//top\n\n            if(use_pred) {\n\n                memcpy(ac_val2 + 8, ac_val + 8, 8 * 2);\n\n                if(q2 && q1!=q2) {\n\n                    q1 = q1 * 2 + ((q1 == v->pq) ? v->halfpq : 0) - 1;\n\n                    q2 = q2 * 2 + ((q2 == v->pq) ? v->halfpq : 0) - 1;\n\n                    for(k = 1; k < 8; k++)\n\n                        ac_val2[k + 8] = (ac_val2[k + 8] * q2 * vc1_dqscale[q1 - 1] + 0x20000) >> 18;\n\n                }\n\n            }\n\n        }\n\n\n\n        /* apply AC prediction if needed */\n\n        if(use_pred) {\n\n            if(dc_pred_dir) { //left\n\n                for(k = 1; k < 8; k++) {\n\n                    block[k << 3] = ac_val2[k] * scale;\n\n                    if(!v->pquantizer && block[k << 3])\n\n                        block[k << 3] += (block[k << 3] < 0) ? -mquant : mquant;\n\n                }\n\n            } else { //top\n\n                for(k = 1; k < 8; k++) {\n\n                    block[k] = ac_val2[k + 8] * scale;\n\n                    if(!v->pquantizer && block[k])\n\n                        block[k] += (block[k] < 0) ? -mquant : mquant;\n\n                }\n\n            }\n\n            i = 63;\n\n        }\n\n    }\n\n    s->block_last_index[n] = i;\n\n\n\n    return 0;\n\n}\n", "idx": 26053}
{"project": "FFmpeg", "commit_id": "e494f44c051d7dccc038a603ab22532b87dd1705", "target": 0, "func": "static int can_safely_read(GetBitContext* gb, uint64_t bits) {\n\n    return get_bits_left(gb) >= bits;\n\n}\n", "idx": 26054}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int tta_probe(AVProbeData *p)\n\n{\n\n    const uint8_t *d = p->buf;\n\n    if (p->buf_size < 4)\n\n        return 0;\n\n    if (d[0] == 'T' && d[1] == 'T' && d[2] == 'A' && d[3] == '1')\n\n        return 80;\n\n    return 0;\n\n}\n", "idx": 26055}
{"project": "FFmpeg", "commit_id": "931da6a5e9dd54563fe5d4d30b7bd4d0a0218c87", "target": 0, "func": "static void list_formats(AVFormatContext *ctx, int type)\n\n{\n\n    const struct video_data *s = ctx->priv_data;\n\n    struct v4l2_fmtdesc vfd = { .type = V4L2_BUF_TYPE_VIDEO_CAPTURE };\n\n\n\n    while(!v4l2_ioctl(s->fd, VIDIOC_ENUM_FMT, &vfd)) {\n\n        enum AVCodecID codec_id = avpriv_fmt_v4l2codec(vfd.pixelformat);\n\n        enum AVPixelFormat pix_fmt = avpriv_fmt_v4l2ff(vfd.pixelformat, codec_id);\n\n\n\n        vfd.index++;\n\n\n\n        if (!(vfd.flags & V4L2_FMT_FLAG_COMPRESSED) &&\n\n            type & V4L_RAWFORMATS) {\n\n            const char *fmt_name = av_get_pix_fmt_name(pix_fmt);\n\n            av_log(ctx, AV_LOG_INFO, \"Raw       : %9s : %20s :\",\n\n                   fmt_name ? fmt_name : \"Unsupported\",\n\n                   vfd.description);\n\n        } else if (vfd.flags & V4L2_FMT_FLAG_COMPRESSED &&\n\n                   type & V4L_COMPFORMATS) {\n\n            AVCodec *codec = avcodec_find_decoder(codec_id);\n\n            av_log(ctx, AV_LOG_INFO, \"Compressed: %9s : %20s :\",\n\n                   codec ? codec->name : \"Unsupported\",\n\n                   vfd.description);\n\n        } else {\n\n            continue;\n\n        }\n\n\n\n#ifdef V4L2_FMT_FLAG_EMULATED\n\n        if (vfd.flags & V4L2_FMT_FLAG_EMULATED)\n\n            av_log(ctx, AV_LOG_INFO, \" Emulated :\");\n\n#endif\n\n#if HAVE_STRUCT_V4L2_FRMIVALENUM_DISCRETE\n\n        list_framesizes(ctx, vfd.pixelformat);\n\n#endif\n\n        av_log(ctx, AV_LOG_INFO, \"\\n\");\n\n    }\n\n}\n", "idx": 26060}
{"project": "FFmpeg", "commit_id": "7056f13a89da1d1f4afd5c6342e7ca6824777125", "target": 0, "func": "static int cinepak_decode_strip (CinepakContext *s,\n\n                                 cvid_strip *strip, const uint8_t *data, int size)\n\n{\n\n    const uint8_t *eod = (data + size);\n\n    int      chunk_id, chunk_size;\n\n\n\n    /* coordinate sanity checks */\n\n    if (strip->x1 >= s->width  || strip->x2 > s->width  ||\n\n        strip->y1 >= s->height || strip->y2 > s->height ||\n\n        strip->x1 >= strip->x2 || strip->y1 >= strip->y2)\n\n        return -1;\n\n\n\n    while ((data + 4) <= eod) {\n\n        chunk_id   = data[0];\n\n        chunk_size = AV_RB24 (&data[1]) - 4;\n\n        if(chunk_size < 0)\n\n            return -1;\n\n\n\n        data      += 4;\n\n        chunk_size = ((data + chunk_size) > eod) ? (eod - data) : chunk_size;\n\n\n\n        switch (chunk_id) {\n\n\n\n        case 0x20:\n\n        case 0x21:\n\n        case 0x24:\n\n        case 0x25:\n\n            cinepak_decode_codebook (strip->v4_codebook, chunk_id,\n\n                chunk_size, data);\n\n            break;\n\n\n\n        case 0x22:\n\n        case 0x23:\n\n        case 0x26:\n\n        case 0x27:\n\n            cinepak_decode_codebook (strip->v1_codebook, chunk_id,\n\n                chunk_size, data);\n\n            break;\n\n\n\n        case 0x30:\n\n        case 0x31:\n\n        case 0x32:\n\n            return cinepak_decode_vectors (s, strip, chunk_id,\n\n                chunk_size, data);\n\n        }\n\n\n\n        data += chunk_size;\n\n    }\n\n\n\n    return -1;\n\n}\n", "idx": 26071}
{"project": "FFmpeg", "commit_id": "229843aa359ae0c9519977d7fa952688db63f559", "target": 0, "func": "static int gen_sub_bitmap(TeletextContext *ctx, AVSubtitleRect *sub_rect, vbi_page *page, int chop_top)\n\n{\n\n    int resx = page->columns * BITMAP_CHAR_WIDTH;\n\n    int resy = (page->rows - chop_top) * BITMAP_CHAR_HEIGHT;\n\n    uint8_t ci, cmax = 0;\n\n    int ret;\n\n    vbi_char *vc = page->text + (chop_top * page->columns);\n\n    vbi_char *vcend = page->text + (page->rows * page->columns);\n\n\n\n    for (; vc < vcend; vc++) {\n\n        if (vc->opacity != VBI_TRANSPARENT_SPACE) {\n\n            cmax = VBI_NB_COLORS;\n\n            break;\n\n        }\n\n    }\n\n\n\n    if (cmax == 0) {\n\n        av_log(ctx, AV_LOG_DEBUG, \"dropping empty page %3x\\n\", page->pgno);\n\n        sub_rect->type = SUBTITLE_NONE;\n\n        return 0;\n\n    }\n\n\n\n    if ((ret = avpicture_alloc(&sub_rect->pict, AV_PIX_FMT_PAL8, resx, resy)) < 0)\n\n        return ret;\n\n    // Yes, we want to allocate the palette on our own because AVSubtitle works this way\n\n    sub_rect->pict.data[1] = NULL;\n\n\n\n    vbi_draw_vt_page_region(page, VBI_PIXFMT_PAL8,\n\n                            sub_rect->pict.data[0], sub_rect->pict.linesize[0],\n\n                            0, chop_top, page->columns, page->rows - chop_top,\n\n                            /*reveal*/ 1, /*flash*/ 1);\n\n\n\n    fix_transparency(ctx, sub_rect, page, chop_top, cmax, resx, resy);\n\n    sub_rect->x = ctx->x_offset;\n\n    sub_rect->y = ctx->y_offset + chop_top * BITMAP_CHAR_HEIGHT;\n\n    sub_rect->w = resx;\n\n    sub_rect->h = resy;\n\n    sub_rect->nb_colors = (int)cmax + 1;\n\n    sub_rect->pict.data[1] = av_mallocz(AVPALETTE_SIZE);\n\n    if (!sub_rect->pict.data[1]) {\n\n        av_freep(&sub_rect->pict.data[0]);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    for (ci = 0; ci < cmax; ci++) {\n\n        int r, g, b, a;\n\n\n\n        r = VBI_R(page->color_map[ci]);\n\n        g = VBI_G(page->color_map[ci]);\n\n        b = VBI_B(page->color_map[ci]);\n\n        a = VBI_A(page->color_map[ci]);\n\n        ((uint32_t *)sub_rect->pict.data[1])[ci] = RGBA(r, g, b, a);\n\n        av_dlog(ctx, \"palette %0x\\n\", ((uint32_t *)sub_rect->pict.data[1])[ci]);\n\n    }\n\n    ((uint32_t *)sub_rect->pict.data[1])[cmax] = RGBA(0, 0, 0, 0);\n\n    sub_rect->type = SUBTITLE_BITMAP;\n\n    return 0;\n\n}\n", "idx": 26075}
{"project": "FFmpeg", "commit_id": "b7d77f8e64d5e30982671e861f63654709111a8e", "target": 0, "func": "static int ast_write_header(AVFormatContext *s)\n\n{\n\n    ASTMuxContext *ast = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVCodecContext *enc;\n\n    unsigned int codec_tag;\n\n\n\n    if (s->nb_streams == 1) {\n\n        enc = s->streams[0]->codec;\n\n    } else {\n\n        av_log(s, AV_LOG_ERROR, \"only one stream is supported\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (enc->codec_id == AV_CODEC_ID_ADPCM_AFC) {\n\n        av_log(s, AV_LOG_ERROR, \"muxing ADPCM AFC is not implemented\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    codec_tag = ff_codec_get_tag(ff_codec_ast_tags, enc->codec_id);\n\n    if (!codec_tag) {\n\n        av_log(s, AV_LOG_ERROR, \"unsupported codec\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (ast->loopstart && ast->loopend && ast->loopstart >= ast->loopend) {\n\n        av_log(s, AV_LOG_ERROR, \"loopend can't be less or equal to loopstart\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    /* Convert milliseconds to samples */\n\n    CHECK_LOOP(start)\n\n    CHECK_LOOP(end)\n\n\n\n    ffio_wfourcc(pb, \"STRM\");\n\n\n\n    ast->size = avio_tell(pb);\n\n    avio_wb32(pb, 0); /* File size minus header */\n\n    avio_wb16(pb, codec_tag);\n\n    avio_wb16(pb, 16); /* Bit depth */\n\n    avio_wb16(pb, enc->channels);\n\n    avio_wb16(pb, 0xFFFF);\n\n    avio_wb32(pb, enc->sample_rate);\n\n\n\n    ast->samples = avio_tell(pb);\n\n    avio_wb32(pb, 0); /* Number of samples */\n\n    avio_wb32(pb, 0); /* Loopstart */\n\n    avio_wb32(pb, 0); /* Loopend */\n\n    avio_wb32(pb, 0); /* Size of first block */\n\n\n\n    /* Unknown */\n\n    avio_wb32(pb, 0);\n\n    avio_wl32(pb, 0x7F);\n\n    avio_wb64(pb, 0);\n\n    avio_wb64(pb, 0);\n\n    avio_wb32(pb, 0);\n\n\n\n    avio_flush(pb);\n\n\n\n    return 0;\n\n}\n", "idx": 26076}
{"project": "FFmpeg", "commit_id": "f67a0d115254461649470452058fa3c28c0df294", "target": 0, "func": "static int read_old_huffman_tables(HYuvContext *s)\n\n{\n\n    GetBitContext gb;\n\n    int i;\n\n\n\n    init_get_bits(&gb, classic_shift_luma,\n\n                  classic_shift_luma_table_size * 8);\n\n    if (read_len_table(s->len[0], &gb) < 0)\n\n        return -1;\n\n\n\n    init_get_bits(&gb, classic_shift_chroma,\n\n                  classic_shift_chroma_table_size * 8);\n\n    if (read_len_table(s->len[1], &gb) < 0)\n\n        return -1;\n\n\n\n    for(i=0; i<256; i++) s->bits[0][i] = classic_add_luma  [i];\n\n    for(i=0; i<256; i++) s->bits[1][i] = classic_add_chroma[i];\n\n\n\n    if (s->bitstream_bpp >= 24) {\n\n        memcpy(s->bits[1], s->bits[0], 256 * sizeof(uint32_t));\n\n        memcpy(s->len[1] , s->len [0], 256 * sizeof(uint8_t));\n\n    }\n\n    memcpy(s->bits[2], s->bits[1], 256 * sizeof(uint32_t));\n\n    memcpy(s->len[2] , s->len [1], 256 * sizeof(uint8_t));\n\n\n\n    for (i = 0; i < 3; i++) {\n\n        ff_free_vlc(&s->vlc[i]);\n\n        init_vlc(&s->vlc[i], VLC_BITS, 256, s->len[i], 1, 1,\n\n                 s->bits[i], 4, 4, 0);\n\n    }\n\n\n\n    generate_joint_tables(s);\n\n\n\n    return 0;\n\n}\n", "idx": 26077}
{"project": "FFmpeg", "commit_id": "87e85a133f3ce2f037b90e9c7bbca99951df6c15", "target": 1, "func": "static int decode_ics_info(AACContext *ac, IndividualChannelStream *ics,\n\n                           GetBitContext *gb)\n\n{\n\n    const MPEG4AudioConfig *const m4ac = &ac->oc[1].m4ac;\n\n    const int aot = m4ac->object_type;\n\n    const int sampling_index = m4ac->sampling_index;\n\n    if (aot != AOT_ER_AAC_ELD) {\n\n        if (get_bits1(gb)) {\n\n            av_log(ac->avctx, AV_LOG_ERROR, \"Reserved bit set.\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        ics->window_sequence[1] = ics->window_sequence[0];\n\n        ics->window_sequence[0] = get_bits(gb, 2);\n\n        if (aot == AOT_ER_AAC_LD &&\n\n            ics->window_sequence[0] != ONLY_LONG_SEQUENCE) {\n\n            av_log(ac->avctx, AV_LOG_ERROR,\n\n                   \"AAC LD is only defined for ONLY_LONG_SEQUENCE but \"\n\n                   \"window sequence %d found.\\n\", ics->window_sequence[0]);\n\n            ics->window_sequence[0] = ONLY_LONG_SEQUENCE;\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        ics->use_kb_window[1]   = ics->use_kb_window[0];\n\n        ics->use_kb_window[0]   = get_bits1(gb);\n\n    }\n\n    ics->num_window_groups  = 1;\n\n    ics->group_len[0]       = 1;\n\n    if (ics->window_sequence[0] == EIGHT_SHORT_SEQUENCE) {\n\n        int i;\n\n        ics->max_sfb = get_bits(gb, 4);\n\n        for (i = 0; i < 7; i++) {\n\n            if (get_bits1(gb)) {\n\n                ics->group_len[ics->num_window_groups - 1]++;\n\n            } else {\n\n                ics->num_window_groups++;\n\n                ics->group_len[ics->num_window_groups - 1] = 1;\n\n            }\n\n        }\n\n        ics->num_windows       = 8;\n\n        ics->swb_offset        =    ff_swb_offset_128[sampling_index];\n\n        ics->num_swb           =   ff_aac_num_swb_128[sampling_index];\n\n        ics->tns_max_bands     = ff_tns_max_bands_128[sampling_index];\n\n        ics->predictor_present = 0;\n\n    } else {\n\n        ics->max_sfb           = get_bits(gb, 6);\n\n        ics->num_windows       = 1;\n\n        if (aot == AOT_ER_AAC_LD || aot == AOT_ER_AAC_ELD) {\n\n            if (m4ac->frame_length_short) {\n\n                ics->swb_offset    =     ff_swb_offset_480[sampling_index];\n\n                ics->num_swb       =    ff_aac_num_swb_480[sampling_index];\n\n                ics->tns_max_bands =  ff_tns_max_bands_480[sampling_index];\n\n            } else {\n\n                ics->swb_offset    =     ff_swb_offset_512[sampling_index];\n\n                ics->num_swb       =    ff_aac_num_swb_512[sampling_index];\n\n                ics->tns_max_bands =  ff_tns_max_bands_512[sampling_index];\n\n            }\n\n            if (!ics->num_swb || !ics->swb_offset)\n\n                return AVERROR_BUG;\n\n        } else {\n\n            ics->swb_offset    =    ff_swb_offset_1024[sampling_index];\n\n            ics->num_swb       =   ff_aac_num_swb_1024[sampling_index];\n\n            ics->tns_max_bands = ff_tns_max_bands_1024[sampling_index];\n\n        }\n\n        if (aot != AOT_ER_AAC_ELD) {\n\n            ics->predictor_present     = get_bits1(gb);\n\n            ics->predictor_reset_group = 0;\n\n        }\n\n        if (ics->predictor_present) {\n\n            if (aot == AOT_AAC_MAIN) {\n\n                if (decode_prediction(ac, ics, gb)) {\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n            } else if (aot == AOT_AAC_LC ||\n\n                       aot == AOT_ER_AAC_LC) {\n\n                av_log(ac->avctx, AV_LOG_ERROR,\n\n                       \"Prediction is not allowed in AAC-LC.\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            } else {\n\n                if (aot == AOT_ER_AAC_LD) {\n\n                    av_log(ac->avctx, AV_LOG_ERROR,\n\n                           \"LTP in ER AAC LD not yet implemented.\\n\");\n\n                    return AVERROR_PATCHWELCOME;\n\n                }\n\n                if ((ics->ltp.present = get_bits(gb, 1)))\n\n                    decode_ltp(&ics->ltp, gb, ics->max_sfb);\n\n            }\n\n        }\n\n    }\n\n\n\n    if (ics->max_sfb > ics->num_swb) {\n\n        av_log(ac->avctx, AV_LOG_ERROR,\n\n               \"Number of scalefactor bands in group (%d) \"\n\n               \"exceeds limit (%d).\\n\",\n\n               ics->max_sfb, ics->num_swb);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26079}
{"project": "FFmpeg", "commit_id": "2867ed9b1c0561b0e50d9c4f73e09621333e2f1f", "target": 1, "func": "static void dvbsub_parse_region_segment(AVCodecContext *avctx,\n\n                                        uint8_t *buf, int buf_size)\n\n{\n\n    DVBSubContext *ctx = (DVBSubContext*) avctx->priv_data;\n\n\n\n    uint8_t *buf_end = buf + buf_size;\n\n    int region_id, object_id;\n\n    DVBSubRegion *region;\n\n    DVBSubObject *object;\n\n    DVBSubObjectDisplay *display;\n\n    int fill;\n\n\n\n    if (buf_size < 10)\n\n        return;\n\n\n\n    region_id = *buf++;\n\n\n\n    region = get_region(ctx, region_id);\n\n\n\n    if (region == NULL)\n\n    {\n\n        region = av_mallocz(sizeof(DVBSubRegion));\n\n\n\n        region->id = region_id;\n\n\n\n        region->next = ctx->region_list;\n\n        ctx->region_list = region;\n\n\n\n\n    fill = ((*buf++) >> 3) & 1;\n\n\n\n    region->width = AV_RB16(buf);\n\n    buf += 2;\n\n    region->height = AV_RB16(buf);\n\n    buf += 2;\n\n\n\n    if (region->width * region->height != region->buf_size) {\n\n        if (region->pbuf != 0)\n\n            av_free(region->pbuf);\n\n\n\n        region->buf_size = region->width * region->height;\n\n\n\n        region->pbuf = av_malloc(region->buf_size);\n\n\n\n        fill = 1;\n\n\n\n\n    region->depth = 1 << (((*buf++) >> 2) & 7);\n\n\n\n\n\n    region->clut = *buf++;\n\n\n\n    if (region->depth == 8)\n\n        region->bgcolour = *buf++;\n\n    else {\n\n        buf += 1;\n\n\n\n        if (region->depth == 4)\n\n            region->bgcolour = (((*buf++) >> 4) & 15);\n\n        else\n\n            region->bgcolour = (((*buf++) >> 2) & 3);\n\n\n\n\n#ifdef DEBUG\n\n    av_log(avctx, AV_LOG_INFO, \"Region %d, (%dx%d)\\n\", region_id, region->width, region->height);\n\n#endif\n\n\n\n    if (fill) {\n\n        memset(region->pbuf, region->bgcolour, region->buf_size);\n\n#ifdef DEBUG\n\n        av_log(avctx, AV_LOG_INFO, \"Fill region (%d)\\n\", region->bgcolour);\n\n#endif\n\n\n\n\n    delete_region_display_list(ctx, region);\n\n\n\n    while (buf + 5 < buf_end) {\n\n        object_id = AV_RB16(buf);\n\n        buf += 2;\n\n\n\n        object = get_object(ctx, object_id);\n\n\n\n        if (object == NULL) {\n\n            object = av_mallocz(sizeof(DVBSubObject));\n\n\n\n            object->id = object_id;\n\n            object->next = ctx->object_list;\n\n            ctx->object_list = object;\n\n\n\n\n        object->type = (*buf) >> 6;\n\n\n\n        display = av_mallocz(sizeof(DVBSubObjectDisplay));\n\n\n\n        display->object_id = object_id;\n\n        display->region_id = region_id;\n\n\n\n        display->x_pos = AV_RB16(buf) & 0xfff;\n\n        buf += 2;\n\n        display->y_pos = AV_RB16(buf) & 0xfff;\n\n        buf += 2;\n\n\n\n        if ((object->type == 1 || object->type == 2) && buf+1 < buf_end) {\n\n            display->fgcolour = *buf++;\n\n            display->bgcolour = *buf++;\n\n\n\n\n        display->region_list_next = region->display_list;\n\n        region->display_list = display;\n\n\n\n        display->object_list_next = object->display_list;\n\n        object->display_list = display;\n\n", "idx": 26080}
{"project": "FFmpeg", "commit_id": "a04c2c707de2ce850f79870e84ac9d7ec7aa9143", "target": 1, "func": "int ff_unlock_avcodec(const AVCodec *codec)\n\n{\n\n    if (codec->caps_internal & FF_CODEC_CAP_INIT_THREADSAFE || !codec->init)\n\n        return 0;\n\n\n\n    av_assert0(ff_avcodec_locked);\n\n    ff_avcodec_locked = 0;\n\n    atomic_fetch_add(&entangled_thread_counter, -1);\n\n    if (lockmgr_cb) {\n\n        if ((*lockmgr_cb)(&codec_mutex, AV_LOCK_RELEASE))\n\n            return -1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26081}
{"project": "FFmpeg", "commit_id": "cf2b7c01f81c1fb3283a1390c0ca9a2f81f4f4a8", "target": 1, "func": "static inline void copy(LZOContext *c, int cnt)\n\n{\n\n    register const uint8_t *src = c->in;\n\n    register uint8_t *dst       = c->out;\n\n\n    if (cnt > c->in_end - src) {\n\n        cnt       = FFMAX(c->in_end - src, 0);\n\n        c->error |= AV_LZO_INPUT_DEPLETED;\n\n    }\n\n    if (cnt > c->out_end - dst) {\n\n        cnt       = FFMAX(c->out_end - dst, 0);\n\n        c->error |= AV_LZO_OUTPUT_FULL;\n\n    }\n\n#if defined(INBUF_PADDED) && defined(OUTBUF_PADDED)\n\n    AV_COPY32U(dst, src);\n\n    src += 4;\n\n    dst += 4;\n\n    cnt -= 4;\n\n    if (cnt > 0)\n\n#endif\n\n    memcpy(dst, src, cnt);\n\n    c->in  = src + cnt;\n\n    c->out = dst + cnt;\n\n}", "idx": 26082}
{"project": "FFmpeg", "commit_id": "fd34dbea58e097609ff09cf7dcc59f74930195d3", "target": 1, "func": "static int mxf_read_generic_descriptor(void *arg, AVIOContext *pb, int tag, int size, UID uid)\n\n{\n\n    MXFDescriptor *descriptor = arg;\n\n    switch(tag) {\n\n    case 0x3F01:\n\n        descriptor->sub_descriptors_count = avio_rb32(pb);\n\n        if (descriptor->sub_descriptors_count >= UINT_MAX / sizeof(UID))\n\n            return -1;\n\n        descriptor->sub_descriptors_refs = av_malloc(descriptor->sub_descriptors_count * sizeof(UID));\n\n        if (!descriptor->sub_descriptors_refs)\n\n            return -1;\n\n        avio_skip(pb, 4); /* useless size of objects, always 16 according to specs */\n\n        avio_read(pb, (uint8_t *)descriptor->sub_descriptors_refs, descriptor->sub_descriptors_count * sizeof(UID));\n\n        break;\n\n    case 0x3004:\n\n        avio_read(pb, descriptor->essence_container_ul, 16);\n\n        break;\n\n    case 0x3006:\n\n        descriptor->linked_track_id = avio_rb32(pb);\n\n        break;\n\n    case 0x3201: /* PictureEssenceCoding */\n\n        avio_read(pb, descriptor->essence_codec_ul, 16);\n\n        break;\n\n    case 0x3203:\n\n        descriptor->width = avio_rb32(pb);\n\n        break;\n\n    case 0x3202:\n\n        descriptor->height = avio_rb32(pb);\n\n        break;\n\n    case 0x320E:\n\n        descriptor->aspect_ratio.num = avio_rb32(pb);\n\n        descriptor->aspect_ratio.den = avio_rb32(pb);\n\n        break;\n\n    case 0x3D03:\n\n        descriptor->sample_rate.num = avio_rb32(pb);\n\n        descriptor->sample_rate.den = avio_rb32(pb);\n\n        break;\n\n    case 0x3D06: /* SoundEssenceCompression */\n\n        avio_read(pb, descriptor->essence_codec_ul, 16);\n\n        break;\n\n    case 0x3D07:\n\n        descriptor->channels = avio_rb32(pb);\n\n        break;\n\n    case 0x3D01:\n\n        descriptor->bits_per_sample = avio_rb32(pb);\n\n        break;\n\n    case 0x3401:\n\n        mxf_read_pixel_layout(pb, descriptor);\n\n        break;\n\n    default:\n\n        /* Private uid used by SONY C0023S01.mxf */\n\n        if (IS_KLV_KEY(uid, mxf_sony_mpeg4_extradata)) {\n\n            descriptor->extradata = av_malloc(size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (!descriptor->extradata)\n\n                return -1;\n\n            descriptor->extradata_size = size;\n\n            avio_read(pb, descriptor->extradata, size);\n\n        }\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 26083}
{"project": "FFmpeg", "commit_id": "bd404e3949b081788247e2e6e9df0581ef7cc190", "target": 0, "func": "static int fir_channel(AVFilterContext *ctx, void *arg, int ch, int nb_jobs)\n\n{\n\n    AudioFIRContext *s = ctx->priv;\n\n    const float *src = (const float *)s->in[0]->extended_data[ch];\n\n    int index1 = (s->index + 1) % 3;\n\n    int index2 = (s->index + 2) % 3;\n\n    float *sum = s->sum[ch];\n\n    AVFrame *out = arg;\n\n    float *block;\n\n    float *dst;\n\n    int n, i, j;\n\n\n\n    memset(sum, 0, sizeof(*sum) * s->fft_length);\n\n    block = s->block[ch] + s->part_index * s->block_size;\n\n    memset(block, 0, sizeof(*block) * s->fft_length);\n\n\n\n    s->fdsp->vector_fmul_scalar(block + s->part_size, src, s->dry_gain, s->nb_samples);\n\n    emms_c();\n\n\n\n    av_rdft_calc(s->rdft[ch], block);\n\n    block[2 * s->part_size] = block[1];\n\n    block[1] = 0;\n\n\n\n    j = s->part_index;\n\n\n\n    for (i = 0; i < s->nb_partitions; i++) {\n\n        const int coffset = i * s->coeff_size;\n\n        const FFTComplex *coeff = s->coeff[ch * !s->one2many] + coffset;\n\n\n\n        block = s->block[ch] + j * s->block_size;\n\n        s->fcmul_add(sum, block, (const float *)coeff, s->part_size);\n\n\n\n        if (j == 0)\n\n            j = s->nb_partitions;\n\n        j--;\n\n    }\n\n\n\n    sum[1] = sum[2 * s->part_size];\n\n    av_rdft_calc(s->irdft[ch], sum);\n\n\n\n    dst = (float *)s->buffer->extended_data[ch] + index1 * s->part_size;\n\n    for (n = 0; n < s->part_size; n++) {\n\n        dst[n] += sum[n];\n\n    }\n\n\n\n    dst = (float *)s->buffer->extended_data[ch] + index2 * s->part_size;\n\n\n\n    memcpy(dst, sum + s->part_size, s->part_size * sizeof(*dst));\n\n\n\n    dst = (float *)s->buffer->extended_data[ch] + s->index * s->part_size;\n\n\n\n    if (out) {\n\n        float *ptr = (float *)out->extended_data[ch];\n\n        s->fdsp->vector_fmul_scalar(ptr, dst, s->gain * s->wet_gain, out->nb_samples);\n\n        emms_c();\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26084}
{"project": "FFmpeg", "commit_id": "763e714442e07f6430b003c8a9f4b62deaa7b3a5", "target": 0, "func": "static int aiff_read_packet(AVFormatContext *s,\n\n                            AVPacket *pkt)\n\n{\n\n    AVStream *st = s->streams[0];\n\n    AIFFInputContext *aiff = s->priv_data;\n\n    int64_t max_size;\n\n    int res, size;\n\n\n\n    /* calculate size of remaining data */\n\n    max_size = aiff->data_end - avio_tell(s->pb);\n\n    if (max_size <= 0)\n\n        return AVERROR_EOF;\n\n\n\n    /* Now for that packet */\n\n    if (st->codec->block_align >= 17) // GSM, QCLP, IMA4\n\n        size = st->codec->block_align;\n\n    else\n\n        size = (MAX_SIZE / st->codec->block_align) * st->codec->block_align;\n\n    size = FFMIN(max_size, size);\n\n    res = av_get_packet(s->pb, pkt, size);\n\n    if (res < 0)\n\n        return res;\n\n\n\n    if (size >= st->codec->block_align)\n\n        pkt->flags &= ~AV_PKT_FLAG_CORRUPT;\n\n    /* Only one stream in an AIFF file */\n\n    pkt->stream_index = 0;\n\n    pkt->duration     = (res / st->codec->block_align) * aiff->block_duration;\n\n    return 0;\n\n}\n", "idx": 26085}
{"project": "FFmpeg", "commit_id": "8a048fe6f8bf41de93c091a7a9b3132bedc1b41c", "target": 1, "func": "static int get_riff(AVFormatContext *s, AVIOContext *pb)\n\n{\n\n    AVIContext *avi = s->priv_data;\n\n    char header[8];\n\n    int i;\n\n\n\n    /* check RIFF header */\n\n    avio_read(pb, header, 4);\n\n    avi->riff_end  = avio_rl32(pb); /* RIFF chunk size */\n\n    avi->riff_end += avio_tell(pb); /* RIFF chunk end */\n\n    avio_read(pb, header + 4, 4);\n\n\n\n    for (i = 0; avi_headers[i][0]; i++)\n\n        if (!memcmp(header, avi_headers[i], 8))\n\n            break;\n\n    if (!avi_headers[i][0])\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (header[7] == 0x19)\n\n        av_log(s, AV_LOG_INFO,\n\n               \"This file has been generated by a totally broken muxer.\\n\");\n\n\n\n    return 0;\n\n}\n", "idx": 26086}
{"project": "FFmpeg", "commit_id": "41a052a6badc9ed672a810a40b8e54af5d093b5d", "target": 1, "func": "int opt_default(const char *opt, const char *arg)\n\n{\n\n    const AVOption *oc, *of, *os, *oswr;\n\n    char opt_stripped[128];\n\n    const char *p;\n\n    const AVClass *cc = avcodec_get_class(), *fc = avformat_get_class(), *sc, *swr_class;\n\n\n\n    if (!(p = strchr(opt, ':')))\n\n        p = opt + strlen(opt);\n\n    av_strlcpy(opt_stripped, opt, FFMIN(sizeof(opt_stripped), p - opt + 1));\n\n\n\n    if ((oc = av_opt_find(&cc, opt_stripped, NULL, 0,\n\n                         AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ)) ||\n\n        ((opt[0] == 'v' || opt[0] == 'a' || opt[0] == 's') &&\n\n         (oc = av_opt_find(&cc, opt + 1, NULL, 0, AV_OPT_SEARCH_FAKE_OBJ))))\n\n        av_dict_set(&codec_opts, opt, arg, FLAGS(oc));\n\n    if ((of = av_opt_find(&fc, opt, NULL, 0,\n\n                          AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ)))\n\n        av_dict_set(&format_opts, opt, arg, FLAGS(of));\n\n#if CONFIG_SWSCALE\n\n    sc = sws_get_class();\n\n    if ((os = av_opt_find(&sc, opt, NULL, 0,\n\n                          AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ))) {\n\n        // XXX we only support sws_flags, not arbitrary sws options\n\n        int ret = av_opt_set(sws_opts, opt, arg, 0);\n\n        if (ret < 0) {\n\n            av_log(NULL, AV_LOG_ERROR, \"Error setting option %s.\\n\", opt);\n\n            return ret;\n\n        }\n\n    }\n\n#endif\n\n    swr_class = swr_get_class();\n\n    if (!oc && !of && !os && (oswr = av_opt_find(&swr_class, opt, NULL, 0,\n\n                          AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ))) {\n\n        int ret = av_opt_set(swr_opts, opt, arg, 0);\n\n        if (ret < 0) {\n\n            av_log(NULL, AV_LOG_ERROR, \"Error setting option %s.\\n\", opt);\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    if (oc || of || os || oswr)\n\n        return 0;\n\n    av_log(NULL, AV_LOG_ERROR, \"Unrecognized option '%s'\\n\", opt);\n\n    return AVERROR_OPTION_NOT_FOUND;\n\n}\n", "idx": 26087}
{"project": "FFmpeg", "commit_id": "955db411929a9876d3cd016fbbb9c49b6362feba", "target": 1, "func": "static int decode_segment(TAKDecContext *s, int8_t mode, int32_t *decoded, int len)\n\n{\n\n    struct CParam code;\n\n    GetBitContext *gb = &s->gb;\n\n    int i;\n\n\n\n    if (!mode) {\n\n        memset(decoded, 0, len * sizeof(*decoded));\n\n        return 0;\n\n    }\n\n\n\n    if (mode > FF_ARRAY_ELEMS(xcodes))\n\n        return AVERROR_INVALIDDATA;\n\n    code = xcodes[mode - 1];\n\n\n\n    for (i = 0; i < len; i++) {\n\n        int x = get_bits_long(gb, code.init);\n\n        if (x >= code.escape && get_bits1(gb)) {\n\n            x |= 1 << code.init;\n\n            if (x >= code.aescape) {\n\n                int scale = get_unary(gb, 1, 9);\n\n                if (scale == 9) {\n\n                    int scale_bits = get_bits(gb, 3);\n\n                    if (scale_bits > 0) {\n\n                        if (scale_bits == 7) {\n\n                            scale_bits += get_bits(gb, 5);\n\n                            if (scale_bits > 29)\n\n                                return AVERROR_INVALIDDATA;\n\n                        }\n\n                        scale = get_bits_long(gb, scale_bits) + 1;\n\n                        x    += code.scale * scale;\n\n                    }\n\n                    x += code.bias;\n\n                } else\n\n                    x += code.scale * scale - code.escape;\n\n            } else\n\n                x -= code.escape;\n\n        }\n\n        decoded[i] = (x >> 1) ^ -(x & 1);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26088}
{"project": "FFmpeg", "commit_id": "c4360559ee2a6c8c624f24fc7e2a1cf00972ba68", "target": 1, "func": "static int paf_video_decode(AVCodecContext *avctx, void *data,\n\n                            int *got_frame, AVPacket *pkt)\n\n{\n\n    PAFVideoDecContext *c = avctx->priv_data;\n\n    uint8_t code, *dst, *end;\n\n    int i, frame, ret;\n\n\n\n    if (pkt->size < 2)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    bytestream2_init(&c->gb, pkt->data, pkt->size);\n\n\n\n    code = bytestream2_get_byte(&c->gb);\n\n    if ((code & 0xF) > 4) {\n\n        avpriv_request_sample(avctx, \"unknown/invalid code\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if ((ret = ff_reget_buffer(avctx, c->pic)) < 0)\n\n        return ret;\n\n\n\n    if (code & 0x20) {  // frame is keyframe\n\n        for (i = 0; i < 4; i++)\n\n            memset(c->frame[i], 0, c->frame_size);\n\n\n\n        memset(c->pic->data[1], 0, AVPALETTE_SIZE);\n\n        c->current_frame  = 0;\n\n        c->pic->key_frame = 1;\n\n        c->pic->pict_type = AV_PICTURE_TYPE_I;\n\n    } else {\n\n        c->pic->key_frame = 0;\n\n        c->pic->pict_type = AV_PICTURE_TYPE_P;\n\n    }\n\n\n\n    if (code & 0x40) {  // palette update\n\n        uint32_t *out = (uint32_t *)c->pic->data[1];\n\n        int index, count;\n\n\n\n        index = bytestream2_get_byte(&c->gb);\n\n        count = bytestream2_get_byte(&c->gb) + 1;\n\n\n\n        if (index + count > 256)\n\n            return AVERROR_INVALIDDATA;\n\n        if (bytestream2_get_bytes_left(&c->gb) < 3 * count)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        out += index;\n\n        for (i = 0; i < count; i++) {\n\n            unsigned r, g, b;\n\n\n\n            r = bytestream2_get_byteu(&c->gb);\n\n            r = r << 2 | r >> 4;\n\n            g = bytestream2_get_byteu(&c->gb);\n\n            g = g << 2 | g >> 4;\n\n            b = bytestream2_get_byteu(&c->gb);\n\n            b = b << 2 | b >> 4;\n\n            *out++ = (0xFFU << 24) | (r << 16) | (g << 8) | b;\n\n        }\n\n        c->pic->palette_has_changed = 1;\n\n    }\n\n\n\n    switch (code & 0x0F) {\n\n    case 0:\n\n        /* Block-based motion compensation using 4x4 blocks with either\n\n         * horizontal or vertical vectors; might incorporate VQ as well. */\n\n        if ((ret = decode_0(c, pkt->data, code)) < 0)\n\n            return ret;\n\n        break;\n\n    case 1:\n\n        /* Uncompressed data. This mode specifies that (width * height) bytes\n\n         * should be copied directly from the encoded buffer into the output. */\n\n        dst = c->frame[c->current_frame];\n\n        // possibly chunk length data\n\n        bytestream2_skip(&c->gb, 2);\n\n        if (bytestream2_get_bytes_left(&c->gb) < c->video_size)\n\n            return AVERROR_INVALIDDATA;\n\n        bytestream2_get_bufferu(&c->gb, dst, c->video_size);\n\n        break;\n\n    case 2:\n\n        /* Copy reference frame: Consume the next byte in the stream as the\n\n         * reference frame (which should be 0, 1, 2, or 3, and should not be\n\n         * the same as the current frame number). */\n\n        frame = bytestream2_get_byte(&c->gb);\n\n        if (frame > 3)\n\n            return AVERROR_INVALIDDATA;\n\n        if (frame != c->current_frame)\n\n            memcpy(c->frame[c->current_frame], c->frame[frame], c->frame_size);\n\n        break;\n\n    case 4:\n\n        /* Run length encoding.*/\n\n        dst = c->frame[c->current_frame];\n\n        end = dst + c->video_size;\n\n\n\n        bytestream2_skip(&c->gb, 2);\n\n\n\n        while (dst < end) {\n\n            int8_t code;\n\n            int count;\n\n\n\n            if (bytestream2_get_bytes_left(&c->gb) < 2)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            code  = bytestream2_get_byteu(&c->gb);\n\n            count = FFABS(code) + 1;\n\n\n\n            if (dst + count > end)\n\n                return AVERROR_INVALIDDATA;\n\n            if (code < 0)\n\n                memset(dst, bytestream2_get_byteu(&c->gb), count);\n\n            else\n\n                bytestream2_get_buffer(&c->gb, dst, count);\n\n            dst += count;\n\n        }\n\n        break;\n\n    default:\n\n        av_assert0(0);\n\n    }\n\n\n\n    av_image_copy_plane(c->pic->data[0], c->pic->linesize[0],\n\n                        c->frame[c->current_frame], c->width,\n\n                        c->width, c->height);\n\n\n\n    c->current_frame = (c->current_frame + 1) & 3;\n\n    if ((ret = av_frame_ref(data, c->pic)) < 0)\n\n        return ret;\n\n\n\n    *got_frame = 1;\n\n\n\n    return pkt->size;\n\n}\n", "idx": 26089}
{"project": "FFmpeg", "commit_id": "8821ae649e61097ec57ca58472c3e4239c82913c", "target": 1, "func": "int avresample_get_matrix(AVAudioResampleContext *avr, double *matrix,\n\n                          int stride)\n\n{\n\n    int in_channels, out_channels, i, o;\n\n\n\n    in_channels  = av_get_channel_layout_nb_channels(avr->in_channel_layout);\n\n    out_channels = av_get_channel_layout_nb_channels(avr->out_channel_layout);\n\n\n\n    if ( in_channels < 0 ||  in_channels > AVRESAMPLE_MAX_CHANNELS ||\n\n        out_channels < 0 || out_channels > AVRESAMPLE_MAX_CHANNELS) {\n\n        av_log(avr, AV_LOG_ERROR, \"Invalid channel layouts\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    switch (avr->mix_coeff_type) {\n\n    case AV_MIX_COEFF_TYPE_Q8:\n\n        if (!avr->am->matrix_q8[0]) {\n\n            av_log(avr, AV_LOG_ERROR, \"matrix is not set\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n        for (o = 0; o < out_channels; o++)\n\n            for (i = 0; i < in_channels; i++)\n\n                matrix[o * stride + i] = avr->am->matrix_q8[o][i] / 256.0;\n\n        break;\n\n    case AV_MIX_COEFF_TYPE_Q15:\n\n        if (!avr->am->matrix_q15[0]) {\n\n            av_log(avr, AV_LOG_ERROR, \"matrix is not set\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n        for (o = 0; o < out_channels; o++)\n\n            for (i = 0; i < in_channels; i++)\n\n                matrix[o * stride + i] = avr->am->matrix_q15[o][i] / 32768.0;\n\n        break;\n\n    case AV_MIX_COEFF_TYPE_FLT:\n\n        if (!avr->am->matrix_flt[0]) {\n\n            av_log(avr, AV_LOG_ERROR, \"matrix is not set\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n        for (o = 0; o < out_channels; o++)\n\n            for (i = 0; i < in_channels; i++)\n\n                matrix[o * stride + i] = avr->am->matrix_flt[o][i];\n\n        break;\n\n    default:\n\n        av_log(avr, AV_LOG_ERROR, \"Invalid mix coeff type\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    return 0;\n\n}\n", "idx": 26091}
{"project": "FFmpeg", "commit_id": "d584533cf38141172e20bae5436629ee17c8ce50", "target": 0, "func": "static int parse_packet(AVFormatContext *s, AVPacket *pkt, int stream_index)\n\n{\n\n    AVPacket out_pkt = { 0 }, flush_pkt = { 0 };\n\n    AVStream *st = s->streams[stream_index];\n\n    uint8_t *data = pkt ? pkt->data : NULL;\n\n    int size      = pkt ? pkt->size : 0;\n\n    int ret = 0, got_output = 0;\n\n\n\n    if (!pkt) {\n\n        av_init_packet(&flush_pkt);\n\n        pkt        = &flush_pkt;\n\n        got_output = 1;\n\n    }\n\n\n\n    while (size > 0 || (pkt == &flush_pkt && got_output)) {\n\n        int len;\n\n\n\n        av_init_packet(&out_pkt);\n\n        len = av_parser_parse2(st->parser, st->codec,\n\n                               &out_pkt.data, &out_pkt.size, data, size,\n\n                               pkt->pts, pkt->dts, pkt->pos);\n\n\n\n        pkt->pts = pkt->dts = AV_NOPTS_VALUE;\n\n        /* increment read pointer */\n\n        data += len;\n\n        size -= len;\n\n\n\n        got_output = !!out_pkt.size;\n\n\n\n        if (!out_pkt.size)\n\n            continue;\n\n\n\n        if (pkt->side_data) {\n\n            out_pkt.side_data       = pkt->side_data;\n\n            out_pkt.side_data_elems = pkt->side_data_elems;\n\n            pkt->side_data          = NULL;\n\n            pkt->side_data_elems    = 0;\n\n        }\n\n\n\n        /* set the duration */\n\n        out_pkt.duration = 0;\n\n        if (st->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            if (st->codec->sample_rate > 0) {\n\n                out_pkt.duration =\n\n                    av_rescale_q_rnd(st->parser->duration,\n\n                                     (AVRational) { 1, st->codec->sample_rate },\n\n                                     st->time_base,\n\n                                     AV_ROUND_DOWN);\n\n            }\n\n        }\n\n\n\n        out_pkt.stream_index = st->index;\n\n        out_pkt.pts          = st->parser->pts;\n\n        out_pkt.dts          = st->parser->dts;\n\n        out_pkt.pos          = st->parser->pos;\n\n\n\n        if (st->parser->key_frame == 1 ||\n\n            (st->parser->key_frame == -1 &&\n\n             st->parser->pict_type == AV_PICTURE_TYPE_I))\n\n            out_pkt.flags |= AV_PKT_FLAG_KEY;\n\n\n\n        compute_pkt_fields(s, st, st->parser, &out_pkt);\n\n\n\n        if ((s->iformat->flags & AVFMT_GENERIC_INDEX) &&\n\n            out_pkt.flags & AV_PKT_FLAG_KEY) {\n\n            ff_reduce_index(s, st->index);\n\n            av_add_index_entry(st, st->parser->frame_offset, out_pkt.dts,\n\n                               0, 0, AVINDEX_KEYFRAME);\n\n        }\n\n\n\n        if (out_pkt.data == pkt->data && out_pkt.size == pkt->size) {\n\n            out_pkt.buf = pkt->buf;\n\n            pkt->buf    = NULL;\n\n        }\n\n        if ((ret = av_dup_packet(&out_pkt)) < 0)\n\n            goto fail;\n\n\n\n        if (!add_to_pktbuf(&s->internal->parse_queue, &out_pkt, &s->internal->parse_queue_end)) {\n\n            av_packet_unref(&out_pkt);\n\n            ret = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n    /* end of the stream => close and free the parser */\n\n    if (pkt == &flush_pkt) {\n\n        av_parser_close(st->parser);\n\n        st->parser = NULL;\n\n    }\n\n\n\nfail:\n\n    av_packet_unref(pkt);\n\n    return ret;\n\n}\n", "idx": 26092}
{"project": "FFmpeg", "commit_id": "5cb57a16ede71d913384a0b3036a2c6df5da5e43", "target": 1, "func": "int avpriv_dv_produce_packet(DVDemuxContext *c, AVPacket *pkt,\n\n                      uint8_t* buf, int buf_size, int64_t pos)\n\n{\n\n    int size, i;\n\n    uint8_t *ppcm[4] = {0};\n\n\n\n    if (buf_size < DV_PROFILE_BYTES ||\n\n        !(c->sys = avpriv_dv_frame_profile(c->sys, buf, buf_size)) ||\n\n        buf_size < c->sys->frame_size) {\n\n          return -1;   /* Broken frame, or not enough data */\n\n    }\n\n\n\n    /* Queueing audio packet */\n\n    /* FIXME: in case of no audio/bad audio we have to do something */\n\n    size = dv_extract_audio_info(c, buf);\n\n    for (i = 0; i < c->ach; i++) {\n\n       c->audio_pkt[i].pos  = pos;\n\n       c->audio_pkt[i].size = size;\n\n       c->audio_pkt[i].pts  = c->abytes * 30000*8 / c->ast[i]->codec->bit_rate;\n\n       ppcm[i] = c->audio_buf[i];\n\n    }\n\n    dv_extract_audio(buf, ppcm, c->sys);\n\n\n\n    /* We work with 720p frames split in half, thus even frames have\n\n     * channels 0,1 and odd 2,3. */\n\n    if (c->sys->height == 720) {\n\n        if (buf[1] & 0x0C) {\n\n            c->audio_pkt[2].size = c->audio_pkt[3].size = 0;\n\n        } else {\n\n            c->audio_pkt[0].size = c->audio_pkt[1].size = 0;\n\n            c->abytes += size;\n\n        }\n\n    } else {\n\n        c->abytes += size;\n\n    }\n\n\n\n    /* Now it's time to return video packet */\n\n    size = dv_extract_video_info(c, buf);\n\n    av_init_packet(pkt);\n\n    pkt->data         = buf;\n\n    pkt->pos          = pos;\n\n    pkt->size         = size;\n\n    pkt->flags       |= AV_PKT_FLAG_KEY;\n\n    pkt->stream_index = c->vst->id;\n\n    pkt->pts          = c->frames;\n\n\n\n    c->frames++;\n\n\n\n    return size;\n\n}\n", "idx": 26093}
{"project": "FFmpeg", "commit_id": "cf5a6c754aa3b67062b8cc60fa244e9c7d82010f", "target": 1, "func": "static int gdv_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame, AVPacket *avpkt)\n\n{\n\n    GDVContext *gdv = avctx->priv_data;\n\n    GetByteContext *gb = &gdv->gb;\n\n    PutByteContext *pb = &gdv->pb;\n\n    AVFrame *frame = data;\n\n    int ret, i, pal_size;\n\n    const uint8_t *pal = av_packet_get_side_data(avpkt, AV_PKT_DATA_PALETTE, &pal_size);\n\n    int compression;\n\n    unsigned flags;\n\n    uint8_t *dst;\n\n\n\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n\n        return ret;\n\n    if (pal && pal_size == AVPALETTE_SIZE)\n\n        memcpy(gdv->pal, pal, AVPALETTE_SIZE);\n\n\n\n    bytestream2_init(gb, avpkt->data, avpkt->size);\n\n    bytestream2_init_writer(pb, gdv->frame, gdv->frame_size);\n\n\n\n    flags = bytestream2_get_le32(gb);\n\n    compression = flags & 0xF;\n\n\n\n    rescale(gdv, gdv->frame, avctx->width, avctx->height,\n\n            !!(flags & 0x10), !!(flags & 0x20));\n\n\n\n    switch (compression) {\n\n    case 1:\n\n        memset(gdv->frame + PREAMBLE_SIZE, 0, gdv->frame_size - PREAMBLE_SIZE);\n\n    case 0:\n\n        if (bytestream2_get_bytes_left(gb) < 256*3)\n\n            return AVERROR_INVALIDDATA;\n\n        for (i = 0; i < 256; i++) {\n\n            unsigned r = bytestream2_get_byte(gb);\n\n            unsigned g = bytestream2_get_byte(gb);\n\n            unsigned b = bytestream2_get_byte(gb);\n\n            gdv->pal[i] = 0xFFU << 24 | r << 18 | g << 10 | b << 2;\n\n        }\n\n        break;\n\n    case 2:\n\n        ret = decompress_2(avctx);\n\n        break;\n\n    case 3:\n\n        break;\n\n    case 5:\n\n        ret = decompress_5(avctx, flags >> 8);\n\n        break;\n\n    case 6:\n\n        ret = decompress_68(avctx, flags >> 8, 0);\n\n        break;\n\n    case 8:\n\n        ret = decompress_68(avctx, flags >> 8, 1);\n\n        break;\n\n    default:\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    memcpy(frame->data[1], gdv->pal, AVPALETTE_SIZE);\n\n    dst = frame->data[0];\n\n\n\n    if (!gdv->scale_v && !gdv->scale_h) {\n\n        int sidx = PREAMBLE_SIZE, didx = 0;\n\n        int y, x;\n\n\n\n        for (y = 0; y < avctx->height; y++) {\n\n            for (x = 0; x < avctx->width; x++) {\n\n                dst[x+didx] = gdv->frame[x+sidx];\n\n            }\n\n            sidx += avctx->width;\n\n            didx += frame->linesize[0];\n\n        }\n\n    } else {\n\n        int sidx = PREAMBLE_SIZE, didx = 0;\n\n        int y, x;\n\n\n\n        for (y = 0; y < avctx->height; y++) {\n\n            if (!gdv->scale_v) {\n\n                for (x = 0; x < avctx->width; x++) {\n\n                    dst[didx + x] = gdv->frame[sidx + x];\n\n                }\n\n            } else {\n\n                for (x = 0; x < avctx->width; x++) {\n\n                    dst[didx + x] = gdv->frame[sidx + x/2];\n\n                }\n\n            }\n\n            if (!gdv->scale_h || ((y & 1) == 1)) {\n\n                sidx += !gdv->scale_v ? avctx->width : avctx->width/2;\n\n            }\n\n            didx += frame->linesize[0];\n\n        }\n\n    }\n\n\n\n    *got_frame = 1;\n\n\n\n    return ret < 0 ? ret : avpkt->size;\n\n}\n", "idx": 26096}
{"project": "FFmpeg", "commit_id": "0afdedcafb4d524abfe2c958f17aafe4f1ab8d9a", "target": 0, "func": "int ff_rle_encode(uint8_t *outbuf, int out_size, const uint8_t *ptr , int bpp, int w,\n\n                  int add_rep, int xor_rep, int add_raw, int xor_raw)\n\n{\n\n    int count, x;\n\n    uint8_t *out = outbuf;\n\n\n\n    for(x = 0; x < w; x += count) {\n\n        /* see if we can encode the next set of pixels with RLE */\n\n        if((count = count_pixels(ptr, w-x, bpp, 1)) > 1) {\n\n            if(out + bpp + 1 > outbuf + out_size) return -1;\n\n            *out++ = (count ^ xor_rep) + add_rep;\n\n            memcpy(out, ptr, bpp);\n\n            out += bpp;\n\n        } else {\n\n            /* fall back on uncompressed */\n\n            count = count_pixels(ptr, w-x, bpp, 0);\n\n            *out++ = (count ^ xor_raw) + add_raw;\n\n\n\n            if(out + bpp*count > outbuf + out_size) return -1;\n\n            memcpy(out, ptr, bpp * count);\n\n            out += bpp * count;\n\n        }\n\n\n\n        ptr += count * bpp;\n\n    }\n\n\n\n    return out - outbuf;\n\n}\n", "idx": 26097}
{"project": "FFmpeg", "commit_id": "4fd07b9366fb2f74b6af0dea8092d6bafa38f131", "target": 0, "func": "static void stream_component_close(VideoState *is, int stream_index)\n\n{\n\n    AVFormatContext *ic = is->ic;\n\n    AVCodecContext *avctx;\n\n\n\n    if (stream_index < 0 || stream_index >= ic->nb_streams)\n\n        return;\n\n    avctx = ic->streams[stream_index]->codec;\n\n\n\n    switch (avctx->codec_type) {\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        packet_queue_abort(&is->audioq);\n\n\n\n        SDL_CloseAudio();\n\n\n\n        packet_queue_flush(&is->audioq);\n\n        av_free_packet(&is->audio_pkt);\n\n        if (is->swr_ctx)\n\n            swr_free(&is->swr_ctx);\n\n        av_freep(&is->audio_buf1);\n\n        is->audio_buf = NULL;\n\n        av_freep(&is->frame);\n\n\n\n        if (is->rdft) {\n\n            av_rdft_end(is->rdft);\n\n            av_freep(&is->rdft_data);\n\n            is->rdft = NULL;\n\n            is->rdft_bits = 0;\n\n        }\n\n        break;\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        packet_queue_abort(&is->videoq);\n\n\n\n        /* note: we also signal this mutex to make sure we deblock the\n\n           video thread in all cases */\n\n        SDL_LockMutex(is->pictq_mutex);\n\n        SDL_CondSignal(is->pictq_cond);\n\n        SDL_UnlockMutex(is->pictq_mutex);\n\n\n\n        SDL_WaitThread(is->video_tid, NULL);\n\n\n\n        packet_queue_flush(&is->videoq);\n\n        break;\n\n    case AVMEDIA_TYPE_SUBTITLE:\n\n        packet_queue_abort(&is->subtitleq);\n\n\n\n        /* note: we also signal this mutex to make sure we deblock the\n\n           video thread in all cases */\n\n        SDL_LockMutex(is->subpq_mutex);\n\n        is->subtitle_stream_changed = 1;\n\n\n\n        SDL_CondSignal(is->subpq_cond);\n\n        SDL_UnlockMutex(is->subpq_mutex);\n\n\n\n        SDL_WaitThread(is->subtitle_tid, NULL);\n\n\n\n        packet_queue_flush(&is->subtitleq);\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n\n\n    ic->streams[stream_index]->discard = AVDISCARD_ALL;\n\n    avcodec_close(avctx);\n\n#if CONFIG_AVFILTER\n\n    free_buffer_pool(&is->buffer_pool);\n\n#endif\n\n    switch (avctx->codec_type) {\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        is->audio_st = NULL;\n\n        is->audio_stream = -1;\n\n        break;\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        is->video_st = NULL;\n\n        is->video_stream = -1;\n\n        break;\n\n    case AVMEDIA_TYPE_SUBTITLE:\n\n        is->subtitle_st = NULL;\n\n        is->subtitle_stream = -1;\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n}\n", "idx": 26098}
{"project": "FFmpeg", "commit_id": "6d93307f8df81808f0dcdbc064b848054a6e83b3", "target": 1, "func": "static inline int mpeg1_decode_block_inter(MpegEncContext *s, int16_t *block, int n)\n\n{\n\n    int level, i, j, run;\n\n    RLTable *rl = &ff_rl_mpeg1;\n\n    uint8_t * const scantable    = s->intra_scantable.permutated;\n\n    const uint16_t *quant_matrix = s->inter_matrix;\n\n    const int qscale             = s->qscale;\n\n\n\n    {\n\n        OPEN_READER(re, &s->gb);\n\n        i = -1;\n\n        // special case for first coefficient, no need to add second VLC table\n\n        UPDATE_CACHE(re, &s->gb);\n\n        if (((int32_t)GET_CACHE(re, &s->gb)) < 0) {\n\n            level = (3 * qscale * quant_matrix[0]) >> 5;\n\n            level = (level - 1) | 1;\n\n            if (GET_CACHE(re, &s->gb) & 0x40000000)\n\n                level = -level;\n\n            block[0] = level;\n\n            i++;\n\n            SKIP_BITS(re, &s->gb, 2);\n\n            if (((int32_t)GET_CACHE(re, &s->gb)) <= (int32_t)0xBFFFFFFF)\n\n                goto end;\n\n        }\n\n        /* now quantify & encode AC coefficients */\n\n        for (;;) {\n\n            GET_RL_VLC(level, run, re, &s->gb, rl->rl_vlc[0], TEX_VLC_BITS, 2, 0);\n\n\n\n            if (level != 0) {\n\n                i += run;\n\n                j = scantable[i];\n\n                level = ((level * 2 + 1) * qscale * quant_matrix[j]) >> 5;\n\n                level = (level - 1) | 1;\n\n                level = (level ^ SHOW_SBITS(re, &s->gb, 1)) - SHOW_SBITS(re, &s->gb, 1);\n\n                SKIP_BITS(re, &s->gb, 1);\n\n            } else {\n\n                /* escape */\n\n                run = SHOW_UBITS(re, &s->gb, 6) + 1; LAST_SKIP_BITS(re, &s->gb, 6);\n\n                UPDATE_CACHE(re, &s->gb);\n\n                level = SHOW_SBITS(re, &s->gb, 8); SKIP_BITS(re, &s->gb, 8);\n\n                if (level == -128) {\n\n                    level = SHOW_UBITS(re, &s->gb, 8) - 256; SKIP_BITS(re, &s->gb, 8);\n\n                } else if (level == 0) {\n\n                    level = SHOW_UBITS(re, &s->gb, 8)      ; SKIP_BITS(re, &s->gb, 8);\n\n                }\n\n                i += run;\n\n                j = scantable[i];\n\n                if (level < 0) {\n\n                    level = -level;\n\n                    level = ((level * 2 + 1) * qscale * quant_matrix[j]) >> 5;\n\n                    level = (level - 1) | 1;\n\n                    level = -level;\n\n                } else {\n\n                    level = ((level * 2 + 1) * qscale * quant_matrix[j]) >> 5;\n\n                    level = (level - 1) | 1;\n\n                }\n\n            }\n\n            if (i > 63) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"ac-tex damaged at %d %d\\n\", s->mb_x, s->mb_y);\n\n                return -1;\n\n            }\n\n\n\n            block[j] = level;\n\n            if (((int32_t)GET_CACHE(re, &s->gb)) <= (int32_t)0xBFFFFFFF)\n\n                break;\n\n            UPDATE_CACHE(re, &s->gb);\n\n        }\n\nend:\n\n        LAST_SKIP_BITS(re, &s->gb, 2);\n\n        CLOSE_READER(re, &s->gb);\n\n    }\n\n    s->block_last_index[n] = i;\n\n    return 0;\n\n}\n", "idx": 26099}
{"project": "FFmpeg", "commit_id": "ac4b32df71bd932838043a4838b86d11e169707f", "target": 1, "func": "int check_tm_pred4x4_mode(int mode, int mb_x, int mb_y)\n\n{\n\n    if (!mb_x) {\n\n        return mb_y ? VERT_VP8_PRED : DC_129_PRED;\n\n    } else {\n\n        return mb_y ? mode : HOR_VP8_PRED;\n\n    }\n\n}\n", "idx": 26100}
{"project": "FFmpeg", "commit_id": "ac4b32df71bd932838043a4838b86d11e169707f", "target": 1, "func": "static void vp8_decode_mv_mb_modes(AVCodecContext *avctx, VP8Frame *curframe,\n\n                                   VP8Frame *prev_frame)\n\n{\n\n    VP8Context *s = avctx->priv_data;\n\n    int mb_x, mb_y;\n\n\n\n    s->mv_min.y = -MARGIN;\n\n    s->mv_max.y = ((s->mb_height - 1) << 6) + MARGIN;\n\n    for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n\n        VP8Macroblock *mb = s->macroblocks_base +\n\n                            ((s->mb_width + 1) * (mb_y + 1) + 1);\n\n        int mb_xy = mb_y * s->mb_width;\n\n\n\n        AV_WN32A(s->intra4x4_pred_mode_left, DC_PRED * 0x01010101);\n\n\n\n        s->mv_min.x = -MARGIN;\n\n        s->mv_max.x = ((s->mb_width - 1) << 6) + MARGIN;\n\n        for (mb_x = 0; mb_x < s->mb_width; mb_x++, mb_xy++, mb++) {\n\n            if (mb_y == 0)\n\n                AV_WN32A((mb - s->mb_width - 1)->intra4x4_pred_mode_top,\n\n                         DC_PRED * 0x01010101);\n\n            decode_mb_mode(s, mb, mb_x, mb_y, curframe->seg_map->data + mb_xy,\n\n                           prev_frame && prev_frame->seg_map ?\n\n                           prev_frame->seg_map->data + mb_xy : NULL, 1);\n\n            s->mv_min.x -= 64;\n\n            s->mv_max.x -= 64;\n\n        }\n\n        s->mv_min.y -= 64;\n\n        s->mv_max.y -= 64;\n\n    }\n\n}\n", "idx": 26101}
{"project": "FFmpeg", "commit_id": "68caef9d48c4f1540b1b3181ebe7062a3417c62a", "target": 1, "func": "static av_always_inline void mc_luma_scaled(VP9Context *s, vp9_scaled_mc_func smc,\n\n                                            vp9_mc_func (*mc)[2],\n\n                                            uint8_t *dst, ptrdiff_t dst_stride,\n\n                                            const uint8_t *ref, ptrdiff_t ref_stride,\n\n                                            ThreadFrame *ref_frame,\n\n                                            ptrdiff_t y, ptrdiff_t x, const VP56mv *in_mv,\n\n                                            int px, int py, int pw, int ph,\n\n                                            int bw, int bh, int w, int h, int bytesperpixel,\n\n                                            const uint16_t *scale, const uint8_t *step)\n\n{\n\n    if (s->s.frames[CUR_FRAME].tf.f->width == ref_frame->f->width &&\n\n        s->s.frames[CUR_FRAME].tf.f->height == ref_frame->f->height) {\n\n        mc_luma_unscaled(s, mc, dst, dst_stride, ref, ref_stride, ref_frame,\n\n                         y, x, in_mv, bw, bh, w, h, bytesperpixel);\n\n    } else {\n\n#define scale_mv(n, dim) (((int64_t)(n) * scale[dim]) >> 14)\n\n    int mx, my;\n\n    int refbw_m1, refbh_m1;\n\n    int th;\n\n    VP56mv mv;\n\n\n\n    mv.x = av_clip(in_mv->x, -(x + pw - px + 4) * 8, (s->cols * 8 - x + px + 3) * 8);\n\n    mv.y = av_clip(in_mv->y, -(y + ph - py + 4) * 8, (s->rows * 8 - y + py + 3) * 8);\n\n    // BUG libvpx seems to scale the two components separately. This introduces\n\n    // rounding errors but we have to reproduce them to be exactly compatible\n\n    // with the output from libvpx...\n\n    mx = scale_mv(mv.x * 2, 0) + scale_mv(x * 16, 0);\n\n    my = scale_mv(mv.y * 2, 1) + scale_mv(y * 16, 1);\n\n\n\n    y = my >> 4;\n\n    x = mx >> 4;\n\n    ref += y * ref_stride + x * bytesperpixel;\n\n    mx &= 15;\n\n    my &= 15;\n\n    refbw_m1 = ((bw - 1) * step[0] + mx) >> 4;\n\n    refbh_m1 = ((bh - 1) * step[1] + my) >> 4;\n\n    // FIXME bilinear filter only needs 0/1 pixels, not 3/4\n\n    // we use +7 because the last 7 pixels of each sbrow can be changed in\n\n    // the longest loopfilter of the next sbrow\n\n    th = (y + refbh_m1 + 4 + 7) >> 6;\n\n    ff_thread_await_progress(ref_frame, FFMAX(th, 0), 0);\n\n    if (x < 3 || y < 3 || x + 4 >= w - refbw_m1 || y + 4 >= h - refbh_m1) {\n\n        s->vdsp.emulated_edge_mc(s->edge_emu_buffer,\n\n                                 ref - 3 * ref_stride - 3 * bytesperpixel,\n\n                                 288, ref_stride,\n\n                                 refbw_m1 + 8, refbh_m1 + 8,\n\n                                 x - 3, y - 3, w, h);\n\n        ref = s->edge_emu_buffer + 3 * 288 + 3 * bytesperpixel;\n\n        ref_stride = 288;\n\n    }\n\n    smc(dst, dst_stride, ref, ref_stride, bh, mx, my, step[0], step[1]);\n\n    }\n\n}\n", "idx": 26105}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "static void vc1_inv_trans_4x4_c(uint8_t *dest, int linesize, DCTELEM *block)\n\n{\n\n    int i;\n\n    register int t1,t2,t3,t4;\n\n    DCTELEM *src, *dst;\n\n    const uint8_t *cm = ff_cropTbl + MAX_NEG_CROP;\n\n\n\n    src = block;\n\n    dst = block;\n\n    for(i = 0; i < 4; i++){\n\n        t1 = 17 * (src[0] + src[2]) + 4;\n\n        t2 = 17 * (src[0] - src[2]) + 4;\n\n        t3 = 22 * src[1] + 10 * src[3];\n\n        t4 = 22 * src[3] - 10 * src[1];\n\n\n\n        dst[0] = (t1 + t3) >> 3;\n\n        dst[1] = (t2 - t4) >> 3;\n\n        dst[2] = (t2 + t4) >> 3;\n\n        dst[3] = (t1 - t3) >> 3;\n\n\n\n        src += 8;\n\n        dst += 8;\n\n    }\n\n\n\n    src = block;\n\n    for(i = 0; i < 4; i++){\n\n        t1 = 17 * (src[ 0] + src[16]) + 64;\n\n        t2 = 17 * (src[ 0] - src[16]) + 64;\n\n        t3 = 22 * src[ 8] + 10 * src[24];\n\n        t4 = 22 * src[24] - 10 * src[ 8];\n\n\n\n        dest[0*linesize] = cm[dest[0*linesize] + ((t1 + t3) >> 7)];\n\n        dest[1*linesize] = cm[dest[1*linesize] + ((t2 - t4) >> 7)];\n\n        dest[2*linesize] = cm[dest[2*linesize] + ((t2 + t4) >> 7)];\n\n        dest[3*linesize] = cm[dest[3*linesize] + ((t1 - t3) >> 7)];\n\n\n\n        src ++;\n\n        dest++;\n\n    }\n\n}\n", "idx": 26106}
{"project": "FFmpeg", "commit_id": "24eac3cff54a5828ba76bc1ad93b99724cde45c1", "target": 1, "func": "int ff_draw_init(FFDrawContext *draw, enum PixelFormat format, unsigned flags)\n\n{\n\n    const AVPixFmtDescriptor *desc = &av_pix_fmt_descriptors[format];\n\n    const AVComponentDescriptor *c;\n\n    unsigned i, nb_planes = 0;\n\n    int pixelstep[MAX_PLANES] = { 0 };\n\n\n\n    if (!desc->name)\n\n        return AVERROR(EINVAL);\n\n    if (desc->flags & ~(PIX_FMT_PLANAR | PIX_FMT_RGB))\n\n        return AVERROR(ENOSYS);\n\n    for (i = 0; i < desc->nb_components; i++) {\n\n        c = &desc->comp[i];\n\n        /* for now, only 8-bits formats */\n\n        if (c->depth_minus1 != 8 - 1)\n\n            return AVERROR(ENOSYS);\n\n        if (c->plane >= MAX_PLANES)\n\n            return AVERROR(ENOSYS);\n\n        /* strange interleaving */\n\n        if (pixelstep[c->plane] != 0 &&\n\n            pixelstep[c->plane] != c->step_minus1 + 1)\n\n            return AVERROR(ENOSYS);\n\n        pixelstep[c->plane] = c->step_minus1 + 1;\n\n        if (pixelstep[c->plane] >= 8)\n\n            return AVERROR(ENOSYS);\n\n        nb_planes = FFMAX(nb_planes, c->plane + 1);\n\n    }\n\n    if ((desc->log2_chroma_w || desc->log2_chroma_h) && nb_planes < 3)\n\n        return AVERROR(ENOSYS); /* exclude NV12 and NV21 */\n\n    memset(draw, 0, sizeof(*draw));\n\n    draw->desc      = desc;\n\n    draw->format    = format;\n\n    draw->nb_planes = nb_planes;\n\n    memcpy(draw->pixelstep, pixelstep, sizeof(draw->pixelstep));\n\n    if (nb_planes >= 3 && !(desc->flags & PIX_FMT_RGB)) {\n\n        draw->hsub[1] = draw->hsub[2] = draw->hsub_max = desc->log2_chroma_w;\n\n        draw->vsub[1] = draw->vsub[2] = draw->vsub_max = desc->log2_chroma_h;\n\n    }\n\n    for (i = 0; i < ((desc->nb_components - 1) | 1); i++)\n\n        draw->comp_mask[desc->comp[i].plane] |=\n\n            1 << (desc->comp[i].offset_plus1 - 1);\n\n    return 0;\n\n}\n", "idx": 26108}
{"project": "FFmpeg", "commit_id": "da34e4e13238b755bb0e6ebf549015797d9b4467", "target": 1, "func": "static struct ResampleContext *create(struct ResampleContext *c, int out_rate, int in_rate, int filter_size, int phase_shift, int linear,\n\n        double cutoff, enum AVSampleFormat format, enum SwrFilterType filter_type, double kaiser_beta, double precision, int cheby, int exact_rational){\n\n    soxr_error_t error;\n\n\n\n    soxr_datatype_t type =\n\n        format == AV_SAMPLE_FMT_S16P? SOXR_INT16_S :\n\n        format == AV_SAMPLE_FMT_S16 ? SOXR_INT16_I :\n\n        format == AV_SAMPLE_FMT_S32P? SOXR_INT32_S :\n\n        format == AV_SAMPLE_FMT_S32 ? SOXR_INT32_I :\n\n        format == AV_SAMPLE_FMT_FLTP? SOXR_FLOAT32_S :\n\n        format == AV_SAMPLE_FMT_FLT ? SOXR_FLOAT32_I :\n\n        format == AV_SAMPLE_FMT_DBLP? SOXR_FLOAT64_S :\n\n        format == AV_SAMPLE_FMT_DBL ? SOXR_FLOAT64_I : (soxr_datatype_t)-1;\n\n\n\n    soxr_io_spec_t io_spec = soxr_io_spec(type, type);\n\n\n\n    soxr_quality_spec_t q_spec = soxr_quality_spec((int)((precision-2)/4), (SOXR_HI_PREC_CLOCK|SOXR_ROLLOFF_NONE)*!!cheby);\n\n    q_spec.precision = linear? 0 : precision;\n\n#if !defined SOXR_VERSION /* Deprecated @ March 2013: */\n\n    q_spec.bw_pc = cutoff? FFMAX(FFMIN(cutoff,.995),.8)*100 : q_spec.bw_pc;\n\n#else\n\n    q_spec.passband_end = cutoff? FFMAX(FFMIN(cutoff,.995),.8) : q_spec.passband_end;\n\n#endif\n\n\n\n    soxr_delete((soxr_t)c);\n\n    c = (struct ResampleContext *)\n\n        soxr_create(in_rate, out_rate, 0, &error, &io_spec, &q_spec, 0);\n\n    if (!c)\n\n        av_log(NULL, AV_LOG_ERROR, \"soxr_create: %s\\n\", error);\n\n    return c;\n\n}\n", "idx": 26110}
{"project": "FFmpeg", "commit_id": "e0c6cce44729d94e2a5507a4b6d031f23e8bd7b6", "target": 0, "func": "av_cold void ff_dct_init_mmx(DCTContext *s)\n\n{\n\n#if HAVE_YASM\n\n    int has_vectors = av_get_cpu_flags();\n\n    if (has_vectors & AV_CPU_FLAG_SSE && HAVE_SSE)\n\n        s->dct32 = ff_dct32_float_sse;\n\n    if (has_vectors & AV_CPU_FLAG_SSE2 && HAVE_SSE)\n\n        s->dct32 = ff_dct32_float_sse2;\n\n    if (has_vectors & AV_CPU_FLAG_AVX && HAVE_AVX)\n\n        s->dct32 = ff_dct32_float_avx;\n\n#endif\n\n}\n", "idx": 26111}
{"project": "FFmpeg", "commit_id": "4a0f6651434c6f213d830140f575b4ec7858519f", "target": 0, "func": "int ff_reget_buffer(AVCodecContext *avctx, AVFrame *frame)\n\n{\n\n    AVFrame *tmp;\n\n    int ret;\n\n\n\n    av_assert0(avctx->codec_type == AVMEDIA_TYPE_VIDEO);\n\n\n\n    if (!frame->data[0])\n\n        return ff_get_buffer(avctx, frame, AV_GET_BUFFER_FLAG_REF);\n\n\n\n    if (av_frame_is_writable(frame)) {\n\n        frame->pkt_pts = avctx->internal->pkt ? avctx->internal->pkt->pts : AV_NOPTS_VALUE;\n\n        frame->reordered_opaque = avctx->reordered_opaque;\n\n        return 0;\n\n    }\n\n\n\n    tmp = av_frame_alloc();\n\n    if (!tmp)\n\n        return AVERROR(ENOMEM);\n\n\n\n    av_frame_move_ref(tmp, frame);\n\n\n\n    ret = ff_get_buffer(avctx, frame, AV_GET_BUFFER_FLAG_REF);\n\n    if (ret < 0) {\n\n        av_frame_free(&tmp);\n\n        return ret;\n\n    }\n\n\n\n    av_frame_copy(frame, tmp);\n\n    av_frame_free(&tmp);\n\n\n\n    return 0;\n\n}\n", "idx": 26112}
{"project": "FFmpeg", "commit_id": "ac9919b9662f28816cf79c1d5c36719160009588", "target": 0, "func": "static void mxf_write_cdci_common(AVFormatContext *s, AVStream *st, const UID key, unsigned size)\n\n{\n\n    MXFStreamContext *sc = st->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int stored_height = (st->codec->height+15)/16*16;\n\n    int display_height;\n\n    int f1, f2;\n\n    unsigned desc_size = size+8+8+8+8+8+8+5+16+sc->interlaced*4+12+20;\n\n    if (sc->interlaced && sc->field_dominance)\n\n        desc_size += 5;\n\n\n\n    mxf_write_generic_desc(s, st, key, desc_size);\n\n\n\n    mxf_write_local_tag(pb, 4, 0x3203);\n\n    avio_wb32(pb, st->codec->width);\n\n\n\n    mxf_write_local_tag(pb, 4, 0x3202);\n\n    avio_wb32(pb, stored_height>>sc->interlaced);\n\n\n\n    mxf_write_local_tag(pb, 4, 0x3209);\n\n    avio_wb32(pb, st->codec->width);\n\n\n\n    if (st->codec->height == 608) // PAL + VBI\n\n        display_height = 576;\n\n    else if (st->codec->height == 512)  // NTSC + VBI\n\n        display_height = 486;\n\n    else\n\n        display_height = st->codec->height;\n\n\n\n    mxf_write_local_tag(pb, 4, 0x3208);\n\n    avio_wb32(pb, display_height>>sc->interlaced);\n\n\n\n    // component depth\n\n    mxf_write_local_tag(pb, 4, 0x3301);\n\n    avio_wb32(pb, sc->component_depth);\n\n\n\n    // horizontal subsampling\n\n    mxf_write_local_tag(pb, 4, 0x3302);\n\n    avio_wb32(pb, 2);\n\n\n\n    // frame layout\n\n    mxf_write_local_tag(pb, 1, 0x320C);\n\n    avio_w8(pb, sc->interlaced);\n\n\n\n    // video line map\n\n    switch (st->codec->height) {\n\n    case  576: f1 = 23; f2 = st->codec->codec_id == AV_CODEC_ID_DVVIDEO ? 335 : 336; break;\n\n    case  608: f1 =  7; f2 = 320; break;\n\n    case  480: f1 = 20; f2 = st->codec->codec_id == AV_CODEC_ID_DVVIDEO ? 285 : 283; break;\n\n    case  512: f1 =  7; f2 = 270; break;\n\n    case  720: f1 = 26; f2 =   0; break; // progressive\n\n    case 1080: f1 = 21; f2 = 584; break;\n\n    default:   f1 =  0; f2 =   0; break;\n\n    }\n\n\n\n    if (!sc->interlaced) {\n\n        f2  = 0;\n\n        f1 *= 2;\n\n    }\n\n\n\n    mxf_write_local_tag(pb, 12+sc->interlaced*4, 0x320D);\n\n    avio_wb32(pb, sc->interlaced ? 2 : 1);\n\n    avio_wb32(pb, 4);\n\n    avio_wb32(pb, f1);\n\n    if (sc->interlaced)\n\n        avio_wb32(pb, f2);\n\n\n\n    mxf_write_local_tag(pb, 8, 0x320E);\n\n    avio_wb32(pb, sc->aspect_ratio.num);\n\n    avio_wb32(pb, sc->aspect_ratio.den);\n\n\n\n    mxf_write_local_tag(pb, 16, 0x3201);\n\n    avio_write(pb, *sc->codec_ul, 16);\n\n\n\n    if (sc->interlaced && sc->field_dominance) {\n\n        mxf_write_local_tag(pb, 1, 0x3212);\n\n        avio_w8(pb, sc->field_dominance);\n\n    }\n\n\n\n}\n", "idx": 26114}
{"project": "FFmpeg", "commit_id": "e6c90ce94f1b07f50cea2babf7471af455cca0ff", "target": 0, "func": "static av_always_inline void h264_filter_mb_fast_internal(H264Context *h,\n\n                                                          H264SliceContext *sl,\n\n                                                          int mb_x, int mb_y,\n\n                                                          uint8_t *img_y,\n\n                                                          uint8_t *img_cb,\n\n                                                          uint8_t *img_cr,\n\n                                                          unsigned int linesize,\n\n                                                          unsigned int uvlinesize,\n\n                                                          int pixel_shift)\n\n{\n\n    int chroma = !(CONFIG_GRAY && (h->flags&CODEC_FLAG_GRAY));\n\n    int chroma444 = CHROMA444(h);\n\n    int chroma422 = CHROMA422(h);\n\n\n\n    int mb_xy = h->mb_xy;\n\n    int left_type = sl->left_type[LTOP];\n\n    int top_type  = sl->top_type;\n\n\n\n    int qp_bd_offset = 6 * (h->sps.bit_depth_luma - 8);\n\n    int a = 52 + h->slice_alpha_c0_offset - qp_bd_offset;\n\n    int b = 52 + h->slice_beta_offset - qp_bd_offset;\n\n\n\n    int mb_type = h->cur_pic.mb_type[mb_xy];\n\n    int qp      = h->cur_pic.qscale_table[mb_xy];\n\n    int qp0     = h->cur_pic.qscale_table[mb_xy - 1];\n\n    int qp1     = h->cur_pic.qscale_table[sl->top_mb_xy];\n\n    int qpc = get_chroma_qp( h, 0, qp );\n\n    int qpc0 = get_chroma_qp( h, 0, qp0 );\n\n    int qpc1 = get_chroma_qp( h, 0, qp1 );\n\n    qp0 = (qp + qp0 + 1) >> 1;\n\n    qp1 = (qp + qp1 + 1) >> 1;\n\n    qpc0 = (qpc + qpc0 + 1) >> 1;\n\n    qpc1 = (qpc + qpc1 + 1) >> 1;\n\n\n\n    if( IS_INTRA(mb_type) ) {\n\n        static const int16_t bS4[4] = {4,4,4,4};\n\n        static const int16_t bS3[4] = {3,3,3,3};\n\n        const int16_t *bSH = FIELD_PICTURE(h) ? bS3 : bS4;\n\n        if(left_type)\n\n            filter_mb_edgev( &img_y[4*0<<pixel_shift], linesize, bS4, qp0, a, b, h, 1);\n\n        if( IS_8x8DCT(mb_type) ) {\n\n            filter_mb_edgev( &img_y[4*2<<pixel_shift], linesize, bS3, qp, a, b, h, 0);\n\n            if(top_type){\n\n                filter_mb_edgeh( &img_y[4*0*linesize], linesize, bSH, qp1, a, b, h, 1);\n\n            }\n\n            filter_mb_edgeh( &img_y[4*2*linesize], linesize, bS3, qp, a, b, h, 0);\n\n        } else {\n\n            filter_mb_edgev( &img_y[4*1<<pixel_shift], linesize, bS3, qp, a, b, h, 0);\n\n            filter_mb_edgev( &img_y[4*2<<pixel_shift], linesize, bS3, qp, a, b, h, 0);\n\n            filter_mb_edgev( &img_y[4*3<<pixel_shift], linesize, bS3, qp, a, b, h, 0);\n\n            if(top_type){\n\n                filter_mb_edgeh( &img_y[4*0*linesize], linesize, bSH, qp1, a, b, h, 1);\n\n            }\n\n            filter_mb_edgeh( &img_y[4*1*linesize], linesize, bS3, qp, a, b, h, 0);\n\n            filter_mb_edgeh( &img_y[4*2*linesize], linesize, bS3, qp, a, b, h, 0);\n\n            filter_mb_edgeh( &img_y[4*3*linesize], linesize, bS3, qp, a, b, h, 0);\n\n        }\n\n        if(chroma){\n\n            if(chroma444){\n\n                if(left_type){\n\n                    filter_mb_edgev( &img_cb[4*0<<pixel_shift], linesize, bS4, qpc0, a, b, h, 1);\n\n                    filter_mb_edgev( &img_cr[4*0<<pixel_shift], linesize, bS4, qpc0, a, b, h, 1);\n\n                }\n\n                if( IS_8x8DCT(mb_type) ) {\n\n                    filter_mb_edgev( &img_cb[4*2<<pixel_shift], linesize, bS3, qpc, a, b, h, 0);\n\n                    filter_mb_edgev( &img_cr[4*2<<pixel_shift], linesize, bS3, qpc, a, b, h, 0);\n\n                    if(top_type){\n\n                        filter_mb_edgeh( &img_cb[4*0*linesize], linesize, bSH, qpc1, a, b, h, 1 );\n\n                        filter_mb_edgeh( &img_cr[4*0*linesize], linesize, bSH, qpc1, a, b, h, 1 );\n\n                    }\n\n                    filter_mb_edgeh( &img_cb[4*2*linesize], linesize, bS3, qpc, a, b, h, 0);\n\n                    filter_mb_edgeh( &img_cr[4*2*linesize], linesize, bS3, qpc, a, b, h, 0);\n\n                } else {\n\n                    filter_mb_edgev( &img_cb[4*1<<pixel_shift], linesize, bS3, qpc, a, b, h, 0);\n\n                    filter_mb_edgev( &img_cr[4*1<<pixel_shift], linesize, bS3, qpc, a, b, h, 0);\n\n                    filter_mb_edgev( &img_cb[4*2<<pixel_shift], linesize, bS3, qpc, a, b, h, 0);\n\n                    filter_mb_edgev( &img_cr[4*2<<pixel_shift], linesize, bS3, qpc, a, b, h, 0);\n\n                    filter_mb_edgev( &img_cb[4*3<<pixel_shift], linesize, bS3, qpc, a, b, h, 0);\n\n                    filter_mb_edgev( &img_cr[4*3<<pixel_shift], linesize, bS3, qpc, a, b, h, 0);\n\n                    if(top_type){\n\n                        filter_mb_edgeh( &img_cb[4*0*linesize], linesize, bSH, qpc1, a, b, h, 1);\n\n                        filter_mb_edgeh( &img_cr[4*0*linesize], linesize, bSH, qpc1, a, b, h, 1);\n\n                    }\n\n                    filter_mb_edgeh( &img_cb[4*1*linesize], linesize, bS3, qpc, a, b, h, 0);\n\n                    filter_mb_edgeh( &img_cr[4*1*linesize], linesize, bS3, qpc, a, b, h, 0);\n\n                    filter_mb_edgeh( &img_cb[4*2*linesize], linesize, bS3, qpc, a, b, h, 0);\n\n                    filter_mb_edgeh( &img_cr[4*2*linesize], linesize, bS3, qpc, a, b, h, 0);\n\n                    filter_mb_edgeh( &img_cb[4*3*linesize], linesize, bS3, qpc, a, b, h, 0);\n\n                    filter_mb_edgeh( &img_cr[4*3*linesize], linesize, bS3, qpc, a, b, h, 0);\n\n                }\n\n            }else if(chroma422){\n\n                if(left_type){\n\n                    filter_mb_edgecv(&img_cb[2*0<<pixel_shift], uvlinesize, bS4, qpc0, a, b, h, 1);\n\n                    filter_mb_edgecv(&img_cr[2*0<<pixel_shift], uvlinesize, bS4, qpc0, a, b, h, 1);\n\n                }\n\n                filter_mb_edgecv(&img_cb[2*2<<pixel_shift], uvlinesize, bS3, qpc, a, b, h, 0);\n\n                filter_mb_edgecv(&img_cr[2*2<<pixel_shift], uvlinesize, bS3, qpc, a, b, h, 0);\n\n                if(top_type){\n\n                    filter_mb_edgech(&img_cb[4*0*uvlinesize], uvlinesize, bSH, qpc1, a, b, h, 1);\n\n                    filter_mb_edgech(&img_cr[4*0*uvlinesize], uvlinesize, bSH, qpc1, a, b, h, 1);\n\n                }\n\n                filter_mb_edgech(&img_cb[4*1*uvlinesize], uvlinesize, bS3, qpc, a, b, h, 0);\n\n                filter_mb_edgech(&img_cr[4*1*uvlinesize], uvlinesize, bS3, qpc, a, b, h, 0);\n\n                filter_mb_edgech(&img_cb[4*2*uvlinesize], uvlinesize, bS3, qpc, a, b, h, 0);\n\n                filter_mb_edgech(&img_cr[4*2*uvlinesize], uvlinesize, bS3, qpc, a, b, h, 0);\n\n                filter_mb_edgech(&img_cb[4*3*uvlinesize], uvlinesize, bS3, qpc, a, b, h, 0);\n\n                filter_mb_edgech(&img_cr[4*3*uvlinesize], uvlinesize, bS3, qpc, a, b, h, 0);\n\n            }else{\n\n                if(left_type){\n\n                    filter_mb_edgecv( &img_cb[2*0<<pixel_shift], uvlinesize, bS4, qpc0, a, b, h, 1);\n\n                    filter_mb_edgecv( &img_cr[2*0<<pixel_shift], uvlinesize, bS4, qpc0, a, b, h, 1);\n\n                }\n\n                filter_mb_edgecv( &img_cb[2*2<<pixel_shift], uvlinesize, bS3, qpc, a, b, h, 0);\n\n                filter_mb_edgecv( &img_cr[2*2<<pixel_shift], uvlinesize, bS3, qpc, a, b, h, 0);\n\n                if(top_type){\n\n                    filter_mb_edgech( &img_cb[2*0*uvlinesize], uvlinesize, bSH, qpc1, a, b, h, 1);\n\n                    filter_mb_edgech( &img_cr[2*0*uvlinesize], uvlinesize, bSH, qpc1, a, b, h, 1);\n\n                }\n\n                filter_mb_edgech( &img_cb[2*2*uvlinesize], uvlinesize, bS3, qpc, a, b, h, 0);\n\n                filter_mb_edgech( &img_cr[2*2*uvlinesize], uvlinesize, bS3, qpc, a, b, h, 0);\n\n            }\n\n        }\n\n        return;\n\n    } else {\n\n        LOCAL_ALIGNED_8(int16_t, bS, [2], [4][4]);\n\n        int edges;\n\n        if( IS_8x8DCT(mb_type) && (sl->cbp&7) == 7 && !chroma444 ) {\n\n            edges = 4;\n\n            AV_WN64A(bS[0][0], 0x0002000200020002ULL);\n\n            AV_WN64A(bS[0][2], 0x0002000200020002ULL);\n\n            AV_WN64A(bS[1][0], 0x0002000200020002ULL);\n\n            AV_WN64A(bS[1][2], 0x0002000200020002ULL);\n\n        } else {\n\n            int mask_edge1 = (3*(((5*mb_type)>>5)&1)) | (mb_type>>4); //(mb_type & (MB_TYPE_16x16 | MB_TYPE_8x16)) ? 3 : (mb_type & MB_TYPE_16x8) ? 1 : 0;\n\n            int mask_edge0 = 3*((mask_edge1>>1) & ((5*left_type)>>5)&1); // (mb_type & (MB_TYPE_16x16 | MB_TYPE_8x16)) && (h->left_type[LTOP] & (MB_TYPE_16x16 | MB_TYPE_8x16)) ? 3 : 0;\n\n            int step =  1+(mb_type>>24); //IS_8x8DCT(mb_type) ? 2 : 1;\n\n            edges = 4 - 3*((mb_type>>3) & !(sl->cbp & 15)); //(mb_type & MB_TYPE_16x16) && !(h->cbp & 15) ? 1 : 4;\n\n            h->h264dsp.h264_loop_filter_strength(bS, sl->non_zero_count_cache, sl->ref_cache, sl->mv_cache,\n\n                                                 sl->list_count==2, edges, step, mask_edge0, mask_edge1, FIELD_PICTURE(h));\n\n        }\n\n        if( IS_INTRA(left_type) )\n\n            AV_WN64A(bS[0][0], 0x0004000400040004ULL);\n\n        if( IS_INTRA(top_type) )\n\n            AV_WN64A(bS[1][0], FIELD_PICTURE(h) ? 0x0003000300030003ULL : 0x0004000400040004ULL);\n\n\n\n#define FILTER(hv,dir,edge,intra)\\\n\n        if(AV_RN64A(bS[dir][edge])) {                                   \\\n\n            filter_mb_edge##hv( &img_y[4*edge*(dir?linesize:1<<pixel_shift)], linesize, bS[dir][edge], edge ? qp : qp##dir, a, b, h, intra );\\\n\n            if(chroma){\\\n\n                if(chroma444){\\\n\n                    filter_mb_edge##hv( &img_cb[4*edge*(dir?linesize:1<<pixel_shift)], linesize, bS[dir][edge], edge ? qpc : qpc##dir, a, b, h, intra );\\\n\n                    filter_mb_edge##hv( &img_cr[4*edge*(dir?linesize:1<<pixel_shift)], linesize, bS[dir][edge], edge ? qpc : qpc##dir, a, b, h, intra );\\\n\n                } else if(!(edge&1)) {\\\n\n                    filter_mb_edgec##hv( &img_cb[2*edge*(dir?uvlinesize:1<<pixel_shift)], uvlinesize, bS[dir][edge], edge ? qpc : qpc##dir, a, b, h, intra );\\\n\n                    filter_mb_edgec##hv( &img_cr[2*edge*(dir?uvlinesize:1<<pixel_shift)], uvlinesize, bS[dir][edge], edge ? qpc : qpc##dir, a, b, h, intra );\\\n\n                }\\\n\n            }\\\n\n        }\n\n        if(left_type)\n\n            FILTER(v,0,0,1);\n\n        if( edges == 1 ) {\n\n            if(top_type)\n\n                FILTER(h,1,0,1);\n\n        } else if( IS_8x8DCT(mb_type) ) {\n\n            FILTER(v,0,2,0);\n\n            if(top_type)\n\n                FILTER(h,1,0,1);\n\n            FILTER(h,1,2,0);\n\n        } else {\n\n            FILTER(v,0,1,0);\n\n            FILTER(v,0,2,0);\n\n            FILTER(v,0,3,0);\n\n            if(top_type)\n\n                FILTER(h,1,0,1);\n\n            FILTER(h,1,1,0);\n\n            FILTER(h,1,2,0);\n\n            FILTER(h,1,3,0);\n\n        }\n\n#undef FILTER\n\n    }\n\n}\n", "idx": 26125}
{"project": "FFmpeg", "commit_id": "3c4add27f7513f435e9daa03643fd992d5f6bcee", "target": 1, "func": "static int mpc7_decode_frame(AVCodecContext * avctx, void *data,\n\n                             int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    MPCContext *c = avctx->priv_data;\n\n    GetBitContext gb;\n\n    uint8_t *bits;\n\n    int i, ch;\n\n    int mb = -1;\n\n    Band *bands = c->bands;\n\n    int off, ret;\n\n    int bits_used, bits_avail;\n\n\n\n    memset(bands, 0, sizeof(*bands) * (c->maxbands + 1));\n\n    if(buf_size <= 4){\n\n        av_log(avctx, AV_LOG_ERROR, \"Too small buffer passed (%i bytes)\\n\", buf_size);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    /* get output buffer */\n\n    c->frame.nb_samples = buf[1] ? c->lastframelen : MPC_FRAME_SIZE;\n\n    if ((ret = avctx->get_buffer(avctx, &c->frame)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n\n\n    bits = av_malloc(((buf_size - 1) & ~3) + FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n    c->dsp.bswap_buf((uint32_t*)bits, (const uint32_t*)(buf + 4), (buf_size - 4) >> 2);\n\n    init_get_bits(&gb, bits, (buf_size - 4)* 8);\n\n    skip_bits_long(&gb, buf[0]);\n\n\n\n    /* read subband indexes */\n\n    for(i = 0; i <= c->maxbands; i++){\n\n        for(ch = 0; ch < 2; ch++){\n\n            int t = 4;\n\n            if(i) t = get_vlc2(&gb, hdr_vlc.table, MPC7_HDR_BITS, 1) - 5;\n\n            if(t == 4) bands[i].res[ch] = get_bits(&gb, 4);\n\n            else bands[i].res[ch] = bands[i-1].res[ch] + t;\n\n        }\n\n\n\n        if(bands[i].res[0] || bands[i].res[1]){\n\n            mb = i;\n\n            if(c->MSS) bands[i].msf = get_bits1(&gb);\n\n        }\n\n    }\n\n    /* get scale indexes coding method */\n\n    for(i = 0; i <= mb; i++)\n\n        for(ch = 0; ch < 2; ch++)\n\n            if(bands[i].res[ch]) bands[i].scfi[ch] = get_vlc2(&gb, scfi_vlc.table, MPC7_SCFI_BITS, 1);\n\n    /* get scale indexes */\n\n    for(i = 0; i <= mb; i++){\n\n        for(ch = 0; ch < 2; ch++){\n\n            if(bands[i].res[ch]){\n\n                bands[i].scf_idx[ch][2] = c->oldDSCF[ch][i];\n\n                bands[i].scf_idx[ch][0] = get_scale_idx(&gb, bands[i].scf_idx[ch][2]);\n\n                switch(bands[i].scfi[ch]){\n\n                case 0:\n\n                    bands[i].scf_idx[ch][1] = get_scale_idx(&gb, bands[i].scf_idx[ch][0]);\n\n                    bands[i].scf_idx[ch][2] = get_scale_idx(&gb, bands[i].scf_idx[ch][1]);\n\n                    break;\n\n                case 1:\n\n                    bands[i].scf_idx[ch][1] = get_scale_idx(&gb, bands[i].scf_idx[ch][0]);\n\n                    bands[i].scf_idx[ch][2] = bands[i].scf_idx[ch][1];\n\n                    break;\n\n                case 2:\n\n                    bands[i].scf_idx[ch][1] = bands[i].scf_idx[ch][0];\n\n                    bands[i].scf_idx[ch][2] = get_scale_idx(&gb, bands[i].scf_idx[ch][1]);\n\n                    break;\n\n                case 3:\n\n                    bands[i].scf_idx[ch][2] = bands[i].scf_idx[ch][1] = bands[i].scf_idx[ch][0];\n\n                    break;\n\n                }\n\n                c->oldDSCF[ch][i] = bands[i].scf_idx[ch][2];\n\n            }\n\n        }\n\n    }\n\n    /* get quantizers */\n\n    memset(c->Q, 0, sizeof(c->Q));\n\n    off = 0;\n\n    for(i = 0; i < BANDS; i++, off += SAMPLES_PER_BAND)\n\n        for(ch = 0; ch < 2; ch++)\n\n            idx_to_quant(c, &gb, bands[i].res[ch], c->Q[ch] + off);\n\n\n\n    ff_mpc_dequantize_and_synth(c, mb, c->frame.data[0], 2);\n\n\n\n    av_free(bits);\n\n\n\n    bits_used = get_bits_count(&gb);\n\n    bits_avail = (buf_size - 4) * 8;\n\n    if(!buf[1] && ((bits_avail < bits_used) || (bits_used + 32 <= bits_avail))){\n\n        av_log(NULL,0, \"Error decoding frame: used %i of %i bits\\n\", bits_used, bits_avail);\n\n        return -1;\n\n    }\n\n    if(c->frames_to_skip){\n\n        c->frames_to_skip--;\n\n        *got_frame_ptr = 0;\n\n        return buf_size;\n\n    }\n\n\n\n    *got_frame_ptr   = 1;\n\n    *(AVFrame *)data = c->frame;\n\n\n\n    return buf_size;\n\n}", "idx": 26133}
{"project": "FFmpeg", "commit_id": "224bb46fb857dab589597bdab302ba8ba012008c", "target": 1, "func": "uint8_t* ff_AMediaCodec_getOutputBuffer(FFAMediaCodec* codec, size_t idx, size_t *out_size)\n\n{\n\n    uint8_t *ret = NULL;\n\n    JNIEnv *env = NULL;\n\n\n\n    jobject buffer = NULL;\n\n\n\n    JNI_GET_ENV_OR_RETURN(env, codec, NULL);\n\n\n\n    if (codec->has_get_i_o_buffer) {\n\n        buffer = (*env)->CallObjectMethod(env, codec->object, codec->jfields.get_output_buffer_id, idx);\n\n        if (ff_jni_exception_check(env, 1, codec) < 0) {\n\n            goto fail;\n\n        }\n\n    } else {\n\n        if (!codec->output_buffers) {\n\n            codec->output_buffers = (*env)->CallObjectMethod(env, codec->object, codec->jfields.get_output_buffers_id);\n\n            if (ff_jni_exception_check(env, 1, codec) < 0) {\n\n                goto fail;\n\n            }\n\n\n\n            codec->output_buffers = (*env)->NewGlobalRef(env, codec->output_buffers);\n\n            if (ff_jni_exception_check(env, 1, codec) < 0) {\n\n                goto fail;\n\n            }\n\n        }\n\n\n\n        buffer = (*env)->GetObjectArrayElement(env, codec->output_buffers, idx);\n\n        if (ff_jni_exception_check(env, 1, codec) < 0) {\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n    ret = (*env)->GetDirectBufferAddress(env, buffer);\n\n    *out_size = (*env)->GetDirectBufferCapacity(env, buffer);\n\nfail:\n\n    if (buffer) {\n\n        (*env)->DeleteLocalRef(env, buffer);\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 26135}
{"project": "FFmpeg", "commit_id": "dfbb5de172b3a0373cbead8a966c41f5ba1ae08b", "target": 1, "func": "static int try_decode_video_frame(AVCodecContext *codec_ctx, AVPacket *pkt, int decode)\n\n{\n\n    int ret = 0;\n\n    int got_frame = 0;\n\n    AVFrame *frame = NULL;\n\n    int skip_frame = codec_ctx->skip_frame;\n\n\n\n    if (!avcodec_is_open(codec_ctx)) {\n\n        const AVCodec *codec = avcodec_find_decoder(codec_ctx->codec_id);\n\n\n\n        ret = avcodec_open2(codec_ctx, codec, NULL);\n\n        if (ret < 0) {\n\n            av_log(codec_ctx, AV_LOG_ERROR, \"Failed to open codec\\n\");\n\n            goto end;\n\n        }\n\n    }\n\n\n\n    frame = av_frame_alloc();\n\n    if (!frame) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Failed to allocate frame\\n\");\n\n        goto end;\n\n    }\n\n\n\n    if (!decode && codec_ctx->codec->caps_internal & FF_CODEC_CAP_SKIP_FRAME_FILL_PARAM) {\n\n        codec_ctx->skip_frame = AVDISCARD_ALL;\n\n    }\n\n\n\n    do {\n\n        ret = avcodec_decode_video2(codec_ctx, frame, &got_frame, pkt);\n\n        av_assert0(decode || (!decode && !got_frame));\n\n        if (ret < 0)\n\n            break;\n\n        pkt->data += ret;\n\n        pkt->size -= ret;\n\n\n\n        if (got_frame) {\n\n            break;\n\n        }\n\n    } while (pkt->size > 0);\n\n\n\nend:\n\n    codec_ctx->skip_frame = skip_frame;\n\n\n\n    av_frame_free(&frame);\n\n    return ret;\n\n}\n", "idx": 26138}
{"project": "FFmpeg", "commit_id": "e1c0cfaa419aa5d320540d5a1b3f8fd9b82ab7e5", "target": 0, "func": "static int tiff_decode_tag(TiffContext *s, AVFrame *frame)\n\n{\n\n    unsigned tag, type, count, off, value = 0, value2 = 0;\n\n    int i, start;\n\n    int pos;\n\n    int ret;\n\n    double *dp;\n\n\n\n    ret = ff_tread_tag(&s->gb, s->le, &tag, &type, &count, &start);\n\n    if (ret < 0) {\n\n        goto end;\n\n    }\n\n\n\n    off = bytestream2_tell(&s->gb);\n\n    if (count == 1) {\n\n        switch (type) {\n\n        case TIFF_BYTE:\n\n        case TIFF_SHORT:\n\n        case TIFF_LONG:\n\n            value = ff_tget(&s->gb, type, s->le);\n\n            break;\n\n        case TIFF_RATIONAL:\n\n            value  = ff_tget(&s->gb, TIFF_LONG, s->le);\n\n            value2 = ff_tget(&s->gb, TIFF_LONG, s->le);\n\n            break;\n\n        case TIFF_STRING:\n\n            if (count <= 4) {\n\n                break;\n\n            }\n\n        default:\n\n            value = UINT_MAX;\n\n        }\n\n    }\n\n\n\n    switch (tag) {\n\n    case TIFF_WIDTH:\n\n        s->width = value;\n\n        break;\n\n    case TIFF_HEIGHT:\n\n        s->height = value;\n\n        break;\n\n    case TIFF_BPP:\n\n        s->bppcount = count;\n\n        if (count > 4) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"This format is not supported (bpp=%d, %d components)\\n\",\n\n                   s->bpp, count);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (count == 1)\n\n            s->bpp = value;\n\n        else {\n\n            switch (type) {\n\n            case TIFF_BYTE:\n\n            case TIFF_SHORT:\n\n            case TIFF_LONG:\n\n                s->bpp = 0;\n\n                if (bytestream2_get_bytes_left(&s->gb) < type_sizes[type] * count)\n\n                    return AVERROR_INVALIDDATA;\n\n                for (i = 0; i < count; i++)\n\n                    s->bpp += ff_tget(&s->gb, type, s->le);\n\n                break;\n\n            default:\n\n                s->bpp = -1;\n\n            }\n\n        }\n\n        break;\n\n    case TIFF_SAMPLES_PER_PIXEL:\n\n        if (count != 1) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Samples per pixel requires a single value, many provided\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (value > 4U) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Samples per pixel %d is too large\\n\", value);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (s->bppcount == 1)\n\n            s->bpp *= value;\n\n        s->bppcount = value;\n\n        break;\n\n    case TIFF_COMPR:\n\n        s->compr     = value;\n\n        s->predictor = 0;\n\n        switch (s->compr) {\n\n        case TIFF_RAW:\n\n        case TIFF_PACKBITS:\n\n        case TIFF_LZW:\n\n        case TIFF_CCITT_RLE:\n\n            break;\n\n        case TIFF_G3:\n\n        case TIFF_G4:\n\n            s->fax_opts = 0;\n\n            break;\n\n        case TIFF_DEFLATE:\n\n        case TIFF_ADOBE_DEFLATE:\n\n#if CONFIG_ZLIB\n\n            break;\n\n#else\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Deflate: ZLib not compiled in\\n\");\n\n            return AVERROR(ENOSYS);\n\n#endif\n\n        case TIFF_JPEG:\n\n        case TIFF_NEWJPEG:\n\n            avpriv_report_missing_feature(s->avctx, \"JPEG compression\");\n\n            return AVERROR_PATCHWELCOME;\n\n        case TIFF_LZMA:\n\n#if CONFIG_LZMA\n\n            break;\n\n#else\n\n            av_log(s->avctx, AV_LOG_ERROR, \"LZMA not compiled in\\n\");\n\n            return AVERROR(ENOSYS);\n\n#endif\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Unknown compression method %i\\n\",\n\n                   s->compr);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        break;\n\n    case TIFF_ROWSPERSTRIP:\n\n        if (!value || (type == TIFF_LONG && value == UINT_MAX))\n\n            value = s->height;\n\n        s->rps = FFMIN(value, s->height);\n\n        break;\n\n    case TIFF_STRIP_OFFS:\n\n        if (count == 1) {\n\n            s->strippos = 0;\n\n            s->stripoff = value;\n\n        } else\n\n            s->strippos = off;\n\n        s->strips = count;\n\n        if (s->strips == 1)\n\n            s->rps = s->height;\n\n        s->sot = type;\n\n        break;\n\n    case TIFF_STRIP_SIZE:\n\n        if (count == 1) {\n\n            s->stripsizesoff = 0;\n\n            s->stripsize     = value;\n\n            s->strips        = 1;\n\n        } else {\n\n            s->stripsizesoff = off;\n\n        }\n\n        s->strips = count;\n\n        s->sstype = type;\n\n        break;\n\n    case TIFF_XRES:\n\n    case TIFF_YRES:\n\n        set_sar(s, tag, value, value2);\n\n        break;\n\n    case TIFF_TILE_BYTE_COUNTS:\n\n    case TIFF_TILE_LENGTH:\n\n    case TIFF_TILE_OFFSETS:\n\n    case TIFF_TILE_WIDTH:\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Tiled images are not supported\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n        break;\n\n    case TIFF_PREDICTOR:\n\n        s->predictor = value;\n\n        break;\n\n    case TIFF_PHOTOMETRIC:\n\n        switch (value) {\n\n        case TIFF_PHOTOMETRIC_WHITE_IS_ZERO:\n\n        case TIFF_PHOTOMETRIC_BLACK_IS_ZERO:\n\n        case TIFF_PHOTOMETRIC_RGB:\n\n        case TIFF_PHOTOMETRIC_PALETTE:\n\n        case TIFF_PHOTOMETRIC_YCBCR:\n\n            s->photometric = value;\n\n            break;\n\n        case TIFF_PHOTOMETRIC_ALPHA_MASK:\n\n        case TIFF_PHOTOMETRIC_SEPARATED:\n\n        case TIFF_PHOTOMETRIC_CIE_LAB:\n\n        case TIFF_PHOTOMETRIC_ICC_LAB:\n\n        case TIFF_PHOTOMETRIC_ITU_LAB:\n\n        case TIFF_PHOTOMETRIC_CFA:\n\n        case TIFF_PHOTOMETRIC_LOG_L:\n\n        case TIFF_PHOTOMETRIC_LOG_LUV:\n\n        case TIFF_PHOTOMETRIC_LINEAR_RAW:\n\n            avpriv_report_missing_feature(s->avctx,\n\n                                          \"PhotometricInterpretation 0x%04X\",\n\n                                          value);\n\n            return AVERROR_PATCHWELCOME;\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"PhotometricInterpretation %u is \"\n\n                   \"unknown\\n\", value);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        break;\n\n    case TIFF_FILL_ORDER:\n\n        if (value < 1 || value > 2) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Unknown FillOrder value %d, trying default one\\n\", value);\n\n            value = 1;\n\n        }\n\n        s->fill_order = value - 1;\n\n        break;\n\n    case TIFF_PAL: {\n\n        GetByteContext pal_gb[3];\n\n        off = type_sizes[type];\n\n        if (count / 3 > 256 ||\n\n            bytestream2_get_bytes_left(&s->gb) < count / 3 * off * 3)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        pal_gb[0] = pal_gb[1] = pal_gb[2] = s->gb;\n\n        bytestream2_skip(&pal_gb[1], count / 3 * off);\n\n        bytestream2_skip(&pal_gb[2], count / 3 * off * 2);\n\n\n\n        off = (type_sizes[type] - 1) << 3;\n\n        for (i = 0; i < count / 3; i++) {\n\n            uint32_t p = 0xFF000000;\n\n            p |= (ff_tget(&pal_gb[0], type, s->le) >> off) << 16;\n\n            p |= (ff_tget(&pal_gb[1], type, s->le) >> off) << 8;\n\n            p |=  ff_tget(&pal_gb[2], type, s->le) >> off;\n\n            s->palette[i] = p;\n\n        }\n\n        s->palette_is_set = 1;\n\n        break;\n\n    }\n\n    case TIFF_PLANAR:\n\n        s->planar = value == 2;\n\n        break;\n\n    case TIFF_YCBCR_SUBSAMPLING:\n\n        if (count != 2) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"subsample count invalid\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        for (i = 0; i < count; i++)\n\n            s->subsampling[i] = ff_tget(&s->gb, type, s->le);\n\n        break;\n\n    case TIFF_T4OPTIONS:\n\n        if (s->compr == TIFF_G3)\n\n            s->fax_opts = value;\n\n        break;\n\n    case TIFF_T6OPTIONS:\n\n        if (s->compr == TIFF_G4)\n\n            s->fax_opts = value;\n\n        break;\n\n#define ADD_METADATA(count, name, sep)\\\n\n    if ((ret = add_metadata(count, type, name, sep, s, frame)) < 0) {\\\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\\\n\n        goto end;\\\n\n    }\n\n    case TIFF_MODEL_PIXEL_SCALE:\n\n        ADD_METADATA(count, \"ModelPixelScaleTag\", NULL);\n\n        break;\n\n    case TIFF_MODEL_TRANSFORMATION:\n\n        ADD_METADATA(count, \"ModelTransformationTag\", NULL);\n\n        break;\n\n    case TIFF_MODEL_TIEPOINT:\n\n        ADD_METADATA(count, \"ModelTiepointTag\", NULL);\n\n        break;\n\n    case TIFF_GEO_KEY_DIRECTORY:\n\n        ADD_METADATA(1, \"GeoTIFF_Version\", NULL);\n\n        ADD_METADATA(2, \"GeoTIFF_Key_Revision\", \".\");\n\n        s->geotag_count   = ff_tget_short(&s->gb, s->le);\n\n        if (s->geotag_count > count / 4 - 1) {\n\n            s->geotag_count = count / 4 - 1;\n\n            av_log(s->avctx, AV_LOG_WARNING, \"GeoTIFF key directory buffer shorter than specified\\n\");\n\n        }\n\n        if (bytestream2_get_bytes_left(&s->gb) < s->geotag_count * sizeof(int16_t) * 4) {\n\n            s->geotag_count = 0;\n\n            return -1;\n\n        }\n\n        s->geotags = av_mallocz_array(s->geotag_count, sizeof(TiffGeoTag));\n\n        if (!s->geotags) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n            s->geotag_count = 0;\n\n            goto end;\n\n        }\n\n        for (i = 0; i < s->geotag_count; i++) {\n\n            s->geotags[i].key    = ff_tget_short(&s->gb, s->le);\n\n            s->geotags[i].type   = ff_tget_short(&s->gb, s->le);\n\n            s->geotags[i].count  = ff_tget_short(&s->gb, s->le);\n\n\n\n            if (!s->geotags[i].type)\n\n                s->geotags[i].val  = get_geokey_val(s->geotags[i].key, ff_tget_short(&s->gb, s->le));\n\n            else\n\n                s->geotags[i].offset = ff_tget_short(&s->gb, s->le);\n\n        }\n\n        break;\n\n    case TIFF_GEO_DOUBLE_PARAMS:\n\n        if (count >= INT_MAX / sizeof(int64_t))\n\n            return AVERROR_INVALIDDATA;\n\n        if (bytestream2_get_bytes_left(&s->gb) < count * sizeof(int64_t))\n\n            return AVERROR_INVALIDDATA;\n\n        dp = av_malloc_array(count, sizeof(double));\n\n        if (!dp) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n            goto end;\n\n        }\n\n        for (i = 0; i < count; i++)\n\n            dp[i] = ff_tget_double(&s->gb, s->le);\n\n        for (i = 0; i < s->geotag_count; i++) {\n\n            if (s->geotags[i].type == TIFF_GEO_DOUBLE_PARAMS) {\n\n                if (s->geotags[i].count == 0\n\n                    || s->geotags[i].offset + s->geotags[i].count > count) {\n\n                    av_log(s->avctx, AV_LOG_WARNING, \"Invalid GeoTIFF key %d\\n\", s->geotags[i].key);\n\n                } else {\n\n                    char *ap = doubles2str(&dp[s->geotags[i].offset], s->geotags[i].count, \", \");\n\n                    if (!ap) {\n\n                        av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n                        av_freep(&dp);\n\n                        return AVERROR(ENOMEM);\n\n                    }\n\n                    s->geotags[i].val = ap;\n\n                }\n\n            }\n\n        }\n\n        av_freep(&dp);\n\n        break;\n\n    case TIFF_GEO_ASCII_PARAMS:\n\n        pos = bytestream2_tell(&s->gb);\n\n        for (i = 0; i < s->geotag_count; i++) {\n\n            if (s->geotags[i].type == TIFF_GEO_ASCII_PARAMS) {\n\n                if (s->geotags[i].count == 0\n\n                    || s->geotags[i].offset +  s->geotags[i].count > count) {\n\n                    av_log(s->avctx, AV_LOG_WARNING, \"Invalid GeoTIFF key %d\\n\", s->geotags[i].key);\n\n                } else {\n\n                    char *ap;\n\n\n\n                    bytestream2_seek(&s->gb, pos + s->geotags[i].offset, SEEK_SET);\n\n                    if (bytestream2_get_bytes_left(&s->gb) < s->geotags[i].count)\n\n                        return AVERROR_INVALIDDATA;\n\n                    ap = av_malloc(s->geotags[i].count);\n\n                    if (!ap) {\n\n                        av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n                        return AVERROR(ENOMEM);\n\n                    }\n\n                    bytestream2_get_bufferu(&s->gb, ap, s->geotags[i].count);\n\n                    ap[s->geotags[i].count - 1] = '\\0'; //replace the \"|\" delimiter with a 0 byte\n\n                    s->geotags[i].val = ap;\n\n                }\n\n            }\n\n        }\n\n        break;\n\n    case TIFF_ARTIST:\n\n        ADD_METADATA(count, \"artist\", NULL);\n\n        break;\n\n    case TIFF_COPYRIGHT:\n\n        ADD_METADATA(count, \"copyright\", NULL);\n\n        break;\n\n    case TIFF_DATE:\n\n        ADD_METADATA(count, \"date\", NULL);\n\n        break;\n\n    case TIFF_DOCUMENT_NAME:\n\n        ADD_METADATA(count, \"document_name\", NULL);\n\n        break;\n\n    case TIFF_HOST_COMPUTER:\n\n        ADD_METADATA(count, \"computer\", NULL);\n\n        break;\n\n    case TIFF_IMAGE_DESCRIPTION:\n\n        ADD_METADATA(count, \"description\", NULL);\n\n        break;\n\n    case TIFF_MAKE:\n\n        ADD_METADATA(count, \"make\", NULL);\n\n        break;\n\n    case TIFF_MODEL:\n\n        ADD_METADATA(count, \"model\", NULL);\n\n        break;\n\n    case TIFF_PAGE_NAME:\n\n        ADD_METADATA(count, \"page_name\", NULL);\n\n        break;\n\n    case TIFF_PAGE_NUMBER:\n\n        ADD_METADATA(count, \"page_number\", \" / \");\n\n        break;\n\n    case TIFF_SOFTWARE_NAME:\n\n        ADD_METADATA(count, \"software\", NULL);\n\n        break;\n\n    default:\n\n        if (s->avctx->err_recognition & AV_EF_EXPLODE) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Unknown or unsupported tag %d/0X%0X\\n\",\n\n                   tag, tag);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\nend:\n\n    bytestream2_seek(&s->gb, start, SEEK_SET);\n\n    return 0;\n\n}\n", "idx": 26139}
{"project": "FFmpeg", "commit_id": "c3fb20bab4f00621733809fb35ee39a5ae11e598", "target": 1, "func": "static int reap_filters(void)\n\n{\n\n    AVFilterBufferRef *picref;\n\n    AVFrame *filtered_frame = NULL;\n\n    int i;\n\n    int64_t frame_pts;\n\n\n\n    /* Reap all buffers present in the buffer sinks */\n\n    for (i = 0; i < nb_output_streams; i++) {\n\n        OutputStream *ost = output_streams[i];\n\n        OutputFile    *of = output_files[ost->file_index];\n\n        int ret = 0;\n\n\n\n        if (!ost->filter)\n\n            continue;\n\n\n\n        if (!ost->filtered_frame && !(ost->filtered_frame = avcodec_alloc_frame())) {\n\n            return AVERROR(ENOMEM);\n\n        } else\n\n            avcodec_get_frame_defaults(ost->filtered_frame);\n\n        filtered_frame = ost->filtered_frame;\n\n\n\n        while (1) {\n\n            ret = av_buffersink_get_buffer_ref(ost->filter->filter, &picref,\n\n                                               AV_BUFFERSINK_FLAG_NO_REQUEST);\n\n            if (ret < 0) {\n\n                if (ret != AVERROR(EAGAIN) && ret != AVERROR_EOF) {\n\n                    char buf[256];\n\n                    av_strerror(ret, buf, sizeof(buf));\n\n                    av_log(NULL, AV_LOG_WARNING,\n\n                           \"Error in av_buffersink_get_buffer_ref(): %s\\n\", buf);\n\n\n\n\n            frame_pts = AV_NOPTS_VALUE;\n\n            if (picref->pts != AV_NOPTS_VALUE) {\n\n                filtered_frame->pts = frame_pts = av_rescale_q(picref->pts,\n\n                                                ost->filter->filter->inputs[0]->time_base,\n\n                                                ost->st->codec->time_base) -\n\n                                    av_rescale_q(of->start_time,\n\n                                                AV_TIME_BASE_Q,\n\n                                                ost->st->codec->time_base);\n\n\n\n                if (of->start_time && filtered_frame->pts < 0) {\n\n                    avfilter_unref_buffer(picref);\n\n                    continue;\n\n\n\n            //if (ost->source_index >= 0)\n\n            //    *filtered_frame= *input_streams[ost->source_index]->decoded_frame; //for me_threshold\n\n\n\n\n\n            switch (ost->filter->filter->inputs[0]->type) {\n\n            case AVMEDIA_TYPE_VIDEO:\n\n                avfilter_copy_buf_props(filtered_frame, picref);\n\n                filtered_frame->pts = frame_pts;\n\n                if (!ost->frame_aspect_ratio)\n\n                    ost->st->codec->sample_aspect_ratio = picref->video->sample_aspect_ratio;\n\n\n\n                do_video_out(of->ctx, ost, filtered_frame);\n\n\n            case AVMEDIA_TYPE_AUDIO:\n\n                avfilter_copy_buf_props(filtered_frame, picref);\n\n                filtered_frame->pts = frame_pts;\n\n\n\n\n\n\n\n                do_audio_out(of->ctx, ost, filtered_frame);\n\n\n            default:\n\n                // TODO support subtitle filters\n\n                av_assert0(0);\n\n\n\n\n            avfilter_unref_buffer(picref);\n\n\n\n\n\n    return 0;\n", "idx": 26140}
{"project": "FFmpeg", "commit_id": "4d1418cd4f620b382106542d0f33d96e33a0fdae", "target": 1, "func": "static av_always_inline void hl_decode_mb_predict_luma(H264Context *h, int mb_type, int is_h264, int simple, int transform_bypass,\n\n                                                       int pixel_shift, int *block_offset, int linesize, uint8_t *dest_y, int p)\n\n{\n\n    MpegEncContext * const s = &h->s;\n\n    void (*idct_add)(uint8_t *dst, DCTELEM *block, int stride);\n\n    void (*idct_dc_add)(uint8_t *dst, DCTELEM *block, int stride);\n\n    int i;\n\n    int qscale = p == 0 ? s->qscale : h->chroma_qp[p-1];\n\n    block_offset += 16*p;\n\n    if(IS_INTRA4x4(mb_type)){\n\n        if(simple || !s->encoding){\n\n            if(IS_8x8DCT(mb_type)){\n\n                if(transform_bypass){\n\n                    idct_dc_add =\n\n                    idct_add    = s->dsp.add_pixels8;\n\n                }else{\n\n                    idct_dc_add = h->h264dsp.h264_idct8_dc_add;\n\n                    idct_add    = h->h264dsp.h264_idct8_add;\n\n                }\n\n                for(i=0; i<16; i+=4){\n\n                    uint8_t * const ptr= dest_y + block_offset[i];\n\n                    const int dir= h->intra4x4_pred_mode_cache[ scan8[i] ];\n\n                    if(transform_bypass && h->sps.profile_idc==244 && dir<=1){\n\n                        h->hpc.pred8x8l_add[dir](ptr, h->mb + (i*16+p*256 << pixel_shift), linesize);\n\n                    }else{\n\n                        const int nnz = h->non_zero_count_cache[ scan8[i+p*16] ];\n\n                        h->hpc.pred8x8l[ dir ](ptr, (h->topleft_samples_available<<i)&0x8000,\n\n                                                    (h->topright_samples_available<<i)&0x4000, linesize);\n\n                        if(nnz){\n\n                            if(nnz == 1 && dctcoef_get(h->mb, pixel_shift, i*16+p*256))\n\n                                idct_dc_add(ptr, h->mb + (i*16+p*256 << pixel_shift), linesize);\n\n                            else\n\n                                idct_add   (ptr, h->mb + (i*16+p*256 << pixel_shift), linesize);\n\n                        }\n\n                    }\n\n                }\n\n            }else{\n\n                if(transform_bypass){\n\n                    idct_dc_add =\n\n                    idct_add    = s->dsp.add_pixels4;\n\n                }else{\n\n                    idct_dc_add = h->h264dsp.h264_idct_dc_add;\n\n                    idct_add    = h->h264dsp.h264_idct_add;\n\n                }\n\n                for(i=0; i<16; i++){\n\n                    uint8_t * const ptr= dest_y + block_offset[i];\n\n                    const int dir= h->intra4x4_pred_mode_cache[ scan8[i] ];\n\n\n\n                    if(transform_bypass && h->sps.profile_idc==244 && dir<=1){\n\n                        h->hpc.pred4x4_add[dir](ptr, h->mb + (i*16+p*256 << pixel_shift), linesize);\n\n                    }else{\n\n                        uint8_t *topright;\n\n                        int nnz, tr;\n\n                        uint64_t tr_high;\n\n                        if(dir == DIAG_DOWN_LEFT_PRED || dir == VERT_LEFT_PRED){\n\n                            const int topright_avail= (h->topright_samples_available<<i)&0x8000;\n\n                            assert(s->mb_y || linesize <= block_offset[i]);\n\n                            if(!topright_avail){\n\n                                if (pixel_shift) {\n\n                                    tr_high= ((uint16_t*)ptr)[3 - linesize/2]*0x0001000100010001ULL;\n\n                                    topright= (uint8_t*) &tr_high;\n\n                                } else {\n\n                                    tr= ptr[3 - linesize]*0x01010101;\n\n                                    topright= (uint8_t*) &tr;\n\n                                }\n\n                            }else\n\n                                topright= ptr + (4 << pixel_shift) - linesize;\n\n                        }else\n\n                            topright= NULL;\n\n\n\n                        h->hpc.pred4x4[ dir ](ptr, topright, linesize);\n\n                        nnz = h->non_zero_count_cache[ scan8[i+p*16] ];\n\n                        if(nnz){\n\n                            if(is_h264){\n\n                                if(nnz == 1 && dctcoef_get(h->mb, pixel_shift, i*16+p*256))\n\n                                    idct_dc_add(ptr, h->mb + (i*16+p*256 << pixel_shift), linesize);\n\n                                else\n\n                                    idct_add   (ptr, h->mb + (i*16+p*256 << pixel_shift), linesize);\n\n                            }else\n\n                                ff_svq3_add_idct_c(ptr, h->mb + i*16+p*256, linesize, qscale, 0);\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }else{\n\n        h->hpc.pred16x16[ h->intra16x16_pred_mode ](dest_y , linesize);\n\n        if(is_h264){\n\n            if(h->non_zero_count_cache[ scan8[LUMA_DC_BLOCK_INDEX+p] ]){\n\n                if(!transform_bypass)\n\n                    h->h264dsp.h264_luma_dc_dequant_idct(h->mb+(p*256 << pixel_shift), h->mb_luma_dc[p], h->dequant4_coeff[p][qscale][0]);\n\n                else{\n\n                    static const uint8_t dc_mapping[16] = { 0*16, 1*16, 4*16, 5*16, 2*16, 3*16, 6*16, 7*16,\n\n                                                            8*16, 9*16,12*16,13*16,10*16,11*16,14*16,15*16};\n\n                    for(i = 0; i < 16; i++)\n\n                        dctcoef_set(h->mb+p*256, pixel_shift, dc_mapping[i], dctcoef_get(h->mb_luma_dc[p], pixel_shift, i));\n\n                }\n\n            }\n\n        }else\n\n            ff_svq3_luma_dc_dequant_idct_c(h->mb+p*256, h->mb_luma_dc[p], qscale);\n\n    }\n\n}\n", "idx": 26142}
{"project": "FFmpeg", "commit_id": "7faa40af982960608b117e20fec999b48011e5e0", "target": 1, "func": "static int adx_read_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    ADXDemuxerContext *c = s->priv_data;\n    AVCodecContext *avctx = s->streams[0]->codec;\n    int ret, size;\n    size = BLOCK_SIZE * avctx->channels;\n    pkt->pos = avio_tell(s->pb);\n    pkt->stream_index = 0;\n    ret = av_get_packet(s->pb, pkt, size);\n    if (ret != size) {\n        av_free_packet(pkt);\n        return ret < 0 ? ret : AVERROR(EIO);\n    if (AV_RB16(pkt->data) & 0x8000) {\n        av_free_packet(pkt);\n        return AVERROR_EOF;\n    pkt->size     = size;\n    pkt->duration = 1;\n    pkt->pts      = (pkt->pos - c->header_size) / size;\n    return 0;", "idx": 26143}
{"project": "FFmpeg", "commit_id": "13a099799e89a76eb921ca452e1b04a7a28a9855", "target": 0, "func": "yuv2rgb_1_c_template(SwsContext *c, const uint16_t *buf0,\n\n                     const uint16_t *ubuf0, const uint16_t *ubuf1,\n\n                     const uint16_t *vbuf0, const uint16_t *vbuf1,\n\n                     const uint16_t *abuf0, uint8_t *dest, int dstW,\n\n                     int uvalpha, enum PixelFormat dstFormat,\n\n                     int flags, int y, enum PixelFormat target,\n\n                     int hasAlpha)\n\n{\n\n    int i;\n\n\n\n    if (uvalpha < 2048) {\n\n        for (i = 0; i < (dstW >> 1); i++) {\n\n            int Y1 = buf0[i * 2]     >> 7;\n\n            int Y2 = buf0[i * 2 + 1] >> 7;\n\n            int U  = ubuf1[i]        >> 7;\n\n            int V  = vbuf1[i]        >> 7;\n\n            int A1, A2;\n\n            const void *r =  c->table_rV[V],\n\n                       *g = (c->table_gU[U] + c->table_gV[V]),\n\n                       *b =  c->table_bU[U];\n\n\n\n            if (hasAlpha) {\n\n                A1 = abuf0[i * 2    ] >> 7;\n\n                A2 = abuf0[i * 2 + 1] >> 7;\n\n            }\n\n\n\n            yuv2rgb_write(dest, i, Y1, Y2, U, V, hasAlpha ? A1 : 0, hasAlpha ? A2 : 0,\n\n                          r, g, b, y, target, hasAlpha);\n\n        }\n\n    } else {\n\n        for (i = 0; i < (dstW >> 1); i++) {\n\n            int Y1 =  buf0[i * 2]          >> 7;\n\n            int Y2 =  buf0[i * 2 + 1]      >> 7;\n\n            int U  = (ubuf0[i] + ubuf1[i]) >> 8;\n\n            int V  = (vbuf0[i] + vbuf1[i]) >> 8;\n\n            int A1, A2;\n\n            const void *r =  c->table_rV[V],\n\n                       *g = (c->table_gU[U] + c->table_gV[V]),\n\n                       *b =  c->table_bU[U];\n\n\n\n            if (hasAlpha) {\n\n                A1 = abuf0[i * 2    ] >> 7;\n\n                A2 = abuf0[i * 2 + 1] >> 7;\n\n            }\n\n\n\n            yuv2rgb_write(dest, i, Y1, Y2, U, V, hasAlpha ? A1 : 0, hasAlpha ? A2 : 0,\n\n                          r, g, b, y, target, hasAlpha);\n\n        }\n\n    }\n\n}\n", "idx": 26154}
{"project": "FFmpeg", "commit_id": "59c6178a54c414fd19e064f0077d00b82a1eb812", "target": 0, "func": "static int put_flac_codecpriv(AVFormatContext *s, ByteIOContext *pb, AVCodecContext *codec)\n\n{\n\n    // if the extradata_size is greater than FLAC_STREAMINFO_SIZE,\n\n    // assume that it's in Matroska format already\n\n    if (codec->extradata_size < FLAC_STREAMINFO_SIZE) {\n\n        av_log(s, AV_LOG_ERROR, \"Invalid FLAC extradata\\n\");\n\n        return -1;\n\n    } else if (codec->extradata_size == FLAC_STREAMINFO_SIZE) {\n\n        // only the streaminfo packet\n\n        put_buffer(pb, \"fLaC\", 4);\n\n        put_byte(pb, 0x80);\n\n        put_be24(pb, FLAC_STREAMINFO_SIZE);\n\n    } else if(memcmp(\"fLaC\", codec->extradata, 4)) {\n\n        av_log(s, AV_LOG_ERROR, \"Invalid FLAC extradata\\n\");\n\n        return -1;\n\n    }\n\n    put_buffer(pb, codec->extradata, codec->extradata_size);\n\n    return 0;\n\n}\n", "idx": 26165}
{"project": "FFmpeg", "commit_id": "ddebfb15dc8ee01f7f8ff4e15e80b9843e550f00", "target": 0, "func": "int avcodec_open(AVCodecContext *avctx, AVCodec *codec)\n\n{\n\n    int ret;\n\n\n\n    if(avctx->codec)\n\n        return -1;\n\n\n\n    avctx->codec = codec;\n\n    avctx->codec_id = codec->id;\n\n    avctx->frame_number = 0;\n\n    if (codec->priv_data_size > 0) {\n\n        avctx->priv_data = av_mallocz(codec->priv_data_size);\n\n        if (!avctx->priv_data) \n\n            return -ENOMEM;\n\n    } else {\n\n        avctx->priv_data = NULL;\n\n    }\n\n\n\n    if(avctx->coded_width && avctx->coded_height)\n\n        avcodec_set_dimensions(avctx, avctx->coded_width, avctx->coded_height);\n\n    else if(avctx->width && avctx->height)\n\n        avcodec_set_dimensions(avctx, avctx->width, avctx->height);\n\n\n\n    if((avctx->coded_width||avctx->coded_height) && avcodec_check_dimensions(avctx,avctx->coded_width,avctx->coded_height)){\n\n        av_freep(&avctx->priv_data);\n\n        return -1;\n\n    }\n\n\n\n    ret = avctx->codec->init(avctx);\n\n    if (ret < 0) {\n\n        av_freep(&avctx->priv_data);\n\n        return ret;\n\n    }\n\n    return 0;\n\n}\n", "idx": 26168}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(yv12touyvy)(const uint8_t *ysrc, const uint8_t *usrc, const uint8_t *vsrc, uint8_t *dst,\n\n                                      long width, long height,\n\n                                      long lumStride, long chromStride, long dstStride)\n\n{\n\n    //FIXME interpolate chroma\n\n    RENAME(yuvPlanartouyvy)(ysrc, usrc, vsrc, dst, width, height, lumStride, chromStride, dstStride, 2);\n\n}\n", "idx": 26169}
{"project": "FFmpeg", "commit_id": "ac4b32df71bd932838043a4838b86d11e169707f", "target": 1, "func": "static int decode_block_coeffs_internal(VP56RangeCoder *r, int16_t block[16],\n\n                                        uint8_t probs[16][3][NUM_DCT_TOKENS - 1],\n\n                                        int i, uint8_t *token_prob,\n\n                                        int16_t qmul[2])\n\n{\n\n    VP56RangeCoder c = *r;\n\n    goto skip_eob;\n\n    do {\n\n        int coeff;\n\n        if (!vp56_rac_get_prob_branchy(&c, token_prob[0]))   // DCT_EOB\n\n            break;\n\n\n\nskip_eob:\n\n        if (!vp56_rac_get_prob_branchy(&c, token_prob[1])) { // DCT_0\n\n            if (++i == 16)\n\n                break; // invalid input; blocks should end with EOB\n\n            token_prob = probs[i][0];\n\n            goto skip_eob;\n\n        }\n\n\n\n        if (!vp56_rac_get_prob_branchy(&c, token_prob[2])) { // DCT_1\n\n            coeff = 1;\n\n            token_prob = probs[i + 1][1];\n\n        } else {\n\n            if (!vp56_rac_get_prob_branchy(&c, token_prob[3])) { // DCT 2,3,4\n\n                coeff = vp56_rac_get_prob_branchy(&c, token_prob[4]);\n\n                if (coeff)\n\n                    coeff += vp56_rac_get_prob(&c, token_prob[5]);\n\n                coeff += 2;\n\n            } else {\n\n                // DCT_CAT*\n\n                if (!vp56_rac_get_prob_branchy(&c, token_prob[6])) {\n\n                    if (!vp56_rac_get_prob_branchy(&c, token_prob[7])) { // DCT_CAT1\n\n                        coeff = 5 + vp56_rac_get_prob(&c, vp8_dct_cat1_prob[0]);\n\n                    } else {                                    // DCT_CAT2\n\n                        coeff  = 7;\n\n                        coeff += vp56_rac_get_prob(&c, vp8_dct_cat2_prob[0]) << 1;\n\n                        coeff += vp56_rac_get_prob(&c, vp8_dct_cat2_prob[1]);\n\n                    }\n\n                } else {    // DCT_CAT3 and up\n\n                    int a   = vp56_rac_get_prob(&c, token_prob[8]);\n\n                    int b   = vp56_rac_get_prob(&c, token_prob[9 + a]);\n\n                    int cat = (a << 1) + b;\n\n                    coeff  = 3 + (8 << cat);\n\n                    coeff += vp8_rac_get_coeff(&c, ff_vp8_dct_cat_prob[cat]);\n\n                }\n\n            }\n\n            token_prob = probs[i + 1][2];\n\n        }\n\n        block[zigzag_scan[i]] = (vp8_rac_get(&c) ? -coeff : coeff) * qmul[!!i];\n\n    } while (++i < 16);\n\n\n\n    *r = c;\n\n    return i;\n\n}\n", "idx": 26170}
{"project": "FFmpeg", "commit_id": "5a8fec1b33f2c9da89fe565516fff24b09988dc9", "target": 1, "func": "static void imdct12(INTFLOAT *out, INTFLOAT *in)\n\n{\n\n    INTFLOAT in0, in1, in2, in3, in4, in5, t1, t2;\n\n\n\n    in0  = in[0*3];\n\n    in1  = in[1*3] + in[0*3];\n\n    in2  = in[2*3] + in[1*3];\n\n    in3  = in[3*3] + in[2*3];\n\n    in4  = in[4*3] + in[3*3];\n\n    in5  = in[5*3] + in[4*3];\n\n    in5 += in3;\n\n    in3 += in1;\n\n\n\n    in2  = MULH3(in2, C3, 2);\n\n    in3  = MULH3(in3, C3, 4);\n\n\n\n    t1   = in0 - in4;\n\n    t2   = MULH3(in1 - in5, C4, 2);\n\n\n\n    out[ 7] =\n\n    out[10] = t1 + t2;\n\n    out[ 1] =\n\n    out[ 4] = t1 - t2;\n\n\n\n    in0    += SHR(in4, 1);\n\n    in4     = in0 + in2;\n\n    in5    += 2*in1;\n\n    in1     = MULH3(in5 + in3, C5, 1);\n\n    out[ 8] =\n\n    out[ 9] = in4 + in1;\n\n    out[ 2] =\n\n    out[ 3] = in4 - in1;\n\n\n\n    in0    -= in2;\n\n    in5     = MULH3(in5 - in3, C6, 2);\n\n    out[ 0] =\n\n    out[ 5] = in0 - in5;\n\n    out[ 6] =\n\n    out[11] = in0 + in5;\n\n}\n", "idx": 26172}
{"project": "FFmpeg", "commit_id": "bf238a6a3ca92de686e0e103135c1336f33f685b", "target": 1, "func": "static int hwupload_query_formats(AVFilterContext *avctx)\n\n{\n\n    HWUploadContext *ctx = avctx->priv;\n\n    AVHWFramesConstraints *constraints = NULL;\n\n    const enum AVPixelFormat *input_pix_fmts, *output_pix_fmts;\n\n    AVFilterFormats *input_formats = NULL;\n\n    int err, i;\n\n\n\n    if (!avctx->hw_device_ctx) {\n\n        av_log(ctx, AV_LOG_ERROR, \"A hardware device reference is required \"\n\n               \"to upload frames to.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    ctx->hwdevice_ref = av_buffer_ref(avctx->hw_device_ctx);\n\n    if (!ctx->hwdevice_ref)\n\n        return AVERROR(ENOMEM);\n\n    ctx->hwdevice = (AVHWDeviceContext*)ctx->hwdevice_ref->data;\n\n\n\n    constraints = av_hwdevice_get_hwframe_constraints(ctx->hwdevice_ref, NULL);\n\n    if (!constraints) {\n\n        err = AVERROR(EINVAL);\n\n        goto fail;\n\n    }\n\n\n\n    input_pix_fmts  = constraints->valid_sw_formats;\n\n    output_pix_fmts = constraints->valid_hw_formats;\n\n\n\n    input_formats = ff_make_format_list(output_pix_fmts);\n\n    if (!input_formats) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    if (input_pix_fmts) {\n\n        for (i = 0; input_pix_fmts[i] != AV_PIX_FMT_NONE; i++) {\n\n            err = ff_add_format(&input_formats, input_pix_fmts[i]);\n\n            if (err < 0) {\n\n                ff_formats_unref(&input_formats);\n\n                goto fail;\n\n            }\n\n        }\n\n    }\n\n\n\n    ff_formats_ref(input_formats, &avctx->inputs[0]->out_formats);\n\n\n\n    ff_formats_ref(ff_make_format_list(output_pix_fmts),\n\n                   &avctx->outputs[0]->in_formats);\n\n\n\n    av_hwframe_constraints_free(&constraints);\n\n    return 0;\n\n\n\nfail:\n\n    av_buffer_unref(&ctx->hwdevice_ref);\n\n    av_hwframe_constraints_free(&constraints);\n\n    return err;\n\n}\n", "idx": 26173}
{"project": "FFmpeg", "commit_id": "a4d70941cd4a82f7db9fbaa2148d60ce550e7611", "target": 1, "func": "static void start_children(FFStream *feed)\n{\n    if (no_launch)\n        return;\n    for (; feed; feed = feed->next) {\n        if (feed->child_argv && !feed->pid) {\n            feed->pid_start = time(0);\n            feed->pid = fork();\n            if (feed->pid < 0) {\n                fprintf(stderr, \"Unable to create children\\n\");\n                exit(1);\n            }\n            if (!feed->pid) {\n                /* In child */\n                char pathname[1024];\n                char *slash;\n                int i;\n                for (i = 3; i < 256; i++) {\n                    close(i);\n                }\n                if (!ffserver_debug) {\n                    i = open(\"/dev/null\", O_RDWR);\n                    if (i)\n                        dup2(i, 0);\n                    dup2(i, 1);\n                    dup2(i, 2);\n                    if (i)\n                        close(i);\n                }\n                pstrcpy(pathname, sizeof(pathname), my_program_name);\n                slash = strrchr(pathname, '/');\n                if (!slash) {\n                    slash = pathname;\n                } else {\n                    slash++;\n                }\n                strcpy(slash, \"ffmpeg\");\n                /* This is needed to make relative pathnames work */\n                chdir(my_program_dir);\n                execvp(pathname, feed->child_argv);\n                _exit(1);\n            }\n        }\n    }\n}", "idx": 26174}
{"project": "FFmpeg", "commit_id": "ca402f32e392590a81a1381dab41c4f9c2c2f98a", "target": 1, "func": "static int dxa_read_header(AVFormatContext *s, AVFormatParameters *ap)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    DXAContext *c = s->priv_data;\n\n    AVStream *st, *ast;\n\n    uint32_t tag;\n\n    int32_t fps;\n\n    int w, h;\n\n    int num, den;\n\n    int flags;\n\n\n\n    tag = avio_rl32(pb);\n\n    if (tag != MKTAG('D', 'E', 'X', 'A'))\n\n        return -1;\n\n    flags = avio_r8(pb);\n\n    c->frames = avio_rb16(pb);\n\n    if(!c->frames){\n\n        av_log(s, AV_LOG_ERROR, \"File contains no frames ???\\n\");\n\n        return -1;\n\n    }\n\n\n\n    fps = avio_rb32(pb);\n\n    if(fps > 0){\n\n        den = 1000;\n\n        num = fps;\n\n    }else if (fps < 0){\n\n        den = 100000;\n\n        num = -fps;\n\n    }else{\n\n        den = 10;\n\n        num = 1;\n\n    }\n\n    w = avio_rb16(pb);\n\n    h = avio_rb16(pb);\n\n    c->has_sound = 0;\n\n\n\n    st = av_new_stream(s, 0);\n\n    if (!st)\n\n        return -1;\n\n\n\n    // Parse WAV data header\n\n    if(avio_rl32(pb) == MKTAG('W', 'A', 'V', 'E')){\n\n        uint32_t size, fsize;\n\n        c->has_sound = 1;\n\n        size = avio_rb32(pb);\n\n        c->vidpos = avio_tell(pb) + size;\n\n        avio_skip(pb, 16);\n\n        fsize = avio_rl32(pb);\n\n\n\n        ast = av_new_stream(s, 0);\n\n        if (!ast)\n\n            return -1;\n\n        ff_get_wav_header(pb, ast->codec, fsize);\n\n        // find 'data' chunk\n\n        while(avio_tell(pb) < c->vidpos && !pb->eof_reached){\n\n            tag = avio_rl32(pb);\n\n            fsize = avio_rl32(pb);\n\n            if(tag == MKTAG('d', 'a', 't', 'a')) break;\n\n            avio_skip(pb, fsize);\n\n        }\n\n        c->bpc = (fsize + c->frames - 1) / c->frames;\n\n        if(ast->codec->block_align)\n\n            c->bpc = ((c->bpc + ast->codec->block_align - 1) / ast->codec->block_align) * ast->codec->block_align;\n\n        c->bytes_left = fsize;\n\n        c->wavpos = avio_tell(pb);\n\n        avio_seek(pb, c->vidpos, SEEK_SET);\n\n    }\n\n\n\n    /* now we are ready: build format streams */\n\n    st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id   = CODEC_ID_DXA;\n\n    st->codec->width      = w;\n\n    st->codec->height     = h;\n\n    av_reduce(&den, &num, den, num, (1UL<<31)-1);\n\n    av_set_pts_info(st, 33, num, den);\n\n    /* flags & 0x80 means that image is interlaced,\n\n     * flags & 0x40 means that image has double height\n\n     * either way set true height\n\n     */\n\n    if(flags & 0xC0){\n\n        st->codec->height >>= 1;\n\n    }\n\n    c->readvid = !c->has_sound;\n\n    c->vidpos  = avio_tell(pb);\n\n    s->start_time = 0;\n\n    s->duration = (int64_t)c->frames * AV_TIME_BASE * num / den;\n\n    av_log(s, AV_LOG_DEBUG, \"%d frame(s)\\n\",c->frames);\n\n\n\n    return 0;\n\n}\n", "idx": 26178}
{"project": "FFmpeg", "commit_id": "dcd3418a35aab7ef283b68ed9997ce4ac204094e", "target": 0, "func": "static int get_cv_color_primaries(AVCodecContext *avctx,\n\n                                  CFStringRef *primaries)\n\n{\n\n    enum AVColorPrimaries pri = avctx->color_primaries;\n\n    switch (pri) {\n\n        case AVCOL_PRI_UNSPECIFIED:\n\n            *primaries = NULL;\n\n            break;\n\n\n\n        case AVCOL_PRI_BT709:\n\n            *primaries = kCVImageBufferColorPrimaries_ITU_R_709_2;\n\n            break;\n\n\n\n        case AVCOL_PRI_BT2020:\n\n            *primaries = kCVImageBufferColorPrimaries_ITU_R_2020;\n\n            break;\n\n\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Color primaries %s is not supported.\\n\", av_color_primaries_name(pri));\n\n            *primaries = NULL;\n\n            return -1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26179}
{"project": "FFmpeg", "commit_id": "a4fd95b5d511384ed3ce388d8d20a16b1c4c0530", "target": 0, "func": "int ff_h264_check_intra_pred_mode(H264Context *h, int mode){\n\n    MpegEncContext * const s = &h->s;\n\n    static const int8_t top [7]= {LEFT_DC_PRED8x8, 1,-1,-1};\n\n    static const int8_t left[7]= { TOP_DC_PRED8x8,-1, 2,-1,DC_128_PRED8x8};\n\n\n\n    if(mode > 6U) {\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"out of range intra chroma pred mode at %d %d\\n\", s->mb_x, s->mb_y);\n\n        return -1;\n\n    }\n\n\n\n    if(!(h->top_samples_available&0x8000)){\n\n        mode= top[ mode ];\n\n        if(mode<0){\n\n            av_log(h->s.avctx, AV_LOG_ERROR, \"top block unavailable for requested intra mode at %d %d\\n\", s->mb_x, s->mb_y);\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    if((h->left_samples_available&0x8080) != 0x8080){\n\n        mode= left[ mode ];\n\n        if(h->left_samples_available&0x8080){ //mad cow disease mode, aka MBAFF + constrained_intra_pred\n\n            mode= ALZHEIMER_DC_L0T_PRED8x8 + (!(h->left_samples_available&0x8000)) + 2*(mode == DC_128_PRED8x8);\n\n        }\n\n        if(mode<0){\n\n            av_log(h->s.avctx, AV_LOG_ERROR, \"left block unavailable for requested intra mode at %d %d\\n\", s->mb_x, s->mb_y);\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    return mode;\n\n}\n", "idx": 26180}
{"project": "FFmpeg", "commit_id": "bcd7bf7eeb09a395cc01698842d1b8be9af483fc", "target": 0, "func": "static void avc_wgt_4x4multiple_msa(uint8_t *data,\n\n                                    int32_t stride,\n\n                                    int32_t height,\n\n                                    int32_t log2_denom,\n\n                                    int32_t src_weight,\n\n                                    int32_t offset_in)\n\n{\n\n    uint8_t cnt;\n\n    uint32_t data0, data1, data2, data3;\n\n    v16u8 zero = { 0 };\n\n    v16u8 src0, src1, src2, src3;\n\n    v8u16 temp0, temp1, temp2, temp3;\n\n    v8i16 wgt, denom, offset;\n\n\n\n    offset_in <<= (log2_denom);\n\n\n\n    if (log2_denom) {\n\n        offset_in += (1 << (log2_denom - 1));\n\n    }\n\n\n\n    wgt = __msa_fill_h(src_weight);\n\n    offset = __msa_fill_h(offset_in);\n\n    denom = __msa_fill_h(log2_denom);\n\n\n\n    for (cnt = height / 4; cnt--;) {\n\n        LOAD_4WORDS_WITH_STRIDE(data, stride, data0, data1, data2, data3);\n\n\n\n        src0 = (v16u8) __msa_fill_w(data0);\n\n        src1 = (v16u8) __msa_fill_w(data1);\n\n        src2 = (v16u8) __msa_fill_w(data2);\n\n        src3 = (v16u8) __msa_fill_w(data3);\n\n\n\n        ILVR_B_4VECS_UH(src0, src1, src2, src3, zero, zero, zero, zero,\n\n                        temp0, temp1, temp2, temp3);\n\n\n\n        temp0 *= wgt;\n\n        temp1 *= wgt;\n\n        temp2 *= wgt;\n\n        temp3 *= wgt;\n\n\n\n        ADDS_S_H_4VECS_UH(temp0, offset, temp1, offset,\n\n                          temp2, offset, temp3, offset,\n\n                          temp0, temp1, temp2, temp3);\n\n\n\n        MAXI_S_H_4VECS_UH(temp0, temp1, temp2, temp3, 0);\n\n\n\n        SRL_H_4VECS_UH(temp0, temp1, temp2, temp3,\n\n                       temp0, temp1, temp2, temp3, denom);\n\n\n\n        SAT_U_H_4VECS_UH(temp0, temp1, temp2, temp3, 7);\n\n\n\n        PCKEV_B_STORE_4_BYTES_4(temp0, temp1, temp2, temp3, data, stride);\n\n        data += (4 * stride);\n\n    }\n\n}\n", "idx": 26181}
{"project": "FFmpeg", "commit_id": "acc163c6ab52d2235767852262c64c7f6b273d1c", "target": 0, "func": "static void FUNC(flac_decorrelate_indep_c)(uint8_t **out, int32_t **in,\n\n                                           int channels, int len, int shift)\n\n{\n\n    sample *samples = (sample *) OUT(out);\n\n    int i, j;\n\n\n\n    for (j = 0; j < len; j++)\n\n        for (i = 0; i < channels; i++)\n\n            S(samples, i, j) = in[i][j] << shift;\n\n}\n", "idx": 26182}
{"project": "FFmpeg", "commit_id": "0114c571d4c8cc1036850ced924683709390681a", "target": 1, "func": "void ff_MPV_frame_end(MpegEncContext *s)\n\n{\n\n    int i;\n\n    /* redraw edges for the frame if decoding didn't complete */\n\n    // just to make sure that all data is rendered.\n\n    if (CONFIG_MPEG_XVMC_DECODER && s->avctx->xvmc_acceleration) {\n\n        ff_xvmc_field_end(s);\n\n   } else if((s->error_count || s->encoding || !(s->avctx->codec->capabilities&CODEC_CAP_DRAW_HORIZ_BAND)) &&\n\n              !s->avctx->hwaccel &&\n\n              !(s->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU) &&\n\n              s->unrestricted_mv &&\n\n              s->current_picture.f.reference &&\n\n              !s->intra_only &&\n\n              !(s->flags & CODEC_FLAG_EMU_EDGE)) {\n\n        int hshift = av_pix_fmt_descriptors[s->avctx->pix_fmt].log2_chroma_w;\n\n        int vshift = av_pix_fmt_descriptors[s->avctx->pix_fmt].log2_chroma_h;\n\n        s->dsp.draw_edges(s->current_picture.f.data[0], s->current_picture.f.linesize[0],\n\n                          s->h_edge_pos, s->v_edge_pos,\n\n                          EDGE_WIDTH, EDGE_WIDTH,\n\n                          EDGE_TOP | EDGE_BOTTOM);\n\n        s->dsp.draw_edges(s->current_picture.f.data[1], s->current_picture.f.linesize[1],\n\n                          s->h_edge_pos >> hshift, s->v_edge_pos >> vshift,\n\n                          EDGE_WIDTH >> hshift, EDGE_WIDTH >> vshift,\n\n                          EDGE_TOP | EDGE_BOTTOM);\n\n        s->dsp.draw_edges(s->current_picture.f.data[2], s->current_picture.f.linesize[2],\n\n                          s->h_edge_pos >> hshift, s->v_edge_pos >> vshift,\n\n                          EDGE_WIDTH >> hshift, EDGE_WIDTH >> vshift,\n\n                          EDGE_TOP | EDGE_BOTTOM);\n\n    }\n\n\n\n    emms_c();\n\n\n\n    s->last_pict_type                 = s->pict_type;\n\n    s->last_lambda_for [s->pict_type] = s->current_picture_ptr->f.quality;\n\n    if (s->pict_type!= AV_PICTURE_TYPE_B) {\n\n        s->last_non_b_pict_type = s->pict_type;\n\n    }\n\n#if 0\n\n    /* copy back current_picture variables */\n\n    for (i = 0; i < MAX_PICTURE_COUNT; i++) {\n\n        if (s->picture[i].f.data[0] == s->current_picture.f.data[0]) {\n\n            s->picture[i] = s->current_picture;\n\n            break;\n\n        }\n\n    }\n\n    assert(i < MAX_PICTURE_COUNT);\n\n#endif\n\n\n\n    if (s->encoding) {\n\n        /* release non-reference frames */\n\n        for (i = 0; i < s->picture_count; i++) {\n\n            if (s->picture[i].f.data[0] && !s->picture[i].f.reference\n\n                /* && s->picture[i].type != FF_BUFFER_TYPE_SHARED */) {\n\n                free_frame_buffer(s, &s->picture[i]);\n\n            }\n\n        }\n\n    }\n\n    // clear copies, to avoid confusion\n\n#if 0\n\n    memset(&s->last_picture,    0, sizeof(Picture));\n\n    memset(&s->next_picture,    0, sizeof(Picture));\n\n    memset(&s->current_picture, 0, sizeof(Picture));\n\n#endif\n\n    s->avctx->coded_frame = &s->current_picture_ptr->f;\n\n\n\n    if (s->codec_id != AV_CODEC_ID_H264 && s->current_picture.f.reference) {\n\n        ff_thread_report_progress(&s->current_picture_ptr->f, INT_MAX, 0);\n\n    }\n\n}\n", "idx": 26183}
{"project": "FFmpeg", "commit_id": "c9c7263e5820c957598643216c42be9b1c4f2d2b", "target": 0, "func": "static int mov_open_dref(MOVContext *c, AVIOContext **pb, const char *src, MOVDref *ref,\n\n                         AVIOInterruptCB *int_cb)\n\n{\n\n    AVOpenCallback open_func = c->fc->open_cb;\n\n\n\n    if (!open_func)\n\n        open_func = ffio_open2_wrapper;\n\n\n\n    /* try relative path, we do not try the absolute because it can leak information about our\n\n       system to an attacker */\n\n    if (ref->nlvl_to > 0 && ref->nlvl_from > 0 && ref->path[0] != '/') {\n\n        char filename[1025];\n\n        const char *src_path;\n\n        int i, l;\n\n\n\n        /* find a source dir */\n\n        src_path = strrchr(src, '/');\n\n        if (src_path)\n\n            src_path++;\n\n        else\n\n            src_path = src;\n\n\n\n        /* find a next level down to target */\n\n        for (i = 0, l = strlen(ref->path) - 1; l >= 0; l--)\n\n            if (ref->path[l] == '/') {\n\n                if (i == ref->nlvl_to - 1)\n\n                    break;\n\n                else\n\n                    i++;\n\n            }\n\n\n\n        /* compose filename if next level down to target was found */\n\n        if (i == ref->nlvl_to - 1 && src_path - src  < sizeof(filename)) {\n\n            memcpy(filename, src, src_path - src);\n\n            filename[src_path - src] = 0;\n\n\n\n            for (i = 1; i < ref->nlvl_from; i++)\n\n                av_strlcat(filename, \"../\", sizeof(filename));\n\n\n\n            av_strlcat(filename, ref->path + l + 1, sizeof(filename));\n\n            if (!c->use_absolute_path && !c->fc->open_cb)\n\n                if(strstr(ref->path + l + 1, \"..\") || ref->nlvl_from > 1)\n\n                    return AVERROR(ENOENT);\n\n\n\n            if (strlen(filename) + 1 == sizeof(filename))\n\n                return AVERROR(ENOENT);\n\n            if (!open_func(c->fc, pb, filename, AVIO_FLAG_READ, int_cb, NULL))\n\n                return 0;\n\n        }\n\n    } else if (c->use_absolute_path) {\n\n        av_log(c->fc, AV_LOG_WARNING, \"Using absolute path on user request, \"\n\n               \"this is a possible security issue\\n\");\n\n        if (!open_func(c->fc, pb, ref->path, AVIO_FLAG_READ, int_cb, NULL))\n\n            return 0;\n\n    } else if (c->fc->open_cb) {\n\n        if (!open_func(c->fc, pb, ref->path, AVIO_FLAG_READ, int_cb, NULL))\n\n            return 0;\n\n    } else {\n\n        av_log(c->fc, AV_LOG_ERROR,\n\n               \"Absolute path %s not tried for security reasons, \"\n\n               \"set demuxer option use_absolute_path to allow absolute paths\\n\",\n\n               ref->path);\n\n    }\n\n\n\n    return AVERROR(ENOENT);\n\n}\n", "idx": 26189}
{"project": "FFmpeg", "commit_id": "aac8b76983e340bc744d3542d676f72efa3b474f", "target": 0, "func": "static void filter_mb_edgev( H264Context *h, uint8_t *pix, int stride, int16_t bS[4], int qp ) {\n\n    int i, d;\n\n    const int index_a = qp + h->slice_alpha_c0_offset;\n\n    const int alpha = (alpha_table+52)[index_a];\n\n    const int beta  = (beta_table+52)[qp + h->slice_beta_offset];\n\n\n\n    if( bS[0] < 4 ) {\n\n        int8_t tc[4];\n\n        for(i=0; i<4; i++)\n\n            tc[i] = bS[i] ? (tc0_table+52)[index_a][bS[i] - 1] : -1;\n\n        h->s.dsp.h264_h_loop_filter_luma(pix, stride, alpha, beta, tc);\n\n    } else {\n\n        h->s.dsp.h264_h_loop_filter_luma_intra(pix, stride, alpha, beta);\n\n    }\n\n}\n", "idx": 26190}
{"project": "FFmpeg", "commit_id": "e55ed689a264c78f332745598ea8c58a3422ee13", "target": 0, "func": "static void selfTest(uint8_t *src[4], int stride[4], int w, int h){\n\n    enum PixelFormat srcFormat, dstFormat;\n\n    int srcW, srcH, dstW, dstH;\n\n    int flags;\n\n\n\n    for (srcFormat = 0; srcFormat < PIX_FMT_NB; srcFormat++) {\n\n        for (dstFormat = 0; dstFormat < PIX_FMT_NB; dstFormat++) {\n\n            printf(\"%s -> %s\\n\",\n\n                   sws_format_name(srcFormat),\n\n                   sws_format_name(dstFormat));\n\n            fflush(stdout);\n\n\n\n            srcW= w;\n\n            srcH= h;\n\n            for (dstW=w - w/3; dstW<= 4*w/3; dstW+= w/3){\n\n                for (dstH=h - h/3; dstH<= 4*h/3; dstH+= h/3){\n\n                    for (flags=1; flags<33; flags*=2) {\n\n                        int res;\n\n\n\n                        res = doTest(src, stride, w, h, srcFormat, dstFormat,\n\n                                     srcW, srcH, dstW, dstH, flags);\n\n                        if (res < 0) {\n\n                            dstW = 4 * w / 3;\n\n                            dstH = 4 * h / 3;\n\n                            flags = 33;\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 26201}
{"project": "FFmpeg", "commit_id": "7b05b5093ea67a3397b0c37cf398bab471e1ce2b", "target": 1, "func": "void ff_eac3_apply_spectral_extension(AC3DecodeContext *s)\n\n{\n\n    int bin, bnd, ch, i;\n\n    uint8_t wrapflag[SPX_MAX_BANDS]={1,0,}, num_copy_sections, copy_sizes[SPX_MAX_BANDS];\n\n    float rms_energy[SPX_MAX_BANDS];\n\n\n\n    /* Set copy index mapping table. Set wrap flags to apply a notch filter at\n\n       wrap points later on. */\n\n    bin = s->spx_dst_start_freq;\n\n    num_copy_sections = 0;\n\n    for (bnd = 0; bnd < s->num_spx_bands; bnd++) {\n\n        int copysize;\n\n        int bandsize = s->spx_band_sizes[bnd];\n\n        if (bin + bandsize > s->spx_src_start_freq) {\n\n            copy_sizes[num_copy_sections++] = bin - s->spx_dst_start_freq;\n\n            bin = s->spx_dst_start_freq;\n\n            wrapflag[bnd] = 1;\n\n        }\n\n        for (i = 0; i < bandsize; i += copysize) {\n\n            if (bin == s->spx_src_start_freq) {\n\n                copy_sizes[num_copy_sections++] = bin - s->spx_dst_start_freq;\n\n                bin = s->spx_dst_start_freq;\n\n            }\n\n            copysize = FFMIN(bandsize - i, s->spx_src_start_freq - bin);\n\n            bin += copysize;\n\n        }\n\n    }\n\n    copy_sizes[num_copy_sections++] = bin - s->spx_dst_start_freq;\n\n\n\n    for (ch = 1; ch <= s->fbw_channels; ch++) {\n\n        if (!s->channel_uses_spx[ch])\n\n            continue;\n\n\n\n        /* Copy coeffs from normal bands to extension bands */\n\n        bin = s->spx_src_start_freq;\n\n        for (i = 0; i < num_copy_sections; i++) {\n\n            memcpy(&s->transform_coeffs[ch][bin],\n\n                   &s->transform_coeffs[ch][s->spx_dst_start_freq],\n\n                   copy_sizes[i]*sizeof(float));\n\n            bin += copy_sizes[i];\n\n        }\n\n\n\n        /* Calculate RMS energy for each SPX band. */\n\n        bin = s->spx_src_start_freq;\n\n        for (bnd = 0; bnd < s->num_spx_bands; bnd++) {\n\n            int bandsize = s->spx_band_sizes[bnd];\n\n            float accum = 0.0f;\n\n            for (i = 0; i < bandsize; i++) {\n\n                float coeff = s->transform_coeffs[ch][bin++];\n\n                accum += coeff * coeff;\n\n            }\n\n            rms_energy[bnd] = sqrtf(accum / bandsize);\n\n        }\n\n\n\n        /* Apply a notch filter at transitions between normal and extension\n\n           bands and at all wrap points. */\n\n        if (s->spx_atten_code[ch] >= 0) {\n\n            const float *atten_tab = ff_eac3_spx_atten_tab[s->spx_atten_code[ch]];\n\n            bin = s->spx_src_start_freq - 2;\n\n            for (bnd = 0; bnd < s->num_spx_bands; bnd++) {\n\n                if (wrapflag[bnd]) {\n\n                    float *coeffs = &s->transform_coeffs[ch][bin];\n\n                    coeffs[0] *= atten_tab[0];\n\n                    coeffs[1] *= atten_tab[1];\n\n                    coeffs[2] *= atten_tab[2];\n\n                    coeffs[3] *= atten_tab[1];\n\n                    coeffs[4] *= atten_tab[0];\n\n                }\n\n                bin += s->spx_band_sizes[bnd];\n\n            }\n\n        }\n\n\n\n        /* Apply noise-blended coefficient scaling based on previously\n\n           calculated RMS energy, blending factors, and SPX coordinates for\n\n           each band. */\n\n        bin = s->spx_src_start_freq;\n\n        for (bnd = 0; bnd < s->num_spx_bands; bnd++) {\n\n            float nscale = s->spx_noise_blend[ch][bnd] * rms_energy[bnd] * (1.0f / INT32_MIN);\n\n            float sscale = s->spx_signal_blend[ch][bnd];\n\n            for (i = 0; i < s->spx_band_sizes[bnd]; i++) {\n\n                float noise  = nscale * (int32_t)av_lfg_get(&s->dith_state);\n\n                s->transform_coeffs[ch][bin]   *= sscale;\n\n                s->transform_coeffs[ch][bin++] += noise;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 26211}
{"project": "FFmpeg", "commit_id": "ff17c76e92cd9a9072a8771cad73c96cd620040b", "target": 1, "func": "static int add_crc_to_array(uint32_t crc, int64_t pts)\n\n{\n\n    if (size_of_array <= number_of_elements) {\n\n        if (size_of_array == 0)\n\n            size_of_array = 10;\n\n        size_of_array *= 2;\n\n        crc_array = av_realloc(crc_array, size_of_array * sizeof(uint32_t));\n\n        pts_array = av_realloc(pts_array, size_of_array * sizeof(int64_t));\n\n        if ((crc_array == NULL) || (pts_array == NULL)) {\n\n            av_log(NULL, AV_LOG_ERROR, \"Can't allocate array to store crcs\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n    }\n\n    crc_array[number_of_elements] = crc;\n\n    pts_array[number_of_elements] = pts;\n\n    number_of_elements++;\n\n    return 0;\n\n}\n", "idx": 26212}
{"project": "FFmpeg", "commit_id": "5b4da8a38a5ed211df9504c85ce401c30af86b97", "target": 0, "func": "static av_cold void init_mv_penalty_and_fcode(MpegEncContext *s)\n\n{\n\n    int f_code;\n\n    int mv;\n\n\n\n    for(f_code=1; f_code<=MAX_FCODE; f_code++){\n\n        for(mv=-MAX_MV; mv<=MAX_MV; mv++){\n\n            int len;\n\n\n\n            if(mv==0) len= ff_mvtab[0][1];\n\n            else{\n\n                int val, bit_size, code;\n\n\n\n                bit_size = f_code - 1;\n\n\n\n                val=mv;\n\n                if (val < 0)\n\n                    val = -val;\n\n                val--;\n\n                code = (val >> bit_size) + 1;\n\n                if(code<33){\n\n                    len= ff_mvtab[code][1] + 1 + bit_size;\n\n                }else{\n\n                    len= ff_mvtab[32][1] + av_log2(code>>5) + 2 + bit_size;\n\n                }\n\n            }\n\n\n\n            mv_penalty[f_code][mv+MAX_MV]= len;\n\n        }\n\n    }\n\n\n\n    for(f_code=MAX_FCODE; f_code>0; f_code--){\n\n        for(mv=-(16<<f_code); mv<(16<<f_code); mv++){\n\n            fcode_tab[mv+MAX_MV]= f_code;\n\n        }\n\n    }\n\n\n\n    for(mv=0; mv<MAX_MV*2+1; mv++){\n\n        umv_fcode_tab[mv]= 1;\n\n    }\n\n}\n", "idx": 26214}
{"project": "FFmpeg", "commit_id": "ddf1b4a2f8a680126eb611428e4f47e6e5b8c6c0", "target": 0, "func": "static av_always_inline int setup_classifs(vorbis_context *vc,\n\n                                           vorbis_residue *vr,\n\n                                           uint8_t *do_not_decode,\n\n                                           unsigned ch_used,\n\n                                           int partition_count)\n\n{\n\n    int p, j, i;\n\n    unsigned c_p_c         = vc->codebooks[vr->classbook].dimensions;\n\n    unsigned inverse_class = ff_inverse[vr->classifications];\n\n    unsigned temp, temp2;\n\n    for (p = 0, j = 0; j < ch_used; ++j) {\n\n        if (!do_not_decode[j]) {\n\n            temp = get_vlc2(&vc->gb, vc->codebooks[vr->classbook].vlc.table,\n\n                                     vc->codebooks[vr->classbook].nb_bits, 3);\n\n\n\n            av_dlog(NULL, \"Classword: %u\\n\", temp);\n\n\n\n            assert(vr->classifications > 1 && temp <= 65536); //needed for inverse[]\n\n\n\n            for (i = 0; i < c_p_c; ++i) {\n\n                temp2 = (((uint64_t)temp) * inverse_class) >> 32;\n\n                if (partition_count + c_p_c - 1 - i < vr->ptns_to_read)\n\n                    vr->classifs[p + partition_count + c_p_c - 1 - i] =\n\n                        temp - temp2 * vr->classifications;\n\n                temp = temp2;\n\n            }\n\n        }\n\n        p += vr->ptns_to_read;\n\n    }\n\n    return 0;\n\n}\n", "idx": 26215}
{"project": "FFmpeg", "commit_id": "ee9f36a88eb3e2706ea659acb0ca80c414fa5d8a", "target": 0, "func": "static uint32_t adler32(uint32_t adler, const uint8_t *buf, unsigned int len)\n\n{\n\n    unsigned long s1 = adler & 0xffff;\n\n    unsigned long s2 = (adler >> 16) & 0xffff;\n\n    int k;\n\n\n\n    if (buf == NULL) return 1L;\n\n\n\n    while (len > 0) {\n\n        k = len < NMAX ? len : NMAX;\n\n        len -= k;\n\n        while (k >= 16) {\n\n            DO16(buf);\n\n            k -= 16;\n\n        }\n\n        if (k != 0) do {\n\n            DO1(buf);\n\n        } while (--k);\n\n        s1 %= BASE;\n\n        s2 %= BASE;\n\n    }\n\n    return (s2 << 16) | s1;\n\n}\n", "idx": 26219}
{"project": "FFmpeg", "commit_id": "dca2fa10d37022684c61166be59294c9f98530d4", "target": 0, "func": "static int mc_subpel(DiracContext *s, DiracBlock *block, const uint8_t *src[5],\n\n                     int x, int y, int ref, int plane)\n\n{\n\n    Plane *p = &s->plane[plane];\n\n    uint8_t **ref_hpel = s->ref_pics[ref]->hpel[plane];\n\n    int motion_x = block->u.mv[ref][0];\n\n    int motion_y = block->u.mv[ref][1];\n\n    int mx, my, i, epel, nplanes = 0;\n\n\n\n    if (plane) {\n\n        motion_x >>= s->chroma_x_shift;\n\n        motion_y >>= s->chroma_y_shift;\n\n    }\n\n\n\n    mx         = motion_x & ~(-1 << s->mv_precision);\n\n    my         = motion_y & ~(-1 << s->mv_precision);\n\n    motion_x >>= s->mv_precision;\n\n    motion_y >>= s->mv_precision;\n\n    /* normalize subpel coordinates to epel */\n\n    /* TODO: template this function? */\n\n    mx      <<= 3 - s->mv_precision;\n\n    my      <<= 3 - s->mv_precision;\n\n\n\n    x += motion_x;\n\n    y += motion_y;\n\n    epel = (mx|my)&1;\n\n\n\n    /* hpel position */\n\n    if (!((mx|my)&3)) {\n\n        nplanes = 1;\n\n        src[0] = ref_hpel[(my>>1)+(mx>>2)] + y*p->stride + x;\n\n    } else {\n\n        /* qpel or epel */\n\n        nplanes = 4;\n\n        for (i = 0; i < 4; i++)\n\n            src[i] = ref_hpel[i] + y*p->stride + x;\n\n\n\n        /* if we're interpolating in the right/bottom halves, adjust the planes as needed\n\n           we increment x/y because the edge changes for half of the pixels */\n\n        if (mx > 4) {\n\n            src[0] += 1;\n\n            src[2] += 1;\n\n            x++;\n\n        }\n\n        if (my > 4) {\n\n            src[0] += p->stride;\n\n            src[1] += p->stride;\n\n            y++;\n\n        }\n\n\n\n        /* hpel planes are:\n\n           [0]: F  [1]: H\n\n           [2]: V  [3]: C */\n\n        if (!epel) {\n\n            /* check if we really only need 2 planes since either mx or my is\n\n               a hpel position. (epel weights of 0 handle this there) */\n\n            if (!(mx&3)) {\n\n                /* mx == 0: average [0] and [2]\n\n                   mx == 4: average [1] and [3] */\n\n                src[!mx] = src[2 + !!mx];\n\n                nplanes = 2;\n\n            } else if (!(my&3)) {\n\n                src[0] = src[(my>>1)  ];\n\n                src[1] = src[(my>>1)+1];\n\n                nplanes = 2;\n\n            }\n\n        } else {\n\n            /* adjust the ordering if needed so the weights work */\n\n            if (mx > 4) {\n\n                FFSWAP(const uint8_t *, src[0], src[1]);\n\n                FFSWAP(const uint8_t *, src[2], src[3]);\n\n            }\n\n            if (my > 4) {\n\n                FFSWAP(const uint8_t *, src[0], src[2]);\n\n                FFSWAP(const uint8_t *, src[1], src[3]);\n\n            }\n\n            src[4] = epel_weights[my&3][mx&3];\n\n        }\n\n    }\n\n\n\n    /* fixme: v/h _edge_pos */\n\n    if ((unsigned)x > p->width +EDGE_WIDTH/2 - p->xblen ||\n\n        (unsigned)y > p->height+EDGE_WIDTH/2 - p->yblen) {\n\n        for (i = 0; i < nplanes; i++) {\n\n            ff_emulated_edge_mc(s->edge_emu_buffer[i], src[i], p->stride,\n\n                                p->xblen, p->yblen, x, y,\n\n                                p->width+EDGE_WIDTH/2, p->height+EDGE_WIDTH/2);\n\n            src[i] = s->edge_emu_buffer[i];\n\n        }\n\n    }\n\n    return (nplanes>>1) + epel;\n\n}\n", "idx": 26230}
{"project": "FFmpeg", "commit_id": "041086191fc08ab162ad6117b07a5f39639d5d9d", "target": 0, "func": "void event_loop(void)\n\n{\n\n    SDL_Event event;\n\n    double incr, pos, frac;\n\n\n\n    for(;;) {\n\n        SDL_WaitEvent(&event);\n\n        switch(event.type) {\n\n        case SDL_KEYDOWN:\n\n            switch(event.key.keysym.sym) {\n\n            case SDLK_ESCAPE:\n\n            case SDLK_q:\n\n                do_exit();\n\n                break;\n\n            case SDLK_f:\n\n                toggle_full_screen();\n\n                break;\n\n            case SDLK_p:\n\n            case SDLK_SPACE:\n\n                toggle_pause();\n\n                break;\n\n            case SDLK_s: //S: Step to next frame\n\n                step_to_next_frame();\n\n                break;\n\n            case SDLK_a:\n\n                if (cur_stream) \n\n                    stream_cycle_channel(cur_stream, CODEC_TYPE_AUDIO);\n\n                break;\n\n            case SDLK_v:\n\n                if (cur_stream) \n\n                    stream_cycle_channel(cur_stream, CODEC_TYPE_VIDEO);\n\n                break;\n\n            case SDLK_w:\n\n                toggle_audio_display();\n\n                break;\n\n            case SDLK_LEFT:\n\n                incr = -10.0;\n\n                goto do_seek;\n\n            case SDLK_RIGHT:\n\n                incr = 10.0;\n\n                goto do_seek;\n\n            case SDLK_UP:\n\n                incr = 60.0;\n\n                goto do_seek;\n\n            case SDLK_DOWN:\n\n                incr = -60.0;\n\n            do_seek:\n\n                if (cur_stream) {\n\n                    pos = get_master_clock(cur_stream);\n\nprintf(\"%f %f %d %d %d %d\\n\", (float)pos, (float)incr, cur_stream->av_sync_type == AV_SYNC_VIDEO_MASTER, \n\ncur_stream->av_sync_type == AV_SYNC_AUDIO_MASTER, cur_stream->video_st, cur_stream->audio_st);\n\n                    pos += incr;\n\n                    stream_seek(cur_stream, (int64_t)(pos * AV_TIME_BASE));\n\n                }\n\n                break;\n\n            default:\n\n                break;\n\n            }\n\n            break;\n\n        case SDL_MOUSEBUTTONDOWN:\n\n\t    if (cur_stream) {\n\n\t\tint ns, hh, mm, ss;\n\n\t\tint tns, thh, tmm, tss;\n\n\t\ttns = cur_stream->ic->duration/1000000LL;\n\n\t\tthh = tns/3600;\n\n\t\ttmm = (tns%3600)/60;\n\n\t\ttss = (tns%60);\n\n\t\tfrac = (double)event.button.x/(double)cur_stream->width;\n\n\t\tns = frac*tns;\n\n\t\thh = ns/3600;\n\n\t\tmm = (ns%3600)/60;\n\n\t\tss = (ns%60);\n\n\t\tfprintf(stderr, \"Seek to %2.0f%% (%2d:%02d:%02d) of total duration (%2d:%02d:%02d)       \\n\", frac*100,\n\n\t\t\thh, mm, ss, thh, tmm, tss);\n\n\t\tstream_seek(cur_stream, (int64_t)(cur_stream->ic->start_time+frac*cur_stream->ic->duration));\n\n\t    }\n\n\t    break;\n\n        case SDL_VIDEORESIZE:\n\n            if (cur_stream) {\n\n                screen = SDL_SetVideoMode(event.resize.w, event.resize.h, 0, \n\n                                          SDL_HWSURFACE|SDL_RESIZABLE|SDL_ASYNCBLIT|SDL_HWACCEL);\n\n                cur_stream->width = event.resize.w;\n\n                cur_stream->height = event.resize.h;\n\n            }\n\n            break;\n\n        case SDL_QUIT:\n\n        case FF_QUIT_EVENT:\n\n            do_exit();\n\n            break;\n\n        case FF_ALLOC_EVENT:\n\n            alloc_picture(event.user.data1);\n\n            break;\n\n        case FF_REFRESH_EVENT:\n\n            video_refresh_timer(event.user.data1);\n\n            break;\n\n        default:\n\n            break;\n\n        }\n\n    }\n\n}\n", "idx": 26231}
{"project": "FFmpeg", "commit_id": "565e0c6d866ce08d4b06427456d3d1f4fd856e9c", "target": 0, "func": "static int mov_write_ilst_tag(AVIOContext *pb, MOVMuxContext *mov,\n\n                              AVFormatContext *s)\n\n{\n\n    int64_t pos = avio_tell(pb);\n\n    avio_wb32(pb, 0); /* size */\n\n    ffio_wfourcc(pb, \"ilst\");\n\n    mov_write_string_metadata(s, pb, \"\\251nam\", \"title\"    , 1);\n\n    mov_write_string_metadata(s, pb, \"\\251ART\", \"artist\"   , 1);\n\n    mov_write_string_metadata(s, pb, \"aART\", \"album_artist\", 1);\n\n    mov_write_string_metadata(s, pb, \"\\251wrt\", \"composer\" , 1);\n\n    mov_write_string_metadata(s, pb, \"\\251alb\", \"album\"    , 1);\n\n    mov_write_string_metadata(s, pb, \"\\251day\", \"date\"     , 1);\n\n    mov_write_string_tag(pb, \"\\251too\", LIBAVFORMAT_IDENT, 0, 1);\n\n    mov_write_string_metadata(s, pb, \"\\251cmt\", \"comment\"  , 1);\n\n    mov_write_string_metadata(s, pb, \"\\251gen\", \"genre\"    , 1);\n\n    mov_write_string_metadata(s, pb, \"\\251cpy\", \"copyright\", 1);\n\n    mov_write_string_metadata(s, pb, \"\\251grp\", \"grouping\" , 1);\n\n    mov_write_string_metadata(s, pb, \"\\251lyr\", \"lyrics\"   , 1);\n\n    mov_write_string_metadata(s, pb, \"desc\",    \"description\",1);\n\n    mov_write_string_metadata(s, pb, \"ldes\",    \"synopsis\" , 1);\n\n    mov_write_string_metadata(s, pb, \"tvsh\",    \"show\"     , 1);\n\n    mov_write_string_metadata(s, pb, \"tven\",    \"episode_id\",1);\n\n    mov_write_string_metadata(s, pb, \"tvnn\",    \"network\"  , 1);\n\n    mov_write_trkn_tag(pb, mov, s);\n\n    return update_size(pb, pos);\n\n}\n", "idx": 26235}
{"project": "FFmpeg", "commit_id": "0b54f3c0878a3acaa9142e4f24942e762d97e350", "target": 1, "func": "static int gif_read_close(AVFormatContext *s1)\n\n{\n\n    GifState *s = s1->priv_data;\n\n    av_free(s->image_buf);\n\n    return 0;\n\n}\n", "idx": 26236}
{"project": "FFmpeg", "commit_id": "2c046c718aefbc9f8223e22f85bb119da4fea04d", "target": 1, "func": "static int pnm_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf   = avpkt->data;\n\n    int buf_size         = avpkt->size;\n\n    PNMContext * const s = avctx->priv_data;\n\n    AVFrame * const p    = data;\n\n    int i, j, n, linesize, h, upgrade = 0, is_mono = 0;\n\n    unsigned char *ptr;\n\n    int components, sample_len, ret;\n\n    unsigned int maskval = 0;\n\n\n\n    s->bytestream_start =\n\n    s->bytestream       = (uint8_t *)buf;\n\n    s->bytestream_end   = (uint8_t *)buf + buf_size;\n\n\n\n    if ((ret = ff_pnm_decode_header(avctx, s)) < 0)\n\n        return ret;\n\n\n\n    if ((ret = ff_get_buffer(avctx, p, 0)) < 0)\n\n        return ret;\n\n    p->pict_type = AV_PICTURE_TYPE_I;\n\n    p->key_frame = 1;\n\n\n\n    switch (avctx->pix_fmt) {\n\n    default:\n\n        return AVERROR(EINVAL);\n\n    case AV_PIX_FMT_RGBA64BE:\n\n        n = avctx->width * 8;\n\n        components=4;\n\n        sample_len=16;\n\n        goto do_read;\n\n    case AV_PIX_FMT_RGB48BE:\n\n        n = avctx->width * 6;\n\n        components=3;\n\n        sample_len=16;\n\n        goto do_read;\n\n    case AV_PIX_FMT_RGBA:\n\n        n = avctx->width * 4;\n\n        components=4;\n\n        sample_len=8;\n\n        goto do_read;\n\n    case AV_PIX_FMT_RGB24:\n\n        n = avctx->width * 3;\n\n        components=3;\n\n        sample_len=8;\n\n        goto do_read;\n\n    case AV_PIX_FMT_GRAY8:\n\n        n = avctx->width;\n\n        components=1;\n\n        sample_len=8;\n\n        if (s->maxval < 255) {\n\n            upgrade = 1;\n\n            maskval = (2 << av_log2(s->maxval)) - 1;\n\n        }\n\n        goto do_read;\n\n    case AV_PIX_FMT_GRAY8A:\n\n        n = avctx->width * 2;\n\n        components=2;\n\n        sample_len=8;\n\n        goto do_read;\n\n    case AV_PIX_FMT_GRAY16BE:\n\n    case AV_PIX_FMT_GRAY16LE:\n\n        n = avctx->width * 2;\n\n        components=1;\n\n        sample_len=16;\n\n        if (s->maxval < 65535) {\n\n            upgrade = 2;\n\n            maskval = (2 << av_log2(s->maxval)) - 1;\n\n        }\n\n        goto do_read;\n\n    case AV_PIX_FMT_MONOWHITE:\n\n    case AV_PIX_FMT_MONOBLACK:\n\n        n = (avctx->width + 7) >> 3;\n\n        components=1;\n\n        sample_len=1;\n\n        is_mono = 1;\n\n    do_read:\n\n        ptr      = p->data[0];\n\n        linesize = p->linesize[0];\n\n        if (s->bytestream + n * avctx->height > s->bytestream_end)\n\n            return AVERROR_INVALIDDATA;\n\n        if(s->type < 4 || (is_mono && s->type==7)){\n\n            for (i=0; i<avctx->height; i++) {\n\n                PutBitContext pb;\n\n                init_put_bits(&pb, ptr, linesize);\n\n                for(j=0; j<avctx->width * components; j++){\n\n                    unsigned int c=0;\n\n                    int v=0;\n\n                    if(s->type < 4)\n\n                    while(s->bytestream < s->bytestream_end && (*s->bytestream < '0' || *s->bytestream > '9' ))\n\n                        s->bytestream++;\n\n                    if(s->bytestream >= s->bytestream_end)\n\n                        return AVERROR_INVALIDDATA;\n\n                    if (is_mono) {\n\n                        /* read a single digit */\n\n                        v = (*s->bytestream++)&1;\n\n                    } else {\n\n                        /* read a sequence of digits */\n\n                        do {\n\n                            v = 10*v + c;\n\n                            c = (*s->bytestream++) - '0';\n\n                        } while (c <= 9);\n\n                    }\n\n                    put_bits(&pb, sample_len, (((1<<sample_len)-1)*v + (s->maxval>>1))/s->maxval);\n\n                }\n\n                flush_put_bits(&pb);\n\n                ptr+= linesize;\n\n            }\n\n        }else{\n\n        for (i = 0; i < avctx->height; i++) {\n\n            if (!upgrade)\n\n                memcpy(ptr, s->bytestream, n);\n\n            else if (upgrade == 1) {\n\n                unsigned int j, f = (255 * 128 + s->maxval / 2) / s->maxval;\n\n                for (j = 0; j < n; j++)\n\n                    ptr[j] = ((s->bytestream[j] & maskval) * f + 64) >> 7;\n\n            } else if (upgrade == 2) {\n\n                unsigned int j, v, f = (65535 * 32768 + s->maxval / 2) / s->maxval;\n\n                for (j = 0; j < n / 2; j++) {\n\n                    v = av_be2ne16(((uint16_t *)s->bytestream)[j]) & maskval;\n\n                    ((uint16_t *)ptr)[j] = (v * f + 16384) >> 15;\n\n                }\n\n            }\n\n            s->bytestream += n;\n\n            ptr           += linesize;\n\n        }\n\n        }\n\n        break;\n\n    case AV_PIX_FMT_YUV420P:\n\n    case AV_PIX_FMT_YUV420P9BE:\n\n    case AV_PIX_FMT_YUV420P10BE:\n\n        {\n\n            unsigned char *ptr1, *ptr2;\n\n\n\n            n        = avctx->width;\n\n            ptr      = p->data[0];\n\n            linesize = p->linesize[0];\n\n            if (s->maxval >= 256)\n\n                n *= 2;\n\n            if (s->bytestream + n * avctx->height * 3 / 2 > s->bytestream_end)\n\n                return AVERROR_INVALIDDATA;\n\n            for (i = 0; i < avctx->height; i++) {\n\n                memcpy(ptr, s->bytestream, n);\n\n                s->bytestream += n;\n\n                ptr           += linesize;\n\n            }\n\n            ptr1 = p->data[1];\n\n            ptr2 = p->data[2];\n\n            n >>= 1;\n\n            h = avctx->height >> 1;\n\n            for (i = 0; i < h; i++) {\n\n                memcpy(ptr1, s->bytestream, n);\n\n                s->bytestream += n;\n\n                memcpy(ptr2, s->bytestream, n);\n\n                s->bytestream += n;\n\n                ptr1 += p->linesize[1];\n\n                ptr2 += p->linesize[2];\n\n            }\n\n        }\n\n        break;\n\n    case AV_PIX_FMT_YUV420P16:\n\n        {\n\n            uint16_t *ptr1, *ptr2;\n\n            const int f = (65535 * 32768 + s->maxval / 2) / s->maxval;\n\n            unsigned int j, v;\n\n\n\n            n        = avctx->width * 2;\n\n            ptr      = p->data[0];\n\n            linesize = p->linesize[0];\n\n            if (s->bytestream + n * avctx->height * 3 / 2 > s->bytestream_end)\n\n                return AVERROR_INVALIDDATA;\n\n            for (i = 0; i < avctx->height; i++) {\n\n                for (j = 0; j < n / 2; j++) {\n\n                    v = av_be2ne16(((uint16_t *)s->bytestream)[j]);\n\n                    ((uint16_t *)ptr)[j] = (v * f + 16384) >> 15;\n\n                }\n\n                s->bytestream += n;\n\n                ptr           += linesize;\n\n            }\n\n            ptr1 = (uint16_t*)p->data[1];\n\n            ptr2 = (uint16_t*)p->data[2];\n\n            n >>= 1;\n\n            h = avctx->height >> 1;\n\n            for (i = 0; i < h; i++) {\n\n                for (j = 0; j < n / 2; j++) {\n\n                    v = av_be2ne16(((uint16_t *)s->bytestream)[j]);\n\n                    ptr1[j] = (v * f + 16384) >> 15;\n\n                }\n\n                s->bytestream += n;\n\n\n\n                for (j = 0; j < n / 2; j++) {\n\n                    v = av_be2ne16(((uint16_t *)s->bytestream)[j]);\n\n                    ptr2[j] = (v * f + 16384) >> 15;\n\n                }\n\n                s->bytestream += n;\n\n\n\n                ptr1 += p->linesize[1] / 2;\n\n                ptr2 += p->linesize[2] / 2;\n\n            }\n\n        }\n\n        break;\n\n    }\n\n    *got_frame = 1;\n\n\n\n    return s->bytestream - s->bytestream_start;\n\n}\n", "idx": 26240}
{"project": "FFmpeg", "commit_id": "0cf3505930913d3584b215f6912de04ff41366e0", "target": 0, "func": "int ff_audio_mix_get_matrix(AudioMix *am, double *matrix, int stride)\n\n{\n\n    int i, o;\n\n\n\n    if ( am->in_channels <= 0 ||  am->in_channels > AVRESAMPLE_MAX_CHANNELS ||\n\n        am->out_channels <= 0 || am->out_channels > AVRESAMPLE_MAX_CHANNELS) {\n\n        av_log(am, AV_LOG_ERROR, \"Invalid channel counts\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n#define GET_MATRIX_CONVERT(suffix, scale)                                   \\\n\n    if (!am->matrix_ ## suffix[0]) {                                        \\\n\n        av_log(am, AV_LOG_ERROR, \"matrix is not set\\n\");                    \\\n\n        return AVERROR(EINVAL);                                             \\\n\n    }                                                                       \\\n\n    for (o = 0; o < am->out_channels; o++)                                  \\\n\n        for (i = 0; i < am->in_channels; i++)                               \\\n\n            matrix[o * stride + i] = am->matrix_ ## suffix[o][i] * (scale);\n\n\n\n    switch (am->coeff_type) {\n\n    case AV_MIX_COEFF_TYPE_Q8:\n\n        GET_MATRIX_CONVERT(q8, 1.0 / 256.0);\n\n        break;\n\n    case AV_MIX_COEFF_TYPE_Q15:\n\n        GET_MATRIX_CONVERT(q15, 1.0 / 32768.0);\n\n        break;\n\n    case AV_MIX_COEFF_TYPE_FLT:\n\n        GET_MATRIX_CONVERT(flt, 1.0);\n\n        break;\n\n    default:\n\n        av_log(am, AV_LOG_ERROR, \"Invalid mix coeff type\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26249}
{"project": "FFmpeg", "commit_id": "aff01de6415f1ba022f1a58e354ad6e4d0796e97", "target": 0, "func": "static int link_filter_inouts(AVFilterContext *filt_ctx,\n\n                              AVFilterInOut **curr_inputs,\n\n                              AVFilterInOut **open_inputs, void *log_ctx)\n\n{\n\n    int pad, ret;\n\n\n\n    for (pad = 0; pad < filt_ctx->input_count; pad++) {\n\n        AVFilterInOut *p = *curr_inputs;\n\n\n\n        if (p)\n\n            *curr_inputs = (*curr_inputs)->next;\n\n        else if (!(p = av_mallocz(sizeof(*p))))\n\n            return AVERROR(ENOMEM);\n\n\n\n        if (p->filter_ctx) {\n\n            if ((ret = link_filter(p->filter_ctx, p->pad_idx, filt_ctx, pad, log_ctx)) < 0)\n\n                return ret;\n\n            av_free(p->name);\n\n            av_free(p);\n\n        } else {\n\n            p->filter_ctx = filt_ctx;\n\n            p->pad_idx = pad;\n\n            append_inout(open_inputs, &p);\n\n        }\n\n    }\n\n\n\n    if (*curr_inputs) {\n\n        av_log(log_ctx, AV_LOG_ERROR,\n\n               \"Too many inputs specified for the \\\"%s\\\" filter.\\n\",\n\n               filt_ctx->filter->name);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    pad = filt_ctx->output_count;\n\n    while (pad--) {\n\n        AVFilterInOut *currlinkn = av_mallocz(sizeof(AVFilterInOut));\n\n        if (!currlinkn)\n\n            return AVERROR(ENOMEM);\n\n        currlinkn->filter_ctx  = filt_ctx;\n\n        currlinkn->pad_idx = pad;\n\n        insert_inout(curr_inputs, currlinkn);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26262}
{"project": "FFmpeg", "commit_id": "6260ab60a80fd8baebf79f9ce9299b0db72333b5", "target": 0, "func": "static void blend_image_rgba(AVFilterContext *ctx, AVFrame *dst, const AVFrame *src, int x, int y)\n\n{\n\n    blend_image_packed_rgb(ctx, dst, src, 1, x, y, 0);\n\n}\n", "idx": 26273}
{"project": "FFmpeg", "commit_id": "9bcbb250e23959075765edd3cb4c1fcb46736d7d", "target": 0, "func": "static inline void RENAME(yuv2yuv1)(SwsContext *c, const int16_t *lumSrc,\n\n                                    const int16_t *chrUSrc, const int16_t *chrVSrc,\n\n                                    const int16_t *alpSrc,\n\n                                    uint8_t *dest, uint8_t *uDest, uint8_t *vDest,\n\n                                    uint8_t *aDest, int dstW, int chrDstW)\n\n{\n\n    int p= 4;\n\n    const uint8_t *src[4]= { alpSrc + dstW, lumSrc + dstW, chrUSrc + chrDstW, chrVSrc + chrDstW };\n\n    uint8_t *dst[4]= { aDest, dest, uDest, vDest };\n\n    x86_reg counter[4]= { dstW, dstW, chrDstW, chrDstW };\n\n\n\n    while (p--) {\n\n        if (dst[p]) {\n\n            __asm__ volatile(\n\n                \"mov %2, %%\"REG_a\"                    \\n\\t\"\n\n                \".p2align               4             \\n\\t\" /* FIXME Unroll? */\n\n                \"1:                                   \\n\\t\"\n\n                \"movq  (%0, %%\"REG_a\", 2), %%mm0      \\n\\t\"\n\n                \"movq 8(%0, %%\"REG_a\", 2), %%mm1      \\n\\t\"\n\n                \"psraw                 $7, %%mm0      \\n\\t\"\n\n                \"psraw                 $7, %%mm1      \\n\\t\"\n\n                \"packuswb           %%mm1, %%mm0      \\n\\t\"\n\n                MOVNTQ(%%mm0, (%1, %%REGa))\n\n                \"add                   $8, %%\"REG_a\"  \\n\\t\"\n\n                \"jnc                   1b             \\n\\t\"\n\n                :: \"r\" (src[p]), \"r\" (dst[p] + counter[p]),\n\n                   \"g\" (-counter[p])\n\n                : \"%\"REG_a\n\n            );\n\n        }\n\n    }\n\n}\n", "idx": 26280}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(rgb15to16)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n    register const uint8_t* s=src;\n\n    register uint8_t* d=dst;\n\n    register const uint8_t *end;\n\n    const uint8_t *mm_end;\n\n    end = s + src_size;\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*s));\n\n    __asm__ volatile(\"movq        %0, %%mm4\"::\"m\"(mask15s));\n\n    mm_end = end - 15;\n\n    while (s<mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"  32%1         \\n\\t\"\n\n            \"movq        %1, %%mm0  \\n\\t\"\n\n            \"movq       8%1, %%mm2  \\n\\t\"\n\n            \"movq     %%mm0, %%mm1  \\n\\t\"\n\n            \"movq     %%mm2, %%mm3  \\n\\t\"\n\n            \"pand     %%mm4, %%mm0  \\n\\t\"\n\n            \"pand     %%mm4, %%mm2  \\n\\t\"\n\n            \"paddw    %%mm1, %%mm0  \\n\\t\"\n\n            \"paddw    %%mm3, %%mm2  \\n\\t\"\n\n            MOVNTQ\"   %%mm0,  %0    \\n\\t\"\n\n            MOVNTQ\"   %%mm2, 8%0\"\n\n            :\"=m\"(*d)\n\n            :\"m\"(*s)\n\n        );\n\n        d+=16;\n\n        s+=16;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n#endif\n\n    mm_end = end - 3;\n\n    while (s < mm_end) {\n\n        register unsigned x= *((const uint32_t *)s);\n\n        *((uint32_t *)d) = (x&0x7FFF7FFF) + (x&0x7FE07FE0);\n\n        d+=4;\n\n        s+=4;\n\n    }\n\n    if (s < end) {\n\n        register unsigned short x= *((const uint16_t *)s);\n\n        *((uint16_t *)d) = (x&0x7FFF) + (x&0x7FE0);\n\n    }\n\n}\n", "idx": 26281}
{"project": "FFmpeg", "commit_id": "9bbf1a5c232cffb64e5f8cf071d1626cc0d033e1", "target": 1, "func": "void ff_vdpau_mpeg_picture_complete(MpegEncContext *s, const uint8_t *buf,\n                                    int buf_size, int slice_count)\n{\n    struct vdpau_render_state *render, *last, *next;\n    int i;\n    render = (struct vdpau_render_state *)s->current_picture_ptr->data[0];\n    assert(render);\n    /* fill VdpPictureInfoMPEG1Or2 struct */\n    render->info.mpeg.picture_structure          = s->picture_structure;\n    render->info.mpeg.picture_coding_type        = s->pict_type;\n    render->info.mpeg.intra_dc_precision         = s->intra_dc_precision;\n    render->info.mpeg.frame_pred_frame_dct       = s->frame_pred_frame_dct;\n    render->info.mpeg.concealment_motion_vectors = s->concealment_motion_vectors;\n    render->info.mpeg.intra_vlc_format           = s->intra_vlc_format;\n    render->info.mpeg.alternate_scan             = s->alternate_scan;\n    render->info.mpeg.q_scale_type               = s->q_scale_type;\n    render->info.mpeg.top_field_first            = s->top_field_first;\n    render->info.mpeg.full_pel_forward_vector    = s->full_pel[0]; // MPEG-1 only.  Set 0 for MPEG-2\n    render->info.mpeg.full_pel_backward_vector   = s->full_pel[1]; // MPEG-1 only.  Set 0 for MPEG-2\n    render->info.mpeg.f_code[0][0]               = s->mpeg_f_code[0][0]; // For MPEG-1 fill both horiz. & vert.\n    render->info.mpeg.f_code[0][1]               = s->mpeg_f_code[0][1];\n    render->info.mpeg.f_code[1][0]               = s->mpeg_f_code[1][0];\n    render->info.mpeg.f_code[1][1]               = s->mpeg_f_code[1][1];\n    for (i = 0; i < 64; ++i) {\n        render->info.mpeg.intra_quantizer_matrix[i]     = s->intra_matrix[i];\n        render->info.mpeg.non_intra_quantizer_matrix[i] = s->inter_matrix[i];\n    }\n    render->info.mpeg.forward_reference          = VDP_INVALID_HANDLE;\n    render->info.mpeg.backward_reference         = VDP_INVALID_HANDLE;\n    switch(s->pict_type){\n    case  FF_B_TYPE:\n        next = (struct vdpau_render_state *)s->next_picture.data[0];\n        assert(next);\n        render->info.mpeg.backward_reference     = next->surface;\n        // no return here, going to set forward prediction\n    case  FF_P_TYPE:\n        last = (struct vdpau_render_state *)s->last_picture.data[0];\n        if (!last) // FIXME: Does this test make sense?\n            last = render; // predict second field from the first\n        render->info.mpeg.forward_reference      = last->surface;\n    }\n    ff_vdpau_add_data_chunk(s, buf, buf_size);\n    render->info.mpeg.slice_count                = slice_count;\n    if (slice_count)\n        ff_draw_horiz_band(s, 0, s->avctx->height);\n    render->bitstream_buffers_used               = 0;\n}", "idx": 26283}
{"project": "FFmpeg", "commit_id": "bc9eb0467a52828d6be48de5e60f042bf3b62d1f", "target": 1, "func": "static int open_input_stream(HTTPContext *c, const char *info)\n\n{\n\n    char buf[128];\n\n    char input_filename[1024];\n\n    AVFormatContext *s = NULL;\n\n    int buf_size, i, ret;\n\n    int64_t stream_pos;\n\n\n\n    /* find file name */\n\n    if (c->stream->feed) {\n\n        strcpy(input_filename, c->stream->feed->feed_filename);\n\n        buf_size = FFM_PACKET_SIZE;\n\n        /* compute position (absolute time) */\n\n        if (av_find_info_tag(buf, sizeof(buf), \"date\", info)) {\n\n            if ((ret = av_parse_time(&stream_pos, buf, 0)) < 0) {\n\n                http_log(\"Invalid date specification '%s' for stream\\n\", buf);\n\n                return ret;\n\n            }\n\n        } else if (av_find_info_tag(buf, sizeof(buf), \"buffer\", info)) {\n\n            int prebuffer = strtol(buf, 0, 10);\n\n            stream_pos = av_gettime() - prebuffer * (int64_t)1000000;\n\n        } else\n\n            stream_pos = av_gettime() - c->stream->prebuffer * (int64_t)1000;\n\n    } else {\n\n        strcpy(input_filename, c->stream->feed_filename);\n\n        buf_size = 0;\n\n        /* compute position (relative time) */\n\n        if (av_find_info_tag(buf, sizeof(buf), \"date\", info)) {\n\n            if ((ret = av_parse_time(&stream_pos, buf, 1)) < 0) {\n\n                http_log(\"Invalid date specification '%s' for stream\\n\", buf);\n\n                return ret;\n\n            }\n\n        } else\n\n            stream_pos = 0;\n\n    }\n\n    if (!input_filename[0]) {\n\n        http_log(\"No filename was specified for stream\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    /* open stream */\n\n    ret = avformat_open_input(&s, input_filename, c->stream->ifmt,\n\n                              &c->stream->in_opts);\n\n    if (ret < 0) {\n\n        http_log(\"Could not open input '%s': %s\\n\",\n\n                 input_filename, av_err2str(ret));\n\n        return ret;\n\n    }\n\n\n\n    /* set buffer size */\n\n    if (buf_size > 0) {\n\n        ret = ffio_set_buf_size(s->pb, buf_size);\n\n        if (ret < 0) {\n\n            http_log(\"Failed to set buffer size\\n\");\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    s->flags |= AVFMT_FLAG_GENPTS;\n\n    c->fmt_in = s;\n\n    if (strcmp(s->iformat->name, \"ffm\") &&\n\n        (ret = avformat_find_stream_info(c->fmt_in, NULL)) < 0) {\n\n        http_log(\"Could not find stream info for input '%s'\\n\", input_filename);\n\n        avformat_close_input(&s);\n\n        return ret;\n\n    }\n\n\n\n    /* choose stream as clock source (we favor the video stream if\n\n     * present) for packet sending */\n\n    c->pts_stream_index = 0;\n\n    for(i=0;i<c->stream->nb_streams;i++) {\n\n        if (c->pts_stream_index == 0 &&\n\n            c->stream->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            c->pts_stream_index = i;\n\n        }\n\n    }\n\n\n\n    if (c->fmt_in->iformat->read_seek)\n\n        av_seek_frame(c->fmt_in, -1, stream_pos, 0);\n\n    /* set the start time (needed for maxtime and RTP packet timing) */\n\n    c->start_time = cur_time;\n\n    c->first_pts = AV_NOPTS_VALUE;\n\n    return 0;\n\n}\n", "idx": 26284}
{"project": "FFmpeg", "commit_id": "49cf36f4e3e9183611859af1a07dc6a82ab47288", "target": 1, "func": "static int decode_5(SANMVideoContext *ctx)\n\n{\n\n#if HAVE_BIGENDIAN\n\n    uint16_t *frm;\n\n    int npixels;\n\n#endif\n\n    uint8_t *dst = (uint8_t*)ctx->frm0;\n\n\n\n    if (rle_decode(ctx, dst, ctx->buf_size))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n#if HAVE_BIGENDIAN\n\n    npixels = ctx->npixels;\n\n    frm = ctx->frm0;\n\n    while (npixels--)\n\n        *frm++ = av_bswap16(*frm);\n\n#endif\n\n\n\n    return 0;\n\n}\n", "idx": 26294}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "static void vc1_inv_trans_4x8_c(uint8_t *dest, int linesize, DCTELEM *block)\n\n{\n\n    int i;\n\n    register int t1,t2,t3,t4,t5,t6,t7,t8;\n\n    DCTELEM *src, *dst;\n\n    const uint8_t *cm = ff_cropTbl + MAX_NEG_CROP;\n\n\n\n    src = block;\n\n    dst = block;\n\n    for(i = 0; i < 8; i++){\n\n        t1 = 17 * (src[0] + src[2]) + 4;\n\n        t2 = 17 * (src[0] - src[2]) + 4;\n\n        t3 = 22 * src[1] + 10 * src[3];\n\n        t4 = 22 * src[3] - 10 * src[1];\n\n\n\n        dst[0] = (t1 + t3) >> 3;\n\n        dst[1] = (t2 - t4) >> 3;\n\n        dst[2] = (t2 + t4) >> 3;\n\n        dst[3] = (t1 - t3) >> 3;\n\n\n\n        src += 8;\n\n        dst += 8;\n\n    }\n\n\n\n    src = block;\n\n    for(i = 0; i < 4; i++){\n\n        t1 = 12 * (src[ 0] + src[32]) + 64;\n\n        t2 = 12 * (src[ 0] - src[32]) + 64;\n\n        t3 = 16 * src[16] +  6 * src[48];\n\n        t4 =  6 * src[16] - 16 * src[48];\n\n\n\n        t5 = t1 + t3;\n\n        t6 = t2 + t4;\n\n        t7 = t2 - t4;\n\n        t8 = t1 - t3;\n\n\n\n        t1 = 16 * src[ 8] + 15 * src[24] +  9 * src[40] +  4 * src[56];\n\n        t2 = 15 * src[ 8] -  4 * src[24] - 16 * src[40] -  9 * src[56];\n\n        t3 =  9 * src[ 8] - 16 * src[24] +  4 * src[40] + 15 * src[56];\n\n        t4 =  4 * src[ 8] -  9 * src[24] + 15 * src[40] - 16 * src[56];\n\n\n\n        dest[0*linesize] = cm[dest[0*linesize] + ((t5 + t1) >> 7)];\n\n        dest[1*linesize] = cm[dest[1*linesize] + ((t6 + t2) >> 7)];\n\n        dest[2*linesize] = cm[dest[2*linesize] + ((t7 + t3) >> 7)];\n\n        dest[3*linesize] = cm[dest[3*linesize] + ((t8 + t4) >> 7)];\n\n        dest[4*linesize] = cm[dest[4*linesize] + ((t8 - t4 + 1) >> 7)];\n\n        dest[5*linesize] = cm[dest[5*linesize] + ((t7 - t3 + 1) >> 7)];\n\n        dest[6*linesize] = cm[dest[6*linesize] + ((t6 - t2 + 1) >> 7)];\n\n        dest[7*linesize] = cm[dest[7*linesize] + ((t5 - t1 + 1) >> 7)];\n\n\n\n        src ++;\n\n        dest++;\n\n    }\n\n}\n", "idx": 26295}
{"project": "FFmpeg", "commit_id": "9ccc6cecd2d0645f5073382360509eb278b239b1", "target": 1, "func": "static av_cold int decode_init(WMAProDecodeCtx *s, AVCodecContext *avctx)\n\n{\n\n    uint8_t *edata_ptr = avctx->extradata;\n\n    unsigned int channel_mask;\n\n    int i, bits;\n\n    int log2_max_num_subframes;\n\n    int num_possible_block_sizes;\n\n\n\n    if (avctx->codec_id == AV_CODEC_ID_XMA1 || avctx->codec_id == AV_CODEC_ID_XMA2)\n\n        avctx->block_align = 2048;\n\n\n\n    if (!avctx->block_align) {\n\n        av_log(avctx, AV_LOG_ERROR, \"block_align is not set\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    s->avctx = avctx;\n\n    s->fdsp = avpriv_float_dsp_alloc(avctx->flags & AV_CODEC_FLAG_BITEXACT);\n\n    if (!s->fdsp)\n\n        return AVERROR(ENOMEM);\n\n\n\n    init_put_bits(&s->pb, s->frame_data, MAX_FRAMESIZE);\n\n\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_FLTP;\n\n\n\n    /** dump the extradata */\n\n    av_log(avctx, AV_LOG_DEBUG, \"extradata:\\n\");\n\n    for (i = 0; i < avctx->extradata_size; i++)\n\n        av_log(avctx, AV_LOG_DEBUG, \"[%x] \", avctx->extradata[i]);\n\n    av_log(avctx, AV_LOG_DEBUG, \"\\n\");\n\n    if (avctx->codec_id == AV_CODEC_ID_XMA2 && (!avctx->extradata || avctx->extradata_size >= 6)) {\n\n        s->decode_flags    = 0x10d6;\n\n        channel_mask       = avctx->extradata ? AV_RL32(edata_ptr+2) : 0;\n\n        s->bits_per_sample = 16;\n\n     } else if (avctx->codec_id == AV_CODEC_ID_XMA1) {\n\n        s->decode_flags    = 0x10d6;\n\n        s->bits_per_sample = 16;\n\n        channel_mask       = 0;\n\n     } else if (avctx->codec_id == AV_CODEC_ID_WMAPRO && avctx->extradata_size >= 18) {\n\n        s->decode_flags    = AV_RL16(edata_ptr+14);\n\n        channel_mask       = AV_RL32(edata_ptr+2);\n\n        s->bits_per_sample = AV_RL16(edata_ptr);\n\n\n\n        if (s->bits_per_sample > 32 || s->bits_per_sample < 1) {\n\n            avpriv_request_sample(avctx, \"bits per sample is %d\", s->bits_per_sample);\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n    } else {\n\n        avpriv_request_sample(avctx, \"Unknown extradata size\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if (avctx->codec_id != AV_CODEC_ID_WMAPRO && avctx->channels > 2) {\n\n        s->nb_channels = 2;\n\n    } else {\n\n        s->nb_channels = avctx->channels;\n\n    }\n\n\n\n    /** generic init */\n\n    s->log2_frame_size = av_log2(avctx->block_align) + 4;\n\n    if (s->log2_frame_size > 25) {\n\n        avpriv_request_sample(avctx, \"Large block align\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    /** frame info */\n\n    if (avctx->codec_id != AV_CODEC_ID_WMAPRO)\n\n        s->skip_frame = 0;\n\n    else\n\n        s->skip_frame = 1; /* skip first frame */\n\n\n\n    s->packet_loss = 1;\n\n    s->len_prefix  = (s->decode_flags & 0x40);\n\n\n\n    /** get frame len */\n\n    if (avctx->codec_id == AV_CODEC_ID_WMAPRO) {\n\n        bits = ff_wma_get_frame_len_bits(avctx->sample_rate, 3, s->decode_flags);\n\n        if (bits > WMAPRO_BLOCK_MAX_BITS) {\n\n            avpriv_request_sample(avctx, \"14-bit block sizes\");\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n        s->samples_per_frame = 1 << bits;\n\n    } else {\n\n        s->samples_per_frame = 512;\n\n    }\n\n\n\n    /** subframe info */\n\n    log2_max_num_subframes       = ((s->decode_flags & 0x38) >> 3);\n\n    s->max_num_subframes         = 1 << log2_max_num_subframes;\n\n    if (s->max_num_subframes == 16 || s->max_num_subframes == 4)\n\n        s->max_subframe_len_bit = 1;\n\n    s->subframe_len_bits = av_log2(log2_max_num_subframes) + 1;\n\n\n\n    num_possible_block_sizes     = log2_max_num_subframes + 1;\n\n    s->min_samples_per_subframe  = s->samples_per_frame / s->max_num_subframes;\n\n    s->dynamic_range_compression = (s->decode_flags & 0x80);\n\n\n\n    if (s->max_num_subframes > MAX_SUBFRAMES) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid number of subframes %\"PRId8\"\\n\",\n\n               s->max_num_subframes);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->min_samples_per_subframe < WMAPRO_BLOCK_MIN_SIZE) {\n\n        av_log(avctx, AV_LOG_ERROR, \"min_samples_per_subframe of %d too small\\n\",\n\n               s->min_samples_per_subframe);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->avctx->sample_rate <= 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid sample rate\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->nb_channels <= 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid number of channels %d\\n\",\n\n               s->nb_channels);\n\n        return AVERROR_INVALIDDATA;\n\n    } else if (s->nb_channels > WMAPRO_MAX_CHANNELS) {\n\n        avpriv_request_sample(avctx,\n\n                              \"More than %d channels\", WMAPRO_MAX_CHANNELS);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    /** init previous block len */\n\n    for (i = 0; i < s->nb_channels; i++)\n\n        s->channel[i].prev_block_len = s->samples_per_frame;\n\n\n\n    /** extract lfe channel position */\n\n    s->lfe_channel = -1;\n\n\n\n    if (channel_mask & 8) {\n\n        unsigned int mask;\n\n        for (mask = 1; mask < 16; mask <<= 1) {\n\n            if (channel_mask & mask)\n\n                ++s->lfe_channel;\n\n        }\n\n    }\n\n\n\n    INIT_VLC_STATIC(&sf_vlc, SCALEVLCBITS, HUFF_SCALE_SIZE,\n\n                    scale_huffbits, 1, 1,\n\n                    scale_huffcodes, 2, 2, 616);\n\n\n\n    INIT_VLC_STATIC(&sf_rl_vlc, VLCBITS, HUFF_SCALE_RL_SIZE,\n\n                    scale_rl_huffbits, 1, 1,\n\n                    scale_rl_huffcodes, 4, 4, 1406);\n\n\n\n    INIT_VLC_STATIC(&coef_vlc[0], VLCBITS, HUFF_COEF0_SIZE,\n\n                    coef0_huffbits, 1, 1,\n\n                    coef0_huffcodes, 4, 4, 2108);\n\n\n\n    INIT_VLC_STATIC(&coef_vlc[1], VLCBITS, HUFF_COEF1_SIZE,\n\n                    coef1_huffbits, 1, 1,\n\n                    coef1_huffcodes, 4, 4, 3912);\n\n\n\n    INIT_VLC_STATIC(&vec4_vlc, VLCBITS, HUFF_VEC4_SIZE,\n\n                    vec4_huffbits, 1, 1,\n\n                    vec4_huffcodes, 2, 2, 604);\n\n\n\n    INIT_VLC_STATIC(&vec2_vlc, VLCBITS, HUFF_VEC2_SIZE,\n\n                    vec2_huffbits, 1, 1,\n\n                    vec2_huffcodes, 2, 2, 562);\n\n\n\n    INIT_VLC_STATIC(&vec1_vlc, VLCBITS, HUFF_VEC1_SIZE,\n\n                    vec1_huffbits, 1, 1,\n\n                    vec1_huffcodes, 2, 2, 562);\n\n\n\n    /** calculate number of scale factor bands and their offsets\n\n        for every possible block size */\n\n    for (i = 0; i < num_possible_block_sizes; i++) {\n\n        int subframe_len = s->samples_per_frame >> i;\n\n        int x;\n\n        int band = 1;\n\n        int rate = get_rate(avctx);\n\n\n\n        s->sfb_offsets[i][0] = 0;\n\n\n\n        for (x = 0; x < MAX_BANDS-1 && s->sfb_offsets[i][band - 1] < subframe_len; x++) {\n\n            int offset = (subframe_len * 2 * critical_freq[x]) / rate + 2;\n\n            offset &= ~3;\n\n            if (offset > s->sfb_offsets[i][band - 1])\n\n                s->sfb_offsets[i][band++] = offset;\n\n\n\n            if (offset >= subframe_len)\n\n                break;\n\n        }\n\n        s->sfb_offsets[i][band - 1] = subframe_len;\n\n        s->num_sfb[i]               = band - 1;\n\n        if (s->num_sfb[i] <= 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"num_sfb invalid\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n\n\n    /** Scale factors can be shared between blocks of different size\n\n        as every block has a different scale factor band layout.\n\n        The matrix sf_offsets is needed to find the correct scale factor.\n\n     */\n\n\n\n    for (i = 0; i < num_possible_block_sizes; i++) {\n\n        int b;\n\n        for (b = 0; b < s->num_sfb[i]; b++) {\n\n            int x;\n\n            int offset = ((s->sfb_offsets[i][b]\n\n                           + s->sfb_offsets[i][b + 1] - 1) << i) >> 1;\n\n            for (x = 0; x < num_possible_block_sizes; x++) {\n\n                int v = 0;\n\n                while (s->sfb_offsets[x][v + 1] << x < offset) {\n\n                    v++;\n\n                    av_assert0(v < MAX_BANDS);\n\n                }\n\n                s->sf_offsets[i][x][b] = v;\n\n            }\n\n        }\n\n    }\n\n\n\n    /** init MDCT, FIXME: only init needed sizes */\n\n    for (i = 0; i < WMAPRO_BLOCK_SIZES; i++)\n\n        ff_mdct_init(&s->mdct_ctx[i], WMAPRO_BLOCK_MIN_BITS+1+i, 1,\n\n                     1.0 / (1 << (WMAPRO_BLOCK_MIN_BITS + i - 1))\n\n                     / (1 << (s->bits_per_sample - 1)));\n\n\n\n    /** init MDCT windows: simple sine window */\n\n    for (i = 0; i < WMAPRO_BLOCK_SIZES; i++) {\n\n        const int win_idx = WMAPRO_BLOCK_MAX_BITS - i;\n\n        ff_init_ff_sine_windows(win_idx);\n\n        s->windows[WMAPRO_BLOCK_SIZES - i - 1] = ff_sine_windows[win_idx];\n\n    }\n\n\n\n    /** calculate subwoofer cutoff values */\n\n    for (i = 0; i < num_possible_block_sizes; i++) {\n\n        int block_size = s->samples_per_frame >> i;\n\n        int cutoff = (440*block_size + 3LL * (s->avctx->sample_rate >> 1) - 1)\n\n                     / s->avctx->sample_rate;\n\n        s->subwoofer_cutoffs[i] = av_clip(cutoff, 4, block_size);\n\n    }\n\n\n\n    /** calculate sine values for the decorrelation matrix */\n\n    for (i = 0; i < 33; i++)\n\n        sin64[i] = sin(i*M_PI / 64.0);\n\n\n\n    if (avctx->debug & FF_DEBUG_BITSTREAM)\n\n        dump_context(s);\n\n\n\n    avctx->channel_layout = channel_mask;\n\n\n\n    return 0;\n\n}\n", "idx": 26298}
{"project": "FFmpeg", "commit_id": "7cc01c25727a96eaaa0c177234b626e47c8ea491", "target": 1, "func": "static void implicit_weight_table(const H264Context *h, H264SliceContext *sl, int field)\n\n{\n\n    int ref0, ref1, i, cur_poc, ref_start, ref_count0, ref_count1;\n\n\n\n    for (i = 0; i < 2; i++) {\n\n        sl->luma_weight_flag[i]   = 0;\n\n        sl->chroma_weight_flag[i] = 0;\n\n    }\n\n\n\n    if (field < 0) {\n\n        if (h->picture_structure == PICT_FRAME) {\n\n            cur_poc = h->cur_pic_ptr->poc;\n\n        } else {\n\n            cur_poc = h->cur_pic_ptr->field_poc[h->picture_structure - 1];\n\n        }\n\n        if (sl->ref_count[0] == 1 && sl->ref_count[1] == 1 && !FRAME_MBAFF(h) &&\n\n            sl->ref_list[0][0].poc + sl->ref_list[1][0].poc == 2 * cur_poc) {\n\n            sl->use_weight        = 0;\n\n            sl->use_weight_chroma = 0;\n\n            return;\n\n        }\n\n        ref_start  = 0;\n\n        ref_count0 = sl->ref_count[0];\n\n        ref_count1 = sl->ref_count[1];\n\n    } else {\n\n        cur_poc    = h->cur_pic_ptr->field_poc[field];\n\n        ref_start  = 16;\n\n        ref_count0 = 16 + 2 * sl->ref_count[0];\n\n        ref_count1 = 16 + 2 * sl->ref_count[1];\n\n    }\n\n\n\n    sl->use_weight               = 2;\n\n    sl->use_weight_chroma        = 2;\n\n    sl->luma_log2_weight_denom   = 5;\n\n    sl->chroma_log2_weight_denom = 5;\n\n\n\n    for (ref0 = ref_start; ref0 < ref_count0; ref0++) {\n\n        int poc0 = sl->ref_list[0][ref0].poc;\n\n        for (ref1 = ref_start; ref1 < ref_count1; ref1++) {\n\n            int w = 32;\n\n            if (!sl->ref_list[0][ref0].parent->long_ref && !sl->ref_list[1][ref1].parent->long_ref) {\n\n                int poc1 = sl->ref_list[1][ref1].poc;\n\n                int td   = av_clip_int8(poc1 - poc0);\n\n                if (td) {\n\n                    int tb = av_clip_int8(cur_poc - poc0);\n\n                    int tx = (16384 + (FFABS(td) >> 1)) / td;\n\n                    int dist_scale_factor = (tb * tx + 32) >> 8;\n\n                    if (dist_scale_factor >= -64 && dist_scale_factor <= 128)\n\n                        w = 64 - dist_scale_factor;\n\n                }\n\n            }\n\n            if (field < 0) {\n\n                sl->implicit_weight[ref0][ref1][0] =\n\n                sl->implicit_weight[ref0][ref1][1] = w;\n\n            } else {\n\n                sl->implicit_weight[ref0][ref1][field] = w;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 26300}
{"project": "FFmpeg", "commit_id": "b8b8e82ea14016b2cb04b49ecea57f836e6ee7f8", "target": 1, "func": "static void dnxhd_decode_dct_block_8(const DNXHDContext *ctx,\n\n                                     RowContext *row, int n)\n\n{\n\n    dnxhd_decode_dct_block(ctx, row, n, 4, 32, 6);\n\n}\n", "idx": 26302}
{"project": "FFmpeg", "commit_id": "386601286fed2dff5e1955bc21a0256f6f35ab19", "target": 1, "func": "int ff_h264_decode_slice_header(H264Context *h, H264SliceContext *sl)\n\n{\n\n    unsigned int first_mb_in_slice;\n\n    unsigned int pps_id;\n\n    int ret;\n\n    unsigned int slice_type, tmp, i, j;\n\n    int last_pic_structure, last_pic_droppable;\n\n    int must_reinit;\n\n    int needs_reinit = 0;\n\n    int field_pic_flag, bottom_field_flag;\n\n    int first_slice = sl == h->slice_ctx && !h->current_slice;\n\n    int frame_num, picture_structure, droppable;\n\n    PPS *pps;\n\n\n\n    h->qpel_put = h->h264qpel.put_h264_qpel_pixels_tab;\n\n    h->qpel_avg = h->h264qpel.avg_h264_qpel_pixels_tab;\n\n\n\n    first_mb_in_slice = get_ue_golomb_long(&sl->gb);\n\n\n\n    if (first_mb_in_slice == 0) { // FIXME better field boundary detection\n\n        if (h->current_slice) {\n\n            if (h->cur_pic_ptr && FIELD_PICTURE(h) && h->first_field) {\n\n                ff_h264_field_end(h, sl, 1);\n\n                h->current_slice = 0;\n\n            } else if (h->cur_pic_ptr && !FIELD_PICTURE(h) && !h->first_field && h->nal_unit_type  == NAL_IDR_SLICE) {\n\n                av_log(h, AV_LOG_WARNING, \"Broken frame packetizing\\n\");\n\n                ff_h264_field_end(h, sl, 1);\n\n                h->current_slice = 0;\n\n                ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX, 0);\n\n                ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX, 1);\n\n                h->cur_pic_ptr = NULL;\n\n            } else\n\n                return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        if (!h->first_field) {\n\n            if (h->cur_pic_ptr && !h->droppable) {\n\n                ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n\n                                          h->picture_structure == PICT_BOTTOM_FIELD);\n\n            }\n\n            h->cur_pic_ptr = NULL;\n\n        }\n\n    }\n\n\n\n    slice_type = get_ue_golomb_31(&sl->gb);\n\n    if (slice_type > 9) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"slice type %d too large at %d\\n\",\n\n               slice_type, first_mb_in_slice);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (slice_type > 4) {\n\n        slice_type -= 5;\n\n        sl->slice_type_fixed = 1;\n\n    } else\n\n        sl->slice_type_fixed = 0;\n\n\n\n    slice_type = golomb_to_pict_type[slice_type];\n\n\n\n    sl->slice_type     = slice_type;\n\n    sl->slice_type_nos = slice_type & 3;\n\n\n\n    if (h->nal_unit_type  == NAL_IDR_SLICE &&\n\n        sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"A non-intra slice in an IDR NAL unit.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (\n\n        (h->avctx->skip_frame >= AVDISCARD_NONREF && !h->nal_ref_idc) ||\n\n        (h->avctx->skip_frame >= AVDISCARD_BIDIR  && sl->slice_type_nos == AV_PICTURE_TYPE_B) ||\n\n        (h->avctx->skip_frame >= AVDISCARD_NONINTRA && sl->slice_type_nos != AV_PICTURE_TYPE_I) ||\n\n        (h->avctx->skip_frame >= AVDISCARD_NONKEY && h->nal_unit_type != NAL_IDR_SLICE) ||\n\n         h->avctx->skip_frame >= AVDISCARD_ALL) {\n\n         return SLICE_SKIPED;\n\n     }\n\n\n\n    // to make a few old functions happy, it's wrong though\n\n    h->pict_type = sl->slice_type;\n\n\n\n    pps_id = get_ue_golomb(&sl->gb);\n\n    if (pps_id >= MAX_PPS_COUNT) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"pps_id %u out of range\\n\", pps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (!h->pps_buffers[pps_id]) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"non-existing PPS %u referenced\\n\",\n\n               pps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (h->au_pps_id >= 0 && pps_id != h->au_pps_id) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"PPS change from %d to %d forbidden\\n\",\n\n               h->au_pps_id, pps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    pps = h->pps_buffers[pps_id];\n\n\n\n    if (!h->sps_buffers[pps->sps_id]) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"non-existing SPS %u referenced\\n\",\n\n               h->pps.sps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (first_slice)\n\n        h->pps = *h->pps_buffers[pps_id];\n\n\n\n    if (pps->sps_id != h->sps.sps_id ||\n\n        pps->sps_id != h->current_sps_id ||\n\n        h->sps_buffers[pps->sps_id]->new) {\n\n\n\n        if (!first_slice) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n               \"SPS changed in the middle of the frame\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        h->sps = *h->sps_buffers[h->pps.sps_id];\n\n\n\n        if (h->mb_width  != h->sps.mb_width ||\n\n            h->mb_height != h->sps.mb_height * (2 - h->sps.frame_mbs_only_flag) ||\n\n            h->cur_bit_depth_luma    != h->sps.bit_depth_luma ||\n\n            h->cur_chroma_format_idc != h->sps.chroma_format_idc\n\n        )\n\n            needs_reinit = 1;\n\n\n\n        if (h->bit_depth_luma    != h->sps.bit_depth_luma ||\n\n            h->chroma_format_idc != h->sps.chroma_format_idc) {\n\n            h->bit_depth_luma    = h->sps.bit_depth_luma;\n\n            h->chroma_format_idc = h->sps.chroma_format_idc;\n\n            needs_reinit         = 1;\n\n        }\n\n        if ((ret = ff_h264_set_parameter_from_sps(h)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    h->avctx->profile = ff_h264_get_profile(&h->sps);\n\n    h->avctx->level   = h->sps.level_idc;\n\n    h->avctx->refs    = h->sps.ref_frame_count;\n\n\n\n    must_reinit = (h->context_initialized &&\n\n                    (   16*h->sps.mb_width != h->avctx->coded_width\n\n                     || 16*h->sps.mb_height * (2 - h->sps.frame_mbs_only_flag) != h->avctx->coded_height\n\n                     || h->cur_bit_depth_luma    != h->sps.bit_depth_luma\n\n                     || h->cur_chroma_format_idc != h->sps.chroma_format_idc\n\n                     || h->mb_width  != h->sps.mb_width\n\n                     || h->mb_height != h->sps.mb_height * (2 - h->sps.frame_mbs_only_flag)\n\n                    ));\n\n    if (h->avctx->pix_fmt == AV_PIX_FMT_NONE\n\n        || (non_j_pixfmt(h->avctx->pix_fmt) != non_j_pixfmt(get_pixel_format(h, 0))))\n\n        must_reinit = 1;\n\n\n\n    if (first_slice && av_cmp_q(h->sps.sar, h->avctx->sample_aspect_ratio))\n\n        must_reinit = 1;\n\n\n\n    h->mb_width  = h->sps.mb_width;\n\n    h->mb_height = h->sps.mb_height * (2 - h->sps.frame_mbs_only_flag);\n\n    h->mb_num    = h->mb_width * h->mb_height;\n\n    h->mb_stride = h->mb_width + 1;\n\n\n\n    h->b_stride = h->mb_width * 4;\n\n\n\n    h->chroma_y_shift = h->sps.chroma_format_idc <= 1; // 400 uses yuv420p\n\n\n\n    h->width  = 16 * h->mb_width;\n\n    h->height = 16 * h->mb_height;\n\n\n\n    ret = init_dimensions(h);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (h->sps.video_signal_type_present_flag) {\n\n        h->avctx->color_range = h->sps.full_range>0 ? AVCOL_RANGE_JPEG\n\n                                                    : AVCOL_RANGE_MPEG;\n\n        if (h->sps.colour_description_present_flag) {\n\n            if (h->avctx->colorspace != h->sps.colorspace)\n\n                needs_reinit = 1;\n\n            h->avctx->color_primaries = h->sps.color_primaries;\n\n            h->avctx->color_trc       = h->sps.color_trc;\n\n            h->avctx->colorspace      = h->sps.colorspace;\n\n        }\n\n    }\n\n\n\n    if (h->context_initialized &&\n\n        (must_reinit || needs_reinit)) {\n\n        if (sl != h->slice_ctx) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"changing width %d -> %d / height %d -> %d on \"\n\n                   \"slice %d\\n\",\n\n                   h->width, h->avctx->coded_width,\n\n                   h->height, h->avctx->coded_height,\n\n                   h->current_slice + 1);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        av_assert1(first_slice);\n\n\n\n        ff_h264_flush_change(h);\n\n\n\n        if ((ret = get_pixel_format(h, 1)) < 0)\n\n            return ret;\n\n        h->avctx->pix_fmt = ret;\n\n\n\n        av_log(h->avctx, AV_LOG_INFO, \"Reinit context to %dx%d, \"\n\n               \"pix_fmt: %s\\n\", h->width, h->height, av_get_pix_fmt_name(h->avctx->pix_fmt));\n\n\n\n        if ((ret = h264_slice_header_init(h, 1)) < 0) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"h264_slice_header_init() failed\\n\");\n\n            return ret;\n\n        }\n\n    }\n\n    if (!h->context_initialized) {\n\n        if (sl != h->slice_ctx) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"Cannot (re-)initialize context during parallel decoding.\\n\");\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n\n\n        if ((ret = get_pixel_format(h, 1)) < 0)\n\n            return ret;\n\n        h->avctx->pix_fmt = ret;\n\n\n\n        if ((ret = h264_slice_header_init(h, 0)) < 0) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"h264_slice_header_init() failed\\n\");\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    if (first_slice && h->dequant_coeff_pps != pps_id) {\n\n        h->dequant_coeff_pps = pps_id;\n\n        ff_h264_init_dequant_tables(h);\n\n    }\n\n\n\n    frame_num = get_bits(&sl->gb, h->sps.log2_max_frame_num);\n\n    if (!first_slice) {\n\n        if (h->frame_num != frame_num) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"Frame num change from %d to %d\\n\",\n\n                   h->frame_num, frame_num);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    sl->mb_mbaff       = 0;\n\n    h->mb_aff_frame    = 0;\n\n    last_pic_structure = h->picture_structure;\n\n    last_pic_droppable = h->droppable;\n\n    droppable          = h->nal_ref_idc == 0;\n\n    if (h->sps.frame_mbs_only_flag) {\n\n        picture_structure = PICT_FRAME;\n\n    } else {\n\n        if (!h->sps.direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"This stream was generated by a broken encoder, invalid 8x8 inference\\n\");\n\n            return -1;\n\n        }\n\n        field_pic_flag = get_bits1(&sl->gb);\n\n\n\n        if (field_pic_flag) {\n\n            bottom_field_flag = get_bits1(&sl->gb);\n\n            picture_structure = PICT_TOP_FIELD + bottom_field_flag;\n\n        } else {\n\n            picture_structure = PICT_FRAME;\n\n            h->mb_aff_frame      = h->sps.mb_aff;\n\n        }\n\n    }\n\n    if (h->current_slice) {\n\n        if (last_pic_structure != picture_structure ||\n\n            last_pic_droppable != droppable) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"Changing field mode (%d -> %d) between slices is not allowed\\n\",\n\n                   last_pic_structure, h->picture_structure);\n\n            return AVERROR_INVALIDDATA;\n\n        } else if (!h->cur_pic_ptr) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"unset cur_pic_ptr on slice %d\\n\",\n\n                   h->current_slice + 1);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    h->picture_structure = picture_structure;\n\n    h->droppable         = droppable;\n\n    h->frame_num         = frame_num;\n\n    sl->mb_field_decoding_flag = picture_structure != PICT_FRAME;\n\n\n\n    if (h->current_slice == 0) {\n\n        /* Shorten frame num gaps so we don't have to allocate reference\n\n         * frames just to throw them away */\n\n        if (h->frame_num != h->prev_frame_num) {\n\n            int unwrap_prev_frame_num = h->prev_frame_num;\n\n            int max_frame_num         = 1 << h->sps.log2_max_frame_num;\n\n\n\n            if (unwrap_prev_frame_num > h->frame_num)\n\n                unwrap_prev_frame_num -= max_frame_num;\n\n\n\n            if ((h->frame_num - unwrap_prev_frame_num) > h->sps.ref_frame_count) {\n\n                unwrap_prev_frame_num = (h->frame_num - h->sps.ref_frame_count) - 1;\n\n                if (unwrap_prev_frame_num < 0)\n\n                    unwrap_prev_frame_num += max_frame_num;\n\n\n\n                h->prev_frame_num = unwrap_prev_frame_num;\n\n            }\n\n        }\n\n\n\n        /* See if we have a decoded first field looking for a pair...\n\n         * Here, we're using that to see if we should mark previously\n\n         * decode frames as \"finished\".\n\n         * We have to do that before the \"dummy\" in-between frame allocation,\n\n         * since that can modify h->cur_pic_ptr. */\n\n        if (h->first_field) {\n\n            assert(h->cur_pic_ptr);\n\n            assert(h->cur_pic_ptr->f.buf[0]);\n\n            assert(h->cur_pic_ptr->reference != DELAYED_PIC_REF);\n\n\n\n            /* Mark old field/frame as completed */\n\n            if (h->cur_pic_ptr->tf.owner == h->avctx) {\n\n                ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n\n                                          last_pic_structure == PICT_BOTTOM_FIELD);\n\n            }\n\n\n\n            /* figure out if we have a complementary field pair */\n\n            if (!FIELD_PICTURE(h) || h->picture_structure == last_pic_structure) {\n\n                /* Previous field is unmatched. Don't display it, but let it\n\n                 * remain for reference if marked as such. */\n\n                if (last_pic_structure != PICT_FRAME) {\n\n                    ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n\n                                              last_pic_structure == PICT_TOP_FIELD);\n\n                }\n\n            } else {\n\n                if (h->cur_pic_ptr->frame_num != h->frame_num) {\n\n                    /* This and previous field were reference, but had\n\n                     * different frame_nums. Consider this field first in\n\n                     * pair. Throw away previous field except for reference\n\n                     * purposes. */\n\n                    if (last_pic_structure != PICT_FRAME) {\n\n                        ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n\n                                                  last_pic_structure == PICT_TOP_FIELD);\n\n                    }\n\n                } else {\n\n                    /* Second field in complementary pair */\n\n                    if (!((last_pic_structure   == PICT_TOP_FIELD &&\n\n                           h->picture_structure == PICT_BOTTOM_FIELD) ||\n\n                          (last_pic_structure   == PICT_BOTTOM_FIELD &&\n\n                           h->picture_structure == PICT_TOP_FIELD))) {\n\n                        av_log(h->avctx, AV_LOG_ERROR,\n\n                               \"Invalid field mode combination %d/%d\\n\",\n\n                               last_pic_structure, h->picture_structure);\n\n                        h->picture_structure = last_pic_structure;\n\n                        h->droppable         = last_pic_droppable;\n\n                        return AVERROR_INVALIDDATA;\n\n                    } else if (last_pic_droppable != h->droppable) {\n\n                        avpriv_request_sample(h->avctx,\n\n                                              \"Found reference and non-reference fields in the same frame, which\");\n\n                        h->picture_structure = last_pic_structure;\n\n                        h->droppable         = last_pic_droppable;\n\n                        return AVERROR_PATCHWELCOME;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n\n\n        while (h->frame_num != h->prev_frame_num && !h->first_field &&\n\n               h->frame_num != (h->prev_frame_num + 1) % (1 << h->sps.log2_max_frame_num)) {\n\n            H264Picture *prev = h->short_ref_count ? h->short_ref[0] : NULL;\n\n            av_log(h->avctx, AV_LOG_DEBUG, \"Frame num gap %d %d\\n\",\n\n                   h->frame_num, h->prev_frame_num);\n\n            if (!h->sps.gaps_in_frame_num_allowed_flag)\n\n                for(i=0; i<FF_ARRAY_ELEMS(h->last_pocs); i++)\n\n                    h->last_pocs[i] = INT_MIN;\n\n            ret = h264_frame_start(h);\n\n            if (ret < 0) {\n\n                h->first_field = 0;\n\n                return ret;\n\n            }\n\n\n\n            h->prev_frame_num++;\n\n            h->prev_frame_num        %= 1 << h->sps.log2_max_frame_num;\n\n            h->cur_pic_ptr->frame_num = h->prev_frame_num;\n\n            h->cur_pic_ptr->invalid_gap = !h->sps.gaps_in_frame_num_allowed_flag;\n\n            ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX, 0);\n\n            ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX, 1);\n\n            ret = ff_generate_sliding_window_mmcos(h, 1);\n\n            if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n\n                return ret;\n\n            ret = ff_h264_execute_ref_pic_marking(h, h->mmco, h->mmco_index);\n\n            if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n\n                return ret;\n\n            /* Error concealment: If a ref is missing, copy the previous ref\n\n             * in its place.\n\n             * FIXME: Avoiding a memcpy would be nice, but ref handling makes\n\n             * many assumptions about there being no actual duplicates.\n\n             * FIXME: This does not copy padding for out-of-frame motion\n\n             * vectors.  Given we are concealing a lost frame, this probably\n\n             * is not noticeable by comparison, but it should be fixed. */\n\n            if (h->short_ref_count) {\n\n                if (prev) {\n\n                    av_image_copy(h->short_ref[0]->f.data,\n\n                                  h->short_ref[0]->f.linesize,\n\n                                  (const uint8_t **)prev->f.data,\n\n                                  prev->f.linesize,\n\n                                  h->avctx->pix_fmt,\n\n                                  h->mb_width  * 16,\n\n                                  h->mb_height * 16);\n\n                    h->short_ref[0]->poc = prev->poc + 2;\n\n                }\n\n                h->short_ref[0]->frame_num = h->prev_frame_num;\n\n            }\n\n        }\n\n\n\n        /* See if we have a decoded first field looking for a pair...\n\n         * We're using that to see whether to continue decoding in that\n\n         * frame, or to allocate a new one. */\n\n        if (h->first_field) {\n\n            assert(h->cur_pic_ptr);\n\n            assert(h->cur_pic_ptr->f.buf[0]);\n\n            assert(h->cur_pic_ptr->reference != DELAYED_PIC_REF);\n\n\n\n            /* figure out if we have a complementary field pair */\n\n            if (!FIELD_PICTURE(h) || h->picture_structure == last_pic_structure) {\n\n                /* Previous field is unmatched. Don't display it, but let it\n\n                 * remain for reference if marked as such. */\n\n                h->missing_fields ++;\n\n                h->cur_pic_ptr = NULL;\n\n                h->first_field = FIELD_PICTURE(h);\n\n            } else {\n\n                h->missing_fields = 0;\n\n                if (h->cur_pic_ptr->frame_num != h->frame_num) {\n\n                    ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n\n                                              h->picture_structure==PICT_BOTTOM_FIELD);\n\n                    /* This and the previous field had different frame_nums.\n\n                     * Consider this field first in pair. Throw away previous\n\n                     * one except for reference purposes. */\n\n                    h->first_field = 1;\n\n                    h->cur_pic_ptr = NULL;\n\n                } else {\n\n                    /* Second field in complementary pair */\n\n                    h->first_field = 0;\n\n                }\n\n            }\n\n        } else {\n\n            /* Frame or first field in a potentially complementary pair */\n\n            h->first_field = FIELD_PICTURE(h);\n\n        }\n\n\n\n        if (!FIELD_PICTURE(h) || h->first_field) {\n\n            if (h264_frame_start(h) < 0) {\n\n                h->first_field = 0;\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        } else {\n\n            release_unused_pictures(h, 0);\n\n        }\n\n        /* Some macroblocks can be accessed before they're available in case\n\n        * of lost slices, MBAFF or threading. */\n\n        if (FIELD_PICTURE(h)) {\n\n            for(i = (h->picture_structure == PICT_BOTTOM_FIELD); i<h->mb_height; i++)\n\n                memset(h->slice_table + i*h->mb_stride, -1, (h->mb_stride - (i+1==h->mb_height)) * sizeof(*h->slice_table));\n\n        } else {\n\n            memset(h->slice_table, -1,\n\n                (h->mb_height * h->mb_stride - 1) * sizeof(*h->slice_table));\n\n        }\n\n        h->last_slice_type = -1;\n\n    }\n\n\n\n\n\n    h->cur_pic_ptr->frame_num = h->frame_num; // FIXME frame_num cleanup\n\n\n\n    av_assert1(h->mb_num == h->mb_width * h->mb_height);\n\n    if (first_mb_in_slice << FIELD_OR_MBAFF_PICTURE(h) >= h->mb_num ||\n\n        first_mb_in_slice >= h->mb_num) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"first_mb_in_slice overflow\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    sl->resync_mb_x = sl->mb_x =  first_mb_in_slice % h->mb_width;\n\n    sl->resync_mb_y = sl->mb_y = (first_mb_in_slice / h->mb_width) <<\n\n                                 FIELD_OR_MBAFF_PICTURE(h);\n\n    if (h->picture_structure == PICT_BOTTOM_FIELD)\n\n        sl->resync_mb_y = sl->mb_y = sl->mb_y + 1;\n\n    av_assert1(sl->mb_y < h->mb_height);\n\n\n\n    if (h->picture_structure == PICT_FRAME) {\n\n        h->curr_pic_num = h->frame_num;\n\n        h->max_pic_num  = 1 << h->sps.log2_max_frame_num;\n\n    } else {\n\n        h->curr_pic_num = 2 * h->frame_num + 1;\n\n        h->max_pic_num  = 1 << (h->sps.log2_max_frame_num + 1);\n\n    }\n\n\n\n    if (h->nal_unit_type == NAL_IDR_SLICE)\n\n        get_ue_golomb(&sl->gb); /* idr_pic_id */\n\n\n\n    if (h->sps.poc_type == 0) {\n\n        h->poc_lsb = get_bits(&sl->gb, h->sps.log2_max_poc_lsb);\n\n\n\n        if (h->pps.pic_order_present == 1 && h->picture_structure == PICT_FRAME)\n\n            h->delta_poc_bottom = get_se_golomb(&sl->gb);\n\n    }\n\n\n\n    if (h->sps.poc_type == 1 && !h->sps.delta_pic_order_always_zero_flag) {\n\n        h->delta_poc[0] = get_se_golomb(&sl->gb);\n\n\n\n        if (h->pps.pic_order_present == 1 && h->picture_structure == PICT_FRAME)\n\n            h->delta_poc[1] = get_se_golomb(&sl->gb);\n\n    }\n\n\n\n    ff_init_poc(h, h->cur_pic_ptr->field_poc, &h->cur_pic_ptr->poc);\n\n\n\n    if (h->pps.redundant_pic_cnt_present)\n\n        sl->redundant_pic_count = get_ue_golomb(&sl->gb);\n\n\n\n    ret = ff_set_ref_count(h, sl);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (slice_type != AV_PICTURE_TYPE_I &&\n\n        (h->current_slice == 0 ||\n\n         slice_type != h->last_slice_type ||\n\n         memcmp(h->last_ref_count, sl->ref_count, sizeof(sl->ref_count)))) {\n\n\n\n        ff_h264_fill_default_ref_list(h, sl);\n\n    }\n\n\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n       ret = ff_h264_decode_ref_pic_list_reordering(h, sl);\n\n       if (ret < 0) {\n\n           sl->ref_count[1] = sl->ref_count[0] = 0;\n\n           return ret;\n\n       }\n\n    }\n\n\n\n    if ((h->pps.weighted_pred && sl->slice_type_nos == AV_PICTURE_TYPE_P) ||\n\n        (h->pps.weighted_bipred_idc == 1 &&\n\n         sl->slice_type_nos == AV_PICTURE_TYPE_B))\n\n        ff_pred_weight_table(h, sl);\n\n    else if (h->pps.weighted_bipred_idc == 2 &&\n\n             sl->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n        implicit_weight_table(h, sl, -1);\n\n    } else {\n\n        sl->use_weight = 0;\n\n        for (i = 0; i < 2; i++) {\n\n            sl->luma_weight_flag[i]   = 0;\n\n            sl->chroma_weight_flag[i] = 0;\n\n        }\n\n    }\n\n\n\n    // If frame-mt is enabled, only update mmco tables for the first slice\n\n    // in a field. Subsequent slices can temporarily clobber h->mmco_index\n\n    // or h->mmco, which will cause ref list mix-ups and decoding errors\n\n    // further down the line. This may break decoding if the first slice is\n\n    // corrupt, thus we only do this if frame-mt is enabled.\n\n    if (h->nal_ref_idc) {\n\n        ret = ff_h264_decode_ref_pic_marking(h, &sl->gb,\n\n                                             !(h->avctx->active_thread_type & FF_THREAD_FRAME) ||\n\n                                             h->current_slice == 0);\n\n        if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (FRAME_MBAFF(h)) {\n\n        ff_h264_fill_mbaff_ref_list(h, sl);\n\n\n\n        if (h->pps.weighted_bipred_idc == 2 && sl->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n            implicit_weight_table(h, sl, 0);\n\n            implicit_weight_table(h, sl, 1);\n\n        }\n\n    }\n\n\n\n    if (sl->slice_type_nos == AV_PICTURE_TYPE_B && !sl->direct_spatial_mv_pred)\n\n        ff_h264_direct_dist_scale_factor(h, sl);\n\n    ff_h264_direct_ref_list_init(h, sl);\n\n\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I && h->pps.cabac) {\n\n        tmp = get_ue_golomb_31(&sl->gb);\n\n        if (tmp > 2) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"cabac_init_idc %u overflow\\n\", tmp);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        sl->cabac_init_idc = tmp;\n\n    }\n\n\n\n    sl->last_qscale_diff = 0;\n\n    tmp = h->pps.init_qp + get_se_golomb(&sl->gb);\n\n    if (tmp > 51 + 6 * (h->sps.bit_depth_luma - 8)) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"QP %u out of range\\n\", tmp);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    sl->qscale       = tmp;\n\n    sl->chroma_qp[0] = get_chroma_qp(h, 0, sl->qscale);\n\n    sl->chroma_qp[1] = get_chroma_qp(h, 1, sl->qscale);\n\n    // FIXME qscale / qp ... stuff\n\n    if (sl->slice_type == AV_PICTURE_TYPE_SP)\n\n        get_bits1(&sl->gb); /* sp_for_switch_flag */\n\n    if (sl->slice_type == AV_PICTURE_TYPE_SP ||\n\n        sl->slice_type == AV_PICTURE_TYPE_SI)\n\n        get_se_golomb(&sl->gb); /* slice_qs_delta */\n\n\n\n    sl->deblocking_filter     = 1;\n\n    sl->slice_alpha_c0_offset = 0;\n\n    sl->slice_beta_offset     = 0;\n\n    if (h->pps.deblocking_filter_parameters_present) {\n\n        tmp = get_ue_golomb_31(&sl->gb);\n\n        if (tmp > 2) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"deblocking_filter_idc %u out of range\\n\", tmp);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        sl->deblocking_filter = tmp;\n\n        if (sl->deblocking_filter < 2)\n\n            sl->deblocking_filter ^= 1;  // 1<->0\n\n\n\n        if (sl->deblocking_filter) {\n\n            sl->slice_alpha_c0_offset = get_se_golomb(&sl->gb) * 2;\n\n            sl->slice_beta_offset     = get_se_golomb(&sl->gb) * 2;\n\n            if (sl->slice_alpha_c0_offset >  12 ||\n\n                sl->slice_alpha_c0_offset < -12 ||\n\n                sl->slice_beta_offset >  12     ||\n\n                sl->slice_beta_offset < -12) {\n\n                av_log(h->avctx, AV_LOG_ERROR,\n\n                       \"deblocking filter parameters %d %d out of range\\n\",\n\n                       sl->slice_alpha_c0_offset, sl->slice_beta_offset);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (h->avctx->skip_loop_filter >= AVDISCARD_ALL ||\n\n        (h->avctx->skip_loop_filter >= AVDISCARD_NONKEY &&\n\n         h->nal_unit_type != NAL_IDR_SLICE) ||\n\n        (h->avctx->skip_loop_filter >= AVDISCARD_NONINTRA &&\n\n         sl->slice_type_nos != AV_PICTURE_TYPE_I) ||\n\n        (h->avctx->skip_loop_filter >= AVDISCARD_BIDIR  &&\n\n         sl->slice_type_nos == AV_PICTURE_TYPE_B) ||\n\n        (h->avctx->skip_loop_filter >= AVDISCARD_NONREF &&\n\n         h->nal_ref_idc == 0))\n\n        sl->deblocking_filter = 0;\n\n\n\n    if (sl->deblocking_filter == 1 && h->max_contexts > 1) {\n\n        if (h->avctx->flags2 & CODEC_FLAG2_FAST) {\n\n            /* Cheat slightly for speed:\n\n             * Do not bother to deblock across slices. */\n\n            sl->deblocking_filter = 2;\n\n        } else {\n\n            h->max_contexts = 1;\n\n            if (!h->single_decode_warning) {\n\n                av_log(h->avctx, AV_LOG_INFO,\n\n                       \"Cannot parallelize slice decoding with deblocking filter type 1, decoding such frames in sequential order\\n\"\n\n                       \"To parallelize slice decoding you need video encoded with disable_deblocking_filter_idc set to 2 (deblock only edges that do not cross slices).\\n\"\n\n                       \"Setting the flags2 libavcodec option to +fast (-flags2 +fast) will disable deblocking across slices and enable parallel slice decoding \"\n\n                       \"but will generate non-standard-compliant output.\\n\");\n\n                h->single_decode_warning = 1;\n\n            }\n\n            if (sl != h->slice_ctx) {\n\n                av_log(h->avctx, AV_LOG_ERROR,\n\n                       \"Deblocking switched inside frame.\\n\");\n\n                return SLICE_SINGLETHREAD;\n\n            }\n\n        }\n\n    }\n\n    sl->qp_thresh = 15 -\n\n                   FFMIN(sl->slice_alpha_c0_offset, sl->slice_beta_offset) -\n\n                   FFMAX3(0,\n\n                          h->pps.chroma_qp_index_offset[0],\n\n                          h->pps.chroma_qp_index_offset[1]) +\n\n                   6 * (h->sps.bit_depth_luma - 8);\n\n\n\n    h->last_slice_type = slice_type;\n\n    memcpy(h->last_ref_count, sl->ref_count, sizeof(h->last_ref_count));\n\n    sl->slice_num       = ++h->current_slice;\n\n\n\n    if (sl->slice_num)\n\n        h->slice_row[(sl->slice_num-1)&(MAX_SLICES-1)]= sl->resync_mb_y;\n\n    if (   h->slice_row[sl->slice_num&(MAX_SLICES-1)] + 3 >= sl->resync_mb_y\n\n        && h->slice_row[sl->slice_num&(MAX_SLICES-1)] <= sl->resync_mb_y\n\n        && sl->slice_num >= MAX_SLICES) {\n\n        //in case of ASO this check needs to be updated depending on how we decide to assign slice numbers in this case\n\n        av_log(h->avctx, AV_LOG_WARNING, \"Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\\n\", sl->slice_num, MAX_SLICES);\n\n    }\n\n\n\n    for (j = 0; j < 2; j++) {\n\n        int id_list[16];\n\n        int *ref2frm = sl->ref2frm[sl->slice_num & (MAX_SLICES - 1)][j];\n\n        for (i = 0; i < 16; i++) {\n\n            id_list[i] = 60;\n\n            if (j < sl->list_count && i < sl->ref_count[j] &&\n\n                sl->ref_list[j][i].parent->f.buf[0]) {\n\n                int k;\n\n                AVBuffer *buf = sl->ref_list[j][i].parent->f.buf[0]->buffer;\n\n                for (k = 0; k < h->short_ref_count; k++)\n\n                    if (h->short_ref[k]->f.buf[0]->buffer == buf) {\n\n                        id_list[i] = k;\n\n                        break;\n\n                    }\n\n                for (k = 0; k < h->long_ref_count; k++)\n\n                    if (h->long_ref[k] && h->long_ref[k]->f.buf[0]->buffer == buf) {\n\n                        id_list[i] = h->short_ref_count + k;\n\n                        break;\n\n                    }\n\n            }\n\n        }\n\n\n\n        ref2frm[0] =\n\n        ref2frm[1] = -1;\n\n        for (i = 0; i < 16; i++)\n\n            ref2frm[i + 2] = 4 * id_list[i] + (sl->ref_list[j][i].reference & 3);\n\n        ref2frm[18 + 0] =\n\n        ref2frm[18 + 1] = -1;\n\n        for (i = 16; i < 48; i++)\n\n            ref2frm[i + 4] = 4 * id_list[(i - 16) >> 1] +\n\n                             (sl->ref_list[j][i].reference & 3);\n\n    }\n\n\n\n    h->au_pps_id = pps_id;\n\n    h->sps.new =\n\n    h->sps_buffers[h->pps.sps_id]->new = 0;\n\n    h->current_sps_id = h->pps.sps_id;\n\n\n\n    if (h->avctx->debug & FF_DEBUG_PICT_INFO) {\n\n        av_log(h->avctx, AV_LOG_DEBUG,\n\n               \"slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\\n\",\n\n               sl->slice_num,\n\n               (h->picture_structure == PICT_FRAME ? \"F\" : h->picture_structure == PICT_TOP_FIELD ? \"T\" : \"B\"),\n\n               first_mb_in_slice,\n\n               av_get_picture_type_char(sl->slice_type),\n\n               sl->slice_type_fixed ? \" fix\" : \"\",\n\n               h->nal_unit_type == NAL_IDR_SLICE ? \" IDR\" : \"\",\n\n               pps_id, h->frame_num,\n\n               h->cur_pic_ptr->field_poc[0],\n\n               h->cur_pic_ptr->field_poc[1],\n\n               sl->ref_count[0], sl->ref_count[1],\n\n               sl->qscale,\n\n               sl->deblocking_filter,\n\n               sl->slice_alpha_c0_offset, sl->slice_beta_offset,\n\n               sl->use_weight,\n\n               sl->use_weight == 1 && sl->use_weight_chroma ? \"c\" : \"\",\n\n               sl->slice_type == AV_PICTURE_TYPE_B ? (sl->direct_spatial_mv_pred ? \"SPAT\" : \"TEMP\") : \"\");\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26303}
{"project": "FFmpeg", "commit_id": "c6831e2a70f734c71f483d69d46d0635963530c7", "target": 1, "func": "static int wv_get_value(WavpackFrameContext *ctx, GetBitContext *gb,\n\n                        int channel, int *last)\n\n{\n\n    int t, t2;\n\n    int sign, base, add, ret;\n\n    WvChannel *c = &ctx->ch[channel];\n\n\n\n    *last = 0;\n\n\n\n    if ((ctx->ch[0].median[0] < 2U) && (ctx->ch[1].median[0] < 2U) &&\n\n        !ctx->zero && !ctx->one) {\n\n        if (ctx->zeroes) {\n\n            ctx->zeroes--;\n\n            if (ctx->zeroes) {\n\n                c->slow_level -= LEVEL_DECAY(c->slow_level);\n\n                return 0;\n\n\n        } else {\n\n            t = get_unary_0_33(gb);\n\n            if (t >= 2) {\n\n                if (get_bits_left(gb) < t - 1)\n\n\n                t = get_bits(gb, t - 1) | (1 << (t-1));\n\n            } else {\n\n                if (get_bits_left(gb) < 0)\n\n\n\n            ctx->zeroes = t;\n\n            if (ctx->zeroes) {\n\n                memset(ctx->ch[0].median, 0, sizeof(ctx->ch[0].median));\n\n                memset(ctx->ch[1].median, 0, sizeof(ctx->ch[1].median));\n\n                c->slow_level -= LEVEL_DECAY(c->slow_level);\n\n                return 0;\n\n\n\n\n\n\n    if (ctx->zero) {\n\n        t = 0;\n\n        ctx->zero = 0;\n\n    } else {\n\n        t = get_unary_0_33(gb);\n\n        if (get_bits_left(gb) < 0)\n\n\n        if (t == 16) {\n\n            t2 = get_unary_0_33(gb);\n\n            if (t2 < 2) {\n\n                if (get_bits_left(gb) < 0)\n\n\n                t += t2;\n\n            } else {\n\n                if (get_bits_left(gb) < t2 - 1)\n\n\n                t += get_bits(gb, t2 - 1) | (1 << (t2 - 1));\n\n\n\n\n\n        if (ctx->one) {\n\n            ctx->one = t & 1;\n\n            t = (t >> 1) + 1;\n\n        } else {\n\n            ctx->one = t & 1;\n\n            t >>= 1;\n\n\n        ctx->zero = !ctx->one;\n\n\n\n\n    if (ctx->hybrid && !channel)\n\n        update_error_limit(ctx);\n\n\n\n    if (!t) {\n\n        base = 0;\n\n        add  = GET_MED(0) - 1;\n\n        DEC_MED(0);\n\n    } else if (t == 1) {\n\n        base = GET_MED(0);\n\n        add  = GET_MED(1) - 1;\n\n        INC_MED(0);\n\n        DEC_MED(1);\n\n    } else if (t == 2) {\n\n        base = GET_MED(0) + GET_MED(1);\n\n        add  = GET_MED(2) - 1;\n\n        INC_MED(0);\n\n        INC_MED(1);\n\n        DEC_MED(2);\n\n    } else {\n\n        base = GET_MED(0) + GET_MED(1) + GET_MED(2) * (t - 2);\n\n        add  = GET_MED(2) - 1;\n\n        INC_MED(0);\n\n        INC_MED(1);\n\n        INC_MED(2);\n\n\n    if (!c->error_limit) {\n\n\n\n\n\n        ret = base + get_tail(gb, add);\n\n        if (get_bits_left(gb) <= 0)\n\n\n    } else {\n\n        int mid = (base * 2 + add + 1) >> 1;\n\n        while (add > c->error_limit) {\n\n            if (get_bits_left(gb) <= 0)\n\n\n            if (get_bits1(gb)) {\n\n                add -= (mid - base);\n\n                base = mid;\n\n            } else\n\n                add = mid - base - 1;\n\n            mid = (base * 2 + add + 1) >> 1;\n\n\n        ret = mid;\n\n\n    sign = get_bits1(gb);\n\n    if (ctx->hybrid_bitrate)\n\n        c->slow_level += wp_log2(ret) - LEVEL_DECAY(c->slow_level);\n\n    return sign ? ~ret : ret;\n\n\n\nerror:\n\n    *last = 1;\n\n    return 0;\n", "idx": 26304}
{"project": "FFmpeg", "commit_id": "ec3b22326dc07fb8300a577bd6b17c19a0f1bcf7", "target": 1, "func": "static void http_write_packet(void *opaque, \n\n                              unsigned char *buf, int size)\n\n{\n\n    HTTPContext *c = opaque;\n\n\n\n    if (c->buffer_ptr == c->buffer_end || !c->buffer_ptr)\n\n        c->buffer_ptr = c->buffer_end = c->buffer;\n\n\n\n    if (c->buffer_end - c->buffer + size > IOBUFFER_MAX_SIZE)\n\n        abort();\n\n\n\n    memcpy(c->buffer_end, buf, size);\n\n    c->buffer_end += size;\n\n}\n", "idx": 26307}
{"project": "FFmpeg", "commit_id": "131644677970a3c4a0096270ea2a5b5d437c2e63", "target": 1, "func": "static int http_read_stream(URLContext *h, uint8_t *buf, int size)\n\n{\n\n    HTTPContext *s = h->priv_data;\n\n    int err, new_location;\n\n\n\n    if (!s->hd)\n\n        return AVERROR_EOF;\n\n\n\n    if (s->end_chunked_post && !s->end_header) {\n\n        err = http_read_header(h, &new_location);\n\n        if (err < 0)\n\n            return err;\n\n    }\n\n\n\n    if (s->chunksize >= 0) {\n\n        if (!s->chunksize) {\n\n            char line[32];\n\n\n\n            for (;;) {\n\n                do {\n\n                    if ((err = http_get_line(s, line, sizeof(line))) < 0)\n\n                        return err;\n\n                } while (!*line);    /* skip CR LF from last chunk */\n\n\n\n                s->chunksize = strtoll(line, NULL, 16);\n\n\n\n                av_log(NULL, AV_LOG_TRACE, \"Chunked encoding data size: %\"PRId64\"'\\n\",\n\n                        s->chunksize);\n\n\n\n                if (!s->chunksize)\n\n                    return 0;\n\n                break;\n\n            }\n\n        }\n\n        size = FFMIN(size, s->chunksize);\n\n    }\n\n#if CONFIG_ZLIB\n\n    if (s->compressed)\n\n        return http_buf_read_compressed(h, buf, size);\n\n#endif /* CONFIG_ZLIB */\n\n    return http_buf_read(h, buf, size);\n\n}\n", "idx": 26309}
{"project": "FFmpeg", "commit_id": "ed3c9b5b0dd5abb545c48e930e1c32c187b0776a", "target": 1, "func": "static int lag_read_prob_header(lag_rac *rac, GetBitContext *gb)\n\n{\n\n    int i, j, scale_factor;\n\n    unsigned prob, cumulative_target;\n\n    unsigned cumul_prob = 0;\n\n    unsigned scaled_cumul_prob = 0;\n\n\n\n    rac->prob[0] = 0;\n\n    rac->prob[257] = UINT_MAX;\n\n    /* Read probabilities from bitstream */\n\n    for (i = 1; i < 257; i++) {\n\n        if (lag_decode_prob(gb, &rac->prob[i]) < 0) {\n\n            av_log(rac->avctx, AV_LOG_ERROR, \"Invalid probability encountered.\\n\");\n\n            return -1;\n\n        }\n\n        if ((uint64_t)cumul_prob + rac->prob[i] > UINT_MAX) {\n\n            av_log(rac->avctx, AV_LOG_ERROR, \"Integer overflow encountered in cumulative probability calculation.\\n\");\n\n            return -1;\n\n        }\n\n        cumul_prob += rac->prob[i];\n\n        if (!rac->prob[i]) {\n\n            if (lag_decode_prob(gb, &prob)) {\n\n                av_log(rac->avctx, AV_LOG_ERROR, \"Invalid probability run encountered.\\n\");\n\n                return -1;\n\n            }\n\n            if (prob > 256 - i)\n\n                prob = 256 - i;\n\n            for (j = 0; j < prob; j++)\n\n                rac->prob[++i] = 0;\n\n        }\n\n    }\n\n\n\n    if (!cumul_prob) {\n\n        av_log(rac->avctx, AV_LOG_ERROR, \"All probabilities are 0!\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* Scale probabilities so cumulative probability is an even power of 2. */\n\n    scale_factor = av_log2(cumul_prob);\n\n\n\n    if (cumul_prob & (cumul_prob - 1)) {\n\n        uint64_t mul = softfloat_reciprocal(cumul_prob);\n\n        for (i = 1; i <= 128; i++) {\n\n            rac->prob[i] = softfloat_mul(rac->prob[i], mul);\n\n            scaled_cumul_prob += rac->prob[i];\n\n        }\n\n        if (scaled_cumul_prob <= 0) {\n\n            av_log(rac->avctx, AV_LOG_ERROR, \"Scaled probabilities invalid\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        for (; i < 257; i++) {\n\n            rac->prob[i] = softfloat_mul(rac->prob[i], mul);\n\n            scaled_cumul_prob += rac->prob[i];\n\n        }\n\n\n\n        scale_factor++;\n\n        cumulative_target = 1 << scale_factor;\n\n\n\n        if (scaled_cumul_prob > cumulative_target) {\n\n            av_log(rac->avctx, AV_LOG_ERROR,\n\n                   \"Scaled probabilities are larger than target!\\n\");\n\n            return -1;\n\n        }\n\n\n\n        scaled_cumul_prob = cumulative_target - scaled_cumul_prob;\n\n\n\n        for (i = 1; scaled_cumul_prob; i = (i & 0x7f) + 1) {\n\n            if (rac->prob[i]) {\n\n                rac->prob[i]++;\n\n                scaled_cumul_prob--;\n\n            }\n\n            /* Comment from reference source:\n\n             * if (b & 0x80 == 0) {     // order of operations is 'wrong'; it has been left this way\n\n             *                          // since the compression change is negligible and fixing it\n\n             *                          // breaks backwards compatibility\n\n             *      b =- (signed int)b;\n\n             *      b &= 0xFF;\n\n             * } else {\n\n             *      b++;\n\n             *      b &= 0x7f;\n\n             * }\n\n             */\n\n        }\n\n    }\n\n\n\n    rac->scale = scale_factor;\n\n\n\n    /* Fill probability array with cumulative probability for each symbol. */\n\n    for (i = 1; i < 257; i++)\n\n        rac->prob[i] += rac->prob[i - 1];\n\n\n\n    return 0;\n\n}\n", "idx": 26310}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static inline void downmix_2f_2r_to_stereo(float *samples)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        samples[i] += samples[i + 512];\n\n        samples[i + 256] = samples[i + 768];\n\n        samples[i + 512] = samples[i + 768] = 0;\n\n    }\n\n}\n", "idx": 26312}
{"project": "FFmpeg", "commit_id": "c04c3282b4334ff64cfd69d40fea010602e830fd", "target": 0, "func": "static int video_read_header(AVFormatContext *s,\n\n                             AVFormatParameters *ap)\n\n{\n\n    AVStream *st;\n\n\n\n    st = av_new_stream(s, 0);\n\n    if (!st)\n\n        return AVERROR_NOMEM;\n\n\n\n    st->codec->codec_type = CODEC_TYPE_VIDEO;\n\n    st->codec->codec_id = s->iformat->value;\n\n    st->need_parsing = 1;\n\n\n\n    /* for mjpeg, specify frame rate */\n\n    /* for mpeg4 specify it too (most mpeg4 streams dont have the fixed_vop_rate set ...)*/\n\n    if (ap && ap->time_base.num) {\n\n        av_set_pts_info(st, 64, ap->time_base.num, ap->time_base.den);\n\n    } else if ( st->codec->codec_id == CODEC_ID_MJPEG ||\n\n                st->codec->codec_id == CODEC_ID_MPEG4 ||\n\n                st->codec->codec_id == CODEC_ID_H264) {\n\n        av_set_pts_info(st, 64, 1, 25);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26313}
{"project": "FFmpeg", "commit_id": "e278056fbad7405fc47901faea7de98db003a0fa", "target": 0, "func": "static int vp3_decode_frame(AVCodecContext *avctx,\n\n                            void *data, int *data_size,\n\n                            uint8_t *buf, int buf_size)\n\n{\n\n    Vp3DecodeContext *s = avctx->priv_data;\n\n    GetBitContext gb;\n\n    static int counter = 0;\n\n    int i;\n\n\n\n    init_get_bits(&gb, buf, buf_size * 8);\n\n\n\n    if (s->theora && get_bits1(&gb))\n\n    {\n\n#if 1\n\n        av_log(avctx, AV_LOG_ERROR, \"Header packet passed to frame decoder, skipping\\n\");\n\n        return -1;\n\n#else\n\n        int ptype = get_bits(&gb, 7);\n\n\n\n        skip_bits(&gb, 6*8); /* \"theora\" */\n\n\n\n        switch(ptype)\n\n        {\n\n            case 1:\n\n                theora_decode_comments(avctx, gb);\n\n                break;\n\n            case 2:\n\n                theora_decode_tables(avctx, gb);\n\n                    init_dequantizer(s);\n\n                break;\n\n            default:\n\n                av_log(avctx, AV_LOG_ERROR, \"Unknown Theora config packet: %d\\n\", ptype);\n\n        }\n\n        return buf_size;\n\n#endif\n\n    }\n\n\n\n    s->keyframe = !get_bits1(&gb);\n\n    if (!s->theora)\n\n        skip_bits(&gb, 1);\n\n    s->last_quality_index = s->quality_index;\n\n    s->quality_index = get_bits(&gb, 6);\n\n    if (s->theora >= 0x030200)\n\n        skip_bits1(&gb);\n\n\n\n    if (s->avctx->debug & FF_DEBUG_PICT_INFO)\n\n        av_log(s->avctx, AV_LOG_INFO, \" VP3 %sframe #%d: Q index = %d\\n\",\n\n            s->keyframe?\"key\":\"\", counter, s->quality_index);\n\n    counter++;\n\n\n\n    if (s->quality_index != s->last_quality_index) {\n\n        init_dequantizer(s);\n\n        init_loop_filter(s);\n\n    }\n\n\n\n    if (s->keyframe) {\n\n        if (!s->theora)\n\n        {\n\n            skip_bits(&gb, 4); /* width code */\n\n            skip_bits(&gb, 4); /* height code */\n\n            if (s->version)\n\n            {\n\n                s->version = get_bits(&gb, 5);\n\n                if (counter == 1)\n\n                    av_log(s->avctx, AV_LOG_DEBUG, \"VP version: %d\\n\", s->version);\n\n            }\n\n        }\n\n        if (s->version || s->theora)\n\n        {\n\n                if (get_bits1(&gb))\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"Warning, unsupported keyframe coding type?!\\n\");\n\n            skip_bits(&gb, 2); /* reserved? */\n\n        }\n\n\n\n        if (s->last_frame.data[0] == s->golden_frame.data[0]) {\n\n            if (s->golden_frame.data[0])\n\n                avctx->release_buffer(avctx, &s->golden_frame);\n\n            s->last_frame= s->golden_frame; /* ensure that we catch any access to this released frame */\n\n        } else {\n\n            if (s->golden_frame.data[0])\n\n                avctx->release_buffer(avctx, &s->golden_frame);\n\n            if (s->last_frame.data[0])\n\n                avctx->release_buffer(avctx, &s->last_frame);\n\n        }\n\n\n\n        s->golden_frame.reference = 3;\n\n        if(avctx->get_buffer(avctx, &s->golden_frame) < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"vp3: get_buffer() failed\\n\");\n\n            return -1;\n\n        }\n\n\n\n        /* golden frame is also the current frame */\n\n        memcpy(&s->current_frame, &s->golden_frame, sizeof(AVFrame));\n\n\n\n        /* time to figure out pixel addresses? */\n\n        if (!s->pixel_addresses_inited)\n\n        {\n\n            if (!s->flipped_image)\n\n                vp3_calculate_pixel_addresses(s);\n\n            else\n\n                theora_calculate_pixel_addresses(s);\n\n        }\n\n    } else {\n\n        /* allocate a new current frame */\n\n        s->current_frame.reference = 3;\n\n        if(avctx->get_buffer(avctx, &s->current_frame) < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"vp3: get_buffer() failed\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    s->current_frame.qscale_table= s->qscale_table; //FIXME allocate individual tables per AVFrame\n\n    s->current_frame.qstride= 0;\n\n\n\n    {START_TIMER\n\n    init_frame(s, &gb);\n\n    STOP_TIMER(\"init_frame\")}\n\n\n\n#if KEYFRAMES_ONLY\n\nif (!s->keyframe) {\n\n\n\n    memcpy(s->current_frame.data[0], s->golden_frame.data[0],\n\n        s->current_frame.linesize[0] * s->height);\n\n    memcpy(s->current_frame.data[1], s->golden_frame.data[1],\n\n        s->current_frame.linesize[1] * s->height / 2);\n\n    memcpy(s->current_frame.data[2], s->golden_frame.data[2],\n\n        s->current_frame.linesize[2] * s->height / 2);\n\n\n\n} else {\n\n#endif\n\n\n\n    {START_TIMER\n\n    if (unpack_superblocks(s, &gb)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_superblocks\\n\");\n\n        return -1;\n\n    }\n\n    STOP_TIMER(\"unpack_superblocks\")}\n\n    {START_TIMER\n\n    if (unpack_modes(s, &gb)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_modes\\n\");\n\n        return -1;\n\n    }\n\n    STOP_TIMER(\"unpack_modes\")}\n\n    {START_TIMER\n\n    if (unpack_vectors(s, &gb)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_vectors\\n\");\n\n        return -1;\n\n    }\n\n    STOP_TIMER(\"unpack_vectors\")}\n\n    {START_TIMER\n\n    if (unpack_dct_coeffs(s, &gb)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_dct_coeffs\\n\");\n\n        return -1;\n\n    }\n\n    STOP_TIMER(\"unpack_dct_coeffs\")}\n\n    {START_TIMER\n\n\n\n    reverse_dc_prediction(s, 0, s->fragment_width, s->fragment_height);\n\n    if ((avctx->flags & CODEC_FLAG_GRAY) == 0) {\n\n        reverse_dc_prediction(s, s->u_fragment_start,\n\n            s->fragment_width / 2, s->fragment_height / 2);\n\n        reverse_dc_prediction(s, s->v_fragment_start,\n\n            s->fragment_width / 2, s->fragment_height / 2);\n\n    }\n\n    STOP_TIMER(\"reverse_dc_prediction\")}\n\n    {START_TIMER\n\n\n\n    for (i = 0; i < s->macroblock_height; i++)\n\n        render_slice(s, i);\n\n    STOP_TIMER(\"render_fragments\")}\n\n\n\n    {START_TIMER\n\n    apply_loop_filter(s);\n\n    STOP_TIMER(\"apply_loop_filter\")}\n\n#if KEYFRAMES_ONLY\n\n}\n\n#endif\n\n\n\n    *data_size=sizeof(AVFrame);\n\n    *(AVFrame*)data= s->current_frame;\n\n\n\n    /* release the last frame, if it is allocated and if it is not the\n\n     * golden frame */\n\n    if ((s->last_frame.data[0]) &&\n\n        (s->last_frame.data[0] != s->golden_frame.data[0]))\n\n        avctx->release_buffer(avctx, &s->last_frame);\n\n\n\n    /* shuffle frames (last = current) */\n\n    memcpy(&s->last_frame, &s->current_frame, sizeof(AVFrame));\n\n    s->current_frame.data[0]= NULL; /* ensure that we catch any access to this released frame */\n\n\n\n    return buf_size;\n\n}\n", "idx": 26314}
{"project": "FFmpeg", "commit_id": "c39059bea3adebcd888571d1181db215eee54495", "target": 0, "func": "void ff_h264_direct_dist_scale_factor(H264Context *const h)\n\n{\n\n    const int poc  = h->cur_pic_ptr->field_poc[h->picture_structure == PICT_BOTTOM_FIELD];\n\n    const int poc1 = h->ref_list[1][0].poc;\n\n    int i, field;\n\n\n\n    if (FRAME_MBAFF(h))\n\n        for (field = 0; field < 2; field++) {\n\n            const int poc  = h->cur_pic_ptr->field_poc[field];\n\n            const int poc1 = h->ref_list[1][0].field_poc[field];\n\n            for (i = 0; i < 2 * h->ref_count[0]; i++)\n\n                h->dist_scale_factor_field[field][i ^ field] =\n\n                    get_scale_factor(h, poc, poc1, i + 16);\n\n        }\n\n\n\n    for (i = 0; i < h->ref_count[0]; i++)\n\n        h->dist_scale_factor[i] = get_scale_factor(h, poc, poc1, i);\n\n}\n", "idx": 26322}
{"project": "FFmpeg", "commit_id": "f58cd2867a8af2eed13acdd21d067b48249b14a1", "target": 1, "func": "static int read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    PAFDemuxContext *p = s->priv_data;\n\n    AVIOContext     *pb = s->pb;\n\n    uint32_t        count, offset;\n\n    int             size, i;\n\n\n\n    if (p->current_frame >= p->nb_frames)\n\n        return AVERROR_EOF;\n\n\n\n    if (url_feof(pb))\n\n        return AVERROR_EOF;\n\n\n\n    if (p->got_audio) {\n\n        if (av_new_packet(pkt, p->audio_size) < 0)\n\n            return AVERROR(ENOMEM);\n\n\n\n        memcpy(pkt->data, p->temp_audio_frame, p->audio_size);\n\n        pkt->duration     = PAF_SOUND_SAMPLES * (p->audio_size / PAF_SOUND_FRAME_SIZE);\n\n        pkt->flags       |= AV_PKT_FLAG_KEY;\n\n        pkt->stream_index = 1;\n\n        p->got_audio      = 0;\n\n        return pkt->size;\n\n    }\n\n\n\n    count = (p->current_frame == 0) ? p->preload_count : p->blocks_count_table[p->current_frame - 1];\n\n    for (i = 0; i < count; i++) {\n\n        if (p->current_frame_block >= p->frame_blks)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        offset = p->blocks_offset_table[p->current_frame_block] & ~(1U << 31);\n\n        if (p->blocks_offset_table[p->current_frame_block] & (1U << 31)) {\n\n            if (offset > p->audio_size - p->buffer_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            avio_read(pb, p->audio_frame + offset, p->buffer_size);\n\n            if (offset == (p->max_audio_blks - 2) * p->buffer_size) {\n\n                memcpy(p->temp_audio_frame, p->audio_frame, p->audio_size);\n\n                p->got_audio = 1;\n\n            }\n\n        } else {\n\n            if (offset > p->video_size - p->buffer_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            avio_read(pb, p->video_frame + offset, p->buffer_size);\n\n        }\n\n        p->current_frame_block++;\n\n    }\n\n\n\n    size = p->video_size - p->frames_offset_table[p->current_frame];\n\n    if (size < 1)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (av_new_packet(pkt, size) < 0)\n\n        return AVERROR(ENOMEM);\n\n\n\n    pkt->stream_index = 0;\n\n    pkt->duration     = 1;\n\n    memcpy(pkt->data, p->video_frame + p->frames_offset_table[p->current_frame], size);\n\n    if (pkt->data[0] & 0x20)\n\n        pkt->flags   |= AV_PKT_FLAG_KEY;\n\n    p->current_frame++;\n\n\n\n    return pkt->size;\n\n}\n", "idx": 26325}
{"project": "FFmpeg", "commit_id": "ce41c51b0c71c87f623914ba0786aef325d818fe", "target": 1, "func": "AVFormatContext *ff_rtp_chain_mux_open(AVFormatContext *s, AVStream *st,\n\n                                       URLContext *handle, int packet_size)\n\n{\n\n    AVFormatContext *rtpctx;\n\n    int ret;\n\n    AVOutputFormat *rtp_format = av_guess_format(\"rtp\", NULL, NULL);\n\n\n\n    if (!rtp_format)\n\n        return NULL;\n\n\n\n    /* Allocate an AVFormatContext for each output stream */\n\n    rtpctx = avformat_alloc_context();\n\n    if (!rtpctx)\n\n        return NULL;\n\n\n\n    rtpctx->oformat = rtp_format;\n\n    if (!av_new_stream(rtpctx, 0)) {\n\n        av_free(rtpctx);\n\n        return NULL;\n\n    }\n\n    /* Copy the max delay setting; the rtp muxer reads this. */\n\n    rtpctx->max_delay = s->max_delay;\n\n    /* Copy other stream parameters. */\n\n    rtpctx->streams[0]->sample_aspect_ratio = st->sample_aspect_ratio;\n\n\n\n    /* Set the synchronized start time. */\n\n    rtpctx->start_time_realtime = s->start_time_realtime;\n\n\n\n    /* Remove the local codec, link to the original codec\n\n     * context instead, to give the rtp muxer access to\n\n     * codec parameters. */\n\n    av_free(rtpctx->streams[0]->codec);\n\n    rtpctx->streams[0]->codec = st->codec;\n\n\n\n    if (handle) {\n\n        url_fdopen(&rtpctx->pb, handle);\n\n    } else\n\n        url_open_dyn_packet_buf(&rtpctx->pb, packet_size);\n\n    ret = av_write_header(rtpctx);\n\n\n\n    if (ret) {\n\n        if (handle) {\n\n            url_fclose(rtpctx->pb);\n\n        } else {\n\n            uint8_t *ptr;\n\n            url_close_dyn_buf(rtpctx->pb, &ptr);\n\n            av_free(ptr);\n\n        }\n\n\n        av_free(rtpctx->streams[0]);\n\n        av_free(rtpctx);\n\n        return NULL;\n\n    }\n\n\n\n    /* Copy the RTP AVStream timebase back to the original AVStream */\n\n    st->time_base = rtpctx->streams[0]->time_base;\n\n    return rtpctx;\n\n}", "idx": 26327}
{"project": "FFmpeg", "commit_id": "a443a2530d00b7019269202ac0f5ca8ba0a021c7", "target": 1, "func": "static void rm_read_audio_stream_info(AVFormatContext *s, AVStream *st,\n                                      int read_all)\n{\n    RMContext *rm = s->priv_data;\n    ByteIOContext *pb = &s->pb;\n    char buf[256];\n    uint32_t version;\n    int i;\n    /* ra type header */\n    version = get_be32(pb); /* version */\n    if (((version >> 16) & 0xff) == 3) {\n        int64_t startpos = url_ftell(pb);\n        /* very old version */\n        for(i = 0; i < 14; i++)\n            get_byte(pb);\n        get_str8(pb, s->title, sizeof(s->title));\n        get_str8(pb, s->author, sizeof(s->author));\n        get_str8(pb, s->copyright, sizeof(s->copyright));\n        get_str8(pb, s->comment, sizeof(s->comment));\n        if ((startpos + (version & 0xffff)) >= url_ftell(pb) + 2) {\n        // fourcc (should always be \"lpcJ\")\n        get_byte(pb);\n        get_str8(pb, buf, sizeof(buf));\n        // Skip extra header crap (this should never happen)\n        if ((startpos + (version & 0xffff)) > url_ftell(pb))\n            url_fskip(pb, (version & 0xffff) + startpos - url_ftell(pb));\n        st->codec->sample_rate = 8000;\n        st->codec->channels = 1;\n        st->codec->codec_type = CODEC_TYPE_AUDIO;\n        st->codec->codec_id = CODEC_ID_RA_144;\n    } else {\n        int flavor, sub_packet_h, coded_framesize, sub_packet_size;\n        /* old version (4) */\n        get_be32(pb); /* .ra4 */\n        get_be32(pb); /* data size */\n        get_be16(pb); /* version2 */\n        get_be32(pb); /* header size */\n        flavor= get_be16(pb); /* add codec info / flavor */\n        rm->coded_framesize = coded_framesize = get_be32(pb); /* coded frame size */\n        get_be32(pb); /* ??? */\n        get_be32(pb); /* ??? */\n        get_be32(pb); /* ??? */\n        rm->sub_packet_h = sub_packet_h = get_be16(pb); /* 1 */\n        st->codec->block_align= get_be16(pb); /* frame size */\n        rm->sub_packet_size = sub_packet_size = get_be16(pb); /* sub packet size */\n        get_be16(pb); /* ??? */\n        if (((version >> 16) & 0xff) == 5) {\n            get_be16(pb); get_be16(pb); get_be16(pb); }\n        st->codec->sample_rate = get_be16(pb);\n        get_be32(pb);\n        st->codec->channels = get_be16(pb);\n        if (((version >> 16) & 0xff) == 5) {\n            get_be32(pb);\n            buf[0] = get_byte(pb);\n            buf[1] = get_byte(pb);\n            buf[2] = get_byte(pb);\n            buf[3] = get_byte(pb);\n            buf[4] = 0;\n        } else {\n        get_str8(pb, buf, sizeof(buf)); /* desc */\n        get_str8(pb, buf, sizeof(buf)); /* desc */\n        st->codec->codec_type = CODEC_TYPE_AUDIO;\n        if (!strcmp(buf, \"dnet\")) {\n            st->codec->codec_id = CODEC_ID_AC3;\n        } else if (!strcmp(buf, \"28_8\")) {\n            st->codec->codec_id = CODEC_ID_RA_288;\n            st->codec->extradata_size= 0;\n            rm->audio_framesize = st->codec->block_align;\n            st->codec->block_align = coded_framesize;\n            rm->audiobuf = av_malloc(rm->audio_framesize * sub_packet_h);\n        } else if (!strcmp(buf, \"cook\")) {\n            int codecdata_length, i;\n            get_be16(pb); get_byte(pb);\n            if (((version >> 16) & 0xff) == 5)\n                get_byte(pb);\n            codecdata_length = get_be32(pb);\n            if(codecdata_length + FF_INPUT_BUFFER_PADDING_SIZE <= (unsigned)codecdata_length){\n                av_log(s, AV_LOG_ERROR, \"codecdata_length too large\\n\");\n            st->codec->codec_id = CODEC_ID_COOK;\n            st->codec->extradata_size= codecdata_length;\n            st->codec->extradata= av_mallocz(st->codec->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE);\n            for(i = 0; i < codecdata_length; i++)\n                ((uint8_t*)st->codec->extradata)[i] = get_byte(pb);\n            rm->audio_framesize = st->codec->block_align;\n            st->codec->block_align = rm->sub_packet_size;\n            rm->audiobuf = av_malloc(rm->audio_framesize * sub_packet_h);\n        } else {\n            st->codec->codec_id = CODEC_ID_NONE;\n            pstrcpy(st->codec->codec_name, sizeof(st->codec->codec_name),\n                    buf);\n        if (read_all) {\n            get_byte(pb);\n            get_byte(pb);\n            get_byte(pb);\n            get_str8(pb, s->title, sizeof(s->title));\n            get_str8(pb, s->author, sizeof(s->author));\n            get_str8(pb, s->copyright, sizeof(s->copyright));\n            get_str8(pb, s->comment, sizeof(s->comment));", "idx": 26329}
{"project": "FFmpeg", "commit_id": "aba232cfa9b193604ed98f3fa505378d006b1b3b", "target": 1, "func": "static int vc1test_write_header(AVFormatContext *s)\n\n{\n\n    AVCodecContext *avc = s->streams[0]->codec;\n\n    AVIOContext *pb = s->pb;\n\n\n\n    if (avc->codec_id != CODEC_ID_WMV3) {\n\n        av_log(s, AV_LOG_ERROR, \"Only WMV3 is accepted!\\n\");\n\n        return -1;\n\n    }\n\n    avio_wl24(pb, 0); //frames count will be here\n\n    avio_w8(pb, 0xC5);\n\n    avio_wl32(pb, 4);\n\n    avio_write(pb, avc->extradata, 4);\n\n    avio_wl32(pb, avc->height);\n\n    avio_wl32(pb, avc->width);\n\n    avio_wl32(pb, 0xC);\n\n    avio_wl24(pb, 0); // hrd_buffer\n\n    avio_w8(pb, 0x80); // level|cbr|res1\n\n    avio_wl32(pb, 0); // hrd_rate\n\n    if (s->streams[0]->r_frame_rate.den && s->streams[0]->r_frame_rate.num == 1)\n\n        avio_wl32(pb, s->streams[0]->r_frame_rate.den);\n\n    else\n\n        avio_wl32(pb, 0xFFFFFFFF); //variable framerate\n\n    avpriv_set_pts_info(s->streams[0], 32, 1, 1000);\n\n\n\n    return 0;\n\n}\n", "idx": 26332}
{"project": "FFmpeg", "commit_id": "c0b91348fe4aec7d2245d95ccabb460a6971e361", "target": 1, "func": "static int caca_write_trailer(AVFormatContext *s)\n\n{\n\n    CACAContext *c = s->priv_data;\n\n\n\n    av_freep(&c->window_title);\n\n\n\n    caca_free_dither(c->dither);\n\n    caca_free_display(c->display);\n\n    caca_free_canvas(c->canvas);\n\n    return 0;\n\n}\n", "idx": 26334}
{"project": "FFmpeg", "commit_id": "e2710e790c09e49e86baa58c6063af0097cc8cb0", "target": 1, "func": "int av_parse_cpu_flags(const char *s)\n\n{\n\n#define CPUFLAG_MMXEXT   (AV_CPU_FLAG_MMX      | AV_CPU_FLAG_MMXEXT | AV_CPU_FLAG_CMOV)\n\n#define CPUFLAG_3DNOW    (AV_CPU_FLAG_3DNOW    | AV_CPU_FLAG_MMX)\n\n#define CPUFLAG_3DNOWEXT (AV_CPU_FLAG_3DNOWEXT | CPUFLAG_3DNOW)\n\n#define CPUFLAG_SSE      (AV_CPU_FLAG_SSE      | CPUFLAG_MMXEXT)\n\n#define CPUFLAG_SSE2     (AV_CPU_FLAG_SSE2     | CPUFLAG_SSE)\n\n#define CPUFLAG_SSE2SLOW (AV_CPU_FLAG_SSE2SLOW | CPUFLAG_SSE2)\n\n#define CPUFLAG_SSE3     (AV_CPU_FLAG_SSE3     | CPUFLAG_SSE2)\n\n#define CPUFLAG_SSE3SLOW (AV_CPU_FLAG_SSE3SLOW | CPUFLAG_SSE3)\n\n#define CPUFLAG_SSSE3    (AV_CPU_FLAG_SSSE3    | CPUFLAG_SSE3)\n\n#define CPUFLAG_SSE4     (AV_CPU_FLAG_SSE4     | CPUFLAG_SSSE3)\n\n#define CPUFLAG_SSE42    (AV_CPU_FLAG_SSE42    | CPUFLAG_SSE4)\n\n#define CPUFLAG_AVX      (AV_CPU_FLAG_AVX      | CPUFLAG_SSE42)\n\n#define CPUFLAG_AVXSLOW  (AV_CPU_FLAG_AVXSLOW  | CPUFLAG_AVX)\n\n#define CPUFLAG_XOP      (AV_CPU_FLAG_XOP      | CPUFLAG_AVX)\n\n#define CPUFLAG_FMA3     (AV_CPU_FLAG_FMA3     | CPUFLAG_AVX)\n\n#define CPUFLAG_FMA4     (AV_CPU_FLAG_FMA4     | CPUFLAG_AVX)\n\n#define CPUFLAG_AVX2     (AV_CPU_FLAG_AVX2     | CPUFLAG_AVX)\n\n#define CPUFLAG_BMI2     (AV_CPU_FLAG_BMI2     | AV_CPU_FLAG_BMI1)\n\n    static const AVOption cpuflags_opts[] = {\n\n        { \"flags\"   , NULL, 0, AV_OPT_TYPE_FLAGS, { .i64 = 0 }, INT64_MIN, INT64_MAX, .unit = \"flags\" },\n\n#if   ARCH_PPC\n\n        { \"altivec\" , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ALTIVEC  },    .unit = \"flags\" },\n\n#elif ARCH_X86\n\n        { \"mmx\"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_MMX      },    .unit = \"flags\" },\n\n        { \"mmxext\"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_MMXEXT       },    .unit = \"flags\" },\n\n        { \"sse\"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE          },    .unit = \"flags\" },\n\n        { \"sse2\"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE2         },    .unit = \"flags\" },\n\n        { \"sse2slow\", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE2SLOW     },    .unit = \"flags\" },\n\n        { \"sse3\"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE3         },    .unit = \"flags\" },\n\n        { \"sse3slow\", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE3SLOW     },    .unit = \"flags\" },\n\n        { \"ssse3\"   , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSSE3        },    .unit = \"flags\" },\n\n        { \"atom\"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ATOM     },    .unit = \"flags\" },\n\n        { \"sse4.1\"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE4         },    .unit = \"flags\" },\n\n        { \"sse4.2\"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE42        },    .unit = \"flags\" },\n\n        { \"avx\"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_AVX          },    .unit = \"flags\" },\n\n        { \"avxslow\" , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_AVXSLOW      },    .unit = \"flags\" },\n\n        { \"xop\"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_XOP          },    .unit = \"flags\" },\n\n        { \"fma3\"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_FMA3         },    .unit = \"flags\" },\n\n        { \"fma4\"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_FMA4         },    .unit = \"flags\" },\n\n        { \"avx2\"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_AVX2         },    .unit = \"flags\" },\n\n        { \"bmi1\"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_BMI1     },    .unit = \"flags\" },\n\n        { \"bmi2\"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_BMI2         },    .unit = \"flags\" },\n\n        { \"3dnow\"   , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_3DNOW        },    .unit = \"flags\" },\n\n        { \"3dnowext\", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_3DNOWEXT     },    .unit = \"flags\" },\n\n        { \"cmov\",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_CMOV     },    .unit = \"flags\" },\n\n#elif ARCH_ARM\n\n        { \"armv5te\",  NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV5TE  },    .unit = \"flags\" },\n\n        { \"armv6\",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV6    },    .unit = \"flags\" },\n\n        { \"armv6t2\",  NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV6T2  },    .unit = \"flags\" },\n\n        { \"vfp\",      NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFP      },    .unit = \"flags\" },\n\n\n        { \"vfpv3\",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFPV3    },    .unit = \"flags\" },\n\n        { \"neon\",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_NEON     },    .unit = \"flags\" },\n\n#elif ARCH_AARCH64\n\n        { \"armv8\",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV8    },    .unit = \"flags\" },\n\n        { \"neon\",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_NEON     },    .unit = \"flags\" },\n\n        { \"vfp\",      NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFP      },    .unit = \"flags\" },\n\n#endif\n\n        { NULL },\n\n    };\n\n    static const AVClass class = {\n\n        .class_name = \"cpuflags\",\n\n        .item_name  = av_default_item_name,\n\n        .option     = cpuflags_opts,\n\n        .version    = LIBAVUTIL_VERSION_INT,\n\n    };\n\n\n\n    int flags = 0, ret;\n\n    const AVClass *pclass = &class;\n\n\n\n    if ((ret = av_opt_eval_flags(&pclass, &cpuflags_opts[0], s, &flags)) < 0)\n\n        return ret;\n\n\n\n    return flags & INT_MAX;\n\n}", "idx": 26336}
{"project": "FFmpeg", "commit_id": "915bbac6815eddd911fb5cb8a23517b3cac3a84b", "target": 1, "func": "void mpeg1_init_vlc(MpegEncContext *s)\n\n{\n\n    static int done = 0;\n\n\n\n    if (!done) {\n\n\n\n\n        init_vlc(&dc_lum_vlc, 9, 12, \n\n                 vlc_dc_lum_bits, 1, 1,\n\n                 vlc_dc_lum_code, 2, 2);\n\n        init_vlc(&dc_chroma_vlc, 9, 12, \n\n                 vlc_dc_chroma_bits, 1, 1,\n\n                 vlc_dc_chroma_code, 2, 2);\n\n        init_vlc(&mv_vlc, 9, 17, \n\n                 &mbMotionVectorTable[0][1], 2, 1,\n\n                 &mbMotionVectorTable[0][0], 2, 1);\n\n        init_vlc(&mbincr_vlc, 9, 35, \n\n                 &mbAddrIncrTable[0][1], 2, 1,\n\n                 &mbAddrIncrTable[0][0], 2, 1);\n\n        init_vlc(&mb_pat_vlc, 9, 63, \n\n                 &mbPatTable[0][1], 2, 1,\n\n                 &mbPatTable[0][0], 2, 1);\n\n        \n\n        init_vlc(&mb_ptype_vlc, 6, 32, \n\n                 &table_mb_ptype[0][1], 2, 1,\n\n                 &table_mb_ptype[0][0], 2, 1);\n\n        init_vlc(&mb_btype_vlc, 6, 32, \n\n                 &table_mb_btype[0][1], 2, 1,\n\n                 &table_mb_btype[0][0], 2, 1);\n\n        init_rl(&rl_mpeg1);\n\n        init_rl(&rl_mpeg2);\n\n        /* cannot use generic init because we must add the EOB code */\n\n        init_vlc(&rl_mpeg1.vlc, 9, rl_mpeg1.n + 2, \n\n                 &rl_mpeg1.table_vlc[0][1], 4, 2,\n\n                 &rl_mpeg1.table_vlc[0][0], 4, 2);\n\n        init_vlc(&rl_mpeg2.vlc, 9, rl_mpeg2.n + 2, \n\n                 &rl_mpeg2.table_vlc[0][1], 4, 2,\n\n                 &rl_mpeg2.table_vlc[0][0], 4, 2);\n\n    }\n\n}", "idx": 26337}
{"project": "FFmpeg", "commit_id": "50833c9f7b4e1922197a8955669f8ab3589c8cef", "target": 1, "func": "static int encode_bitstream(FlashSVContext *s, const AVFrame *p, uint8_t *buf,\n\n                            int buf_size, int block_width, int block_height,\n\n                            uint8_t *previous_frame, int *I_frame)\n\n{\n\n\n\n    PutBitContext pb;\n\n    int h_blocks, v_blocks, h_part, v_part, i, j;\n\n    int buf_pos, res;\n\n    int pred_blocks = 0;\n\n\n\n    init_put_bits(&pb, buf, buf_size * 8);\n\n\n\n    put_bits(&pb,  4, block_width / 16 - 1);\n\n    put_bits(&pb, 12, s->image_width);\n\n    put_bits(&pb,  4, block_height / 16 - 1);\n\n    put_bits(&pb, 12, s->image_height);\n\n    flush_put_bits(&pb);\n\n    buf_pos = 4;\n\n\n\n    h_blocks = s->image_width  / block_width;\n\n    h_part   = s->image_width  % block_width;\n\n    v_blocks = s->image_height / block_height;\n\n    v_part   = s->image_height % block_height;\n\n\n\n    /* loop over all block columns */\n\n    for (j = 0; j < v_blocks + (v_part ? 1 : 0); j++) {\n\n\n\n        int y_pos = j * block_height; // vertical position in frame\n\n        int cur_blk_height = (j < v_blocks) ? block_height : v_part;\n\n\n\n        /* loop over all block rows */\n\n        for (i = 0; i < h_blocks + (h_part ? 1 : 0); i++) {\n\n            int x_pos = i * block_width; // horizontal position in frame\n\n            int cur_blk_width = (i < h_blocks) ? block_width : h_part;\n\n            int ret = Z_OK;\n\n            uint8_t *ptr = buf + buf_pos;\n\n\n\n            /* copy the block to the temp buffer before compression\n\n             * (if it differs from the previous frame's block) */\n\n            res = copy_region_enc(p->data[0], s->tmpblock,\n\n                                  s->image_height - (y_pos + cur_blk_height + 1),\n\n                                  x_pos, cur_blk_height, cur_blk_width,\n\n                                  p->linesize[0], previous_frame);\n\n\n\n            if (res || *I_frame) {\n\n                unsigned long zsize = 3 * block_width * block_height;\n\n                ret = compress2(ptr + 2, &zsize, s->tmpblock,\n\n                                3 * cur_blk_width * cur_blk_height, 9);\n\n\n\n                //ret = deflateReset(&s->zstream);\n\n                if (ret != Z_OK)\n\n                    av_log(s->avctx, AV_LOG_ERROR,\n\n                           \"error while compressing block %dx%d\\n\", i, j);\n\n\n\n                bytestream_put_be16(&ptr, zsize);\n\n                buf_pos += zsize + 2;\n\n                av_dlog(s->avctx, \"buf_pos = %d\\n\", buf_pos);\n\n            } else {\n\n                pred_blocks++;\n\n                bytestream_put_be16(&ptr, 0);\n\n                buf_pos += 2;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (pred_blocks)\n\n        *I_frame = 0;\n\n    else\n\n        *I_frame = 1;\n\n\n\n    return buf_pos;\n\n}\n", "idx": 26338}
{"project": "FFmpeg", "commit_id": "32c3047cac9294bb56d23c89a40a22409db5cc70", "target": 0, "func": "static int smc_decode_init(AVCodecContext *avctx)\n\n{\n\n    SmcContext *s = avctx->priv_data;\n\n\n\n    s->avctx = avctx;\n\n    avctx->pix_fmt = PIX_FMT_PAL8;\n\n    dsputil_init(&s->dsp, avctx);\n\n\n\n    s->frame.data[0] = NULL;\n\n\n\n    return 0;\n\n}\n", "idx": 26342}
{"project": "FFmpeg", "commit_id": "403ee835e7913eb9536b22c2b22edfdd700166a9", "target": 0, "func": "int ff_mov_add_hinted_packet(AVFormatContext *s, AVPacket *pkt,\n\n                             int track_index, int sample)\n\n{\n\n    MOVMuxContext *mov = s->priv_data;\n\n    MOVTrack *trk = &mov->tracks[track_index];\n\n    AVFormatContext *rtp_ctx = trk->rtp_ctx;\n\n    uint8_t *buf = NULL;\n\n    int size;\n\n    AVIOContext *hintbuf = NULL;\n\n    AVPacket hint_pkt;\n\n    int ret = 0, count;\n\n\n\n    if (!rtp_ctx)\n\n        return AVERROR(ENOENT);\n\n    if (!rtp_ctx->pb)\n\n        return AVERROR(ENOMEM);\n\n\n\n    sample_queue_push(&trk->sample_queue, pkt, sample);\n\n\n\n    /* Feed the packet to the RTP muxer */\n\n    ff_write_chained(rtp_ctx, 0, pkt, s);\n\n\n\n    /* Fetch the output from the RTP muxer, open a new output buffer\n\n     * for next time. */\n\n    size = avio_close_dyn_buf(rtp_ctx->pb, &buf);\n\n    if ((ret = url_open_dyn_packet_buf(&rtp_ctx->pb,\n\n                                       RTP_MAX_PACKET_SIZE)) < 0)\n\n        goto done;\n\n\n\n    if (size <= 0)\n\n        goto done;\n\n\n\n    /* Open a buffer for writing the hint */\n\n    if ((ret = avio_open_dyn_buf(&hintbuf)) < 0)\n\n        goto done;\n\n    av_init_packet(&hint_pkt);\n\n    count = write_hint_packets(hintbuf, buf, size, trk, &hint_pkt.dts);\n\n    av_freep(&buf);\n\n\n\n    /* Write the hint data into the hint track */\n\n    hint_pkt.size = size = avio_close_dyn_buf(hintbuf, &buf);\n\n    hint_pkt.data = buf;\n\n    hint_pkt.pts  = hint_pkt.dts;\n\n    hint_pkt.stream_index = track_index;\n\n    if (pkt->flags & AV_PKT_FLAG_KEY)\n\n        hint_pkt.flags |= AV_PKT_FLAG_KEY;\n\n    if (count > 0)\n\n        ff_mov_write_packet(s, &hint_pkt);\n\ndone:\n\n    av_free(buf);\n\n    sample_queue_retain(&trk->sample_queue);\n\n    return ret;\n\n}\n", "idx": 26343}
{"project": "FFmpeg", "commit_id": "a4d3cf10b2ece441ae25849a66b1c11d838f9381", "target": 0, "func": "static void decode_lowdelay(DiracContext *s)\n\n{\n\n    AVCodecContext *avctx = s->avctx;\n\n    int slice_x, slice_y, bytes, bufsize;\n\n    const uint8_t *buf;\n\n    struct lowdelay_slice *slices;\n\n    int slice_num = 0;\n\n\n\n    slices = av_mallocz_array(s->lowdelay.num_x, s->lowdelay.num_y * sizeof(struct lowdelay_slice));\n\n\n\n    align_get_bits(&s->gb);\n\n    /*[DIRAC_STD] 13.5.2 Slices. slice(sx,sy) */\n\n    buf = s->gb.buffer + get_bits_count(&s->gb)/8;\n\n    bufsize = get_bits_left(&s->gb);\n\n\n\n    for (slice_y = 0; bufsize > 0 && slice_y < s->lowdelay.num_y; slice_y++)\n\n        for (slice_x = 0; bufsize > 0 && slice_x < s->lowdelay.num_x; slice_x++) {\n\n            bytes = (slice_num+1) * s->lowdelay.bytes.num / s->lowdelay.bytes.den\n\n                - slice_num    * s->lowdelay.bytes.num / s->lowdelay.bytes.den;\n\n\n\n            slices[slice_num].bytes   = bytes;\n\n            slices[slice_num].slice_x = slice_x;\n\n            slices[slice_num].slice_y = slice_y;\n\n            init_get_bits(&slices[slice_num].gb, buf, bufsize);\n\n            slice_num++;\n\n\n\n            buf     += bytes;\n\n            bufsize -= bytes*8;\n\n        }\n\n\n\n    avctx->execute(avctx, decode_lowdelay_slice, slices, NULL, slice_num,\n\n                   sizeof(struct lowdelay_slice)); /* [DIRAC_STD] 13.5.2 Slices */\n\n    intra_dc_prediction(&s->plane[0].band[0][0]);  /* [DIRAC_STD] 13.3 intra_dc_prediction() */\n\n    intra_dc_prediction(&s->plane[1].band[0][0]);  /* [DIRAC_STD] 13.3 intra_dc_prediction() */\n\n    intra_dc_prediction(&s->plane[2].band[0][0]);  /* [DIRAC_STD] 13.3 intra_dc_prediction() */\n\n    av_free(slices);\n\n}\n", "idx": 26344}
{"project": "FFmpeg", "commit_id": "b7e7ee6231bc1f3608ed4005c3e7550ec4815296", "target": 1, "func": "static void copy_video_props(AVFilterBufferRefVideoProps *dst, AVFilterBufferRefVideoProps *src) {\n\n    *dst = *src;\n\n    if (src->qp_table) {\n\n        int qsize = src->qp_table_size;\n\n        dst->qp_table = av_malloc(qsize);\n\n        memcpy(dst->qp_table, src->qp_table, qsize);\n\n    }\n\n}\n", "idx": 26345}
{"project": "FFmpeg", "commit_id": "3c6607eb6f946ed3e108db3f0694cab7e5a5df7e", "target": 1, "func": "int attribute_align_arg avcodec_encode_audio2(AVCodecContext *avctx,\n\n                                              AVPacket *avpkt,\n\n                                              const AVFrame *frame,\n\n                                              int *got_packet_ptr)\n\n{\n\n    int ret;\n\n    int user_packet = !!avpkt->data;\n\n    int nb_samples;\n\n\n\n    *got_packet_ptr = 0;\n\n\n\n    if (!(avctx->codec->capabilities & CODEC_CAP_DELAY) && !frame) {\n\n        av_free_packet(avpkt);\n\n        av_init_packet(avpkt);\n\n        avpkt->size = 0;\n\n        return 0;\n\n    }\n\n\n\n    /* check for valid frame size */\n\n    if (frame) {\n\n        nb_samples = frame->nb_samples;\n\n        if (avctx->codec->capabilities & CODEC_CAP_SMALL_LAST_FRAME) {\n\n            if (nb_samples > avctx->frame_size)\n\n                return AVERROR(EINVAL);\n\n        } else if (!(avctx->codec->capabilities & CODEC_CAP_VARIABLE_FRAME_SIZE)) {\n\n            if (nb_samples != avctx->frame_size)\n\n                return AVERROR(EINVAL);\n\n        }\n\n    } else {\n\n        nb_samples = avctx->frame_size;\n\n    }\n\n\n\n    if (avctx->codec->encode2) {\n\n        ret = avctx->codec->encode2(avctx, avpkt, frame, got_packet_ptr);\n\n        if (!ret && *got_packet_ptr) {\n\n            if (!(avctx->codec->capabilities & CODEC_CAP_DELAY)) {\n\n                if (avpkt->pts == AV_NOPTS_VALUE)\n\n                    avpkt->pts = frame->pts;\n\n                if (!avpkt->duration)\n\n                    avpkt->duration = ff_samples_to_time_base(avctx,\n\n                                                              frame->nb_samples);\n\n            }\n\n            avpkt->dts = avpkt->pts;\n\n        } else {\n\n            avpkt->size = 0;\n\n        }\n\n    } else {\n\n        /* for compatibility with encoders not supporting encode2(), we need to\n\n           allocate a packet buffer if the user has not provided one or check\n\n           the size otherwise */\n\n        int fs_tmp   = 0;\n\n        int buf_size = avpkt->size;\n\n        if (!user_packet) {\n\n            if (avctx->codec->capabilities & CODEC_CAP_VARIABLE_FRAME_SIZE) {\n\n                av_assert0(av_get_bits_per_sample(avctx->codec_id) != 0);\n\n                buf_size = nb_samples * avctx->channels *\n\n                           av_get_bits_per_sample(avctx->codec_id) / 8;\n\n            } else {\n\n                /* this is a guess as to the required size.\n\n                   if an encoder needs more than this, it should probably\n\n                   implement encode2() */\n\n                buf_size = 2 * avctx->frame_size * avctx->channels *\n\n                           av_get_bytes_per_sample(avctx->sample_fmt);\n\n                buf_size += FF_MIN_BUFFER_SIZE;\n\n            }\n\n        }\n\n        if ((ret = ff_alloc_packet(avpkt, buf_size)))\n\n            return ret;\n\n\n\n        /* Encoders using AVCodec.encode() that support\n\n           CODEC_CAP_SMALL_LAST_FRAME require avctx->frame_size to be set to\n\n           the smaller size when encoding the last frame.\n\n           This code can be removed once all encoders supporting\n\n           CODEC_CAP_SMALL_LAST_FRAME use encode2() */\n\n        if ((avctx->codec->capabilities & CODEC_CAP_SMALL_LAST_FRAME) &&\n\n            nb_samples < avctx->frame_size) {\n\n            fs_tmp = avctx->frame_size;\n\n            avctx->frame_size = nb_samples;\n\n        }\n\n\n\n        /* encode the frame */\n\n        ret = avctx->codec->encode(avctx, avpkt->data, avpkt->size,\n\n                                   frame ? frame->data[0] : NULL);\n\n        if (ret >= 0) {\n\n            if (!ret) {\n\n                /* no output. if the packet data was allocated by libavcodec,\n\n                   free it */\n\n                if (!user_packet)\n\n                    av_freep(&avpkt->data);\n\n            } else {\n\n                if (avctx->coded_frame)\n\n                    avpkt->pts = avpkt->dts = avctx->coded_frame->pts;\n\n                /* Set duration for final small packet. This can be removed\n\n                   once all encoders supporting CODEC_CAP_SMALL_LAST_FRAME use\n\n                   encode2() */\n\n                if (fs_tmp) {\n\n                    avpkt->duration = ff_samples_to_time_base(avctx,\n\n                                                              avctx->frame_size);\n\n                }\n\n            }\n\n            avpkt->size = ret;\n\n            *got_packet_ptr = (ret > 0);\n\n            ret = 0;\n\n        }\n\n\n\n        if (fs_tmp)\n\n            avctx->frame_size = fs_tmp;\n\n    }\n\n    if (!ret) {\n\n        if (!user_packet && avpkt->data) {\n\n            uint8_t *new_data = av_realloc(avpkt->data, avpkt->size);\n\n            if (new_data)\n\n                avpkt->data = new_data;\n\n        }\n\n\n\n        avctx->frame_number++;\n\n    }\n\n\n\n    if (ret < 0 || !*got_packet_ptr)\n\n        av_free_packet(avpkt);\n\n\n\n    /* NOTE: if we add any audio encoders which output non-keyframe packets,\n\n             this needs to be moved to the encoders, but for now we can do it\n\n             here to simplify things */\n\n    avpkt->flags |= AV_PKT_FLAG_KEY;\n\n\n\n    return ret;\n\n}\n", "idx": 26348}
{"project": "FFmpeg", "commit_id": "3c1199c3c4cbdb4ffff0de89f06d5a08acefe356", "target": 1, "func": "static int matroska_parse_frame(MatroskaDemuxContext *matroska,\n\n                                MatroskaTrack *track, AVStream *st,\n\n                                uint8_t *data, int pkt_size,\n\n                                uint64_t timecode, uint64_t duration,\n\n                                int64_t pos, int is_keyframe)\n\n{\n\n    MatroskaTrackEncoding *encodings = track->encodings.elem;\n\n    uint8_t *pkt_data = data;\n\n    int offset = 0, res;\n\n    AVPacket *pkt;\n\n\n\n    if (encodings && encodings->scope & 1) {\n\n        res = matroska_decode_buffer(&pkt_data, &pkt_size, track);\n\n        if (res < 0)\n\n            return res;\n\n    }\n\n\n\n    if (st->codec->codec_id == AV_CODEC_ID_WAVPACK) {\n\n        uint8_t *wv_data;\n\n        res = matroska_parse_wavpack(track, pkt_data, &wv_data, &pkt_size);\n\n        if (res < 0) {\n\n            av_log(matroska->ctx, AV_LOG_ERROR,\n\n                   \"Error parsing a wavpack block.\\n\");\n\n            goto fail;\n\n        }\n\n        if (pkt_data != data)\n\n\n        pkt_data = wv_data;\n\n    }\n\n\n\n    if (st->codec->codec_id == AV_CODEC_ID_PRORES)\n\n        offset = 8;\n\n\n\n    pkt = av_mallocz(sizeof(AVPacket));\n\n    /* XXX: prevent data copy... */\n\n    if (av_new_packet(pkt, pkt_size + offset) < 0) {\n\n        av_free(pkt);\n\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    if (st->codec->codec_id == AV_CODEC_ID_PRORES) {\n\n        uint8_t *buf = pkt->data;\n\n        bytestream_put_be32(&buf, pkt_size);\n\n        bytestream_put_be32(&buf, MKBETAG('i', 'c', 'p', 'f'));\n\n    }\n\n\n\n    memcpy(pkt->data + offset, pkt_data, pkt_size);\n\n\n\n    if (pkt_data != data)\n\n        av_free(pkt_data);\n\n\n\n    pkt->flags        = is_keyframe;\n\n    pkt->stream_index = st->index;\n\n\n\n    if (track->ms_compat)\n\n        pkt->dts = timecode;\n\n    else\n\n        pkt->pts = timecode;\n\n    pkt->pos = pos;\n\n    if (st->codec->codec_id == AV_CODEC_ID_TEXT)\n\n        pkt->convergence_duration = duration;\n\n    else if (track->type != MATROSKA_TRACK_TYPE_SUBTITLE)\n\n        pkt->duration = duration;\n\n\n\n    if (st->codec->codec_id == AV_CODEC_ID_SSA)\n\n        matroska_fix_ass_packet(matroska, pkt, duration);\n\n\n\n    if (matroska->prev_pkt                                 &&\n\n        timecode                         != AV_NOPTS_VALUE &&\n\n        matroska->prev_pkt->pts          == timecode       &&\n\n        matroska->prev_pkt->stream_index == st->index      &&\n\n        st->codec->codec_id == AV_CODEC_ID_SSA)\n\n        matroska_merge_packets(matroska->prev_pkt, pkt);\n\n    else {\n\n        dynarray_add(&matroska->packets, &matroska->num_packets, pkt);\n\n        matroska->prev_pkt = pkt;\n\n    }\n\n\n\n    return 0;\n\n\n\nfail:\n\n    if (pkt_data != data)\n\n\n    return res;\n\n}", "idx": 26352}
{"project": "FFmpeg", "commit_id": "0ecca7a49f8e254c12a3a1de048d738bfbb614c6", "target": 1, "func": "void *av_fast_realloc(void *ptr, unsigned int *size, unsigned int min_size)\n\n{\n\n    if(min_size < *size) \n\n        return ptr;\n\n    \n\n    *size= 17*min_size/16 + 32;\n\n\n\n    return av_realloc(ptr, *size);\n\n}\n", "idx": 26353}
{"project": "FFmpeg", "commit_id": "26c208cf0ff59efd7786528884a64d35fc42e9bf", "target": 0, "func": "static int get_video_frame(VideoState *is, AVFrame *frame, int64_t *pts, AVPacket *pkt, int *serial)\n\n{\n\n    int got_picture;\n\n\n\n    if (packet_queue_get(&is->videoq, pkt, 1, serial) < 0)\n\n        return -1;\n\n\n\n    if (pkt->data == flush_pkt.data) {\n\n        avcodec_flush_buffers(is->video_st->codec);\n\n\n\n        SDL_LockMutex(is->pictq_mutex);\n\n        // Make sure there are no long delay timers (ideally we should just flush the queue but that's harder)\n\n        while (is->pictq_size && !is->videoq.abort_request) {\n\n            SDL_CondWait(is->pictq_cond, is->pictq_mutex);\n\n        }\n\n        is->video_current_pos = -1;\n\n        is->frame_last_pts = AV_NOPTS_VALUE;\n\n        is->frame_last_duration = 0;\n\n        is->frame_timer = (double)av_gettime() / 1000000.0;\n\n        is->frame_last_dropped_pts = AV_NOPTS_VALUE;\n\n        SDL_UnlockMutex(is->pictq_mutex);\n\n\n\n        return 0;\n\n    }\n\n\n\n    if(avcodec_decode_video2(is->video_st->codec, frame, &got_picture, pkt) < 0)\n\n        return 0;\n\n\n\n    if (got_picture) {\n\n        int ret = 1;\n\n\n\n        if (decoder_reorder_pts == -1) {\n\n            *pts = av_frame_get_best_effort_timestamp(frame);\n\n        } else if (decoder_reorder_pts) {\n\n            *pts = frame->pkt_pts;\n\n        } else {\n\n            *pts = frame->pkt_dts;\n\n        }\n\n\n\n        if (*pts == AV_NOPTS_VALUE) {\n\n            *pts = 0;\n\n        }\n\n\n\n        if (framedrop>0 || (framedrop && get_master_sync_type(is) != AV_SYNC_VIDEO_MASTER)) {\n\n            SDL_LockMutex(is->pictq_mutex);\n\n            if (is->frame_last_pts != AV_NOPTS_VALUE && *pts) {\n\n                double clockdiff = get_video_clock(is) - get_master_clock(is);\n\n                double dpts = av_q2d(is->video_st->time_base) * *pts;\n\n                double ptsdiff = dpts - is->frame_last_pts;\n\n                if (fabs(clockdiff) < AV_NOSYNC_THRESHOLD &&\n\n                     ptsdiff > 0 && ptsdiff < AV_NOSYNC_THRESHOLD &&\n\n                     clockdiff + ptsdiff - is->frame_last_filter_delay < 0) {\n\n                    is->frame_last_dropped_pos = pkt->pos;\n\n                    is->frame_last_dropped_pts = dpts;\n\n                    is->frame_drops_early++;\n\n                    ret = 0;\n\n                }\n\n            }\n\n            SDL_UnlockMutex(is->pictq_mutex);\n\n        }\n\n\n\n        return ret;\n\n    }\n\n    return 0;\n\n}\n", "idx": 26354}
{"project": "FFmpeg", "commit_id": "b9fa32082c71013e90eab9e9997967d2939cf4a6", "target": 1, "func": "int ff_fft_init(FFTContext *s, int nbits, int inverse)\n\n{\n\n    int i, j, m, n;\n\n    float alpha, c1, s1, s2;\n\n    int shuffle = 0;\n\n    int av_unused has_vectors;\n\n\n\n    s->nbits = nbits;\n\n    n = 1 << nbits;\n\n\n\n    s->exptab = av_malloc((n / 2) * sizeof(FFTComplex));\n\n    if (!s->exptab)\n\n        goto fail;\n\n    s->revtab = av_malloc(n * sizeof(uint16_t));\n\n    if (!s->revtab)\n\n        goto fail;\n\n    s->inverse = inverse;\n\n\n\n    s2 = inverse ? 1.0 : -1.0;\n\n\n\n    for(i=0;i<(n/2);i++) {\n\n        alpha = 2 * M_PI * (float)i / (float)n;\n\n        c1 = cos(alpha);\n\n        s1 = sin(alpha) * s2;\n\n        s->exptab[i].re = c1;\n\n        s->exptab[i].im = s1;\n\n    }\n\n    s->fft_calc = ff_fft_calc_c;\n\n    s->imdct_calc = ff_imdct_calc;\n\n    s->imdct_half = ff_imdct_half;\n\n    s->exptab1 = NULL;\n\n\n\n#ifdef HAVE_MMX\n\n    has_vectors = mm_support();\n\n    shuffle = 1;\n\n    if (has_vectors & MM_3DNOWEXT) {\n\n        /* 3DNowEx for K7/K8 */\n\n        s->imdct_calc = ff_imdct_calc_3dn2;\n\n\n        s->fft_calc = ff_fft_calc_3dn2;\n\n    } else if (has_vectors & MM_3DNOW) {\n\n        /* 3DNow! for K6-2/3 */\n\n        s->fft_calc = ff_fft_calc_3dn;\n\n    } else if (has_vectors & MM_SSE) {\n\n        /* SSE for P3/P4 */\n\n        s->imdct_calc = ff_imdct_calc_sse;\n\n        s->imdct_half = ff_imdct_half_sse;\n\n        s->fft_calc = ff_fft_calc_sse;\n\n    } else {\n\n        shuffle = 0;\n\n    }\n\n#elif defined HAVE_ALTIVEC && !defined ALTIVEC_USE_REFERENCE_C_CODE\n\n    has_vectors = mm_support();\n\n    if (has_vectors & MM_ALTIVEC) {\n\n        s->fft_calc = ff_fft_calc_altivec;\n\n        shuffle = 1;\n\n    }\n\n#endif\n\n\n\n    /* compute constant table for HAVE_SSE version */\n\n    if (shuffle) {\n\n        int np, nblocks, np2, l;\n\n        FFTComplex *q;\n\n\n\n        np = 1 << nbits;\n\n        nblocks = np >> 3;\n\n        np2 = np >> 1;\n\n        s->exptab1 = av_malloc(np * 2 * sizeof(FFTComplex));\n\n        if (!s->exptab1)\n\n            goto fail;\n\n        q = s->exptab1;\n\n        do {\n\n            for(l = 0; l < np2; l += 2 * nblocks) {\n\n                *q++ = s->exptab[l];\n\n                *q++ = s->exptab[l + nblocks];\n\n\n\n                q->re = -s->exptab[l].im;\n\n                q->im = s->exptab[l].re;\n\n                q++;\n\n                q->re = -s->exptab[l + nblocks].im;\n\n                q->im = s->exptab[l + nblocks].re;\n\n                q++;\n\n            }\n\n            nblocks = nblocks >> 1;\n\n        } while (nblocks != 0);\n\n        av_freep(&s->exptab);\n\n    }\n\n\n\n    /* compute bit reverse table */\n\n\n\n    for(i=0;i<n;i++) {\n\n        m=0;\n\n        for(j=0;j<nbits;j++) {\n\n            m |= ((i >> j) & 1) << (nbits-j-1);\n\n        }\n\n        s->revtab[i]=m;\n\n    }\n\n    return 0;\n\n fail:\n\n    av_freep(&s->revtab);\n\n    av_freep(&s->exptab);\n\n    av_freep(&s->exptab1);\n\n    return -1;\n\n}", "idx": 26358}
{"project": "FFmpeg", "commit_id": "45daae06fd6f05baddb897686a6fa90cda3abb49", "target": 0, "func": "static void write_mainheader(NUTContext *nut, AVIOContext *bc)\n\n{\n\n    int i, j, tmp_pts, tmp_flags, tmp_stream, tmp_mul, tmp_size, tmp_fields,\n\n        tmp_head_idx;\n\n    int64_t tmp_match;\n\n\n\n    ff_put_v(bc, nut->version);\n\n    if (nut->version > 3)\n\n        ff_put_v(bc, nut->minor_version);\n\n    ff_put_v(bc, nut->avf->nb_streams);\n\n    ff_put_v(bc, nut->max_distance);\n\n    ff_put_v(bc, nut->time_base_count);\n\n\n\n    for (i = 0; i < nut->time_base_count; i++) {\n\n        ff_put_v(bc, nut->time_base[i].num);\n\n        ff_put_v(bc, nut->time_base[i].den);\n\n    }\n\n\n\n    tmp_pts      = 0;\n\n    tmp_mul      = 1;\n\n    tmp_stream   = 0;\n\n    tmp_match    = 1 - (1LL << 62);\n\n    tmp_head_idx = 0;\n\n    for (i = 0; i < 256; ) {\n\n        tmp_fields = 0;\n\n        tmp_size   = 0;\n\n//        tmp_res=0;\n\n        if (tmp_pts      != nut->frame_code[i].pts_delta ) tmp_fields = 1;\n\n        if (tmp_mul      != nut->frame_code[i].size_mul  ) tmp_fields = 2;\n\n        if (tmp_stream   != nut->frame_code[i].stream_id ) tmp_fields = 3;\n\n        if (tmp_size     != nut->frame_code[i].size_lsb  ) tmp_fields = 4;\n\n//        if (tmp_res    != nut->frame_code[i].res            ) tmp_fields=5;\n\n        if (tmp_head_idx != nut->frame_code[i].header_idx) tmp_fields = 8;\n\n\n\n        tmp_pts    = nut->frame_code[i].pts_delta;\n\n        tmp_flags  = nut->frame_code[i].flags;\n\n        tmp_stream = nut->frame_code[i].stream_id;\n\n        tmp_mul    = nut->frame_code[i].size_mul;\n\n        tmp_size   = nut->frame_code[i].size_lsb;\n\n//        tmp_res   = nut->frame_code[i].res;\n\n        tmp_head_idx = nut->frame_code[i].header_idx;\n\n\n\n        for (j = 0; i < 256; j++, i++) {\n\n            if (i == 'N') {\n\n                j--;\n\n                continue;\n\n            }\n\n            if (nut->frame_code[i].pts_delta  != tmp_pts      ||\n\n                nut->frame_code[i].flags      != tmp_flags    ||\n\n                nut->frame_code[i].stream_id  != tmp_stream   ||\n\n                nut->frame_code[i].size_mul   != tmp_mul      ||\n\n                nut->frame_code[i].size_lsb   != tmp_size + j ||\n\n//              nut->frame_code[i].res        != tmp_res      ||\n\n                nut->frame_code[i].header_idx != tmp_head_idx)\n\n                break;\n\n        }\n\n        if (j != tmp_mul - tmp_size)\n\n            tmp_fields = 6;\n\n\n\n        ff_put_v(bc, tmp_flags);\n\n        ff_put_v(bc, tmp_fields);\n\n        if (tmp_fields > 0) put_s(bc, tmp_pts);\n\n        if (tmp_fields > 1) ff_put_v(bc, tmp_mul);\n\n        if (tmp_fields > 2) ff_put_v(bc, tmp_stream);\n\n        if (tmp_fields > 3) ff_put_v(bc, tmp_size);\n\n        if (tmp_fields > 4) ff_put_v(bc, 0 /*tmp_res*/);\n\n        if (tmp_fields > 5) ff_put_v(bc, j);\n\n        if (tmp_fields > 6) ff_put_v(bc, tmp_match);\n\n        if (tmp_fields > 7) ff_put_v(bc, tmp_head_idx);\n\n    }\n\n    ff_put_v(bc, nut->header_count - 1);\n\n    for (i = 1; i < nut->header_count; i++) {\n\n        ff_put_v(bc, nut->header_len[i]);\n\n        avio_write(bc, nut->header[i], nut->header_len[i]);\n\n    }\n\n    // flags had been effectively introduced in version 4\n\n    if (nut->version > NUT_STABLE_VERSION)\n\n        ff_put_v(bc, nut->flags);\n\n}\n", "idx": 26359}
{"project": "FFmpeg", "commit_id": "01e4537f66c6d054f8c7bdbdd5b3cfb4220d12fe", "target": 0, "func": "static void flat_print_key_prefix(WriterContext *wctx)\n\n{\n\n    FlatContext *flat = wctx->priv;\n\n    const struct section *parent_section = wctx->section[wctx->level-1];\n\n\n\n    printf(\"%s\", flat->section_header[wctx->level].str);\n\n\n\n    if (parent_section->flags & SECTION_FLAG_IS_ARRAY) {\n\n        int n = parent_section->id == SECTION_ID_PACKETS_AND_FRAMES ?\n\n            wctx->nb_section_packet_frame : wctx->nb_item[wctx->level-1];\n\n        printf(\"%d%s\", n, flat->sep_str);\n\n    }\n\n}\n", "idx": 26360}
{"project": "FFmpeg", "commit_id": "bac9c03ed9328c63aba46e280ba408431b53fcb4", "target": 1, "func": "static int mov_text_decode_frame(AVCodecContext *avctx,\n                            void *data, int *got_sub_ptr, AVPacket *avpkt)\n{\n    AVSubtitle *sub = data;\n    MovTextContext *m = avctx->priv_data;\n    int ret;\n    AVBPrint buf;\n    char *ptr = avpkt->data;\n    char *end;\n    int text_length, tsmb_type, ret_tsmb;\n    uint64_t tsmb_size;\n    const uint8_t *tsmb;\n    if (!ptr || avpkt->size < 2)\n        return AVERROR_INVALIDDATA;\n    /*\n     * A packet of size two with value zero is an empty subtitle\n     * used to mark the end of the previous non-empty subtitle.\n     * We can just drop them here as we have duration information\n     * already. If the value is non-zero, then it's technically a\n     * bad packet.\n     */\n    if (avpkt->size == 2)\n        return AV_RB16(ptr) == 0 ? 0 : AVERROR_INVALIDDATA;\n    /*\n     * The first two bytes of the packet are the length of the text string\n     * In complex cases, there are style descriptors appended to the string\n     * so we can't just assume the packet size is the string size.\n     */\n    text_length = AV_RB16(ptr);\n    end = ptr + FFMIN(2 + text_length, avpkt->size);\n    ptr += 2;\n    tsmb_size = 0;\n    m->tracksize = 2 + text_length;\n    m->style_entries = 0;\n    m->box_flags = 0;\n    m->count_s = 0;\n    // Note that the spec recommends lines be no longer than 2048 characters.\n    av_bprint_init(&buf, 0, AV_BPRINT_SIZE_UNLIMITED);\n    if (text_length + 2 != avpkt->size) {\n        while (m->tracksize + 8 <= avpkt->size) {\n            // A box is a minimum of 8 bytes.\n            tsmb = ptr + m->tracksize - 2;\n            tsmb_size = AV_RB32(tsmb);\n            tsmb += 4;\n            tsmb_type = AV_RB32(tsmb);\n            tsmb += 4;\n            if (tsmb_size == 1) {\n                if (m->tracksize + 16 > avpkt->size)\n                    break;\n                tsmb_size = AV_RB64(tsmb);\n                tsmb += 8;\n                m->size_var = 16;\n            } else\n                m->size_var = 8;\n            //size_var is equal to 8 or 16 depending on the size of box\n            if (tsmb_size == 0) {\n                av_log(avctx, AV_LOG_ERROR, \"tsmb_size is 0\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            if (tsmb_size > avpkt->size - m->tracksize)\n                break;\n            for (size_t i = 0; i < box_count; i++) {\n                if (tsmb_type == box_types[i].type) {\n                    if (m->tracksize + m->size_var + box_types[i].base_size > avpkt->size)\n                        break;\n                    ret_tsmb = box_types[i].decode(tsmb, m, avpkt);\n                    if (ret_tsmb == -1)\n                        break;\n                }\n            }\n            m->tracksize = m->tracksize + tsmb_size;\n        }\n        text_to_ass(&buf, ptr, end, m);\n    } else\n        text_to_ass(&buf, ptr, end, m);\n    ret = ff_ass_add_rect(sub, buf.str, m->readorder++, 0, NULL, NULL);\n    av_bprint_finalize(&buf, NULL);\n    if (ret < 0)\n        return ret;\n    *got_sub_ptr = sub->num_rects > 0;\n    return avpkt->size;\n}", "idx": 26363}
{"project": "FFmpeg", "commit_id": "53c0c637d36c1de9ea461a8d863e8703da090894", "target": 1, "func": "static int ra144_decode_frame(AVCodecContext * avctx, void *data,\n\n                              int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    AVFrame *frame     = data;\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    static const uint8_t sizes[LPC_ORDER] = {6, 5, 5, 4, 4, 3, 3, 3, 3, 2};\n\n    unsigned int refl_rms[NBLOCKS];           // RMS of the reflection coefficients\n\n    int16_t block_coefs[NBLOCKS][LPC_ORDER];  // LPC coefficients of each sub-block\n\n    unsigned int lpc_refl[LPC_ORDER];         // LPC reflection coefficients of the frame\n\n    int i, j;\n\n    int ret;\n\n    int16_t *samples;\n\n    unsigned int energy;\n\n\n\n    RA144Context *ractx = avctx->priv_data;\n\n    GetBitContext gb;\n\n\n\n    if (buf_size < FRAME_SIZE) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Frame too small (%d bytes). Truncated file?\\n\", buf_size);\n\n        *got_frame_ptr = 0;\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* get output buffer */\n\n    frame->nb_samples = NBLOCKS * BLOCKSIZE;\n\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n\n        return ret;\n\n    samples = (int16_t *)frame->data[0];\n\n\n\n    init_get_bits8(&gb, buf, FRAME_SIZE);\n\n\n\n    for (i = 0; i < LPC_ORDER; i++)\n\n        lpc_refl[i] = ff_lpc_refl_cb[i][get_bits(&gb, sizes[i])];\n\n\n\n    ff_eval_coefs(ractx->lpc_coef[0], lpc_refl);\n\n    ractx->lpc_refl_rms[0] = ff_rms(lpc_refl);\n\n\n\n    energy = ff_energy_tab[get_bits(&gb, 5)];\n\n\n\n    refl_rms[0] = ff_interp(ractx, block_coefs[0], 1, 1, ractx->old_energy);\n\n    refl_rms[1] = ff_interp(ractx, block_coefs[1], 2,\n\n                            energy <= ractx->old_energy,\n\n                            ff_t_sqrt(energy*ractx->old_energy) >> 12);\n\n    refl_rms[2] = ff_interp(ractx, block_coefs[2], 3, 0, energy);\n\n    refl_rms[3] = ff_rescale_rms(ractx->lpc_refl_rms[0], energy);\n\n\n\n    ff_int_to_int16(block_coefs[3], ractx->lpc_coef[0]);\n\n\n\n    for (i=0; i < NBLOCKS; i++) {\n\n        do_output_subblock(ractx, block_coefs[i], refl_rms[i], &gb);\n\n\n\n        for (j=0; j < BLOCKSIZE; j++)\n\n            *samples++ = av_clip_int16(ractx->curr_sblock[j + 10] << 2);\n\n    }\n\n\n\n    ractx->old_energy = energy;\n\n    ractx->lpc_refl_rms[1] = ractx->lpc_refl_rms[0];\n\n\n\n    FFSWAP(unsigned int *, ractx->lpc_coef[0], ractx->lpc_coef[1]);\n\n\n\n    *got_frame_ptr = 1;\n\n\n\n    return FRAME_SIZE;\n\n}\n", "idx": 26364}
{"project": "FFmpeg", "commit_id": "b97d21e4d6813498f458777ff42c7eab1eed3adf", "target": 1, "func": "static int sdp_parse_fmtp_config_h264(AVStream *stream,\n\n                                      PayloadContext *h264_data,\n\n                                      char *attr, char *value)\n\n{\n\n    AVCodecContext *codec = stream->codec;\n\n    assert(codec->codec_id == CODEC_ID_H264);\n\n    assert(h264_data != NULL);\n\n\n\n    if (!strcmp(attr, \"packetization-mode\")) {\n\n        av_log(codec, AV_LOG_DEBUG, \"RTP Packetization Mode: %d\\n\", atoi(value));\n\n        h264_data->packetization_mode = atoi(value);\n\n        /*\n\n         * Packetization Mode:\n\n         * 0 or not present: Single NAL mode (Only nals from 1-23 are allowed)\n\n         * 1: Non-interleaved Mode: 1-23, 24 (STAP-A), 28 (FU-A) are allowed.\n\n         * 2: Interleaved Mode: 25 (STAP-B), 26 (MTAP16), 27 (MTAP24), 28 (FU-A),\n\n         *                      and 29 (FU-B) are allowed.\n\n         */\n\n        if (h264_data->packetization_mode > 1)\n\n            av_log(codec, AV_LOG_ERROR,\n\n                   \"Interleaved RTP mode is not supported yet.\");\n\n    } else if (!strcmp(attr, \"profile-level-id\")) {\n\n        if (strlen(value) == 6) {\n\n            char buffer[3];\n\n            // 6 characters=3 bytes, in hex.\n\n            uint8_t profile_idc;\n\n            uint8_t profile_iop;\n\n            uint8_t level_idc;\n\n\n\n            buffer[0]   = value[0];\n\n            buffer[1]   = value[1];\n\n            buffer[2]   = '\\0';\n\n            profile_idc = strtol(buffer, NULL, 16);\n\n            buffer[0]   = value[2];\n\n            buffer[1]   = value[3];\n\n            profile_iop = strtol(buffer, NULL, 16);\n\n            buffer[0]   = value[4];\n\n            buffer[1]   = value[5];\n\n            level_idc   = strtol(buffer, NULL, 16);\n\n\n\n            av_log(codec, AV_LOG_DEBUG,\n\n                   \"RTP Profile IDC: %x Profile IOP: %x Level: %x\\n\",\n\n                   profile_idc, profile_iop, level_idc);\n\n            h264_data->profile_idc = profile_idc;\n\n            h264_data->profile_iop = profile_iop;\n\n            h264_data->level_idc   = level_idc;\n\n        }\n\n    } else if (!strcmp(attr, \"sprop-parameter-sets\")) {\n\n        codec->extradata_size = 0;\n\n        codec->extradata      = NULL;\n\n\n\n        while (*value) {\n\n            char base64packet[1024];\n\n            uint8_t decoded_packet[1024];\n\n            int packet_size;\n\n            char *dst = base64packet;\n\n\n\n            while (*value && *value != ','\n\n                   && (dst - base64packet) < sizeof(base64packet) - 1) {\n\n                *dst++ = *value++;\n\n            }\n\n            *dst++ = '\\0';\n\n\n\n            if (*value == ',')\n\n                value++;\n\n\n\n            packet_size = av_base64_decode(decoded_packet, base64packet,\n\n                                           sizeof(decoded_packet));\n\n            if (packet_size > 0) {\n\n                uint8_t *dest = av_malloc(packet_size + sizeof(start_sequence) +\n\n                                          codec->extradata_size +\n\n                                          FF_INPUT_BUFFER_PADDING_SIZE);\n\n                if (!dest) {\n\n                    av_log(codec, AV_LOG_ERROR,\n\n                           \"Unable to allocate memory for extradata!\");\n\n                    return AVERROR(ENOMEM);\n\n                }\n\n                if (codec->extradata_size) {\n\n                    memcpy(dest, codec->extradata, codec->extradata_size);\n\n                    av_free(codec->extradata);\n\n                }\n\n\n\n                memcpy(dest + codec->extradata_size, start_sequence,\n\n                       sizeof(start_sequence));\n\n                memcpy(dest + codec->extradata_size + sizeof(start_sequence),\n\n                       decoded_packet, packet_size);\n\n                memset(dest + codec->extradata_size + sizeof(start_sequence) +\n\n                       packet_size, 0, FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n                codec->extradata       = dest;\n\n                codec->extradata_size += sizeof(start_sequence) + packet_size;\n\n            }\n\n        }\n\n        av_log(codec, AV_LOG_DEBUG, \"Extradata set to %p (size: %d)!\",\n\n               codec->extradata, codec->extradata_size);\n\n    }\n\n    return 0;\n\n}\n", "idx": 26367}
{"project": "FFmpeg", "commit_id": "95b192de5d05f3e1542e7b2378cdefbc195f5185", "target": 0, "func": "static int decode_sequence_header_adv(VC1Context *v, GetBitContext *gb)\n\n{\n\n    v->res_rtm_flag = 1;\n\n    v->level = get_bits(gb, 3);\n\n    if (v->level >= 5) {\n\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Reserved LEVEL %i\\n\",v->level);\n\n    }\n\n    v->chromaformat = get_bits(gb, 2);\n\n    if (v->chromaformat != 1) {\n\n        av_log(v->s.avctx, AV_LOG_ERROR,\n\n               \"Only 4:2:0 chroma format supported\\n\");\n\n        return -1;\n\n    }\n\n\n\n    // (fps-2)/4 (->30)\n\n    v->frmrtq_postproc       = get_bits(gb, 3); //common\n\n    // (bitrate-32kbps)/64kbps\n\n    v->bitrtq_postproc       = get_bits(gb, 5); //common\n\n    v->postprocflag          = get_bits1(gb);   //common\n\n\n\n    v->s.avctx->coded_width  = (get_bits(gb, 12) + 1) << 1;\n\n    v->s.avctx->coded_height = (get_bits(gb, 12) + 1) << 1;\n\n    v->s.avctx->width        = v->s.avctx->coded_width;\n\n    v->s.avctx->height       = v->s.avctx->coded_height;\n\n    v->broadcast             = get_bits1(gb);\n\n    v->interlace             = get_bits1(gb);\n\n    v->tfcntrflag            = get_bits1(gb);\n\n    v->finterpflag           = get_bits1(gb);\n\n    skip_bits1(gb); // reserved\n\n\n\n    av_log(v->s.avctx, AV_LOG_DEBUG,\n\n           \"Advanced Profile level %i:\\nfrmrtq_postproc=%i, bitrtq_postproc=%i\\n\"\n\n           \"LoopFilter=%i, ChromaFormat=%i, Pulldown=%i, Interlace: %i\\n\"\n\n           \"TFCTRflag=%i, FINTERPflag=%i\\n\",\n\n           v->level, v->frmrtq_postproc, v->bitrtq_postproc,\n\n           v->s.loop_filter, v->chromaformat, v->broadcast, v->interlace,\n\n           v->tfcntrflag, v->finterpflag);\n\n\n\n    v->psf = get_bits1(gb);\n\n    if (v->psf) { //PsF, 6.1.13\n\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Progressive Segmented Frame mode: not supported (yet)\\n\");\n\n        return -1;\n\n    }\n\n    v->s.max_b_frames = v->s.avctx->max_b_frames = 7;\n\n    if (get_bits1(gb)) { //Display Info - decoding is not affected by it\n\n        int w, h, ar = 0;\n\n        av_log(v->s.avctx, AV_LOG_DEBUG, \"Display extended info:\\n\");\n\n        w = get_bits(gb, 14) + 1;\n\n        h = get_bits(gb, 14) + 1;\n\n        av_log(v->s.avctx, AV_LOG_DEBUG, \"Display dimensions: %ix%i\\n\", w, h);\n\n        if (get_bits1(gb))\n\n            ar = get_bits(gb, 4);\n\n        if (ar && ar < 14) {\n\n            v->s.avctx->sample_aspect_ratio = ff_vc1_pixel_aspect[ar];\n\n        } else if (ar == 15) {\n\n            w = get_bits(gb, 8) + 1;\n\n            h = get_bits(gb, 8) + 1;\n\n            v->s.avctx->sample_aspect_ratio = (AVRational){w, h};\n\n        } else {\n\n            av_reduce(&v->s.avctx->sample_aspect_ratio.num,\n\n                      &v->s.avctx->sample_aspect_ratio.den,\n\n                      v->s.avctx->height * w,\n\n                      v->s.avctx->width * h,\n\n                      1 << 30);\n\n        }\n\n        av_log(v->s.avctx, AV_LOG_DEBUG, \"Aspect: %i:%i\\n\",\n\n               v->s.avctx->sample_aspect_ratio.num,\n\n               v->s.avctx->sample_aspect_ratio.den);\n\n\n\n        if (get_bits1(gb)) { //framerate stuff\n\n            if (get_bits1(gb)) {\n\n                v->s.avctx->time_base.num = 32;\n\n                v->s.avctx->time_base.den = get_bits(gb, 16) + 1;\n\n            } else {\n\n                int nr, dr;\n\n                nr = get_bits(gb, 8);\n\n                dr = get_bits(gb, 4);\n\n                if (nr && nr < 8 && dr && dr < 3) {\n\n                    v->s.avctx->time_base.num = ff_vc1_fps_dr[dr - 1];\n\n                    v->s.avctx->time_base.den = ff_vc1_fps_nr[nr - 1] * 1000;\n\n                }\n\n            }\n\n            if (v->broadcast) { // Pulldown may be present\n\n                v->s.avctx->time_base.den  *= 2;\n\n                v->s.avctx->ticks_per_frame = 2;\n\n            }\n\n        }\n\n\n\n        if (get_bits1(gb)) {\n\n            v->color_prim    = get_bits(gb, 8);\n\n            v->transfer_char = get_bits(gb, 8);\n\n            v->matrix_coef   = get_bits(gb, 8);\n\n        }\n\n    }\n\n\n\n    v->hrd_param_flag = get_bits1(gb);\n\n    if (v->hrd_param_flag) {\n\n        int i;\n\n        v->hrd_num_leaky_buckets = get_bits(gb, 5);\n\n        skip_bits(gb, 4); //bitrate exponent\n\n        skip_bits(gb, 4); //buffer size exponent\n\n        for (i = 0; i < v->hrd_num_leaky_buckets; i++) {\n\n            skip_bits(gb, 16); //hrd_rate[n]\n\n            skip_bits(gb, 16); //hrd_buffer[n]\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 26370}
{"project": "FFmpeg", "commit_id": "c04643a2c24564aed96a5b0760de8bf02eb305c6", "target": 0, "func": "void opt_input_file(const char *filename)\n\n{\n\n    AVFormatContext *ic;\n\n    AVFormatParameters params, *ap = &params;\n\n    int err, i, ret, rfps;\n\n\n\n    /* get default parameters from command line */\n\n    memset(ap, 0, sizeof(*ap));\n\n    ap->sample_rate = audio_sample_rate;\n\n    ap->channels = audio_channels;\n\n    ap->frame_rate = frame_rate;\n\n    ap->width = frame_width;\n\n    ap->height = frame_height;\n\n\n\n    /* open the input file with generic libav function */\n\n    err = av_open_input_file(&ic, filename, file_iformat, 0, ap);\n\n    if (err < 0) {\n\n        print_error(filename, err);\n\n        exit(1);\n\n    }\n\n    \n\n    /* If not enough info to get the stream parameters, we decode the\n\n       first frames to get it. (used in mpeg case for example) */\n\n    ret = av_find_stream_info(ic);\n\n    if (ret < 0) {\n\n        fprintf(stderr, \"%s: could not find codec parameters\\n\", filename);\n\n        exit(1);\n\n    }\n\n\n\n    /* update the current parameters so that they match the one of the input stream */\n\n    for(i=0;i<ic->nb_streams;i++) {\n\n        AVCodecContext *enc = &ic->streams[i]->codec;\n\n        switch(enc->codec_type) {\n\n        case CODEC_TYPE_AUDIO:\n\n            //fprintf(stderr, \"\\nInput Audio channels: %d\", enc->channels);\n\n            audio_channels = enc->channels;\n\n            audio_sample_rate = enc->sample_rate;\n\n            break;\n\n        case CODEC_TYPE_VIDEO:\n\n            frame_height = enc->height;\n\n            frame_width = enc->width;\n\n            rfps = ic->streams[i]->r_frame_rate;\n\n            if (enc->frame_rate != rfps) {\n\n                fprintf(stderr,\"\\nSeems that stream %d comes from film source: %2.2f->%2.2f\\n\",\n\n                    i, (float)enc->frame_rate / FRAME_RATE_BASE,\n\n                    (float)rfps / FRAME_RATE_BASE);\n\n            }\n\n            /* update the current frame rate to match the stream frame rate */\n\n            frame_rate = rfps;\n\n            break;\n\n        default:\n\n            abort();\n\n        }\n\n    }\n\n    \n\n    input_files[nb_input_files] = ic;\n\n    /* dump the file content */\n\n    dump_format(ic, nb_input_files, filename, 0);\n\n    nb_input_files++;\n\n    file_iformat = NULL;\n\n    file_oformat = NULL;\n\n}\n", "idx": 26376}
{"project": "FFmpeg", "commit_id": "8805589b803fab5f362008306319336ac79a3fa7", "target": 1, "func": "static int parse_iplconvkernel(IplConvKernel **kernel, char *buf, void *log_ctx)\n\n{\n\n    char shape_filename[128] = \"\", shape_str[32] = \"rect\";\n\n    int cols = 0, rows = 0, anchor_x = 0, anchor_y = 0, shape = CV_SHAPE_RECT;\n\n    int *values = NULL, ret;\n\n\n\n    sscanf(buf, \"%dx%d+%dx%d/%32[^=]=%127s\", &cols, &rows, &anchor_x, &anchor_y, shape_str, shape_filename);\n\n\n\n    if      (!strcmp(shape_str, \"rect\"   )) shape = CV_SHAPE_RECT;\n\n    else if (!strcmp(shape_str, \"cross\"  )) shape = CV_SHAPE_CROSS;\n\n    else if (!strcmp(shape_str, \"ellipse\")) shape = CV_SHAPE_ELLIPSE;\n\n    else if (!strcmp(shape_str, \"custom\" )) {\n\n        shape = CV_SHAPE_CUSTOM;\n\n        if ((ret = read_shape_from_file(&cols, &rows, &values, shape_filename, log_ctx)) < 0)\n\n            return ret;\n\n    } else {\n\n        av_log(log_ctx, AV_LOG_ERROR,\n\n               \"Shape unspecified or type '%s' unknown.\\n\", shape_str);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (rows <= 0 || cols <= 0) {\n\n        av_log(log_ctx, AV_LOG_ERROR,\n\n               \"Invalid non-positive values for shape size %dx%d\\n\", cols, rows);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (anchor_x < 0 || anchor_y < 0 || anchor_x >= cols || anchor_y >= rows) {\n\n        av_log(log_ctx, AV_LOG_ERROR,\n\n               \"Shape anchor %dx%d is not inside the rectangle with size %dx%d.\\n\",\n\n               anchor_x, anchor_y, cols, rows);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    *kernel = cvCreateStructuringElementEx(cols, rows, anchor_x, anchor_y, shape, values);\n\n    av_freep(&values);\n\n    if (!*kernel)\n\n        return AVERROR(ENOMEM);\n\n\n\n    av_log(log_ctx, AV_LOG_VERBOSE, \"Structuring element: w:%d h:%d x:%d y:%d shape:%s\\n\",\n\n           rows, cols, anchor_x, anchor_y, shape_str);\n\n    return 0;\n\n}\n", "idx": 26378}
{"project": "FFmpeg", "commit_id": "a852db796edce2792525d88ab47cf78222e01512", "target": 1, "func": "static int encode_apng(AVCodecContext *avctx, AVPacket *pkt,\n                       const AVFrame *pict, int *got_packet)\n{\n    PNGEncContext *s = avctx->priv_data;\n    int ret;\n    int enc_row_size;\n    size_t max_packet_size;\n    APNGFctlChunk fctl_chunk = {0};\n    if (pict && avctx->codec_id == AV_CODEC_ID_APNG && s->color_type == PNG_COLOR_TYPE_PALETTE) {\n        uint32_t checksum = ~av_crc(av_crc_get_table(AV_CRC_32_IEEE_LE), ~0U, pict->data[1], 256 * sizeof(uint32_t));\n        if (avctx->frame_number == 0) {\n            s->palette_checksum = checksum;\n        } else if (checksum != s->palette_checksum) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"Input contains more than one unique palette. APNG does not support multiple palettes.\\n\");\n            return -1;\n        }\n    }\n    enc_row_size    = deflateBound(&s->zstream, (avctx->width * s->bits_per_pixel + 7) >> 3);\n    max_packet_size =\n        AV_INPUT_BUFFER_MIN_SIZE + // headers\n        avctx->height * (\n            enc_row_size +\n            (4 + 12) * (((int64_t)enc_row_size + IOBUF_SIZE - 1) / IOBUF_SIZE) // fdAT * ceil(enc_row_size / IOBUF_SIZE)\n        );\n    if (max_packet_size > INT_MAX)\n        return AVERROR(ENOMEM);\n    if (avctx->frame_number == 0) {\n        s->bytestream = avctx->extradata = av_malloc(FF_MIN_BUFFER_SIZE);\n        if (!avctx->extradata)\n            return AVERROR(ENOMEM);\n        ret = encode_headers(avctx, pict);\n        if (ret < 0)\n            return ret;\n        avctx->extradata_size = s->bytestream - avctx->extradata;\n        s->last_frame_packet = av_malloc(max_packet_size);\n        if (!s->last_frame_packet)\n            return AVERROR(ENOMEM);\n    } else if (s->last_frame) {\n        ret = ff_alloc_packet2(avctx, pkt, max_packet_size, 0);\n        if (ret < 0)\n            return ret;\n        memcpy(pkt->data, s->last_frame_packet, s->last_frame_packet_size);\n        pkt->size = s->last_frame_packet_size;\n        pkt->pts = pkt->dts = s->last_frame->pts;\n    }\n    if (pict) {\n        s->bytestream_start =\n        s->bytestream       = s->last_frame_packet;\n        s->bytestream_end   = s->bytestream + max_packet_size;\n        // We're encoding the frame first, so we have to do a bit of shuffling around\n        // to have the image data write to the correct place in the buffer\n        fctl_chunk.sequence_number = s->sequence_number;\n        ++s->sequence_number;\n        s->bytestream += 26 + 12;\n        ret = apng_encode_frame(avctx, pict, &fctl_chunk, &s->last_frame_fctl);\n        if (ret < 0)\n            return ret;\n        fctl_chunk.delay_num = 0; // delay filled in during muxing\n        fctl_chunk.delay_den = 0;\n    } else {\n        s->last_frame_fctl.dispose_op = APNG_DISPOSE_OP_NONE;\n    }\n    if (s->last_frame) {\n        uint8_t* last_fctl_chunk_start = pkt->data;\n        uint8_t buf[26];\n        AV_WB32(buf + 0, s->last_frame_fctl.sequence_number);\n        AV_WB32(buf + 4, s->last_frame_fctl.width);\n        AV_WB32(buf + 8, s->last_frame_fctl.height);\n        AV_WB32(buf + 12, s->last_frame_fctl.x_offset);\n        AV_WB32(buf + 16, s->last_frame_fctl.y_offset);\n        AV_WB16(buf + 20, s->last_frame_fctl.delay_num);\n        AV_WB16(buf + 22, s->last_frame_fctl.delay_den);\n        buf[24] = s->last_frame_fctl.dispose_op;\n        buf[25] = s->last_frame_fctl.blend_op;\n        png_write_chunk(&last_fctl_chunk_start, MKTAG('f', 'c', 'T', 'L'), buf, 26);\n        *got_packet = 1;\n    }\n    if (pict) {\n        if (!s->last_frame) {\n            s->last_frame = av_frame_alloc();\n            if (!s->last_frame)\n                return AVERROR(ENOMEM);\n        } else if (s->last_frame_fctl.dispose_op != APNG_DISPOSE_OP_PREVIOUS) {\n            if (!s->prev_frame) {\n                s->prev_frame = av_frame_alloc();\n                if (!s->prev_frame)\n                    return AVERROR(ENOMEM);\n                s->prev_frame->format = pict->format;\n                s->prev_frame->width = pict->width;\n                s->prev_frame->height = pict->height;\n                if ((ret = av_frame_get_buffer(s->prev_frame, 32)) < 0)\n                    return ret;\n            }\n            // Do disposal, but not blending\n            memcpy(s->prev_frame->data[0], s->last_frame->data[0],\n                   s->last_frame->linesize[0] * s->last_frame->height);\n            if (s->last_frame_fctl.dispose_op == APNG_DISPOSE_OP_BACKGROUND) {\n                uint32_t y;\n                uint8_t bpp = (s->bits_per_pixel + 7) >> 3;\n                for (y = s->last_frame_fctl.y_offset; y < s->last_frame_fctl.y_offset + s->last_frame_fctl.height; ++y) {\n                    size_t row_start = s->last_frame->linesize[0] * y + bpp * s->last_frame_fctl.x_offset;\n                    memset(s->prev_frame->data[0] + row_start, 0, bpp * s->last_frame_fctl.width);\n                }\n            }\n        }\n        av_frame_unref(s->last_frame);\n        ret = av_frame_ref(s->last_frame, (AVFrame*)pict);\n        if (ret < 0)\n            return ret;\n        s->last_frame_fctl = fctl_chunk;\n        s->last_frame_packet_size = s->bytestream - s->bytestream_start;\n    } else {\n        av_frame_free(&s->last_frame);\n    }\n    return 0;\n}", "idx": 26379}
{"project": "FFmpeg", "commit_id": "30011bf20109eef1a0f9ee949b19f9998ad88663", "target": 1, "func": "void decode_mb_mode(VP8Context *s, VP8Macroblock *mb, int mb_x, int mb_y, uint8_t *segment, uint8_t *ref)\n\n{\n\n    VP56RangeCoder *c = &s->c;\n\n\n\n    if (s->segmentation.update_map)\n\n        *segment = vp8_rac_get_tree(c, vp8_segmentid_tree, s->prob->segmentid);\n\n    else\n\n        *segment = ref ? *ref : *segment;\n\n    s->segment = *segment;\n\n\n\n    mb->skip = s->mbskip_enabled ? vp56_rac_get_prob(c, s->prob->mbskip) : 0;\n\n\n\n    if (s->keyframe) {\n\n        mb->mode = vp8_rac_get_tree(c, vp8_pred16x16_tree_intra, vp8_pred16x16_prob_intra);\n\n\n\n        if (mb->mode == MODE_I4x4) {\n\n            decode_intra4x4_modes(s, c, mb_x, 1);\n\n        } else {\n\n            const uint32_t modes = vp8_pred4x4_mode[mb->mode] * 0x01010101u;\n\n            AV_WN32A(s->intra4x4_pred_mode_top + 4 * mb_x, modes);\n\n            AV_WN32A(s->intra4x4_pred_mode_left, modes);\n\n        }\n\n\n\n        s->chroma_pred_mode = vp8_rac_get_tree(c, vp8_pred8x8c_tree, vp8_pred8x8c_prob_intra);\n\n        mb->ref_frame = VP56_FRAME_CURRENT;\n\n    } else if (vp56_rac_get_prob_branchy(c, s->prob->intra)) {\n\n        // inter MB, 16.2\n\n        if (vp56_rac_get_prob_branchy(c, s->prob->last))\n\n            mb->ref_frame = vp56_rac_get_prob(c, s->prob->golden) ?\n\n                VP56_FRAME_GOLDEN2 /* altref */ : VP56_FRAME_GOLDEN;\n\n        else\n\n            mb->ref_frame = VP56_FRAME_PREVIOUS;\n\n        s->ref_count[mb->ref_frame-1]++;\n\n\n\n        // motion vectors, 16.3\n\n        decode_mvs(s, mb, mb_x, mb_y);\n\n    } else {\n\n        // intra MB, 16.1\n\n        mb->mode = vp8_rac_get_tree(c, vp8_pred16x16_tree_inter, s->prob->pred16x16);\n\n\n\n        if (mb->mode == MODE_I4x4)\n\n            decode_intra4x4_modes(s, c, mb_x, 0);\n\n\n\n        s->chroma_pred_mode = vp8_rac_get_tree(c, vp8_pred8x8c_tree, s->prob->pred8x8c);\n\n        mb->ref_frame = VP56_FRAME_CURRENT;\n\n        mb->partitioning = VP8_SPLITMVMODE_NONE;\n\n        AV_ZERO32(&mb->bmv[0]);\n\n    }\n\n}\n", "idx": 26381}
{"project": "FFmpeg", "commit_id": "2b1a4c5b3411c3030a5bdbd70d80bc606be570f7", "target": 1, "func": "static int amovie_request_frame(AVFilterLink *outlink)\n\n{\n\n    MovieContext *movie = outlink->src->priv;\n\n    int ret;\n\n\n\n    if (movie->is_done)\n\n        return AVERROR_EOF;\n\n    if ((ret = amovie_get_samples(outlink)) < 0)\n\n        return ret;\n\n\n\n    avfilter_filter_samples(outlink, avfilter_ref_buffer(movie->samplesref, ~0));\n\n    avfilter_unref_buffer(movie->samplesref);\n\n    movie->samplesref = NULL;\n\n\n\n    return 0;\n\n}\n", "idx": 26382}
{"project": "FFmpeg", "commit_id": "2da0d70d5eebe42f9fcd27ee554419ebe2a5da06", "target": 1, "func": "inline static void RENAME(hcscale)(uint16_t *dst, long dstWidth, uint8_t *src1, uint8_t *src2,\n\n\t\t\t\t   int srcW, int xInc, int flags, int canMMX2BeUsed, int16_t *hChrFilter,\n\n\t\t\t\t   int16_t *hChrFilterPos, int hChrFilterSize, void *funnyUVCode,\n\n\t\t\t\t   int srcFormat, uint8_t *formatConvBuffer, int16_t *mmx2Filter,\n\n\t\t\t\t   int32_t *mmx2FilterPos, uint8_t *pal)\n\n{\n\n    if(srcFormat==PIX_FMT_YUYV422)\n\n    {\n\n\tRENAME(yuy2ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==PIX_FMT_UYVY422)\n\n    {\n\n\tRENAME(uyvyToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==PIX_FMT_RGB32)\n\n    {\n\n\tRENAME(bgr32ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==PIX_FMT_BGR24)\n\n    {\n\n\tRENAME(bgr24ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==PIX_FMT_BGR565)\n\n    {\n\n\tRENAME(bgr16ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==PIX_FMT_BGR555)\n\n    {\n\n\tRENAME(bgr15ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==PIX_FMT_BGR32)\n\n    {\n\n\tRENAME(rgb32ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==PIX_FMT_RGB24)\n\n    {\n\n\tRENAME(rgb24ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==PIX_FMT_RGB565)\n\n    {\n\n\tRENAME(rgb16ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==PIX_FMT_RGB555)\n\n    {\n\n\tRENAME(rgb15ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(isGray(srcFormat))\n\n    {\n\n    \treturn;\n\n    }\n\n    else if(srcFormat==PIX_FMT_RGB8 || srcFormat==PIX_FMT_BGR8 || srcFormat==PIX_FMT_PAL8 || srcFormat==PIX_FMT_BGR4_BYTE  || srcFormat==PIX_FMT_RGB4_BYTE)\n\n    {\n\n\tRENAME(palToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW, pal);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n\n\n#ifdef HAVE_MMX\n\n\t// use the new MMX scaler if the mmx2 can't be used (its faster than the x86asm one)\n\n    if(!(flags&SWS_FAST_BILINEAR) || (!canMMX2BeUsed))\n\n#else\n\n    if(!(flags&SWS_FAST_BILINEAR))\n\n#endif\n\n    {\n\n    \tRENAME(hScale)(dst     , dstWidth, src1, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n    \tRENAME(hScale)(dst+2048, dstWidth, src2, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n    }\n\n    else // Fast Bilinear upscale / crap downscale\n\n    {\n\n#if defined(ARCH_X86)\n\n#ifdef HAVE_MMX2\n\n\tint i;\n\n#if defined(PIC)\n\n\tuint64_t ebxsave __attribute__((aligned(8)));\n\n#endif\n\n\tif(canMMX2BeUsed)\n\n\t{\n\n\t\tasm volatile(\n\n#if defined(PIC)\n\n\t\t\t\"mov %%\"REG_b\", %6    \\n\\t\"\n\n#endif\n\n\t\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"mov %0, %%\"REG_c\"\t\t\\n\\t\"\n\n\t\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\t\"mov %2, %%\"REG_d\"\t\t\\n\\t\"\n\n\t\t\t\"mov %3, %%\"REG_b\"\t\t\\n\\t\"\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\" // i\n\n\t\t\tPREFETCH\" (%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%%\"REG_c\")\t\t\\n\\t\"\n\n\n\n#ifdef ARCH_X86_64\n\n\n\n#define FUNNY_UV_CODE \\\n\n\t\t\t\"movl (%%\"REG_b\"), %%esi\t\\n\\t\"\\\n\n\t\t\t\"call *%4\t\t\t\\n\\t\"\\\n\n\t\t\t\"movl (%%\"REG_b\", %%\"REG_a\"), %%esi\\n\\t\"\\\n\n\t\t\t\"add %%\"REG_S\", %%\"REG_c\"\t\\n\\t\"\\\n\n\t\t\t\"add %%\"REG_a\", %%\"REG_D\"\t\\n\\t\"\\\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\"\\\n\n\n\n#else\n\n\n\n#define FUNNY_UV_CODE \\\n\n\t\t\t\"movl (%%\"REG_b\"), %%esi\t\\n\\t\"\\\n\n\t\t\t\"call *%4\t\t\t\\n\\t\"\\\n\n\t\t\t\"addl (%%\"REG_b\", %%\"REG_a\"), %%\"REG_c\"\\n\\t\"\\\n\n\t\t\t\"add %%\"REG_a\", %%\"REG_D\"\t\\n\\t\"\\\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\"\\\n\n\n\n#endif\n\n\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\" // i\n\n\t\t\t\"mov %5, %%\"REG_c\"\t\t\\n\\t\" // src\n\n\t\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\" // buf1\n\n\t\t\t\"add $4096, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" (%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%%\"REG_c\")\t\t\\n\\t\"\n\n\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\n\n\n#if defined(PIC)\n\n\t\t\t\"mov %6, %%\"REG_b\"    \\n\\t\"\n\n#endif\n\n\t\t\t:: \"m\" (src1), \"m\" (dst), \"m\" (mmx2Filter), \"m\" (mmx2FilterPos),\n\n\t\t\t\"m\" (funnyUVCode), \"m\" (src2)\n\n#if defined(PIC)\n\n\t\t\t,\"m\" (ebxsave)\n\n#endif\n\n\t\t\t: \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S, \"%\"REG_D\n\n#if !defined(PIC)\n\n\t\t\t ,\"%\"REG_b\n\n#endif\n\n\t\t);\n\n\t\tfor(i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--)\n\n\t\t{\n\n//\t\t\tprintf(\"%d %d %d\\n\", dstWidth, i, srcW);\n\n\t\t\tdst[i] = src1[srcW-1]*128;\n\n\t\t\tdst[i+2048] = src2[srcW-1]*128;\n\n\t\t}\n\n\t}\n\n\telse\n\n\t{\n\n#endif\n\n\tlong xInc_shr16 = (long) (xInc >> 16);\n\n\tuint16_t xInc_mask = xInc & 0xffff;\n\n\tasm volatile(\n\n\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\" // i\n\n\t\t\"xor %%\"REG_d\", %%\"REG_d\"\t\t\\n\\t\" // xx\n\n\t\t\"xorl %%ecx, %%ecx\t\t\\n\\t\" // 2*xalpha\n\n\t\tASMALIGN(4)\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\"mov %0, %%\"REG_S\"\t\t\\n\\t\"\n\n\t\t\"movzbl  (%%\"REG_S\", %%\"REG_d\"), %%edi\t\\n\\t\" //src[xx]\n\n\t\t\"movzbl 1(%%\"REG_S\", %%\"REG_d\"), %%esi\t\\n\\t\" //src[xx+1]\n\n\t\t\"subl %%edi, %%esi\t\t\\n\\t\" //src[xx+1] - src[xx]\n\n\t\t\"imull %%ecx, %%esi\t\t\\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n\t\t\"shll $16, %%edi\t\t\\n\\t\"\n\n\t\t\"addl %%edi, %%esi\t\t\\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\"shrl $9, %%esi\t\t\t\\n\\t\"\n\n\t\t\"movw %%si, (%%\"REG_D\", %%\"REG_a\", 2)\\n\\t\"\n\n\n\n\t\t\"movzbl  (%5, %%\"REG_d\"), %%edi\t\\n\\t\" //src[xx]\n\n\t\t\"movzbl 1(%5, %%\"REG_d\"), %%esi\t\\n\\t\" //src[xx+1]\n\n\t\t\"subl %%edi, %%esi\t\t\\n\\t\" //src[xx+1] - src[xx]\n\n\t\t\"imull %%ecx, %%esi\t\t\\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n\t\t\"shll $16, %%edi\t\t\\n\\t\"\n\n\t\t\"addl %%edi, %%esi\t\t\\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\"shrl $9, %%esi\t\t\t\\n\\t\"\n\n\t\t\"movw %%si, 4096(%%\"REG_D\", %%\"REG_a\", 2)\\n\\t\"\n\n\n\n\t\t\"addw %4, %%cx\t\t\t\\n\\t\" //2*xalpha += xInc&0xFF\n\n\t\t\"adc %3, %%\"REG_d\"\t\t\\n\\t\" //xx+= xInc>>8 + carry\n\n\t\t\"add $1, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\"cmp %2, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\n\n/* GCC-3.3 makes MPlayer crash on IA-32 machines when using \"g\" operand here,\n\n   which is needed to support GCC-4.0 */\n\n#if defined(ARCH_X86_64) && ((__GNUC__ > 3) || ( __GNUC__ == 3 && __GNUC_MINOR__ >= 4))\n\n\t\t:: \"m\" (src1), \"m\" (dst), \"g\" ((long)dstWidth), \"m\" (xInc_shr16), \"m\" (xInc_mask),\n\n#else\n\n\t\t:: \"m\" (src1), \"m\" (dst), \"m\" ((long)dstWidth), \"m\" (xInc_shr16), \"m\" (xInc_mask),\n\n#endif\n\n\t\t\"r\" (src2)\n\n\t\t: \"%\"REG_a, \"%\"REG_d, \"%ecx\", \"%\"REG_D, \"%esi\"\n\n\t\t);\n\n#ifdef HAVE_MMX2\n\n\t} //if MMX2 can't be used\n\n#endif\n\n#else\n\n\tint i;\n\n\tunsigned int xpos=0;\n\n\tfor(i=0;i<dstWidth;i++)\n\n\t{\n\n\t\tregister unsigned int xx=xpos>>16;\n\n\t\tregister unsigned int xalpha=(xpos&0xFFFF)>>9;\n\n\t\tdst[i]=(src1[xx]*(xalpha^127)+src1[xx+1]*xalpha);\n\n\t\tdst[i+2048]=(src2[xx]*(xalpha^127)+src2[xx+1]*xalpha);\n\n/* slower\n\n\t  dst[i]= (src1[xx]<<7) + (src1[xx+1] - src1[xx])*xalpha;\n\n\t  dst[i+2048]=(src2[xx]<<7) + (src2[xx+1] - src2[xx])*xalpha;\n\n*/\n\n\t\txpos+=xInc;\n\n\t}\n\n#endif\n\n   }\n\n}\n", "idx": 26383}
{"project": "FFmpeg", "commit_id": "bb9747c8eee134f2bf6058d368f8cbc799f4b7d3", "target": 1, "func": "static int wavpack_decode_block(AVCodecContext *avctx, int block_no,\n\n                                void *data, int *got_frame_ptr,\n\n                                const uint8_t *buf, int buf_size)\n\n{\n\n    WavpackContext *wc = avctx->priv_data;\n\n    WavpackFrameContext *s;\n\n    void *samples = data;\n\n    int samplecount;\n\n    int got_terms = 0, got_weights = 0, got_samples = 0, got_entropy = 0, got_bs = 0, got_float = 0;\n\n    int got_hybrid = 0;\n\n    const uint8_t* orig_buf = buf;\n\n    const uint8_t* buf_end = buf + buf_size;\n\n    int i, j, id, size, ssize, weights, t;\n\n    int bpp, chan, chmask;\n\n\n\n    if (buf_size == 0){\n\n        *got_frame_ptr = 0;\n\n        return 0;\n\n    }\n\n\n\n    if(block_no >= wc->fdec_num && wv_alloc_frame_context(wc) < 0){\n\n        av_log(avctx, AV_LOG_ERROR, \"Error creating frame decode context\\n\");\n\n        return -1;\n\n    }\n\n\n\n    s = wc->fdec[block_no];\n\n    if(!s){\n\n        av_log(avctx, AV_LOG_ERROR, \"Context for block %d is not present\\n\", block_no);\n\n        return -1;\n\n    }\n\n\n\n        memset(s->decorr, 0, MAX_TERMS * sizeof(Decorr));\n\n        memset(s->ch, 0, sizeof(s->ch));\n\n        s->extra_bits = 0;\n\n        s->and = s->or = s->shift = 0;\n\n        s->got_extra_bits = 0;\n\n\n\n    if(!wc->mkv_mode){\n\n        s->samples = AV_RL32(buf); buf += 4;\n\n        if(!s->samples){\n\n            *got_frame_ptr = 0;\n\n            return 0;\n\n        }\n\n    }else{\n\n        s->samples = wc->samples;\n\n    }\n\n    s->frame_flags = AV_RL32(buf); buf += 4;\n\n    if(s->frame_flags&0x80){\n\n        avctx->sample_fmt = AV_SAMPLE_FMT_FLT;\n\n    } else if((s->frame_flags&0x03) <= 1){\n\n        avctx->sample_fmt = AV_SAMPLE_FMT_S16;\n\n    } else {\n\n        avctx->sample_fmt = AV_SAMPLE_FMT_S32;\n\n    }\n\n    bpp = av_get_bytes_per_sample(avctx->sample_fmt);\n\n    samples = (uint8_t*)samples + bpp * wc->ch_offset;\n\n\n\n    s->stereo = !(s->frame_flags & WV_MONO);\n\n    s->stereo_in = (s->frame_flags & WV_FALSE_STEREO) ? 0 : s->stereo;\n\n    s->joint = s->frame_flags & WV_JOINT_STEREO;\n\n    s->hybrid = s->frame_flags & WV_HYBRID_MODE;\n\n    s->hybrid_bitrate = s->frame_flags & WV_HYBRID_BITRATE;\n\n    s->hybrid_maxclip = 1 << ((((s->frame_flags & 0x03) + 1) << 3) - 1);\n\n    s->post_shift = 8 * (bpp-1-(s->frame_flags&0x03)) + ((s->frame_flags >> 13) & 0x1f);\n\n    s->CRC = AV_RL32(buf); buf += 4;\n\n    if(wc->mkv_mode)\n\n        buf += 4; //skip block size;\n\n\n\n    wc->ch_offset += 1 + s->stereo;\n\n\n\n    // parse metadata blocks\n\n    while(buf < buf_end){\n\n        id = *buf++;\n\n        size = *buf++;\n\n        if(id & WP_IDF_LONG) {\n\n            size |= (*buf++) << 8;\n\n            size |= (*buf++) << 16;\n\n        }\n\n        size <<= 1; // size is specified in words\n\n        ssize = size;\n\n        if(id & WP_IDF_ODD) size--;\n\n        if(size < 0){\n\n            av_log(avctx, AV_LOG_ERROR, \"Got incorrect block %02X with size %i\\n\", id, size);\n\n            break;\n\n        }\n\n        if(buf + ssize > buf_end){\n\n            av_log(avctx, AV_LOG_ERROR, \"Block size %i is out of bounds\\n\", size);\n\n            break;\n\n        }\n\n        if(id & WP_IDF_IGNORE){\n\n            buf += ssize;\n\n            continue;\n\n        }\n\n        switch(id & WP_IDF_MASK){\n\n        case WP_ID_DECTERMS:\n\n            if(size > MAX_TERMS){\n\n                av_log(avctx, AV_LOG_ERROR, \"Too many decorrelation terms\\n\");\n\n                s->terms = 0;\n\n                buf += ssize;\n\n                continue;\n\n            }\n\n            s->terms = size;\n\n            for(i = 0; i < s->terms; i++) {\n\n                s->decorr[s->terms - i - 1].value = (*buf & 0x1F) - 5;\n\n                s->decorr[s->terms - i - 1].delta = *buf >> 5;\n\n                buf++;\n\n            }\n\n            got_terms = 1;\n\n            break;\n\n        case WP_ID_DECWEIGHTS:\n\n            if(!got_terms){\n\n                av_log(avctx, AV_LOG_ERROR, \"No decorrelation terms met\\n\");\n\n                continue;\n\n            }\n\n            weights = size >> s->stereo_in;\n\n            if(weights > MAX_TERMS || weights > s->terms){\n\n                av_log(avctx, AV_LOG_ERROR, \"Too many decorrelation weights\\n\");\n\n                buf += ssize;\n\n                continue;\n\n            }\n\n            for(i = 0; i < weights; i++) {\n\n                t = (int8_t)(*buf++);\n\n                s->decorr[s->terms - i - 1].weightA = t << 3;\n\n                if(s->decorr[s->terms - i - 1].weightA > 0)\n\n                    s->decorr[s->terms - i - 1].weightA += (s->decorr[s->terms - i - 1].weightA + 64) >> 7;\n\n                if(s->stereo_in){\n\n                    t = (int8_t)(*buf++);\n\n                    s->decorr[s->terms - i - 1].weightB = t << 3;\n\n                    if(s->decorr[s->terms - i - 1].weightB > 0)\n\n                        s->decorr[s->terms - i - 1].weightB += (s->decorr[s->terms - i - 1].weightB + 64) >> 7;\n\n                }\n\n            }\n\n            got_weights = 1;\n\n            break;\n\n        case WP_ID_DECSAMPLES:\n\n            if(!got_terms){\n\n                av_log(avctx, AV_LOG_ERROR, \"No decorrelation terms met\\n\");\n\n                continue;\n\n            }\n\n            t = 0;\n\n            for(i = s->terms - 1; (i >= 0) && (t < size); i--) {\n\n                if(s->decorr[i].value > 8){\n\n                    s->decorr[i].samplesA[0] = wp_exp2(AV_RL16(buf)); buf += 2;\n\n                    s->decorr[i].samplesA[1] = wp_exp2(AV_RL16(buf)); buf += 2;\n\n                    if(s->stereo_in){\n\n                        s->decorr[i].samplesB[0] = wp_exp2(AV_RL16(buf)); buf += 2;\n\n                        s->decorr[i].samplesB[1] = wp_exp2(AV_RL16(buf)); buf += 2;\n\n                        t += 4;\n\n                    }\n\n                    t += 4;\n\n                }else if(s->decorr[i].value < 0){\n\n                    s->decorr[i].samplesA[0] = wp_exp2(AV_RL16(buf)); buf += 2;\n\n                    s->decorr[i].samplesB[0] = wp_exp2(AV_RL16(buf)); buf += 2;\n\n                    t += 4;\n\n                }else{\n\n                    for(j = 0; j < s->decorr[i].value; j++){\n\n                        s->decorr[i].samplesA[j] = wp_exp2(AV_RL16(buf)); buf += 2;\n\n                        if(s->stereo_in){\n\n                            s->decorr[i].samplesB[j] = wp_exp2(AV_RL16(buf)); buf += 2;\n\n                        }\n\n                    }\n\n                    t += s->decorr[i].value * 2 * (s->stereo_in + 1);\n\n                }\n\n            }\n\n            got_samples = 1;\n\n            break;\n\n        case WP_ID_ENTROPY:\n\n            if(size != 6 * (s->stereo_in + 1)){\n\n                av_log(avctx, AV_LOG_ERROR, \"Entropy vars size should be %i, got %i\", 6 * (s->stereo_in + 1), size);\n\n                buf += ssize;\n\n                continue;\n\n            }\n\n            for(j = 0; j <= s->stereo_in; j++){\n\n                for(i = 0; i < 3; i++){\n\n                    s->ch[j].median[i] = wp_exp2(AV_RL16(buf));\n\n                    buf += 2;\n\n                }\n\n            }\n\n            got_entropy = 1;\n\n            break;\n\n        case WP_ID_HYBRID:\n\n            if(s->hybrid_bitrate){\n\n                for(i = 0; i <= s->stereo_in; i++){\n\n                    s->ch[i].slow_level = wp_exp2(AV_RL16(buf));\n\n                    buf += 2;\n\n                    size -= 2;\n\n                }\n\n            }\n\n            for(i = 0; i < (s->stereo_in + 1); i++){\n\n                s->ch[i].bitrate_acc = AV_RL16(buf) << 16;\n\n                buf += 2;\n\n                size -= 2;\n\n            }\n\n            if(size > 0){\n\n                for(i = 0; i < (s->stereo_in + 1); i++){\n\n                    s->ch[i].bitrate_delta = wp_exp2((int16_t)AV_RL16(buf));\n\n                    buf += 2;\n\n                }\n\n            }else{\n\n                for(i = 0; i < (s->stereo_in + 1); i++)\n\n                    s->ch[i].bitrate_delta = 0;\n\n            }\n\n            got_hybrid = 1;\n\n            break;\n\n        case WP_ID_INT32INFO:\n\n            if(size != 4){\n\n                av_log(avctx, AV_LOG_ERROR, \"Invalid INT32INFO, size = %i, sent_bits = %i\\n\", size, *buf);\n\n                buf += ssize;\n\n                continue;\n\n            }\n\n            if(buf[0])\n\n                s->extra_bits = buf[0];\n\n            else if(buf[1])\n\n                s->shift = buf[1];\n\n            else if(buf[2]){\n\n                s->and = s->or = 1;\n\n                s->shift = buf[2];\n\n            }else if(buf[3]){\n\n                s->and = 1;\n\n                s->shift = buf[3];\n\n            }\n\n            buf += 4;\n\n            break;\n\n        case WP_ID_FLOATINFO:\n\n            if(size != 4){\n\n                av_log(avctx, AV_LOG_ERROR, \"Invalid FLOATINFO, size = %i\\n\", size);\n\n                buf += ssize;\n\n                continue;\n\n            }\n\n            s->float_flag = buf[0];\n\n            s->float_shift = buf[1];\n\n            s->float_max_exp = buf[2];\n\n            buf += 4;\n\n            got_float = 1;\n\n            break;\n\n        case WP_ID_DATA:\n\n            s->sc.offset = buf - orig_buf;\n\n            s->sc.size   = size * 8;\n\n            init_get_bits(&s->gb, buf, size * 8);\n\n            s->data_size = size * 8;\n\n            buf += size;\n\n            got_bs = 1;\n\n            break;\n\n        case WP_ID_EXTRABITS:\n\n            if(size <= 4){\n\n                av_log(avctx, AV_LOG_ERROR, \"Invalid EXTRABITS, size = %i\\n\", size);\n\n                buf += size;\n\n                continue;\n\n            }\n\n            s->extra_sc.offset = buf - orig_buf;\n\n            s->extra_sc.size   = size * 8;\n\n            init_get_bits(&s->gb_extra_bits, buf, size * 8);\n\n            s->crc_extra_bits = get_bits_long(&s->gb_extra_bits, 32);\n\n            buf += size;\n\n            s->got_extra_bits = 1;\n\n            break;\n\n        case WP_ID_CHANINFO:\n\n            if(size <= 1){\n\n                av_log(avctx, AV_LOG_ERROR, \"Insufficient channel information\\n\");\n\n                return -1;\n\n            }\n\n            chan = *buf++;\n\n            switch(size - 2){\n\n            case 0:\n\n                chmask = *buf;\n\n                break;\n\n            case 1:\n\n                chmask = AV_RL16(buf);\n\n                break;\n\n            case 2:\n\n                chmask = AV_RL24(buf);\n\n                break;\n\n            case 3:\n\n                chmask = AV_RL32(buf);\n\n                break;\n\n            case 5:\n\n                chan |= (buf[1] & 0xF) << 8;\n\n                chmask = AV_RL24(buf + 2);\n\n                break;\n\n            default:\n\n                av_log(avctx, AV_LOG_ERROR, \"Invalid channel info size %d\\n\", size);\n\n                chan = avctx->channels;\n\n                chmask = avctx->channel_layout;\n\n            }\n\n            if(chan != avctx->channels){\n\n                av_log(avctx, AV_LOG_ERROR, \"Block reports total %d channels, decoder believes it's %d channels\\n\",\n\n                       chan, avctx->channels);\n\n                return -1;\n\n            }\n\n            if(!avctx->channel_layout)\n\n                avctx->channel_layout = chmask;\n\n            buf += size - 1;\n\n            break;\n\n        default:\n\n            buf += size;\n\n        }\n\n        if(id & WP_IDF_ODD) buf++;\n\n    }\n\n\n\n        if(!got_terms){\n\n            av_log(avctx, AV_LOG_ERROR, \"No block with decorrelation terms\\n\");\n\n            return -1;\n\n        }\n\n        if(!got_weights){\n\n            av_log(avctx, AV_LOG_ERROR, \"No block with decorrelation weights\\n\");\n\n            return -1;\n\n        }\n\n        if(!got_samples){\n\n            av_log(avctx, AV_LOG_ERROR, \"No block with decorrelation samples\\n\");\n\n            return -1;\n\n        }\n\n        if(!got_entropy){\n\n            av_log(avctx, AV_LOG_ERROR, \"No block with entropy info\\n\");\n\n            return -1;\n\n        }\n\n        if(s->hybrid && !got_hybrid){\n\n            av_log(avctx, AV_LOG_ERROR, \"Hybrid config not found\\n\");\n\n            return -1;\n\n        }\n\n        if(!got_bs){\n\n            av_log(avctx, AV_LOG_ERROR, \"Packed samples not found\\n\");\n\n            return -1;\n\n        }\n\n        if(!got_float && avctx->sample_fmt == AV_SAMPLE_FMT_FLT){\n\n            av_log(avctx, AV_LOG_ERROR, \"Float information not found\\n\");\n\n            return -1;\n\n        }\n\n        if(s->got_extra_bits && avctx->sample_fmt != AV_SAMPLE_FMT_FLT){\n\n            const int size = get_bits_left(&s->gb_extra_bits);\n\n            const int wanted = s->samples * s->extra_bits << s->stereo_in;\n\n            if(size < wanted){\n\n                av_log(avctx, AV_LOG_ERROR, \"Too small EXTRABITS\\n\");\n\n                s->got_extra_bits = 0;\n\n            }\n\n        }\n\n\n\n    if(s->stereo_in){\n\n        if(avctx->sample_fmt == AV_SAMPLE_FMT_S16)\n\n            samplecount = wv_unpack_stereo(s, &s->gb, samples, AV_SAMPLE_FMT_S16);\n\n        else if(avctx->sample_fmt == AV_SAMPLE_FMT_S32)\n\n            samplecount = wv_unpack_stereo(s, &s->gb, samples, AV_SAMPLE_FMT_S32);\n\n        else\n\n            samplecount = wv_unpack_stereo(s, &s->gb, samples, AV_SAMPLE_FMT_FLT);\n\n\n\n        if (samplecount < 0)\n\n            return -1;\n\n\n\n        samplecount >>= 1;\n\n    }else{\n\n        const int channel_stride = avctx->channels;\n\n\n\n        if(avctx->sample_fmt == AV_SAMPLE_FMT_S16)\n\n            samplecount = wv_unpack_mono(s, &s->gb, samples, AV_SAMPLE_FMT_S16);\n\n        else if(avctx->sample_fmt == AV_SAMPLE_FMT_S32)\n\n            samplecount = wv_unpack_mono(s, &s->gb, samples, AV_SAMPLE_FMT_S32);\n\n        else\n\n            samplecount = wv_unpack_mono(s, &s->gb, samples, AV_SAMPLE_FMT_FLT);\n\n\n\n        if (samplecount < 0)\n\n            return -1;\n\n\n\n        if(s->stereo && avctx->sample_fmt == AV_SAMPLE_FMT_S16){\n\n            int16_t *dst = (int16_t*)samples + 1;\n\n            int16_t *src = (int16_t*)samples;\n\n            int cnt = samplecount;\n\n            while(cnt--){\n\n                *dst = *src;\n\n                src += channel_stride;\n\n                dst += channel_stride;\n\n            }\n\n        }else if(s->stereo && avctx->sample_fmt == AV_SAMPLE_FMT_S32){\n\n            int32_t *dst = (int32_t*)samples + 1;\n\n            int32_t *src = (int32_t*)samples;\n\n            int cnt = samplecount;\n\n            while(cnt--){\n\n                *dst = *src;\n\n                src += channel_stride;\n\n                dst += channel_stride;\n\n            }\n\n        }else if(s->stereo){\n\n            float *dst = (float*)samples + 1;\n\n            float *src = (float*)samples;\n\n            int cnt = samplecount;\n\n            while(cnt--){\n\n                *dst = *src;\n\n                src += channel_stride;\n\n                dst += channel_stride;\n\n            }\n\n        }\n\n    }\n\n\n\n    *got_frame_ptr = 1;\n\n\n\n    return samplecount * bpp;\n\n}\n", "idx": 26386}
{"project": "FFmpeg", "commit_id": "fe8959bbece4d86a1872b813c25c2682dcd5ef42", "target": 1, "func": "int ff_put_wav_header(AVFormatContext *s, AVIOContext *pb,\n\n                      AVCodecParameters *par, int flags)\n\n{\n\n    int bps, blkalign, bytespersec, frame_size;\n\n    int hdrsize;\n\n    int64_t hdrstart = avio_tell(pb);\n\n    int waveformatextensible;\n\n    uint8_t temp[256];\n\n    uint8_t *riff_extradata       = temp;\n\n    uint8_t *riff_extradata_start = temp;\n\n\n\n    if (!par->codec_tag || par->codec_tag > 0xffff)\n\n        return -1;\n\n\n\n    /* We use the known constant frame size for the codec if known, otherwise\n\n     * fall back on using AVCodecContext.frame_size, which is not as reliable\n\n     * for indicating packet duration. */\n\n    frame_size = av_get_audio_frame_duration2(par, par->block_align);\n\n\n\n    waveformatextensible = (par->channels > 2 && par->channel_layout) ||\n\n\n\n                           par->sample_rate > 48000 ||\n\n                           par->codec_id == AV_CODEC_ID_EAC3 ||\n\n                           av_get_bits_per_sample(par->codec_id) > 16;\n\n\n\n    if (waveformatextensible)\n\n        avio_wl16(pb, 0xfffe);\n\n    else\n\n        avio_wl16(pb, par->codec_tag);\n\n\n\n    avio_wl16(pb, par->channels);\n\n    avio_wl32(pb, par->sample_rate);\n\n    if (par->codec_id == AV_CODEC_ID_ATRAC3 ||\n\n        par->codec_id == AV_CODEC_ID_G723_1 ||\n\n        par->codec_id == AV_CODEC_ID_MP2    ||\n\n        par->codec_id == AV_CODEC_ID_MP3    ||\n\n        par->codec_id == AV_CODEC_ID_GSM_MS) {\n\n        bps = 0;\n\n    } else {\n\n        if (!(bps = av_get_bits_per_sample(par->codec_id))) {\n\n            if (par->bits_per_coded_sample)\n\n                bps = par->bits_per_coded_sample;\n\n            else\n\n                bps = 16;  // default to 16\n\n        }\n\n    }\n\n    if (bps != par->bits_per_coded_sample && par->bits_per_coded_sample) {\n\n        av_log(s, AV_LOG_WARNING,\n\n               \"requested bits_per_coded_sample (%d) \"\n\n               \"and actually stored (%d) differ\\n\",\n\n               par->bits_per_coded_sample, bps);\n\n    }\n\n\n\n    if (par->codec_id == AV_CODEC_ID_MP2) {\n\n        blkalign = (144 * par->bit_rate - 1)/par->sample_rate + 1;\n\n    } else if (par->codec_id == AV_CODEC_ID_MP3) {\n\n        blkalign = 576 * (par->sample_rate <= (24000 + 32000)/2 ? 1 : 2);\n\n    } else if (par->codec_id == AV_CODEC_ID_AC3) {\n\n        blkalign = 3840;                /* maximum bytes per frame */\n\n    } else if (par->codec_id == AV_CODEC_ID_AAC) {\n\n        blkalign = 768 * par->channels; /* maximum bytes per frame */\n\n    } else if (par->codec_id == AV_CODEC_ID_G723_1) {\n\n        blkalign = 24;\n\n    } else if (par->block_align != 0) { /* specified by the codec */\n\n        blkalign = par->block_align;\n\n    } else\n\n        blkalign = bps * par->channels / av_gcd(8, bps);\n\n    if (par->codec_id == AV_CODEC_ID_PCM_U8 ||\n\n        par->codec_id == AV_CODEC_ID_PCM_S24LE ||\n\n        par->codec_id == AV_CODEC_ID_PCM_S32LE ||\n\n        par->codec_id == AV_CODEC_ID_PCM_F32LE ||\n\n        par->codec_id == AV_CODEC_ID_PCM_F64LE ||\n\n        par->codec_id == AV_CODEC_ID_PCM_S16LE) {\n\n        bytespersec = par->sample_rate * blkalign;\n\n    } else if (par->codec_id == AV_CODEC_ID_G723_1) {\n\n        bytespersec = 800;\n\n    } else {\n\n        bytespersec = par->bit_rate / 8;\n\n    }\n\n    avio_wl32(pb, bytespersec); /* bytes per second */\n\n    avio_wl16(pb, blkalign);    /* block align */\n\n    avio_wl16(pb, bps);         /* bits per sample */\n\n    if (par->codec_id == AV_CODEC_ID_MP3) {\n\n        bytestream_put_le16(&riff_extradata, 1);    /* wID */\n\n        bytestream_put_le32(&riff_extradata, 2);    /* fdwFlags */\n\n        bytestream_put_le16(&riff_extradata, 1152); /* nBlockSize */\n\n        bytestream_put_le16(&riff_extradata, 1);    /* nFramesPerBlock */\n\n        bytestream_put_le16(&riff_extradata, 1393); /* nCodecDelay */\n\n    } else if (par->codec_id == AV_CODEC_ID_MP2) {\n\n        /* fwHeadLayer */\n\n        bytestream_put_le16(&riff_extradata, 2);\n\n        /* dwHeadBitrate */\n\n        bytestream_put_le32(&riff_extradata, par->bit_rate);\n\n        /* fwHeadMode */\n\n        bytestream_put_le16(&riff_extradata, par->channels == 2 ? 1 : 8);\n\n        /* fwHeadModeExt */\n\n        bytestream_put_le16(&riff_extradata, 0);\n\n        /* wHeadEmphasis */\n\n        bytestream_put_le16(&riff_extradata, 1);\n\n        /* fwHeadFlags */\n\n        bytestream_put_le16(&riff_extradata, 16);\n\n        /* dwPTSLow */\n\n        bytestream_put_le32(&riff_extradata, 0);\n\n        /* dwPTSHigh */\n\n        bytestream_put_le32(&riff_extradata, 0);\n\n    } else if (par->codec_id == AV_CODEC_ID_G723_1) {\n\n        bytestream_put_le32(&riff_extradata, 0x9ace0002); /* extradata needed for msacm g723.1 codec */\n\n        bytestream_put_le32(&riff_extradata, 0xaea2f732);\n\n        bytestream_put_le16(&riff_extradata, 0xacde);\n\n    } else if (par->codec_id == AV_CODEC_ID_GSM_MS ||\n\n               par->codec_id == AV_CODEC_ID_ADPCM_IMA_WAV) {\n\n        /* wSamplesPerBlock */\n\n        bytestream_put_le16(&riff_extradata, frame_size);\n\n    } else if (par->extradata_size) {\n\n        riff_extradata_start = par->extradata;\n\n        riff_extradata       = par->extradata + par->extradata_size;\n\n    }\n\n    /* write WAVEFORMATEXTENSIBLE extensions */\n\n    if (waveformatextensible) {\n\n        int write_channel_mask = !(flags & FF_PUT_WAV_HEADER_SKIP_CHANNELMASK) &&\n\n                                 (s->strict_std_compliance < FF_COMPLIANCE_NORMAL ||\n\n                                  par->channel_layout < 0x40000);\n\n        /* 22 is WAVEFORMATEXTENSIBLE size */\n\n        avio_wl16(pb, riff_extradata - riff_extradata_start + 22);\n\n        /* ValidBitsPerSample || SamplesPerBlock || Reserved */\n\n        avio_wl16(pb, bps);\n\n        /* dwChannelMask */\n\n        avio_wl32(pb, write_channel_mask ? par->channel_layout : 0);\n\n        /* GUID + next 3 */\n\n        if (par->codec_id == AV_CODEC_ID_EAC3) {\n\n            ff_put_guid(pb, ff_get_codec_guid(par->codec_id, ff_codec_wav_guids));\n\n        } else {\n\n        avio_wl32(pb, par->codec_tag);\n\n        avio_wl32(pb, 0x00100000);\n\n        avio_wl32(pb, 0xAA000080);\n\n        avio_wl32(pb, 0x719B3800);\n\n        }\n\n    } else if ((flags & FF_PUT_WAV_HEADER_FORCE_WAVEFORMATEX) ||\n\n               par->codec_tag != 0x0001 /* PCM */ ||\n\n               riff_extradata - riff_extradata_start) {\n\n        /* WAVEFORMATEX */\n\n        avio_wl16(pb, riff_extradata - riff_extradata_start); /* cbSize */\n\n    } /* else PCMWAVEFORMAT */\n\n    avio_write(pb, riff_extradata_start, riff_extradata - riff_extradata_start);\n\n    hdrsize = avio_tell(pb) - hdrstart;\n\n    if (hdrsize & 1) {\n\n        hdrsize++;\n\n        avio_w8(pb, 0);\n\n    }\n\n\n\n    return hdrsize;\n\n}", "idx": 26387}
{"project": "FFmpeg", "commit_id": "db5604ac26f06be34030c8ae8040c19d549280f1", "target": 1, "func": "static av_cold int join_init(AVFilterContext *ctx)\n\n{\n\n    JoinContext *s = ctx->priv;\n\n    int ret, i;\n\n\n\n    if (!(s->channel_layout = av_get_channel_layout(s->channel_layout_str))) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Error parsing channel layout '%s'.\\n\",\n\n               s->channel_layout_str);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    s->nb_channels  = av_get_channel_layout_nb_channels(s->channel_layout);\n\n    s->channels     = av_mallocz_array(s->nb_channels, sizeof(*s->channels));\n\n    s->buffers      = av_mallocz_array(s->nb_channels, sizeof(*s->buffers));\n\n    s->input_frames = av_mallocz_array(s->inputs, sizeof(*s->input_frames));\n\n    if (!s->channels || !s->buffers|| !s->input_frames)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for (i = 0; i < s->nb_channels; i++) {\n\n        s->channels[i].out_channel = av_channel_layout_extract_channel(s->channel_layout, i);\n\n        s->channels[i].input       = -1;\n\n    }\n\n\n\n    if ((ret = parse_maps(ctx)) < 0)\n\n        return ret;\n\n\n\n    for (i = 0; i < s->inputs; i++) {\n\n        char name[32];\n\n        AVFilterPad pad = { 0 };\n\n\n\n        snprintf(name, sizeof(name), \"input%d\", i);\n\n        pad.type           = AVMEDIA_TYPE_AUDIO;\n\n        pad.name           = av_strdup(name);\n\n        if (!pad.name)\n\n            return AVERROR(ENOMEM);\n\n        pad.filter_frame   = filter_frame;\n\n\n\n        pad.needs_fifo = 1;\n\n\n\n        ff_insert_inpad(ctx, i, &pad);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26389}
{"project": "FFmpeg", "commit_id": "3dea28cc2ef22861347918b6740c4c05c46a6614", "target": 0, "func": "static void idr(H264Context *h){\n\n    int i;\n\n    ff_h264_remove_all_refs(h);\n\n    h->prev_frame_num= -1;\n\n    h->prev_frame_num_offset= 0;\n\n    h->prev_poc_msb= 1<<16;\n\n    h->prev_poc_lsb= 0;\n\n    for (i = 0; i < MAX_DELAYED_PIC_COUNT; i++)\n\n        h->last_pocs[i] = INT_MIN;\n\n}\n", "idx": 26390}
{"project": "FFmpeg", "commit_id": "2fc354f90d61f5f1bb75dbdd808a502dec69cf99", "target": 0, "func": "static void do_audio_out(AVFormatContext *s, OutputStream *ost,\n\n                         AVFrame *frame)\n\n{\n\n    AVCodecContext *enc = ost->st->codec;\n\n    AVPacket pkt;\n\n    int got_packet = 0;\n\n\n\n    av_init_packet(&pkt);\n\n    pkt.data = NULL;\n\n    pkt.size = 0;\n\n#if 0\n\n    if (!check_recording_time(ost))\n\n        return;\n\n#endif\n\n    if (frame->pts == AV_NOPTS_VALUE || audio_sync_method < 0)\n\n        frame->pts = ost->sync_opts;\n\n    ost->sync_opts = frame->pts + frame->nb_samples;\n\n\n\n    av_assert0(pkt.size || !pkt.data);\n\n    update_benchmark(NULL);\n\n    if (avcodec_encode_audio2(enc, &pkt, frame, &got_packet) < 0) {\n\n        av_log(NULL, AV_LOG_FATAL, \"Audio encoding failed (avcodec_encode_audio2)\\n\");\n\n        exit_program(1);\n\n    }\n\n    update_benchmark(\"encode_audio %d.%d\", ost->file_index, ost->index);\n\n\n\n    if (got_packet) {\n\n        if (pkt.pts != AV_NOPTS_VALUE)\n\n            pkt.pts      = av_rescale_q(pkt.pts,      enc->time_base, ost->st->time_base);\n\n        if (pkt.dts != AV_NOPTS_VALUE)\n\n            pkt.dts      = av_rescale_q(pkt.dts,      enc->time_base, ost->st->time_base);\n\n        if (pkt.duration > 0)\n\n            pkt.duration = av_rescale_q(pkt.duration, enc->time_base, ost->st->time_base);\n\n\n\n        if (debug_ts) {\n\n            av_log(NULL, AV_LOG_INFO, \"encoder -> type:audio \"\n\n                   \"pkt_pts:%s pkt_pts_time:%s pkt_dts:%s pkt_dts_time:%s\\n\",\n\n                   av_ts2str(pkt.pts), av_ts2timestr(pkt.pts, &ost->st->time_base),\n\n                   av_ts2str(pkt.dts), av_ts2timestr(pkt.dts, &ost->st->time_base));\n\n        }\n\n\n\n        write_frame(s, &pkt, ost);\n\n\n\n        audio_size += pkt.size;\n\n        av_free_packet(&pkt);\n\n    }\n\n}\n", "idx": 26401}
{"project": "FFmpeg", "commit_id": "7a8cbb39f6154fb091597d28deba8d3bec38df64", "target": 0, "func": "static av_cold int Faac_encode_close(AVCodecContext *avctx)\n\n{\n\n    FaacAudioContext *s = avctx->priv_data;\n\n\n\n    av_freep(&avctx->coded_frame);\n\n    av_freep(&avctx->extradata);\n\n\n\n    faacEncClose(s->faac_handle);\n\n    return 0;\n\n}\n", "idx": 26412}
{"project": "FFmpeg", "commit_id": "a0c624e299730c8c5800375c2f5f3c6c200053ff", "target": 1, "func": "static av_cold int v4l2_encode_init(AVCodecContext *avctx)\n\n{\n\n    V4L2m2mContext *s = avctx->priv_data;\n\n    V4L2Context *capture = &s->capture;\n\n    V4L2Context *output = &s->output;\n\n    int ret;\n\n\n\n    /* common settings output/capture */\n\n    output->height = capture->height = avctx->height;\n\n    output->width = capture->width = avctx->width;\n\n\n\n    /* output context */\n\n    output->av_codec_id = AV_CODEC_ID_RAWVIDEO;\n\n    output->av_pix_fmt = avctx->pix_fmt;\n\n\n\n    /* capture context */\n\n    capture->av_codec_id = avctx->codec_id;\n\n    capture->av_pix_fmt = AV_PIX_FMT_NONE;\n\n\n\n    ret = ff_v4l2_m2m_codec_init(avctx);\n\n    if (ret) {\n\n        av_log(avctx, AV_LOG_ERROR, \"can't configure encoder\\n\");\n\n        return ret;\n\n    }\n\n\n\n    return v4l2_prepare_encoder(s);\n\n}\n", "idx": 26414}
{"project": "FFmpeg", "commit_id": "f3202871598f59b570b31b01cfeb64b8fedbd700", "target": 1, "func": "AVD3D11VAContext *av_d3d11va_alloc_context(void)\n\n{\n\n    AVD3D11VAContext* res = av_mallocz(sizeof(AVD3D11VAContext));\n\n\n\n    res->context_mutex = INVALID_HANDLE_VALUE;\n\n    return res;\n\n}", "idx": 26417}
{"project": "FFmpeg", "commit_id": "7dafb3a25a580a5f8f1a5083835c67be9ed17043", "target": 1, "func": "static int cudaupload_query_formats(AVFilterContext *ctx)\n\n{\n\n    int ret;\n\n\n\n    static const enum AVPixelFormat input_pix_fmts[] = {\n\n        AV_PIX_FMT_NV12, AV_PIX_FMT_YUV420P, AV_PIX_FMT_YUV444P,\n\n        AV_PIX_FMT_NONE,\n\n    };\n\n    static const enum AVPixelFormat output_pix_fmts[] = {\n\n        AV_PIX_FMT_CUDA, AV_PIX_FMT_NONE,\n\n    };\n\n    AVFilterFormats *in_fmts  = ff_make_format_list(input_pix_fmts);\n\n    AVFilterFormats *out_fmts = ff_make_format_list(output_pix_fmts);\n\n\n\n    ret = ff_formats_ref(in_fmts, &ctx->inputs[0]->out_formats);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    ret = ff_formats_ref(out_fmts, &ctx->outputs[0]->in_formats);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    return 0;\n\n}\n", "idx": 26419}
{"project": "FFmpeg", "commit_id": "f1e173049ecc9de03817385ba8962d14cba779db", "target": 0, "func": "static int encode_tile(Jpeg2000EncoderContext *s, Jpeg2000Tile *tile, int tileno)\n\n{\n\n    int compno, reslevelno, bandno, ret;\n\n    Jpeg2000T1Context t1;\n\n    Jpeg2000CodingStyle *codsty = &s->codsty;\n\n    for (compno = 0; compno < s->ncomponents; compno++){\n\n        Jpeg2000Component *comp = s->tile[tileno].comp + compno;\n\n\n\n        av_log(s->avctx, AV_LOG_DEBUG,\"dwt\\n\");\n\n        if ((ret = ff_dwt_encode(&comp->dwt, comp->i_data)) < 0)\n\n            return ret;\n\n        av_log(s->avctx, AV_LOG_DEBUG,\"after dwt -> tier1\\n\");\n\n\n\n        for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++){\n\n            Jpeg2000ResLevel *reslevel = comp->reslevel + reslevelno;\n\n\n\n            for (bandno = 0; bandno < reslevel->nbands ; bandno++){\n\n                Jpeg2000Band *band = reslevel->band + bandno;\n\n                Jpeg2000Prec *prec = band->prec; // we support only 1 precinct per band ATM in the encoder\n\n                int cblkx, cblky, cblkno=0, xx0, x0, xx1, y0, yy0, yy1, bandpos;\n\n                yy0 = bandno == 0 ? 0 : comp->reslevel[reslevelno-1].coord[1][1] - comp->reslevel[reslevelno-1].coord[1][0];\n\n                y0 = yy0;\n\n                yy1 = FFMIN(ff_jpeg2000_ceildivpow2(band->coord[1][0] + 1, band->log2_cblk_height) << band->log2_cblk_height,\n\n                            band->coord[1][1]) - band->coord[1][0] + yy0;\n\n\n\n                if (band->coord[0][0] == band->coord[0][1] || band->coord[1][0] == band->coord[1][1])\n\n                    continue;\n\n\n\n                bandpos = bandno + (reslevelno > 0);\n\n\n\n                for (cblky = 0; cblky < prec->nb_codeblocks_height; cblky++){\n\n                    if (reslevelno == 0 || bandno == 1)\n\n                        xx0 = 0;\n\n                    else\n\n                        xx0 = comp->reslevel[reslevelno-1].coord[0][1] - comp->reslevel[reslevelno-1].coord[0][0];\n\n                    x0 = xx0;\n\n                    xx1 = FFMIN(ff_jpeg2000_ceildivpow2(band->coord[0][0] + 1, band->log2_cblk_width) << band->log2_cblk_width,\n\n                                band->coord[0][1]) - band->coord[0][0] + xx0;\n\n\n\n                    for (cblkx = 0; cblkx < prec->nb_codeblocks_width; cblkx++, cblkno++){\n\n                        int y, x;\n\n                        if (codsty->transform == FF_DWT53){\n\n                            for (y = yy0; y < yy1; y++){\n\n                                int *ptr = t1.data[y-yy0];\n\n                                for (x = xx0; x < xx1; x++){\n\n                                    *ptr++ = comp->i_data[(comp->coord[0][1] - comp->coord[0][0]) * y + x] << NMSEDEC_FRACBITS;\n\n                                }\n\n                            }\n\n                        } else{\n\n                            for (y = yy0; y < yy1; y++){\n\n                                int *ptr = t1.data[y-yy0];\n\n                                for (x = xx0; x < xx1; x++){\n\n                                    *ptr = (comp->i_data[(comp->coord[0][1] - comp->coord[0][0]) * y + x]);\n\n                                    *ptr = (int64_t)*ptr * (int64_t)(16384 * 65536 / band->i_stepsize) >> 15 - NMSEDEC_FRACBITS;\n\n                                    ptr++;\n\n                                }\n\n                            }\n\n                        }\n\n                        encode_cblk(s, &t1, prec->cblk + cblkno, tile, xx1 - xx0, yy1 - yy0,\n\n                                    bandpos, codsty->nreslevels - reslevelno - 1);\n\n                        xx0 = xx1;\n\n                        xx1 = FFMIN(xx1 + (1 << band->log2_cblk_width), band->coord[0][1] - band->coord[0][0] + x0);\n\n                    }\n\n                    yy0 = yy1;\n\n                    yy1 = FFMIN(yy1 + (1 << band->log2_cblk_height), band->coord[1][1] - band->coord[1][0] + y0);\n\n                }\n\n            }\n\n        }\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"after tier1\\n\");\n\n    }\n\n\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"rate control\\n\");\n\n    truncpasses(s, tile);\n\n    if ((ret = encode_packets(s, tile, tileno)) < 0)\n\n        return ret;\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"after rate control\\n\");\n\n    return 0;\n\n}\n", "idx": 26422}
{"project": "FFmpeg", "commit_id": "4c7b023d56e09a78a587d036db1b64bf7c493b3d", "target": 0, "func": "static int nvdec_vp9_decode_slice(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)\n\n{\n\n    NVDECContext *ctx = avctx->internal->hwaccel_priv_data;\n\n    void *tmp;\n\n\n\n    tmp = av_fast_realloc(ctx->slice_offsets, &ctx->slice_offsets_allocated,\n\n                          (ctx->nb_slices + 1) * sizeof(*ctx->slice_offsets));\n\n    if (!tmp)\n\n        return AVERROR(ENOMEM);\n\n    ctx->slice_offsets = tmp;\n\n\n\n    if (!ctx->bitstream)\n\n        ctx->bitstream = (uint8_t*)buffer;\n\n\n\n    ctx->slice_offsets[ctx->nb_slices] = buffer - ctx->bitstream;\n\n    ctx->bitstream_len += size;\n\n    ctx->nb_slices++;\n\n\n\n    return 0;\n\n}\n", "idx": 26423}
{"project": "FFmpeg", "commit_id": "20a93ea8d489304d5c522283d79ea5f9c8fdc804", "target": 0, "func": "static void check_mct(uint8_t *ref0, uint8_t *ref1, uint8_t *ref2,\n\n                      uint8_t *new0, uint8_t *new1, uint8_t *new2) {\n\n    declare_func(void, void *src0, void *src1, void *src2, int csize);\n\n\n\n    randomize_buffers();\n\n    call_ref(ref0, ref1, ref2, BUF_SIZE / sizeof(int32_t));\n\n    call_new(new0, new1, new2, BUF_SIZE / sizeof(int32_t));\n\n    if (memcmp(ref0, new0, BUF_SIZE) || memcmp(ref1, new1, BUF_SIZE) ||\n\n        memcmp(ref2, new2, BUF_SIZE))\n\n        fail();\n\n    bench_new(new0, new1, new2, BUF_SIZE / sizeof(int32_t));\n\n}\n", "idx": 26424}
{"project": "FFmpeg", "commit_id": "d6945aeee419a8417b8019c7c92227e12e45b7ad", "target": 1, "func": "static void FUNCC(ff_h264_add_pixels4)(uint8_t *_dst, int16_t *_src, int stride)\n\n{\n\n    int i;\n\n    pixel *dst = (pixel *) _dst;\n\n    dctcoef *src = (dctcoef *) _src;\n\n    stride /= sizeof(pixel);\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        dst[0] += src[0];\n\n        dst[1] += src[1];\n\n        dst[2] += src[2];\n\n        dst[3] += src[3];\n\n\n\n        dst += stride;\n\n        src += 4;\n\n    }\n\n\n\n    memset(_src, 0, sizeof(dctcoef) * 16);\n\n}\n", "idx": 26427}
{"project": "FFmpeg", "commit_id": "636ced8e1dc8248a1353b416240b93d70ad03edb", "target": 1, "func": "static void abort_codec_experimental(AVCodec *c, int encoder)\n\n{\n\n    const char *codec_string = encoder ? \"encoder\" : \"decoder\";\n\n    AVCodec *codec;\n\n    av_log(NULL, AV_LOG_FATAL, \"%s '%s' is experimental and might produce bad \"\n\n            \"results.\\nAdd '-strict experimental' if you want to use it.\\n\",\n\n            codec_string, c->name);\n\n    codec = encoder ? avcodec_find_encoder(c->id) : avcodec_find_decoder(c->id);\n\n    if (!(codec->capabilities & CODEC_CAP_EXPERIMENTAL))\n\n        av_log(NULL, AV_LOG_FATAL, \"Or use the non experimental %s '%s'.\\n\",\n\n               codec_string, codec->name);\n\n    exit(1);\n\n}\n", "idx": 26428}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static inline void downmix_2f_2r_to_mono(float *samples)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        samples[i] += (samples[i + 256] + samples[i + 512] + samples[i + 768]);\n\n        samples[i + 256] = samples[i + 512] = samples[i + 768] = 0;\n\n    }\n\n}\n", "idx": 26429}
{"project": "FFmpeg", "commit_id": "1c010fd035c1a14dc73827b84f21f593e969a5d6", "target": 0, "func": "static int mxf_read_header(AVFormatContext *s)\n\n{\n\n    MXFContext *mxf = s->priv_data;\n\n    KLVPacket klv;\n\n    int64_t essence_offset = 0;\n\n    int ret;\n\n\n\n    mxf->last_forward_tell = INT64_MAX;\n\n    mxf->edit_units_per_packet = 1;\n\n\n\n    if (!mxf_read_sync(s->pb, mxf_header_partition_pack_key, 14)) {\n\n        av_log(s, AV_LOG_ERROR, \"could not find header partition pack key\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avio_seek(s->pb, -14, SEEK_CUR);\n\n    mxf->fc = s;\n\n    mxf->run_in = avio_tell(s->pb);\n\n\n\n    mxf_read_random_index_pack(s);\n\n\n\n    while (!url_feof(s->pb)) {\n\n        const MXFMetadataReadTableEntry *metadata;\n\n\n\n        if (klv_read_packet(&klv, s->pb) < 0) {\n\n            /* EOF - seek to previous partition or stop */\n\n            if(mxf_parse_handle_partition_or_eof(mxf) <= 0)\n\n                break;\n\n            else\n\n                continue;\n\n        }\n\n\n\n        PRINT_KEY(s, \"read header\", klv.key);\n\n        av_dlog(s, \"size %\"PRIu64\" offset %#\"PRIx64\"\\n\", klv.length, klv.offset);\n\n        if (IS_KLV_KEY(klv.key, mxf_encrypted_triplet_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_essence_element_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_avid_essence_element_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_system_item_key)) {\n\n\n\n            if (!mxf->current_partition) {\n\n                av_log(mxf->fc, AV_LOG_ERROR, \"found essence prior to first PartitionPack\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            if (!mxf->current_partition->essence_offset) {\n\n                /* for OP1a we compute essence_offset\n\n                 * for OPAtom we point essence_offset after the KL (usually op1a_essence_offset + 20 or 25)\n\n                 * TODO: for OP1a we could eliminate this entire if statement, always stopping parsing at op1a_essence_offset\n\n                 *       for OPAtom we still need the actual essence_offset though (the KL's length can vary)\n\n                 */\n\n                int64_t op1a_essence_offset =\n\n                    round_to_kag(mxf->current_partition->this_partition +\n\n                                 mxf->current_partition->pack_length,       mxf->current_partition->kag_size) +\n\n                    round_to_kag(mxf->current_partition->header_byte_count, mxf->current_partition->kag_size) +\n\n                    round_to_kag(mxf->current_partition->index_byte_count,  mxf->current_partition->kag_size);\n\n\n\n                if (mxf->op == OPAtom) {\n\n                    /* point essence_offset to the actual data\n\n                    * OPAtom has all the essence in one big KLV\n\n                    */\n\n                    mxf->current_partition->essence_offset = avio_tell(s->pb);\n\n                    mxf->current_partition->essence_length = klv.length;\n\n                } else {\n\n                    /* NOTE: op1a_essence_offset may be less than to klv.offset (C0023S01.mxf)  */\n\n                    mxf->current_partition->essence_offset = op1a_essence_offset;\n\n                }\n\n            }\n\n\n\n            if (!essence_offset)\n\n                essence_offset = klv.offset;\n\n\n\n            /* seek to footer, previous partition or stop */\n\n            if (mxf_parse_handle_essence(mxf) <= 0)\n\n                break;\n\n            continue;\n\n        } else if (!memcmp(klv.key, mxf_header_partition_pack_key, 13) &&\n\n                   klv.key[13] >= 2 && klv.key[13] <= 4 && mxf->current_partition) {\n\n            /* next partition pack - keep going, seek to previous partition or stop */\n\n            if(mxf_parse_handle_partition_or_eof(mxf) <= 0)\n\n                break;\n\n            else if (mxf->parsing_backward)\n\n                continue;\n\n            /* we're still parsing forward. proceed to parsing this partition pack */\n\n        }\n\n\n\n        for (metadata = mxf_metadata_read_table; metadata->read; metadata++) {\n\n            if (IS_KLV_KEY(klv.key, metadata->key)) {\n\n                int res;\n\n                if (klv.key[5] == 0x53) {\n\n                    res = mxf_read_local_tags(mxf, &klv, metadata->read, metadata->ctx_size, metadata->type);\n\n                } else {\n\n                    uint64_t next = avio_tell(s->pb) + klv.length;\n\n                    res = metadata->read(mxf, s->pb, 0, klv.length, klv.key, klv.offset);\n\n\n\n                    /* only seek forward, else this can loop for a long time */\n\n                    if (avio_tell(s->pb) > next) {\n\n                        av_log(s, AV_LOG_ERROR, \"read past end of KLV @ %#\"PRIx64\"\\n\",\n\n                               klv.offset);\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n\n\n                    avio_seek(s->pb, next, SEEK_SET);\n\n                }\n\n                if (res < 0) {\n\n                    av_log(s, AV_LOG_ERROR, \"error reading header metadata\\n\");\n\n                    return res;\n\n                }\n\n                break;\n\n            }\n\n        }\n\n        if (!metadata->read)\n\n            avio_skip(s->pb, klv.length);\n\n    }\n\n    /* FIXME avoid seek */\n\n    if (!essence_offset)  {\n\n        av_log(s, AV_LOG_ERROR, \"no essence\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avio_seek(s->pb, essence_offset, SEEK_SET);\n\n\n\n    mxf_compute_essence_containers(mxf);\n\n\n\n    /* we need to do this before computing the index tables\n\n     * to be able to fill in zero IndexDurations with st->duration */\n\n    if ((ret = mxf_parse_structural_metadata(mxf)) < 0)\n\n        goto fail;\n\n\n\n    if ((ret = mxf_compute_index_tables(mxf)) < 0)\n\n        goto fail;\n\n\n\n    if (mxf->nb_index_tables > 1) {\n\n        /* TODO: look up which IndexSID to use via EssenceContainerData */\n\n        av_log(mxf->fc, AV_LOG_INFO, \"got %i index tables - only the first one (IndexSID %i) will be used\\n\",\n\n               mxf->nb_index_tables, mxf->index_tables[0].index_sid);\n\n    } else if (mxf->nb_index_tables == 0 && mxf->op == OPAtom) {\n\n        av_log(mxf->fc, AV_LOG_ERROR, \"cannot demux OPAtom without an index\\n\");\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto fail;\n\n    }\n\n\n\n    mxf_handle_small_eubc(s);\n\n\n\n    return 0;\n\nfail:\n\n    mxf_read_close(s);\n\n\n\n    return ret;\n\n}\n", "idx": 26430}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static inline void downmix_3f_1r_to_dolby(float *samples)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        samples[i] += (samples[i + 256] - samples[i + 768]);\n\n        samples[i + 256] += (samples[i + 512] + samples[i + 768]);\n\n        samples[i + 512] = samples[i + 768] = 0;\n\n    }\n\n}\n", "idx": 26431}
{"project": "FFmpeg", "commit_id": "a11c16a0b0cadf3a14fa5e7329c2a144a2165bc6", "target": 1, "func": "void compute_images_mse(PSNRContext *s,\n\n                        const uint8_t *main_data[4], const int main_linesizes[4],\n\n                        const uint8_t *ref_data[4], const int ref_linesizes[4],\n\n                        int w, int h, double mse[4])\n\n{\n\n    int i, c, j;\n\n\n\n    for (c = 0; c < s->nb_components; c++) {\n\n        const int outw = s->planewidth[c];\n\n        const int outh = s->planeheight[c];\n\n        const uint8_t *main_line = main_data[c];\n\n        const uint8_t *ref_line = ref_data[c];\n\n        const int ref_linesize = ref_linesizes[c];\n\n        const int main_linesize = main_linesizes[c];\n\n        int m = 0;\n\n\n\n        for (i = 0; i < outh; i++) {\n\n            for (j = 0; j < outw; j++)\n\n                m += pow2(main_line[j] - ref_line[j]);\n\n            ref_line += ref_linesize;\n\n            main_line += main_linesize;\n\n        }\n\n        mse[c] = m / (double)(outw * outh);\n\n    }\n\n}\n", "idx": 26433}
{"project": "FFmpeg", "commit_id": "877f76ad33bb9b0b0d09565dd9ec1cf8e91096f1", "target": 1, "func": "static inline void hyscale_fast_c(SwsContext *c, int16_t *dst, int dstWidth,\n\n                                  const uint8_t *src, int srcW, int xInc)\n\n{\n\n    int i;\n\n    unsigned int xpos=0;\n\n    for (i=0;i<dstWidth;i++) {\n\n        register unsigned int xx=xpos>>16;\n\n        register unsigned int xalpha=(xpos&0xFFFF)>>9;\n\n        dst[i]= (src[xx]<<7) + (src[xx+1] - src[xx])*xalpha;\n\n        xpos+=xInc;\n\n    }\n\n\n\n}", "idx": 26435}
{"project": "FFmpeg", "commit_id": "7cc84d241ba6ef8e27e4d057176a4ad385ad3d59", "target": 1, "func": "static int standard_decode_i_mbs(VC9Context *v)\n\n{\n\n    GetBitContext *gb = &v->s.gb;\n\n    MpegEncContext *s = &v->s;\n\n    int current_mb = 0; /* MB/Block Position info */\n\n    uint8_t cbpcy[4], previous_cbpcy[4], predicted_cbpcy,\n\n        *p_cbpcy /* Pointer to skip some math */;\n\n\n\n    /* Reset CBPCY predictors */\n\n    memset(v->previous_line_cbpcy, 0, s->mb_stride<<2);\n\n\n\n    /* Select ttmb table depending on pq */\n\n    if (v->pq < 5) v->ttmb_vlc = &vc9_ttmb_vlc[0];\n\n    else if (v->pq < 13) v->ttmb_vlc = &vc9_ttmb_vlc[1];\n\n    else v->ttmb_vlc = &vc9_ttmb_vlc[2];\n\n\n\n    for (s->mb_y=0; s->mb_y<s->mb_height; s->mb_y++)\n\n    {\n\n        /* Init CBPCY for line */\n\n        *((uint32_t*)previous_cbpcy) = 0x00000000;\n\n        p_cbpcy = v->previous_line_cbpcy+4;\n\n\n\n        for (s->mb_x=0; s->mb_x<s->mb_width; s->mb_x++, p_cbpcy += 4)\n\n        {\n\n            /* Get CBPCY */\n\n            GET_CBPCY(ff_msmp4_mb_i_vlc.table, MB_INTRA_VLC_BITS);\n\n\n\n            s->ac_pred = get_bits(gb, 1);\n\n\n\n            /* TODO: Decode blocks from that mb wrt cbpcy */\n\n\n\n            /* Update for next block */\n\n#if TRACE > 2\n\n            av_log(s->avctx, AV_LOG_DEBUG, \"Block %4i: p_cbpcy=%i%i%i%i, previous_cbpcy=%i%i%i%i,\"\n\n                   \" cbpcy=%i%i%i%i\\n\", current_mb,\n\n                   p_cbpcy[0], p_cbpcy[1], p_cbpcy[2], p_cbpcy[3],\n\n                   previous_cbpcy[0], previous_cbpcy[1], previous_cbpcy[2], previous_cbpcy[3],\n\n                   cbpcy[0], cbpcy[1], cbpcy[2], cbpcy[3]);\n\n#endif\n\n            *((uint32_t*)p_cbpcy) = *((uint32_t*)previous_cbpcy);\n\n            *((uint32_t*)previous_cbpcy) = *((uint32_t*)cbpcy);\n\n            current_mb++;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 26437}
{"project": "FFmpeg", "commit_id": "464c49155ce7ffc88ed39eb2511e7a75565c24be", "target": 0, "func": "static int ape_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    AVFrame *frame     = data;\n\n    const uint8_t *buf = avpkt->data;\n\n    APEContext *s = avctx->priv_data;\n\n    uint8_t *sample8;\n\n    int16_t *sample16;\n\n    int32_t *sample24;\n\n    int i, ch, ret;\n\n    int blockstodecode;\n\n\n\n    /* this should never be negative, but bad things will happen if it is, so\n\n       check it just to make sure. */\n\n    av_assert0(s->samples >= 0);\n\n\n\n    if(!s->samples){\n\n        uint32_t nblocks, offset;\n\n        int buf_size;\n\n\n\n        if (!avpkt->size) {\n\n            *got_frame_ptr = 0;\n\n            return 0;\n\n        }\n\n        if (avpkt->size < 8) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        buf_size = avpkt->size & ~3;\n\n        if (buf_size != avpkt->size) {\n\n            av_log(avctx, AV_LOG_WARNING, \"packet size is not a multiple of 4. \"\n\n                   \"extra bytes at the end will be skipped.\\n\");\n\n        }\n\n        if (s->fileversion < 3950) // previous versions overread two bytes\n\n            buf_size += 2;\n\n        av_fast_padded_malloc(&s->data, &s->data_size, buf_size);\n\n        if (!s->data)\n\n            return AVERROR(ENOMEM);\n\n        s->bdsp.bswap_buf((uint32_t *) s->data, (const uint32_t *) buf,\n\n                          buf_size >> 2);\n\n        memset(s->data + (buf_size & ~3), 0, buf_size & 3);\n\n        s->ptr = s->data;\n\n        s->data_end = s->data + buf_size;\n\n\n\n        nblocks = bytestream_get_be32(&s->ptr);\n\n        offset  = bytestream_get_be32(&s->ptr);\n\n        if (s->fileversion >= 3900) {\n\n            if (offset > 3) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Incorrect offset passed\\n\");\n\n                s->data = NULL;\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if (s->data_end - s->ptr < offset) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            s->ptr += offset;\n\n        } else {\n\n            if ((ret = init_get_bits8(&s->gb, s->ptr, s->data_end - s->ptr)) < 0)\n\n                return ret;\n\n            if (s->fileversion > 3800)\n\n                skip_bits_long(&s->gb, offset * 8);\n\n            else\n\n                skip_bits_long(&s->gb, offset);\n\n        }\n\n\n\n        if (!nblocks || nblocks > INT_MAX) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Invalid sample count: %\"PRIu32\".\\n\",\n\n                   nblocks);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        s->samples = nblocks;\n\n\n\n        /* Initialize the frame decoder */\n\n        if (init_frame_decoder(s) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Error reading frame header\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    if (!s->data) {\n\n        *got_frame_ptr = 0;\n\n        return avpkt->size;\n\n    }\n\n\n\n    blockstodecode = FFMIN(s->blocks_per_loop, s->samples);\n\n    // for old files coefficients were not interleaved,\n\n    // so we need to decode all of them at once\n\n    if (s->fileversion < 3930)\n\n        blockstodecode = s->samples;\n\n\n\n    /* reallocate decoded sample buffer if needed */\n\n    av_fast_malloc(&s->decoded_buffer, &s->decoded_size,\n\n                   2 * FFALIGN(blockstodecode, 8) * sizeof(*s->decoded_buffer));\n\n    if (!s->decoded_buffer)\n\n        return AVERROR(ENOMEM);\n\n    memset(s->decoded_buffer, 0, s->decoded_size);\n\n    s->decoded[0] = s->decoded_buffer;\n\n    s->decoded[1] = s->decoded_buffer + FFALIGN(blockstodecode, 8);\n\n\n\n    /* get output buffer */\n\n    frame->nb_samples = blockstodecode;\n\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n\n        return ret;\n\n\n\n    s->error=0;\n\n\n\n    if ((s->channels == 1) || (s->frameflags & APE_FRAMECODE_PSEUDO_STEREO))\n\n        ape_unpack_mono(s, blockstodecode);\n\n    else\n\n        ape_unpack_stereo(s, blockstodecode);\n\n    emms_c();\n\n\n\n    if (s->error) {\n\n        s->samples=0;\n\n        av_log(avctx, AV_LOG_ERROR, \"Error decoding frame\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    switch (s->bps) {\n\n    case 8:\n\n        for (ch = 0; ch < s->channels; ch++) {\n\n            sample8 = (uint8_t *)frame->data[ch];\n\n            for (i = 0; i < blockstodecode; i++)\n\n                *sample8++ = (s->decoded[ch][i] + 0x80) & 0xff;\n\n        }\n\n        break;\n\n    case 16:\n\n        for (ch = 0; ch < s->channels; ch++) {\n\n            sample16 = (int16_t *)frame->data[ch];\n\n            for (i = 0; i < blockstodecode; i++)\n\n                *sample16++ = s->decoded[ch][i];\n\n        }\n\n        break;\n\n    case 24:\n\n        for (ch = 0; ch < s->channels; ch++) {\n\n            sample24 = (int32_t *)frame->data[ch];\n\n            for (i = 0; i < blockstodecode; i++)\n\n                *sample24++ = s->decoded[ch][i] << 8;\n\n        }\n\n        break;\n\n    }\n\n\n\n    s->samples -= blockstodecode;\n\n\n\n    *got_frame_ptr = 1;\n\n\n\n    return !s->samples ? avpkt->size : 0;\n\n}\n", "idx": 26439}
{"project": "FFmpeg", "commit_id": "46e1af3b0f2c28936dfa88063cc5a35f466f5ac3", "target": 0, "func": "static int decode_plane(UtvideoContext *c, int plane_no,\n\n                        uint8_t *dst, int step, int stride,\n\n                        int width, int height,\n\n                        const uint8_t *src, int src_size, int use_pred)\n\n{\n\n    int i, j, slice, pix;\n\n    int sstart, send;\n\n    VLC vlc;\n\n    GetBitContext gb;\n\n    int prev;\n\n    const int cmask = ~(!plane_no && c->avctx->pix_fmt == PIX_FMT_YUV420P);\n\n\n\n    if (build_huff(src, &vlc)) {\n\n        av_log(c->avctx, AV_LOG_ERROR, \"Cannot build Huffman codes\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    src      += 256;\n\n    src_size -= 256;\n\n\n\n    send = 0;\n\n    for (slice = 0; slice < c->slices; slice++) {\n\n        uint8_t *dest;\n\n        int slice_data_start, slice_data_end, slice_size;\n\n\n\n        sstart = send;\n\n        send   = (height * (slice + 1) / c->slices) & cmask;\n\n        dest   = dst + sstart * stride;\n\n\n\n        // slice offset and size validation was done earlier\n\n        slice_data_start = slice ? AV_RL32(src + slice * 4 - 4) : 0;\n\n        slice_data_end   = AV_RL32(src + slice * 4);\n\n        slice_size       = slice_data_end - slice_data_start;\n\n\n\n        if (!slice_size) {\n\n            for (j = sstart; j < send; j++) {\n\n                for (i = 0; i < width * step; i += step)\n\n                    dest[i] = 0x80;\n\n                dest += stride;\n\n            }\n\n            continue;\n\n        }\n\n\n\n        memcpy(c->slice_bits, src + slice_data_start + c->slices * 4, slice_size);\n\n        memset(c->slice_bits + slice_size, 0, FF_INPUT_BUFFER_PADDING_SIZE);\n\n        c->dsp.bswap_buf((uint32_t*)c->slice_bits, (uint32_t*)c->slice_bits,\n\n                         (slice_data_end - slice_data_start + 3) >> 2);\n\n        init_get_bits(&gb, c->slice_bits, slice_size * 8);\n\n\n\n        prev = 0x80;\n\n        for (j = sstart; j < send; j++) {\n\n            for (i = 0; i < width * step; i += step) {\n\n                if (get_bits_left(&gb) <= 0) {\n\n                    av_log(c->avctx, AV_LOG_ERROR, \"Slice decoding ran out of bits\\n\");\n\n                    goto fail;\n\n                }\n\n                pix = get_vlc2(&gb, vlc.table, vlc.bits, 4);\n\n                if (pix < 0) {\n\n                    av_log(c->avctx, AV_LOG_ERROR, \"Decoding error\\n\");\n\n                    goto fail;\n\n                }\n\n                if (use_pred) {\n\n                    prev += pix;\n\n                    pix   = prev;\n\n                }\n\n                dest[i] = pix;\n\n            }\n\n            dest += stride;\n\n        }\n\n        if (get_bits_left(&gb) > 32)\n\n            av_log(c->avctx, AV_LOG_WARNING, \"%d bits left after decoding slice\\n\",\n\n                   get_bits_left(&gb));\n\n    }\n\n\n\n    free_vlc(&vlc);\n\n\n\n    return 0;\n\nfail:\n\n    free_vlc(&vlc);\n\n    return AVERROR_INVALIDDATA;\n\n}\n", "idx": 26440}
{"project": "FFmpeg", "commit_id": "7f4ec4364bc4a73036660c1c6a3c4801db524e9e", "target": 0, "func": "static int mov_read_dac3(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st;\n\n    enum AVAudioServiceType *ast;\n\n    int ac3info, acmod, lfeon, bsmod;\n\n\n\n    if (c->fc->nb_streams < 1)\n\n        return 0;\n\n    st = c->fc->streams[c->fc->nb_streams-1];\n\n\n\n    ast = (enum AVAudioServiceType*)ff_stream_new_side_data(st, AV_PKT_DATA_AUDIO_SERVICE_TYPE,\n\n                                                            sizeof(*ast));\n\n    if (!ast)\n\n        return AVERROR(ENOMEM);\n\n\n\n    ac3info = avio_rb24(pb);\n\n    bsmod = (ac3info >> 14) & 0x7;\n\n    acmod = (ac3info >> 11) & 0x7;\n\n    lfeon = (ac3info >> 10) & 0x1;\n\n    st->codec->channels = ((int[]){2,1,2,3,3,4,4,5})[acmod] + lfeon;\n\n    st->codec->channel_layout = avpriv_ac3_channel_layout_tab[acmod];\n\n    if (lfeon)\n\n        st->codec->channel_layout |= AV_CH_LOW_FREQUENCY;\n\n    *ast = bsmod;\n\n    if (st->codec->channels > 1 && bsmod == 0x7)\n\n        *ast = AV_AUDIO_SERVICE_TYPE_KARAOKE;\n\n\n\n    st->codec->audio_service_type = *ast;\n\n\n\n    return 0;\n\n}\n", "idx": 26441}
{"project": "FFmpeg", "commit_id": "e60dbe421c7e9cd896d33e35a6a1b0cef953918e", "target": 0, "func": "static int set_pix_fmt(AVCodecContext *avctx, struct vpx_image *img,\n\n                       int has_alpha_channel)\n\n{\n\n#if VPX_IMAGE_ABI_VERSION >= 3\n\n    static const enum AVColorSpace colorspaces[8] = {\n\n        AVCOL_SPC_UNSPECIFIED, AVCOL_SPC_BT470BG, AVCOL_SPC_BT709, AVCOL_SPC_SMPTE170M,\n\n        AVCOL_SPC_SMPTE240M, AVCOL_SPC_BT2020_NCL, AVCOL_SPC_RESERVED, AVCOL_SPC_RGB,\n\n    };\n\n#if VPX_IMAGE_ABI_VERSION >= 4\n\n    static const enum AVColorRange color_ranges[] = {\n\n        AVCOL_RANGE_MPEG, AVCOL_RANGE_JPEG\n\n    };\n\n    avctx->color_range = color_ranges[img->range];\n\n#endif\n\n    avctx->colorspace = colorspaces[img->cs];\n\n#endif\n\n    if (avctx->codec_id == AV_CODEC_ID_VP8 && img->fmt != VPX_IMG_FMT_I420)\n\n        return AVERROR_INVALIDDATA;\n\n    switch (img->fmt) {\n\n    case VPX_IMG_FMT_I420:\n\n        if (avctx->codec_id == AV_CODEC_ID_VP9)\n\n            avctx->profile = FF_PROFILE_VP9_0;\n\n        avctx->pix_fmt =\n\n            has_alpha_channel ? AV_PIX_FMT_YUVA420P : AV_PIX_FMT_YUV420P;\n\n        return 0;\n\n#if CONFIG_LIBVPX_VP9_DECODER\n\n    case VPX_IMG_FMT_I422:\n\n        avctx->profile = FF_PROFILE_VP9_1;\n\n        avctx->pix_fmt = AV_PIX_FMT_YUV422P;\n\n        return 0;\n\n#if VPX_IMAGE_ABI_VERSION >= 3\n\n    case VPX_IMG_FMT_I440:\n\n        avctx->profile = FF_PROFILE_VP9_1;\n\n        avctx->pix_fmt = AV_PIX_FMT_YUV440P;\n\n        return 0;\n\n#endif\n\n    case VPX_IMG_FMT_I444:\n\n        avctx->profile = FF_PROFILE_VP9_1;\n\n#if VPX_IMAGE_ABI_VERSION >= 3\n\n        avctx->pix_fmt = avctx->colorspace == AVCOL_SPC_RGB ?\n\n                         AV_PIX_FMT_GBRP : AV_PIX_FMT_YUV444P;\n\n#else\n\n        avctx->pix_fmt = AV_PIX_FMT_YUV444P;\n\n#endif\n\n        return 0;\n\n#ifdef VPX_IMG_FMT_HIGHBITDEPTH\n\n    case VPX_IMG_FMT_I42016:\n\n        avctx->profile = FF_PROFILE_VP9_2;\n\n        if (img->bit_depth == 10) {\n\n            avctx->pix_fmt = AV_PIX_FMT_YUV420P10;\n\n            return 0;\n\n        } else if (img->bit_depth == 12) {\n\n            avctx->pix_fmt = AV_PIX_FMT_YUV420P12;\n\n            return 0;\n\n        } else {\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    case VPX_IMG_FMT_I42216:\n\n        avctx->profile = FF_PROFILE_VP9_3;\n\n        if (img->bit_depth == 10) {\n\n            avctx->pix_fmt = AV_PIX_FMT_YUV422P10;\n\n            return 0;\n\n        } else if (img->bit_depth == 12) {\n\n            avctx->pix_fmt = AV_PIX_FMT_YUV422P12;\n\n            return 0;\n\n        } else {\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n#if VPX_IMAGE_ABI_VERSION >= 3\n\n    case VPX_IMG_FMT_I44016:\n\n        avctx->profile = FF_PROFILE_VP9_3;\n\n        if (img->bit_depth == 10) {\n\n            avctx->pix_fmt = AV_PIX_FMT_YUV440P10;\n\n            return 0;\n\n        } else if (img->bit_depth == 12) {\n\n            avctx->pix_fmt = AV_PIX_FMT_YUV440P12;\n\n            return 0;\n\n        } else {\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n#endif\n\n    case VPX_IMG_FMT_I44416:\n\n        avctx->profile = FF_PROFILE_VP9_3;\n\n        if (img->bit_depth == 10) {\n\n#if VPX_IMAGE_ABI_VERSION >= 3\n\n            avctx->pix_fmt = avctx->colorspace == AVCOL_SPC_RGB ?\n\n                             AV_PIX_FMT_GBRP10 : AV_PIX_FMT_YUV444P10;\n\n#else\n\n            avctx->pix_fmt = AV_PIX_FMT_YUV444P10;\n\n#endif\n\n            return 0;\n\n        } else if (img->bit_depth == 12) {\n\n#if VPX_IMAGE_ABI_VERSION >= 3\n\n            avctx->pix_fmt = avctx->colorspace == AVCOL_SPC_RGB ?\n\n                             AV_PIX_FMT_GBRP12 : AV_PIX_FMT_YUV444P12;\n\n#else\n\n            avctx->pix_fmt = AV_PIX_FMT_YUV444P12;\n\n#endif\n\n            return 0;\n\n        } else {\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n#endif\n\n#endif\n\n    default:\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n}\n", "idx": 26442}
{"project": "FFmpeg", "commit_id": "90fc00a623de44e137fe1601b91356e8cd8bdd54", "target": 1, "func": "static int mpsub_probe(AVProbeData *p)\n\n{\n\n    const char *ptr     = p->buf;\n\n    const char *ptr_end = p->buf + p->buf_size;\n\n\n\n    while (ptr < ptr_end) {\n\n        if (!memcmp(ptr, \"FORMAT=TIME\", 11))\n\n            return AVPROBE_SCORE_EXTENSION;\n\n        if (!memcmp(ptr, \"FORMAT=\", 7))\n\n            return AVPROBE_SCORE_EXTENSION / 3;\n\n        ptr += strcspn(ptr, \"\\n\") + 1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 26446}
{"project": "FFmpeg", "commit_id": "3518c5a96b0417f6e66bd0c8c64bd2b32d936064", "target": 1, "func": "void MPV_common_init_altivec(MpegEncContext *s)\n{\n    if (s->avctx->lowres==0)\n    {\n        if ((s->avctx->idct_algo == FF_IDCT_AUTO) ||\n                (s->avctx->idct_algo == FF_IDCT_ALTIVEC))\n        {\n            s->dsp.idct_put = idct_put_altivec;\n            s->dsp.idct_add = idct_add_altivec;\n            s->dsp.idct_permutation_type = FF_TRANSPOSE_IDCT_PERM;\n        }\n    }\n    // Test to make sure that the dct required alignments are met.\n    if ((((long)(s->q_intra_matrix) & 0x0f) != 0) ||\n        (((long)(s->q_inter_matrix) & 0x0f) != 0))\n    {\n        av_log(s->avctx, AV_LOG_INFO, \"Internal Error: q-matrix blocks must be 16-byte aligned \"\n                \"to use AltiVec DCT. Reverting to non-AltiVec version.\\n\");\n        return;\n    }\n    if (((long)(s->intra_scantable.inverse) & 0x0f) != 0)\n    {\n        av_log(s->avctx, AV_LOG_INFO, \"Internal Error: scan table blocks must be 16-byte aligned \"\n                \"to use AltiVec DCT. Reverting to non-AltiVec version.\\n\");\n        return;\n    }\n    if ((s->avctx->dct_algo == FF_DCT_AUTO) ||\n            (s->avctx->dct_algo == FF_DCT_ALTIVEC))\n    {\n#if 0 /* seems to cause trouble under some circumstances */\n        s->dct_quantize = dct_quantize_altivec;\n#endif\n        s->dct_unquantize_h263_intra = dct_unquantize_h263_altivec;\n        s->dct_unquantize_h263_inter = dct_unquantize_h263_altivec;\n    }\n}", "idx": 26447}
{"project": "FFmpeg", "commit_id": "fc49f22c3b735db5aaac5f98e40b7124a2be13b8", "target": 1, "func": "static int configure_output_filter(FilterGraph *fg, OutputFilter *ofilter, AVFilterInOut *out)\n\n{\n\n    char *pix_fmts;\n\n    AVCodecContext *codec = ofilter->ost->st->codec;\n\n    AVFilterContext *last_filter = out->filter_ctx;\n\n    int pad_idx = out->pad_idx;\n\n    int ret;\n\n    AVBufferSinkParams *buffersink_params = av_buffersink_params_alloc();\n\n\n\n#if FF_API_OLD_VSINK_API\n\n    ret = avfilter_graph_create_filter(&ofilter->filter,\n\n                                       avfilter_get_by_name(\"buffersink\"),\n\n                                       \"out\", NULL, NULL, fg->graph);\n\n#else\n\n    ret = avfilter_graph_create_filter(&ofilter->filter,\n\n                                       avfilter_get_by_name(\"buffersink\"),\n\n                                       \"out\", NULL, buffersink_params, fg->graph);\n\n#endif\n\n    av_freep(&buffersink_params);\n\n\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (codec->width || codec->height) {\n\n        char args[255];\n\n        AVFilterContext *filter;\n\n\n\n        snprintf(args, sizeof(args), \"%d:%d:flags=0x%X\",\n\n                 codec->width,\n\n                 codec->height,\n\n                 (unsigned)ofilter->ost->sws_flags);\n\n        if ((ret = avfilter_graph_create_filter(&filter, avfilter_get_by_name(\"scale\"),\n\n                                                NULL, args, NULL, fg->graph)) < 0)\n\n            return ret;\n\n        if ((ret = avfilter_link(last_filter, pad_idx, filter, 0)) < 0)\n\n            return ret;\n\n\n\n        last_filter = filter;\n\n        pad_idx = 0;\n\n    }\n\n\n\n    if ((pix_fmts = choose_pixel_fmts(ofilter->ost))) {\n\n        AVFilterContext *filter;\n\n        if ((ret = avfilter_graph_create_filter(&filter,\n\n                                                avfilter_get_by_name(\"format\"),\n\n                                                \"format\", pix_fmts, NULL,\n\n                                                fg->graph)) < 0)\n\n            return ret;\n\n        if ((ret = avfilter_link(last_filter, pad_idx, filter, 0)) < 0)\n\n            return ret;\n\n\n\n        last_filter = filter;\n\n        pad_idx     = 0;\n\n        av_freep(&pix_fmts);\n\n    }\n\n\n\n    if ((ret = avfilter_link(last_filter, pad_idx, ofilter->filter, 0)) < 0)\n\n        return ret;\n\n\n\n    return 0;\n\n}\n", "idx": 26448}
{"project": "FFmpeg", "commit_id": "6eee9f5596074f9c0ff2cb25050b56c2914ff411", "target": 1, "func": "static int eightsvx_decode_frame(AVCodecContext *avctx, void *data,\n\n                                 int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    EightSvxContext *esc = avctx->priv_data;\n\n    int n, out_data_size, ret;\n\n    uint8_t *src, *dst;\n\n\n\n    /* decode and interleave the first packet */\n\n    if (!esc->samples && avpkt) {\n\n        uint8_t *deinterleaved_samples, *p = NULL;\n\n\n\n        esc->samples_size = !esc->table ?\n\n            avpkt->size : avctx->channels + (avpkt->size-avctx->channels) * 2;\n\n        if (!(esc->samples = av_malloc(esc->samples_size)))\n\n            return AVERROR(ENOMEM);\n\n\n\n        /* decompress */\n\n        if (esc->table) {\n\n            const uint8_t *buf = avpkt->data;\n\n            uint8_t *dst;\n\n            int buf_size = avpkt->size;\n\n            int i, n = esc->samples_size;\n\n\n\n            if (buf_size < 2) {\n\n                av_log(avctx, AV_LOG_ERROR, \"packet size is too small\\n\");\n\n                return AVERROR(EINVAL);\n\n            }\n\n            if (!(deinterleaved_samples = av_mallocz(n)))\n\n                return AVERROR(ENOMEM);\n\n            dst = p = deinterleaved_samples;\n\n\n\n            /* the uncompressed starting value is contained in the first byte */\n\n            dst = deinterleaved_samples;\n\n            for (i = 0; i < avctx->channels; i++) {\n\n                delta_decode(dst, buf + 1, buf_size / avctx->channels - 1, buf[0], esc->table);\n\n                buf += buf_size / avctx->channels;\n\n                dst += n / avctx->channels - 1;\n\n            }\n\n        } else {\n\n            deinterleaved_samples = avpkt->data;\n\n        }\n\n\n\n        if (avctx->channels == 2)\n\n            interleave_stereo(esc->samples, deinterleaved_samples, esc->samples_size);\n\n        else\n\n            memcpy(esc->samples, deinterleaved_samples, esc->samples_size);\n\n        av_freep(&p);\n\n    }\n\n\n\n    /* get output buffer */\n\n    av_assert1(!(esc->samples_size % avctx->channels || esc->samples_idx % avctx->channels));\n\n    esc->frame.nb_samples = FFMIN(MAX_FRAME_SIZE, esc->samples_size - esc->samples_idx)  / avctx->channels;\n\n    if ((ret = avctx->get_buffer(avctx, &esc->frame)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n\n\n    *got_frame_ptr   = 1;\n\n    *(AVFrame *)data = esc->frame;\n\n\n\n    dst = esc->frame.data[0];\n\n    src = esc->samples + esc->samples_idx;\n\n    out_data_size = esc->frame.nb_samples * avctx->channels;\n\n    for (n = out_data_size; n > 0; n--)\n\n        *dst++ = *src++ + 128;\n\n    esc->samples_idx += out_data_size;\n\n\n\n    return esc->table ?\n\n        (avctx->frame_number == 0)*2 + out_data_size / 2 :\n\n        out_data_size;\n\n}\n", "idx": 26449}
{"project": "FFmpeg", "commit_id": "4cb6964244fd6c099383d8b7e99731e72cc844b9", "target": 0, "func": "static void int8x8_fmul_int32_c(float *dst, const int8_t *src, int scale)\n\n{\n\n    float fscale = scale / 16.0;\n\n    int i;\n\n    for (i = 0; i < 8; i++)\n\n        dst[i] = src[i] * fscale;\n\n}\n", "idx": 26459}
{"project": "FFmpeg", "commit_id": "ddbcc48b646737c8bff7f8e28e0a69dca65509cf", "target": 0, "func": "static int ftp_auth(FTPContext *s)\n\n{\n\n    const char *user = NULL, *pass = NULL;\n\n    char *end = NULL, buf[CONTROL_BUFFER_SIZE], credencials[CREDENTIALS_BUFFER_SIZE];\n\n    int err;\n\n    const int user_codes[] = {331, 230, 0};\n\n    const int pass_codes[] = {230, 0};\n\n\n\n    /* Authentication may be repeated, original string has to be saved */\n\n    av_strlcpy(credencials, s->credencials, sizeof(credencials));\n\n\n\n    user = av_strtok(credencials, \":\", &end);\n\n    pass = av_strtok(end, \":\", &end);\n\n\n\n    if (!user) {\n\n        user = \"anonymous\";\n\n        pass = s->anonymous_password ? s->anonymous_password : \"nopassword\";\n\n    }\n\n\n\n    snprintf(buf, sizeof(buf), \"USER %s\\r\\n\", user);\n\n    err = ftp_send_command(s, buf, user_codes, NULL);\n\n    if (err == 331) {\n\n        if (pass) {\n\n            snprintf(buf, sizeof(buf), \"PASS %s\\r\\n\", pass);\n\n            err = ftp_send_command(s, buf, pass_codes, NULL);\n\n        } else\n\n            return AVERROR(EACCES);\n\n    }\n\n    if (!err)\n\n        return AVERROR(EACCES);\n\n\n\n    return 0;\n\n}\n", "idx": 26470}
{"project": "FFmpeg", "commit_id": "fddc5b9bea39968ed1f45c667869428865de7626", "target": 0, "func": "int ff_celp_lp_synthesis_filter(int16_t *out, const int16_t *filter_coeffs,\n\n                                const int16_t *in, int buffer_length,\n\n                                int filter_length, int stop_on_overflow,\n\n                                int shift, int rounder)\n\n{\n\n    int i,n;\n\n\n\n    for (n = 0; n < buffer_length; n++) {\n\n        int sum = rounder;\n\n        for (i = 1; i <= filter_length; i++)\n\n            sum -= filter_coeffs[i-1] * out[n-i];\n\n\n\n        sum = ((sum >> 12) + in[n]) >> shift;\n\n\n\n        if (sum + 0x8000 > 0xFFFFU) {\n\n            if (stop_on_overflow)\n\n                return 1;\n\n            sum = (sum >> 31) ^ 32767;\n\n        }\n\n        out[n] = sum;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26473}
{"project": "FFmpeg", "commit_id": "b570f24d7600ef4c8f05018c46bea6356927ba4d", "target": 0, "func": "static int push_samples(AVFilterLink *outlink)\n\n{\n\n    ASNSContext *asns = outlink->src->priv;\n\n    AVFrame *outsamples = NULL;\n\n    int ret, nb_out_samples, nb_pad_samples;\n\n\n\n    if (asns->pad) {\n\n        nb_out_samples = av_audio_fifo_size(asns->fifo) ? asns->nb_out_samples : 0;\n\n        nb_pad_samples = nb_out_samples - FFMIN(nb_out_samples, av_audio_fifo_size(asns->fifo));\n\n    } else {\n\n        nb_out_samples = FFMIN(asns->nb_out_samples, av_audio_fifo_size(asns->fifo));\n\n        nb_pad_samples = 0;\n\n    }\n\n\n\n    if (!nb_out_samples)\n\n        return 0;\n\n\n\n    outsamples = ff_get_audio_buffer(outlink, nb_out_samples);\n\n    av_assert0(outsamples);\n\n\n\n    av_audio_fifo_read(asns->fifo,\n\n                       (void **)outsamples->extended_data, nb_out_samples);\n\n\n\n    if (nb_pad_samples)\n\n        av_samples_set_silence(outsamples->extended_data, nb_out_samples - nb_pad_samples,\n\n                               nb_pad_samples, av_get_channel_layout_nb_channels(outlink->channel_layout),\n\n                               outlink->format);\n\n    outsamples->nb_samples     = nb_out_samples;\n\n    outsamples->channel_layout = outlink->channel_layout;\n\n    outsamples->sample_rate    = outlink->sample_rate;\n\n    outsamples->pts = asns->next_out_pts;\n\n\n\n    if (asns->next_out_pts != AV_NOPTS_VALUE)\n\n        asns->next_out_pts += nb_out_samples;\n\n\n\n    ret = ff_filter_frame(outlink, outsamples);\n\n    if (ret < 0)\n\n        return ret;\n\n    asns->req_fullfilled = 1;\n\n    return nb_out_samples;\n\n}\n", "idx": 26474}
{"project": "FFmpeg", "commit_id": "a813cdda487e252681df36f675332b04c2e0e5a6", "target": 0, "func": "static void truemotion1_decode_16bit(TrueMotion1Context *s)\n\n{\n\n    int y;\n\n    int pixels_left;  /* remaining pixels on this line */\n\n    unsigned int predictor_pair;\n\n    unsigned int horiz_pred;\n\n    unsigned int *vert_pred;\n\n    unsigned int *current_pixel_pair;\n\n    unsigned char *current_line = s->frame->data[0];\n\n    int keyframe = s->flags & FLAG_KEYFRAME;\n\n\n\n    /* these variables are for managing the stream of macroblock change bits */\n\n    const unsigned char *mb_change_bits = s->mb_change_bits;\n\n    unsigned char mb_change_byte;\n\n    unsigned char mb_change_byte_mask;\n\n    int mb_change_index;\n\n\n\n    /* these variables are for managing the main index stream */\n\n    int index_stream_index = 0;  /* yes, the index into the index stream */\n\n    int index;\n\n\n\n    /* clean out the line buffer */\n\n    memset(s->vert_pred, 0, s->avctx->width * sizeof(unsigned int));\n\n\n\n    GET_NEXT_INDEX();\n\n\n\n    for (y = 0; y < s->avctx->height; y++) {\n\n\n\n        /* re-init variables for the next line iteration */\n\n        horiz_pred = 0;\n\n        current_pixel_pair = (unsigned int *)current_line;\n\n        vert_pred = s->vert_pred;\n\n        mb_change_index = 0;\n\n        mb_change_byte = mb_change_bits[mb_change_index++];\n\n        mb_change_byte_mask = 0x01;\n\n        pixels_left = s->avctx->width;\n\n\n\n        while (pixels_left > 0) {\n\n\n\n            if (keyframe || ((mb_change_byte & mb_change_byte_mask) == 0)) {\n\n\n\n                switch (y & 3) {\n\n                case 0:\n\n                    /* if macroblock width is 2, apply C-Y-C-Y; else\n\n                     * apply C-Y-Y */\n\n                    if (s->block_width == 2) {\n\n                        APPLY_C_PREDICTOR();\n\n                        APPLY_Y_PREDICTOR();\n\n                        OUTPUT_PIXEL_PAIR();\n\n                        APPLY_C_PREDICTOR();\n\n                        APPLY_Y_PREDICTOR();\n\n                        OUTPUT_PIXEL_PAIR();\n\n                    } else {\n\n                        APPLY_C_PREDICTOR();\n\n                        APPLY_Y_PREDICTOR();\n\n                        OUTPUT_PIXEL_PAIR();\n\n                        APPLY_Y_PREDICTOR();\n\n                        OUTPUT_PIXEL_PAIR();\n\n                    }\n\n                    break;\n\n\n\n                case 1:\n\n                case 3:\n\n                    /* always apply 2 Y predictors on these iterations */\n\n                    APPLY_Y_PREDICTOR();\n\n                    OUTPUT_PIXEL_PAIR();\n\n                    APPLY_Y_PREDICTOR();\n\n                    OUTPUT_PIXEL_PAIR();\n\n                    break;\n\n\n\n                case 2:\n\n                    /* this iteration might be C-Y-C-Y, Y-Y, or C-Y-Y\n\n                     * depending on the macroblock type */\n\n                    if (s->block_type == BLOCK_2x2) {\n\n                        APPLY_C_PREDICTOR();\n\n                        APPLY_Y_PREDICTOR();\n\n                        OUTPUT_PIXEL_PAIR();\n\n                        APPLY_C_PREDICTOR();\n\n                        APPLY_Y_PREDICTOR();\n\n                        OUTPUT_PIXEL_PAIR();\n\n                    } else if (s->block_type == BLOCK_4x2) {\n\n                        APPLY_C_PREDICTOR();\n\n                        APPLY_Y_PREDICTOR();\n\n                        OUTPUT_PIXEL_PAIR();\n\n                        APPLY_Y_PREDICTOR();\n\n                        OUTPUT_PIXEL_PAIR();\n\n                    } else {\n\n                        APPLY_Y_PREDICTOR();\n\n                        OUTPUT_PIXEL_PAIR();\n\n                        APPLY_Y_PREDICTOR();\n\n                        OUTPUT_PIXEL_PAIR();\n\n                    }\n\n                    break;\n\n                }\n\n\n\n            } else {\n\n\n\n                /* skip (copy) four pixels, but reassign the horizontal\n\n                 * predictor */\n\n                *vert_pred++ = *current_pixel_pair++;\n\n                horiz_pred = *current_pixel_pair - *vert_pred;\n\n                *vert_pred++ = *current_pixel_pair++;\n\n\n\n            }\n\n\n\n            if (!keyframe) {\n\n                mb_change_byte_mask <<= 1;\n\n\n\n                /* next byte */\n\n                if (!mb_change_byte_mask) {\n\n                    mb_change_byte = mb_change_bits[mb_change_index++];\n\n                    mb_change_byte_mask = 0x01;\n\n                }\n\n            }\n\n\n\n            pixels_left -= 4;\n\n        }\n\n\n\n        /* next change row */\n\n        if (((y + 1) & 3) == 0)\n\n            mb_change_bits += s->mb_change_bits_row_size;\n\n\n\n        current_line += s->frame->linesize[0];\n\n    }\n\n}\n", "idx": 26475}
{"project": "FFmpeg", "commit_id": "6f1a5e8d6b7e085171a49b8ce6a371a7c9643764", "target": 0, "func": "av_cold void dsputil_init(DSPContext* c, AVCodecContext *avctx)\n\n{\n\n    int i;\n\n\n\n    ff_check_alignment();\n\n\n\n#if CONFIG_ENCODERS\n\n    if (avctx->bits_per_raw_sample == 10) {\n\n        c->fdct    = ff_jpeg_fdct_islow_10;\n\n        c->fdct248 = ff_fdct248_islow_10;\n\n    } else {\n\n        if(avctx->dct_algo==FF_DCT_FASTINT) {\n\n            c->fdct    = fdct_ifast;\n\n            c->fdct248 = fdct_ifast248;\n\n        }\n\n        else if(avctx->dct_algo==FF_DCT_FAAN) {\n\n            c->fdct    = ff_faandct;\n\n            c->fdct248 = ff_faandct248;\n\n        }\n\n        else {\n\n            c->fdct    = ff_jpeg_fdct_islow_8; //slow/accurate/default\n\n            c->fdct248 = ff_fdct248_islow_8;\n\n        }\n\n    }\n\n#endif //CONFIG_ENCODERS\n\n\n\n    if(avctx->lowres==1){\n\n        c->idct_put= ff_jref_idct4_put;\n\n        c->idct_add= ff_jref_idct4_add;\n\n        c->idct    = j_rev_dct4;\n\n        c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n    }else if(avctx->lowres==2){\n\n        c->idct_put= ff_jref_idct2_put;\n\n        c->idct_add= ff_jref_idct2_add;\n\n        c->idct    = j_rev_dct2;\n\n        c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n    }else if(avctx->lowres==3){\n\n        c->idct_put= ff_jref_idct1_put;\n\n        c->idct_add= ff_jref_idct1_add;\n\n        c->idct    = j_rev_dct1;\n\n        c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n    }else{\n\n        if (avctx->bits_per_raw_sample == 10) {\n\n            c->idct_put              = ff_simple_idct_put_10;\n\n            c->idct_add              = ff_simple_idct_add_10;\n\n            c->idct                  = ff_simple_idct_10;\n\n            c->idct_permutation_type = FF_NO_IDCT_PERM;\n\n        } else {\n\n        if(avctx->idct_algo==FF_IDCT_INT){\n\n            c->idct_put= ff_jref_idct_put;\n\n            c->idct_add= ff_jref_idct_add;\n\n            c->idct    = j_rev_dct;\n\n            c->idct_permutation_type= FF_LIBMPEG2_IDCT_PERM;\n\n        }else if((CONFIG_VP3_DECODER || CONFIG_VP5_DECODER || CONFIG_VP6_DECODER ) &&\n\n                avctx->idct_algo==FF_IDCT_VP3){\n\n            c->idct_put= ff_vp3_idct_put_c;\n\n            c->idct_add= ff_vp3_idct_add_c;\n\n            c->idct    = ff_vp3_idct_c;\n\n            c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n        }else if(avctx->idct_algo==FF_IDCT_WMV2){\n\n            c->idct_put= ff_wmv2_idct_put_c;\n\n            c->idct_add= ff_wmv2_idct_add_c;\n\n            c->idct    = ff_wmv2_idct_c;\n\n            c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n        }else if(avctx->idct_algo==FF_IDCT_FAAN){\n\n            c->idct_put= ff_faanidct_put;\n\n            c->idct_add= ff_faanidct_add;\n\n            c->idct    = ff_faanidct;\n\n            c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n        }else if(CONFIG_EATGQ_DECODER && avctx->idct_algo==FF_IDCT_EA) {\n\n            c->idct_put= ff_ea_idct_put_c;\n\n            c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n        }else{ //accurate/default\n\n            c->idct_put = ff_simple_idct_put_8;\n\n            c->idct_add = ff_simple_idct_add_8;\n\n            c->idct     = ff_simple_idct_8;\n\n            c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n        }\n\n        }\n\n    }\n\n\n\n    c->diff_pixels = diff_pixels_c;\n\n    c->put_pixels_clamped = ff_put_pixels_clamped_c;\n\n    c->put_signed_pixels_clamped = ff_put_signed_pixels_clamped_c;\n\n    c->add_pixels_clamped = ff_add_pixels_clamped_c;\n\n    c->sum_abs_dctelem = sum_abs_dctelem_c;\n\n    c->gmc1 = gmc1_c;\n\n    c->gmc = ff_gmc_c;\n\n    c->pix_sum = pix_sum_c;\n\n    c->pix_norm1 = pix_norm1_c;\n\n\n\n    c->fill_block_tab[0] = fill_block16_c;\n\n    c->fill_block_tab[1] = fill_block8_c;\n\n\n\n    /* TODO [0] 16  [1] 8 */\n\n    c->pix_abs[0][0] = pix_abs16_c;\n\n    c->pix_abs[0][1] = pix_abs16_x2_c;\n\n    c->pix_abs[0][2] = pix_abs16_y2_c;\n\n    c->pix_abs[0][3] = pix_abs16_xy2_c;\n\n    c->pix_abs[1][0] = pix_abs8_c;\n\n    c->pix_abs[1][1] = pix_abs8_x2_c;\n\n    c->pix_abs[1][2] = pix_abs8_y2_c;\n\n    c->pix_abs[1][3] = pix_abs8_xy2_c;\n\n\n\n    c->put_tpel_pixels_tab[ 0] = put_tpel_pixels_mc00_c;\n\n    c->put_tpel_pixels_tab[ 1] = put_tpel_pixels_mc10_c;\n\n    c->put_tpel_pixels_tab[ 2] = put_tpel_pixels_mc20_c;\n\n    c->put_tpel_pixels_tab[ 4] = put_tpel_pixels_mc01_c;\n\n    c->put_tpel_pixels_tab[ 5] = put_tpel_pixels_mc11_c;\n\n    c->put_tpel_pixels_tab[ 6] = put_tpel_pixels_mc21_c;\n\n    c->put_tpel_pixels_tab[ 8] = put_tpel_pixels_mc02_c;\n\n    c->put_tpel_pixels_tab[ 9] = put_tpel_pixels_mc12_c;\n\n    c->put_tpel_pixels_tab[10] = put_tpel_pixels_mc22_c;\n\n\n\n    c->avg_tpel_pixels_tab[ 0] = avg_tpel_pixels_mc00_c;\n\n    c->avg_tpel_pixels_tab[ 1] = avg_tpel_pixels_mc10_c;\n\n    c->avg_tpel_pixels_tab[ 2] = avg_tpel_pixels_mc20_c;\n\n    c->avg_tpel_pixels_tab[ 4] = avg_tpel_pixels_mc01_c;\n\n    c->avg_tpel_pixels_tab[ 5] = avg_tpel_pixels_mc11_c;\n\n    c->avg_tpel_pixels_tab[ 6] = avg_tpel_pixels_mc21_c;\n\n    c->avg_tpel_pixels_tab[ 8] = avg_tpel_pixels_mc02_c;\n\n    c->avg_tpel_pixels_tab[ 9] = avg_tpel_pixels_mc12_c;\n\n    c->avg_tpel_pixels_tab[10] = avg_tpel_pixels_mc22_c;\n\n\n\n#define dspfunc(PFX, IDX, NUM) \\\n\n    c->PFX ## _pixels_tab[IDX][ 0] = PFX ## NUM ## _mc00_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 1] = PFX ## NUM ## _mc10_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 2] = PFX ## NUM ## _mc20_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 3] = PFX ## NUM ## _mc30_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 4] = PFX ## NUM ## _mc01_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 5] = PFX ## NUM ## _mc11_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 6] = PFX ## NUM ## _mc21_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 7] = PFX ## NUM ## _mc31_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 8] = PFX ## NUM ## _mc02_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 9] = PFX ## NUM ## _mc12_c; \\\n\n    c->PFX ## _pixels_tab[IDX][10] = PFX ## NUM ## _mc22_c; \\\n\n    c->PFX ## _pixels_tab[IDX][11] = PFX ## NUM ## _mc32_c; \\\n\n    c->PFX ## _pixels_tab[IDX][12] = PFX ## NUM ## _mc03_c; \\\n\n    c->PFX ## _pixels_tab[IDX][13] = PFX ## NUM ## _mc13_c; \\\n\n    c->PFX ## _pixels_tab[IDX][14] = PFX ## NUM ## _mc23_c; \\\n\n    c->PFX ## _pixels_tab[IDX][15] = PFX ## NUM ## _mc33_c\n\n\n\n    dspfunc(put_qpel, 0, 16);\n\n    dspfunc(put_no_rnd_qpel, 0, 16);\n\n\n\n    dspfunc(avg_qpel, 0, 16);\n\n    /* dspfunc(avg_no_rnd_qpel, 0, 16); */\n\n\n\n    dspfunc(put_qpel, 1, 8);\n\n    dspfunc(put_no_rnd_qpel, 1, 8);\n\n\n\n    dspfunc(avg_qpel, 1, 8);\n\n    /* dspfunc(avg_no_rnd_qpel, 1, 8); */\n\n\n\n#undef dspfunc\n\n\n\n#if CONFIG_MLP_DECODER || CONFIG_TRUEHD_DECODER\n\n    ff_mlp_init(c, avctx);\n\n#endif\n\n#if CONFIG_WMV2_DECODER || CONFIG_VC1_DECODER\n\n    ff_intrax8dsp_init(c,avctx);\n\n#endif\n\n\n\n    c->put_mspel_pixels_tab[0]= ff_put_pixels8x8_c;\n\n    c->put_mspel_pixels_tab[1]= put_mspel8_mc10_c;\n\n    c->put_mspel_pixels_tab[2]= put_mspel8_mc20_c;\n\n    c->put_mspel_pixels_tab[3]= put_mspel8_mc30_c;\n\n    c->put_mspel_pixels_tab[4]= put_mspel8_mc02_c;\n\n    c->put_mspel_pixels_tab[5]= put_mspel8_mc12_c;\n\n    c->put_mspel_pixels_tab[6]= put_mspel8_mc22_c;\n\n    c->put_mspel_pixels_tab[7]= put_mspel8_mc32_c;\n\n\n\n#define SET_CMP_FUNC(name) \\\n\n    c->name[0]= name ## 16_c;\\\n\n    c->name[1]= name ## 8x8_c;\n\n\n\n    SET_CMP_FUNC(hadamard8_diff)\n\n    c->hadamard8_diff[4]= hadamard8_intra16_c;\n\n    c->hadamard8_diff[5]= hadamard8_intra8x8_c;\n\n    SET_CMP_FUNC(dct_sad)\n\n    SET_CMP_FUNC(dct_max)\n\n#if CONFIG_GPL\n\n    SET_CMP_FUNC(dct264_sad)\n\n#endif\n\n    c->sad[0]= pix_abs16_c;\n\n    c->sad[1]= pix_abs8_c;\n\n    c->sse[0]= sse16_c;\n\n    c->sse[1]= sse8_c;\n\n    c->sse[2]= sse4_c;\n\n    SET_CMP_FUNC(quant_psnr)\n\n    SET_CMP_FUNC(rd)\n\n    SET_CMP_FUNC(bit)\n\n    c->vsad[0]= vsad16_c;\n\n    c->vsad[4]= vsad_intra16_c;\n\n    c->vsad[5]= vsad_intra8_c;\n\n    c->vsse[0]= vsse16_c;\n\n    c->vsse[4]= vsse_intra16_c;\n\n    c->vsse[5]= vsse_intra8_c;\n\n    c->nsse[0]= nsse16_c;\n\n    c->nsse[1]= nsse8_c;\n\n#if CONFIG_DWT\n\n    ff_dsputil_init_dwt(c);\n\n#endif\n\n\n\n    c->ssd_int8_vs_int16 = ssd_int8_vs_int16_c;\n\n\n\n    c->add_bytes= add_bytes_c;\n\n    c->diff_bytes= diff_bytes_c;\n\n    c->add_hfyu_median_prediction= add_hfyu_median_prediction_c;\n\n    c->sub_hfyu_median_prediction= sub_hfyu_median_prediction_c;\n\n    c->add_hfyu_left_prediction  = add_hfyu_left_prediction_c;\n\n    c->add_hfyu_left_prediction_bgr32 = add_hfyu_left_prediction_bgr32_c;\n\n    c->bswap_buf= bswap_buf;\n\n    c->bswap16_buf = bswap16_buf;\n\n\n\n    if (CONFIG_H263_DECODER || CONFIG_H263_ENCODER) {\n\n        c->h263_h_loop_filter= h263_h_loop_filter_c;\n\n        c->h263_v_loop_filter= h263_v_loop_filter_c;\n\n    }\n\n\n\n    if (CONFIG_VP3_DECODER) {\n\n        c->vp3_h_loop_filter= ff_vp3_h_loop_filter_c;\n\n        c->vp3_v_loop_filter= ff_vp3_v_loop_filter_c;\n\n        c->vp3_idct_dc_add= ff_vp3_idct_dc_add_c;\n\n    }\n\n\n\n    c->h261_loop_filter= h261_loop_filter_c;\n\n\n\n    c->try_8x8basis= try_8x8basis_c;\n\n    c->add_8x8basis= add_8x8basis_c;\n\n\n\n#if CONFIG_VORBIS_DECODER\n\n    c->vorbis_inverse_coupling = vorbis_inverse_coupling;\n\n#endif\n\n#if CONFIG_AC3_DECODER\n\n    c->ac3_downmix = ff_ac3_downmix_c;\n\n#endif\n\n    c->vector_fmul = vector_fmul_c;\n\n    c->vector_fmul_reverse = vector_fmul_reverse_c;\n\n    c->vector_fmul_add = vector_fmul_add_c;\n\n    c->vector_fmul_window = vector_fmul_window_c;\n\n    c->vector_clipf = vector_clipf_c;\n\n    c->scalarproduct_int16 = scalarproduct_int16_c;\n\n    c->scalarproduct_and_madd_int16 = scalarproduct_and_madd_int16_c;\n\n    c->apply_window_int16 = apply_window_int16_c;\n\n    c->vector_clip_int32 = vector_clip_int32_c;\n\n    c->scalarproduct_float = scalarproduct_float_c;\n\n    c->butterflies_float = butterflies_float_c;\n\n    c->butterflies_float_interleave = butterflies_float_interleave_c;\n\n    c->vector_fmul_scalar = vector_fmul_scalar_c;\n\n    c->vector_fmac_scalar = vector_fmac_scalar_c;\n\n\n\n    c->shrink[0]= av_image_copy_plane;\n\n    c->shrink[1]= ff_shrink22;\n\n    c->shrink[2]= ff_shrink44;\n\n    c->shrink[3]= ff_shrink88;\n\n\n\n    c->prefetch= just_return;\n\n\n\n    memset(c->put_2tap_qpel_pixels_tab, 0, sizeof(c->put_2tap_qpel_pixels_tab));\n\n    memset(c->avg_2tap_qpel_pixels_tab, 0, sizeof(c->avg_2tap_qpel_pixels_tab));\n\n\n\n#undef FUNC\n\n#undef FUNCC\n\n#define FUNC(f, depth) f ## _ ## depth\n\n#define FUNCC(f, depth) f ## _ ## depth ## _c\n\n\n\n#define dspfunc1(PFX, IDX, NUM, depth)\\\n\n    c->PFX ## _pixels_tab[IDX][0] = FUNCC(PFX ## _pixels ## NUM        , depth);\\\n\n    c->PFX ## _pixels_tab[IDX][1] = FUNCC(PFX ## _pixels ## NUM ## _x2 , depth);\\\n\n    c->PFX ## _pixels_tab[IDX][2] = FUNCC(PFX ## _pixels ## NUM ## _y2 , depth);\\\n\n    c->PFX ## _pixels_tab[IDX][3] = FUNCC(PFX ## _pixels ## NUM ## _xy2, depth)\n\n\n\n#define dspfunc2(PFX, IDX, NUM, depth)\\\n\n    c->PFX ## _pixels_tab[IDX][ 0] = FUNCC(PFX ## NUM ## _mc00, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 1] = FUNCC(PFX ## NUM ## _mc10, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 2] = FUNCC(PFX ## NUM ## _mc20, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 3] = FUNCC(PFX ## NUM ## _mc30, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 4] = FUNCC(PFX ## NUM ## _mc01, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 5] = FUNCC(PFX ## NUM ## _mc11, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 6] = FUNCC(PFX ## NUM ## _mc21, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 7] = FUNCC(PFX ## NUM ## _mc31, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 8] = FUNCC(PFX ## NUM ## _mc02, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 9] = FUNCC(PFX ## NUM ## _mc12, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][10] = FUNCC(PFX ## NUM ## _mc22, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][11] = FUNCC(PFX ## NUM ## _mc32, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][12] = FUNCC(PFX ## NUM ## _mc03, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][13] = FUNCC(PFX ## NUM ## _mc13, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][14] = FUNCC(PFX ## NUM ## _mc23, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][15] = FUNCC(PFX ## NUM ## _mc33, depth)\n\n\n\n\n\n#define BIT_DEPTH_FUNCS(depth, dct)\\\n\n    c->get_pixels                    = FUNCC(get_pixels   ## dct   , depth);\\\n\n    c->draw_edges                    = FUNCC(draw_edges            , depth);\\\n\n    c->emulated_edge_mc              = FUNC (ff_emulated_edge_mc   , depth);\\\n\n    c->clear_block                   = FUNCC(clear_block  ## dct   , depth);\\\n\n    c->clear_blocks                  = FUNCC(clear_blocks ## dct   , depth);\\\n\n    c->add_pixels8                   = FUNCC(add_pixels8  ## dct   , depth);\\\n\n    c->add_pixels4                   = FUNCC(add_pixels4  ## dct   , depth);\\\n\n    c->put_no_rnd_pixels_l2[0]       = FUNCC(put_no_rnd_pixels16_l2, depth);\\\n\n    c->put_no_rnd_pixels_l2[1]       = FUNCC(put_no_rnd_pixels8_l2 , depth);\\\n\n\\\n\n    c->put_h264_chroma_pixels_tab[0] = FUNCC(put_h264_chroma_mc8   , depth);\\\n\n    c->put_h264_chroma_pixels_tab[1] = FUNCC(put_h264_chroma_mc4   , depth);\\\n\n    c->put_h264_chroma_pixels_tab[2] = FUNCC(put_h264_chroma_mc2   , depth);\\\n\n    c->avg_h264_chroma_pixels_tab[0] = FUNCC(avg_h264_chroma_mc8   , depth);\\\n\n    c->avg_h264_chroma_pixels_tab[1] = FUNCC(avg_h264_chroma_mc4   , depth);\\\n\n    c->avg_h264_chroma_pixels_tab[2] = FUNCC(avg_h264_chroma_mc2   , depth);\\\n\n\\\n\n    dspfunc1(put       , 0, 16, depth);\\\n\n    dspfunc1(put       , 1,  8, depth);\\\n\n    dspfunc1(put       , 2,  4, depth);\\\n\n    dspfunc1(put       , 3,  2, depth);\\\n\n    dspfunc1(put_no_rnd, 0, 16, depth);\\\n\n    dspfunc1(put_no_rnd, 1,  8, depth);\\\n\n    dspfunc1(avg       , 0, 16, depth);\\\n\n    dspfunc1(avg       , 1,  8, depth);\\\n\n    dspfunc1(avg       , 2,  4, depth);\\\n\n    dspfunc1(avg       , 3,  2, depth);\\\n\n    dspfunc1(avg_no_rnd, 0, 16, depth);\\\n\n    dspfunc1(avg_no_rnd, 1,  8, depth);\\\n\n\\\n\n    dspfunc2(put_h264_qpel, 0, 16, depth);\\\n\n    dspfunc2(put_h264_qpel, 1,  8, depth);\\\n\n    dspfunc2(put_h264_qpel, 2,  4, depth);\\\n\n    dspfunc2(put_h264_qpel, 3,  2, depth);\\\n\n    dspfunc2(avg_h264_qpel, 0, 16, depth);\\\n\n    dspfunc2(avg_h264_qpel, 1,  8, depth);\\\n\n    dspfunc2(avg_h264_qpel, 2,  4, depth);\n\n\n\n    switch (avctx->bits_per_raw_sample) {\n\n    case 9:\n\n        if (c->dct_bits == 32) {\n\n            BIT_DEPTH_FUNCS(9, _32);\n\n        } else {\n\n            BIT_DEPTH_FUNCS(9, _16);\n\n        }\n\n        break;\n\n    case 10:\n\n        if (c->dct_bits == 32) {\n\n            BIT_DEPTH_FUNCS(10, _32);\n\n        } else {\n\n            BIT_DEPTH_FUNCS(10, _16);\n\n        }\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_DEBUG, \"Unsupported bit depth: %d\\n\", avctx->bits_per_raw_sample);\n\n    case 8:\n\n        BIT_DEPTH_FUNCS(8, _16);\n\n        break;\n\n    }\n\n\n\n\n\n    if (HAVE_MMX)        dsputil_init_mmx   (c, avctx);\n\n    if (ARCH_ARM)        dsputil_init_arm   (c, avctx);\n\n    if (CONFIG_MLIB)     dsputil_init_mlib  (c, avctx);\n\n    if (HAVE_VIS)        dsputil_init_vis   (c, avctx);\n\n    if (ARCH_ALPHA)      dsputil_init_alpha (c, avctx);\n\n    if (ARCH_PPC)        dsputil_init_ppc   (c, avctx);\n\n    if (HAVE_MMI)        dsputil_init_mmi   (c, avctx);\n\n    if (ARCH_SH4)        dsputil_init_sh4   (c, avctx);\n\n    if (ARCH_BFIN)       dsputil_init_bfin  (c, avctx);\n\n\n\n    for(i=0; i<64; i++){\n\n        if(!c->put_2tap_qpel_pixels_tab[0][i])\n\n            c->put_2tap_qpel_pixels_tab[0][i]= c->put_h264_qpel_pixels_tab[0][i];\n\n        if(!c->avg_2tap_qpel_pixels_tab[0][i])\n\n            c->avg_2tap_qpel_pixels_tab[0][i]= c->avg_h264_qpel_pixels_tab[0][i];\n\n    }\n\n\n\n    ff_init_scantable_permutation(c->idct_permutation,\n\n                                  c->idct_permutation_type);\n\n}\n", "idx": 26476}
{"project": "FFmpeg", "commit_id": "86ab6b6e08e2982fb5785e0691c0a7e289339ffb", "target": 0, "func": "static void decode(GetByteContext *gb, RangeCoder *rc, unsigned cumFreq, unsigned freq, unsigned total_freq)\n\n{\n\n    rc->code -= cumFreq * rc->range;\n\n    rc->range *= freq;\n\n\n\n    while (rc->range < TOP && bytestream2_get_bytes_left(gb) > 0) {\n\n        unsigned byte = bytestream2_get_byte(gb);\n\n        rc->code = (rc->code << 8) | byte;\n\n        rc->range <<= 8;\n\n    }\n\n}\n", "idx": 26477}
{"project": "FFmpeg", "commit_id": "343e2833994655c252d5236a3394bf6db7a4d8b1", "target": 0, "func": "int ff_thread_get_buffer(AVCodecContext *avctx, ThreadFrame *f, int flags)\n\n{\n\n    PerThreadContext *p = avctx->internal->thread_ctx;\n\n    int err;\n\n\n\n    f->owner = avctx;\n\n\n\n    if (!(avctx->active_thread_type & FF_THREAD_FRAME))\n\n        return ff_get_buffer(avctx, f->f, flags);\n\n\n\n    if (atomic_load(&p->state) != STATE_SETTING_UP &&\n\n        (avctx->codec->update_thread_context || !avctx->thread_safe_callbacks)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() cannot be called after ff_thread_finish_setup()\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (avctx->internal->allocate_progress) {\n\n        atomic_int *progress;\n\n        f->progress = av_buffer_alloc(2 * sizeof(*progress));\n\n        if (!f->progress) {\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        progress = (atomic_int*)f->progress->data;\n\n\n\n        atomic_store(&progress[0], -1);\n\n        atomic_store(&progress[1], -1);\n\n    }\n\n\n\n    pthread_mutex_lock(&p->parent->buffer_mutex);\n\n    if (avctx->thread_safe_callbacks ||\n\n        avctx->get_buffer2 == avcodec_default_get_buffer2) {\n\n        err = ff_get_buffer(avctx, f->f, flags);\n\n    } else {\n\n        p->requested_frame = f->f;\n\n        p->requested_flags = flags;\n\n        atomic_store_explicit(&p->state, STATE_GET_BUFFER, memory_order_release);\n\n        pthread_mutex_lock(&p->progress_mutex);\n\n        pthread_cond_signal(&p->progress_cond);\n\n\n\n        while (atomic_load(&p->state) != STATE_SETTING_UP)\n\n            pthread_cond_wait(&p->progress_cond, &p->progress_mutex);\n\n\n\n        err = p->result;\n\n\n\n        pthread_mutex_unlock(&p->progress_mutex);\n\n\n\n    }\n\n    if (!avctx->thread_safe_callbacks && !avctx->codec->update_thread_context)\n\n        ff_thread_finish_setup(avctx);\n\n\n\n    if (err)\n\n        av_buffer_unref(&f->progress);\n\n\n\n    pthread_mutex_unlock(&p->parent->buffer_mutex);\n\n\n\n    return err;\n\n}\n", "idx": 26478}
{"project": "FFmpeg", "commit_id": "2f9ca64556cba9a7edcca9a1c55923a60022937d", "target": 0, "func": "static int open_url(AVFormatContext *s, AVIOContext **pb, const char *url,\n\n                    AVDictionary *opts, AVDictionary *opts2, int *is_http)\n\n{\n\n    HLSContext *c = s->priv_data;\n\n    AVDictionary *tmp = NULL;\n\n    const char *proto_name = NULL;\n\n    int ret;\n\n\n\n    av_dict_copy(&tmp, opts, 0);\n\n    av_dict_copy(&tmp, opts2, 0);\n\n\n\n    if (av_strstart(url, \"crypto\", NULL)) {\n\n        if (url[6] == '+' || url[6] == ':')\n\n            proto_name = avio_find_protocol_name(url + 7);\n\n    }\n\n\n\n    if (!proto_name)\n\n        proto_name = avio_find_protocol_name(url);\n\n\n\n    if (!proto_name)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    // only http(s) & file are allowed\n\n    if (av_strstart(proto_name, \"file\", NULL)) {\n\n        if (strcmp(c->allowed_extensions, \"ALL\") && !av_match_ext(url, c->allowed_extensions)) {\n\n            av_log(s, AV_LOG_ERROR,\n\n                \"Filename extension of \\'%s\\' is not a common multimedia extension, blocked for security reasons.\\n\"\n\n                \"If you wish to override this adjust allowed_extensions, you can set it to \\'ALL\\' to allow all\\n\",\n\n                url);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    } else if (av_strstart(proto_name, \"http\", NULL)) {\n\n        ;\n\n    } else\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (!strncmp(proto_name, url, strlen(proto_name)) && url[strlen(proto_name)] == ':')\n\n        ;\n\n    else if (av_strstart(url, \"crypto\", NULL) && !strncmp(proto_name, url + 7, strlen(proto_name)) && url[7 + strlen(proto_name)] == ':')\n\n        ;\n\n    else if (strcmp(proto_name, \"file\") || !strncmp(url, \"file,\", 5))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (c->http_persistent && *pb && av_strstart(proto_name, \"http\", NULL)) {\n\n        ret = open_url_keepalive(c->ctx, pb, url);\n\n        if (ret == AVERROR_EXIT) {\n\n            return ret;\n\n        } else if (ret < 0) {\n\n            if (ret != AVERROR_EOF)\n\n                av_log(s, AV_LOG_WARNING,\n\n                    \"keepalive request failed for '%s', retrying with new connection: %s\\n\",\n\n                    url, av_err2str(ret));\n\n            ret = s->io_open(s, pb, url, AVIO_FLAG_READ, &tmp);\n\n        }\n\n    } else {\n\n        ret = s->io_open(s, pb, url, AVIO_FLAG_READ, &tmp);\n\n    }\n\n    if (ret >= 0) {\n\n        // update cookies on http response with setcookies.\n\n        char *new_cookies = NULL;\n\n\n\n        if (!(s->flags & AVFMT_FLAG_CUSTOM_IO))\n\n            av_opt_get(*pb, \"cookies\", AV_OPT_SEARCH_CHILDREN, (uint8_t**)&new_cookies);\n\n\n\n        if (new_cookies) {\n\n            av_free(c->cookies);\n\n            c->cookies = new_cookies;\n\n        }\n\n\n\n        av_dict_set(&opts, \"cookies\", c->cookies, 0);\n\n    }\n\n\n\n    av_dict_free(&tmp);\n\n\n\n    if (is_http)\n\n        *is_http = av_strstart(proto_name, \"http\", NULL);\n\n\n\n    return ret;\n\n}\n", "idx": 26481}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(rgb15tobgr24)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n    const uint16_t *end;\n\n#if COMPILE_TEMPLATE_MMX\n\n    const uint16_t *mm_end;\n\n#endif\n\n    uint8_t *d = dst;\n\n    const uint16_t *s = (const uint16_t*)src;\n\n    end = s + src_size/2;\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*s):\"memory\");\n\n    mm_end = end - 7;\n\n    while (s < mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"    32%1           \\n\\t\"\n\n            \"movq          %1, %%mm0    \\n\\t\"\n\n            \"movq          %1, %%mm1    \\n\\t\"\n\n            \"movq          %1, %%mm2    \\n\\t\"\n\n            \"pand          %2, %%mm0    \\n\\t\"\n\n            \"pand          %3, %%mm1    \\n\\t\"\n\n            \"pand          %4, %%mm2    \\n\\t\"\n\n            \"psllq         $3, %%mm0    \\n\\t\"\n\n            \"psrlq         $2, %%mm1    \\n\\t\"\n\n            \"psrlq         $7, %%mm2    \\n\\t\"\n\n            \"movq       %%mm0, %%mm3    \\n\\t\"\n\n            \"movq       %%mm1, %%mm4    \\n\\t\"\n\n            \"movq       %%mm2, %%mm5    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm0    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm1    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm2    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm3    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm4    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm5    \\n\\t\"\n\n            \"psllq         $8, %%mm1    \\n\\t\"\n\n            \"psllq        $16, %%mm2    \\n\\t\"\n\n            \"por        %%mm1, %%mm0    \\n\\t\"\n\n            \"por        %%mm2, %%mm0    \\n\\t\"\n\n            \"psllq         $8, %%mm4    \\n\\t\"\n\n            \"psllq        $16, %%mm5    \\n\\t\"\n\n            \"por        %%mm4, %%mm3    \\n\\t\"\n\n            \"por        %%mm5, %%mm3    \\n\\t\"\n\n\n\n            \"movq       %%mm0, %%mm6    \\n\\t\"\n\n            \"movq       %%mm3, %%mm7    \\n\\t\"\n\n\n\n            \"movq         8%1, %%mm0    \\n\\t\"\n\n            \"movq         8%1, %%mm1    \\n\\t\"\n\n            \"movq         8%1, %%mm2    \\n\\t\"\n\n            \"pand          %2, %%mm0    \\n\\t\"\n\n            \"pand          %3, %%mm1    \\n\\t\"\n\n            \"pand          %4, %%mm2    \\n\\t\"\n\n            \"psllq         $3, %%mm0    \\n\\t\"\n\n            \"psrlq         $2, %%mm1    \\n\\t\"\n\n            \"psrlq         $7, %%mm2    \\n\\t\"\n\n            \"movq       %%mm0, %%mm3    \\n\\t\"\n\n            \"movq       %%mm1, %%mm4    \\n\\t\"\n\n            \"movq       %%mm2, %%mm5    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm0    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm1    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm2    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm3    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm4    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm5    \\n\\t\"\n\n            \"psllq         $8, %%mm1    \\n\\t\"\n\n            \"psllq        $16, %%mm2    \\n\\t\"\n\n            \"por        %%mm1, %%mm0    \\n\\t\"\n\n            \"por        %%mm2, %%mm0    \\n\\t\"\n\n            \"psllq         $8, %%mm4    \\n\\t\"\n\n            \"psllq        $16, %%mm5    \\n\\t\"\n\n            \"por        %%mm4, %%mm3    \\n\\t\"\n\n            \"por        %%mm5, %%mm3    \\n\\t\"\n\n\n\n            :\"=m\"(*d)\n\n            :\"m\"(*s),\"m\"(mask15b),\"m\"(mask15g),\"m\"(mask15r), \"m\"(mmx_null)\n\n            :\"memory\");\n\n        /* borrowed 32 to 24 */\n\n        __asm__ volatile(\n\n            \"movq       %%mm0, %%mm4    \\n\\t\"\n\n            \"movq       %%mm3, %%mm5    \\n\\t\"\n\n            \"movq       %%mm6, %%mm0    \\n\\t\"\n\n            \"movq       %%mm7, %%mm1    \\n\\t\"\n\n\n\n            \"movq       %%mm4, %%mm6    \\n\\t\"\n\n            \"movq       %%mm5, %%mm7    \\n\\t\"\n\n            \"movq       %%mm0, %%mm2    \\n\\t\"\n\n            \"movq       %%mm1, %%mm3    \\n\\t\"\n\n\n\n            STORE_BGR24_MMX\n\n\n\n            :\"=m\"(*d)\n\n            :\"m\"(*s)\n\n            :\"memory\");\n\n        d += 24;\n\n        s += 8;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n#endif\n\n    while (s < end) {\n\n        register uint16_t bgr;\n\n        bgr = *s++;\n\n        *d++ = (bgr&0x1F)<<3;\n\n        *d++ = (bgr&0x3E0)>>2;\n\n        *d++ = (bgr&0x7C00)>>7;\n\n    }\n\n}\n", "idx": 26492}
{"project": "FFmpeg", "commit_id": "1d3a9e63e0dcbcba633d939cdfb79e977259be13", "target": 1, "func": "static int rv10_decode_frame(AVCodecContext *avctx,\n\n                             void *data, int *data_size,\n\n                             AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int i;\n\n    AVFrame *pict = data;\n\n    int slice_count;\n\n    const uint8_t *slices_hdr = NULL;\n\n\n\n    av_dlog(avctx, \"*****frame %d size=%d\\n\", avctx->frame_number, buf_size);\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0) {\n\n        return 0;\n\n    }\n\n\n\n    if(!avctx->slice_count){\n\n        slice_count = (*buf++) + 1;\n\n        slices_hdr = buf + 4;\n\n        buf += 8 * slice_count;\n\n    }else\n\n        slice_count = avctx->slice_count;\n\n\n\n    for(i=0; i<slice_count; i++){\n\n        int offset= get_slice_offset(avctx, slices_hdr, i);\n\n        int size, size2;\n\n\n\n        if(i+1 == slice_count)\n\n            size= buf_size - offset;\n\n        else\n\n            size= get_slice_offset(avctx, slices_hdr, i+1) - offset;\n\n\n\n        if(i+2 >= slice_count)\n\n            size2= buf_size - offset;\n\n        else\n\n            size2= get_slice_offset(avctx, slices_hdr, i+2) - offset;\n\n\n\n        if(rv10_decode_packet(avctx, buf+offset, size, size2) > 8*size)\n\n            i++;\n\n    }\n\n\n\n    if(s->current_picture_ptr != NULL && s->mb_y>=s->mb_height){\n\n        ff_er_frame_end(s);\n\n        MPV_frame_end(s);\n\n\n\n        if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n\n            *pict= *(AVFrame*)s->current_picture_ptr;\n\n        } else if (s->last_picture_ptr != NULL) {\n\n            *pict= *(AVFrame*)s->last_picture_ptr;\n\n        }\n\n\n\n        if(s->last_picture_ptr || s->low_delay){\n\n            *data_size = sizeof(AVFrame);\n\n            ff_print_debug_info(s, pict);\n\n        }\n\n        s->current_picture_ptr= NULL; //so we can detect if frame_end wasnt called (find some nicer solution...)\n\n    }\n\n\n\n    return buf_size;\n\n}\n", "idx": 26501}
{"project": "FFmpeg", "commit_id": "30327865f388260e49d40affd1b9c9fc2e20ebfe", "target": 1, "func": "static void output_client_manifest(struct VideoFiles *files,\n\n                                   const char *basename, int split)\n\n{\n\n    char filename[1000];\n\n    FILE *out;\n\n    int i, j;\n\n\n\n    if (split)\n\n        snprintf(filename, sizeof(filename), \"Manifest\");\n\n    else\n\n        snprintf(filename, sizeof(filename), \"%s.ismc\", basename);\n\n    out = fopen(filename, \"w\");\n\n    if (!out) {\n\n        perror(filename);\n\n        return;\n\n    }\n\n    fprintf(out, \"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\\n\");\n\n    fprintf(out, \"<SmoothStreamingMedia MajorVersion=\\\"2\\\" MinorVersion=\\\"0\\\" \"\n\n                 \"Duration=\\\"%\"PRId64 \"\\\">\\n\", files->duration * 10);\n\n    if (files->video_file >= 0) {\n\n        struct VideoFile *vf = files->files[files->video_file];\n\n        int index = 0;\n\n        fprintf(out,\n\n                \"\\t<StreamIndex Type=\\\"video\\\" QualityLevels=\\\"%d\\\" \"\n\n                \"Chunks=\\\"%d\\\" \"\n\n                \"Url=\\\"QualityLevels({bitrate})/Fragments(video={start time})\\\">\\n\",\n\n                files->nb_video_files, vf->chunks);\n\n        for (i = 0; i < files->nb_files; i++) {\n\n            vf = files->files[i];\n\n            if (!vf->is_video)\n\n                continue;\n\n            fprintf(out,\n\n                    \"\\t\\t<QualityLevel Index=\\\"%d\\\" Bitrate=\\\"%d\\\" \"\n\n                    \"FourCC=\\\"%s\\\" MaxWidth=\\\"%d\\\" MaxHeight=\\\"%d\\\" \"\n\n                    \"CodecPrivateData=\\\"\",\n\n                    index, vf->bitrate, vf->fourcc, vf->width, vf->height);\n\n            for (j = 0; j < vf->codec_private_size; j++)\n\n                fprintf(out, \"%02X\", vf->codec_private[j]);\n\n            fprintf(out, \"\\\" />\\n\");\n\n            index++;\n\n        }\n\n        vf = files->files[files->video_file];\n\n        for (i = 0; i < vf->chunks; i++)\n\n            fprintf(out, \"\\t\\t<c n=\\\"%d\\\" d=\\\"%d\\\" />\\n\", i,\n\n                    vf->offsets[i].duration);\n\n        fprintf(out, \"\\t</StreamIndex>\\n\");\n\n    }\n\n    if (files->audio_file >= 0) {\n\n        struct VideoFile *vf = files->files[files->audio_file];\n\n        int index = 0;\n\n        fprintf(out,\n\n                \"\\t<StreamIndex Type=\\\"audio\\\" QualityLevels=\\\"%d\\\" \"\n\n                \"Chunks=\\\"%d\\\" \"\n\n                \"Url=\\\"QualityLevels({bitrate})/Fragments(audio={start time})\\\">\\n\",\n\n                files->nb_audio_files, vf->chunks);\n\n        for (i = 0; i < files->nb_files; i++) {\n\n            vf = files->files[i];\n\n            if (!vf->is_audio)\n\n                continue;\n\n            fprintf(out,\n\n                    \"\\t\\t<QualityLevel Index=\\\"%d\\\" Bitrate=\\\"%d\\\" \"\n\n                    \"FourCC=\\\"%s\\\" SamplingRate=\\\"%d\\\" Channels=\\\"%d\\\" \"\n\n                    \"BitsPerSample=\\\"16\\\" PacketSize=\\\"%d\\\" \"\n\n                    \"AudioTag=\\\"%d\\\" CodecPrivateData=\\\"\",\n\n                    index, vf->bitrate, vf->fourcc, vf->sample_rate,\n\n                    vf->channels, vf->blocksize, vf->tag);\n\n            for (j = 0; j < vf->codec_private_size; j++)\n\n                fprintf(out, \"%02X\", vf->codec_private[j]);\n\n            fprintf(out, \"\\\" />\\n\");\n\n            index++;\n\n        }\n\n        vf = files->files[files->audio_file];\n\n        for (i = 0; i < vf->chunks; i++)\n\n            fprintf(out, \"\\t\\t<c n=\\\"%d\\\" d=\\\"%d\\\" />\\n\",\n\n                    i, vf->offsets[i].duration);\n\n        fprintf(out, \"\\t</StreamIndex>\\n\");\n\n    }\n\n    fprintf(out, \"</SmoothStreamingMedia>\\n\");\n\n    fclose(out);\n\n}\n", "idx": 26502}
{"project": "FFmpeg", "commit_id": "8e28e0721c61cface6496fe4657ff5d3c3d2e6b8", "target": 0, "func": "static int aa_read_header(AVFormatContext *s)\n\n{\n\n    int i, j, idx, largest_idx = -1;\n\n    uint32_t nkey, nval, toc_size, npairs, header_seed, start;\n\n    char key[128], val[128], codec_name[64] = {0};\n\n    uint8_t output[24], dst[8], src[8];\n\n    int64_t largest_size = -1, current_size = -1;\n\n    struct toc_entry {\n\n        uint32_t offset;\n\n        uint32_t size;\n\n    } TOC[MAX_TOC_ENTRIES];\n\n    uint32_t header_key_part[4];\n\n    uint8_t header_key[16];\n\n    AADemuxContext *c = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st;\n\n\n\n    /* parse .aa header */\n\n    avio_skip(pb, 4); // file size\n\n    avio_skip(pb, 4); // magic string\n\n    toc_size = avio_rb32(pb); // TOC size\n\n    avio_skip(pb, 4); // unidentified integer\n\n    if (toc_size > MAX_TOC_ENTRIES)\n\n        return AVERROR_INVALIDDATA;\n\n    for (i = 0; i < toc_size; i++) { // read TOC\n\n        avio_skip(pb, 4); // TOC entry index\n\n        TOC[i].offset = avio_rb32(pb); // block offset\n\n        TOC[i].size = avio_rb32(pb); // block size\n\n    }\n\n    avio_skip(pb, 24); // header termination block (ignored)\n\n    npairs = avio_rb32(pb); // read dictionary entries\n\n    if (npairs > MAX_DICTIONARY_ENTRIES)\n\n        return AVERROR_INVALIDDATA;\n\n    for (i = 0; i < npairs; i++) {\n\n        memset(val, 0, sizeof(val));\n\n        memset(key, 0, sizeof(key));\n\n        avio_skip(pb, 1); // unidentified integer\n\n        nkey = avio_rb32(pb); // key string length\n\n        nval = avio_rb32(pb); // value string length\n\n        if (nkey > sizeof(key)) {\n\n            avio_skip(pb, nkey);\n\n        } else {\n\n            avio_read(pb, key, nkey); // key string\n\n        }\n\n        if (nval > sizeof(val)) {\n\n            avio_skip(pb, nval);\n\n        } else {\n\n            avio_read(pb, val, nval); // value string\n\n        }\n\n        if (!strcmp(key, \"codec\")) {\n\n            av_log(s, AV_LOG_DEBUG, \"Codec is <%s>\\n\", val);\n\n            strncpy(codec_name, val, sizeof(codec_name) - 1);\n\n        }\n\n        if (!strcmp(key, \"HeaderSeed\")) {\n\n            av_log(s, AV_LOG_DEBUG, \"HeaderSeed is <%s>\\n\", val);\n\n            header_seed = atoi(val);\n\n        }\n\n        if (!strcmp(key, \"HeaderKey\")) { // this looks like \"1234567890 1234567890 1234567890 1234567890\"\n\n            av_log(s, AV_LOG_DEBUG, \"HeaderKey is <%s>\\n\", val);\n\n            sscanf(val, \"%u%u%u%u\", &header_key_part[0], &header_key_part[1], &header_key_part[2], &header_key_part[3]);\n\n            for (idx = 0; idx < 4; idx++) {\n\n                AV_WB32(&header_key[idx * 4], header_key_part[idx]); // convert each part to BE!\n\n            }\n\n            av_log(s, AV_LOG_DEBUG, \"Processed HeaderKey is \");\n\n            for (i = 0; i < 16; i++)\n\n                av_log(s, AV_LOG_DEBUG, \"%02x\", header_key[i]);\n\n            av_log(s, AV_LOG_DEBUG, \"\\n\");\n\n        }\n\n    }\n\n\n\n    /* verify fixed key */\n\n    if (c->aa_fixed_key_len != 16) {\n\n        av_log(s, AV_LOG_ERROR, \"aa_fixed_key value needs to be 16 bytes!\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    /* verify codec */\n\n    if ((c->codec_second_size = get_second_size(codec_name)) == -1) {\n\n        av_log(s, AV_LOG_ERROR, \"unknown codec <%s>!\\n\", codec_name);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    /* decryption key derivation */\n\n    c->tea_ctx = av_tea_alloc();\n\n    if (!c->tea_ctx)\n\n        return AVERROR(ENOMEM);\n\n    av_tea_init(c->tea_ctx, c->aa_fixed_key, 16);\n\n    output[0] = output[1] = 0; // purely for padding purposes\n\n    memcpy(output + 2, header_key, 16);\n\n    idx = 0;\n\n    for (i = 0; i < 3; i++) { // TEA CBC with weird mixed endianness\n\n        AV_WB32(src, header_seed);\n\n        AV_WB32(src + 4, header_seed + 1);\n\n        header_seed += 2;\n\n        av_tea_crypt(c->tea_ctx, dst, src, 1, NULL, 0); // TEA ECB encrypt\n\n        for (j = 0; j < TEA_BLOCK_SIZE && idx < 18; j+=1, idx+=1) {\n\n            output[idx] = output[idx] ^ dst[j];\n\n        }\n\n    }\n\n    memcpy(c->file_key, output + 2, 16); // skip first 2 bytes of output\n\n    av_log(s, AV_LOG_DEBUG, \"File key is \");\n\n    for (i = 0; i < 16; i++)\n\n        av_log(s, AV_LOG_DEBUG, \"%02x\", c->file_key[i]);\n\n    av_log(s, AV_LOG_DEBUG, \"\\n\");\n\n\n\n    /* decoder setup */\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st) {\n\n        av_freep(&c->tea_ctx);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n    if (!strcmp(codec_name, \"mp332\")) {\n\n        st->codec->codec_id = AV_CODEC_ID_MP3;\n\n        st->codec->sample_rate = 22050;\n\n        st->need_parsing = AVSTREAM_PARSE_FULL_RAW;\n\n        st->start_time = 0;\n\n    } else if (!strcmp(codec_name, \"acelp85\")) {\n\n        st->codec->codec_id = AV_CODEC_ID_SIPR;\n\n        st->codec->block_align = 19;\n\n        st->codec->channels = 1;\n\n        st->codec->sample_rate = 8500;\n\n    } else if (!strcmp(codec_name, \"acelp16\")) {\n\n        st->codec->codec_id = AV_CODEC_ID_SIPR;\n\n        st->codec->block_align = 20;\n\n        st->codec->channels = 1;\n\n        st->codec->sample_rate = 16000;\n\n    }\n\n\n\n    /* determine, and jump to audio start offset */\n\n    for (i = 1; i < toc_size; i++) { // skip the first entry!\n\n        current_size = TOC[i].size;\n\n        if (current_size > largest_size) {\n\n            largest_idx = i;\n\n            largest_size = current_size;\n\n        }\n\n    }\n\n    start = TOC[largest_idx].offset;\n\n    avio_seek(pb, start, SEEK_SET);\n\n    c->current_chapter_size = 0;\n\n\n\n    return 0;\n\n}\n", "idx": 26504}
{"project": "FFmpeg", "commit_id": "98422c44cf86de6da8f73a7bd80284ed165c5a98", "target": 1, "func": "vorbis_comment(AVFormatContext * as, uint8_t *buf, int size)\n\n{\n\n    const uint8_t *p = buf;\n\n    const uint8_t *end = buf + size;\n\n    unsigned s, n, j;\n\n\n\n    if (size < 8) /* must have vendor_length and user_comment_list_length */\n\n        return -1;\n\n\n\n    s = bytestream_get_le32(&p);\n\n\n\n    if (end - p < s)\n\n        return -1;\n\n\n\n    p += s;\n\n\n\n    n = bytestream_get_le32(&p);\n\n\n\n    while (p < end && n > 0) {\n\n        const char *t, *v;\n\n        int tl, vl;\n\n\n\n        s = bytestream_get_le32(&p);\n\n\n\n        if (end - p < s)\n\n            break;\n\n\n\n        t = p;\n\n        p += s;\n\n        n--;\n\n\n\n        v = memchr(t, '=', s);\n\n        if (!v)\n\n            continue;\n\n\n\n        tl = v - t;\n\n        vl = s - tl - 1;\n\n        v++;\n\n\n\n        if (tl && vl) {\n\n            char *tt, *ct;\n\n\n\n            tt = av_malloc(tl + 1);\n\n            ct = av_malloc(vl + 1);\n\n            if (!tt || !ct) {\n\n                av_freep(&tt);\n\n                av_freep(&ct);\n\n                av_log(as, AV_LOG_WARNING, \"out-of-memory error. skipping VorbisComment tag.\\n\");\n\n                continue;\n\n            }\n\n\n\n            for (j = 0; j < tl; j++)\n\n                tt[j] = toupper(t[j]);\n\n            tt[tl] = 0;\n\n\n\n            memcpy(ct, v, vl);\n\n            ct[vl] = 0;\n\n\n\n            av_metadata_set(&as->metadata, tt, ct);\n\n\n\n            av_freep(&tt);\n\n            av_freep(&ct);\n\n        }\n\n    }\n\n\n\n    if (p != end)\n\n        av_log(as, AV_LOG_INFO, \"%ti bytes of comment header remain\\n\", end-p);\n\n    if (n > 0)\n\n        av_log(as, AV_LOG_INFO,\n\n               \"truncated comment header, %i comments not found\\n\", n);\n\n\n\n    return 0;\n\n}\n", "idx": 26505}
{"project": "FFmpeg", "commit_id": "01ecb7172b684f1c4b3e748f95c5a9a494ca36ec", "target": 1, "func": "static float get_band_cost_ESC_mips(struct AACEncContext *s,\n\n                                    PutBitContext *pb, const float *in,\n\n                                    const float *scaled, int size, int scale_idx,\n\n                                    int cb, const float lambda, const float uplim,\n\n                                    int *bits)\n\n{\n\n    const float Q34 = ff_aac_pow34sf_tab[POW_SF2_ZERO - scale_idx + SCALE_ONE_POS - SCALE_DIV_512];\n\n    const float IQ  = ff_aac_pow2sf_tab [POW_SF2_ZERO + scale_idx - SCALE_ONE_POS + SCALE_DIV_512];\n\n    const float CLIPPED_ESCAPE = 165140.0f * IQ;\n\n    int i;\n\n    float cost = 0;\n\n    int qc1, qc2, qc3, qc4;\n\n    int curbits = 0;\n\n\n\n    uint8_t *p_bits  = (uint8_t*)ff_aac_spectral_bits[cb-1];\n\n    float   *p_codes = (float*  )ff_aac_codebook_vectors[cb-1];\n\n\n\n    for (i = 0; i < size; i += 4) {\n\n        const float *vec, *vec2;\n\n        int curidx, curidx2;\n\n        float t1, t2, t3, t4;\n\n        float di1, di2, di3, di4;\n\n        int cond0, cond1, cond2, cond3;\n\n        int c1, c2, c3, c4;\n\n        int t6, t7;\n\n\n\n        qc1 = scaled[i  ] * Q34 + ROUND_STANDARD;\n\n        qc2 = scaled[i+1] * Q34 + ROUND_STANDARD;\n\n        qc3 = scaled[i+2] * Q34 + ROUND_STANDARD;\n\n        qc4 = scaled[i+3] * Q34 + ROUND_STANDARD;\n\n\n\n        __asm__ volatile (\n\n            \".set push                                  \\n\\t\"\n\n            \".set noreorder                             \\n\\t\"\n\n\n\n            \"ori        %[t6],      $zero,  15          \\n\\t\"\n\n            \"ori        %[t7],      $zero,  16          \\n\\t\"\n\n            \"shll_s.w   %[c1],      %[qc1], 18          \\n\\t\"\n\n            \"shll_s.w   %[c2],      %[qc2], 18          \\n\\t\"\n\n            \"shll_s.w   %[c3],      %[qc3], 18          \\n\\t\"\n\n            \"shll_s.w   %[c4],      %[qc4], 18          \\n\\t\"\n\n            \"srl        %[c1],      %[c1],  18          \\n\\t\"\n\n            \"srl        %[c2],      %[c2],  18          \\n\\t\"\n\n            \"srl        %[c3],      %[c3],  18          \\n\\t\"\n\n            \"srl        %[c4],      %[c4],  18          \\n\\t\"\n\n            \"slt        %[cond0],   %[t6],  %[qc1]      \\n\\t\"\n\n            \"slt        %[cond1],   %[t6],  %[qc2]      \\n\\t\"\n\n            \"slt        %[cond2],   %[t6],  %[qc3]      \\n\\t\"\n\n            \"slt        %[cond3],   %[t6],  %[qc4]      \\n\\t\"\n\n            \"movn       %[qc1],     %[t7],  %[cond0]    \\n\\t\"\n\n            \"movn       %[qc2],     %[t7],  %[cond1]    \\n\\t\"\n\n            \"movn       %[qc3],     %[t7],  %[cond2]    \\n\\t\"\n\n            \"movn       %[qc4],     %[t7],  %[cond3]    \\n\\t\"\n\n\n\n            \".set pop                                   \\n\\t\"\n\n\n\n            : [qc1]\"+r\"(qc1), [qc2]\"+r\"(qc2),\n\n              [qc3]\"+r\"(qc3), [qc4]\"+r\"(qc4),\n\n              [cond0]\"=&r\"(cond0), [cond1]\"=&r\"(cond1),\n\n              [cond2]\"=&r\"(cond2), [cond3]\"=&r\"(cond3),\n\n              [c1]\"=&r\"(c1), [c2]\"=&r\"(c2),\n\n              [c3]\"=&r\"(c3), [c4]\"=&r\"(c4),\n\n              [t6]\"=&r\"(t6), [t7]\"=&r\"(t7)\n\n        );\n\n\n\n        curidx = 17 * qc1;\n\n        curidx += qc2;\n\n\n\n        curidx2 = 17 * qc3;\n\n        curidx2 += qc4;\n\n\n\n        curbits += p_bits[curidx];\n\n        curbits += esc_sign_bits[curidx];\n\n        vec     = &p_codes[curidx*2];\n\n\n\n        curbits += p_bits[curidx2];\n\n        curbits += esc_sign_bits[curidx2];\n\n        vec2     = &p_codes[curidx2*2];\n\n\n\n        curbits += (av_log2(c1) * 2 - 3) & (-cond0);\n\n        curbits += (av_log2(c2) * 2 - 3) & (-cond1);\n\n        curbits += (av_log2(c3) * 2 - 3) & (-cond2);\n\n        curbits += (av_log2(c4) * 2 - 3) & (-cond3);\n\n\n\n        t1 = fabsf(in[i  ]);\n\n        t2 = fabsf(in[i+1]);\n\n        t3 = fabsf(in[i+2]);\n\n        t4 = fabsf(in[i+3]);\n\n\n\n        if (cond0) {\n\n            if (t1 >= CLIPPED_ESCAPE) {\n\n                di1 = t1 - CLIPPED_ESCAPE;\n\n            } else {\n\n                di1 = t1 - c1 * cbrtf(c1) * IQ;\n\n            }\n\n        } else\n\n            di1 = t1 - vec[0] * IQ;\n\n\n\n        if (cond1) {\n\n            if (t2 >= CLIPPED_ESCAPE) {\n\n                di2 = t2 - CLIPPED_ESCAPE;\n\n            } else {\n\n                di2 = t2 - c2 * cbrtf(c2) * IQ;\n\n            }\n\n        } else\n\n            di2 = t2 - vec[1] * IQ;\n\n\n\n        if (cond2) {\n\n            if (t3 >= CLIPPED_ESCAPE) {\n\n                di3 = t3 - CLIPPED_ESCAPE;\n\n            } else {\n\n                di3 = t3 - c3 * cbrtf(c3) * IQ;\n\n            }\n\n        } else\n\n            di3 = t3 - vec2[0] * IQ;\n\n\n\n        if (cond3) {\n\n            if (t4 >= CLIPPED_ESCAPE) {\n\n                di4 = t4 - CLIPPED_ESCAPE;\n\n            } else {\n\n                di4 = t4 - c4 * cbrtf(c4) * IQ;\n\n            }\n\n        } else\n\n            di4 = t4 - vec2[1]*IQ;\n\n\n\n        cost += di1 * di1 + di2 * di2\n\n                + di3 * di3 + di4 * di4;\n\n    }\n\n\n\n    if (bits)\n\n        *bits = curbits;\n\n    return cost * lambda + curbits;\n\n}\n", "idx": 26506}
{"project": "FFmpeg", "commit_id": "5a571d324129ce367584ad9d92aae1d286f389a2", "target": 1, "func": "static PayloadContext *h264_new_context(void)\n\n{\n\n    PayloadContext *data =\n\n        av_mallocz(sizeof(PayloadContext) +\n\n                   FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n    if (data) {\n\n        data->cookie = MAGIC_COOKIE;\n\n    }\n\n\n\n    return data;\n\n}\n", "idx": 26507}
{"project": "FFmpeg", "commit_id": "8fa0ae060b759d00c8d8f4070b36c16b3dbf0d8a", "target": 1, "func": "static inline int parse_nal_units(AVCodecParserContext *s,\n\n                                  AVCodecContext *avctx,\n\n                                  const uint8_t *buf, int buf_size)\n\n{\n\n    H264Context *h = s->priv_data;\n\n    const uint8_t *buf_end = buf + buf_size;\n\n    unsigned int pps_id;\n\n    unsigned int slice_type;\n\n    int state;\n\n    const uint8_t *ptr;\n\n\n\n    /* set some sane default values */\n\n    s->pict_type = FF_I_TYPE;\n\n    s->key_frame = 0;\n\n\n\n    h->s.avctx= avctx;\n\n    h->sei_recovery_frame_cnt = -1;\n\n    h->sei_dpb_output_delay         =  0;\n\n    h->sei_cpb_removal_delay        = -1;\n\n    h->sei_buffering_period_present =  0;\n\n\n\n    for(;;) {\n\n        int src_length, dst_length, consumed;\n\n        buf = ff_find_start_code(buf, buf_end, &state);\n\n        if(buf >= buf_end)\n\n            break;\n\n        --buf;\n\n        src_length = buf_end - buf;\n\n        switch (state & 0x1f) {\n\n        case NAL_SLICE:\n\n        case NAL_IDR_SLICE:\n\n            // Do not walk the whole buffer just to decode slice header\n\n            if (src_length > 20)\n\n                src_length = 20;\n\n            break;\n\n        }\n\n        ptr= ff_h264_decode_nal(h, buf, &dst_length, &consumed, src_length);\n\n        if (ptr==NULL || dst_length < 0)\n\n            break;\n\n\n\n        init_get_bits(&h->s.gb, ptr, 8*dst_length);\n\n        switch(h->nal_unit_type) {\n\n        case NAL_SPS:\n\n            ff_h264_decode_seq_parameter_set(h);\n\n            break;\n\n        case NAL_PPS:\n\n            ff_h264_decode_picture_parameter_set(h, h->s.gb.size_in_bits);\n\n            break;\n\n        case NAL_SEI:\n\n            ff_h264_decode_sei(h);\n\n            break;\n\n        case NAL_IDR_SLICE:\n\n            s->key_frame = 1;\n\n            /* fall through */\n\n        case NAL_SLICE:\n\n            get_ue_golomb(&h->s.gb);  // skip first_mb_in_slice\n\n            slice_type = get_ue_golomb_31(&h->s.gb);\n\n            s->pict_type = golomb_to_pict_type[slice_type % 5];\n\n            if (h->sei_recovery_frame_cnt >= 0) {\n\n                /* key frame, since recovery_frame_cnt is set */\n\n                s->key_frame = 1;\n\n            }\n\n            pps_id= get_ue_golomb(&h->s.gb);\n\n            if(pps_id>=MAX_PPS_COUNT) {\n\n                av_log(h->s.avctx, AV_LOG_ERROR, \"pps_id out of range\\n\");\n\n                return -1;\n\n            }\n\n            if(!h->pps_buffers[pps_id]) {\n\n                av_log(h->s.avctx, AV_LOG_ERROR, \"non-existing PPS referenced\\n\");\n\n                return -1;\n\n            }\n\n            h->pps= *h->pps_buffers[pps_id];\n\n            if(!h->sps_buffers[h->pps.sps_id]) {\n\n                av_log(h->s.avctx, AV_LOG_ERROR, \"non-existing SPS referenced\\n\");\n\n                return -1;\n\n            }\n\n            h->sps = *h->sps_buffers[h->pps.sps_id];\n\n            h->frame_num = get_bits(&h->s.gb, h->sps.log2_max_frame_num);\n\n\n\n            if(h->sps.frame_mbs_only_flag){\n\n                h->s.picture_structure= PICT_FRAME;\n\n            }else{\n\n                if(get_bits1(&h->s.gb)) { //field_pic_flag\n\n                    h->s.picture_structure= PICT_TOP_FIELD + get_bits1(&h->s.gb); //bottom_field_flag\n\n                } else {\n\n                    h->s.picture_structure= PICT_FRAME;\n\n                }\n\n            }\n\n\n\n            if(h->sps.pic_struct_present_flag) {\n\n                switch (h->sei_pic_struct) {\n\n                    case SEI_PIC_STRUCT_TOP_FIELD:\n\n                    case SEI_PIC_STRUCT_BOTTOM_FIELD:\n\n                        s->repeat_pict = 0;\n\n                        break;\n\n                    case SEI_PIC_STRUCT_FRAME:\n\n                    case SEI_PIC_STRUCT_TOP_BOTTOM:\n\n                    case SEI_PIC_STRUCT_BOTTOM_TOP:\n\n                        s->repeat_pict = 1;\n\n                        break;\n\n                    case SEI_PIC_STRUCT_TOP_BOTTOM_TOP:\n\n                    case SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM:\n\n                        s->repeat_pict = 2;\n\n                        break;\n\n                    case SEI_PIC_STRUCT_FRAME_DOUBLING:\n\n                        s->repeat_pict = 3;\n\n                        break;\n\n                    case SEI_PIC_STRUCT_FRAME_TRIPLING:\n\n                        s->repeat_pict = 5;\n\n                        break;\n\n                    default:\n\n                        s->repeat_pict = h->s.picture_structure == PICT_FRAME ? 1 : 0;\n\n                        break;\n\n                }\n\n            } else {\n\n                s->repeat_pict = h->s.picture_structure == PICT_FRAME ? 1 : 0;\n\n            }\n\n\n\n            return 0; /* no need to evaluate the rest */\n\n        }\n\n        buf += consumed;\n\n    }\n\n    /* didn't find a picture! */\n\n    av_log(h->s.avctx, AV_LOG_ERROR, \"missing picture in access unit\\n\");\n\n    return -1;\n\n}\n", "idx": 26510}
{"project": "FFmpeg", "commit_id": "44d854a518f97cb65090420b0b9f55611a0ea932", "target": 1, "func": "static av_cold int atrac3_decode_init(AVCodecContext *avctx)\n\n{\n\n    int i, ret;\n\n    int version, delay, samples_per_frame, frame_factor;\n\n    const uint8_t *edata_ptr = avctx->extradata;\n\n    ATRAC3Context *q = avctx->priv_data;\n\n\n\n    if (avctx->channels <= 0 || avctx->channels > 2) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Channel configuration error!\\n\");\n\n\n    }\n\n\n\n    /* Take care of the codec-specific extradata. */\n\n    if (avctx->extradata_size == 14) {\n\n        /* Parse the extradata, WAV format */\n\n        av_log(avctx, AV_LOG_DEBUG, \"[0-1] %d\\n\",\n\n               bytestream_get_le16(&edata_ptr));  // Unknown value always 1\n\n        edata_ptr += 4;                             // samples per channel\n\n        q->coding_mode = bytestream_get_le16(&edata_ptr);\n\n        av_log(avctx, AV_LOG_DEBUG,\"[8-9] %d\\n\",\n\n               bytestream_get_le16(&edata_ptr));  //Dupe of coding mode\n\n        frame_factor = bytestream_get_le16(&edata_ptr);  // Unknown always 1\n\n        av_log(avctx, AV_LOG_DEBUG,\"[12-13] %d\\n\",\n\n               bytestream_get_le16(&edata_ptr));  // Unknown always 0\n\n\n\n        /* setup */\n\n        samples_per_frame    = SAMPLES_PER_FRAME * avctx->channels;\n\n        version              = 4;\n\n        delay                = 0x88E;\n\n        q->coding_mode       = q->coding_mode ? JOINT_STEREO : STEREO;\n\n        q->scrambled_stream  = 0;\n\n\n\n        if (avctx->block_align !=  96 * avctx->channels * frame_factor &&\n\n            avctx->block_align != 152 * avctx->channels * frame_factor &&\n\n            avctx->block_align != 192 * avctx->channels * frame_factor) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Unknown frame/channel/frame_factor \"\n\n                   \"configuration %d/%d/%d\\n\", avctx->block_align,\n\n                   avctx->channels, frame_factor);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    } else if (avctx->extradata_size == 10) {\n\n        /* Parse the extradata, RM format. */\n\n        version                = bytestream_get_be32(&edata_ptr);\n\n        samples_per_frame      = bytestream_get_be16(&edata_ptr);\n\n        delay                  = bytestream_get_be16(&edata_ptr);\n\n        q->coding_mode         = bytestream_get_be16(&edata_ptr);\n\n        q->scrambled_stream    = 1;\n\n\n\n    } else {\n\n        av_log(NULL, AV_LOG_ERROR, \"Unknown extradata size %d.\\n\",\n\n               avctx->extradata_size);\n\n\n    }\n\n\n\n    /* Check the extradata */\n\n\n\n    if (version != 4) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Version %d != 4.\\n\", version);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (samples_per_frame != SAMPLES_PER_FRAME &&\n\n        samples_per_frame != SAMPLES_PER_FRAME * 2) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown amount of samples per frame %d.\\n\",\n\n               samples_per_frame);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (delay != 0x88E) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown amount of delay %x != 0x88E.\\n\",\n\n               delay);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (q->coding_mode == STEREO)\n\n        av_log(avctx, AV_LOG_DEBUG, \"Normal stereo detected.\\n\");\n\n    else if (q->coding_mode == JOINT_STEREO)\n\n        av_log(avctx, AV_LOG_DEBUG, \"Joint stereo detected.\\n\");\n\n    else {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown channel coding mode %x!\\n\",\n\n               q->coding_mode);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (avctx->block_align >= UINT_MAX / 2)\n\n\n\n\n    q->decoded_bytes_buffer = av_mallocz(FFALIGN(avctx->block_align, 4) +\n\n                                         FF_INPUT_BUFFER_PADDING_SIZE);\n\n    if (q->decoded_bytes_buffer == NULL)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_FLTP;\n\n\n\n    /* initialize the MDCT transform */\n\n    if ((ret = ff_mdct_init(&q->mdct_ctx, 9, 1, 1.0 / 32768)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error initializing MDCT\\n\");\n\n        av_freep(&q->decoded_bytes_buffer);\n\n        return ret;\n\n    }\n\n\n\n    /* init the joint-stereo decoding data */\n\n    q->weighting_delay[0] = 0;\n\n    q->weighting_delay[1] = 7;\n\n    q->weighting_delay[2] = 0;\n\n    q->weighting_delay[3] = 7;\n\n    q->weighting_delay[4] = 0;\n\n    q->weighting_delay[5] = 7;\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        q->matrix_coeff_index_prev[i] = 3;\n\n        q->matrix_coeff_index_now[i]  = 3;\n\n        q->matrix_coeff_index_next[i] = 3;\n\n    }\n\n\n\n    avpriv_float_dsp_init(&q->fdsp, avctx->flags & CODEC_FLAG_BITEXACT);\n\n    ff_fmt_convert_init(&q->fmt_conv, avctx);\n\n\n\n    q->units = av_mallocz(sizeof(*q->units) * avctx->channels);\n\n    if (!q->units) {\n\n        atrac3_decode_close(avctx);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    avcodec_get_frame_defaults(&q->frame);\n\n    avctx->coded_frame = &q->frame;\n\n\n\n    return 0;\n\n}", "idx": 26512}
{"project": "FFmpeg", "commit_id": "1d16a1cf99488f16492b1bb48e023f4da8377e07", "target": 0, "func": "static void ff_h264_idct_add16_sse2(uint8_t *dst, const int *block_offset, DCTELEM *block, int stride, const uint8_t nnzc[6*8]){\n\n    int i;\n\n    for(i=0; i<16; i+=2)\n\n        if(nnzc[ scan8[i+0] ]|nnzc[ scan8[i+1] ])\n\n            ff_x264_add8x4_idct_sse2 (dst + block_offset[i], block + i*16, stride);\n\n}\n", "idx": 26513}
{"project": "FFmpeg", "commit_id": "76ba09d18245a2a41dc5f93a60fd00cdf358cb1f", "target": 1, "func": "static int mpeg4_decode_sprite_trajectory(Mpeg4DecContext *ctx, GetBitContext *gb)\n{\n    MpegEncContext *s = &ctx->m;\n    int a     = 2 << s->sprite_warping_accuracy;\n    int rho   = 3  - s->sprite_warping_accuracy;\n    int r     = 16 / a;\n    int alpha = 0;\n    int beta  = 0;\n    int w     = s->width;\n    int h     = s->height;\n    int min_ab, i, w2, h2, w3, h3;\n    int sprite_ref[4][2];\n    int virtual_ref[2][2];\n    // only true for rectangle shapes\n    const int vop_ref[4][2] = { { 0, 0 },         { s->width, 0 },\n                                { 0, s->height }, { s->width, s->height } };\n    int d[4][2]             = { { 0, 0 }, { 0, 0 }, { 0, 0 }, { 0, 0 } };\n    if (w <= 0 || h <= 0)\n        return AVERROR_INVALIDDATA;\n    for (i = 0; i < ctx->num_sprite_warping_points; i++) {\n        int length;\n        int x = 0, y = 0;\n        length = get_vlc2(gb, sprite_trajectory.table, SPRITE_TRAJ_VLC_BITS, 3);\n        if (length > 0)\n            x = get_xbits(gb, length);\n        if (!(ctx->divx_version == 500 && ctx->divx_build == 413))\n            check_marker(s->avctx, gb, \"before sprite_trajectory\");\n        length = get_vlc2(gb, sprite_trajectory.table, SPRITE_TRAJ_VLC_BITS, 3);\n        if (length > 0)\n            y = get_xbits(gb, length);\n        check_marker(s->avctx, gb, \"after sprite_trajectory\");\n        ctx->sprite_traj[i][0] = d[i][0] = x;\n        ctx->sprite_traj[i][1] = d[i][1] = y;\n    for (; i < 4; i++)\n        ctx->sprite_traj[i][0] = ctx->sprite_traj[i][1] = 0;\n    while ((1 << alpha) < w)\n        alpha++;\n    while ((1 << beta) < h)\n        beta++;  /* typo in the MPEG-4 std for the definition of w' and h' */\n    w2 = 1 << alpha;\n    h2 = 1 << beta;\n    // Note, the 4th point isn't used for GMC\n    if (ctx->divx_version == 500 && ctx->divx_build == 413) {\n        sprite_ref[0][0] = a * vop_ref[0][0] + d[0][0];\n        sprite_ref[0][1] = a * vop_ref[0][1] + d[0][1];\n        sprite_ref[1][0] = a * vop_ref[1][0] + d[0][0] + d[1][0];\n        sprite_ref[1][1] = a * vop_ref[1][1] + d[0][1] + d[1][1];\n        sprite_ref[2][0] = a * vop_ref[2][0] + d[0][0] + d[2][0];\n        sprite_ref[2][1] = a * vop_ref[2][1] + d[0][1] + d[2][1];\n    } else {\n        sprite_ref[0][0] = (a >> 1) * (2 * vop_ref[0][0] + d[0][0]);\n        sprite_ref[0][1] = (a >> 1) * (2 * vop_ref[0][1] + d[0][1]);\n        sprite_ref[1][0] = (a >> 1) * (2 * vop_ref[1][0] + d[0][0] + d[1][0]);\n        sprite_ref[1][1] = (a >> 1) * (2 * vop_ref[1][1] + d[0][1] + d[1][1]);\n        sprite_ref[2][0] = (a >> 1) * (2 * vop_ref[2][0] + d[0][0] + d[2][0]);\n        sprite_ref[2][1] = (a >> 1) * (2 * vop_ref[2][1] + d[0][1] + d[2][1]);\n    /* sprite_ref[3][0] = (a >> 1) * (2 * vop_ref[3][0] + d[0][0] + d[1][0] + d[2][0] + d[3][0]);\n     * sprite_ref[3][1] = (a >> 1) * (2 * vop_ref[3][1] + d[0][1] + d[1][1] + d[2][1] + d[3][1]); */\n    /* This is mostly identical to the MPEG-4 std (and is totally unreadable\n     * because of that...). Perhaps it should be reordered to be more readable.\n     * The idea behind this virtual_ref mess is to be able to use shifts later\n     * per pixel instead of divides so the distance between points is converted\n     * from w&h based to w2&h2 based which are of the 2^x form. */\n    virtual_ref[0][0] = 16 * (vop_ref[0][0] + w2) +\n                         ROUNDED_DIV(((w - w2) *\n                                      (r * sprite_ref[0][0] - 16 * vop_ref[0][0]) +\n                                      w2 * (r * sprite_ref[1][0] - 16 * vop_ref[1][0])), w);\n    virtual_ref[0][1] = 16 * vop_ref[0][1] +\n                        ROUNDED_DIV(((w - w2) *\n                                     (r * sprite_ref[0][1] - 16 * vop_ref[0][1]) +\n                                     w2 * (r * sprite_ref[1][1] - 16 * vop_ref[1][1])), w);\n    virtual_ref[1][0] = 16 * vop_ref[0][0] +\n                        ROUNDED_DIV(((h - h2) * (r * sprite_ref[0][0] - 16 * vop_ref[0][0]) +\n                                     h2 * (r * sprite_ref[2][0] - 16 * vop_ref[2][0])), h);\n    virtual_ref[1][1] = 16 * (vop_ref[0][1] + h2) +\n                        ROUNDED_DIV(((h - h2) * (r * sprite_ref[0][1] - 16 * vop_ref[0][1]) +\n                                     h2 * (r * sprite_ref[2][1] - 16 * vop_ref[2][1])), h);\n    switch (ctx->num_sprite_warping_points) {\n    case 0:\n        s->sprite_offset[0][0] =\n        s->sprite_offset[0][1] =\n        s->sprite_offset[1][0] =\n        s->sprite_offset[1][1] = 0;\n        s->sprite_delta[0][0]  = a;\n        s->sprite_delta[0][1]  =\n        s->sprite_delta[1][0]  = 0;\n        s->sprite_delta[1][1]  = a;\n        ctx->sprite_shift[0]   =\n        ctx->sprite_shift[1]   = 0;\n        break;\n    case 1:     // GMC only\n        s->sprite_offset[0][0] = sprite_ref[0][0] - a * vop_ref[0][0];\n        s->sprite_offset[0][1] = sprite_ref[0][1] - a * vop_ref[0][1];\n        s->sprite_offset[1][0] = ((sprite_ref[0][0] >> 1) | (sprite_ref[0][0] & 1)) -\n                                 a * (vop_ref[0][0] / 2);\n        s->sprite_offset[1][1] = ((sprite_ref[0][1] >> 1) | (sprite_ref[0][1] & 1)) -\n                                 a * (vop_ref[0][1] / 2);\n        s->sprite_delta[0][0]  = a;\n        s->sprite_delta[0][1]  =\n        s->sprite_delta[1][0]  = 0;\n        s->sprite_delta[1][1]  = a;\n        ctx->sprite_shift[0]   =\n        ctx->sprite_shift[1]   = 0;\n        break;\n    case 2:\n        s->sprite_offset[0][0] = (sprite_ref[0][0] << (alpha + rho)) +\n                                 (-r * sprite_ref[0][0] + virtual_ref[0][0]) *\n                                 (-vop_ref[0][0]) +\n                                 (r * sprite_ref[0][1] - virtual_ref[0][1]) *\n                                 (-vop_ref[0][1]) + (1 << (alpha + rho - 1));\n        s->sprite_offset[0][1] = (sprite_ref[0][1] << (alpha + rho)) +\n                                 (-r * sprite_ref[0][1] + virtual_ref[0][1]) *\n                                 (-vop_ref[0][0]) +\n                                 (-r * sprite_ref[0][0] + virtual_ref[0][0]) *\n                                 (-vop_ref[0][1]) + (1 << (alpha + rho - 1));\n        s->sprite_offset[1][0] = ((-r * sprite_ref[0][0] + virtual_ref[0][0]) *\n                                  (-2 * vop_ref[0][0] + 1) +\n                                  (r * sprite_ref[0][1] - virtual_ref[0][1]) *\n                                  (-2 * vop_ref[0][1] + 1) + 2 * w2 * r *\n                                  sprite_ref[0][0] - 16 * w2 + (1 << (alpha + rho + 1)));\n        s->sprite_offset[1][1] = ((-r * sprite_ref[0][1] + virtual_ref[0][1]) *\n                                  (-2 * vop_ref[0][0] + 1) +\n                                  (-r * sprite_ref[0][0] + virtual_ref[0][0]) *\n                                  (-2 * vop_ref[0][1] + 1) + 2 * w2 * r *\n                                  sprite_ref[0][1] - 16 * w2 + (1 << (alpha + rho + 1)));\n        s->sprite_delta[0][0] = (-r * sprite_ref[0][0] + virtual_ref[0][0]);\n        s->sprite_delta[0][1] = (+r * sprite_ref[0][1] - virtual_ref[0][1]);\n        s->sprite_delta[1][0] = (-r * sprite_ref[0][1] + virtual_ref[0][1]);\n        s->sprite_delta[1][1] = (-r * sprite_ref[0][0] + virtual_ref[0][0]);\n        ctx->sprite_shift[0]  = alpha + rho;\n        ctx->sprite_shift[1]  = alpha + rho + 2;\n        break;\n    case 3:\n        min_ab = FFMIN(alpha, beta);\n        w3     = w2 >> min_ab;\n        h3     = h2 >> min_ab;\n        s->sprite_offset[0][0] = (sprite_ref[0][0] * (1<<(alpha + beta + rho - min_ab))) +\n                                 (-r * sprite_ref[0][0] + virtual_ref[0][0]) *\n                                 h3 * (-vop_ref[0][0]) +\n                                 (-r * sprite_ref[0][0] + virtual_ref[1][0]) *\n                                 w3 * (-vop_ref[0][1]) +\n                                 (1 << (alpha + beta + rho - min_ab - 1));\n        s->sprite_offset[0][1] = (sprite_ref[0][1] * (1 << (alpha + beta + rho - min_ab))) +\n                                 (-r * sprite_ref[0][1] + virtual_ref[0][1]) *\n                                 h3 * (-vop_ref[0][0]) +\n                                 (-r * sprite_ref[0][1] + virtual_ref[1][1]) *\n                                 w3 * (-vop_ref[0][1]) +\n                                 (1 << (alpha + beta + rho - min_ab - 1));\n        s->sprite_offset[1][0] = (-r * sprite_ref[0][0] + virtual_ref[0][0]) *\n                                 h3 * (-2 * vop_ref[0][0] + 1) +\n                                 (-r * sprite_ref[0][0] + virtual_ref[1][0]) *\n                                 w3 * (-2 * vop_ref[0][1] + 1) + 2 * w2 * h3 *\n                                 r * sprite_ref[0][0] - 16 * w2 * h3 +\n                                 (1 << (alpha + beta + rho - min_ab + 1));\n        s->sprite_offset[1][1] = (-r * sprite_ref[0][1] + virtual_ref[0][1]) *\n                                 h3 * (-2 * vop_ref[0][0] + 1) +\n                                 (-r * sprite_ref[0][1] + virtual_ref[1][1]) *\n                                 w3 * (-2 * vop_ref[0][1] + 1) + 2 * w2 * h3 *\n                                 r * sprite_ref[0][1] - 16 * w2 * h3 +\n                                 (1 << (alpha + beta + rho - min_ab + 1));\n        s->sprite_delta[0][0] = (-r * sprite_ref[0][0] + virtual_ref[0][0]) * h3;\n        s->sprite_delta[0][1] = (-r * sprite_ref[0][0] + virtual_ref[1][0]) * w3;\n        s->sprite_delta[1][0] = (-r * sprite_ref[0][1] + virtual_ref[0][1]) * h3;\n        s->sprite_delta[1][1] = (-r * sprite_ref[0][1] + virtual_ref[1][1]) * w3;\n        ctx->sprite_shift[0]  = alpha + beta + rho - min_ab;\n        ctx->sprite_shift[1]  = alpha + beta + rho - min_ab + 2;\n        break;\n    /* try to simplify the situation */\n    if (s->sprite_delta[0][0] == a << ctx->sprite_shift[0] &&\n        s->sprite_delta[0][1] == 0 &&\n        s->sprite_delta[1][0] == 0 &&\n        s->sprite_delta[1][1] == a << ctx->sprite_shift[0]) {\n        s->sprite_offset[0][0] >>= ctx->sprite_shift[0];\n        s->sprite_offset[0][1] >>= ctx->sprite_shift[0];\n        s->sprite_offset[1][0] >>= ctx->sprite_shift[1];\n        s->sprite_offset[1][1] >>= ctx->sprite_shift[1];\n        s->sprite_delta[0][0] = a;\n        s->sprite_delta[0][1] = 0;\n        s->sprite_delta[1][0] = 0;\n        s->sprite_delta[1][1] = a;\n        ctx->sprite_shift[0] = 0;\n        ctx->sprite_shift[1] = 0;\n        s->real_sprite_warping_points = 1;\n    } else {\n        int shift_y = 16 - ctx->sprite_shift[0];\n        int shift_c = 16 - ctx->sprite_shift[1];\n        if (shift_c < 0 || shift_y < 0 ||\n            FFABS(s->sprite_offset[0][0]) >= INT_MAX >> shift_y  ||\n            FFABS(s->sprite_offset[1][0]) >= INT_MAX >> shift_c  ||\n            FFABS(s->sprite_offset[0][1]) >= INT_MAX >> shift_y  ||\n            FFABS(s->sprite_offset[1][1]) >= INT_MAX >> shift_c\n        ) {\n            avpriv_request_sample(s->avctx, \"Too large sprite shift or offset\");\n        for (i = 0; i < 2; i++) {\n            s->sprite_offset[0][i] *= 1 << shift_y;\n            s->sprite_offset[1][i] *= 1 << shift_c;\n            s->sprite_delta[0][i]  *= 1 << shift_y;\n            s->sprite_delta[1][i]  *= 1 << shift_y;\n            ctx->sprite_shift[i]     = 16;\n        s->real_sprite_warping_points = ctx->num_sprite_warping_points;\n    return 0;", "idx": 26515}
{"project": "FFmpeg", "commit_id": "41003da94a59cd014d05b3dd1d33a5f9ecf3ccda", "target": 1, "func": "static int ff_filter_frame_framed(AVFilterLink *link, AVFrame *frame)\n\n{\n\n    int (*filter_frame)(AVFilterLink *, AVFrame *);\n\n    AVFilterContext *dstctx = link->dst;\n\n    AVFilterPad *dst = link->dstpad;\n\n    AVFrame *out;\n\n    int ret;\n\n    AVFilterCommand *cmd= link->dst->command_queue;\n\n    int64_t pts;\n\n\n\n    if (link->closed) {\n\n        av_frame_free(&frame);\n\n        return AVERROR_EOF;\n\n    }\n\n\n\n    if (!(filter_frame = dst->filter_frame))\n\n        filter_frame = default_filter_frame;\n\n\n\n    /* copy the frame if needed */\n\n    if (dst->needs_writable && !av_frame_is_writable(frame)) {\n\n        av_log(link->dst, AV_LOG_DEBUG, \"Copying data in avfilter.\\n\");\n\n\n\n        /* Maybe use ff_copy_buffer_ref instead? */\n\n        switch (link->type) {\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            out = ff_get_video_buffer(link, link->w, link->h);\n\n            break;\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            out = ff_get_audio_buffer(link, frame->nb_samples);\n\n            break;\n\n        default:\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n        if (!out) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n\n\n        ret = av_frame_copy_props(out, frame);\n\n        if (ret < 0)\n\n            goto fail;\n\n\n\n        switch (link->type) {\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            av_image_copy(out->data, out->linesize, (const uint8_t **)frame->data, frame->linesize,\n\n                          frame->format, frame->width, frame->height);\n\n            break;\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            av_samples_copy(out->extended_data, frame->extended_data,\n\n                            0, 0, frame->nb_samples,\n\n                            av_get_channel_layout_nb_channels(frame->channel_layout),\n\n                            frame->format);\n\n            break;\n\n        default:\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n\n\n        av_frame_free(&frame);\n\n    } else\n\n        out = frame;\n\n\n\n    while(cmd && cmd->time <= out->pts * av_q2d(link->time_base)){\n\n        av_log(link->dst, AV_LOG_DEBUG,\n\n               \"Processing command time:%f command:%s arg:%s\\n\",\n\n               cmd->time, cmd->command, cmd->arg);\n\n        avfilter_process_command(link->dst, cmd->command, cmd->arg, 0, 0, cmd->flags);\n\n        ff_command_queue_pop(link->dst);\n\n        cmd= link->dst->command_queue;\n\n    }\n\n\n\n    pts = out->pts;\n\n    if (dstctx->enable_str) {\n\n        int64_t pos = av_frame_get_pkt_pos(out);\n\n        dstctx->var_values[VAR_N] = link->frame_count;\n\n        dstctx->var_values[VAR_T] = pts == AV_NOPTS_VALUE ? NAN : pts * av_q2d(link->time_base);\n\n        dstctx->var_values[VAR_POS] = pos == -1 ? NAN : pos;\n\n\n\n        dstctx->is_disabled = fabs(av_expr_eval(dstctx->enable, dstctx->var_values, NULL)) < 0.5;\n\n        if (dstctx->is_disabled &&\n\n            (dstctx->filter->flags & AVFILTER_FLAG_SUPPORT_TIMELINE_GENERIC))\n\n            filter_frame = default_filter_frame;\n\n    }\n\n    ret = filter_frame(link, out);\n\n    link->frame_count++;\n\n    link->frame_requested = 0;\n\n    ff_update_link_current_pts(link, pts);\n\n    return ret;\n\n\n\nfail:\n\n    av_frame_free(&out);\n\n    av_frame_free(&frame);\n\n    return ret;\n\n}\n", "idx": 26519}
{"project": "FFmpeg", "commit_id": "1389b4c18d1042c196603ba66c25113bcee1738b", "target": 0, "func": "static inline void FUNC(idctRowCondDC)(int16_t *row, int extra_shift)\n\n{\n\n    int a0, a1, a2, a3, b0, b1, b2, b3;\n\n\n\n#if HAVE_FAST_64BIT\n\n#define ROW0_MASK (0xffffLL << 48 * HAVE_BIGENDIAN)\n\n    if (((((uint64_t *)row)[0] & ~ROW0_MASK) | ((uint64_t *)row)[1]) == 0) {\n\n        uint64_t temp;\n\n        if (DC_SHIFT - extra_shift > 0) {\n\n            temp = (row[0] << (DC_SHIFT - extra_shift)) & 0xffff;\n\n        } else {\n\n            temp = (row[0] >> (extra_shift - DC_SHIFT)) & 0xffff;\n\n        }\n\n        temp += temp << 16;\n\n        temp += temp << 32;\n\n        ((uint64_t *)row)[0] = temp;\n\n        ((uint64_t *)row)[1] = temp;\n\n        return;\n\n    }\n\n#else\n\n    if (!(((uint32_t*)row)[1] |\n\n          ((uint32_t*)row)[2] |\n\n          ((uint32_t*)row)[3] |\n\n          row[1])) {\n\n        uint32_t temp;\n\n        if (DC_SHIFT - extra_shift > 0) {\n\n            temp = (row[0] << (DC_SHIFT - extra_shift)) & 0xffff;\n\n        } else {\n\n            temp = (row[0] >> (extra_shift - DC_SHIFT)) & 0xffff;\n\n        }\n\n        temp += temp << 16;\n\n        ((uint32_t*)row)[0]=((uint32_t*)row)[1] =\n\n            ((uint32_t*)row)[2]=((uint32_t*)row)[3] = temp;\n\n        return;\n\n    }\n\n#endif\n\n\n\n    a0 = (W4 * row[0]) + (1 << (ROW_SHIFT - 1));\n\n    a1 = a0;\n\n    a2 = a0;\n\n    a3 = a0;\n\n\n\n    a0 += W2 * row[2];\n\n    a1 += W6 * row[2];\n\n    a2 -= W6 * row[2];\n\n    a3 -= W2 * row[2];\n\n\n\n    b0 = MUL(W1, row[1]);\n\n    MAC(b0, W3, row[3]);\n\n    b1 = MUL(W3, row[1]);\n\n    MAC(b1, -W7, row[3]);\n\n    b2 = MUL(W5, row[1]);\n\n    MAC(b2, -W1, row[3]);\n\n    b3 = MUL(W7, row[1]);\n\n    MAC(b3, -W5, row[3]);\n\n\n\n    if (AV_RN64A(row + 4)) {\n\n        a0 +=   W4*row[4] + W6*row[6];\n\n        a1 += - W4*row[4] - W2*row[6];\n\n        a2 += - W4*row[4] + W2*row[6];\n\n        a3 +=   W4*row[4] - W6*row[6];\n\n\n\n        MAC(b0,  W5, row[5]);\n\n        MAC(b0,  W7, row[7]);\n\n\n\n        MAC(b1, -W1, row[5]);\n\n        MAC(b1, -W5, row[7]);\n\n\n\n        MAC(b2,  W7, row[5]);\n\n        MAC(b2,  W3, row[7]);\n\n\n\n        MAC(b3,  W3, row[5]);\n\n        MAC(b3, -W1, row[7]);\n\n    }\n\n\n\n    row[0] = (a0 + b0) >> (ROW_SHIFT + extra_shift);\n\n    row[7] = (a0 - b0) >> (ROW_SHIFT + extra_shift);\n\n    row[1] = (a1 + b1) >> (ROW_SHIFT + extra_shift);\n\n    row[6] = (a1 - b1) >> (ROW_SHIFT + extra_shift);\n\n    row[2] = (a2 + b2) >> (ROW_SHIFT + extra_shift);\n\n    row[5] = (a2 - b2) >> (ROW_SHIFT + extra_shift);\n\n    row[3] = (a3 + b3) >> (ROW_SHIFT + extra_shift);\n\n    row[4] = (a3 - b3) >> (ROW_SHIFT + extra_shift);\n\n}\n", "idx": 26520}
{"project": "FFmpeg", "commit_id": "697400eac07c0614f6b9f2e7615563982dbcbe4a", "target": 0, "func": "static int mov_read_chap(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    c->chapter_track = avio_rb32(pb);\n\n    return 0;\n\n}\n", "idx": 26521}
{"project": "FFmpeg", "commit_id": "de6a1e32fd483db05d957268d5e45e2b1be9cab4", "target": 1, "func": "static int io_write_data_type(void *opaque, uint8_t *buf, int size,\n\n                              enum AVIODataMarkerType type, int64_t time)\n\n{\n\n    char timebuf[30], content[5] = { 0 };\n\n    const char *str;\n\n    switch (type) {\n\n    case AVIO_DATA_MARKER_HEADER:         str = \"header\";   break;\n\n    case AVIO_DATA_MARKER_SYNC_POINT:     str = \"sync\";     break;\n\n    case AVIO_DATA_MARKER_BOUNDARY_POINT: str = \"boundary\"; break;\n\n    case AVIO_DATA_MARKER_UNKNOWN:        str = \"unknown\";  break;\n\n    case AVIO_DATA_MARKER_TRAILER:        str = \"trailer\";  break;\n\n\n    }\n\n    if (time == AV_NOPTS_VALUE)\n\n        snprintf(timebuf, sizeof(timebuf), \"nopts\");\n\n    else\n\n        snprintf(timebuf, sizeof(timebuf), \"%\"PRId64, time);\n\n    // There can be multiple header/trailer callbacks, only log the box type\n\n    // for header at out_size == 0\n\n    if (type != AVIO_DATA_MARKER_UNKNOWN &&\n\n        type != AVIO_DATA_MARKER_TRAILER &&\n\n        (type != AVIO_DATA_MARKER_HEADER || out_size == 0) &&\n\n        size >= 8)\n\n        memcpy(content, &buf[4], 4);\n\n    else\n\n        snprintf(content, sizeof(content), \"-\");\n\n    printf(\"write_data len %d, time %s, type %s atom %s\\n\", size, timebuf, str, content);\n\n    return io_write(opaque, buf, size);\n\n}", "idx": 26523}
{"project": "FFmpeg", "commit_id": "c7269e3a2697c189c907832b8a36341cbb40936c", "target": 1, "func": "static void release_buffer(AVCodecContext *avctx, AVFrame *pic)\n\n{\n\n    int i;\n\n\n\n    CVPixelBufferRef cv_buffer = (CVPixelBufferRef)pic->data[3];\n\n    CVPixelBufferUnlockBaseAddress(cv_buffer, 0);\n\n    CVPixelBufferRelease(cv_buffer);\n\n\n\n    for (i = 0; i < 4; i++)\n\n        pic->data[i] = NULL;\n\n}\n", "idx": 26524}
{"project": "FFmpeg", "commit_id": "f863bee841670384fc46f4f99f511b27eb89a216", "target": 0, "func": "static void final(Real144_internal *glob, short *i1, short *i2, void *out,\n\n                  int *statbuf, int len)\n\n{\n\n    int x, sum;\n\n    int buffer[10];\n\n    short *ptr;\n\n    short *ptr2;\n\n\n\n    memcpy(glob->work, statbuf,20);\n\n    memcpy(glob->work + 10, i2, len * 2);\n\n\n\n    buffer[9] = i1[0];\n\n    buffer[8] = i1[1];\n\n    buffer[7] = i1[2];\n\n    buffer[6] = i1[3];\n\n    buffer[5] = i1[4];\n\n    buffer[4] = i1[5];\n\n    buffer[3] = i1[6];\n\n    buffer[2] = i1[7];\n\n    buffer[1] = i1[8];\n\n    buffer[0] = i1[9];\n\n\n\n    ptr2 = (ptr = glob->work) + len;\n\n\n\n    while (ptr < ptr2) {\n\n        for(sum=0, x=0; x<=9; x++)\n\n            sum += buffer[x] * (ptr[x]);\n\n\n\n        sum = sum >> 12;\n\n        x = ptr[10] - sum;\n\n\n\n        if (x<-32768 || x>32767) {\n\n            memset(out, 0, len * 2);\n\n            memset(statbuf, 0, 20);\n\n            return;\n\n        }\n\n\n\n        ptr[10] = x;\n\n        ptr++;\n\n    }\n\n    memcpy(out, ptr+10 - len, len * 2);\n\n    memcpy(statbuf, ptr, 20);\n\n}\n", "idx": 26525}
{"project": "FFmpeg", "commit_id": "233f6f889ea310c2213f1f678b68e424791bf843", "target": 0, "func": "AVOption *av_set_string(void *obj, const char *name, const char *val){\n\n    AVOption *o= find_opt(obj, name);\n\n    if(!o || !val || o->offset<=0) \n\n        return NULL;\n\n    if(o->type != FF_OPT_TYPE_STRING){\n\n        double d=0, tmp_d;\n\n        for(;;){\n\n            int i;\n\n            char buf[256], *tail;\n\n\n\n            for(i=0; i<sizeof(buf)-1 && val[i] && val[i]!='+'; i++)\n\n                buf[i]= val[i];\n\n            buf[i]=0;\n\n            val+= i;\n\n            \n\n            tmp_d= av_parse_num(buf, &tail);\n\n            if(tail > buf)\n\n                d+= tmp_d;\n\n            else{\n\n                AVOption *o_named= find_opt(obj, buf);\n\n                if(o_named && o_named->type == FF_OPT_TYPE_CONST) \n\n                    d+= o_named->default_val;\n\n                else if(!strcmp(buf, \"default\")) d+= o->default_val;\n\n                else if(!strcmp(buf, \"max\"    )) d+= o->max;\n\n                else if(!strcmp(buf, \"min\"    )) d+= o->min;\n\n                else return NULL;\n\n            }\n\n\n\n            if(*val == '+') val++;\n\n            if(!*val)\n\n                return av_set_number(obj, name, d, 1, 1);\n\n        }\n\n        return NULL;\n\n    }\n\n    \n\n    memcpy(((uint8_t*)obj) + o->offset, val, sizeof(val));\n\n    return o;\n\n}\n", "idx": 26526}
{"project": "FFmpeg", "commit_id": "c8241e730f116f1c9cfc0b34110aa7f052e05332", "target": 0, "func": "static AVBufferRef *vaapi_encode_alloc_output_buffer(void *opaque,\n\n                                                     int size)\n\n{\n\n    AVCodecContext   *avctx = opaque;\n\n    VAAPIEncodeContext *ctx = avctx->priv_data;\n\n    VABufferID buffer_id;\n\n    VAStatus vas;\n\n    AVBufferRef *ref;\n\n\n\n    // The output buffer size is fixed, so it needs to be large enough\n\n    // to hold the largest possible compressed frame.  We assume here\n\n    // that the uncompressed frame plus some header data is an upper\n\n    // bound on that.\n\n    vas = vaCreateBuffer(ctx->hwctx->display, ctx->va_context,\n\n                         VAEncCodedBufferType,\n\n                         3 * ctx->aligned_width * ctx->aligned_height +\n\n                         (1 << 16), 1, 0, &buffer_id);\n\n    if (vas != VA_STATUS_SUCCESS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to create bitstream \"\n\n               \"output buffer: %d (%s).\\n\", vas, vaErrorStr(vas));\n\n        return NULL;\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_DEBUG, \"Allocated output buffer %#x\\n\", buffer_id);\n\n\n\n    ref = av_buffer_create((uint8_t*)(uintptr_t)buffer_id,\n\n                           sizeof(buffer_id),\n\n                           &vaapi_encode_free_output_buffer,\n\n                           avctx, AV_BUFFER_FLAG_READONLY);\n\n    if (!ref) {\n\n        vaDestroyBuffer(ctx->hwctx->display, buffer_id);\n\n        return NULL;\n\n    }\n\n\n\n    return ref;\n\n}\n", "idx": 26537}
{"project": "FFmpeg", "commit_id": "3438d82d4b3bd987304975961e2a42e82767107d", "target": 0, "func": "static int ffm_write_header(AVFormatContext *s)\n\n{\n\n    FFMContext *ffm = s->priv_data;\n\n    AVStream *st;\n\n    ByteIOContext *pb = s->pb;\n\n    AVCodecContext *codec;\n\n    int bit_rate, i;\n\n\n\n    ffm->packet_size = FFM_PACKET_SIZE;\n\n\n\n    /* header */\n\n    put_le32(pb, MKTAG('F', 'F', 'M', '1'));\n\n    put_be32(pb, ffm->packet_size);\n\n    /* XXX: store write position in other file ? */\n\n    put_be64(pb, ffm->packet_size); /* current write position */\n\n\n\n    put_be32(pb, s->nb_streams);\n\n    bit_rate = 0;\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        st = s->streams[i];\n\n        bit_rate += st->codec->bit_rate;\n\n    }\n\n    put_be32(pb, bit_rate);\n\n\n\n    /* list of streams */\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        st = s->streams[i];\n\n        av_set_pts_info(st, 64, 1, 1000000);\n\n\n\n        codec = st->codec;\n\n        /* generic info */\n\n        put_be32(pb, codec->codec_id);\n\n        put_byte(pb, codec->codec_type);\n\n        put_be32(pb, codec->bit_rate);\n\n        put_be32(pb, st->quality);\n\n        put_be32(pb, codec->flags);\n\n        put_be32(pb, codec->flags2);\n\n        put_be32(pb, codec->debug);\n\n        /* specific info */\n\n        switch(codec->codec_type) {\n\n        case CODEC_TYPE_VIDEO:\n\n            put_be32(pb, codec->time_base.num);\n\n            put_be32(pb, codec->time_base.den);\n\n            put_be16(pb, codec->width);\n\n            put_be16(pb, codec->height);\n\n            put_be16(pb, codec->gop_size);\n\n            put_be32(pb, codec->pix_fmt);\n\n            put_byte(pb, codec->qmin);\n\n            put_byte(pb, codec->qmax);\n\n            put_byte(pb, codec->max_qdiff);\n\n            put_be16(pb, (int) (codec->qcompress * 10000.0));\n\n            put_be16(pb, (int) (codec->qblur * 10000.0));\n\n            put_be32(pb, codec->bit_rate_tolerance);\n\n            put_strz(pb, codec->rc_eq);\n\n            put_be32(pb, codec->rc_max_rate);\n\n            put_be32(pb, codec->rc_min_rate);\n\n            put_be32(pb, codec->rc_buffer_size);\n\n            put_be64(pb, av_dbl2int(codec->i_quant_factor));\n\n            put_be64(pb, av_dbl2int(codec->b_quant_factor));\n\n            put_be64(pb, av_dbl2int(codec->i_quant_offset));\n\n            put_be64(pb, av_dbl2int(codec->b_quant_offset));\n\n            put_be32(pb, codec->dct_algo);\n\n            put_be32(pb, codec->strict_std_compliance);\n\n            put_be32(pb, codec->max_b_frames);\n\n            put_be32(pb, codec->luma_elim_threshold);\n\n            put_be32(pb, codec->chroma_elim_threshold);\n\n            put_be32(pb, codec->mpeg_quant);\n\n            put_be32(pb, codec->intra_dc_precision);\n\n            put_be32(pb, codec->me_method);\n\n            put_be32(pb, codec->mb_decision);\n\n            put_be32(pb, codec->nsse_weight);\n\n            put_be32(pb, codec->frame_skip_cmp);\n\n            put_be64(pb, av_dbl2int(codec->rc_buffer_aggressivity));\n\n            put_be32(pb, codec->codec_tag);\n\n            break;\n\n        case CODEC_TYPE_AUDIO:\n\n            put_be32(pb, codec->sample_rate);\n\n            put_le16(pb, codec->channels);\n\n            put_le16(pb, codec->frame_size);\n\n            break;\n\n        default:\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    /* hack to have real time */\n\n    if (ffm_nopts)\n\n        ffm->start_time = 0;\n\n    else\n\n        ffm->start_time = av_gettime();\n\n\n\n    /* flush until end of block reached */\n\n    while ((url_ftell(pb) % ffm->packet_size) != 0)\n\n        put_byte(pb, 0);\n\n\n\n    put_flush_packet(pb);\n\n\n\n    /* init packet mux */\n\n    ffm->packet_ptr = ffm->packet;\n\n    ffm->packet_end = ffm->packet + ffm->packet_size - FFM_HEADER_SIZE;\n\n    assert(ffm->packet_end >= ffm->packet);\n\n    ffm->frame_offset = 0;\n\n    ffm->pts = 0;\n\n    ffm->first_packet = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 26548}
{"project": "FFmpeg", "commit_id": "508a24f8dc63e74bd9917e6f0c4cdbb744741ef0", "target": 0, "func": "static av_cold int mpeg_mc_decode_init(AVCodecContext *avctx){\n\n    if( avctx->thread_count > 1)\n\n        return -1;\n\n    if( !(avctx->slice_flags & SLICE_FLAG_CODED_ORDER) )\n\n        return -1;\n\n    if( !(avctx->slice_flags & SLICE_FLAG_ALLOW_FIELD) ){\n\n        av_dlog(avctx, \"mpeg12.c: XvMC decoder will work better if SLICE_FLAG_ALLOW_FIELD is set\\n\");\n\n    }\n\n    mpeg_decode_init(avctx);\n\n\n\n    avctx->pix_fmt = PIX_FMT_XVMC_MPEG2_IDCT;\n\n    avctx->xvmc_acceleration = 2;//2 - the blocks are packed!\n\n\n\n    return 0;\n\n}\n", "idx": 26555}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static int avs_read_packet(AVFormatContext * s, AVPacket * pkt)\n\n{\n\n    AvsFormat *avs = s->priv_data;\n\n    int sub_type = 0, size = 0;\n\n    AvsBlockType type = AVS_NONE;\n\n    int palette_size = 0;\n\n    uint8_t palette[4 + 3 * 256];\n\n    int ret;\n\n\n\n    if (avs->remaining_audio_size > 0)\n\n        if (avs_read_audio_packet(s, pkt) > 0)\n\n            return 0;\n\n\n\n    while (1) {\n\n        if (avs->remaining_frame_size <= 0) {\n\n            if (!avio_rl16(s->pb))    /* found EOF */\n\n                return AVERROR(EIO);\n\n            avs->remaining_frame_size = avio_rl16(s->pb) - 4;\n\n        }\n\n\n\n        while (avs->remaining_frame_size > 0) {\n\n            sub_type = avio_r8(s->pb);\n\n            type = avio_r8(s->pb);\n\n            size = avio_rl16(s->pb);\n\n            if (size < 4)\n\n                return AVERROR_INVALIDDATA;\n\n            avs->remaining_frame_size -= size;\n\n\n\n            switch (type) {\n\n            case AVS_PALETTE:\n\n                if (size - 4 > sizeof(palette))\n\n                    return AVERROR_INVALIDDATA;\n\n                ret = avio_read(s->pb, palette, size - 4);\n\n                if (ret < size - 4)\n\n                    return AVERROR(EIO);\n\n                palette_size = size;\n\n                break;\n\n\n\n            case AVS_VIDEO:\n\n                if (!avs->st_video) {\n\n                    avs->st_video = avformat_new_stream(s, NULL);\n\n                    if (avs->st_video == NULL)\n\n                        return AVERROR(ENOMEM);\n\n                    avs->st_video->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n                    avs->st_video->codec->codec_id = AV_CODEC_ID_AVS;\n\n                    avs->st_video->codec->width = avs->width;\n\n                    avs->st_video->codec->height = avs->height;\n\n                    avs->st_video->codec->bits_per_coded_sample=avs->bits_per_sample;\n\n                    avs->st_video->nb_frames = avs->nb_frames;\n\n                    avs->st_video->avg_frame_rate = (AVRational){avs->fps, 1};\n\n                }\n\n                return avs_read_video_packet(s, pkt, type, sub_type, size,\n\n                                             palette, palette_size);\n\n\n\n            case AVS_AUDIO:\n\n                if (!avs->st_audio) {\n\n                    avs->st_audio = avformat_new_stream(s, NULL);\n\n                    if (avs->st_audio == NULL)\n\n                        return AVERROR(ENOMEM);\n\n                    avs->st_audio->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n                }\n\n                avs->remaining_audio_size = size - 4;\n\n                size = avs_read_audio_packet(s, pkt);\n\n                if (size != 0)\n\n                    return size;\n\n                break;\n\n\n\n            default:\n\n                avio_skip(s->pb, size - 4);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 26556}
{"project": "FFmpeg", "commit_id": "beefafda639dd53fc59c21d8a7cf8334da9a1062", "target": 1, "func": "static inline int wv_get_value_integer(WavpackFrameContext *s, uint32_t *crc, int S)\n\n{\n\n    int bit;\n\n\n\n    if(s->extra_bits){\n\n        S <<= s->extra_bits;\n\n\n\n        if(s->got_extra_bits){\n\n            S |= get_bits(&s->gb_extra_bits, s->extra_bits);\n\n            *crc = *crc * 9 + (S&0xffff) * 3 + ((unsigned)S>>16);\n\n        }\n\n    }\n\n    bit = (S & s->and) | s->or;\n\n    return (((S + bit) << s->shift) - bit) << s->post_shift;\n\n}\n", "idx": 26559}
{"project": "FFmpeg", "commit_id": "79ff462e73e73591573bcd01e8ee6614b7ac1c69", "target": 1, "func": "static int bfi_decode_frame(AVCodecContext * avctx, void *data,\n\n                            int *data_size, const uint8_t * buf,\n\n                            int buf_size)\n\n{\n\n    BFIContext *bfi = avctx->priv_data;\n\n    uint8_t *dst = bfi->dst;\n\n    uint8_t *src, *dst_offset, colour1, colour2;\n\n    uint8_t *frame_end = bfi->dst + avctx->width * avctx->height;\n\n    uint32_t *pal;\n\n    int i, j, height = avctx->height;\n\n\n\n    if (bfi->frame.data[0])\n\n        avctx->release_buffer(avctx, &bfi->frame);\n\n\n\n    bfi->frame.reference = 1;\n\n\n\n    if (avctx->get_buffer(avctx, &bfi->frame) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* Set frame parameters and palette, if necessary */\n\n    if (!avctx->frame_number) {\n\n        bfi->frame.pict_type = FF_I_TYPE;\n\n        bfi->frame.key_frame = 1;\n\n        /* Setting the palette */\n\n        if(avctx->extradata_size>768) {\n\n            av_log(NULL, AV_LOG_ERROR, \"Palette is too large.\\n\");\n\n            return -1;\n\n        }\n\n        pal = (uint32_t *) bfi->frame.data[1];\n\n        for (i = 0; i < avctx->extradata_size / 3; i++) {\n\n            int shift = 16;\n\n            *pal = 0;\n\n            for (j = 0; j < 3; j++, shift -= 8)\n\n                *pal +=\n\n                    ((avctx->extradata[i * 3 + j] << 2) |\n\n                    (avctx->extradata[i * 3 + j] >> 4)) << shift;\n\n            pal++;\n\n        }\n\n        bfi->frame.palette_has_changed = 1;\n\n    } else {\n\n        bfi->frame.pict_type = FF_P_TYPE;\n\n        bfi->frame.key_frame = 0;\n\n    }\n\n\n\n    buf += 4; //Unpacked size, not required.\n\n\n\n    while (dst != frame_end) {\n\n        static const uint8_t lentab[4]={0,2,0,1};\n\n        unsigned int byte = *buf++, offset;\n\n        unsigned int code = byte >> 6;\n\n        unsigned int length = byte & ~0xC0;\n\n\n\n        /* Get length and offset(if required) */\n\n        if (length == 0) {\n\n            if (code == 1) {\n\n                length = bytestream_get_byte(&buf);\n\n                offset = bytestream_get_le16(&buf);\n\n            } else {\n\n                length = bytestream_get_le16(&buf);\n\n                if (code == 2 && length == 0)\n\n                    break;\n\n            }\n\n        } else {\n\n            if (code == 1)\n\n                offset = bytestream_get_byte(&buf);\n\n        }\n\n\n\n        /* Do boundary check */\n\n        if (dst + (length<<lentab[code]) > frame_end)\n\n            break;\n\n\n\n        switch (code) {\n\n\n\n        case 0:                //Normal Chain\n\n            bytestream_get_buffer(&buf, dst, length);\n\n            dst += length;\n\n            break;\n\n\n\n        case 1:                //Back Chain\n\n            dst_offset = dst - offset;\n\n            length *= 4;        //Convert dwords to bytes.\n\n            if (dst_offset < bfi->dst)\n\n                break;\n\n            while (length--)\n\n                *dst++ = *dst_offset++;\n\n            break;\n\n\n\n        case 2:                //Skip Chain\n\n            dst += length;\n\n            break;\n\n\n\n        case 3:                //Fill Chain\n\n            colour1 = bytestream_get_byte(&buf);\n\n            colour2 = bytestream_get_byte(&buf);\n\n            while (length--) {\n\n                *dst++ = colour1;\n\n                *dst++ = colour2;\n\n            }\n\n            break;\n\n\n\n        }\n\n    }\n\n\n\n    src = bfi->dst;\n\n    dst = bfi->frame.data[0];\n\n    while (height--) {\n\n        memcpy(dst, src, avctx->width);\n\n        src += avctx->width;\n\n        dst += bfi->frame.linesize[0];\n\n    }\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame *) data = bfi->frame;\n\n    return buf_size;\n\n}\n", "idx": 26561}
{"project": "FFmpeg", "commit_id": "42f9132218ca11a8e9a3c82a175b46bca092113e", "target": 0, "func": "static int mxf_read_seek(AVFormatContext *s, int stream_index, int64_t sample_time, int flags)\n\n{\n\n    AVStream *st = s->streams[stream_index];\n\n    int64_t seconds;\n\n    MXFContext* mxf = s->priv_data;\n\n    int64_t seekpos;\n\n    int ret;\n\n    MXFIndexTable *t;\n\n\n\n    if (mxf->nb_index_tables <= 0) {\n\n    if (!s->bit_rate)\n\n        return AVERROR_INVALIDDATA;\n\n    if (sample_time < 0)\n\n        sample_time = 0;\n\n    seconds = av_rescale(sample_time, st->time_base.num, st->time_base.den);\n\n\n\n    if ((ret = avio_seek(s->pb, (s->bit_rate * seconds) >> 3, SEEK_SET)) < 0)\n\n        return ret;\n\n    ff_update_cur_dts(s, st, sample_time);\n\n    mxf->current_edit_unit = sample_time;\n\n    } else {\n\n        t = &mxf->index_tables[0];\n\n\n\n        /* clamp above zero, else ff_index_search_timestamp() returns negative\n\n         * this also means we allow seeking before the start */\n\n        sample_time = FFMAX(sample_time, 0);\n\n\n\n        if (t->fake_index) {\n\n            /* behave as if we have a proper index */\n\n            if ((sample_time = ff_index_search_timestamp(t->fake_index, t->nb_ptses, sample_time, flags)) < 0)\n\n                return sample_time;\n\n        } else {\n\n            /* no IndexEntryArray (one or more CBR segments)\n\n             * make sure we don't seek past the end */\n\n            sample_time = FFMIN(sample_time, st->duration - 1);\n\n        }\n\n\n\n        if ((ret = mxf_edit_unit_absolute_offset(mxf, t, sample_time, &sample_time, &seekpos, 1)) << 0)\n\n            return ret;\n\n\n\n        ff_update_cur_dts(s, st, sample_time);\n\n        mxf->current_edit_unit = sample_time;\n\n        avio_seek(s->pb, seekpos, SEEK_SET);\n\n    }\n\n    return 0;\n\n}\n", "idx": 26568}
{"project": "FFmpeg", "commit_id": "50ce510ac4e3ed093c051738242a9a75aeeb36ce", "target": 0, "func": "static int thread_execute(AVCodecContext *avctx, action_func* func, void *arg, int *ret, int job_count, int job_size)\n\n{\n\n    SliceThreadContext *c = avctx->internal->thread_ctx;\n\n    int dummy_ret;\n\n\n\n    if (!(avctx->active_thread_type&FF_THREAD_SLICE) || avctx->thread_count <= 1)\n\n        return avcodec_default_execute(avctx, func, arg, ret, job_count, job_size);\n\n\n\n    if (job_count <= 0)\n\n        return 0;\n\n\n\n    pthread_mutex_lock(&c->current_job_lock);\n\n\n\n    c->current_job = avctx->thread_count;\n\n    c->job_count = job_count;\n\n    c->job_size = job_size;\n\n    c->args = arg;\n\n    c->func = func;\n\n    if (ret) {\n\n        c->rets = ret;\n\n        c->rets_count = job_count;\n\n    } else {\n\n        c->rets = &dummy_ret;\n\n        c->rets_count = 1;\n\n    }\n\n    c->current_execute++;\n\n    pthread_cond_broadcast(&c->current_job_cond);\n\n\n\n    thread_park_workers(c, avctx->thread_count);\n\n\n\n    return 0;\n\n}\n", "idx": 26579}
{"project": "FFmpeg", "commit_id": "e8a3498f2452ba2be605b1ffb5974143095aacf1", "target": 1, "func": "static void chs_assemble_msbs_lsbs(DCAXllDecoder *s, DCAXllChSet *c, int band)\n\n{\n\n    DCAXllBand *b = &c->bands[band];\n\n    int n, ch, nsamples = s->nframesamples;\n\n\n\n    for (ch = 0; ch < c->nchannels; ch++) {\n\n        int shift = chs_get_lsb_width(s, c, band, ch);\n\n        if (shift) {\n\n            int32_t *msb = b->msb_sample_buffer[ch];\n\n            if (b->nscalablelsbs[ch]) {\n\n                int32_t *lsb = b->lsb_sample_buffer[ch];\n\n                int adj = b->bit_width_adjust[ch];\n\n                for (n = 0; n < nsamples; n++)\n\n                    msb[n] = msb[n] * (1 << shift) + (lsb[n] << adj);\n\n            } else {\n\n                for (n = 0; n < nsamples; n++)\n\n                    msb[n] = msb[n] * (1 << shift);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 26581}
{"project": "FFmpeg", "commit_id": "5a3a906ba29b53fa34d3047af78d9f8fd7678256", "target": 1, "func": "static av_cold int vqa_decode_init(AVCodecContext *avctx)\n\n{\n\n    VqaContext *s = avctx->priv_data;\n\n    unsigned char *vqa_header;\n\n    int i, j, codebook_index;\n\n\n\n    s->avctx = avctx;\n\n    avctx->pix_fmt = PIX_FMT_PAL8;\n\n\n\n    /* make sure the extradata made it */\n\n    if (s->avctx->extradata_size != VQA_HEADER_SIZE) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"  VQA video: expected extradata size of %d\\n\", VQA_HEADER_SIZE);\n\n        return -1;\n\n    }\n\n\n\n    /* load up the VQA parameters from the header */\n\n    vqa_header = (unsigned char *)s->avctx->extradata;\n\n    s->vqa_version = vqa_header[0];\n\n    s->width = AV_RL16(&vqa_header[6]);\n\n    s->height = AV_RL16(&vqa_header[8]);\n\n    if(av_image_check_size(s->width, s->height, 0, avctx)){\n\n        s->width= s->height= 0;\n\n        return -1;\n\n    }\n\n    s->vector_width = vqa_header[10];\n\n    s->vector_height = vqa_header[11];\n\n    s->partial_count = s->partial_countdown = vqa_header[13];\n\n\n\n    /* the vector dimensions have to meet very stringent requirements */\n\n    if ((s->vector_width != 4) ||\n\n        ((s->vector_height != 2) && (s->vector_height != 4))) {\n\n        /* return without further initialization */\n\n        return -1;\n\n    }\n\n\n\n    /* allocate codebooks */\n\n    s->codebook_size = MAX_CODEBOOK_SIZE;\n\n    s->codebook = av_malloc(s->codebook_size);\n\n    if (!s->codebook)\n\n        goto fail;\n\n    s->next_codebook_buffer = av_malloc(s->codebook_size);\n\n    if (!s->next_codebook_buffer)\n\n        goto fail;\n\n\n\n    /* allocate decode buffer */\n\n    s->decode_buffer_size = (s->width / s->vector_width) *\n\n        (s->height / s->vector_height) * 2;\n\n    s->decode_buffer = av_malloc(s->decode_buffer_size);\n\n    if (!s->decode_buffer)\n\n        goto fail;\n\n\n\n    /* initialize the solid-color vectors */\n\n    if (s->vector_height == 4) {\n\n        codebook_index = 0xFF00 * 16;\n\n        for (i = 0; i < 256; i++)\n\n            for (j = 0; j < 16; j++)\n\n                s->codebook[codebook_index++] = i;\n\n    } else {\n\n        codebook_index = 0xF00 * 8;\n\n        for (i = 0; i < 256; i++)\n\n            for (j = 0; j < 8; j++)\n\n                s->codebook[codebook_index++] = i;\n\n    }\n\n    s->next_codebook_buffer_index = 0;\n\n\n\n    s->frame.data[0] = NULL;\n\n\n\n    return 0;\n\nfail:\n\n    av_freep(&s->codebook);\n\n    av_freep(&s->next_codebook_buffer);\n\n    av_freep(&s->decode_buffer);\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 26583}
{"project": "FFmpeg", "commit_id": "5d20f19be25c973fe10d0d17db9245002585710d", "target": 1, "func": "static void init_multbl2(uint8_t tbl[1024], const int c[4],\n\n                         const uint8_t *log8, const uint8_t *alog8,\n\n                         const uint8_t *sbox)\n\n{\n\n    int i, j;\n\n\n\n    for (i = 0; i < 1024; i++) {\n\n        int x = sbox[i >> 2];\n\n        if (x)\n\n            tbl[i] = alog8[log8[x] + log8[c[i & 3]]];\n\n    }\n\n#if !CONFIG_SMALL\n\n    for (j = 256; j < 1024; j++)\n\n        for (i = 0; i < 4; i++)\n\n            tbl[4*j + i] = tbl[4*j + ((i - 1) & 3) - 1024];\n\n#endif\n\n}\n", "idx": 26584}
{"project": "FFmpeg", "commit_id": "14e4e26559697cfdea584767be4e68474a0a9c7f", "target": 1, "func": "static int t27(InterplayACMContext *s, unsigned ind, unsigned col)\n\n{\n\n    GetBitContext *gb = &s->gb;\n\n    unsigned i, b;\n\n    int n1, n2, n3;\n\n\n\n    for (i = 0; i < s->rows; i++) {\n\n        /* b = (x1) + (x2 * 5) + (x3 * 25) */\n\n        b = get_bits(gb, 7);\n\n\n\n\n\n\n\n        n1 =  (mul_3x5[b] & 0x0F) - 2;\n\n        n2 = ((mul_3x5[b] >> 4) & 0x0F) - 2;\n\n        n3 = ((mul_3x5[b] >> 8) & 0x0F) - 2;\n\n\n\n        set_pos(s, i++, col, n1);\n\n        if (i >= s->rows)\n\n            break;\n\n        set_pos(s, i++, col, n2);\n\n        if (i >= s->rows)\n\n            break;\n\n        set_pos(s, i, col, n3);\n\n\n    return 0;\n", "idx": 26585}
{"project": "FFmpeg", "commit_id": "ddd7559ad97d3cde401ce096262af6375685ea22", "target": 1, "func": "static int decode_residual(H264Context *h, GetBitContext *gb, DCTELEM *block, int n, const uint8_t *scantable, const uint32_t *qmul, int max_coeff){\n\n    MpegEncContext * const s = &h->s;\n\n    static const int coeff_token_table_index[17]= {0, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3};\n\n    int level[16];\n\n    int zeros_left, coeff_token, total_coeff, i, trailing_ones, run_before;\n\n\n\n    //FIXME put trailing_onex into the context\n\n\n\n    if(max_coeff <= 8){\n\n        if (max_coeff == 4)\n\n            coeff_token = get_vlc2(gb, chroma_dc_coeff_token_vlc.table, CHROMA_DC_COEFF_TOKEN_VLC_BITS, 1);\n\n        else\n\n            coeff_token = get_vlc2(gb, chroma422_dc_coeff_token_vlc.table, CHROMA422_DC_COEFF_TOKEN_VLC_BITS, 1);\n\n        total_coeff= coeff_token>>2;\n\n    }else{\n\n        if(n >= LUMA_DC_BLOCK_INDEX){\n\n            total_coeff= pred_non_zero_count(h, (n - LUMA_DC_BLOCK_INDEX)*16);\n\n            coeff_token= get_vlc2(gb, coeff_token_vlc[ coeff_token_table_index[total_coeff] ].table, COEFF_TOKEN_VLC_BITS, 2);\n\n            total_coeff= coeff_token>>2;\n\n        }else{\n\n            total_coeff= pred_non_zero_count(h, n);\n\n            coeff_token= get_vlc2(gb, coeff_token_vlc[ coeff_token_table_index[total_coeff] ].table, COEFF_TOKEN_VLC_BITS, 2);\n\n            total_coeff= coeff_token>>2;\n\n        }\n\n    }\n\n    h->non_zero_count_cache[ scan8[n] ]= total_coeff;\n\n\n\n    //FIXME set last_non_zero?\n\n\n\n    if(total_coeff==0)\n\n        return 0;\n\n    if(total_coeff > (unsigned)max_coeff) {\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"corrupted macroblock %d %d (total_coeff=%d)\\n\", s->mb_x, s->mb_y, total_coeff);\n\n        return -1;\n\n    }\n\n\n\n    trailing_ones= coeff_token&3;\n\n    tprintf(h->s.avctx, \"trailing:%d, total:%d\\n\", trailing_ones, total_coeff);\n\n    assert(total_coeff<=16);\n\n\n\n    i = show_bits(gb, 3);\n\n    skip_bits(gb, trailing_ones);\n\n    level[0] = 1-((i&4)>>1);\n\n    level[1] = 1-((i&2)   );\n\n    level[2] = 1-((i&1)<<1);\n\n\n\n    if(trailing_ones<total_coeff) {\n\n        int mask, prefix;\n\n        int suffix_length = total_coeff > 10 & trailing_ones < 3;\n\n        int bitsi= show_bits(gb, LEVEL_TAB_BITS);\n\n        int level_code= cavlc_level_tab[suffix_length][bitsi][0];\n\n\n\n        skip_bits(gb, cavlc_level_tab[suffix_length][bitsi][1]);\n\n        if(level_code >= 100){\n\n            prefix= level_code - 100;\n\n            if(prefix == LEVEL_TAB_BITS)\n\n                prefix += get_level_prefix(gb);\n\n\n\n            //first coefficient has suffix_length equal to 0 or 1\n\n            if(prefix<14){ //FIXME try to build a large unified VLC table for all this\n\n                if(suffix_length)\n\n                    level_code= (prefix<<1) + get_bits1(gb); //part\n\n                else\n\n                    level_code= prefix; //part\n\n            }else if(prefix==14){\n\n                if(suffix_length)\n\n                    level_code= (prefix<<1) + get_bits1(gb); //part\n\n                else\n\n                    level_code= prefix + get_bits(gb, 4); //part\n\n            }else{\n\n                level_code= 30 + get_bits(gb, prefix-3); //part\n\n                if(prefix>=16){\n\n                    if(prefix > 25+3){\n\n                        av_log(h->s.avctx, AV_LOG_ERROR, \"Invalid level prefix\\n\");\n\n                        return -1;\n\n                    }\n\n                    level_code += (1<<(prefix-3))-4096;\n\n                }\n\n            }\n\n\n\n            if(trailing_ones < 3) level_code += 2;\n\n\n\n            suffix_length = 2;\n\n            mask= -(level_code&1);\n\n            level[trailing_ones]= (((2+level_code)>>1) ^ mask) - mask;\n\n        }else{\n\n            level_code += ((level_code>>31)|1) & -(trailing_ones < 3);\n\n\n\n            suffix_length = 1 + (level_code + 3U > 6U);\n\n            level[trailing_ones]= level_code;\n\n        }\n\n\n\n        //remaining coefficients have suffix_length > 0\n\n        for(i=trailing_ones+1;i<total_coeff;i++) {\n\n            static const unsigned int suffix_limit[7] = {0,3,6,12,24,48,INT_MAX };\n\n            int bitsi= show_bits(gb, LEVEL_TAB_BITS);\n\n            level_code= cavlc_level_tab[suffix_length][bitsi][0];\n\n\n\n            skip_bits(gb, cavlc_level_tab[suffix_length][bitsi][1]);\n\n            if(level_code >= 100){\n\n                prefix= level_code - 100;\n\n                if(prefix == LEVEL_TAB_BITS){\n\n                    prefix += get_level_prefix(gb);\n\n                }\n\n                if(prefix<15){\n\n                    level_code = (prefix<<suffix_length) + get_bits(gb, suffix_length);\n\n                }else{\n\n                    level_code = (15<<suffix_length) + get_bits(gb, prefix-3);\n\n                    if(prefix>=16)\n\n                        level_code += (1<<(prefix-3))-4096;\n\n                }\n\n                mask= -(level_code&1);\n\n                level_code= (((2+level_code)>>1) ^ mask) - mask;\n\n            }\n\n            level[i]= level_code;\n\n            suffix_length+= suffix_limit[suffix_length] + level_code > 2U*suffix_limit[suffix_length];\n\n        }\n\n    }\n\n\n\n    if(total_coeff == max_coeff)\n\n        zeros_left=0;\n\n    else{\n\n        if (max_coeff <= 8) {\n\n            if (max_coeff == 4)\n\n                zeros_left = get_vlc2(gb, chroma_dc_total_zeros_vlc[total_coeff - 1].table,\n\n                                      CHROMA_DC_TOTAL_ZEROS_VLC_BITS, 1);\n\n            else\n\n                zeros_left = get_vlc2(gb, chroma422_dc_total_zeros_vlc[total_coeff - 1].table,\n\n                                      CHROMA422_DC_TOTAL_ZEROS_VLC_BITS, 1);\n\n        } else {\n\n            zeros_left= get_vlc2(gb, total_zeros_vlc[total_coeff - 1].table, TOTAL_ZEROS_VLC_BITS, 1);\n\n        }\n\n    }\n\n\n\n#define STORE_BLOCK(type) \\\n\n    scantable += zeros_left + total_coeff - 1; \\\n\n    if(n >= LUMA_DC_BLOCK_INDEX){ \\\n\n        ((type*)block)[*scantable] = level[0]; \\\n\n        for(i=1;i<total_coeff && zeros_left > 0;i++) { \\\n\n            if(zeros_left < 7) \\\n\n                run_before= get_vlc2(gb, run_vlc[zeros_left - 1].table, RUN_VLC_BITS, 1); \\\n\n            else \\\n\n                run_before= get_vlc2(gb, run7_vlc.table, RUN7_VLC_BITS, 2); \\\n\n            zeros_left -= run_before; \\\n\n            scantable -= 1 + run_before; \\\n\n            ((type*)block)[*scantable]= level[i]; \\\n\n        } \\\n\n        for(;i<total_coeff;i++) { \\\n\n            scantable--; \\\n\n            ((type*)block)[*scantable]= level[i]; \\\n\n        } \\\n\n    }else{ \\\n\n        ((type*)block)[*scantable] = ((int)(level[0] * qmul[*scantable] + 32))>>6; \\\n\n        for(i=1;i<total_coeff && zeros_left > 0;i++) { \\\n\n            if(zeros_left < 7) \\\n\n                run_before= get_vlc2(gb, run_vlc[zeros_left - 1].table, RUN_VLC_BITS, 1); \\\n\n            else \\\n\n                run_before= get_vlc2(gb, run7_vlc.table, RUN7_VLC_BITS, 2); \\\n\n            zeros_left -= run_before; \\\n\n            scantable -= 1 + run_before; \\\n\n            ((type*)block)[*scantable]= ((int)(level[i] * qmul[*scantable] + 32))>>6; \\\n\n        } \\\n\n        for(;i<total_coeff;i++) { \\\n\n            scantable--; \\\n\n            ((type*)block)[*scantable]= ((int)(level[i] * qmul[*scantable] + 32))>>6; \\\n\n        } \\\n\n    }\n\n\n\n    if (h->pixel_shift) {\n\n        STORE_BLOCK(int32_t)\n\n    } else {\n\n        STORE_BLOCK(int16_t)\n\n    }\n\n\n\n    if(zeros_left<0){\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"negative number of zero coeffs at %d %d\\n\", s->mb_x, s->mb_y);\n\n        return -1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26586}
{"project": "FFmpeg", "commit_id": "d81be0a60a6dea2bc48ec29f9466eee63984ed34", "target": 1, "func": "static AVFrame *hwmap_get_buffer(AVFilterLink *inlink, int w, int h)\n\n{\n\n    AVFilterContext *avctx = inlink->dst;\n\n    AVFilterLink  *outlink = avctx->outputs[0];\n\n    HWMapContext      *ctx = avctx->priv;\n\n\n\n    if (ctx->map_backwards) {\n\n        AVFrame *src, *dst;\n\n        int err;\n\n\n\n        src = ff_get_video_buffer(outlink, w, h);\n\n        if (!src) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Failed to allocate source \"\n\n                   \"frame for software mapping.\\n\");\n\n            return NULL;\n\n        }\n\n\n\n        dst = av_frame_alloc();\n\n        if (!dst) {\n\n            av_frame_free(&src);\n\n            return NULL;\n\n        }\n\n\n\n        err = av_hwframe_map(dst, src, ctx->mode);\n\n        if (err) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Failed to map frame to \"\n\n                   \"software: %d.\\n\", err);\n\n            av_frame_free(&src);\n\n            av_frame_free(&dst);\n\n            return NULL;\n\n        }\n\n\n\n        av_frame_free(&src);\n\n        return dst;\n\n    } else {\n\n        return ff_default_get_video_buffer(inlink, w, h);\n\n    }\n\n}\n", "idx": 26588}
{"project": "FFmpeg", "commit_id": "29b0d94b43ac960cb442049a5d737a3386ff0337", "target": 1, "func": "static int decode_wdlt(uint8_t *frame, int width, int height,\n\n                       const uint8_t *src, const uint8_t *src_end)\n\n{\n\n    const uint8_t *frame_end   = frame + width * height;\n\n    uint8_t *line_ptr;\n\n    int count, i, v, lines, segments;\n\n\n\n    lines = bytestream_get_le16(&src);\n\n    if (lines > height || src >= src_end)\n\n        return -1;\n\n\n\n    while (lines--) {\n\n        segments = bytestream_get_le16(&src);\n\n        while ((segments & 0xC000) == 0xC000) {\n\n            unsigned delta = -((int16_t)segments * width);\n\n            if (frame_end - frame <= delta)\n\n                return -1;\n\n            frame    += delta;\n\n            segments = bytestream_get_le16(&src);\n\n        }\n\n        if (segments & 0x8000) {\n\n            frame[width - 1] = segments & 0xFF;\n\n            segments = bytestream_get_le16(&src);\n\n        }\n\n        line_ptr = frame;\n\n        frame += width;\n\n        while (segments--) {\n\n            if (src_end - src < 2)\n\n                return -1;\n\n            if (frame - line_ptr <= *src)\n\n                return -1;\n\n            line_ptr += *src++;\n\n            count = (int8_t)*src++;\n\n            if (count >= 0) {\n\n                if (frame - line_ptr < count*2 || src_end - src < count*2)\n\n                    return -1;\n\n                bytestream_get_buffer(&src, line_ptr, count*2);\n\n                line_ptr += count * 2;\n\n            } else {\n\n                count = -count;\n\n                if (frame - line_ptr < count*2 || src_end - src < 2)\n\n                    return -1;\n\n                v = bytestream_get_le16(&src);\n\n                for (i = 0; i < count; i++)\n\n                    bytestream_put_le16(&line_ptr, v);\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26589}
{"project": "FFmpeg", "commit_id": "6526976f0cbb3fa152797b3a15bd634ad14cabe3", "target": 0, "func": "av_cold void ff_vp8dsp_init_x86(VP8DSPContext* c)\n\n{\n\n    mm_flags = mm_support();\n\n\n\n#if HAVE_YASM\n\n    if (mm_flags & FF_MM_MMX) {\n\n        c->vp8_idct_dc_add                  = ff_vp8_idct_dc_add_mmx;\n\n        c->vp8_idct_add                     = ff_vp8_idct_add_mmx;\n\n        c->put_vp8_epel_pixels_tab[0][0][0]     =\n\n        c->put_vp8_bilinear_pixels_tab[0][0][0] = ff_put_vp8_pixels16_mmx;\n\n        c->put_vp8_epel_pixels_tab[1][0][0]     =\n\n        c->put_vp8_bilinear_pixels_tab[1][0][0] = ff_put_vp8_pixels8_mmx;\n\n\n\n        c->vp8_v_loop_filter_simple = ff_vp8_v_loop_filter_simple_mmx;\n\n        c->vp8_h_loop_filter_simple = ff_vp8_h_loop_filter_simple_mmx;\n\n\n\n        c->vp8_v_loop_filter16y_inner = ff_vp8_v_loop_filter16y_inner_mmx;\n\n        c->vp8_h_loop_filter16y_inner = ff_vp8_h_loop_filter16y_inner_mmx;\n\n        c->vp8_v_loop_filter8uv_inner = ff_vp8_v_loop_filter8uv_inner_mmx;\n\n        c->vp8_h_loop_filter8uv_inner = ff_vp8_h_loop_filter8uv_inner_mmx;\n\n    }\n\n\n\n    /* note that 4-tap width=16 functions are missing because w=16\n\n     * is only used for luma, and luma is always a copy or sixtap. */\n\n    if (mm_flags & FF_MM_MMX2) {\n\n        c->vp8_luma_dc_wht = ff_vp8_luma_dc_wht_mmxext;\n\n        VP8_LUMA_MC_FUNC(0, 16, mmxext);\n\n        VP8_MC_FUNC(1, 8, mmxext);\n\n        VP8_MC_FUNC(2, 4, mmxext);\n\n        VP8_BILINEAR_MC_FUNC(0, 16, mmxext);\n\n        VP8_BILINEAR_MC_FUNC(1, 8, mmxext);\n\n        VP8_BILINEAR_MC_FUNC(2, 4, mmxext);\n\n\n\n        c->vp8_v_loop_filter_simple = ff_vp8_v_loop_filter_simple_mmxext;\n\n        c->vp8_h_loop_filter_simple = ff_vp8_h_loop_filter_simple_mmxext;\n\n\n\n        c->vp8_v_loop_filter16y_inner = ff_vp8_v_loop_filter16y_inner_mmxext;\n\n        c->vp8_h_loop_filter16y_inner = ff_vp8_h_loop_filter16y_inner_mmxext;\n\n        c->vp8_v_loop_filter8uv_inner = ff_vp8_v_loop_filter8uv_inner_mmxext;\n\n        c->vp8_h_loop_filter8uv_inner = ff_vp8_h_loop_filter8uv_inner_mmxext;\n\n    }\n\n\n\n    if (mm_flags & FF_MM_SSE) {\n\n        c->put_vp8_epel_pixels_tab[0][0][0]     =\n\n        c->put_vp8_bilinear_pixels_tab[0][0][0] = ff_put_vp8_pixels16_sse;\n\n    }\n\n\n\n    if (mm_flags & FF_MM_SSE2) {\n\n        VP8_LUMA_MC_FUNC(0, 16, sse2);\n\n        VP8_MC_FUNC(1, 8, sse2);\n\n        VP8_BILINEAR_MC_FUNC(0, 16, sse2);\n\n        VP8_BILINEAR_MC_FUNC(1, 8, sse2);\n\n\n\n        c->vp8_v_loop_filter_simple = ff_vp8_v_loop_filter_simple_sse2;\n\n        c->vp8_h_loop_filter_simple = ff_vp8_h_loop_filter_simple_sse2;\n\n\n\n        c->vp8_v_loop_filter16y_inner = ff_vp8_v_loop_filter16y_inner_sse2;\n\n        c->vp8_h_loop_filter16y_inner = ff_vp8_h_loop_filter16y_inner_sse2;\n\n        c->vp8_v_loop_filter8uv_inner = ff_vp8_v_loop_filter8uv_inner_sse2;\n\n        c->vp8_h_loop_filter8uv_inner = ff_vp8_h_loop_filter8uv_inner_sse2;\n\n    }\n\n\n\n    if (mm_flags & FF_MM_SSSE3) {\n\n        VP8_LUMA_MC_FUNC(0, 16, ssse3);\n\n        VP8_MC_FUNC(1, 8, ssse3);\n\n        VP8_MC_FUNC(2, 4, ssse3);\n\n        VP8_BILINEAR_MC_FUNC(0, 16, ssse3);\n\n        VP8_BILINEAR_MC_FUNC(1, 8, ssse3);\n\n        VP8_BILINEAR_MC_FUNC(2, 4, ssse3);\n\n    }\n\n\n\n    if (mm_flags & FF_MM_SSE4) {\n\n        c->vp8_idct_dc_add                  = ff_vp8_idct_dc_add_sse4;\n\n    }\n\n#endif\n\n}\n", "idx": 26590}
{"project": "FFmpeg", "commit_id": "e1bd40fe6beb74a942b7b0cff2d077750a7e733e", "target": 0, "func": "PIX_SAD(mmxext)\n\n\n\n#endif /* HAVE_INLINE_ASM */\n\n\n\nav_cold void ff_dsputil_init_pix_mmx(DSPContext *c, AVCodecContext *avctx)\n\n{\n\n#if HAVE_INLINE_ASM\n\n    int cpu_flags = av_get_cpu_flags();\n\n\n\n    if (INLINE_MMX(cpu_flags)) {\n\n        c->pix_abs[0][0] = sad16_mmx;\n\n        c->pix_abs[0][1] = sad16_x2_mmx;\n\n        c->pix_abs[0][2] = sad16_y2_mmx;\n\n        c->pix_abs[0][3] = sad16_xy2_mmx;\n\n        c->pix_abs[1][0] = sad8_mmx;\n\n        c->pix_abs[1][1] = sad8_x2_mmx;\n\n        c->pix_abs[1][2] = sad8_y2_mmx;\n\n        c->pix_abs[1][3] = sad8_xy2_mmx;\n\n\n\n        c->sad[0] = sad16_mmx;\n\n        c->sad[1] = sad8_mmx;\n\n    }\n\n    if (INLINE_MMXEXT(cpu_flags)) {\n\n        c->pix_abs[0][0] = sad16_mmxext;\n\n        c->pix_abs[1][0] = sad8_mmxext;\n\n\n\n        c->sad[0] = sad16_mmxext;\n\n        c->sad[1] = sad8_mmxext;\n\n\n\n        if (!(avctx->flags & CODEC_FLAG_BITEXACT)) {\n\n            c->pix_abs[0][1] = sad16_x2_mmxext;\n\n            c->pix_abs[0][2] = sad16_y2_mmxext;\n\n            c->pix_abs[0][3] = sad16_xy2_mmxext;\n\n            c->pix_abs[1][1] = sad8_x2_mmxext;\n\n            c->pix_abs[1][2] = sad8_y2_mmxext;\n\n            c->pix_abs[1][3] = sad8_xy2_mmxext;\n\n        }\n\n    }\n\n    if (INLINE_SSE2(cpu_flags) && !(cpu_flags & AV_CPU_FLAG_3DNOW) && avctx->codec_id != AV_CODEC_ID_SNOW) {\n\n        c->sad[0] = sad16_sse2;\n\n    }\n\n#endif /* HAVE_INLINE_ASM */\n\n}\n", "idx": 26591}
{"project": "FFmpeg", "commit_id": "ca16618b01abfde44b4eaf92dc89b01aa1b4a91e", "target": 0, "func": "static int xan_decode_frame(AVCodecContext *avctx,\n\n                            void *data, int *data_size,\n\n                            uint8_t *buf, int buf_size)\n\n{\n\n    XanContext *s = avctx->priv_data;\n\n    AVPaletteControl *palette_control = avctx->palctrl;\n\n    int keyframe = 0;\n\n\n\n    if (palette_control->palette_changed) {\n\n        /* load the new palette and reset the palette control */\n\n        xan_wc3_build_palette(s, palette_control->palette);\n\n        /* If pal8 we clear flag when we copy palette */\n\n        if (s->avctx->pix_fmt != PIX_FMT_PAL8)\n\n            palette_control->palette_changed = 0;\n\n        keyframe = 1;\n\n    }\n\n\n\n    if (avctx->get_buffer(avctx, &s->current_frame)) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"  Xan Video: get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n    s->current_frame.reference = 3;\n\n\n\n    s->buf = buf;\n\n    s->size = buf_size;\n\n\n\n    if (avctx->codec->id == CODEC_ID_XAN_WC3)\n\n        xan_wc3_decode_frame(s);\n\n    else if (avctx->codec->id == CODEC_ID_XAN_WC4)\n\n        xan_wc4_decode_frame(s);\n\n\n\n    /* release the last frame if it is allocated */\n\n    if (s->last_frame.data[0])\n\n        avctx->release_buffer(avctx, &s->last_frame);\n\n\n\n    /* shuffle frames */\n\n    s->last_frame = s->current_frame;\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame*)data = s->current_frame;\n\n\n\n    /* always report that the buffer was completely consumed */\n\n    return buf_size;\n\n}\n", "idx": 26602}
{"project": "FFmpeg", "commit_id": "195784ec95266c69c111f1e977fd4cf4815c6d8d", "target": 0, "func": "static av_cold int libopenjpeg_encode_init(AVCodecContext *avctx)\n\n{\n\n    LibOpenJPEGContext *ctx = avctx->priv_data;\n\n    int err = 0;\n\n\n\n    opj_set_default_encoder_parameters(&ctx->enc_params);\n\n\n\n#if HAVE_OPENJPEG_2_1_OPENJPEG_H\n\n    switch (ctx->cinema_mode) {\n\n    case OPJ_CINEMA2K_24:\n\n        ctx->enc_params.rsiz = OPJ_PROFILE_CINEMA_2K;\n\n        ctx->enc_params.max_cs_size = OPJ_CINEMA_24_CS;\n\n        ctx->enc_params.max_comp_size = OPJ_CINEMA_24_COMP;\n\n        break;\n\n    case OPJ_CINEMA2K_48:\n\n        ctx->enc_params.rsiz = OPJ_PROFILE_CINEMA_2K;\n\n        ctx->enc_params.max_cs_size = OPJ_CINEMA_48_CS;\n\n        ctx->enc_params.max_comp_size = OPJ_CINEMA_48_COMP;\n\n        break;\n\n    case OPJ_CINEMA4K_24:\n\n        ctx->enc_params.rsiz = OPJ_PROFILE_CINEMA_4K;\n\n        ctx->enc_params.max_cs_size = OPJ_CINEMA_24_CS;\n\n        ctx->enc_params.max_comp_size = OPJ_CINEMA_24_COMP;\n\n        break;\n\n    }\n\n\n\n    switch (ctx->profile) {\n\n    case OPJ_CINEMA2K:\n\n        if (ctx->enc_params.rsiz == OPJ_PROFILE_CINEMA_4K) {\n\n            err = AVERROR(EINVAL);\n\n            break;\n\n        }\n\n        ctx->enc_params.rsiz = OPJ_PROFILE_CINEMA_2K;\n\n        break;\n\n    case OPJ_CINEMA4K:\n\n        if (ctx->enc_params.rsiz == OPJ_PROFILE_CINEMA_2K) {\n\n            err = AVERROR(EINVAL);\n\n            break;\n\n        }\n\n        ctx->enc_params.rsiz = OPJ_PROFILE_CINEMA_4K;\n\n        break;\n\n    }\n\n\n\n    if (err) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Invalid parameter pairing: cinema_mode and profile conflict.\\n\");\n\n        goto fail;\n\n    }\n\n#else\n\n    ctx->enc_params.cp_rsiz = ctx->profile;\n\n    ctx->enc_params.cp_cinema = ctx->cinema_mode;\n\n#endif\n\n\n\n    if (!ctx->numresolution) {\n\n        ctx->numresolution = 6;\n\n        while (FFMIN(avctx->width, avctx->height) >> ctx->numresolution < 1)\n\n            ctx->numresolution --;\n\n    }\n\n\n\n    ctx->enc_params.mode = !!avctx->global_quality;\n\n    ctx->enc_params.prog_order = ctx->prog_order;\n\n    ctx->enc_params.numresolution = ctx->numresolution;\n\n    ctx->enc_params.cp_disto_alloc = ctx->disto_alloc;\n\n    ctx->enc_params.cp_fixed_alloc = ctx->fixed_alloc;\n\n    ctx->enc_params.cp_fixed_quality = ctx->fixed_quality;\n\n    ctx->enc_params.tcp_numlayers = ctx->numlayers;\n\n    ctx->enc_params.tcp_rates[0] = FFMAX(avctx->compression_level, 0) * 2;\n\n\n\n    if (ctx->cinema_mode > 0) {\n\n        cinema_parameters(&ctx->enc_params);\n\n    }\n\n\n\n#if OPENJPEG_MAJOR_VERSION == 1\n\n    ctx->image = mj2_create_image(avctx, &ctx->enc_params);\n\n    if (!ctx->image) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error creating the mj2 image\\n\");\n\n        err = AVERROR(EINVAL);\n\n        goto fail;\n\n    }\n\n#endif // OPENJPEG_MAJOR_VERSION == 1\n\n\n\n    return 0;\n\n\n\nfail:\n\n#if OPENJPEG_MAJOR_VERSION == 1\n\n    opj_image_destroy(ctx->image);\n\n    ctx->image = NULL;\n\n#endif // OPENJPEG_MAJOR_VERSION == 1\n\n    return err;\n\n}\n", "idx": 26610}
{"project": "FFmpeg", "commit_id": "ef4c71e8f83a46fb31a11f0a066efb90821c579f", "target": 0, "func": "static void init_filter_param(AVFilterContext *ctx, FilterParam *fp, const char *effect_type, int width)\n\n{\n\n    int z;\n\n    const char *effect;\n\n\n\n    effect = fp->amount == 0 ? \"none\" : fp->amount < 0 ? \"blur\" : \"sharpen\";\n\n\n\n    av_log(ctx, AV_LOG_VERBOSE, \"effect:%s type:%s msize_x:%d msize_y:%d amount:%0.2f\\n\",\n\n           effect, effect_type, fp->msize_x, fp->msize_y, fp->amount / 65535.0);\n\n\n\n    for (z = 0; z < 2 * fp->steps_y; z++)\n\n        fp->sc[z] = av_malloc(sizeof(*(fp->sc[z])) * (width + 2 * fp->steps_x));\n\n}\n", "idx": 26611}
{"project": "FFmpeg", "commit_id": "5df703aa1b03814e9cd216ab703501481166b3bb", "target": 0, "func": "static inline void FUNC(idctRowCondDC_extrashift)(int16_t *row, int extra_shift)\n\n#else\n\nstatic inline void FUNC(idctRowCondDC)(int16_t *row, int extra_shift)\n\n#endif\n\n{\n\n    int a0, a1, a2, a3, b0, b1, b2, b3;\n\n\n\n#if HAVE_FAST_64BIT\n\n#define ROW0_MASK (0xffffLL << 48 * HAVE_BIGENDIAN)\n\n    if (((((uint64_t *)row)[0] & ~ROW0_MASK) | ((uint64_t *)row)[1]) == 0) {\n\n        uint64_t temp;\n\n        if (DC_SHIFT - extra_shift >= 0) {\n\n            temp = (row[0] * (1 << (DC_SHIFT - extra_shift))) & 0xffff;\n\n        } else {\n\n            temp = ((row[0] + (1<<(extra_shift - DC_SHIFT-1))) >> (extra_shift - DC_SHIFT)) & 0xffff;\n\n        }\n\n        temp += temp * (1 << 16);\n\n        temp += temp * ((uint64_t) 1 << 32);\n\n        ((uint64_t *)row)[0] = temp;\n\n        ((uint64_t *)row)[1] = temp;\n\n        return;\n\n    }\n\n#else\n\n    if (!(((uint32_t*)row)[1] |\n\n          ((uint32_t*)row)[2] |\n\n          ((uint32_t*)row)[3] |\n\n          row[1])) {\n\n        uint32_t temp;\n\n        if (DC_SHIFT - extra_shift >= 0) {\n\n            temp = (row[0] * (1 << (DC_SHIFT - extra_shift))) & 0xffff;\n\n        } else {\n\n            temp = ((row[0] + (1<<(extra_shift - DC_SHIFT-1))) >> (extra_shift - DC_SHIFT)) & 0xffff;\n\n        }\n\n        temp += temp * (1 << 16);\n\n        ((uint32_t*)row)[0]=((uint32_t*)row)[1] =\n\n            ((uint32_t*)row)[2]=((uint32_t*)row)[3] = temp;\n\n        return;\n\n    }\n\n#endif\n\n\n\n    a0 = (W4 * row[0]) + (1 << (ROW_SHIFT + extra_shift - 1));\n\n    a1 = a0;\n\n    a2 = a0;\n\n    a3 = a0;\n\n\n\n    a0 += W2 * row[2];\n\n    a1 += W6 * row[2];\n\n    a2 -= W6 * row[2];\n\n    a3 -= W2 * row[2];\n\n\n\n    b0 = MUL(W1, row[1]);\n\n    MAC(b0, W3, row[3]);\n\n    b1 = MUL(W3, row[1]);\n\n    MAC(b1, -W7, row[3]);\n\n    b2 = MUL(W5, row[1]);\n\n    MAC(b2, -W1, row[3]);\n\n    b3 = MUL(W7, row[1]);\n\n    MAC(b3, -W5, row[3]);\n\n\n\n    if (AV_RN64A(row + 4)) {\n\n        a0 +=   W4*row[4] + W6*row[6];\n\n        a1 += - W4*row[4] - W2*row[6];\n\n        a2 += - W4*row[4] + W2*row[6];\n\n        a3 +=   W4*row[4] - W6*row[6];\n\n\n\n        MAC(b0,  W5, row[5]);\n\n        MAC(b0,  W7, row[7]);\n\n\n\n        MAC(b1, -W1, row[5]);\n\n        MAC(b1, -W5, row[7]);\n\n\n\n        MAC(b2,  W7, row[5]);\n\n        MAC(b2,  W3, row[7]);\n\n\n\n        MAC(b3,  W3, row[5]);\n\n        MAC(b3, -W1, row[7]);\n\n    }\n\n\n\n    row[0] = (a0 + b0) >> (ROW_SHIFT + extra_shift);\n\n    row[7] = (a0 - b0) >> (ROW_SHIFT + extra_shift);\n\n    row[1] = (a1 + b1) >> (ROW_SHIFT + extra_shift);\n\n    row[6] = (a1 - b1) >> (ROW_SHIFT + extra_shift);\n\n    row[2] = (a2 + b2) >> (ROW_SHIFT + extra_shift);\n\n    row[5] = (a2 - b2) >> (ROW_SHIFT + extra_shift);\n\n    row[3] = (a3 + b3) >> (ROW_SHIFT + extra_shift);\n\n    row[4] = (a3 - b3) >> (ROW_SHIFT + extra_shift);\n\n}\n", "idx": 26612}
{"project": "FFmpeg", "commit_id": "9888ffb1ce5e0a17f711b01933d504c72ea29d3b", "target": 0, "func": "static int mov_read_stco(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st;\n\n    MOVStreamContext *sc;\n\n    unsigned int i, entries;\n\n\n\n    if (c->fc->nb_streams < 1)\n\n        return 0;\n\n    st = c->fc->streams[c->fc->nb_streams-1];\n\n    sc = st->priv_data;\n\n\n\n    avio_r8(pb); /* version */\n\n    avio_rb24(pb); /* flags */\n\n\n\n    entries = avio_rb32(pb);\n\n\n\n    if (!entries)\n\n        return 0;\n\n    if (entries >= UINT_MAX/sizeof(int64_t))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    sc->chunk_offsets = av_malloc(entries * sizeof(int64_t));\n\n    if (!sc->chunk_offsets)\n\n        return AVERROR(ENOMEM);\n\n    sc->chunk_count = entries;\n\n\n\n    if      (atom.type == MKTAG('s','t','c','o'))\n\n        for (i=0; i<entries; i++)\n\n            sc->chunk_offsets[i] = avio_rb32(pb);\n\n    else if (atom.type == MKTAG('c','o','6','4'))\n\n        for (i=0; i<entries; i++)\n\n            sc->chunk_offsets[i] = avio_rb64(pb);\n\n    else\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    return 0;\n\n}\n", "idx": 26613}
{"project": "FFmpeg", "commit_id": "9bff052b51f27f6cce04e8d7d8b405c710d7ad67", "target": 0, "func": "static void blur(uint8_t       *dst, const int dst_linesize,\n\n                 const uint8_t *src, const int src_linesize,\n\n                 const int w, const int h, FilterParam *fp)\n\n{\n\n    int x, y;\n\n    FilterParam f = *fp;\n\n    const int radius = f.dist_width/2;\n\n\n\n    const uint8_t * const src2[NB_PLANES] = { src };\n\n    int          src2_linesize[NB_PLANES] = { src_linesize };\n\n    uint8_t     *dst2[NB_PLANES] = { f.pre_filter_buf };\n\n    int dst2_linesize[NB_PLANES] = { f.pre_filter_linesize };\n\n\n\n    sws_scale(f.pre_filter_context, src2, src2_linesize, 0, h, dst2, dst2_linesize);\n\n\n\n#define UPDATE_FACTOR do {                                              \\\n\n        int factor;                                                     \\\n\n        factor = f.color_diff_coeff[COLOR_DIFF_COEFF_SIZE/2 + pre_val - \\\n\n                 f.pre_filter_buf[ix + iy*f.pre_filter_linesize]] * f.dist_coeff[dx + dy*f.dist_linesize]; \\\n\n        sum += src[ix + iy*src_linesize] * factor;                      \\\n\n        div += factor;                                                  \\\n\n    } while (0)\n\n\n\n    for (y = 0; y < h; y++) {\n\n        for (x = 0; x < w; x++) {\n\n            int sum = 0;\n\n            int div = 0;\n\n            int dy;\n\n            const int pre_val = f.pre_filter_buf[x + y*f.pre_filter_linesize];\n\n            if (x >= radius && x < w - radius) {\n\n                for (dy = 0; dy < radius*2 + 1; dy++) {\n\n                    int dx;\n\n                    int iy = y+dy - radius;\n\n                    if      (iy < 0)  iy = -iy;\n\n                    else if (iy >= h) iy = h+h-iy-1;\n\n\n\n                    for (dx = 0; dx < radius*2 + 1; dx++) {\n\n                        const int ix = x+dx - radius;\n\n                        UPDATE_FACTOR;\n\n                    }\n\n                }\n\n            } else {\n\n                for (dy = 0; dy < radius*2+1; dy++) {\n\n                    int dx;\n\n                    int iy = y+dy - radius;\n\n                    if      (iy <  0) iy = -iy;\n\n                    else if (iy >= h) iy = h+h-iy-1;\n\n\n\n                    for (dx = 0; dx < radius*2 + 1; dx++) {\n\n                        int ix = x+dx - radius;\n\n                        if      (ix < 0)  ix = -ix;\n\n                        else if (ix >= w) ix = w+w-ix-1;\n\n                        UPDATE_FACTOR;\n\n                    }\n\n                }\n\n            }\n\n            dst[x + y*dst_linesize] = (sum + div/2) / div;\n\n        }\n\n    }\n\n}\n", "idx": 26614}
{"project": "FFmpeg", "commit_id": "3faa303a47e0c3b59a53988e0f76018930c6cb1a", "target": 0, "func": "static inline void decode_subblock(DCTELEM *dst, int code, const int is_block2, GetBitContext *gb, VLC *vlc, int q)\n\n{\n\n    int coeffs[4];\n\n\n\n    coeffs[0] = modulo_three_table[code][0];\n\n    coeffs[1] = modulo_three_table[code][1];\n\n    coeffs[2] = modulo_three_table[code][2];\n\n    coeffs[3] = modulo_three_table[code][3];\n\n    decode_coeff(dst  , coeffs[0], 3, gb, vlc, q);\n\n    if(is_block2){\n\n        decode_coeff(dst+8, coeffs[1], 2, gb, vlc, q);\n\n        decode_coeff(dst+1, coeffs[2], 2, gb, vlc, q);\n\n    }else{\n\n        decode_coeff(dst+1, coeffs[1], 2, gb, vlc, q);\n\n        decode_coeff(dst+8, coeffs[2], 2, gb, vlc, q);\n\n    }\n\n    decode_coeff(dst+9, coeffs[3], 2, gb, vlc, q);\n\n}\n", "idx": 26615}
{"project": "FFmpeg", "commit_id": "fdbc544d29176ba69d67dd879df4696f0a19052e", "target": 1, "func": "static int process_metadata(AVFormatContext *s, uint8_t *name, uint16_t name_len,\n\n                            uint16_t val_len, uint16_t type, AVDictionary **met)\n\n{\n\n    int ret;\n\n    ff_asf_guid guid;\n\n\n\n    if (val_len) {\n\n        switch (type) {\n\n        case ASF_UNICODE:\n\n            asf_read_value(s, name, name_len, val_len, type, met);\n\n            break;\n\n        case ASF_BYTE_ARRAY:\n\n            if (!strcmp(name, \"WM/Picture\")) // handle cover art\n\n                asf_read_picture(s, val_len);\n\n            else if (!strcmp(name, \"ID3\")) // handle ID3 tag\n\n                get_id3_tag(s, val_len);\n\n            else\n\n                asf_read_value(s, name, name_len, val_len, type, met);\n\n            break;\n\n        case ASF_GUID:\n\n            ff_get_guid(s->pb, &guid);\n\n            break;\n\n        default:\n\n            if ((ret = asf_read_generic_value(s, name, name_len, type, met)) < 0)\n\n                return ret;\n\n            break;\n\n        }\n\n    }\n\n    av_freep(&name);\n\n\n\n    return 0;\n\n}\n", "idx": 26618}
{"project": "FFmpeg", "commit_id": "86736f59d6a527d8bc807d09b93f971c0fe0bb07", "target": 0, "func": "static void add_bytes_l2_c(uint8_t *dst, uint8_t *src1, uint8_t *src2, int w)\n\n{\n\n    long i;\n\n    for (i = 0; i <= w - sizeof(long); i += sizeof(long)) {\n\n        long a = *(long *)(src1 + i);\n\n        long b = *(long *)(src2 + i);\n\n        *(long *)(dst + i) = ((a & pb_7f) + (b & pb_7f)) ^ ((a ^ b) & pb_80);\n\n    }\n\n    for (; i < w; i++)\n\n        dst[i] = src1[i] + src2[i];\n\n}\n", "idx": 26622}
{"project": "FFmpeg", "commit_id": "fed50c4304eecb352e29ce789cdb96ea84d6162f", "target": 1, "func": "void av_set_cpu_flags_mask(int mask)\n\n{\n\n    cpu_flags = get_cpu_flags() & mask;\n\n}\n", "idx": 26626}
{"project": "FFmpeg", "commit_id": "21d8c6612fcec630785af5c0ae087d0393bb2a8e", "target": 1, "func": "static int decode_header_trees(SmackVContext *smk) {\n\n    GetBitContext gb;\n\n    int mmap_size, mclr_size, full_size, type_size, ret;\n\n\n\n    mmap_size = AV_RL32(smk->avctx->extradata);\n\n    mclr_size = AV_RL32(smk->avctx->extradata + 4);\n\n    full_size = AV_RL32(smk->avctx->extradata + 8);\n\n    type_size = AV_RL32(smk->avctx->extradata + 12);\n\n\n\n    init_get_bits8(&gb, smk->avctx->extradata + 16, smk->avctx->extradata_size - 16);\n\n\n\n    if(!get_bits1(&gb)) {\n\n        av_log(smk->avctx, AV_LOG_INFO, \"Skipping MMAP tree\\n\");\n\n        smk->mmap_tbl = av_malloc(sizeof(int) * 2);\n\n        if (!smk->mmap_tbl)\n\n            return AVERROR(ENOMEM);\n\n        smk->mmap_tbl[0] = 0;\n\n        smk->mmap_last[0] = smk->mmap_last[1] = smk->mmap_last[2] = 1;\n\n    } else {\n\n        ret = smacker_decode_header_tree(smk, &gb, &smk->mmap_tbl, smk->mmap_last, mmap_size);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n    if(!get_bits1(&gb)) {\n\n        av_log(smk->avctx, AV_LOG_INFO, \"Skipping MCLR tree\\n\");\n\n        smk->mclr_tbl = av_malloc(sizeof(int) * 2);\n\n        if (!smk->mclr_tbl)\n\n            return AVERROR(ENOMEM);\n\n        smk->mclr_tbl[0] = 0;\n\n        smk->mclr_last[0] = smk->mclr_last[1] = smk->mclr_last[2] = 1;\n\n    } else {\n\n        ret = smacker_decode_header_tree(smk, &gb, &smk->mclr_tbl, smk->mclr_last, mclr_size);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n    if(!get_bits1(&gb)) {\n\n        av_log(smk->avctx, AV_LOG_INFO, \"Skipping FULL tree\\n\");\n\n        smk->full_tbl = av_malloc(sizeof(int) * 2);\n\n        if (!smk->full_tbl)\n\n            return AVERROR(ENOMEM);\n\n        smk->full_tbl[0] = 0;\n\n        smk->full_last[0] = smk->full_last[1] = smk->full_last[2] = 1;\n\n    } else {\n\n        ret = smacker_decode_header_tree(smk, &gb, &smk->full_tbl, smk->full_last, full_size);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n    if(!get_bits1(&gb)) {\n\n        av_log(smk->avctx, AV_LOG_INFO, \"Skipping TYPE tree\\n\");\n\n        smk->type_tbl = av_malloc(sizeof(int) * 2);\n\n        if (!smk->type_tbl)\n\n            return AVERROR(ENOMEM);\n\n        smk->type_tbl[0] = 0;\n\n        smk->type_last[0] = smk->type_last[1] = smk->type_last[2] = 1;\n\n    } else {\n\n        ret = smacker_decode_header_tree(smk, &gb, &smk->type_tbl, smk->type_last, type_size);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26627}
{"project": "FFmpeg", "commit_id": "bd737b5178f361a9b592691848f29a7a79603a7e", "target": 0, "func": "static int decode_init_thread_copy(AVCodecContext *avctx)\n\n{\n\n    H264Context *h = avctx->priv_data;\n\n    int ret;\n\n\n\n    if (!avctx->internal->is_copy)\n\n        return 0;\n\n    memset(h->sps_buffers, 0, sizeof(h->sps_buffers));\n\n    memset(h->pps_buffers, 0, sizeof(h->pps_buffers));\n\n\n\n    ret = h264_init_context(avctx, h);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    h->context_initialized = 0;\n\n\n\n    return 0;\n\n}\n", "idx": 26629}
{"project": "FFmpeg", "commit_id": "6dfffe92004dfd8c79d18791f28a2b1c7e387845", "target": 0, "func": "av_cold static int auto_matrix(SwrContext *s)\n\n{\n\n    int i, j, out_i;\n\n    double matrix[64][64]={{0}};\n\n    int64_t unaccounted, in_ch_layout, out_ch_layout;\n\n    double maxcoef=0;\n\n    char buf[128];\n\n    const int matrix_encoding = s->matrix_encoding;\n\n    float maxval;\n\n\n\n    in_ch_layout = clean_layout(s, s->in_ch_layout);\n\n    if(!sane_layout(in_ch_layout)){\n\n        av_get_channel_layout_string(buf, sizeof(buf), -1, s->in_ch_layout);\n\n        av_log(s, AV_LOG_ERROR, \"Input channel layout '%s' is not supported\\n\", buf);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    out_ch_layout = clean_layout(s, s->out_ch_layout);\n\n    if(!sane_layout(out_ch_layout)){\n\n        av_get_channel_layout_string(buf, sizeof(buf), -1, s->out_ch_layout);\n\n        av_log(s, AV_LOG_ERROR, \"Output channel layout '%s' is not supported\\n\", buf);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    memset(s->matrix, 0, sizeof(s->matrix));\n\n    for(i=0; i<64; i++){\n\n        if(in_ch_layout & out_ch_layout & (1ULL<<i))\n\n            matrix[i][i]= 1.0;\n\n    }\n\n\n\n    unaccounted= in_ch_layout & ~out_ch_layout;\n\n\n\n//FIXME implement dolby surround\n\n//FIXME implement full ac3\n\n\n\n\n\n    if(unaccounted & AV_CH_FRONT_CENTER){\n\n        if((out_ch_layout & AV_CH_LAYOUT_STEREO) == AV_CH_LAYOUT_STEREO){\n\n            if(in_ch_layout & AV_CH_LAYOUT_STEREO) {\n\n                matrix[ FRONT_LEFT][FRONT_CENTER]+= s->clev;\n\n                matrix[FRONT_RIGHT][FRONT_CENTER]+= s->clev;\n\n            } else {\n\n                matrix[ FRONT_LEFT][FRONT_CENTER]+= M_SQRT1_2;\n\n                matrix[FRONT_RIGHT][FRONT_CENTER]+= M_SQRT1_2;\n\n            }\n\n        }else\n\n            av_assert0(0);\n\n    }\n\n    if(unaccounted & AV_CH_LAYOUT_STEREO){\n\n        if(out_ch_layout & AV_CH_FRONT_CENTER){\n\n            matrix[FRONT_CENTER][ FRONT_LEFT]+= M_SQRT1_2;\n\n            matrix[FRONT_CENTER][FRONT_RIGHT]+= M_SQRT1_2;\n\n            if(in_ch_layout & AV_CH_FRONT_CENTER)\n\n                matrix[FRONT_CENTER][ FRONT_CENTER] = s->clev*sqrt(2);\n\n        }else\n\n            av_assert0(0);\n\n    }\n\n\n\n    if(unaccounted & AV_CH_BACK_CENTER){\n\n        if(out_ch_layout & AV_CH_BACK_LEFT){\n\n            matrix[ BACK_LEFT][BACK_CENTER]+= M_SQRT1_2;\n\n            matrix[BACK_RIGHT][BACK_CENTER]+= M_SQRT1_2;\n\n        }else if(out_ch_layout & AV_CH_SIDE_LEFT){\n\n            matrix[ SIDE_LEFT][BACK_CENTER]+= M_SQRT1_2;\n\n            matrix[SIDE_RIGHT][BACK_CENTER]+= M_SQRT1_2;\n\n        }else if(out_ch_layout & AV_CH_FRONT_LEFT){\n\n            if (matrix_encoding == AV_MATRIX_ENCODING_DOLBY ||\n\n                matrix_encoding == AV_MATRIX_ENCODING_DPLII) {\n\n                if (unaccounted & (AV_CH_BACK_LEFT | AV_CH_SIDE_LEFT)) {\n\n                    matrix[FRONT_LEFT ][BACK_CENTER] -= s->slev * M_SQRT1_2;\n\n                    matrix[FRONT_RIGHT][BACK_CENTER] += s->slev * M_SQRT1_2;\n\n                } else {\n\n                    matrix[FRONT_LEFT ][BACK_CENTER] -= s->slev;\n\n                    matrix[FRONT_RIGHT][BACK_CENTER] += s->slev;\n\n                }\n\n            } else {\n\n                matrix[ FRONT_LEFT][BACK_CENTER]+= s->slev*M_SQRT1_2;\n\n                matrix[FRONT_RIGHT][BACK_CENTER]+= s->slev*M_SQRT1_2;\n\n            }\n\n        }else if(out_ch_layout & AV_CH_FRONT_CENTER){\n\n            matrix[ FRONT_CENTER][BACK_CENTER]+= s->slev*M_SQRT1_2;\n\n        }else\n\n            av_assert0(0);\n\n    }\n\n    if(unaccounted & AV_CH_BACK_LEFT){\n\n        if(out_ch_layout & AV_CH_BACK_CENTER){\n\n            matrix[BACK_CENTER][ BACK_LEFT]+= M_SQRT1_2;\n\n            matrix[BACK_CENTER][BACK_RIGHT]+= M_SQRT1_2;\n\n        }else if(out_ch_layout & AV_CH_SIDE_LEFT){\n\n            if(in_ch_layout & AV_CH_SIDE_LEFT){\n\n                matrix[ SIDE_LEFT][ BACK_LEFT]+= M_SQRT1_2;\n\n                matrix[SIDE_RIGHT][BACK_RIGHT]+= M_SQRT1_2;\n\n            }else{\n\n            matrix[ SIDE_LEFT][ BACK_LEFT]+= 1.0;\n\n            matrix[SIDE_RIGHT][BACK_RIGHT]+= 1.0;\n\n            }\n\n        }else if(out_ch_layout & AV_CH_FRONT_LEFT){\n\n            if (matrix_encoding == AV_MATRIX_ENCODING_DOLBY) {\n\n                matrix[FRONT_LEFT ][BACK_LEFT ] -= s->slev * M_SQRT1_2;\n\n                matrix[FRONT_LEFT ][BACK_RIGHT] -= s->slev * M_SQRT1_2;\n\n                matrix[FRONT_RIGHT][BACK_LEFT ] += s->slev * M_SQRT1_2;\n\n                matrix[FRONT_RIGHT][BACK_RIGHT] += s->slev * M_SQRT1_2;\n\n            } else if (matrix_encoding == AV_MATRIX_ENCODING_DPLII) {\n\n                matrix[FRONT_LEFT ][BACK_LEFT ] -= s->slev * SQRT3_2;\n\n                matrix[FRONT_LEFT ][BACK_RIGHT] -= s->slev * M_SQRT1_2;\n\n                matrix[FRONT_RIGHT][BACK_LEFT ] += s->slev * M_SQRT1_2;\n\n                matrix[FRONT_RIGHT][BACK_RIGHT] += s->slev * SQRT3_2;\n\n            } else {\n\n                matrix[ FRONT_LEFT][ BACK_LEFT] += s->slev;\n\n                matrix[FRONT_RIGHT][BACK_RIGHT] += s->slev;\n\n            }\n\n        }else if(out_ch_layout & AV_CH_FRONT_CENTER){\n\n            matrix[ FRONT_CENTER][BACK_LEFT ]+= s->slev*M_SQRT1_2;\n\n            matrix[ FRONT_CENTER][BACK_RIGHT]+= s->slev*M_SQRT1_2;\n\n        }else\n\n            av_assert0(0);\n\n    }\n\n\n\n    if(unaccounted & AV_CH_SIDE_LEFT){\n\n        if(out_ch_layout & AV_CH_BACK_LEFT){\n\n            /* if back channels do not exist in the input, just copy side\n\n               channels to back channels, otherwise mix side into back */\n\n            if (in_ch_layout & AV_CH_BACK_LEFT) {\n\n                matrix[BACK_LEFT ][SIDE_LEFT ] += M_SQRT1_2;\n\n                matrix[BACK_RIGHT][SIDE_RIGHT] += M_SQRT1_2;\n\n            } else {\n\n                matrix[BACK_LEFT ][SIDE_LEFT ] += 1.0;\n\n                matrix[BACK_RIGHT][SIDE_RIGHT] += 1.0;\n\n            }\n\n        }else if(out_ch_layout & AV_CH_BACK_CENTER){\n\n            matrix[BACK_CENTER][ SIDE_LEFT]+= M_SQRT1_2;\n\n            matrix[BACK_CENTER][SIDE_RIGHT]+= M_SQRT1_2;\n\n        }else if(out_ch_layout & AV_CH_FRONT_LEFT){\n\n            if (matrix_encoding == AV_MATRIX_ENCODING_DOLBY) {\n\n                matrix[FRONT_LEFT ][SIDE_LEFT ] -= s->slev * M_SQRT1_2;\n\n                matrix[FRONT_LEFT ][SIDE_RIGHT] -= s->slev * M_SQRT1_2;\n\n                matrix[FRONT_RIGHT][SIDE_LEFT ] += s->slev * M_SQRT1_2;\n\n                matrix[FRONT_RIGHT][SIDE_RIGHT] += s->slev * M_SQRT1_2;\n\n            } else if (matrix_encoding == AV_MATRIX_ENCODING_DPLII) {\n\n                matrix[FRONT_LEFT ][SIDE_LEFT ] -= s->slev * SQRT3_2;\n\n                matrix[FRONT_LEFT ][SIDE_RIGHT] -= s->slev * M_SQRT1_2;\n\n                matrix[FRONT_RIGHT][SIDE_LEFT ] += s->slev * M_SQRT1_2;\n\n                matrix[FRONT_RIGHT][SIDE_RIGHT] += s->slev * SQRT3_2;\n\n            } else {\n\n                matrix[ FRONT_LEFT][ SIDE_LEFT] += s->slev;\n\n                matrix[FRONT_RIGHT][SIDE_RIGHT] += s->slev;\n\n            }\n\n        }else if(out_ch_layout & AV_CH_FRONT_CENTER){\n\n            matrix[ FRONT_CENTER][SIDE_LEFT ]+= s->slev*M_SQRT1_2;\n\n            matrix[ FRONT_CENTER][SIDE_RIGHT]+= s->slev*M_SQRT1_2;\n\n        }else\n\n            av_assert0(0);\n\n    }\n\n\n\n    if(unaccounted & AV_CH_FRONT_LEFT_OF_CENTER){\n\n        if(out_ch_layout & AV_CH_FRONT_LEFT){\n\n            matrix[ FRONT_LEFT][ FRONT_LEFT_OF_CENTER]+= 1.0;\n\n            matrix[FRONT_RIGHT][FRONT_RIGHT_OF_CENTER]+= 1.0;\n\n        }else if(out_ch_layout & AV_CH_FRONT_CENTER){\n\n            matrix[ FRONT_CENTER][ FRONT_LEFT_OF_CENTER]+= M_SQRT1_2;\n\n            matrix[ FRONT_CENTER][FRONT_RIGHT_OF_CENTER]+= M_SQRT1_2;\n\n        }else\n\n            av_assert0(0);\n\n    }\n\n    /* mix LFE into front left/right or center */\n\n    if (unaccounted & AV_CH_LOW_FREQUENCY) {\n\n        if (out_ch_layout & AV_CH_FRONT_CENTER) {\n\n            matrix[FRONT_CENTER][LOW_FREQUENCY] += s->lfe_mix_level;\n\n        } else if (out_ch_layout & AV_CH_FRONT_LEFT) {\n\n            matrix[FRONT_LEFT ][LOW_FREQUENCY] += s->lfe_mix_level * M_SQRT1_2;\n\n            matrix[FRONT_RIGHT][LOW_FREQUENCY] += s->lfe_mix_level * M_SQRT1_2;\n\n        } else\n\n            av_assert0(0);\n\n    }\n\n\n\n    for(out_i=i=0; i<64; i++){\n\n        double sum=0;\n\n        int in_i=0;\n\n        for(j=0; j<64; j++){\n\n            s->matrix[out_i][in_i]= matrix[i][j];\n\n            if(matrix[i][j]){\n\n                sum += fabs(matrix[i][j]);\n\n            }\n\n            if(in_ch_layout & (1ULL<<j))\n\n                in_i++;\n\n        }\n\n        maxcoef= FFMAX(maxcoef, sum);\n\n        if(out_ch_layout & (1ULL<<i))\n\n            out_i++;\n\n    }\n\n    if(s->rematrix_volume  < 0)\n\n        maxcoef = -s->rematrix_volume;\n\n\n\n    if (s->rematrix_maxval > 0) {\n\n        maxval = s->rematrix_maxval;\n\n    } else if (   av_get_packed_sample_fmt(s->out_sample_fmt) < AV_SAMPLE_FMT_FLT\n\n               || av_get_packed_sample_fmt(s->int_sample_fmt) < AV_SAMPLE_FMT_FLT) {\n\n        maxval = 1.0;\n\n    } else\n\n        maxval = INT_MAX;\n\n\n\n    if(maxcoef > maxval || s->rematrix_volume  < 0){\n\n        maxcoef /= maxval;\n\n        for(i=0; i<SWR_CH_MAX; i++)\n\n            for(j=0; j<SWR_CH_MAX; j++){\n\n                s->matrix[i][j] /= maxcoef;\n\n            }\n\n    }\n\n\n\n    if(s->rematrix_volume > 0){\n\n        for(i=0; i<SWR_CH_MAX; i++)\n\n            for(j=0; j<SWR_CH_MAX; j++){\n\n                s->matrix[i][j] *= s->rematrix_volume;\n\n            }\n\n    }\n\n\n\n    for(i=0; i<av_get_channel_layout_nb_channels(out_ch_layout); i++){\n\n        for(j=0; j<av_get_channel_layout_nb_channels(in_ch_layout); j++){\n\n            av_log(NULL, AV_LOG_DEBUG, \"%f \", s->matrix[i][j]);\n\n        }\n\n        av_log(NULL, AV_LOG_DEBUG, \"\\n\");\n\n    }\n\n    return 0;\n\n}\n", "idx": 26630}
{"project": "FFmpeg", "commit_id": "90540c2d5ace46a1e9789c75fde0b1f7dbb12a9b", "target": 1, "func": "static inline void RENAME(rgb32tobgr16)(const uint8_t *src, uint8_t *dst, int src_size)\n\n{\n\n    const uint8_t *s = src;\n\n    const uint8_t *end;\n\n    const uint8_t *mm_end;\n\n    uint16_t *d = (uint16_t *)dst;\n\n    end = s + src_size;\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*src):\"memory\");\n\n    __asm__ volatile(\n\n        \"movq          %0, %%mm7    \\n\\t\"\n\n        \"movq          %1, %%mm6    \\n\\t\"\n\n        ::\"m\"(red_16mask),\"m\"(green_16mask));\n\n    mm_end = end - 15;\n\n    while (s < mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"    32%1           \\n\\t\"\n\n            \"movd          %1, %%mm0    \\n\\t\"\n\n            \"movd         4%1, %%mm3    \\n\\t\"\n\n            \"punpckldq    8%1, %%mm0    \\n\\t\"\n\n            \"punpckldq   12%1, %%mm3    \\n\\t\"\n\n            \"movq       %%mm0, %%mm1    \\n\\t\"\n\n            \"movq       %%mm0, %%mm2    \\n\\t\"\n\n            \"movq       %%mm3, %%mm4    \\n\\t\"\n\n            \"movq       %%mm3, %%mm5    \\n\\t\"\n\n            \"psllq         $8, %%mm0    \\n\\t\"\n\n            \"psllq         $8, %%mm3    \\n\\t\"\n\n            \"pand       %%mm7, %%mm0    \\n\\t\"\n\n            \"pand       %%mm7, %%mm3    \\n\\t\"\n\n            \"psrlq         $5, %%mm1    \\n\\t\"\n\n            \"psrlq         $5, %%mm4    \\n\\t\"\n\n            \"pand       %%mm6, %%mm1    \\n\\t\"\n\n            \"pand       %%mm6, %%mm4    \\n\\t\"\n\n            \"psrlq        $19, %%mm2    \\n\\t\"\n\n            \"psrlq        $19, %%mm5    \\n\\t\"\n\n            \"pand          %2, %%mm2    \\n\\t\"\n\n            \"pand          %2, %%mm5    \\n\\t\"\n\n            \"por        %%mm1, %%mm0    \\n\\t\"\n\n            \"por        %%mm4, %%mm3    \\n\\t\"\n\n            \"por        %%mm2, %%mm0    \\n\\t\"\n\n            \"por        %%mm5, %%mm3    \\n\\t\"\n\n            \"psllq        $16, %%mm3    \\n\\t\"\n\n            \"por        %%mm3, %%mm0    \\n\\t\"\n\n            MOVNTQ\"     %%mm0, %0       \\n\\t\"\n\n            :\"=m\"(*d):\"m\"(*s),\"m\"(blue_16mask):\"memory\");\n\n        d += 4;\n\n        s += 16;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n    while (s < end) {\n\n        register int rgb = *(const uint32_t*)s; s += 4;\n\n        *d++ = ((rgb&0xF8)<<8) + ((rgb&0xFC00)>>5) + ((rgb&0xF80000)>>19);\n\n    }\n\n}\n", "idx": 26631}
{"project": "FFmpeg", "commit_id": "426a322aa2bfd8ec28e467743c79dad81c63c108", "target": 1, "func": "static int decode_pic(AVSContext *h)\n\n{\n\n    int ret;\n\n    int skip_count    = -1;\n\n    enum cavs_mb mb_type;\n\n\n\n    if (!h->top_qp) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"No sequence header decoded yet\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    av_frame_unref(h->cur.f);\n\n\n\n    skip_bits(&h->gb, 16);//bbv_dwlay\n\n    if (h->stc == PIC_PB_START_CODE) {\n\n        h->cur.f->pict_type = get_bits(&h->gb, 2) + AV_PICTURE_TYPE_I;\n\n        if (h->cur.f->pict_type > AV_PICTURE_TYPE_B) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"illegal picture type\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        /* make sure we have the reference frames we need */\n\n        if (!h->DPB[0].f->data[0] ||\n\n           (!h->DPB[1].f->data[0] && h->cur.f->pict_type == AV_PICTURE_TYPE_B))\n\n            return AVERROR_INVALIDDATA;\n\n    } else {\n\n        h->cur.f->pict_type = AV_PICTURE_TYPE_I;\n\n        if (get_bits1(&h->gb))\n\n            skip_bits(&h->gb, 24);//time_code\n\n        /* old sample clips were all progressive and no low_delay,\n\n           bump stream revision if detected otherwise */\n\n        if (h->low_delay || !(show_bits(&h->gb, 9) & 1))\n\n            h->stream_revision = 1;\n\n        /* similarly test top_field_first and repeat_first_field */\n\n        else if (show_bits(&h->gb, 11) & 3)\n\n            h->stream_revision = 1;\n\n        if (h->stream_revision > 0)\n\n            skip_bits(&h->gb, 1); //marker_bit\n\n    }\n\n\n\n    ret = ff_get_buffer(h->avctx, h->cur.f, h->cur.f->pict_type == AV_PICTURE_TYPE_B ?\n\n                        0 : AV_GET_BUFFER_FLAG_REF);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (!h->edge_emu_buffer) {\n\n        int alloc_size = FFALIGN(FFABS(h->cur.f->linesize[0]) + 32, 32);\n\n        h->edge_emu_buffer = av_mallocz(alloc_size * 2 * 24);\n\n        if (!h->edge_emu_buffer)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    if ((ret = ff_cavs_init_pic(h)) < 0)\n\n        return ret;\n\n    h->cur.poc = get_bits(&h->gb, 8) * 2;\n\n\n\n    /* get temporal distances and MV scaling factors */\n\n    if (h->cur.f->pict_type != AV_PICTURE_TYPE_B) {\n\n        h->dist[0] = (h->cur.poc - h->DPB[0].poc) & 511;\n\n    } else {\n\n        h->dist[0] = (h->DPB[0].poc  - h->cur.poc) & 511;\n\n    }\n\n    h->dist[1] = (h->cur.poc - h->DPB[1].poc) & 511;\n\n    h->scale_den[0] = h->dist[0] ? 512/h->dist[0] : 0;\n\n    h->scale_den[1] = h->dist[1] ? 512/h->dist[1] : 0;\n\n    if (h->cur.f->pict_type == AV_PICTURE_TYPE_B) {\n\n        h->sym_factor = h->dist[0] * h->scale_den[1];\n\n        if (FFABS(h->sym_factor) > 32768) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"sym_factor %d too large\\n\", h->sym_factor);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    } else {\n\n        h->direct_den[0] = h->dist[0] ? 16384 / h->dist[0] : 0;\n\n        h->direct_den[1] = h->dist[1] ? 16384 / h->dist[1] : 0;\n\n    }\n\n\n\n    if (h->low_delay)\n\n        get_ue_golomb(&h->gb); //bbv_check_times\n\n    h->progressive   = get_bits1(&h->gb);\n\n    h->pic_structure = 1;\n\n    if (!h->progressive)\n\n        h->pic_structure = get_bits1(&h->gb);\n\n    if (!h->pic_structure && h->stc == PIC_PB_START_CODE)\n\n        skip_bits1(&h->gb);     //advanced_pred_mode_disable\n\n    skip_bits1(&h->gb);        //top_field_first\n\n    skip_bits1(&h->gb);        //repeat_first_field\n\n    h->pic_qp_fixed =\n\n    h->qp_fixed = get_bits1(&h->gb);\n\n    h->qp       = get_bits(&h->gb, 6);\n\n    if (h->cur.f->pict_type == AV_PICTURE_TYPE_I) {\n\n        if (!h->progressive && !h->pic_structure)\n\n            skip_bits1(&h->gb);//what is this?\n\n        skip_bits(&h->gb, 4);   //reserved bits\n\n    } else {\n\n        if (!(h->cur.f->pict_type == AV_PICTURE_TYPE_B && h->pic_structure == 1))\n\n            h->ref_flag        = get_bits1(&h->gb);\n\n        skip_bits(&h->gb, 4);   //reserved bits\n\n        h->skip_mode_flag      = get_bits1(&h->gb);\n\n    }\n\n    h->loop_filter_disable     = get_bits1(&h->gb);\n\n    if (!h->loop_filter_disable && get_bits1(&h->gb)) {\n\n        h->alpha_offset        = get_se_golomb(&h->gb);\n\n        h->beta_offset         = get_se_golomb(&h->gb);\n\n    } else {\n\n        h->alpha_offset = h->beta_offset  = 0;\n\n    }\n\n    if (h->cur.f->pict_type == AV_PICTURE_TYPE_I) {\n\n        do {\n\n            check_for_slice(h);\n\n            decode_mb_i(h, 0);\n\n        } while (ff_cavs_next_mb(h));\n\n    } else if (h->cur.f->pict_type == AV_PICTURE_TYPE_P) {\n\n        do {\n\n            if (check_for_slice(h))\n\n                skip_count = -1;\n\n            if (h->skip_mode_flag && (skip_count < 0))\n\n                skip_count = get_ue_golomb(&h->gb);\n\n            if (h->skip_mode_flag && skip_count--) {\n\n                decode_mb_p(h, P_SKIP);\n\n            } else {\n\n                mb_type = get_ue_golomb(&h->gb) + P_SKIP + h->skip_mode_flag;\n\n                if (mb_type > P_8X8)\n\n                    decode_mb_i(h, mb_type - P_8X8 - 1);\n\n                else\n\n                    decode_mb_p(h, mb_type);\n\n            }\n\n        } while (ff_cavs_next_mb(h));\n\n    } else { /* AV_PICTURE_TYPE_B */\n\n        do {\n\n            if (check_for_slice(h))\n\n                skip_count = -1;\n\n            if (h->skip_mode_flag && (skip_count < 0))\n\n                skip_count = get_ue_golomb(&h->gb);\n\n            if (h->skip_mode_flag && skip_count--) {\n\n                decode_mb_b(h, B_SKIP);\n\n            } else {\n\n                mb_type = get_ue_golomb(&h->gb) + B_SKIP + h->skip_mode_flag;\n\n                if (mb_type > B_8X8)\n\n                    decode_mb_i(h, mb_type - B_8X8 - 1);\n\n                else\n\n                    decode_mb_b(h, mb_type);\n\n            }\n\n        } while (ff_cavs_next_mb(h));\n\n    }\n\n    emms_c();\n\n    if (h->cur.f->pict_type != AV_PICTURE_TYPE_B) {\n\n        av_frame_unref(h->DPB[1].f);\n\n        FFSWAP(AVSFrame, h->cur, h->DPB[1]);\n\n        FFSWAP(AVSFrame, h->DPB[0], h->DPB[1]);\n\n    }\n\n    return 0;\n\n}\n", "idx": 26633}
{"project": "FFmpeg", "commit_id": "56ffa3fefb22605ac6507efa046ebddc38301521", "target": 1, "func": "static int decode_cell(Indeo3DecodeContext *ctx, AVCodecContext *avctx,\n\n                       Plane *plane, Cell *cell, const uint8_t *data_ptr,\n\n                       const uint8_t *last_ptr)\n\n{\n\n    int           x, mv_x, mv_y, mode, vq_index, prim_indx, second_indx;\n\n    int           zoom_fac;\n\n    int           offset, error = 0, swap_quads[2];\n\n    uint8_t       code, *block, *ref_block = 0;\n\n    const vqEntry *delta[2];\n\n    const uint8_t *data_start = data_ptr;\n\n\n\n    /* get coding mode and VQ table index from the VQ descriptor byte */\n\n    code     = *data_ptr++;\n\n    mode     = code >> 4;\n\n    vq_index = code & 0xF;\n\n\n\n    /* setup output and reference pointers */\n\n    offset = (cell->ypos << 2) * plane->pitch + (cell->xpos << 2);\n\n    block  =  plane->pixels[ctx->buf_sel] + offset;\n\n    if (!cell->mv_ptr) {\n\n        /* use previous line as reference for INTRA cells */\n\n        ref_block = block - plane->pitch;\n\n    } else if (mode >= 10) {\n\n        /* for mode 10 and 11 INTER first copy the predicted cell into the current one */\n\n        /* so we don't need to do data copying for each RLE code later */\n\n        copy_cell(ctx, plane, cell);\n\n    } else {\n\n        /* set the pointer to the reference pixels for modes 0-4 INTER */\n\n        mv_y      = cell->mv_ptr[0];\n\n        mv_x      = cell->mv_ptr[1];\n\n\n\n\n\n\n\n\n        offset   += mv_y * plane->pitch + mv_x;\n\n        ref_block = plane->pixels[ctx->buf_sel ^ 1] + offset;\n\n\n\n\n    /* select VQ tables as follows: */\n\n    /* modes 0 and 3 use only the primary table for all lines in a block */\n\n    /* while modes 1 and 4 switch between primary and secondary tables on alternate lines */\n\n    if (mode == 1 || mode == 4) {\n\n        code        = ctx->alt_quant[vq_index];\n\n        prim_indx   = (code >> 4)  + ctx->cb_offset;\n\n        second_indx = (code & 0xF) + ctx->cb_offset;\n\n    } else {\n\n        vq_index += ctx->cb_offset;\n\n        prim_indx = second_indx = vq_index;\n\n\n\n\n    if (prim_indx >= 24 || second_indx >= 24) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid VQ table indexes! Primary: %d, secondary: %d!\\n\",\n\n               prim_indx, second_indx);\n\n\n\n\n\n    delta[0] = &vq_tab[second_indx];\n\n    delta[1] = &vq_tab[prim_indx];\n\n    swap_quads[0] = second_indx >= 16;\n\n    swap_quads[1] = prim_indx   >= 16;\n\n\n\n    /* requantize the prediction if VQ index of this cell differs from VQ index */\n\n    /* of the predicted cell in order to avoid overflows. */\n\n    if (vq_index >= 8 && ref_block) {\n\n        for (x = 0; x < cell->width << 2; x++)\n\n            ref_block[x] = requant_tab[vq_index & 7][ref_block[x]];\n\n\n\n\n    error = IV3_NOERR;\n\n\n\n    switch (mode) {\n\n    case 0: /*------------------ MODES 0 & 1 (4x4 block processing) --------------------*/\n\n    case 1:\n\n    case 3: /*------------------ MODES 3 & 4 (4x8 block processing) --------------------*/\n\n    case 4:\n\n        if (mode >= 3 && cell->mv_ptr) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Attempt to apply Mode 3/4 to an INTER cell!\\n\");\n\n\n\n\n\n        zoom_fac = mode >= 3;\n\n        error = decode_cell_data(cell, block, ref_block, plane->pitch, 0, zoom_fac,\n\n                                 mode, delta, swap_quads, &data_ptr, last_ptr);\n\n        break;\n\n    case 10: /*-------------------- MODE 10 (8x8 block processing) ---------------------*/\n\n    case 11: /*----------------- MODE 11 (4x8 INTER block processing) ------------------*/\n\n        if (mode == 10 && !cell->mv_ptr) { /* MODE 10 INTRA processing */\n\n            error = decode_cell_data(cell, block, ref_block, plane->pitch, 1, 1,\n\n                                     mode, delta, swap_quads, &data_ptr, last_ptr);\n\n        } else { /* mode 10 and 11 INTER processing */\n\n            if (mode == 11 && !cell->mv_ptr) {\n\n               av_log(avctx, AV_LOG_ERROR, \"Attempt to use Mode 11 for an INTRA cell!\\n\");\n\n\n\n\n\n            zoom_fac = mode == 10;\n\n            error = decode_cell_data(cell, block, ref_block, plane->pitch,\n\n                                     zoom_fac, 1, mode, delta, swap_quads,\n\n                                     &data_ptr, last_ptr);\n\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported coding mode: %d\\n\", mode);\n\n\n    }//switch mode\n\n\n\n    switch (error) {\n\n    case IV3_BAD_RLE:\n\n        av_log(avctx, AV_LOG_ERROR, \"Mode %d: RLE code %X is not allowed at the current line\\n\",\n\n               mode, data_ptr[-1]);\n\n\n    case IV3_BAD_DATA:\n\n        av_log(avctx, AV_LOG_ERROR, \"Mode %d: invalid VQ data\\n\", mode);\n\n\n    case IV3_BAD_COUNTER:\n\n        av_log(avctx, AV_LOG_ERROR, \"Mode %d: RLE-FB invalid counter: %d\\n\", mode, code);\n\n\n    case IV3_UNSUPPORTED:\n\n        av_log(avctx, AV_LOG_ERROR, \"Mode %d: unsupported RLE code: %X\\n\", mode, data_ptr[-1]);\n\n\n    case IV3_OUT_OF_DATA:\n\n        av_log(avctx, AV_LOG_ERROR, \"Mode %d: attempt to read past end of buffer\\n\", mode);\n\n\n\n\n\n    return data_ptr - data_start; /* report number of bytes consumed from the input buffer */\n", "idx": 26635}
{"project": "FFmpeg", "commit_id": "c3671e1d5760d79c083e7565d951f4628c06cf41", "target": 1, "func": "void ff_riff_write_info_tag(AVIOContext *pb, const char *tag, const char *str)\n\n{\n\n    int len = strlen(str);\n\n    if (len > 0) {\n\n        len++;\n\n        ffio_wfourcc(pb, tag);\n\n        avio_wl32(pb, len);\n\n        avio_put_str(pb, str);\n\n        if (len & 1)\n\n            avio_w8(pb, 0);\n\n    }\n\n}\n", "idx": 26636}
{"project": "FFmpeg", "commit_id": "2884688bd51a808ccda3c0e13367619cd79e0579", "target": 1, "func": "static int mjpegb_decode_frame(AVCodecContext *avctx,\n\n                              void *data, int *got_frame,\n\n                              AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    MJpegDecodeContext *s = avctx->priv_data;\n\n    const uint8_t *buf_end, *buf_ptr;\n\n    GetBitContext hgb; /* for the header */\n\n    uint32_t dqt_offs, dht_offs, sof_offs, sos_offs, second_field_offs;\n\n    uint32_t field_size, sod_offs;\n\n    int ret;\n\n\n\n    buf_ptr = buf;\n\n    buf_end = buf + buf_size;\n\n    s->got_picture = 0;\n\n\n\nread_header:\n\n    /* reset on every SOI */\n\n    s->restart_interval = 0;\n\n    s->restart_count = 0;\n\n    s->mjpb_skiptosod = 0;\n\n\n\n    if (buf_end - buf_ptr >= 1 << 28)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    init_get_bits(&hgb, buf_ptr, /*buf_size*/(buf_end - buf_ptr)*8);\n\n\n\n    skip_bits(&hgb, 32); /* reserved zeros */\n\n\n\n    if (get_bits_long(&hgb, 32) != MKBETAG('m','j','p','g'))\n\n    {\n\n        av_log(avctx, AV_LOG_WARNING, \"not mjpeg-b (bad fourcc)\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    field_size = get_bits_long(&hgb, 32); /* field size */\n\n    av_log(avctx, AV_LOG_DEBUG, \"field size: 0x%x\\n\", field_size);\n\n    skip_bits(&hgb, 32); /* padded field size */\n\n    second_field_offs = read_offs(avctx, &hgb, buf_end - buf_ptr, \"second_field_offs is %d and size is %d\\n\");\n\n    av_log(avctx, AV_LOG_DEBUG, \"second field offs: 0x%x\\n\", second_field_offs);\n\n\n\n    dqt_offs = read_offs(avctx, &hgb, buf_end - buf_ptr, \"dqt is %d and size is %d\\n\");\n\n    av_log(avctx, AV_LOG_DEBUG, \"dqt offs: 0x%x\\n\", dqt_offs);\n\n    if (dqt_offs)\n\n    {\n\n        init_get_bits(&s->gb, buf_ptr+dqt_offs, (buf_end - (buf_ptr+dqt_offs))*8);\n\n        s->start_code = DQT;\n\n        if (ff_mjpeg_decode_dqt(s) < 0 &&\n\n            (avctx->err_recognition & AV_EF_EXPLODE))\n\n          return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    dht_offs = read_offs(avctx, &hgb, buf_end - buf_ptr, \"dht is %d and size is %d\\n\");\n\n    av_log(avctx, AV_LOG_DEBUG, \"dht offs: 0x%x\\n\", dht_offs);\n\n    if (dht_offs)\n\n    {\n\n        init_get_bits(&s->gb, buf_ptr+dht_offs, (buf_end - (buf_ptr+dht_offs))*8);\n\n        s->start_code = DHT;\n\n        ff_mjpeg_decode_dht(s);\n\n    }\n\n\n\n    sof_offs = read_offs(avctx, &hgb, buf_end - buf_ptr, \"sof is %d and size is %d\\n\");\n\n    av_log(avctx, AV_LOG_DEBUG, \"sof offs: 0x%x\\n\", sof_offs);\n\n    if (sof_offs)\n\n    {\n\n        init_get_bits(&s->gb, buf_ptr+sof_offs, (buf_end - (buf_ptr+sof_offs))*8);\n\n        s->start_code = SOF0;\n\n        if (ff_mjpeg_decode_sof(s) < 0)\n\n            return -1;\n\n    }\n\n\n\n    sos_offs = read_offs(avctx, &hgb, buf_end - buf_ptr, \"sos is %d and size is %d\\n\");\n\n    av_log(avctx, AV_LOG_DEBUG, \"sos offs: 0x%x\\n\", sos_offs);\n\n    sod_offs = read_offs(avctx, &hgb, buf_end - buf_ptr, \"sof is %d and size is %d\\n\");\n\n    av_log(avctx, AV_LOG_DEBUG, \"sod offs: 0x%x\\n\", sod_offs);\n\n    if (sos_offs)\n\n    {\n\n        init_get_bits(&s->gb, buf_ptr + sos_offs,\n\n                      8 * FFMIN(field_size, buf_end - buf_ptr - sos_offs));\n\n        s->mjpb_skiptosod = (sod_offs - sos_offs - show_bits(&s->gb, 16));\n\n        s->start_code = SOS;\n\n        if (ff_mjpeg_decode_sos(s, NULL, NULL) < 0 &&\n\n            (avctx->err_recognition & AV_EF_EXPLODE))\n\n          return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->interlaced) {\n\n        s->bottom_field ^= 1;\n\n        /* if not bottom field, do not output image yet */\n\n        if (s->bottom_field != s->interlace_polarity && second_field_offs)\n\n        {\n\n            buf_ptr = buf + second_field_offs;\n\n            goto read_header;\n\n            }\n\n    }\n\n\n\n    //XXX FIXME factorize, this looks very similar to the EOI code\n\n\n\n    if(!s->got_picture) {\n\n        av_log(avctx, AV_LOG_WARNING, \"no picture\\n\");\n\n        return buf_size;\n\n    }\n\n\n\n    if ((ret = av_frame_ref(data, s->picture_ptr)) < 0)\n\n        return ret;\n\n    *got_frame = 1;\n\n\n\n    if (!s->lossless && avctx->debug & FF_DEBUG_QP) {\n\n        av_log(avctx, AV_LOG_DEBUG, \"QP: %d\\n\",\n\n               FFMAX3(s->qscale[0], s->qscale[1], s->qscale[2]));\n\n    }\n\n\n\n    return buf_size;\n\n}\n", "idx": 26637}
{"project": "FFmpeg", "commit_id": "9fd2bf09dbc630484d9e88a1d27f7e8508b70a2c", "target": 0, "func": "static int hqx_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_picture_ptr, AVPacket *avpkt)\n\n{\n\n    HQXContext *ctx = avctx->priv_data;\n\n    uint8_t *src = avpkt->data;\n\n    uint32_t info_tag;\n\n    int data_start;\n\n    int i, ret;\n\n\n\n    if (avpkt->size < 4 + 4) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Frame is too small %d.\\n\", avpkt->size);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    info_tag    = AV_RL32(src);\n\n    if (info_tag == MKTAG('I', 'N', 'F', 'O')) {\n\n        int info_offset = AV_RL32(src + 4);\n\n        if (info_offset > UINT32_MAX - 8 || info_offset + 8 > avpkt->size) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Invalid INFO header offset: 0x%08\"PRIX32\" is too large.\\n\",\n\n                   info_offset);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        ff_canopus_parse_info_tag(avctx, src + 8, info_offset);\n\n\n\n        info_offset += 8;\n\n        src         += info_offset;\n\n    }\n\n\n\n    data_start     = src - avpkt->data;\n\n    ctx->data_size = avpkt->size - data_start;\n\n    ctx->src       = src;\n\n    ctx->pic       = data;\n\n\n\n    if (ctx->data_size < HQX_HEADER_SIZE) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Frame too small.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (src[0] != 'H' || src[1] != 'Q') {\n\n        av_log(avctx, AV_LOG_ERROR, \"Not an HQX frame.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    ctx->interlaced = !(src[2] & 0x80);\n\n    ctx->format     = src[2] & 7;\n\n    ctx->dcb        = (src[3] & 3) + 8;\n\n    ctx->width      = AV_RB16(src + 4);\n\n    ctx->height     = AV_RB16(src + 6);\n\n    for (i = 0; i < 17; i++)\n\n        ctx->slice_off[i] = AV_RB24(src + 8 + i * 3);\n\n\n\n    if (ctx->dcb == 8) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid DC precision %d.\\n\", ctx->dcb);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    ret = av_image_check_size(ctx->width, ctx->height, 0, avctx);\n\n    if (ret < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid stored dimenstions %dx%d.\\n\",\n\n               ctx->width, ctx->height);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    avctx->coded_width         = FFALIGN(ctx->width,  16);\n\n    avctx->coded_height        = FFALIGN(ctx->height, 16);\n\n    avctx->width               = ctx->width;\n\n    avctx->height              = ctx->height;\n\n    avctx->bits_per_raw_sample = 10;\n\n\n\n    switch (ctx->format) {\n\n    case HQX_422:\n\n        avctx->pix_fmt = AV_PIX_FMT_YUV422P16;\n\n        ctx->decode_func = hqx_decode_422;\n\n        break;\n\n    case HQX_444:\n\n        avctx->pix_fmt = AV_PIX_FMT_YUV444P16;\n\n        ctx->decode_func = hqx_decode_444;\n\n        break;\n\n    case HQX_422A:\n\n        avctx->pix_fmt = AV_PIX_FMT_YUVA422P16;\n\n        ctx->decode_func = hqx_decode_422a;\n\n        break;\n\n    case HQX_444A:\n\n        avctx->pix_fmt = AV_PIX_FMT_YUVA444P16;\n\n        ctx->decode_func = hqx_decode_444a;\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid format: %d.\\n\", ctx->format);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    ret = ff_get_buffer(avctx, ctx->pic, 0);\n\n    if (ret < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not allocate buffer.\\n\");\n\n        return ret;\n\n    }\n\n\n\n    avctx->execute2(avctx, decode_slice_thread, NULL, NULL, 16);\n\n\n\n    ctx->pic->key_frame = 1;\n\n    ctx->pic->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    *got_picture_ptr = 1;\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 26648}
{"project": "FFmpeg", "commit_id": "80a5d05108cb218e8cd2e25c6621a3bfef0a832e", "target": 0, "func": "static av_cold int vaapi_encode_mjpeg_init_internal(AVCodecContext *avctx)\n\n{\n\n    static const VAConfigAttrib default_config_attributes[] = {\n\n        { .type  = VAConfigAttribRTFormat,\n\n          .value = VA_RT_FORMAT_YUV420 },\n\n        { .type  = VAConfigAttribEncPackedHeaders,\n\n          .value = VA_ENC_PACKED_HEADER_SEQUENCE },\n\n    };\n\n\n\n    VAAPIEncodeContext       *ctx = avctx->priv_data;\n\n    VAAPIEncodeMJPEGContext *priv = ctx->priv_data;\n\n    int i;\n\n\n\n    ctx->va_profile    = VAProfileJPEGBaseline;\n\n    ctx->va_entrypoint = VAEntrypointEncPicture;\n\n\n\n    ctx->input_width    = avctx->width;\n\n    ctx->input_height   = avctx->height;\n\n    ctx->aligned_width  = FFALIGN(ctx->input_width,  8);\n\n    ctx->aligned_height = FFALIGN(ctx->input_height, 8);\n\n\n\n    for (i = 0; i < FF_ARRAY_ELEMS(default_config_attributes); i++) {\n\n        ctx->config_attributes[ctx->nb_config_attributes++] =\n\n            default_config_attributes[i];\n\n    }\n\n\n\n    priv->quality = avctx->global_quality;\n\n    if (priv->quality < 1 || priv->quality > 100) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid quality value %d \"\n\n               \"(must be 1-100).\\n\", priv->quality);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    vaapi_encode_mjpeg_init_tables(avctx);\n\n\n\n    return 0;\n\n}\n", "idx": 26659}
{"project": "FFmpeg", "commit_id": "488a0fa68973d48e264d54f1722f7afb18afbea7", "target": 0, "func": "static int configure_input_audio_filter(FilterGraph *fg, InputFilter *ifilter,\n\n                                        AVFilterInOut *in)\n\n{\n\n    AVFilterContext *last_filter;\n\n    const AVFilter *abuffer_filt = avfilter_get_by_name(\"abuffer\");\n\n    InputStream *ist = ifilter->ist;\n\n    InputFile     *f = input_files[ist->file_index];\n\n    char args[255], name[255];\n\n    int ret, pad_idx = 0;\n\n\n\n    snprintf(args, sizeof(args), \"time_base=%d/%d:sample_rate=%d:sample_fmt=%s\"\n\n             \":channel_layout=0x%\"PRIx64,\n\n             1, ist->st->codec->sample_rate,\n\n             ist->st->codec->sample_rate,\n\n             av_get_sample_fmt_name(ist->st->codec->sample_fmt),\n\n             ist->st->codec->channel_layout);\n\n    snprintf(name, sizeof(name), \"graph %d input from stream %d:%d\", fg->index,\n\n             ist->file_index, ist->st->index);\n\n\n\n    if ((ret = avfilter_graph_create_filter(&ifilter->filter, abuffer_filt,\n\n                                            name, args, NULL,\n\n                                            fg->graph)) < 0)\n\n        return ret;\n\n    last_filter = ifilter->filter;\n\n\n\n    if (audio_sync_method > 0) {\n\n        AVFilterContext *async;\n\n        int  len = 0;\n\n\n\n        av_log(NULL, AV_LOG_WARNING, \"-async has been deprecated. Used the \"\n\n               \"asyncts audio filter instead.\\n\");\n\n\n\n        if (audio_sync_method > 1)\n\n            len += snprintf(args + len, sizeof(args) - len, \"compensate=1:\"\n\n                            \"max_comp=%d:\", audio_sync_method);\n\n        snprintf(args + len, sizeof(args) - len, \"min_delta=%f\",\n\n                 audio_drift_threshold);\n\n\n\n        snprintf(name, sizeof(name), \"graph %d audio sync for input stream %d:%d\",\n\n                 fg->index, ist->file_index, ist->st->index);\n\n        ret = avfilter_graph_create_filter(&async,\n\n                                           avfilter_get_by_name(\"asyncts\"),\n\n                                           name, args, NULL, fg->graph);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        ret = avfilter_link(last_filter, 0, async, 0);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        last_filter = async;\n\n    }\n\n    if (audio_volume != 256) {\n\n        AVFilterContext *volume;\n\n\n\n        av_log(NULL, AV_LOG_WARNING, \"-vol has been deprecated. Use the volume \"\n\n               \"audio filter instead.\\n\");\n\n\n\n        snprintf(args, sizeof(args), \"volume=%f\", audio_volume / 256.0);\n\n\n\n        snprintf(name, sizeof(name), \"graph %d volume for input stream %d:%d\",\n\n                 fg->index, ist->file_index, ist->st->index);\n\n        ret = avfilter_graph_create_filter(&volume,\n\n                                           avfilter_get_by_name(\"volume\"),\n\n                                           name, args, NULL, fg->graph);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        ret = avfilter_link(last_filter, 0, volume, 0);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        last_filter = volume;\n\n    }\n\n\n\n    snprintf(name, sizeof(name), \"trim for input stream %d:%d\",\n\n             ist->file_index, ist->st->index);\n\n    ret = insert_trim(((f->start_time == AV_NOPTS_VALUE) || !f->accurate_seek) ?\n\n                      AV_NOPTS_VALUE : 0, INT64_MAX, &last_filter, &pad_idx, name);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if ((ret = avfilter_link(last_filter, 0, in->filter_ctx, in->pad_idx)) < 0)\n\n        return ret;\n\n\n\n    return 0;\n\n}\n", "idx": 26664}
{"project": "FFmpeg", "commit_id": "8dca0877e3e1457e9ec79ffa1ead1135aabb791c", "target": 0, "func": "static int mpegts_write_packet_internal(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    AVStream *st = s->streams[pkt->stream_index];\n\n    int size = pkt->size;\n\n    uint8_t *buf = pkt->data;\n\n    uint8_t *data = NULL;\n\n    MpegTSWrite *ts = s->priv_data;\n\n    MpegTSWriteStream *ts_st = st->priv_data;\n\n    const uint64_t delay = av_rescale(s->max_delay, 90000, AV_TIME_BASE) * 2;\n\n    int64_t dts = AV_NOPTS_VALUE, pts = AV_NOPTS_VALUE;\n\n\n\n    if (ts->reemit_pat_pmt) {\n\n        av_log(s, AV_LOG_WARNING,\n\n               \"resend_headers option is deprecated, use -mpegts_flags resend_headers\\n\");\n\n        ts->reemit_pat_pmt = 0;\n\n        ts->flags         |= MPEGTS_FLAG_REEMIT_PAT_PMT;\n\n    }\n\n\n\n    if (ts->flags & MPEGTS_FLAG_REEMIT_PAT_PMT) {\n\n        ts->pat_packet_count = ts->pat_packet_period - 1;\n\n        ts->sdt_packet_count = ts->sdt_packet_period - 1;\n\n        ts->flags           &= ~MPEGTS_FLAG_REEMIT_PAT_PMT;\n\n    }\n\n\n\n    if (pkt->pts != AV_NOPTS_VALUE)\n\n        pts = pkt->pts + delay;\n\n    if (pkt->dts != AV_NOPTS_VALUE)\n\n        dts = pkt->dts + delay;\n\n\n\n    if (ts_st->first_pts_check && pts == AV_NOPTS_VALUE) {\n\n        av_log(s, AV_LOG_ERROR, \"first pts value must set\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    ts_st->first_pts_check = 0;\n\n\n\n    if (st->codec->codec_id == AV_CODEC_ID_H264) {\n\n        const uint8_t *p = buf, *buf_end = p + size;\n\n        uint32_t state = -1;\n\n\n\n        if (pkt->size < 5 || AV_RB32(pkt->data) != 0x0000001) {\n\n            av_log(s, AV_LOG_ERROR, \"H.264 bitstream malformed, \"\n\n                   \"no startcode found, use -bsf h264_mp4toannexb\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n\n\n        do {\n\n            p = avpriv_find_start_code(p, buf_end, &state);\n\n            av_dlog(s, \"nal %d\\n\", state & 0x1f);\n\n        } while (p < buf_end && (state & 0x1f) != 9 &&\n\n                 (state & 0x1f) != 5 && (state & 0x1f) != 1);\n\n\n\n        if ((state & 0x1f) != 9) { // AUD NAL\n\n            data = av_malloc(pkt->size + 6);\n\n            if (!data)\n\n                return AVERROR(ENOMEM);\n\n            memcpy(data + 6, pkt->data, pkt->size);\n\n            AV_WB32(data, 0x00000001);\n\n            data[4] = 0x09;\n\n            data[5] = 0xf0; // any slice type (0xe) + rbsp stop one bit\n\n            buf     = data;\n\n            size    = pkt->size + 6;\n\n        }\n\n    } else if (st->codec->codec_id == AV_CODEC_ID_AAC) {\n\n        if (pkt->size < 2) {\n\n            av_log(s, AV_LOG_ERROR, \"AAC packet too short\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n        if ((AV_RB16(pkt->data) & 0xfff0) != 0xfff0) {\n\n            int ret;\n\n            AVPacket pkt2;\n\n\n\n            if (!ts_st->amux) {\n\n                av_log(s, AV_LOG_ERROR, \"AAC bitstream not in ADTS format \"\n\n                                        \"and extradata missing\\n\");\n\n                return AVERROR(EINVAL);\n\n            }\n\n\n\n            av_init_packet(&pkt2);\n\n            pkt2.data = pkt->data;\n\n            pkt2.size = pkt->size;\n\n\n\n            ret = avio_open_dyn_buf(&ts_st->amux->pb);\n\n            if (ret < 0)\n\n                return AVERROR(ENOMEM);\n\n\n\n            ret = av_write_frame(ts_st->amux, &pkt2);\n\n            if (ret < 0) {\n\n                avio_close_dyn_buf(ts_st->amux->pb, &data);\n\n                ts_st->amux->pb = NULL;\n\n                av_free(data);\n\n                return ret;\n\n            }\n\n            size            = avio_close_dyn_buf(ts_st->amux->pb, &data);\n\n            ts_st->amux->pb = NULL;\n\n            buf             = data;\n\n        }\n\n    }\n\n\n\n    if (st->codec->codec_type != AVMEDIA_TYPE_AUDIO) {\n\n        // for video and subtitle, write a single pes packet\n\n        mpegts_write_pes(s, st, buf, size, pts, dts,\n\n                         pkt->flags & AV_PKT_FLAG_KEY);\n\n        av_free(data);\n\n        return 0;\n\n    }\n\n\n\n    if (ts_st->payload_size + size > ts->pes_payload_size) {\n\n        if (ts_st->payload_size) {\n\n            mpegts_write_pes(s, st, ts_st->payload, ts_st->payload_size,\n\n                             ts_st->payload_pts, ts_st->payload_dts,\n\n                             ts_st->payload_flags & AV_PKT_FLAG_KEY);\n\n            ts_st->payload_size = 0;\n\n        }\n\n        if (size > ts->pes_payload_size) {\n\n            mpegts_write_pes(s, st, buf, size, pts, dts,\n\n                             pkt->flags & AV_PKT_FLAG_KEY);\n\n            av_free(data);\n\n            return 0;\n\n        }\n\n    }\n\n\n\n    if (!ts_st->payload_size) {\n\n        ts_st->payload_pts   = pts;\n\n        ts_st->payload_dts   = dts;\n\n        ts_st->payload_flags = pkt->flags;\n\n    }\n\n\n\n    memcpy(ts_st->payload + ts_st->payload_size, buf, size);\n\n    ts_st->payload_size += size;\n\n\n\n    av_free(data);\n\n\n\n    return 0;\n\n}\n", "idx": 26665}
{"project": "FFmpeg", "commit_id": "4cb6964244fd6c099383d8b7e99731e72cc844b9", "target": 0, "func": "static int dca_subsubframe(DCAContext *s, int base_channel, int block_index)\n\n{\n\n    int k, l;\n\n    int subsubframe = s->current_subsubframe;\n\n\n\n    const float *quant_step_table;\n\n\n\n    /* FIXME */\n\n    float (*subband_samples)[DCA_SUBBANDS][8] = s->subband_samples[block_index];\n\n    LOCAL_ALIGNED_16(int32_t, block, [8 * DCA_SUBBANDS]);\n\n\n\n    /*\n\n     * Audio data\n\n     */\n\n\n\n    /* Select quantization step size table */\n\n    if (s->bit_rate_index == 0x1f)\n\n        quant_step_table = lossless_quant_d;\n\n    else\n\n        quant_step_table = lossy_quant_d;\n\n\n\n    for (k = base_channel; k < s->prim_channels; k++) {\n\n        float rscale[DCA_SUBBANDS];\n\n\n\n        if (get_bits_left(&s->gb) < 0)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        for (l = 0; l < s->vq_start_subband[k]; l++) {\n\n            int m;\n\n\n\n            /* Select the mid-tread linear quantizer */\n\n            int abits = s->bitalloc[k][l];\n\n\n\n            float quant_step_size = quant_step_table[abits];\n\n\n\n            /*\n\n             * Determine quantization index code book and its type\n\n             */\n\n\n\n            /* Select quantization index code book */\n\n            int sel = s->quant_index_huffman[k][abits];\n\n\n\n            /*\n\n             * Extract bits from the bit stream\n\n             */\n\n            if (!abits) {\n\n                rscale[l] = 0;\n\n                memset(block + 8 * l, 0, 8 * sizeof(block[0]));\n\n            } else {\n\n                /* Deal with transients */\n\n                int sfi = s->transition_mode[k][l] && subsubframe >= s->transition_mode[k][l];\n\n                rscale[l] = quant_step_size * s->scale_factor[k][l][sfi] *\n\n                               s->scalefactor_adj[k][sel];\n\n\n\n                if (abits >= 11 || !dca_smpl_bitalloc[abits].vlc[sel].table) {\n\n                    if (abits <= 7) {\n\n                        /* Block code */\n\n                        int block_code1, block_code2, size, levels, err;\n\n\n\n                        size   = abits_sizes[abits - 1];\n\n                        levels = abits_levels[abits - 1];\n\n\n\n                        block_code1 = get_bits(&s->gb, size);\n\n                        block_code2 = get_bits(&s->gb, size);\n\n                        err = decode_blockcodes(block_code1, block_code2,\n\n                                                levels, block + 8 * l);\n\n                        if (err) {\n\n                            av_log(s->avctx, AV_LOG_ERROR,\n\n                                   \"ERROR: block code look-up failed\\n\");\n\n                            return AVERROR_INVALIDDATA;\n\n                        }\n\n                    } else {\n\n                        /* no coding */\n\n                        for (m = 0; m < 8; m++)\n\n                            block[8 * l + m] = get_sbits(&s->gb, abits - 3);\n\n                    }\n\n                } else {\n\n                    /* Huffman coded */\n\n                    for (m = 0; m < 8; m++)\n\n                        block[8 * l + m] = get_bitalloc(&s->gb,\n\n                                                &dca_smpl_bitalloc[abits], sel);\n\n                }\n\n\n\n            }\n\n        }\n\n\n\n        s->fmt_conv.int32_to_float_fmul_array8(&s->fmt_conv, subband_samples[k][0],\n\n                                               block, rscale, 8 * s->vq_start_subband[k]);\n\n\n\n        for (l = 0; l < s->vq_start_subband[k]; l++) {\n\n            int m;\n\n            /*\n\n             * Inverse ADPCM if in prediction mode\n\n             */\n\n            if (s->prediction_mode[k][l]) {\n\n                int n;\n\n                if (s->predictor_history)\n\n                    subband_samples[k][l][0] += (adpcm_vb[s->prediction_vq[k][l]][0] *\n\n                                                 s->subband_samples_hist[k][l][3] +\n\n                                                 adpcm_vb[s->prediction_vq[k][l]][1] *\n\n                                                 s->subband_samples_hist[k][l][2] +\n\n                                                 adpcm_vb[s->prediction_vq[k][l]][2] *\n\n                                                 s->subband_samples_hist[k][l][1] +\n\n                                                 adpcm_vb[s->prediction_vq[k][l]][3] *\n\n                                                 s->subband_samples_hist[k][l][0]) *\n\n                                                (1.0f / 8192);\n\n                for (m = 1; m < 8; m++) {\n\n                    float sum = adpcm_vb[s->prediction_vq[k][l]][0] *\n\n                                subband_samples[k][l][m - 1];\n\n                    for (n = 2; n <= 4; n++)\n\n                        if (m >= n)\n\n                            sum += adpcm_vb[s->prediction_vq[k][l]][n - 1] *\n\n                                   subband_samples[k][l][m - n];\n\n                        else if (s->predictor_history)\n\n                            sum += adpcm_vb[s->prediction_vq[k][l]][n - 1] *\n\n                                   s->subband_samples_hist[k][l][m - n + 4];\n\n                    subband_samples[k][l][m] += sum * 1.0f / 8192;\n\n                }\n\n            }\n\n        }\n\n\n\n        /*\n\n         * Decode VQ encoded high frequencies\n\n         */\n\n        for (l = s->vq_start_subband[k]; l < s->subband_activity[k]; l++) {\n\n            /* 1 vector -> 32 samples but we only need the 8 samples\n\n             * for this subsubframe. */\n\n            int hfvq = s->high_freq_vq[k][l];\n\n\n\n            if (!s->debug_flag & 0x01) {\n\n                av_log(s->avctx, AV_LOG_DEBUG,\n\n                       \"Stream with high frequencies VQ coding\\n\");\n\n                s->debug_flag |= 0x01;\n\n            }\n\n\n\n            int8x8_fmul_int32(&s->dcadsp, subband_samples[k][l],\n\n                              &high_freq_vq[hfvq][subsubframe * 8],\n\n                              s->scale_factor[k][l][0]);\n\n        }\n\n    }\n\n\n\n    /* Check for DSYNC after subsubframe */\n\n    if (s->aspf || subsubframe == s->subsubframes[s->current_subframe] - 1) {\n\n        if (0xFFFF == get_bits(&s->gb, 16)) {   /* 0xFFFF */\n\n#ifdef TRACE\n\n            av_log(s->avctx, AV_LOG_DEBUG, \"Got subframe DSYNC\\n\");\n\n#endif\n\n        } else {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Didn't get subframe DSYNC\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    /* Backup predictor history for adpcm */\n\n    for (k = base_channel; k < s->prim_channels; k++)\n\n        for (l = 0; l < s->vq_start_subband[k]; l++)\n\n            AV_COPY128(s->subband_samples_hist[k][l], &subband_samples[k][l][4]);\n\n\n\n    return 0;\n\n}\n", "idx": 26666}
{"project": "FFmpeg", "commit_id": "f4d73f0fb55e0b5931c859ddb4d2d1617b60d560", "target": 0, "func": "int ff_mpeg_update_thread_context(AVCodecContext *dst,\n\n                                  const AVCodecContext *src)\n\n{\n\n    int i;\n\n    MpegEncContext *s = dst->priv_data, *s1 = src->priv_data;\n\n\n\n    if (dst == src)\n\n        return 0;\n\n\n\n    // FIXME can parameters change on I-frames?\n\n    // in that case dst may need a reinit\n\n    if (!s->context_initialized) {\n\n        memcpy(s, s1, sizeof(MpegEncContext));\n\n\n\n        s->avctx                 = dst;\n\n        s->bitstream_buffer      = NULL;\n\n        s->bitstream_buffer_size = s->allocated_bitstream_buffer_size = 0;\n\n\n\n        if (s1->context_initialized){\n\n            s->picture_range_start  += MAX_PICTURE_COUNT;\n\n            s->picture_range_end    += MAX_PICTURE_COUNT;\n\n            ff_MPV_common_init(s);\n\n        }\n\n    }\n\n\n\n    if (s->height != s1->height || s->width != s1->width || s->context_reinit) {\n\n        int err;\n\n        s->context_reinit = 0;\n\n        s->height = s1->height;\n\n        s->width  = s1->width;\n\n        if ((err = ff_MPV_common_frame_size_change(s)) < 0)\n\n            return err;\n\n    }\n\n\n\n    s->avctx->coded_height  = s1->avctx->coded_height;\n\n    s->avctx->coded_width   = s1->avctx->coded_width;\n\n    s->avctx->width         = s1->avctx->width;\n\n    s->avctx->height        = s1->avctx->height;\n\n\n\n    s->coded_picture_number = s1->coded_picture_number;\n\n    s->picture_number       = s1->picture_number;\n\n    s->input_picture_number = s1->input_picture_number;\n\n\n\n    memcpy(s->picture, s1->picture, s1->picture_count * sizeof(Picture));\n\n    memcpy(&s->last_picture, &s1->last_picture,\n\n           (char *) &s1->last_picture_ptr - (char *) &s1->last_picture);\n\n\n\n    // reset s->picture[].f.extended_data to s->picture[].f.data\n\n    for (i = 0; i < s->picture_count; i++)\n\n        s->picture[i].f.extended_data = s->picture[i].f.data;\n\n\n\n    s->last_picture_ptr    = REBASE_PICTURE(s1->last_picture_ptr,    s, s1);\n\n    s->current_picture_ptr = REBASE_PICTURE(s1->current_picture_ptr, s, s1);\n\n    s->next_picture_ptr    = REBASE_PICTURE(s1->next_picture_ptr,    s, s1);\n\n\n\n    // Error/bug resilience\n\n    s->next_p_frame_damaged = s1->next_p_frame_damaged;\n\n    s->workaround_bugs      = s1->workaround_bugs;\n\n    s->padding_bug_score    = s1->padding_bug_score;\n\n\n\n    // MPEG4 timing info\n\n    memcpy(&s->time_increment_bits, &s1->time_increment_bits,\n\n           (char *) &s1->shape - (char *) &s1->time_increment_bits);\n\n\n\n    // B-frame info\n\n    s->max_b_frames = s1->max_b_frames;\n\n    s->low_delay    = s1->low_delay;\n\n    s->dropable     = s1->dropable;\n\n\n\n    // DivX handling (doesn't work)\n\n    s->divx_packed  = s1->divx_packed;\n\n\n\n    if (s1->bitstream_buffer) {\n\n        if (s1->bitstream_buffer_size +\n\n            FF_INPUT_BUFFER_PADDING_SIZE > s->allocated_bitstream_buffer_size)\n\n            av_fast_malloc(&s->bitstream_buffer,\n\n                           &s->allocated_bitstream_buffer_size,\n\n                           s1->allocated_bitstream_buffer_size);\n\n            s->bitstream_buffer_size = s1->bitstream_buffer_size;\n\n        memcpy(s->bitstream_buffer, s1->bitstream_buffer,\n\n               s1->bitstream_buffer_size);\n\n        memset(s->bitstream_buffer + s->bitstream_buffer_size, 0,\n\n               FF_INPUT_BUFFER_PADDING_SIZE);\n\n    }\n\n\n\n    // MPEG2/interlacing info\n\n    memcpy(&s->progressive_sequence, &s1->progressive_sequence,\n\n           (char *) &s1->rtp_mode - (char *) &s1->progressive_sequence);\n\n\n\n    if (!s1->first_field) {\n\n        s->last_pict_type = s1->pict_type;\n\n        if (s1->current_picture_ptr)\n\n            s->last_lambda_for[s1->pict_type] = s1->current_picture_ptr->f.quality;\n\n\n\n        if (s1->pict_type != AV_PICTURE_TYPE_B) {\n\n            s->last_non_b_pict_type = s1->pict_type;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26667}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int h261_probe(AVProbeData *p)\n\n{\n\n    int code;\n\n    const uint8_t *d;\n\n\n\n    if (p->buf_size < 6)\n\n        return 0;\n\n    d = p->buf;\n\n    code = (d[0] << 12) | (d[1] << 4) | (d[2] >> 4);\n\n    if (code == 0x10) {\n\n        return 50;\n\n    }\n\n    return 0;\n\n}\n", "idx": 26668}
{"project": "FFmpeg", "commit_id": "2007082d2db25f9305b8a345798b840ea7784fdb", "target": 0, "func": "static int mov_read_wfex(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st;\n\n\n\n    if (c->fc->nb_streams < 1)\n\n        return 0;\n\n    st = c->fc->streams[c->fc->nb_streams-1];\n\n\n\n    ff_get_wav_header(pb, st->codec, atom.size);\n\n\n\n    return 0;\n\n}\n", "idx": 26678}
{"project": "FFmpeg", "commit_id": "cd0cfdc0a74cbf45f0d00b65faaf3cf5bd93c016", "target": 0, "func": "static int pcm_bluray_parse_header(AVCodecContext *avctx,\n\n                                   const uint8_t *header)\n\n{\n\n    static const uint8_t bits_per_samples[4] = { 0, 16, 20, 24 };\n\n    static const uint32_t channel_layouts[16] = {\n\n        0, AV_CH_LAYOUT_MONO, 0, AV_CH_LAYOUT_STEREO, AV_CH_LAYOUT_SURROUND,\n\n        AV_CH_LAYOUT_2_1, AV_CH_LAYOUT_4POINT0, AV_CH_LAYOUT_2_2, AV_CH_LAYOUT_5POINT0,\n\n        AV_CH_LAYOUT_5POINT1, AV_CH_LAYOUT_7POINT0, AV_CH_LAYOUT_7POINT1, 0, 0, 0, 0\n\n    };\n\n    static const uint8_t channels[16] = {\n\n        0, 1, 0, 2, 3, 3, 4, 4, 5, 6, 7, 8, 0, 0, 0, 0\n\n    };\n\n    uint8_t channel_layout = header[2] >> 4;\n\n\n\n    if (avctx->debug & FF_DEBUG_PICT_INFO)\n\n        av_dlog(avctx, \"pcm_bluray_parse_header: header = %02x%02x%02x%02x\\n\",\n\n                header[0], header[1], header[2], header[3]);\n\n\n\n    /* get the sample depth and derive the sample format from it */\n\n    avctx->bits_per_coded_sample = bits_per_samples[header[3] >> 6];\n\n    if (!avctx->bits_per_coded_sample) {\n\n        av_log(avctx, AV_LOG_ERROR, \"unsupported sample depth (0)\\n\");\n\n        return -1;\n\n    }\n\n    avctx->sample_fmt = avctx->bits_per_coded_sample == 16 ? AV_SAMPLE_FMT_S16 :\n\n                                                             AV_SAMPLE_FMT_S32;\n\n    if (avctx->sample_fmt == AV_SAMPLE_FMT_S32)\n\n        avctx->bits_per_raw_sample = avctx->bits_per_coded_sample;\n\n\n\n    /* get the sample rate. Not all values are known or exist. */\n\n    switch (header[2] & 0x0f) {\n\n    case 1:\n\n        avctx->sample_rate = 48000;\n\n        break;\n\n    case 4:\n\n        avctx->sample_rate = 96000;\n\n        break;\n\n    case 5:\n\n        avctx->sample_rate = 192000;\n\n        break;\n\n    default:\n\n        avctx->sample_rate = 0;\n\n        av_log(avctx, AV_LOG_ERROR, \"unsupported sample rate (%d)\\n\",\n\n               header[2] & 0x0f);\n\n        return -1;\n\n    }\n\n\n\n    /*\n\n     * get the channel number (and mapping). Not all values are known or exist.\n\n     * It must be noted that the number of channels in the MPEG stream can\n\n     * differ from the actual meaningful number, e.g. mono audio still has two\n\n     * channels, one being empty.\n\n     */\n\n    avctx->channel_layout  = channel_layouts[channel_layout];\n\n    avctx->channels        =        channels[channel_layout];\n\n    if (!avctx->channels) {\n\n        av_log(avctx, AV_LOG_ERROR, \"unsupported channel configuration (%d)\\n\",\n\n               channel_layout);\n\n        return -1;\n\n    }\n\n\n\n    avctx->bit_rate = avctx->channels * avctx->sample_rate *\n\n                      avctx->bits_per_coded_sample;\n\n\n\n    if (avctx->debug & FF_DEBUG_PICT_INFO)\n\n        av_dlog(avctx,\n\n                \"pcm_bluray_parse_header: %d channels, %d bits per sample, %d kHz, %d kbit\\n\",\n\n                avctx->channels, avctx->bits_per_coded_sample,\n\n                avctx->sample_rate, avctx->bit_rate);\n\n    return 0;\n\n}\n", "idx": 26689}
{"project": "FFmpeg", "commit_id": "7ed5d78d619e45b46ba003e8014767b05b73b7d2", "target": 1, "func": "int ff_dxva2_commit_buffer(AVCodecContext *avctx,\n\n                           AVDXVAContext *ctx,\n\n                           DECODER_BUFFER_DESC *dsc,\n\n                           unsigned type, const void *data, unsigned size,\n\n                           unsigned mb_count)\n\n{\n\n    void     *dxva_data;\n\n    unsigned dxva_size;\n\n    int      result;\n\n    HRESULT hr;\n\n\n\n#if CONFIG_D3D11VA\n\n    if (avctx->pix_fmt == AV_PIX_FMT_D3D11VA_VLD)\n\n        hr = ID3D11VideoContext_GetDecoderBuffer(D3D11VA_CONTEXT(ctx)->video_context,\n\n                                                 D3D11VA_CONTEXT(ctx)->decoder,\n\n                                                 type,\n\n                                                 &dxva_size, &dxva_data);\n\n#endif\n\n#if CONFIG_DXVA2\n\n    if (avctx->pix_fmt == AV_PIX_FMT_DXVA2_VLD)\n\n        hr = IDirectXVideoDecoder_GetBuffer(DXVA2_CONTEXT(ctx)->decoder, type,\n\n                                            &dxva_data, &dxva_size);\n\n#endif\n\n    if (FAILED(hr)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to get a buffer for %u: 0x%lx\\n\",\n\n               type, hr);\n\n        return -1;\n\n    }\n\n    if (size <= dxva_size) {\n\n        memcpy(dxva_data, data, size);\n\n\n\n#if CONFIG_D3D11VA\n\n        if (avctx->pix_fmt == AV_PIX_FMT_D3D11VA_VLD) {\n\n            D3D11_VIDEO_DECODER_BUFFER_DESC *dsc11 = dsc;\n\n            memset(dsc11, 0, sizeof(*dsc11));\n\n            dsc11->BufferType           = type;\n\n            dsc11->DataSize             = size;\n\n            dsc11->NumMBsInBuffer       = mb_count;\n\n        }\n\n#endif\n\n#if CONFIG_DXVA2\n\n        if (avctx->pix_fmt == AV_PIX_FMT_DXVA2_VLD) {\n\n            DXVA2_DecodeBufferDesc *dsc2 = dsc;\n\n            memset(dsc2, 0, sizeof(*dsc2));\n\n            dsc2->CompressedBufferType = type;\n\n            dsc2->DataSize             = size;\n\n            dsc2->NumMBsInBuffer       = mb_count;\n\n        }\n\n#endif\n\n\n\n        result = 0;\n\n    } else {\n\n        av_log(avctx, AV_LOG_ERROR, \"Buffer for type %u was too small\\n\", type);\n\n        result = -1;\n\n    }\n\n\n\n#if CONFIG_D3D11VA\n\n    if (avctx->pix_fmt == AV_PIX_FMT_D3D11VA_VLD)\n\n        hr = ID3D11VideoContext_ReleaseDecoderBuffer(D3D11VA_CONTEXT(ctx)->video_context, D3D11VA_CONTEXT(ctx)->decoder, type);\n\n#endif\n\n#if CONFIG_DXVA2\n\n    if (avctx->pix_fmt == AV_PIX_FMT_DXVA2_VLD)\n\n        hr = IDirectXVideoDecoder_ReleaseBuffer(DXVA2_CONTEXT(ctx)->decoder, type);\n\n#endif\n\n    if (FAILED(hr)) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Failed to release buffer type %u: 0x%lx\\n\",\n\n               type, hr);\n\n        result = -1;\n\n    }\n\n    return result;\n\n}\n", "idx": 26692}
{"project": "FFmpeg", "commit_id": "4618637aca3b771b0bfb8fe15f3a080dacf9f0c0", "target": 1, "func": "static void new_video_stream(AVFormatContext *oc, int file_idx)\n\n{\n\n    AVStream *st;\n\n    AVOutputStream *ost;\n\n    AVCodecContext *video_enc;\n\n    enum CodecID codec_id;\n\n    AVCodec *codec= NULL;\n\n\n\n    st = av_new_stream(oc, oc->nb_streams < nb_streamid_map ? streamid_map[oc->nb_streams] : 0);\n\n    if (!st) {\n\n        fprintf(stderr, \"Could not alloc stream\\n\");\n\n        ffmpeg_exit(1);\n\n    }\n\n    ost = new_output_stream(oc, file_idx);\n\n\n\n    output_codecs = grow_array(output_codecs, sizeof(*output_codecs), &nb_output_codecs, nb_output_codecs + 1);\n\n    if(!video_stream_copy){\n\n        if (video_codec_name) {\n\n            codec_id = find_codec_or_die(video_codec_name, AVMEDIA_TYPE_VIDEO, 1,\n\n                                         avcodec_opts[AVMEDIA_TYPE_VIDEO]->strict_std_compliance);\n\n            codec = avcodec_find_encoder_by_name(video_codec_name);\n\n            output_codecs[nb_output_codecs-1] = codec;\n\n        } else {\n\n            codec_id = av_guess_codec(oc->oformat, NULL, oc->filename, NULL, AVMEDIA_TYPE_VIDEO);\n\n            codec = avcodec_find_encoder(codec_id);\n\n        }\n\n    }\n\n\n\n    avcodec_get_context_defaults3(st->codec, codec);\n\n    ost->bitstream_filters = video_bitstream_filters;\n\n    video_bitstream_filters= NULL;\n\n\n\n    avcodec_thread_init(st->codec, thread_count);\n\n\n\n    video_enc = st->codec;\n\n\n\n    if(video_codec_tag)\n\n        video_enc->codec_tag= video_codec_tag;\n\n\n\n    if(   (video_global_header&1)\n\n       || (video_global_header==0 && (oc->oformat->flags & AVFMT_GLOBALHEADER))){\n\n        video_enc->flags |= CODEC_FLAG_GLOBAL_HEADER;\n\n        avcodec_opts[AVMEDIA_TYPE_VIDEO]->flags|= CODEC_FLAG_GLOBAL_HEADER;\n\n    }\n\n    if(video_global_header&2){\n\n        video_enc->flags2 |= CODEC_FLAG2_LOCAL_HEADER;\n\n        avcodec_opts[AVMEDIA_TYPE_VIDEO]->flags2|= CODEC_FLAG2_LOCAL_HEADER;\n\n    }\n\n\n\n    if (video_stream_copy) {\n\n        st->stream_copy = 1;\n\n        video_enc->codec_type = AVMEDIA_TYPE_VIDEO;\n\n        video_enc->sample_aspect_ratio =\n\n        st->sample_aspect_ratio = av_d2q(frame_aspect_ratio*frame_height/frame_width, 255);\n\n    } else {\n\n        const char *p;\n\n        int i;\n\n        AVRational fps= frame_rate.num ? frame_rate : (AVRational){25,1};\n\n\n\n        video_enc->codec_id = codec_id;\n\n        set_context_opts(video_enc, avcodec_opts[AVMEDIA_TYPE_VIDEO], AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM, codec);\n\n\n\n        if (codec && codec->supported_framerates && !force_fps)\n\n            fps = codec->supported_framerates[av_find_nearest_q_idx(fps, codec->supported_framerates)];\n\n        video_enc->time_base.den = fps.num;\n\n        video_enc->time_base.num = fps.den;\n\n\n\n        video_enc->width = frame_width;\n\n        video_enc->height = frame_height;\n\n        video_enc->sample_aspect_ratio = av_d2q(frame_aspect_ratio*video_enc->height/video_enc->width, 255);\n\n        video_enc->pix_fmt = frame_pix_fmt;\n\n        st->sample_aspect_ratio = video_enc->sample_aspect_ratio;\n\n\n\n        choose_pixel_fmt(st, codec);\n\n\n\n        if (intra_only)\n\n            video_enc->gop_size = 0;\n\n        if (video_qscale || same_quality) {\n\n            video_enc->flags |= CODEC_FLAG_QSCALE;\n\n            video_enc->global_quality=\n\n                st->quality = FF_QP2LAMBDA * video_qscale;\n\n        }\n\n\n\n        if(intra_matrix)\n\n            video_enc->intra_matrix = intra_matrix;\n\n        if(inter_matrix)\n\n            video_enc->inter_matrix = inter_matrix;\n\n\n\n        p= video_rc_override_string;\n\n        for(i=0; p; i++){\n\n            int start, end, q;\n\n            int e=sscanf(p, \"%d,%d,%d\", &start, &end, &q);\n\n            if(e!=3){\n\n                fprintf(stderr, \"error parsing rc_override\\n\");\n\n                ffmpeg_exit(1);\n\n            }\n\n            video_enc->rc_override=\n\n                av_realloc(video_enc->rc_override,\n\n                           sizeof(RcOverride)*(i+1));\n\n            video_enc->rc_override[i].start_frame= start;\n\n            video_enc->rc_override[i].end_frame  = end;\n\n            if(q>0){\n\n                video_enc->rc_override[i].qscale= q;\n\n                video_enc->rc_override[i].quality_factor= 1.0;\n\n            }\n\n            else{\n\n                video_enc->rc_override[i].qscale= 0;\n\n                video_enc->rc_override[i].quality_factor= -q/100.0;\n\n            }\n\n            p= strchr(p, '/');\n\n            if(p) p++;\n\n        }\n\n        video_enc->rc_override_count=i;\n\n        if (!video_enc->rc_initial_buffer_occupancy)\n\n            video_enc->rc_initial_buffer_occupancy = video_enc->rc_buffer_size*3/4;\n\n        video_enc->me_threshold= me_threshold;\n\n        video_enc->intra_dc_precision= intra_dc_precision - 8;\n\n\n\n        if (do_psnr)\n\n            video_enc->flags|= CODEC_FLAG_PSNR;\n\n\n\n        /* two pass mode */\n\n        if (do_pass) {\n\n            if (do_pass == 1) {\n\n                video_enc->flags |= CODEC_FLAG_PASS1;\n\n            } else {\n\n                video_enc->flags |= CODEC_FLAG_PASS2;\n\n            }\n\n        }\n\n\n\n        if (forced_key_frames)\n\n            parse_forced_key_frames(forced_key_frames, ost, video_enc);\n\n    }\n\n    if (video_language) {\n\n        av_metadata_set2(&st->metadata, \"language\", video_language, 0);\n\n        av_freep(&video_language);\n\n    }\n\n\n\n    /* reset some key parameters */\n\n    video_disable = 0;\n\n    av_freep(&video_codec_name);\n\n    av_freep(&forced_key_frames);\n\n    video_stream_copy = 0;\n\n    frame_pix_fmt = PIX_FMT_NONE;\n\n}\n", "idx": 26693}
{"project": "FFmpeg", "commit_id": "1e25a7e7ebb55516d522a8ab1c4b7938b5060fe5", "target": 1, "func": "static int alac_decode_frame(AVCodecContext *avctx,\n\n                             void *outbuffer, int *outputsize,\n\n                             uint8_t *inbuffer, int input_buffer_size)\n\n{\n\n    ALACContext *alac = avctx->priv_data;\n\n\n\n    int channels;\n\n    int32_t outputsamples;\n\n\n\n    /* short-circuit null buffers */\n\n    if (!inbuffer || !input_buffer_size)\n\n        return input_buffer_size;\n\n\n\n    /* initialize from the extradata */\n\n    if (!alac->context_initialized) {\n\n        if (alac->avctx->extradata_size != ALAC_EXTRADATA_SIZE) {\n\n            av_log(avctx, AV_LOG_ERROR, \"alac: expected %d extradata bytes\\n\",\n\n                ALAC_EXTRADATA_SIZE);\n\n            return input_buffer_size;\n\n        }\n\n        alac_set_info(alac);\n\n        alac->context_initialized = 1;\n\n    }\n\n\n\n    outputsamples = alac->setinfo_max_samples_per_frame;\n\n\n\n    init_get_bits(&alac->gb, inbuffer, input_buffer_size * 8);\n\n\n\n    channels = get_bits(&alac->gb, 3);\n\n\n\n    *outputsize = outputsamples * alac->bytespersample;\n\n\n\n    switch(channels) {\n\n    case 0: { /* 1 channel */\n\n        int hassize;\n\n        int isnotcompressed;\n\n        int readsamplesize;\n\n\n\n        int wasted_bytes;\n\n        int ricemodifier;\n\n\n\n\n\n        /* 2^result = something to do with output waiting.\n\n         * perhaps matters if we read > 1 frame in a pass?\n\n         */\n\n        get_bits(&alac->gb, 4);\n\n\n\n        get_bits(&alac->gb, 12); /* unknown, skip 12 bits */\n\n\n\n        hassize = get_bits(&alac->gb, 1); /* the output sample size is stored soon */\n\n\n\n        wasted_bytes = get_bits(&alac->gb, 2); /* unknown ? */\n\n\n\n        isnotcompressed = get_bits(&alac->gb, 1); /* whether the frame is compressed */\n\n\n\n        if (hassize) {\n\n            /* now read the number of samples,\n\n             * as a 32bit integer */\n\n            outputsamples = get_bits(&alac->gb, 32);\n\n            *outputsize = outputsamples * alac->bytespersample;\n\n        }\n\n\n\n        readsamplesize = alac->setinfo_sample_size - (wasted_bytes * 8);\n\n\n\n        if (!isnotcompressed) {\n\n         /* so it is compressed */\n\n            int16_t predictor_coef_table[32];\n\n            int predictor_coef_num;\n\n            int prediction_type;\n\n            int prediction_quantitization;\n\n            int i;\n\n\n\n            /* FIXME: skip 16 bits, not sure what they are. seem to be used in\n\n             * two channel case */\n\n            get_bits(&alac->gb, 8);\n\n            get_bits(&alac->gb, 8);\n\n\n\n            prediction_type = get_bits(&alac->gb, 4);\n\n            prediction_quantitization = get_bits(&alac->gb, 4);\n\n\n\n            ricemodifier = get_bits(&alac->gb, 3);\n\n            predictor_coef_num = get_bits(&alac->gb, 5);\n\n\n\n            /* read the predictor table */\n\n            for (i = 0; i < predictor_coef_num; i++) {\n\n                predictor_coef_table[i] = (int16_t)get_bits(&alac->gb, 16);\n\n            }\n\n\n\n            if (wasted_bytes) {\n\n                /* these bytes seem to have something to do with\n\n                 * > 2 channel files.\n\n                 */\n\n                av_log(avctx, AV_LOG_ERROR, \"FIXME: unimplemented, unhandling of wasted_bytes\\n\");\n\n            }\n\n\n\n            bastardized_rice_decompress(alac,\n\n                                        alac->predicterror_buffer_a,\n\n                                        outputsamples,\n\n                                        readsamplesize,\n\n                                        alac->setinfo_rice_initialhistory,\n\n                                        alac->setinfo_rice_kmodifier,\n\n                                        ricemodifier * alac->setinfo_rice_historymult / 4,\n\n                                        (1 << alac->setinfo_rice_kmodifier) - 1);\n\n\n\n            if (prediction_type == 0) {\n\n              /* adaptive fir */\n\n                predictor_decompress_fir_adapt(alac->predicterror_buffer_a,\n\n                                               alac->outputsamples_buffer_a,\n\n                                               outputsamples,\n\n                                               readsamplesize,\n\n                                               predictor_coef_table,\n\n                                               predictor_coef_num,\n\n                                               prediction_quantitization);\n\n            } else {\n\n                av_log(avctx, AV_LOG_ERROR, \"FIXME: unhandled prediction type: %i\\n\", prediction_type);\n\n                /* i think the only other prediction type (or perhaps this is just a\n\n                 * boolean?) runs adaptive fir twice.. like:\n\n                 * predictor_decompress_fir_adapt(predictor_error, tempout, ...)\n\n                 * predictor_decompress_fir_adapt(predictor_error, outputsamples ...)\n\n                 * little strange..\n\n                 */\n\n            }\n\n\n\n        } else {\n\n          /* not compressed, easy case */\n\n            if (readsamplesize <= 16) {\n\n                int i;\n\n                for (i = 0; i < outputsamples; i++) {\n\n                    int32_t audiobits = get_bits(&alac->gb, readsamplesize);\n\n\n\n                    audiobits = SIGN_EXTENDED32(audiobits, readsamplesize);\n\n\n\n                    alac->outputsamples_buffer_a[i] = audiobits;\n\n                }\n\n            } else {\n\n                int i;\n\n                for (i = 0; i < outputsamples; i++) {\n\n                    int32_t audiobits;\n\n\n\n                    audiobits = get_bits(&alac->gb, 16);\n\n                    /* special case of sign extension..\n\n                     * as we'll be ORing the low 16bits into this */\n\n                    audiobits = audiobits << 16;\n\n                    audiobits = audiobits >> (32 - readsamplesize);\n\n\n\n                    audiobits |= get_bits(&alac->gb, readsamplesize - 16);\n\n\n\n                    alac->outputsamples_buffer_a[i] = audiobits;\n\n                }\n\n            }\n\n            /* wasted_bytes = 0; // unused */\n\n        }\n\n\n\n        switch(alac->setinfo_sample_size) {\n\n        case 16: {\n\n            int i;\n\n            for (i = 0; i < outputsamples; i++) {\n\n                int16_t sample = alac->outputsamples_buffer_a[i];\n\n                ((int16_t*)outbuffer)[i * alac->numchannels] = sample;\n\n            }\n\n            break;\n\n        }\n\n        case 20:\n\n        case 24:\n\n        case 32:\n\n            av_log(avctx, AV_LOG_ERROR, \"FIXME: unimplemented sample size %i\\n\", alac->setinfo_sample_size);\n\n            break;\n\n        default:\n\n            break;\n\n        }\n\n        break;\n\n    }\n\n    case 1: { /* 2 channels */\n\n        int hassize;\n\n        int isnotcompressed;\n\n        int readsamplesize;\n\n\n\n        int wasted_bytes;\n\n\n\n        uint8_t interlacing_shift;\n\n        uint8_t interlacing_leftweight;\n\n\n\n        /* 2^result = something to do with output waiting.\n\n         * perhaps matters if we read > 1 frame in a pass?\n\n         */\n\n        get_bits(&alac->gb, 4);\n\n\n\n        get_bits(&alac->gb, 12); /* unknown, skip 12 bits */\n\n\n\n        hassize = get_bits(&alac->gb, 1); /* the output sample size is stored soon */\n\n\n\n        wasted_bytes = get_bits(&alac->gb, 2); /* unknown ? */\n\n\n\n        isnotcompressed = get_bits(&alac->gb, 1); /* whether the frame is compressed */\n\n\n\n        if (hassize) {\n\n            /* now read the number of samples,\n\n             * as a 32bit integer */\n\n            outputsamples = get_bits(&alac->gb, 32);\n\n            *outputsize = outputsamples * alac->bytespersample;\n\n        }\n\n\n\n        readsamplesize = alac->setinfo_sample_size - (wasted_bytes * 8) + 1;\n\n\n\n        if (!isnotcompressed) {\n\n         /* compressed */\n\n            int16_t predictor_coef_table_a[32];\n\n            int predictor_coef_num_a;\n\n            int prediction_type_a;\n\n            int prediction_quantitization_a;\n\n            int ricemodifier_a;\n\n\n\n            int16_t predictor_coef_table_b[32];\n\n            int predictor_coef_num_b;\n\n            int prediction_type_b;\n\n            int prediction_quantitization_b;\n\n            int ricemodifier_b;\n\n\n\n            int i;\n\n\n\n            interlacing_shift = get_bits(&alac->gb, 8);\n\n            interlacing_leftweight = get_bits(&alac->gb, 8);\n\n\n\n            /******** channel 1 ***********/\n\n            prediction_type_a = get_bits(&alac->gb, 4);\n\n            prediction_quantitization_a = get_bits(&alac->gb, 4);\n\n\n\n            ricemodifier_a = get_bits(&alac->gb, 3);\n\n            predictor_coef_num_a = get_bits(&alac->gb, 5);\n\n\n\n            /* read the predictor table */\n\n            for (i = 0; i < predictor_coef_num_a; i++) {\n\n                predictor_coef_table_a[i] = (int16_t)get_bits(&alac->gb, 16);\n\n            }\n\n\n\n            /******** channel 2 *********/\n\n            prediction_type_b = get_bits(&alac->gb, 4);\n\n            prediction_quantitization_b = get_bits(&alac->gb, 4);\n\n\n\n            ricemodifier_b = get_bits(&alac->gb, 3);\n\n            predictor_coef_num_b = get_bits(&alac->gb, 5);\n\n\n\n            /* read the predictor table */\n\n            for (i = 0; i < predictor_coef_num_b; i++) {\n\n                predictor_coef_table_b[i] = (int16_t)get_bits(&alac->gb, 16);\n\n            }\n\n\n\n            /*********************/\n\n            if (wasted_bytes) {\n\n              /* see mono case */\n\n                av_log(avctx, AV_LOG_ERROR, \"FIXME: unimplemented, unhandling of wasted_bytes\\n\");\n\n            }\n\n\n\n            /* channel 1 */\n\n            bastardized_rice_decompress(alac,\n\n                                        alac->predicterror_buffer_a,\n\n                                        outputsamples,\n\n                                        readsamplesize,\n\n                                        alac->setinfo_rice_initialhistory,\n\n                                        alac->setinfo_rice_kmodifier,\n\n                                        ricemodifier_a * alac->setinfo_rice_historymult / 4,\n\n                                        (1 << alac->setinfo_rice_kmodifier) - 1);\n\n\n\n            if (prediction_type_a == 0) {\n\n              /* adaptive fir */\n\n                predictor_decompress_fir_adapt(alac->predicterror_buffer_a,\n\n                                               alac->outputsamples_buffer_a,\n\n                                               outputsamples,\n\n                                               readsamplesize,\n\n                                               predictor_coef_table_a,\n\n                                               predictor_coef_num_a,\n\n                                               prediction_quantitization_a);\n\n            } else {\n\n              /* see mono case */\n\n                av_log(avctx, AV_LOG_ERROR, \"FIXME: unhandled prediction type: %i\\n\", prediction_type_a);\n\n            }\n\n\n\n            /* channel 2 */\n\n            bastardized_rice_decompress(alac,\n\n                                        alac->predicterror_buffer_b,\n\n                                        outputsamples,\n\n                                        readsamplesize,\n\n                                        alac->setinfo_rice_initialhistory,\n\n                                        alac->setinfo_rice_kmodifier,\n\n                                        ricemodifier_b * alac->setinfo_rice_historymult / 4,\n\n                                        (1 << alac->setinfo_rice_kmodifier) - 1);\n\n\n\n            if (prediction_type_b == 0) {\n\n              /* adaptive fir */\n\n                predictor_decompress_fir_adapt(alac->predicterror_buffer_b,\n\n                                               alac->outputsamples_buffer_b,\n\n                                               outputsamples,\n\n                                               readsamplesize,\n\n                                               predictor_coef_table_b,\n\n                                               predictor_coef_num_b,\n\n                                               prediction_quantitization_b);\n\n            } else {\n\n                av_log(avctx, AV_LOG_ERROR, \"FIXME: unhandled prediction type: %i\\n\", prediction_type_b);\n\n            }\n\n        } else {\n\n         /* not compressed, easy case */\n\n            if (alac->setinfo_sample_size <= 16) {\n\n                int i;\n\n                for (i = 0; i < outputsamples; i++) {\n\n                    int32_t audiobits_a, audiobits_b;\n\n\n\n                    audiobits_a = get_bits(&alac->gb, alac->setinfo_sample_size);\n\n                    audiobits_b = get_bits(&alac->gb, alac->setinfo_sample_size);\n\n\n\n                    audiobits_a = SIGN_EXTENDED32(audiobits_a, alac->setinfo_sample_size);\n\n                    audiobits_b = SIGN_EXTENDED32(audiobits_b, alac->setinfo_sample_size);\n\n\n\n                    alac->outputsamples_buffer_a[i] = audiobits_a;\n\n                    alac->outputsamples_buffer_b[i] = audiobits_b;\n\n                }\n\n            } else {\n\n                int i;\n\n                for (i = 0; i < outputsamples; i++) {\n\n                    int32_t audiobits_a, audiobits_b;\n\n\n\n                    audiobits_a = get_bits(&alac->gb, 16);\n\n                    audiobits_a = audiobits_a << 16;\n\n                    audiobits_a = audiobits_a >> (32 - alac->setinfo_sample_size);\n\n                    audiobits_a |= get_bits(&alac->gb, alac->setinfo_sample_size - 16);\n\n\n\n                    audiobits_b = get_bits(&alac->gb, 16);\n\n                    audiobits_b = audiobits_b << 16;\n\n                    audiobits_b = audiobits_b >> (32 - alac->setinfo_sample_size);\n\n                    audiobits_b |= get_bits(&alac->gb, alac->setinfo_sample_size - 16);\n\n\n\n                    alac->outputsamples_buffer_a[i] = audiobits_a;\n\n                    alac->outputsamples_buffer_b[i] = audiobits_b;\n\n                }\n\n            }\n\n            /* wasted_bytes = 0; */\n\n            interlacing_shift = 0;\n\n            interlacing_leftweight = 0;\n\n        }\n\n\n\n        switch(alac->setinfo_sample_size) {\n\n        case 16: {\n\n            deinterlace_16(alac->outputsamples_buffer_a,\n\n                           alac->outputsamples_buffer_b,\n\n                           (int16_t*)outbuffer,\n\n                           alac->numchannels,\n\n                           outputsamples,\n\n                           interlacing_shift,\n\n                           interlacing_leftweight);\n\n            break;\n\n        }\n\n        case 20:\n\n        case 24:\n\n        case 32:\n\n            av_log(avctx, AV_LOG_ERROR, \"FIXME: unimplemented sample size %i\\n\", alac->setinfo_sample_size);\n\n            break;\n\n        default:\n\n            break;\n\n        }\n\n\n\n        break;\n\n    }\n\n    }\n\n\n\n    return input_buffer_size;\n\n}\n", "idx": 26695}
{"project": "FFmpeg", "commit_id": "292850b634240045805e3c2001aed6f046034e93", "target": 0, "func": "static int add_doubles_metadata(int count,\n\n                                const char *name, const char *sep,\n\n                                TiffContext *s)\n\n{\n\n    char *ap;\n\n    int i;\n\n    double *dp;\n\n\n\n    if (bytestream2_get_bytes_left(&s->gb) < count * sizeof(int64_t))\n\n        return -1;\n\n\n\n    dp = av_malloc(count * sizeof(double));\n\n    if (!dp)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for (i = 0; i < count; i++)\n\n        dp[i] = tget_double(&s->gb, s->le);\n\n    ap = doubles2str(dp, count, sep);\n\n    av_freep(&dp);\n\n    if (!ap)\n\n        return AVERROR(ENOMEM);\n\n    av_dict_set(&s->picture.metadata, name, ap, AV_DICT_DONT_STRDUP_VAL);\n\n    return 0;\n\n}\n", "idx": 26704}
{"project": "FFmpeg", "commit_id": "85aded741e03b17b0cc5c588b1f5acbcb25d7996", "target": 1, "func": "static int decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *data_size, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    C93DecoderContext * const c93 = avctx->priv_data;\n\n    AVFrame * const newpic = &c93->pictures[c93->currentpic];\n\n    AVFrame * const oldpic = &c93->pictures[c93->currentpic^1];\n\n    AVFrame *picture = data;\n\n    uint8_t *out;\n\n    int stride, i, x, y, bt = 0;\n\n\n\n    c93->currentpic ^= 1;\n\n\n\n    newpic->reference = 1;\n\n    newpic->buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE |\n\n                         FF_BUFFER_HINTS_REUSABLE | FF_BUFFER_HINTS_READABLE;\n\n    if (avctx->reget_buffer(avctx, newpic)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    stride = newpic->linesize[0];\n\n\n\n    if (buf[0] & C93_FIRST_FRAME) {\n\n        newpic->pict_type = AV_PICTURE_TYPE_I;\n\n        newpic->key_frame = 1;\n\n    } else {\n\n        newpic->pict_type = AV_PICTURE_TYPE_P;\n\n        newpic->key_frame = 0;\n\n    }\n\n\n\n    if (*buf++ & C93_HAS_PALETTE) {\n\n        uint32_t *palette = (uint32_t *) newpic->data[1];\n\n        const uint8_t *palbuf = buf + buf_size - 768 - 1;\n\n        for (i = 0; i < 256; i++) {\n\n            palette[i] = bytestream_get_be24(&palbuf);\n\n        }\n\n    } else {\n\n        if (oldpic->data[1])\n\n            memcpy(newpic->data[1], oldpic->data[1], 256 * 4);\n\n    }\n\n\n\n    for (y = 0; y < HEIGHT; y += 8) {\n\n        out = newpic->data[0] + y * stride;\n\n        for (x = 0; x < WIDTH; x += 8) {\n\n            uint8_t *copy_from = oldpic->data[0];\n\n            unsigned int offset, j;\n\n            uint8_t cols[4], grps[4];\n\n            C93BlockType block_type;\n\n\n\n            if (!bt)\n\n                bt = *buf++;\n\n\n\n            block_type= bt & 0x0F;\n\n            switch (block_type) {\n\n            case C93_8X8_FROM_PREV:\n\n                offset = bytestream_get_le16(&buf);\n\n                if (copy_block(avctx, out, copy_from, offset, 8, stride))\n\n                    return -1;\n\n                break;\n\n\n\n            case C93_4X4_FROM_CURR:\n\n                copy_from = newpic->data[0];\n\n            case C93_4X4_FROM_PREV:\n\n                for (j = 0; j < 8; j += 4) {\n\n                    for (i = 0; i < 8; i += 4) {\n\n                        offset = bytestream_get_le16(&buf);\n\n                        if (copy_block(avctx, &out[j*stride+i],\n\n                                           copy_from, offset, 4, stride))\n\n                            return -1;\n\n                    }\n\n                }\n\n                break;\n\n\n\n            case C93_8X8_2COLOR:\n\n                bytestream_get_buffer(&buf, cols, 2);\n\n                for (i = 0; i < 8; i++) {\n\n                    draw_n_color(out + i*stride, stride, 8, 1, 1, cols,\n\n                                     NULL, *buf++);\n\n                }\n\n\n\n                break;\n\n\n\n            case C93_4X4_2COLOR:\n\n            case C93_4X4_4COLOR:\n\n            case C93_4X4_4COLOR_GRP:\n\n                for (j = 0; j < 8; j += 4) {\n\n                    for (i = 0; i < 8; i += 4) {\n\n                        if (block_type == C93_4X4_2COLOR) {\n\n                            bytestream_get_buffer(&buf, cols, 2);\n\n                            draw_n_color(out + i + j*stride, stride, 4, 4,\n\n                                    1, cols, NULL, bytestream_get_le16(&buf));\n\n                        } else if (block_type == C93_4X4_4COLOR) {\n\n                            bytestream_get_buffer(&buf, cols, 4);\n\n                            draw_n_color(out + i + j*stride, stride, 4, 4,\n\n                                    2, cols, NULL, bytestream_get_le32(&buf));\n\n                        } else {\n\n                            bytestream_get_buffer(&buf, grps, 4);\n\n                            draw_n_color(out + i + j*stride, stride, 4, 4,\n\n                                    1, cols, grps, bytestream_get_le16(&buf));\n\n                        }\n\n                    }\n\n                }\n\n                break;\n\n\n\n            case C93_NOOP:\n\n                break;\n\n\n\n            case C93_8X8_INTRA:\n\n                for (j = 0; j < 8; j++)\n\n                    bytestream_get_buffer(&buf, out + j*stride, 8);\n\n                break;\n\n\n\n            default:\n\n                av_log(avctx, AV_LOG_ERROR, \"unexpected type %x at %dx%d\\n\",\n\n                       block_type, x, y);\n\n                return -1;\n\n            }\n\n            bt >>= 4;\n\n            out += 8;\n\n        }\n\n    }\n\n\n\n    *picture = *newpic;\n\n    *data_size = sizeof(AVFrame);\n\n\n\n    return buf_size;\n\n}\n", "idx": 26714}
{"project": "FFmpeg", "commit_id": "9e1914dfbafb59b424a7c06cfdd324a85c33ef44", "target": 1, "func": "static int filter_frame(AVFilterLink *inlink, AVFilterBufferRef *in)\n\n{\n\n    HQDN3DContext *hqdn3d = inlink->dst->priv;\n\n    AVFilterLink *outlink = inlink->dst->outputs[0];\n\n\n\n    AVFilterBufferRef *out;\n\n    int direct, c;\n\n\n\n    if (in->perms & AV_PERM_WRITE) {\n\n        direct = 1;\n\n        out = in;\n\n    } else {\n\n        out = ff_get_video_buffer(outlink, AV_PERM_WRITE, outlink->w, outlink->h);\n\n        if (!out) {\n\n            avfilter_unref_bufferp(&in);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n\n\n        avfilter_copy_buffer_ref_props(out, in);\n\n        out->video->w = outlink->w;\n\n        out->video->h = outlink->h;\n\n    }\n\n\n\n    for (c = 0; c < 3; c++) {\n\n        denoise(hqdn3d, in->data[c], out->data[c],\n\n                hqdn3d->line, &hqdn3d->frame_prev[c],\n\n                in->video->w >> (!!c * hqdn3d->hsub),\n\n                in->video->h >> (!!c * hqdn3d->vsub),\n\n                in->linesize[c], out->linesize[c],\n\n                hqdn3d->coefs[c?2:0], hqdn3d->coefs[c?3:1]);\n\n    }\n\n\n\n    if (!direct)\n\n        avfilter_unref_bufferp(&in);\n\n\n\n    return ff_filter_frame(outlink, out);\n\n}\n", "idx": 26716}
{"project": "FFmpeg", "commit_id": "9079e99d2c462ec7ef2e89d9e77ee6c3553dacce", "target": 1, "func": "static int encode_block(SVQ1EncContext *s, uint8_t *src, uint8_t *ref,\n\n                        uint8_t *decoded, int stride, int level,\n\n                        int threshold, int lambda, int intra)\n\n{\n\n    int count, y, x, i, j, split, best_mean, best_score, best_count;\n\n    int best_vector[6];\n\n    int block_sum[7] = { 0, 0, 0, 0, 0, 0 };\n\n    int w            = 2 << (level + 2 >> 1);\n\n    int h            = 2 << (level + 1 >> 1);\n\n    int size         = w * h;\n\n    int16_t (*block)[256] = s->encoded_block_levels[level];\n\n    const int8_t *codebook_sum, *codebook;\n\n    const uint16_t(*mean_vlc)[2];\n\n    const uint8_t(*multistage_vlc)[2];\n\n\n\n    best_score = 0;\n\n    // FIXME: Optimize, this does not need to be done multiple times.\n\n    if (intra) {\n\n        codebook_sum   = svq1_intra_codebook_sum[level];\n\n        codebook       = ff_svq1_intra_codebooks[level];\n\n        mean_vlc       = ff_svq1_intra_mean_vlc;\n\n        multistage_vlc = ff_svq1_intra_multistage_vlc[level];\n\n        for (y = 0; y < h; y++) {\n\n            for (x = 0; x < w; x++) {\n\n                int v = src[x + y * stride];\n\n                block[0][x + w * y] = v;\n\n                best_score         += v * v;\n\n                block_sum[0]       += v;\n\n            }\n\n        }\n\n    } else {\n\n        codebook_sum   = svq1_inter_codebook_sum[level];\n\n        codebook       = ff_svq1_inter_codebooks[level];\n\n        mean_vlc       = ff_svq1_inter_mean_vlc + 256;\n\n        multistage_vlc = ff_svq1_inter_multistage_vlc[level];\n\n        for (y = 0; y < h; y++) {\n\n            for (x = 0; x < w; x++) {\n\n                int v = src[x + y * stride] - ref[x + y * stride];\n\n                block[0][x + w * y] = v;\n\n                best_score         += v * v;\n\n                block_sum[0]       += v;\n\n            }\n\n        }\n\n    }\n\n\n\n    best_count  = 0;\n\n    best_score -= (int)((unsigned)block_sum[0] * block_sum[0] >> (level + 3));\n\n    best_mean   = block_sum[0] + (size >> 1) >> (level + 3);\n\n\n\n    if (level < 4) {\n\n        for (count = 1; count < 7; count++) {\n\n            int best_vector_score = INT_MAX;\n\n            int best_vector_sum   = -999, best_vector_mean = -999;\n\n            const int stage       = count - 1;\n\n            const int8_t *vector;\n\n\n\n            for (i = 0; i < 16; i++) {\n\n                int sum = codebook_sum[stage * 16 + i];\n\n                int sqr, diff, score;\n\n\n\n                vector = codebook + stage * size * 16 + i * size;\n\n                sqr    = s->ssd_int8_vs_int16(vector, block[stage], size);\n\n                diff   = block_sum[stage] - sum;\n\n                score  = sqr - (diff * (int64_t)diff >> (level + 3)); // FIXME: 64bit slooow\n\n                if (score < best_vector_score) {\n\n                    int mean = diff + (size >> 1) >> (level + 3);\n\n                    av_assert2(mean > -300 && mean < 300);\n\n                    mean               = av_clip(mean, intra ? 0 : -256, 255);\n\n                    best_vector_score  = score;\n\n                    best_vector[stage] = i;\n\n                    best_vector_sum    = sum;\n\n                    best_vector_mean   = mean;\n\n                }\n\n            }\n\n            av_assert0(best_vector_mean != -999);\n\n            vector = codebook + stage * size * 16 + best_vector[stage] * size;\n\n            for (j = 0; j < size; j++)\n\n                block[stage + 1][j] = block[stage][j] - vector[j];\n\n            block_sum[stage + 1] = block_sum[stage] - best_vector_sum;\n\n            best_vector_score   += lambda *\n\n                                   (+1 + 4 * count +\n\n                                    multistage_vlc[1 + count][1]\n\n                                    + mean_vlc[best_vector_mean][1]);\n\n\n\n            if (best_vector_score < best_score) {\n\n                best_score = best_vector_score;\n\n                best_count = count;\n\n                best_mean  = best_vector_mean;\n\n            }\n\n        }\n\n    }\n\n\n\n    split = 0;\n\n    if (best_score > threshold && level) {\n\n        int score  = 0;\n\n        int offset = level & 1 ? stride * h / 2 : w / 2;\n\n        PutBitContext backup[6];\n\n\n\n        for (i = level - 1; i >= 0; i--)\n\n            backup[i] = s->reorder_pb[i];\n\n        score += encode_block(s, src, ref, decoded, stride, level - 1,\n\n                              threshold >> 1, lambda, intra);\n\n        score += encode_block(s, src + offset, ref + offset, decoded + offset,\n\n                              stride, level - 1, threshold >> 1, lambda, intra);\n\n        score += lambda;\n\n\n\n        if (score < best_score) {\n\n            best_score = score;\n\n            split      = 1;\n\n        } else {\n\n            for (i = level - 1; i >= 0; i--)\n\n                s->reorder_pb[i] = backup[i];\n\n        }\n\n    }\n\n    if (level > 0)\n\n        put_bits(&s->reorder_pb[level], 1, split);\n\n\n\n    if (!split) {\n\n        av_assert1(best_mean >= 0 && best_mean < 256 || !intra);\n\n        av_assert1(best_mean >= -256 && best_mean < 256);\n\n        av_assert1(best_count >= 0 && best_count < 7);\n\n        av_assert1(level < 4 || best_count == 0);\n\n\n\n        /* output the encoding */\n\n        put_bits(&s->reorder_pb[level],\n\n                 multistage_vlc[1 + best_count][1],\n\n                 multistage_vlc[1 + best_count][0]);\n\n        put_bits(&s->reorder_pb[level], mean_vlc[best_mean][1],\n\n                 mean_vlc[best_mean][0]);\n\n\n\n        for (i = 0; i < best_count; i++) {\n\n            av_assert2(best_vector[i] >= 0 && best_vector[i] < 16);\n\n            put_bits(&s->reorder_pb[level], 4, best_vector[i]);\n\n        }\n\n\n\n        for (y = 0; y < h; y++)\n\n            for (x = 0; x < w; x++)\n\n                decoded[x + y * stride] = src[x + y * stride] -\n\n                                          block[best_count][x + w * y] +\n\n                                          best_mean;\n\n    }\n\n\n\n    return best_score;\n\n}\n", "idx": 26720}
{"project": "FFmpeg", "commit_id": "d1ac8e10340f30b6989cfd64ed1f91dae5a54e2d", "target": 0, "func": "static inline CopyRet copy_frame(AVCodecContext *avctx,\n\n                                 BC_DTS_PROC_OUT *output,\n\n                                 void *data, int *data_size)\n\n{\n\n    BC_STATUS ret;\n\n    BC_DTS_STATUS decoder_status = { 0, };\n\n    uint8_t trust_interlaced;\n\n    uint8_t interlaced;\n\n\n\n    CHDContext *priv = avctx->priv_data;\n\n    int64_t pkt_pts  = AV_NOPTS_VALUE;\n\n    uint8_t pic_type = 0;\n\n\n\n    uint8_t bottom_field = (output->PicInfo.flags & VDEC_FLAG_BOTTOMFIELD) ==\n\n                           VDEC_FLAG_BOTTOMFIELD;\n\n    uint8_t bottom_first = !!(output->PicInfo.flags & VDEC_FLAG_BOTTOM_FIRST);\n\n\n\n    int width    = output->PicInfo.width;\n\n    int height   = output->PicInfo.height;\n\n    int bwidth;\n\n    uint8_t *src = output->Ybuff;\n\n    int sStride;\n\n    uint8_t *dst;\n\n    int dStride;\n\n\n\n    if (output->PicInfo.timeStamp != 0) {\n\n        OpaqueList *node = opaque_list_pop(priv, output->PicInfo.timeStamp);\n\n        if (node) {\n\n            pkt_pts = node->reordered_opaque;\n\n            pic_type = node->pic_type;\n\n            av_free(node);\n\n        } else {\n\n            /*\n\n             * We will encounter a situation where a timestamp cannot be\n\n             * popped if a second field is being returned. In this case,\n\n             * each field has the same timestamp and the first one will\n\n             * cause it to be popped. To keep subsequent calculations\n\n             * simple, pic_type should be set a FIELD value - doesn't\n\n             * matter which, but I chose BOTTOM.\n\n             */\n\n            pic_type = PICT_BOTTOM_FIELD;\n\n        }\n\n        av_log(avctx, AV_LOG_VERBOSE, \"output \\\"pts\\\": %\"PRIu64\"\\n\",\n\n               output->PicInfo.timeStamp);\n\n        av_log(avctx, AV_LOG_VERBOSE, \"output picture type %d\\n\",\n\n               pic_type);\n\n    }\n\n\n\n    ret = DtsGetDriverStatus(priv->dev, &decoder_status);\n\n    if (ret != BC_STS_SUCCESS) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"CrystalHD: GetDriverStatus failed: %u\\n\", ret);\n\n       return RET_ERROR;\n\n    }\n\n\n\n    /*\n\n     * For most content, we can trust the interlaced flag returned\n\n     * by the hardware, but sometimes we can't. These are the\n\n     * conditions under which we can trust the flag:\n\n     *\n\n     * 1) It's not h.264 content\n\n     * 2) The UNKNOWN_SRC flag is not set\n\n     * 3) We know we're expecting a second field\n\n     * 4) The hardware reports this picture and the next picture\n\n     *    have the same picture number.\n\n     *\n\n     * Note that there can still be interlaced content that will\n\n     * fail this check, if the hardware hasn't decoded the next\n\n     * picture or if there is a corruption in the stream. (In either\n\n     * case a 0 will be returned for the next picture number)\n\n     */\n\n    trust_interlaced = avctx->codec->id != CODEC_ID_H264 ||\n\n                       !(output->PicInfo.flags & VDEC_FLAG_UNKNOWN_SRC) ||\n\n                       priv->need_second_field ||\n\n                       (decoder_status.picNumFlags & ~0x40000000) ==\n\n                       output->PicInfo.picture_number;\n\n\n\n    /*\n\n     * If we got a false negative for trust_interlaced on the first field,\n\n     * we will realise our mistake here when we see that the picture number is that\n\n     * of the previous picture. We cannot recover the frame and should discard the\n\n     * second field to keep the correct number of output frames.\n\n     */\n\n    if (output->PicInfo.picture_number == priv->last_picture && !priv->need_second_field) {\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"Incorrectly guessed progressive frame. Discarding second field\\n\");\n\n        /* Returning without providing a picture. */\n\n        return RET_OK;\n\n    }\n\n\n\n    interlaced = (output->PicInfo.flags & VDEC_FLAG_INTERLACED_SRC) &&\n\n                 trust_interlaced;\n\n\n\n    if (!trust_interlaced && (decoder_status.picNumFlags & ~0x40000000) == 0) {\n\n        av_log(avctx, AV_LOG_VERBOSE,\n\n               \"Next picture number unknown. Assuming progressive frame.\\n\");\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_VERBOSE, \"Interlaced state: %d | trust_interlaced %d\\n\",\n\n           interlaced, trust_interlaced);\n\n\n\n    if (priv->pic.data[0] && !priv->need_second_field)\n\n        avctx->release_buffer(avctx, &priv->pic);\n\n\n\n    priv->need_second_field = interlaced && !priv->need_second_field;\n\n\n\n    priv->pic.buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE |\n\n                             FF_BUFFER_HINTS_REUSABLE;\n\n    if (!priv->pic.data[0]) {\n\n        if (avctx->get_buffer(avctx, &priv->pic) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n            return RET_ERROR;\n\n        }\n\n    }\n\n\n\n    bwidth = av_image_get_linesize(avctx->pix_fmt, width, 0);\n\n    if (priv->is_70012) {\n\n        int pStride;\n\n\n\n        if (width <= 720)\n\n            pStride = 720;\n\n        else if (width <= 1280)\n\n            pStride = 1280;\n\n        else pStride = 1920;\n\n        sStride = av_image_get_linesize(avctx->pix_fmt, pStride, 0);\n\n    } else {\n\n        sStride = bwidth;\n\n    }\n\n\n\n    dStride = priv->pic.linesize[0];\n\n    dst     = priv->pic.data[0];\n\n\n\n    av_log(priv->avctx, AV_LOG_VERBOSE, \"CrystalHD: Copying out frame\\n\");\n\n\n\n    if (interlaced) {\n\n        int dY = 0;\n\n        int sY = 0;\n\n\n\n        height /= 2;\n\n        if (bottom_field) {\n\n            av_log(priv->avctx, AV_LOG_VERBOSE, \"Interlaced: bottom field\\n\");\n\n            dY = 1;\n\n        } else {\n\n            av_log(priv->avctx, AV_LOG_VERBOSE, \"Interlaced: top field\\n\");\n\n            dY = 0;\n\n        }\n\n\n\n        for (sY = 0; sY < height; dY++, sY++) {\n\n            memcpy(&(dst[dY * dStride]), &(src[sY * sStride]), bwidth);\n\n            dY++;\n\n        }\n\n    } else {\n\n        av_image_copy_plane(dst, dStride, src, sStride, bwidth, height);\n\n    }\n\n\n\n    priv->pic.interlaced_frame = interlaced;\n\n    if (interlaced)\n\n        priv->pic.top_field_first = !bottom_first;\n\n\n\n    priv->pic.pkt_pts = pkt_pts;\n\n\n\n    if (!priv->need_second_field) {\n\n        *data_size       = sizeof(AVFrame);\n\n        *(AVFrame *)data = priv->pic;\n\n    }\n\n\n\n    /*\n\n     * Two types of PAFF content have been observed. One form causes the\n\n     * hardware to return a field pair and the other individual fields,\n\n     * even though the input is always individual fields. We must skip\n\n     * copying on the next decode() call to maintain pipeline length in\n\n     * the first case.\n\n     */\n\n    if (!interlaced && (output->PicInfo.flags & VDEC_FLAG_UNKNOWN_SRC) &&\n\n        (pic_type == PICT_TOP_FIELD || pic_type == PICT_BOTTOM_FIELD)) {\n\n        av_log(priv->avctx, AV_LOG_VERBOSE, \"Fieldpair from two packets.\\n\");\n\n        return RET_SKIP_NEXT_COPY;\n\n    }\n\n\n\n    /*\n\n     * Testing has shown that in all cases where we don't want to return the\n\n     * full frame immediately, VDEC_FLAG_UNKNOWN_SRC is set.\n\n     */\n\n    return priv->need_second_field &&\n\n           !(output->PicInfo.flags & VDEC_FLAG_UNKNOWN_SRC) ?\n\n           RET_COPY_NEXT_FIELD : RET_OK;\n\n}\n", "idx": 26722}
{"project": "FFmpeg", "commit_id": "c3ab0004ae4dffc32494ae84dd15cfaa909a7884", "target": 1, "func": "static inline void RENAME(hyscale_fast)(SwsContext *c, int16_t *dst,\n\n                                        int dstWidth, const uint8_t *src, int srcW,\n\n                                        int xInc)\n\n{\n\n#if ARCH_X86\n\n#if COMPILE_TEMPLATE_MMX2\n\n    int32_t *filterPos = c->hLumFilterPos;\n\n    int16_t *filter    = c->hLumFilter;\n\n    int     canMMX2BeUsed  = c->canMMX2BeUsed;\n\n    void    *mmx2FilterCode= c->lumMmx2FilterCode;\n\n    int i;\n\n#if defined(PIC)\n\n    DECLARE_ALIGNED(8, uint64_t, ebxsave);\n\n#endif\n\n    if (canMMX2BeUsed) {\n\n        __asm__ volatile(\n\n#if defined(PIC)\n\n            \"mov               %%\"REG_b\", %5        \\n\\t\"\n\n#endif\n\n            \"pxor                  %%mm7, %%mm7     \\n\\t\"\n\n            \"mov                      %0, %%\"REG_c\" \\n\\t\"\n\n            \"mov                      %1, %%\"REG_D\" \\n\\t\"\n\n            \"mov                      %2, %%\"REG_d\" \\n\\t\"\n\n            \"mov                      %3, %%\"REG_b\" \\n\\t\"\n\n            \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\" // i\n\n            PREFETCH\"        (%%\"REG_c\")            \\n\\t\"\n\n            PREFETCH\"      32(%%\"REG_c\")            \\n\\t\"\n\n            PREFETCH\"      64(%%\"REG_c\")            \\n\\t\"\n\n\n\n#if ARCH_X86_64\n\n\n\n#define CALL_MMX2_FILTER_CODE \\\n\n            \"movl            (%%\"REG_b\"), %%esi     \\n\\t\"\\\n\n            \"call                    *%4            \\n\\t\"\\\n\n            \"movl (%%\"REG_b\", %%\"REG_a\"), %%esi     \\n\\t\"\\\n\n            \"add               %%\"REG_S\", %%\"REG_c\" \\n\\t\"\\\n\n            \"add               %%\"REG_a\", %%\"REG_D\" \\n\\t\"\\\n\n            \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\"\\\n\n\n\n#else\n\n\n\n#define CALL_MMX2_FILTER_CODE \\\n\n            \"movl (%%\"REG_b\"), %%esi        \\n\\t\"\\\n\n            \"call         *%4                       \\n\\t\"\\\n\n            \"addl (%%\"REG_b\", %%\"REG_a\"), %%\"REG_c\" \\n\\t\"\\\n\n            \"add               %%\"REG_a\", %%\"REG_D\" \\n\\t\"\\\n\n            \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\"\\\n\n\n\n#endif /* ARCH_X86_64 */\n\n\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n\n\n#if defined(PIC)\n\n            \"mov                      %5, %%\"REG_b\" \\n\\t\"\n\n#endif\n\n            :: \"m\" (src), \"m\" (dst), \"m\" (filter), \"m\" (filterPos),\n\n            \"m\" (mmx2FilterCode)\n\n#if defined(PIC)\n\n            ,\"m\" (ebxsave)\n\n#endif\n\n            : \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S, \"%\"REG_D\n\n#if !defined(PIC)\n\n            ,\"%\"REG_b\n\n#endif\n\n        );\n\n        for (i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--) dst[i] = src[srcW-1]*128;\n\n    } else {\n\n#endif /* COMPILE_TEMPLATE_MMX2 */\n\n    x86_reg dstWidth_reg = dstWidth;\n\n    x86_reg xInc_shr16 = xInc >> 16;\n\n    uint16_t xInc_mask = xInc & 0xffff;\n\n    //NO MMX just normal asm ...\n\n    __asm__ volatile(\n\n        \"xor %%\"REG_a\", %%\"REG_a\"            \\n\\t\" // i\n\n        \"xor %%\"REG_d\", %%\"REG_d\"            \\n\\t\" // xx\n\n        \"xorl    %%ecx, %%ecx                \\n\\t\" // xalpha\n\n        ASMALIGN(4)\n\n        \"1:                                  \\n\\t\"\n\n        \"movzbl    (%0, %%\"REG_d\"), %%edi    \\n\\t\" //src[xx]\n\n        \"movzbl   1(%0, %%\"REG_d\"), %%esi    \\n\\t\" //src[xx+1]\n\n        FAST_BILINEAR_X86\n\n        \"movw     %%si, (%%\"REG_D\", %%\"REG_a\", 2)   \\n\\t\"\n\n        \"addw       %4, %%cx                 \\n\\t\" //xalpha += xInc&0xFFFF\n\n        \"adc        %3, %%\"REG_d\"            \\n\\t\" //xx+= xInc>>16 + carry\n\n\n\n        \"movzbl    (%0, %%\"REG_d\"), %%edi    \\n\\t\" //src[xx]\n\n        \"movzbl   1(%0, %%\"REG_d\"), %%esi    \\n\\t\" //src[xx+1]\n\n        FAST_BILINEAR_X86\n\n        \"movw     %%si, 2(%%\"REG_D\", %%\"REG_a\", 2)  \\n\\t\"\n\n        \"addw       %4, %%cx                 \\n\\t\" //xalpha += xInc&0xFFFF\n\n        \"adc        %3, %%\"REG_d\"            \\n\\t\" //xx+= xInc>>16 + carry\n\n\n\n\n\n        \"add        $2, %%\"REG_a\"            \\n\\t\"\n\n        \"cmp        %2, %%\"REG_a\"            \\n\\t\"\n\n        \" jb        1b                       \\n\\t\"\n\n\n\n\n\n        :: \"r\" (src), \"m\" (dst), \"m\" (dstWidth_reg), \"m\" (xInc_shr16), \"m\" (xInc_mask)\n\n        : \"%\"REG_a, \"%\"REG_d, \"%ecx\", \"%\"REG_D, \"%esi\"\n\n    );\n\n#if COMPILE_TEMPLATE_MMX2\n\n    } //if MMX2 can't be used\n\n#endif\n\n#else\n\n    int i;\n\n    unsigned int xpos=0;\n\n    for (i=0;i<dstWidth;i++) {\n\n        register unsigned int xx=xpos>>16;\n\n        register unsigned int xalpha=(xpos&0xFFFF)>>9;\n\n        dst[i]= (src[xx]<<7) + (src[xx+1] - src[xx])*xalpha;\n\n        xpos+=xInc;\n\n    }\n\n#endif /* ARCH_X86 */\n\n}\n", "idx": 26727}
{"project": "FFmpeg", "commit_id": "9d0b45ade864f3d2ccd8610149fe1fff53c4e937", "target": 1, "func": "static int decrypt_init(AVFormatContext *s, ID3v2ExtraMeta *em, uint8_t *header)\n\n{\n\n    OMAContext *oc = s->priv_data;\n\n    ID3v2ExtraMetaGEOB *geob = NULL;\n\n    uint8_t *gdata;\n\n\n\n    oc->encrypted = 1;\n\n    av_log(s, AV_LOG_INFO, \"File is encrypted\\n\");\n\n\n\n    /* find GEOB metadata */\n\n    while (em) {\n\n        if (!strcmp(em->tag, \"GEOB\") &&\n\n            (geob = em->data) &&\n\n            (!strcmp(geob->description, \"OMG_LSI\") ||\n\n             !strcmp(geob->description, \"OMG_BKLSI\"))) {\n\n            break;\n\n        }\n\n        em = em->next;\n\n    }\n\n    if (!em) {\n\n        av_log(s, AV_LOG_ERROR, \"No encryption header found\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (geob->datasize < 64) {\n\n        av_log(s, AV_LOG_ERROR,\n\n               \"Invalid GEOB data size: %u\\n\", geob->datasize);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    gdata = geob->data;\n\n\n\n    if (AV_RB16(gdata) != 1)\n\n        av_log(s, AV_LOG_WARNING, \"Unknown version in encryption header\\n\");\n\n\n\n    oc->k_size = AV_RB16(&gdata[2]);\n\n    oc->e_size = AV_RB16(&gdata[4]);\n\n    oc->i_size = AV_RB16(&gdata[6]);\n\n    oc->s_size = AV_RB16(&gdata[8]);\n\n\n\n    if (memcmp(&gdata[OMA_ENC_HEADER_SIZE], \"KEYRING     \", 12)) {\n\n        av_log(s, AV_LOG_ERROR, \"Invalid encryption header\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    oc->rid = AV_RB32(&gdata[OMA_ENC_HEADER_SIZE + 28]);\n\n    av_log(s, AV_LOG_DEBUG, \"RID: %.8x\\n\", oc->rid);\n\n\n\n    memcpy(oc->iv, &header[0x58], 8);\n\n    hex_log(s, AV_LOG_DEBUG, \"IV\", oc->iv, 8);\n\n\n\n    hex_log(s, AV_LOG_DEBUG, \"CBC-MAC\",\n\n            &gdata[OMA_ENC_HEADER_SIZE + oc->k_size + oc->e_size + oc->i_size],\n\n            8);\n\n\n\n    if (s->keylen > 0) {\n\n        kset(s, s->key, s->key, s->keylen);\n\n    }\n\n    if (!memcmp(oc->r_val, (const uint8_t[8]){0}, 8) ||\n\n        rprobe(s, gdata, oc->r_val) < 0 &&\n\n        nprobe(s, gdata, geob->datasize, oc->n_val) < 0) {\n\n        int i;\n\n        for (i = 0; i < FF_ARRAY_ELEMS(leaf_table); i += 2) {\n\n            uint8_t buf[16];\n\n            AV_WL64(buf,     leaf_table[i]);\n\n            AV_WL64(&buf[8], leaf_table[i + 1]);\n\n            kset(s, buf, buf, 16);\n\n            if (!rprobe(s, gdata, oc->r_val) ||\n\n                !nprobe(s, gdata, geob->datasize, oc->n_val))\n\n                break;\n\n        }\n\n        if (i >= sizeof(leaf_table)) {\n\n            av_log(s, AV_LOG_ERROR, \"Invalid key\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    /* e_val */\n\n    av_des_init(&oc->av_des, oc->m_val, 64, 0);\n\n    av_des_crypt(&oc->av_des, oc->e_val,\n\n                 &gdata[OMA_ENC_HEADER_SIZE + 40], 1, NULL, 0);\n\n    hex_log(s, AV_LOG_DEBUG, \"EK\", oc->e_val, 8);\n\n\n\n    /* init e_val */\n\n    av_des_init(&oc->av_des, oc->e_val, 64, 1);\n\n\n\n    return 0;\n\n}\n", "idx": 26728}
{"project": "FFmpeg", "commit_id": "a443a2530d00b7019269202ac0f5ca8ba0a021c7", "target": 1, "func": "static int tta_read_header(AVFormatContext *s, AVFormatParameters *ap)\n{\n    TTAContext *c = s->priv_data;\n    AVStream *st;\n    int i, channels, bps, samplerate, datalen, framelen, start;\n    start = url_ftell(&s->pb);\n    if (get_le32(&s->pb) != ff_get_fourcc(\"TTA1\"))\n        return -1; // not tta file\n    url_fskip(&s->pb, 2); // FIXME: flags\n    channels = get_le16(&s->pb);\n    bps = get_le16(&s->pb);\n    samplerate = get_le32(&s->pb);\n    datalen = get_le32(&s->pb);\n    url_fskip(&s->pb, 4); // header crc\n    framelen = 1.04489795918367346939 * samplerate;\n    c->totalframes = datalen / framelen + ((datalen % framelen) ? 1 : 0);\n    c->currentframe = 0;\n    c->seektable = av_mallocz(sizeof(uint32_t)*c->totalframes);\n    if (!c->seektable)\n        return AVERROR_NOMEM;\n    for (i = 0; i < c->totalframes; i++)\n            c->seektable[i] = get_le32(&s->pb);\n    url_fskip(&s->pb, 4); // seektable crc\n    st = av_new_stream(s, 0);\n//    av_set_pts_info(st, 32, 1, 1000);\n    if (!st)\n        return AVERROR_NOMEM;\n    st->codec->codec_type = CODEC_TYPE_AUDIO;\n    st->codec->codec_id = CODEC_ID_TTA;\n    st->codec->channels = channels;\n    st->codec->sample_rate = samplerate;\n    st->codec->bits_per_sample = bps;\n    st->codec->extradata_size = url_ftell(&s->pb) - start;\n    if(st->codec->extradata_size+FF_INPUT_BUFFER_PADDING_SIZE <= (unsigned)st->codec->extradata_size){\n        //this check is redundant as get_buffer should fail\n        av_log(s, AV_LOG_ERROR, \"extradata_size too large\\n\");\n    st->codec->extradata = av_mallocz(st->codec->extradata_size+FF_INPUT_BUFFER_PADDING_SIZE);\n    url_fseek(&s->pb, start, SEEK_SET); // or SEEK_CUR and -size ? :)\n    get_buffer(&s->pb, st->codec->extradata, st->codec->extradata_size);\n    return 0;", "idx": 26729}
{"project": "FFmpeg", "commit_id": "79997def65fd2313b48a5f3c3a884c6149ae9b5d", "target": 0, "func": "static av_cold int fft_init(AVCodecContext *avctx, AC3MDCTContext *mdct, int ln)\n\n{\n\n    int i, n, n2;\n\n    float alpha;\n\n\n\n    n  = 1 << ln;\n\n    n2 = n >> 1;\n\n\n\n    FF_ALLOC_OR_GOTO(avctx, mdct->costab, n2 * sizeof(*mdct->costab), fft_alloc_fail);\n\n    FF_ALLOC_OR_GOTO(avctx, mdct->sintab, n2 * sizeof(*mdct->sintab), fft_alloc_fail);\n\n\n\n    for (i = 0; i < n2; i++) {\n\n        alpha     = 2.0 * M_PI * i / n;\n\n        mdct->costab[i] = FIX15(cos(alpha));\n\n        mdct->sintab[i] = FIX15(sin(alpha));\n\n    }\n\n\n\n    return 0;\n\nfft_alloc_fail:\n\n    mdct_end(mdct);\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 26730}
{"project": "FFmpeg", "commit_id": "28bf81c90d36a55cf76e2be913c5215ebebf61f2", "target": 1, "func": "void in_asm_used_var_warning_killer()\n\n{\n\n volatile int i= yCoeff+vrCoeff+ubCoeff+vgCoeff+ugCoeff+bF8+bFC+w400+w80+w10+\n\n bm00001111+bm00000111+bm11111000+b16Mask+g16Mask+r16Mask+b15Mask+g15Mask+r15Mask+temp0+asm_yalpha1+ asm_uvalpha1+\n\n M24A+M24B+M24C+w02 + funnyYCode[0]+ funnyUVCode[0]+b5Dither+g5Dither+r5Dither+g6Dither+dither4[0]+dither8[0];\n\n if(i) i=0;\n\n}\n", "idx": 26732}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "static void vc1_inv_trans_4x8_dc_c(uint8_t *dest, int linesize, DCTELEM *block)\n\n{\n\n    int i;\n\n    int dc = block[0];\n\n    const uint8_t *cm;\n\n    dc = (17 * dc +  4) >> 3;\n\n    dc = (12 * dc + 64) >> 7;\n\n    cm = ff_cropTbl + MAX_NEG_CROP + dc;\n\n    for(i = 0; i < 8; i++){\n\n        dest[0] = cm[dest[0]];\n\n        dest[1] = cm[dest[1]];\n\n        dest[2] = cm[dest[2]];\n\n        dest[3] = cm[dest[3]];\n\n        dest += linesize;\n\n    }\n\n}\n", "idx": 26733}
{"project": "FFmpeg", "commit_id": "b6f80b16d1a82463a77352b8756e1cdcaa3a33d0", "target": 1, "func": "static int qsv_decode(AVCodecContext *avctx, QSVContext *q,\n\n                      AVFrame *frame, int *got_frame,\n\n                      AVPacket *avpkt)\n\n{\n\n    QSVFrame *out_frame;\n\n    mfxFrameSurface1 *insurf;\n\n    mfxFrameSurface1 *outsurf;\n\n    mfxSyncPoint *sync;\n\n    mfxBitstream bs = { { { 0 } } };\n\n    int ret;\n\n\n\n    if (avpkt->size) {\n\n        bs.Data       = avpkt->data;\n\n        bs.DataLength = avpkt->size;\n\n        bs.MaxLength  = bs.DataLength;\n\n        bs.TimeStamp  = avpkt->pts;\n\n    }\n\n\n\n    sync = av_mallocz(sizeof(*sync));\n\n    if (!sync) {\n\n        av_freep(&sync);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    do {\n\n        ret = get_surface(avctx, q, &insurf);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        ret = MFXVideoDECODE_DecodeFrameAsync(q->session, avpkt->size ? &bs : NULL,\n\n                                              insurf, &outsurf, sync);\n\n        if (ret == MFX_WRN_DEVICE_BUSY)\n\n            av_usleep(500);\n\n\n\n    } while (ret == MFX_WRN_DEVICE_BUSY || ret == MFX_ERR_MORE_SURFACE);\n\n\n\n    if (ret != MFX_ERR_NONE &&\n\n        ret != MFX_ERR_MORE_DATA &&\n\n        ret != MFX_WRN_VIDEO_PARAM_CHANGED &&\n\n        ret != MFX_ERR_MORE_SURFACE) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error during QSV decoding.\\n\");\n\n        av_freep(&sync);\n\n        return ff_qsv_error(ret);\n\n    }\n\n\n\n    /* make sure we do not enter an infinite loop if the SDK\n\n     * did not consume any data and did not return anything */\n\n    if (!*sync && !bs.DataOffset) {\n\n        av_log(avctx, AV_LOG_WARNING, \"A decode call did not consume any data\\n\");\n\n        bs.DataOffset = avpkt->size;\n\n    }\n\n\n\n    if (*sync) {\n\n        QSVFrame *out_frame = find_frame(q, outsurf);\n\n\n\n        if (!out_frame) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"The returned surface does not correspond to any frame\\n\");\n\n            av_freep(&sync);\n\n            return AVERROR_BUG;\n\n        }\n\n\n\n        out_frame->queued = 1;\n\n        av_fifo_generic_write(q->async_fifo, &out_frame, sizeof(out_frame), NULL);\n\n        av_fifo_generic_write(q->async_fifo, &sync,      sizeof(sync),      NULL);\n\n    } else {\n\n        av_freep(&sync);\n\n    }\n\n\n\n    if (!av_fifo_space(q->async_fifo) ||\n\n        (!avpkt->size && av_fifo_size(q->async_fifo))) {\n\n        AVFrame *src_frame;\n\n\n\n        av_fifo_generic_read(q->async_fifo, &out_frame, sizeof(out_frame), NULL);\n\n        av_fifo_generic_read(q->async_fifo, &sync,      sizeof(sync),      NULL);\n\n        out_frame->queued = 0;\n\n\n\n        do {\n\n            ret = MFXVideoCORE_SyncOperation(q->session, *sync, 1000);\n\n        } while (ret == MFX_WRN_IN_EXECUTION);\n\n\n\n        av_freep(&sync);\n\n\n\n        src_frame = out_frame->frame;\n\n\n\n        ret = av_frame_ref(frame, src_frame);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        outsurf = out_frame->surface;\n\n\n\n#if FF_API_PKT_PTS\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n        frame->pkt_pts = outsurf->Data.TimeStamp;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n        frame->pts = outsurf->Data.TimeStamp;\n\n\n\n        frame->repeat_pict =\n\n            outsurf->Info.PicStruct & MFX_PICSTRUCT_FRAME_TRIPLING ? 4 :\n\n            outsurf->Info.PicStruct & MFX_PICSTRUCT_FRAME_DOUBLING ? 2 :\n\n            outsurf->Info.PicStruct & MFX_PICSTRUCT_FIELD_REPEATED ? 1 : 0;\n\n        frame->top_field_first =\n\n            outsurf->Info.PicStruct & MFX_PICSTRUCT_FIELD_TFF;\n\n        frame->interlaced_frame =\n\n            !(outsurf->Info.PicStruct & MFX_PICSTRUCT_PROGRESSIVE);\n\n\n\n        *got_frame = 1;\n\n    }\n\n\n\n    return bs.DataOffset;\n\n}\n", "idx": 26740}
{"project": "FFmpeg", "commit_id": "92e483f8ed70d88d4f64337f65bae212502735d4", "target": 1, "func": "static int cmp(const void *a, const void *b)\n\n{\n\n    const double va = *(const double *)a, vb = *(const double *)b;\n\n    return va < vb ? -1 : ( va > vb ? 1 : 0 );\n\n}\n", "idx": 26741}
{"project": "FFmpeg", "commit_id": "e30004fa733ec64b6ff90678098c1f1132d4d603", "target": 1, "func": "static void read_len_table(uint8_t *dst, GetBitContext *gb){\n\n    int i, val, repeat;\n\n\n\n    for(i=0; i<256;){\n\n        repeat= get_bits(gb, 3);\n\n        val   = get_bits(gb, 5);\n\n        if(repeat==0)\n\n            repeat= get_bits(gb, 8);\n\n//printf(\"%d %d\\n\", val, repeat);\n\n        while (repeat--)\n\n            dst[i++] = val;\n\n    }\n\n}\n", "idx": 26743}
{"project": "FFmpeg", "commit_id": "00ae5b401b24592a9f7019baada5b349152ee2fc", "target": 1, "func": "static int dca_parse(AVCodecParserContext *s, AVCodecContext *avctx,\n\n                     const uint8_t **poutbuf, int *poutbuf_size,\n\n                     const uint8_t *buf, int buf_size)\n\n{\n\n    DCAParseContext *pc1 = s->priv_data;\n\n    ParseContext *pc = &pc1->pc;\n\n    int next, duration, sample_rate;\n\n\n\n    if (s->flags & PARSER_FLAG_COMPLETE_FRAMES) {\n\n        next = buf_size;\n\n    } else {\n\n        next = dca_find_frame_end(pc1, buf, buf_size);\n\n\n\n        if (ff_combine_frame(pc, next, &buf, &buf_size) < 0) {\n\n            *poutbuf      = NULL;\n\n            *poutbuf_size = 0;\n\n            return buf_size;\n\n        }\n\n    }\n\n\n\n    /* read the duration and sample rate from the frame header */\n\n    if (!dca_parse_params(buf, buf_size, &duration, &sample_rate, &pc1->framesize)) {\n\n        s->duration        = duration;\n\n        avctx->sample_rate = sample_rate;\n\n    } else\n\n        s->duration = 0;\n\n\n\n    *poutbuf      = buf;\n\n    *poutbuf_size = buf_size;\n\n    return next;\n\n}\n", "idx": 26744}
{"project": "FFmpeg", "commit_id": "ee16a0ced01e6a33b7b01a0b21a0e07c1e1c7884", "target": 0, "func": "static int smacker_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    SmackerContext *smk = s->priv_data;\n\n    int flags;\n\n    int ret;\n\n    int i;\n\n    int frame_size = 0;\n\n    int palchange = 0;\n\n\n\n    if (s->pb->eof_reached || smk->cur_frame >= smk->frames)\n\n        return AVERROR_EOF;\n\n\n\n    /* if we demuxed all streams, pass another frame */\n\n    if(smk->curstream < 0) {\n\n        avio_seek(s->pb, smk->nextpos, 0);\n\n        frame_size = smk->frm_size[smk->cur_frame] & (~3);\n\n        flags = smk->frm_flags[smk->cur_frame];\n\n        /* handle palette change event */\n\n        if(flags & SMACKER_PAL){\n\n            int size, sz, t, off, j, pos;\n\n            uint8_t *pal = smk->pal;\n\n            uint8_t oldpal[768];\n\n\n\n            memcpy(oldpal, pal, 768);\n\n            size = avio_r8(s->pb);\n\n            size = size * 4 - 1;\n\n            frame_size -= size;\n\n            frame_size--;\n\n            sz = 0;\n\n            pos = avio_tell(s->pb) + size;\n\n            while(sz < 256){\n\n                t = avio_r8(s->pb);\n\n                if(t & 0x80){ /* skip palette entries */\n\n                    sz += (t & 0x7F) + 1;\n\n                    pal += ((t & 0x7F) + 1) * 3;\n\n                } else if(t & 0x40){ /* copy with offset */\n\n                    off = avio_r8(s->pb);\n\n                    j = (t & 0x3F) + 1;\n\n                    if (off + j > 0x100) {\n\n                        av_log(s, AV_LOG_ERROR,\n\n                               \"Invalid palette update, offset=%d length=%d extends beyond palette size\\n\",\n\n                               off, j);\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                    off *= 3;\n\n                    while(j-- && sz < 256) {\n\n                        *pal++ = oldpal[off + 0];\n\n                        *pal++ = oldpal[off + 1];\n\n                        *pal++ = oldpal[off + 2];\n\n                        sz++;\n\n                        off += 3;\n\n                    }\n\n                } else { /* new entries */\n\n                    *pal++ = smk_pal[t];\n\n                    *pal++ = smk_pal[avio_r8(s->pb) & 0x3F];\n\n                    *pal++ = smk_pal[avio_r8(s->pb) & 0x3F];\n\n                    sz++;\n\n                }\n\n            }\n\n            avio_seek(s->pb, pos, 0);\n\n            palchange |= 1;\n\n        }\n\n        flags >>= 1;\n\n        smk->curstream = -1;\n\n        /* if audio chunks are present, put them to stack and retrieve later */\n\n        for(i = 0; i < 7; i++) {\n\n            if(flags & 1) {\n\n                int size;\n\n                uint8_t *tmpbuf;\n\n\n\n                size = avio_rl32(s->pb) - 4;\n\n                frame_size -= size;\n\n                frame_size -= 4;\n\n                smk->curstream++;\n\n                tmpbuf = av_realloc(smk->bufs[smk->curstream], size);\n\n                if (!tmpbuf)\n\n                    return AVERROR(ENOMEM);\n\n                smk->bufs[smk->curstream] = tmpbuf;\n\n                smk->buf_sizes[smk->curstream] = size;\n\n                ret = avio_read(s->pb, smk->bufs[smk->curstream], size);\n\n                if(ret != size)\n\n                    return AVERROR(EIO);\n\n                smk->stream_id[smk->curstream] = smk->indexes[i];\n\n            }\n\n            flags >>= 1;\n\n        }\n\n        if (frame_size < 0)\n\n            return AVERROR_INVALIDDATA;\n\n        if (av_new_packet(pkt, frame_size + 769))\n\n            return AVERROR(ENOMEM);\n\n        if(smk->frm_size[smk->cur_frame] & 1)\n\n            palchange |= 2;\n\n        pkt->data[0] = palchange;\n\n        memcpy(pkt->data + 1, smk->pal, 768);\n\n        ret = avio_read(s->pb, pkt->data + 769, frame_size);\n\n        if(ret != frame_size)\n\n            return AVERROR(EIO);\n\n        pkt->stream_index = smk->videoindex;\n\n        pkt->pts          = smk->cur_frame;\n\n        pkt->size = ret + 769;\n\n        smk->cur_frame++;\n\n        smk->nextpos = avio_tell(s->pb);\n\n    } else {\n\n        if (av_new_packet(pkt, smk->buf_sizes[smk->curstream]))\n\n            return AVERROR(ENOMEM);\n\n        memcpy(pkt->data, smk->bufs[smk->curstream], smk->buf_sizes[smk->curstream]);\n\n        pkt->size = smk->buf_sizes[smk->curstream];\n\n        pkt->stream_index = smk->stream_id[smk->curstream];\n\n        pkt->pts = smk->aud_pts[smk->curstream];\n\n        smk->aud_pts[smk->curstream] += AV_RL32(pkt->data);\n\n        smk->curstream--;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26746}
{"project": "FFmpeg", "commit_id": "ffdc5d09e498bee8176c9e35df101c01c546a738", "target": 1, "func": "static int decode_header(EXRContext *s)\n\n{\n\n    int magic_number, version, i, flags, sar = 0;\n\n    int layer_match = 0;\n\n\n\n    s->current_channel_offset = 0;\n\n    s->xmin               = ~0;\n\n    s->xmax               = ~0;\n\n    s->ymin               = ~0;\n\n    s->ymax               = ~0;\n\n    s->xdelta             = ~0;\n\n    s->ydelta             = ~0;\n\n    s->channel_offsets[0] = -1;\n\n    s->channel_offsets[1] = -1;\n\n    s->channel_offsets[2] = -1;\n\n    s->channel_offsets[3] = -1;\n\n    s->pixel_type         = EXR_UNKNOWN;\n\n    s->compression        = EXR_UNKN;\n\n    s->nb_channels        = 0;\n\n    s->w                  = 0;\n\n    s->h                  = 0;\n\n    s->tile_attr.xSize    = -1;\n\n    s->tile_attr.ySize    = -1;\n\n    s->is_tile            = 0;\n\n    s->is_luma            = 0;\n\n\n\n    if (bytestream2_get_bytes_left(&s->gb) < 10) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Header too short to parse.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    magic_number = bytestream2_get_le32(&s->gb);\n\n    if (magic_number != 20000630) {\n\n        /* As per documentation of OpenEXR, it is supposed to be\n\n         * int 20000630 little-endian */\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Wrong magic number %d.\\n\", magic_number);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    version = bytestream2_get_byte(&s->gb);\n\n    if (version != 2) {\n\n        avpriv_report_missing_feature(s->avctx, \"Version %d\", version);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    flags = bytestream2_get_le24(&s->gb);\n\n\n\n    if (flags == 0x00)\n\n        s->is_tile = 0;\n\n    else if (flags & 0x02)\n\n        s->is_tile = 1;\n\n    else{\n\n        avpriv_report_missing_feature(s->avctx, \"flags %d\", flags);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    // Parse the header\n\n    while (bytestream2_get_bytes_left(&s->gb) > 0 && *s->gb.buffer) {\n\n        int var_size;\n\n        if ((var_size = check_header_variable(s, \"channels\",\n\n                                              \"chlist\", 38)) >= 0) {\n\n            GetByteContext ch_gb;\n\n            if (!var_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            bytestream2_init(&ch_gb, s->gb.buffer, var_size);\n\n\n\n            while (bytestream2_get_bytes_left(&ch_gb) >= 19) {\n\n                EXRChannel *channel;\n\n                enum ExrPixelType current_pixel_type;\n\n                int channel_index = -1;\n\n                int xsub, ysub;\n\n\n\n                if (strcmp(s->layer, \"\") != 0) {\n\n                    if (strncmp(ch_gb.buffer, s->layer, strlen(s->layer)) == 0) {\n\n                        layer_match = 1;\n\n                        av_log(s->avctx, AV_LOG_INFO,\n\n                               \"Channel match layer : %s.\\n\", ch_gb.buffer);\n\n                        ch_gb.buffer += strlen(s->layer);\n\n                        if (*ch_gb.buffer == '.')\n\n                            ch_gb.buffer++;         /* skip dot if not given */\n\n                    } else {\n\n                        av_log(s->avctx, AV_LOG_INFO,\n\n                               \"Channel doesn't match layer : %s.\\n\", ch_gb.buffer);\n\n                    }\n\n                } else {\n\n                    layer_match = 1;\n\n                }\n\n\n\n                if (layer_match) { /* only search channel if the layer match is valid */\n\n                    if (!strcmp(ch_gb.buffer, \"R\") ||\n\n                        !strcmp(ch_gb.buffer, \"X\") ||\n\n                        !strcmp(ch_gb.buffer, \"U\")) {\n\n                        channel_index = 0;\n\n                        s->is_luma = 0;\n\n                    } else if (!strcmp(ch_gb.buffer, \"G\") ||\n\n                               !strcmp(ch_gb.buffer, \"V\")) {\n\n                        channel_index = 1;\n\n                        s->is_luma = 0;\n\n                    } else if (!strcmp(ch_gb.buffer, \"Y\")) {\n\n                        channel_index = 1;\n\n                        s->is_luma = 1;\n\n                    } else if (!strcmp(ch_gb.buffer, \"B\") ||\n\n                               !strcmp(ch_gb.buffer, \"Z\") ||\n\n                               !strcmp(ch_gb.buffer, \"W\")){\n\n                               channel_index = 2;\n\n                        s->is_luma = 0;\n\n                    } else if (!strcmp(ch_gb.buffer, \"A\")) {\n\n                        channel_index = 3;\n\n                    } else {\n\n                        av_log(s->avctx, AV_LOG_WARNING,\n\n                               \"Unsupported channel %.256s.\\n\", ch_gb.buffer);\n\n                    }\n\n                }\n\n\n\n                /* skip until you get a 0 */\n\n                while (bytestream2_get_bytes_left(&ch_gb) > 0 &&\n\n                       bytestream2_get_byte(&ch_gb))\n\n                    continue;\n\n\n\n                if (bytestream2_get_bytes_left(&ch_gb) < 4) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"Incomplete header.\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                current_pixel_type = bytestream2_get_le32(&ch_gb);\n\n                if (current_pixel_type >= EXR_UNKNOWN) {\n\n                    avpriv_report_missing_feature(s->avctx, \"Pixel type %d\",\n\n                                                  current_pixel_type);\n\n                    return AVERROR_PATCHWELCOME;\n\n                }\n\n\n\n                bytestream2_skip(&ch_gb, 4);\n\n                xsub = bytestream2_get_le32(&ch_gb);\n\n                ysub = bytestream2_get_le32(&ch_gb);\n\n\n\n                if (xsub != 1 || ysub != 1) {\n\n                    avpriv_report_missing_feature(s->avctx,\n\n                                                  \"Subsampling %dx%d\",\n\n                                                  xsub, ysub);\n\n                    return AVERROR_PATCHWELCOME;\n\n                }\n\n\n\n                if (s->channel_offsets[channel_index] == -1){/* channel have not been previously assign */\n\n                    if (channel_index >= 0) {\n\n                        if (s->pixel_type != EXR_UNKNOWN &&\n\n                            s->pixel_type != current_pixel_type) {\n\n                            av_log(s->avctx, AV_LOG_ERROR,\n\n                                   \"RGB channels not of the same depth.\\n\");\n\n                            return AVERROR_INVALIDDATA;\n\n                        }\n\n                        s->pixel_type                     = current_pixel_type;\n\n                        s->channel_offsets[channel_index] = s->current_channel_offset;\n\n                    }\n\n                }\n\n\n\n                s->channels = av_realloc(s->channels,\n\n                                         ++s->nb_channels * sizeof(EXRChannel));\n\n                if (!s->channels)\n\n                    return AVERROR(ENOMEM);\n\n                channel             = &s->channels[s->nb_channels - 1];\n\n                channel->pixel_type = current_pixel_type;\n\n                channel->xsub       = xsub;\n\n                channel->ysub       = ysub;\n\n\n\n                s->current_channel_offset += 1 << current_pixel_type;\n\n            }\n\n\n\n            /* Check if all channels are set with an offset or if the channels\n\n             * are causing an overflow  */\n\n            if (!s->is_luma){/* if we expected to have at least 3 channels */\n\n                if (FFMIN3(s->channel_offsets[0],\n\n                           s->channel_offsets[1],\n\n                           s->channel_offsets[2]) < 0) {\n\n                    if (s->channel_offsets[0] < 0)\n\n                        av_log(s->avctx, AV_LOG_ERROR, \"Missing red channel.\\n\");\n\n                    if (s->channel_offsets[1] < 0)\n\n                        av_log(s->avctx, AV_LOG_ERROR, \"Missing green channel.\\n\");\n\n                    if (s->channel_offsets[2] < 0)\n\n                        av_log(s->avctx, AV_LOG_ERROR, \"Missing blue channel.\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n            }\n\n\n\n            // skip one last byte and update main gb\n\n            s->gb.buffer = ch_gb.buffer + 1;\n\n            continue;\n\n        } else if ((var_size = check_header_variable(s, \"dataWindow\", \"box2i\",\n\n                                                     31)) >= 0) {\n\n            if (!var_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            s->xmin   = bytestream2_get_le32(&s->gb);\n\n            s->ymin   = bytestream2_get_le32(&s->gb);\n\n            s->xmax   = bytestream2_get_le32(&s->gb);\n\n            s->ymax   = bytestream2_get_le32(&s->gb);\n\n            s->xdelta = (s->xmax - s->xmin) + 1;\n\n            s->ydelta = (s->ymax - s->ymin) + 1;\n\n\n\n            continue;\n\n        } else if ((var_size = check_header_variable(s, \"displayWindow\",\n\n                                                     \"box2i\", 34)) >= 0) {\n\n            if (!var_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            bytestream2_skip(&s->gb, 8);\n\n            s->w = bytestream2_get_le32(&s->gb) + 1;\n\n            s->h = bytestream2_get_le32(&s->gb) + 1;\n\n\n\n            continue;\n\n        } else if ((var_size = check_header_variable(s, \"lineOrder\",\n\n                                                     \"lineOrder\", 25)) >= 0) {\n\n            int line_order;\n\n            if (!var_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            line_order = bytestream2_get_byte(&s->gb);\n\n            av_log(s->avctx, AV_LOG_DEBUG, \"line order: %d.\\n\", line_order);\n\n            if (line_order > 2) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"Unknown line order.\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            continue;\n\n        } else if ((var_size = check_header_variable(s, \"pixelAspectRatio\",\n\n                                                     \"float\", 31)) >= 0) {\n\n            if (!var_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            sar = bytestream2_get_le32(&s->gb);\n\n\n\n            continue;\n\n        } else if ((var_size = check_header_variable(s, \"compression\",\n\n                                                     \"compression\", 29)) >= 0) {\n\n            if (!var_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            if (s->compression == EXR_UNKN)\n\n                s->compression = bytestream2_get_byte(&s->gb);\n\n            else\n\n                av_log(s->avctx, AV_LOG_WARNING,\n\n                       \"Found more than one compression attribute.\\n\");\n\n\n\n            continue;\n\n        } else if ((var_size = check_header_variable(s, \"tiles\",\n\n                                                     \"tiledesc\", 22)) >= 0) {\n\n            char tileLevel;\n\n\n\n            if (!s->is_tile)\n\n                av_log(s->avctx, AV_LOG_WARNING,\n\n                       \"Found tile attribute and scanline flags. Exr will be interpreted as scanline.\\n\");\n\n\n\n            s->tile_attr.xSize = bytestream2_get_le32(&s->gb);\n\n            s->tile_attr.ySize = bytestream2_get_le32(&s->gb);\n\n\n\n            tileLevel = bytestream2_get_byte(&s->gb);\n\n            s->tile_attr.level_mode = tileLevel & 0x0f;\n\n            s->tile_attr.level_round = (tileLevel >> 4) & 0x0f;\n\n\n\n            if (s->tile_attr.level_mode >= EXR_TILE_LEVEL_UNKNOWN){\n\n                avpriv_report_missing_feature(s->avctx, \"Tile level mode %d\",\n\n                                              s->tile_attr.level_mode);\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n\n\n            if (s->tile_attr.level_round >= EXR_TILE_ROUND_UNKNOWN) {\n\n                avpriv_report_missing_feature(s->avctx, \"Tile level round %d\",\n\n                                              s->tile_attr.level_round);\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n\n\n            continue;\n\n        }\n\n\n\n        // Check if there are enough bytes for a header\n\n        if (bytestream2_get_bytes_left(&s->gb) <= 9) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Incomplete header\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        // Process unknown variables\n\n        for (i = 0; i < 2; i++) // value_name and value_type\n\n            while (bytestream2_get_byte(&s->gb) != 0);\n\n\n\n        // Skip variable length\n\n        bytestream2_skip(&s->gb, bytestream2_get_le32(&s->gb));\n\n    }\n\n\n\n    ff_set_sar(s->avctx, av_d2q(av_int2float(sar), 255));\n\n\n\n    if (s->compression == EXR_UNKN) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Missing compression attribute.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->is_tile) {\n\n        if (s->tile_attr.xSize < 1 || s->tile_attr.ySize < 1) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Invalid tile attribute.\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    if (bytestream2_get_bytes_left(&s->gb) <= 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Incomplete frame.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    // aaand we are done\n\n    bytestream2_skip(&s->gb, 1);\n\n    return 0;\n\n}\n", "idx": 26750}
{"project": "FFmpeg", "commit_id": "50833c9f7b4e1922197a8955669f8ab3589c8cef", "target": 1, "func": "static void encode_block(NellyMoserEncodeContext *s, unsigned char *output, int output_size)\n\n{\n\n    PutBitContext pb;\n\n    int i, j, band, block, best_idx, power_idx = 0;\n\n    float power_val, coeff, coeff_sum;\n\n    float pows[NELLY_FILL_LEN];\n\n    int bits[NELLY_BUF_LEN], idx_table[NELLY_BANDS];\n\n    float cand[NELLY_BANDS];\n\n\n\n    apply_mdct(s);\n\n\n\n    init_put_bits(&pb, output, output_size * 8);\n\n\n\n    i = 0;\n\n    for (band = 0; band < NELLY_BANDS; band++) {\n\n        coeff_sum = 0;\n\n        for (j = 0; j < ff_nelly_band_sizes_table[band]; i++, j++) {\n\n            coeff_sum += s->mdct_out[i                ] * s->mdct_out[i                ]\n\n                       + s->mdct_out[i + NELLY_BUF_LEN] * s->mdct_out[i + NELLY_BUF_LEN];\n\n        }\n\n        cand[band] =\n\n            log(FFMAX(1.0, coeff_sum / (ff_nelly_band_sizes_table[band] << 7))) * 1024.0 / M_LN2;\n\n    }\n\n\n\n    if (s->avctx->trellis) {\n\n        get_exponent_dynamic(s, cand, idx_table);\n\n    } else {\n\n        get_exponent_greedy(s, cand, idx_table);\n\n    }\n\n\n\n    i = 0;\n\n    for (band = 0; band < NELLY_BANDS; band++) {\n\n        if (band) {\n\n            power_idx += ff_nelly_delta_table[idx_table[band]];\n\n            put_bits(&pb, 5, idx_table[band]);\n\n        } else {\n\n            power_idx = ff_nelly_init_table[idx_table[0]];\n\n            put_bits(&pb, 6, idx_table[0]);\n\n        }\n\n        power_val = pow_table[power_idx & 0x7FF] / (1 << ((power_idx >> 11) + POW_TABLE_OFFSET));\n\n        for (j = 0; j < ff_nelly_band_sizes_table[band]; i++, j++) {\n\n            s->mdct_out[i] *= power_val;\n\n            s->mdct_out[i + NELLY_BUF_LEN] *= power_val;\n\n            pows[i] = power_idx;\n\n        }\n\n    }\n\n\n\n    ff_nelly_get_sample_bits(pows, bits);\n\n\n\n    for (block = 0; block < 2; block++) {\n\n        for (i = 0; i < NELLY_FILL_LEN; i++) {\n\n            if (bits[i] > 0) {\n\n                const float *table = ff_nelly_dequantization_table + (1 << bits[i]) - 1;\n\n                coeff = s->mdct_out[block * NELLY_BUF_LEN + i];\n\n                best_idx =\n\n                    quant_lut[av_clip (\n\n                            coeff * quant_lut_mul[bits[i]] + quant_lut_add[bits[i]],\n\n                            quant_lut_offset[bits[i]],\n\n                            quant_lut_offset[bits[i]+1] - 1\n\n                            )];\n\n                if (fabs(coeff - table[best_idx]) > fabs(coeff - table[best_idx + 1]))\n\n                    best_idx++;\n\n\n\n                put_bits(&pb, bits[i], best_idx);\n\n            }\n\n        }\n\n        if (!block)\n\n            put_bits(&pb, NELLY_HEADER_BITS + NELLY_DETAIL_BITS - put_bits_count(&pb), 0);\n\n    }\n\n\n\n    flush_put_bits(&pb);\n\n    memset(put_bits_ptr(&pb), 0, output + output_size - put_bits_ptr(&pb));\n\n}\n", "idx": 26751}
{"project": "FFmpeg", "commit_id": "b8b8e82ea14016b2cb04b49ecea57f836e6ee7f8", "target": 1, "func": "static void dnxhd_decode_dct_block_10(const DNXHDContext *ctx,\n\n                                      RowContext *row, int n)\n\n{\n\n    dnxhd_decode_dct_block(ctx, row, n, 6, 8, 4);\n\n}\n", "idx": 26755}
{"project": "FFmpeg", "commit_id": "58bba31e3f22bb07645a764602603364b1ec953d", "target": 0, "func": "static void opt_qsquish(const char *arg)\n\n{\n\n    video_qsquish = atof(arg);\n\n    if (video_qsquish < 0.0 ||\n\n        video_qsquish > 99.0) {\n\n        fprintf(stderr, \"qsquish must be >= 0.0 and <= 99.0\\n\");\n\n        exit(1);\n\n    }\n\n}\n", "idx": 26756}
{"project": "FFmpeg", "commit_id": "5a2ad7ede33b5d63c1f1b1313a218da62e1c0d48", "target": 0, "func": "static int create_vorbis_context(vorbis_enc_context *venc,\n\n                                 AVCodecContext *avctx)\n\n{\n\n    vorbis_enc_floor   *fc;\n\n    vorbis_enc_residue *rc;\n\n    vorbis_enc_mapping *mc;\n\n    int i, book, ret;\n\n\n\n    venc->channels    = avctx->channels;\n\n    venc->sample_rate = avctx->sample_rate;\n\n    venc->log2_blocksize[0] = venc->log2_blocksize[1] = 11;\n\n\n\n    venc->ncodebooks = FF_ARRAY_ELEMS(cvectors);\n\n    venc->codebooks  = av_malloc(sizeof(vorbis_enc_codebook) * venc->ncodebooks);\n\n    if (!venc->codebooks)\n\n        return AVERROR(ENOMEM);\n\n\n\n    // codebook 0..14 - floor1 book, values 0..255\n\n    // codebook 15 residue masterbook\n\n    // codebook 16..29 residue\n\n    for (book = 0; book < venc->ncodebooks; book++) {\n\n        vorbis_enc_codebook *cb = &venc->codebooks[book];\n\n        int vals;\n\n        cb->ndimensions = cvectors[book].dim;\n\n        cb->nentries    = cvectors[book].real_len;\n\n        cb->min         = cvectors[book].min;\n\n        cb->delta       = cvectors[book].delta;\n\n        cb->lookup      = cvectors[book].lookup;\n\n        cb->seq_p       = 0;\n\n\n\n        cb->lens      = av_malloc_array(cb->nentries, sizeof(uint8_t));\n\n        cb->codewords = av_malloc_array(cb->nentries, sizeof(uint32_t));\n\n        if (!cb->lens || !cb->codewords)\n\n            return AVERROR(ENOMEM);\n\n        memcpy(cb->lens, cvectors[book].clens, cvectors[book].len);\n\n        memset(cb->lens + cvectors[book].len, 0, cb->nentries - cvectors[book].len);\n\n\n\n        if (cb->lookup) {\n\n            vals = cb_lookup_vals(cb->lookup, cb->ndimensions, cb->nentries);\n\n            cb->quantlist = av_malloc_array(vals, sizeof(int));\n\n            if (!cb->quantlist)\n\n                return AVERROR(ENOMEM);\n\n            for (i = 0; i < vals; i++)\n\n                cb->quantlist[i] = cvectors[book].quant[i];\n\n        } else {\n\n            cb->quantlist = NULL;\n\n        }\n\n        if ((ret = ready_codebook(cb)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    venc->nfloors = 1;\n\n    venc->floors  = av_malloc(sizeof(vorbis_enc_floor) * venc->nfloors);\n\n    if (!venc->floors)\n\n        return AVERROR(ENOMEM);\n\n\n\n    // just 1 floor\n\n    fc = &venc->floors[0];\n\n    fc->partitions         = NUM_FLOOR_PARTITIONS;\n\n    fc->partition_to_class = av_malloc(sizeof(int) * fc->partitions);\n\n    if (!fc->partition_to_class)\n\n        return AVERROR(ENOMEM);\n\n    fc->nclasses           = 0;\n\n    for (i = 0; i < fc->partitions; i++) {\n\n        static const int a[] = {0, 1, 2, 2, 3, 3, 4, 4};\n\n        fc->partition_to_class[i] = a[i];\n\n        fc->nclasses = FFMAX(fc->nclasses, fc->partition_to_class[i]);\n\n    }\n\n    fc->nclasses++;\n\n    fc->classes = av_malloc_array(fc->nclasses, sizeof(vorbis_enc_floor_class));\n\n    if (!fc->classes)\n\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < fc->nclasses; i++) {\n\n        vorbis_enc_floor_class * c = &fc->classes[i];\n\n        int j, books;\n\n        c->dim        = floor_classes[i].dim;\n\n        c->subclass   = floor_classes[i].subclass;\n\n        c->masterbook = floor_classes[i].masterbook;\n\n        books         = (1 << c->subclass);\n\n        c->books      = av_malloc_array(books, sizeof(int));\n\n        if (!c->books)\n\n            return AVERROR(ENOMEM);\n\n        for (j = 0; j < books; j++)\n\n            c->books[j] = floor_classes[i].nbooks[j];\n\n    }\n\n    fc->multiplier = 2;\n\n    fc->rangebits  = venc->log2_blocksize[0] - 1;\n\n\n\n    fc->values = 2;\n\n    for (i = 0; i < fc->partitions; i++)\n\n        fc->values += fc->classes[fc->partition_to_class[i]].dim;\n\n\n\n    fc->list = av_malloc_array(fc->values, sizeof(vorbis_floor1_entry));\n\n    if (!fc->list)\n\n        return AVERROR(ENOMEM);\n\n    fc->list[0].x = 0;\n\n    fc->list[1].x = 1 << fc->rangebits;\n\n    for (i = 2; i < fc->values; i++) {\n\n        static const int a[] = {\n\n             93, 23,372,  6, 46,186,750, 14, 33, 65,\n\n            130,260,556,  3, 10, 18, 28, 39, 55, 79,\n\n            111,158,220,312,464,650,850\n\n        };\n\n        fc->list[i].x = a[i - 2];\n\n    }\n\n    if (ff_vorbis_ready_floor1_list(avctx, fc->list, fc->values))\n\n        return AVERROR_BUG;\n\n\n\n    venc->nresidues = 1;\n\n    venc->residues  = av_malloc(sizeof(vorbis_enc_residue) * venc->nresidues);\n\n    if (!venc->residues)\n\n        return AVERROR(ENOMEM);\n\n\n\n    // single residue\n\n    rc = &venc->residues[0];\n\n    rc->type            = 2;\n\n    rc->begin           = 0;\n\n    rc->end             = 1600;\n\n    rc->partition_size  = 32;\n\n    rc->classifications = 10;\n\n    rc->classbook       = 15;\n\n    rc->books           = av_malloc(sizeof(*rc->books) * rc->classifications);\n\n    if (!rc->books)\n\n        return AVERROR(ENOMEM);\n\n    {\n\n        static const int8_t a[10][8] = {\n\n            { -1, -1, -1, -1, -1, -1, -1, -1, },\n\n            { -1, -1, 16, -1, -1, -1, -1, -1, },\n\n            { -1, -1, 17, -1, -1, -1, -1, -1, },\n\n            { -1, -1, 18, -1, -1, -1, -1, -1, },\n\n            { -1, -1, 19, -1, -1, -1, -1, -1, },\n\n            { -1, -1, 20, -1, -1, -1, -1, -1, },\n\n            { -1, -1, 21, -1, -1, -1, -1, -1, },\n\n            { 22, 23, -1, -1, -1, -1, -1, -1, },\n\n            { 24, 25, -1, -1, -1, -1, -1, -1, },\n\n            { 26, 27, 28, -1, -1, -1, -1, -1, },\n\n        };\n\n        memcpy(rc->books, a, sizeof a);\n\n    }\n\n    if ((ret = ready_residue(rc, venc)) < 0)\n\n        return ret;\n\n\n\n    venc->nmappings = 1;\n\n    venc->mappings  = av_malloc(sizeof(vorbis_enc_mapping) * venc->nmappings);\n\n    if (!venc->mappings)\n\n        return AVERROR(ENOMEM);\n\n\n\n    // single mapping\n\n    mc = &venc->mappings[0];\n\n    mc->submaps = 1;\n\n    mc->mux     = av_malloc(sizeof(int) * venc->channels);\n\n    if (!mc->mux)\n\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < venc->channels; i++)\n\n        mc->mux[i] = 0;\n\n    mc->floor   = av_malloc(sizeof(int) * mc->submaps);\n\n    mc->residue = av_malloc(sizeof(int) * mc->submaps);\n\n    if (!mc->floor || !mc->residue)\n\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < mc->submaps; i++) {\n\n        mc->floor[i]   = 0;\n\n        mc->residue[i] = 0;\n\n    }\n\n    mc->coupling_steps = venc->channels == 2 ? 1 : 0;\n\n    mc->magnitude      = av_malloc(sizeof(int) * mc->coupling_steps);\n\n    mc->angle          = av_malloc(sizeof(int) * mc->coupling_steps);\n\n    if (!mc->magnitude || !mc->angle)\n\n        return AVERROR(ENOMEM);\n\n    if (mc->coupling_steps) {\n\n        mc->magnitude[0] = 0;\n\n        mc->angle[0]     = 1;\n\n    }\n\n\n\n    venc->nmodes = 1;\n\n    venc->modes  = av_malloc(sizeof(vorbis_enc_mode) * venc->nmodes);\n\n    if (!venc->modes)\n\n        return AVERROR(ENOMEM);\n\n\n\n    // single mode\n\n    venc->modes[0].blockflag = 0;\n\n    venc->modes[0].mapping   = 0;\n\n\n\n    venc->have_saved = 0;\n\n    venc->saved      = av_malloc_array(sizeof(float) * venc->channels, (1 << venc->log2_blocksize[1]) / 2);\n\n    venc->samples    = av_malloc_array(sizeof(float) * venc->channels, (1 << venc->log2_blocksize[1]));\n\n    venc->floor      = av_malloc_array(sizeof(float) * venc->channels, (1 << venc->log2_blocksize[1]) / 2);\n\n    venc->coeffs     = av_malloc_array(sizeof(float) * venc->channels, (1 << venc->log2_blocksize[1]) / 2);\n\n    venc->scratch    = av_malloc_array(sizeof(float) * venc->channels, (1 << venc->log2_blocksize[1]) / 2);\n\n\n\n    if (!venc->saved || !venc->samples || !venc->floor || !venc->coeffs || !venc->scratch)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if ((ret = dsp_init(avctx, venc)) < 0)\n\n        return ret;\n\n\n\n    return 0;\n\n}\n", "idx": 26757}
{"project": "FFmpeg", "commit_id": "7a14430ed75a2eaaa430e46c2f54a7a9a8b71804", "target": 0, "func": "static void mpeg_decode_picture_coding_extension(Mpeg1Context *s1)\n\n{\n\n    MpegEncContext *s= &s1->mpeg_enc_ctx;\n\n\n\n    s->full_pel[0] = s->full_pel[1] = 0;\n\n    s->mpeg_f_code[0][0] = get_bits(&s->gb, 4);\n\n    s->mpeg_f_code[0][1] = get_bits(&s->gb, 4);\n\n    s->mpeg_f_code[1][0] = get_bits(&s->gb, 4);\n\n    s->mpeg_f_code[1][1] = get_bits(&s->gb, 4);\n\n    if(!s->pict_type && s1->mpeg_enc_ctx_allocated){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Missing picture start code, guessing missing values\\n\");\n\n        if(s->mpeg_f_code[1][0] == 15 && s->mpeg_f_code[1][1]==15){\n\n            if(s->mpeg_f_code[0][0] == 15 && s->mpeg_f_code[0][1] == 15)\n\n                s->pict_type= FF_I_TYPE;\n\n            else\n\n                s->pict_type= FF_P_TYPE;\n\n        }else\n\n            s->pict_type= FF_B_TYPE;\n\n        s->current_picture.pict_type= s->pict_type;\n\n        s->current_picture.key_frame= s->pict_type == FF_I_TYPE;\n\n    }\n\n    s->intra_dc_precision = get_bits(&s->gb, 2);\n\n    s->picture_structure = get_bits(&s->gb, 2);\n\n    s->top_field_first = get_bits1(&s->gb);\n\n    s->frame_pred_frame_dct = get_bits1(&s->gb);\n\n    s->concealment_motion_vectors = get_bits1(&s->gb);\n\n    s->q_scale_type = get_bits1(&s->gb);\n\n    s->intra_vlc_format = get_bits1(&s->gb);\n\n    s->alternate_scan = get_bits1(&s->gb);\n\n    s->repeat_first_field = get_bits1(&s->gb);\n\n    s->chroma_420_type = get_bits1(&s->gb);\n\n    s->progressive_frame = get_bits1(&s->gb);\n\n\n\n    if(s->progressive_sequence && !s->progressive_frame){\n\n        s->progressive_frame= 1;\n\n        av_log(s->avctx, AV_LOG_ERROR, \"interlaced frame in progressive sequence, ignoring\\n\");\n\n    }\n\n\n\n    if(s->picture_structure==0 || (s->progressive_frame && s->picture_structure!=PICT_FRAME)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"picture_structure %d invalid, ignoring\\n\", s->picture_structure);\n\n        s->picture_structure= PICT_FRAME;\n\n    }\n\n\n\n    if(s->progressive_frame && !s->frame_pred_frame_dct){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"invalid frame_pred_frame_dct\\n\");\n\n        s->frame_pred_frame_dct= 1;\n\n    }\n\n\n\n    if(s->picture_structure == PICT_FRAME){\n\n        s->first_field=0;\n\n        s->v_edge_pos= 16*s->mb_height;\n\n    }else{\n\n        s->first_field ^= 1;\n\n        s->v_edge_pos=  8*s->mb_height;\n\n        memset(s->mbskip_table, 0, s->mb_stride*s->mb_height);\n\n    }\n\n\n\n    if(s->alternate_scan){\n\n        ff_init_scantable(s->dsp.idct_permutation, &s->inter_scantable  , ff_alternate_vertical_scan);\n\n        ff_init_scantable(s->dsp.idct_permutation, &s->intra_scantable  , ff_alternate_vertical_scan);\n\n    }else{\n\n        ff_init_scantable(s->dsp.idct_permutation, &s->inter_scantable  , ff_zigzag_direct);\n\n        ff_init_scantable(s->dsp.idct_permutation, &s->intra_scantable  , ff_zigzag_direct);\n\n    }\n\n\n\n    /* composite display not parsed */\n\n    dprintf(s->avctx, \"intra_dc_precision=%d\\n\", s->intra_dc_precision);\n\n    dprintf(s->avctx, \"picture_structure=%d\\n\", s->picture_structure);\n\n    dprintf(s->avctx, \"top field first=%d\\n\", s->top_field_first);\n\n    dprintf(s->avctx, \"repeat first field=%d\\n\", s->repeat_first_field);\n\n    dprintf(s->avctx, \"conceal=%d\\n\", s->concealment_motion_vectors);\n\n    dprintf(s->avctx, \"intra_vlc_format=%d\\n\", s->intra_vlc_format);\n\n    dprintf(s->avctx, \"alternate_scan=%d\\n\", s->alternate_scan);\n\n    dprintf(s->avctx, \"frame_pred_frame_dct=%d\\n\", s->frame_pred_frame_dct);\n\n    dprintf(s->avctx, \"progressive_frame=%d\\n\", s->progressive_frame);\n\n}\n", "idx": 26758}
{"project": "FFmpeg", "commit_id": "da048c6d24729d3bab6ccb0ac340ea129e3e88d5", "target": 1, "func": "static int mov_write_mdia_tag(AVIOContext *pb, MOVMuxContext *mov,\n\n                              MOVTrack *track)\n\n{\n\n    int64_t pos = avio_tell(pb);\n\n    avio_wb32(pb, 0); /* size */\n\n    ffio_wfourcc(pb, \"mdia\");\n\n    mov_write_mdhd_tag(pb, mov, track);\n\n    mov_write_hdlr_tag(pb, track);\n\n    mov_write_minf_tag(pb, track);\n\n    return update_size(pb, pos);\n\n}\n", "idx": 26760}
{"project": "FFmpeg", "commit_id": "80c873a87ed07c6dd772dcf6befb4cf0fd98ef7b", "target": 1, "func": "int ff_h264_decode_sei(H264Context *h){\n\n    while (get_bits_left(&h->gb) > 16) {\n\n        int size, type;\n\n\n\n        type=0;\n\n        do{\n\n            if (get_bits_left(&h->gb) < 8)\n\n                return AVERROR_INVALIDDATA;\n\n            type+= show_bits(&h->gb, 8);\n\n        }while(get_bits(&h->gb, 8) == 255);\n\n\n\n        size=0;\n\n        do{\n\n            if (get_bits_left(&h->gb) < 8)\n\n                return AVERROR_INVALIDDATA;\n\n            size+= show_bits(&h->gb, 8);\n\n        }while(get_bits(&h->gb, 8) == 255);\n\n\n\n        if(h->avctx->debug&FF_DEBUG_STARTCODE)\n\n            av_log(h->avctx, AV_LOG_DEBUG, \"SEI %d len:%d\\n\", type, size);\n\n\n\n        switch(type){\n\n        case SEI_TYPE_PIC_TIMING: // Picture timing SEI\n\n            if(decode_picture_timing(h) < 0)\n\n                return -1;\n\n            break;\n\n        case SEI_TYPE_USER_DATA_ITU_T_T35:\n\n            if(decode_user_data_itu_t_t35(h, size) < 0)\n\n                return -1;\n\n            break;\n\n        case SEI_TYPE_USER_DATA_UNREGISTERED:\n\n            if(decode_unregistered_user_data(h, size) < 0)\n\n                return -1;\n\n            break;\n\n        case SEI_TYPE_RECOVERY_POINT:\n\n            if(decode_recovery_point(h) < 0)\n\n                return -1;\n\n            break;\n\n        case SEI_BUFFERING_PERIOD:\n\n            if(decode_buffering_period(h) < 0)\n\n                return -1;\n\n            break;\n\n        case SEI_TYPE_FRAME_PACKING:\n\n            if(decode_frame_packing(h, size) < 0)\n\n                return -1;\n\n        default:\n\n            skip_bits(&h->gb, 8*size);\n\n        }\n\n\n\n        //FIXME check bits here\n\n        align_get_bits(&h->gb);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26761}
{"project": "FFmpeg", "commit_id": "9f61abc8111c7c43f49ca012e957a108b9cc7610", "target": 0, "func": "static int parse_fragment(AVFormatContext *s, const char *filename, int64_t *start_ts, int64_t *duration, int64_t *moof_size, int64_t size)\n\n{\n\n    AVIOContext *in;\n\n    int ret;\n\n    uint32_t len;\n\n    if ((ret = avio_open2(&in, filename, AVIO_FLAG_READ, &s->interrupt_callback, NULL)) < 0)\n\n        return ret;\n\n    ret = AVERROR(EIO);\n\n    *moof_size = avio_rb32(in);\n\n    if (*moof_size < 8 || *moof_size > size)\n\n        goto fail;\n\n    if (avio_rl32(in) != MKTAG('m','o','o','f'))\n\n        goto fail;\n\n    len = avio_rb32(in);\n\n    if (len > *moof_size)\n\n        goto fail;\n\n    if (avio_rl32(in) != MKTAG('m','f','h','d'))\n\n        goto fail;\n\n    avio_seek(in, len - 8, SEEK_CUR);\n\n    avio_rb32(in); /* traf size */\n\n    if (avio_rl32(in) != MKTAG('t','r','a','f'))\n\n        goto fail;\n\n    while (avio_tell(in) < *moof_size) {\n\n        uint32_t len = avio_rb32(in);\n\n        uint32_t tag = avio_rl32(in);\n\n        int64_t end = avio_tell(in) + len - 8;\n\n        if (len < 8 || len >= *moof_size)\n\n            goto fail;\n\n        if (tag == MKTAG('u','u','i','d')) {\n\n            const uint8_t tfxd[] = {\n\n                0x6d, 0x1d, 0x9b, 0x05, 0x42, 0xd5, 0x44, 0xe6,\n\n                0x80, 0xe2, 0x14, 0x1d, 0xaf, 0xf7, 0x57, 0xb2\n\n            };\n\n            uint8_t uuid[16];\n\n            avio_read(in, uuid, 16);\n\n            if (!memcmp(uuid, tfxd, 16) && len >= 8 + 16 + 4 + 16) {\n\n                avio_seek(in, 4, SEEK_CUR);\n\n                *start_ts = avio_rb64(in);\n\n                *duration = avio_rb64(in);\n\n                ret = 0;\n\n                break;\n\n            }\n\n        }\n\n        avio_seek(in, end, SEEK_SET);\n\n    }\n\nfail:\n\n    avio_close(in);\n\n    return ret;\n\n}\n", "idx": 26762}
{"project": "FFmpeg", "commit_id": "75cc57f73f9aee8721a101b3c6ef85312ea9e54c", "target": 0, "func": "static int mpeg_decode_postinit(AVCodecContext *avctx)\n\n{\n\n    Mpeg1Context *s1  = avctx->priv_data;\n\n    MpegEncContext *s = &s1->mpeg_enc_ctx;\n\n    uint8_t old_permutation[64];\n\n    int ret;\n\n\n\n    if (avctx->codec_id == AV_CODEC_ID_MPEG1VIDEO) {\n\n        // MPEG-1 aspect\n\n        avctx->sample_aspect_ratio = av_d2q(1.0 / ff_mpeg1_aspect[s->aspect_ratio_info], 255);\n\n    } else { // MPEG-2\n\n        // MPEG-2 aspect\n\n        if (s->aspect_ratio_info > 1) {\n\n            AVRational dar =\n\n                av_mul_q(av_div_q(ff_mpeg2_aspect[s->aspect_ratio_info],\n\n                                  (AVRational) { s1->pan_scan.width,\n\n                                                 s1->pan_scan.height }),\n\n                         (AVRational) { s->width, s->height });\n\n\n\n            /* We ignore the spec here and guess a bit as reality does not\n\n             * match the spec, see for example res_change_ffmpeg_aspect.ts\n\n             * and sequence-display-aspect.mpg.\n\n             * issue1613, 621, 562 */\n\n            if ((s1->pan_scan.width == 0) || (s1->pan_scan.height == 0) ||\n\n                (av_cmp_q(dar, (AVRational) { 4, 3 }) &&\n\n                 av_cmp_q(dar, (AVRational) { 16, 9 }))) {\n\n                s->avctx->sample_aspect_ratio =\n\n                    av_div_q(ff_mpeg2_aspect[s->aspect_ratio_info],\n\n                             (AVRational) { s->width, s->height });\n\n            } else {\n\n                s->avctx->sample_aspect_ratio =\n\n                    av_div_q(ff_mpeg2_aspect[s->aspect_ratio_info],\n\n                             (AVRational) { s1->pan_scan.width, s1->pan_scan.height });\n\n// issue1613 4/3 16/9 -> 16/9\n\n// res_change_ffmpeg_aspect.ts 4/3 225/44 ->4/3\n\n// widescreen-issue562.mpg 4/3 16/9 -> 16/9\n\n//                s->avctx->sample_aspect_ratio = av_mul_q(s->avctx->sample_aspect_ratio, (AVRational) {s->width, s->height});\n\n                av_dlog(avctx, \"A %d/%d\\n\",\n\n                        ff_mpeg2_aspect[s->aspect_ratio_info].num,\n\n                        ff_mpeg2_aspect[s->aspect_ratio_info].den);\n\n                av_dlog(avctx, \"B %d/%d\\n\", s->avctx->sample_aspect_ratio.num,\n\n                        s->avctx->sample_aspect_ratio.den);\n\n            }\n\n        } else {\n\n            s->avctx->sample_aspect_ratio =\n\n                ff_mpeg2_aspect[s->aspect_ratio_info];\n\n        }\n\n    } // MPEG-2\n\n\n\n    ff_set_sar(s->avctx, s->avctx->sample_aspect_ratio);\n\n\n\n    if ((s1->mpeg_enc_ctx_allocated == 0)                   ||\n\n        avctx->coded_width       != s->width                ||\n\n        avctx->coded_height      != s->height               ||\n\n        s1->save_width           != s->width                ||\n\n        s1->save_height          != s->height               ||\n\n        s1->save_aspect_info     != s->aspect_ratio_info    ||\n\n        (s1->save_progressive_seq != s->progressive_sequence && FFALIGN(s->height, 16) != FFALIGN(s->height, 32)) ||\n\n        0) {\n\n        if (s1->mpeg_enc_ctx_allocated) {\n\n            ParseContext pc = s->parse_context;\n\n            s->parse_context.buffer = 0;\n\n            ff_mpv_common_end(s);\n\n            s->parse_context = pc;\n\n            s1->mpeg_enc_ctx_allocated = 0;\n\n        }\n\n\n\n        ret = ff_set_dimensions(avctx, s->width, s->height);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        if (avctx->codec_id == AV_CODEC_ID_MPEG2VIDEO && s->bit_rate) {\n\n            avctx->rc_max_rate = s->bit_rate;\n\n        } else if (avctx->codec_id == AV_CODEC_ID_MPEG1VIDEO && s->bit_rate &&\n\n                   (s->bit_rate != 0x3FFFF*400 || s->vbv_delay != 0xFFFF)) {\n\n            avctx->bit_rate = s->bit_rate;\n\n        }\n\n        s1->save_aspect_info     = s->aspect_ratio_info;\n\n        s1->save_width           = s->width;\n\n        s1->save_height          = s->height;\n\n        s1->save_progressive_seq = s->progressive_sequence;\n\n\n\n        /* low_delay may be forced, in this case we will have B-frames\n\n         * that behave like P-frames. */\n\n        avctx->has_b_frames = !s->low_delay;\n\n\n\n        if (avctx->codec_id == AV_CODEC_ID_MPEG1VIDEO) {\n\n            // MPEG-1 fps\n\n            avctx->framerate = ff_mpeg12_frame_rate_tab[s->frame_rate_index];\n\n            avctx->ticks_per_frame     = 1;\n\n        } else { // MPEG-2\n\n            // MPEG-2 fps\n\n            av_reduce(&s->avctx->framerate.num,\n\n                      &s->avctx->framerate.den,\n\n                      ff_mpeg12_frame_rate_tab[s->frame_rate_index].num * s1->frame_rate_ext.num,\n\n                      ff_mpeg12_frame_rate_tab[s->frame_rate_index].den * s1->frame_rate_ext.den,\n\n                      1 << 30);\n\n            avctx->ticks_per_frame = 2;\n\n        } // MPEG-2\n\n\n\n        avctx->pix_fmt = mpeg_get_pixelformat(avctx);\n\n        setup_hwaccel_for_pixfmt(avctx);\n\n\n\n        /* Quantization matrices may need reordering\n\n         * if DCT permutation is changed. */\n\n        memcpy(old_permutation, s->idsp.idct_permutation, 64 * sizeof(uint8_t));\n\n\n\n        ff_mpv_idct_init(s);\n\n        if ((ret = ff_mpv_common_init(s)) < 0)\n\n            return ret;\n\n\n\n        quant_matrix_rebuild(s->intra_matrix,        old_permutation, s->idsp.idct_permutation);\n\n        quant_matrix_rebuild(s->inter_matrix,        old_permutation, s->idsp.idct_permutation);\n\n        quant_matrix_rebuild(s->chroma_intra_matrix, old_permutation, s->idsp.idct_permutation);\n\n        quant_matrix_rebuild(s->chroma_inter_matrix, old_permutation, s->idsp.idct_permutation);\n\n\n\n        s1->mpeg_enc_ctx_allocated = 1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 26763}
{"project": "FFmpeg", "commit_id": "aae4f5108d04041bb264a9c547f05c4f0d18c9c7", "target": 1, "func": "static int mxf_read_primer_pack(void *arg, AVIOContext *pb, int tag, int size, UID uid, int64_t klv_offset)\n\n{\n\n    MXFContext *mxf = arg;\n\n    int item_num = avio_rb32(pb);\n\n    int item_len = avio_rb32(pb);\n\n\n\n    if (item_len != 18) {\n\n        avpriv_request_sample(pb, \"Primer pack item length %d\", item_len);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n    if (item_num > 65536) {\n\n        av_log(mxf->fc, AV_LOG_ERROR, \"item_num %d is too large\\n\", item_num);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n\n\n    mxf->local_tags = av_calloc(item_num, item_len);\n\n    if (!mxf->local_tags)\n\n        return AVERROR(ENOMEM);\n\n    mxf->local_tags_count = item_num;\n\n    avio_read(pb, mxf->local_tags, item_num*item_len);\n\n    return 0;\n\n}", "idx": 26764}
{"project": "FFmpeg", "commit_id": "009f829dde811af654af7110326aea3a72c05d5e", "target": 1, "func": "static inline void RENAME(yuv2bgr24_2)(SwsContext *c, const uint16_t *buf0,\n\n                                       const uint16_t *buf1, const uint16_t *ubuf0,\n\n                                       const uint16_t *ubuf1, const uint16_t *vbuf0,\n\n                                       const uint16_t *vbuf1, const uint16_t *abuf0,\n\n                                       const uint16_t *abuf1, uint8_t *dest,\n\n                                       int dstW, int yalpha, int uvalpha, int y)\n\n{\n\n    x86_reg uv_off = c->uv_off << 1;\n\n\n\n    //Note 8280 == DSTW_OFFSET but the preprocessor can't handle that there :(\n\n    __asm__ volatile(\n\n        \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n        \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n        \"push %%\"REG_BP\"                        \\n\\t\"\n\n        YSCALEYUV2RGB(%%REGBP, %5, %6)\n\n        \"pxor    %%mm7, %%mm7                   \\n\\t\"\n\n        WRITEBGR24(%%REGb, 8280(%5), %%REGBP)\n\n        \"pop %%\"REG_BP\"                         \\n\\t\"\n\n        \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n        :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n           \"a\" (&c->redDither), \"m\"(uv_off)\n\n    );\n\n}\n", "idx": 26766}
{"project": "FFmpeg", "commit_id": "7620d48f2eab67812d8c535d12a98eaa754a1177", "target": 1, "func": "int avformat_network_init(void)\n\n{\n\n#if CONFIG_NETWORK\n\n    int ret;\n\n    ff_network_inited_globally = 1;\n\n    if ((ret = ff_network_init()) < 0)\n\n        return ret;\n\n    ff_tls_init();\n\n#endif\n\n    return 0;\n\n}\n", "idx": 26768}
{"project": "FFmpeg", "commit_id": "2b0cdd9ec697164ac0415b8629c4a6e5ae9a3b8d", "target": 1, "func": "static int sab_diamond_search(MpegEncContext * s, int *best, int dmin,\n\n                                       int src_index, int ref_index, int const penalty_factor,\n\n                                       int size, int h, int flags)\n\n{\n\n    MotionEstContext * const c= &s->me;\n\n    me_cmp_func cmpf, chroma_cmpf;\n\n    Minima minima[MAX_SAB_SIZE];\n\n    const int minima_count= FFABS(c->dia_size);\n\n    int i, j;\n\n    LOAD_COMMON\n\n    LOAD_COMMON2\n\n    int map_generation= c->map_generation;\n\n\n\n    cmpf= s->dsp.me_cmp[size];\n\n    chroma_cmpf= s->dsp.me_cmp[size+1];\n\n\n\n    for(j=i=0; i<ME_MAP_SIZE; i++){\n\n        uint32_t key= map[i];\n\n\n\n        key += (1<<(ME_MAP_MV_BITS-1)) + (1<<(2*ME_MAP_MV_BITS-1));\n\n\n\n        if((key&((-1)<<(2*ME_MAP_MV_BITS))) != map_generation) continue;\n\n\n\n        assert(j<MAX_SAB_SIZE); //max j = number of predictors\n\n\n\n        minima[j].height= score_map[i];\n\n        minima[j].x= key & ((1<<ME_MAP_MV_BITS)-1); key>>=ME_MAP_MV_BITS;\n\n        minima[j].y= key & ((1<<ME_MAP_MV_BITS)-1);\n\n        minima[j].x-= (1<<(ME_MAP_MV_BITS-1));\n\n        minima[j].y-= (1<<(ME_MAP_MV_BITS-1));\n\n        minima[j].checked=0;\n\n        if(minima[j].x || minima[j].y)\n\n            minima[j].height+= (mv_penalty[((minima[j].x)<<shift)-pred_x] + mv_penalty[((minima[j].y)<<shift)-pred_y])*penalty_factor;\n\n\n\n        j++;\n\n    }\n\n\n\n    qsort(minima, j, sizeof(Minima), minima_cmp);\n\n\n\n    for(; j<minima_count; j++){\n\n        minima[j].height=256*256*256*64;\n\n        minima[j].checked=0;\n\n        minima[j].x= minima[j].y=0;\n\n    }\n\n\n\n    for(i=0; i<minima_count; i++){\n\n        const int x= minima[i].x;\n\n        const int y= minima[i].y;\n\n        int d;\n\n\n\n        if(minima[i].checked) continue;\n\n\n\n        if(   x >= xmax || x <= xmin\n\n           || y >= ymax || y <= ymin)\n\n           continue;\n\n\n\n        SAB_CHECK_MV(x-1, y)\n\n        SAB_CHECK_MV(x+1, y)\n\n        SAB_CHECK_MV(x  , y-1)\n\n        SAB_CHECK_MV(x  , y+1)\n\n\n\n        minima[i].checked= 1;\n\n    }\n\n\n\n    best[0]= minima[0].x;\n\n    best[1]= minima[0].y;\n\n    dmin= minima[0].height;\n\n\n\n    if(   best[0] < xmax && best[0] > xmin\n\n       && best[1] < ymax && best[1] > ymin){\n\n        int d;\n\n        //ensure that the refernece samples for hpel refinement are in the map\n\n        CHECK_MV(best[0]-1, best[1])\n\n        CHECK_MV(best[0]+1, best[1])\n\n        CHECK_MV(best[0], best[1]-1)\n\n        CHECK_MV(best[0], best[1]+1)\n\n    }\n\n    return dmin;\n\n}\n", "idx": 26770}
{"project": "FFmpeg", "commit_id": "0a467a9b594dd67aa96bad687d05f8845b009f18", "target": 1, "func": "static int tiff_decode_tag(TiffContext *s, const uint8_t *start,\n\n                           const uint8_t *buf, const uint8_t *end_buf)\n\n{\n\n    unsigned tag, type, count, off, value = 0;\n\n    int i;\n\n    uint32_t *pal;\n\n    const uint8_t *rp, *gp, *bp;\n\n\n\n    if (end_buf - buf < 12)\n\n        return AVERROR_INVALIDDATA;\n\n    tag   = tget_short(&buf, s->le);\n\n    type  = tget_short(&buf, s->le);\n\n    count = tget_long(&buf, s->le);\n\n    off   = tget_long(&buf, s->le);\n\n\n\n    if (type == 0 || type >= FF_ARRAY_ELEMS(type_sizes)) {\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"Unknown tiff type (%u) encountered\\n\",\n\n               type);\n\n        return 0;\n\n    }\n\n\n\n    if (count == 1) {\n\n        switch (type) {\n\n        case TIFF_BYTE:\n\n        case TIFF_SHORT:\n\n            buf  -= 4;\n\n            value = tget(&buf, type, s->le);\n\n            buf   = NULL;\n\n            break;\n\n        case TIFF_LONG:\n\n            value = off;\n\n            buf   = NULL;\n\n            break;\n\n        case TIFF_STRING:\n\n            if (count <= 4) {\n\n                buf -= 4;\n\n                break;\n\n            }\n\n        default:\n\n            value = UINT_MAX;\n\n            buf   = start + off;\n\n        }\n\n    } else {\n\n        if (count <= 4 && type_sizes[type] * count <= 4)\n\n            buf -= 4;\n\n        else\n\n            buf = start + off;\n\n    }\n\n\n\n    if (buf && (buf < start || buf > end_buf)) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"Tag referencing position outside the image\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    switch (tag) {\n\n    case TIFF_WIDTH:\n\n        s->width = value;\n\n        break;\n\n    case TIFF_HEIGHT:\n\n        s->height = value;\n\n        break;\n\n    case TIFF_BPP:\n\n        s->bppcount = count;\n\n        if (count > 4) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"This format is not supported (bpp=%d, %d components)\\n\",\n\n                   s->bpp, count);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (count == 1)\n\n            s->bpp = value;\n\n        else {\n\n            switch (type) {\n\n            case TIFF_BYTE:\n\n                s->bpp = (off & 0xFF) + ((off >> 8) & 0xFF) +\n\n                         ((off >> 16) & 0xFF) + ((off >> 24) & 0xFF);\n\n                break;\n\n            case TIFF_SHORT:\n\n            case TIFF_LONG:\n\n                s->bpp = 0;\n\n                for (i = 0; i < count && buf < end_buf; i++)\n\n                    s->bpp += tget(&buf, type, s->le);\n\n                break;\n\n            default:\n\n                s->bpp = -1;\n\n            }\n\n        }\n\n        break;\n\n    case TIFF_SAMPLES_PER_PIXEL:\n\n        if (count != 1) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Samples per pixel requires a single value, many provided\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (s->bppcount == 1)\n\n            s->bpp *= value;\n\n        s->bppcount = value;\n\n        break;\n\n    case TIFF_COMPR:\n\n        s->compr     = value;\n\n        s->predictor = 0;\n\n        switch (s->compr) {\n\n        case TIFF_RAW:\n\n        case TIFF_PACKBITS:\n\n        case TIFF_LZW:\n\n        case TIFF_CCITT_RLE:\n\n            break;\n\n        case TIFF_G3:\n\n        case TIFF_G4:\n\n            s->fax_opts = 0;\n\n            break;\n\n        case TIFF_DEFLATE:\n\n        case TIFF_ADOBE_DEFLATE:\n\n#if CONFIG_ZLIB\n\n            break;\n\n#else\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Deflate: ZLib not compiled in\\n\");\n\n            return AVERROR(ENOSYS);\n\n#endif\n\n        case TIFF_JPEG:\n\n        case TIFF_NEWJPEG:\n\n            avpriv_report_missing_feature(s->avctx, \"JPEG compression\");\n\n            return AVERROR_PATCHWELCOME;\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Unknown compression method %i\\n\",\n\n                   s->compr);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        break;\n\n    case TIFF_ROWSPERSTRIP:\n\n        if (type == TIFF_LONG && value == UINT_MAX)\n\n            value = s->avctx->height;\n\n        if (value < 1) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Incorrect value of rows per strip\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        s->rps = value;\n\n        break;\n\n    case TIFF_STRIP_OFFS:\n\n        if (count == 1) {\n\n            s->stripdata = NULL;\n\n            s->stripoff  = value;\n\n        } else\n\n            s->stripdata = start + off;\n\n        s->strips = count;\n\n        if (s->strips == 1)\n\n            s->rps = s->height;\n\n        s->sot = type;\n\n        if (s->stripdata > end_buf) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Tag referencing position outside the image\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        break;\n\n    case TIFF_STRIP_SIZE:\n\n        if (count == 1) {\n\n            s->stripsizes = NULL;\n\n            s->stripsize  = value;\n\n            s->strips     = 1;\n\n        } else {\n\n            s->stripsizes = start + off;\n\n        }\n\n        s->strips = count;\n\n        s->sstype = type;\n\n        if (s->stripsizes > end_buf) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Tag referencing position outside the image\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        break;\n\n    case TIFF_PREDICTOR:\n\n        s->predictor = value;\n\n        break;\n\n    case TIFF_INVERT:\n\n        switch (value) {\n\n        case 0:\n\n            s->invert = 1;\n\n            break;\n\n        case 1:\n\n            s->invert = 0;\n\n            break;\n\n        case 2:\n\n        case 3:\n\n            break;\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Color mode %d is not supported\\n\",\n\n                   value);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        break;\n\n    case TIFF_FILL_ORDER:\n\n        if (value < 1 || value > 2) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Unknown FillOrder value %d, trying default one\\n\", value);\n\n            value = 1;\n\n        }\n\n        s->fill_order = value - 1;\n\n        break;\n\n    case TIFF_PAL:\n\n        pal = (uint32_t *) s->palette;\n\n        off = type_sizes[type];\n\n        if (count / 3 > 256 || end_buf - buf < count / 3 * off * 3)\n\n            return AVERROR_INVALIDDATA;\n\n        rp  = buf;\n\n        gp  = buf + count / 3 * off;\n\n        bp  = buf + count / 3 * off * 2;\n\n        off = (type_sizes[type] - 1) << 3;\n\n        for (i = 0; i < count / 3; i++) {\n\n            uint32_t p = 0xFF000000;\n\n            p |= (tget(&rp, type, s->le) >> off) << 16;\n\n            p |= (tget(&gp, type, s->le) >> off) << 8;\n\n            p |=  tget(&bp, type, s->le) >> off;\n\n            pal[i] = p;\n\n        }\n\n        s->palette_is_set = 1;\n\n        break;\n\n    case TIFF_PLANAR:\n\n        if (value == 2) {\n\n            avpriv_report_missing_feature(s->avctx, \"Planar format\");\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n        break;\n\n    case TIFF_T4OPTIONS:\n\n        if (s->compr == TIFF_G3)\n\n            s->fax_opts = value;\n\n        break;\n\n    case TIFF_T6OPTIONS:\n\n        if (s->compr == TIFF_G4)\n\n            s->fax_opts = value;\n\n        break;\n\n    default:\n\n        if (s->avctx->err_recognition & AV_EF_EXPLODE) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Unknown or unsupported tag %d/0X%0X\\n\",\n\n                   tag, tag);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 26772}
{"project": "FFmpeg", "commit_id": "0c97fd336e17535239ab44d755a0d957dc2688f3", "target": 0, "func": "static int read_packet(AVFormatContext *s,\n\n                           AVPacket *pkt)\n\n{\n\n    MmDemuxContext *mm = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    unsigned char preamble[MM_PREAMBLE_SIZE];\n\n    unsigned int type, length;\n\n\n\n    while(1) {\n\n\n\n        if (avio_read(pb, preamble, MM_PREAMBLE_SIZE) != MM_PREAMBLE_SIZE) {\n\n            return AVERROR(EIO);\n\n        }\n\n\n\n        type = AV_RL16(&preamble[0]);\n\n        length = AV_RL16(&preamble[2]);\n\n\n\n        switch(type) {\n\n        case MM_TYPE_PALETTE :\n\n        case MM_TYPE_INTER :\n\n        case MM_TYPE_INTRA :\n\n        case MM_TYPE_INTRA_HH :\n\n        case MM_TYPE_INTER_HH :\n\n        case MM_TYPE_INTRA_HHV :\n\n        case MM_TYPE_INTER_HHV :\n\n            /* output preamble + data */\n\n            if (av_new_packet(pkt, length + MM_PREAMBLE_SIZE))\n\n                return AVERROR(ENOMEM);\n\n            memcpy(pkt->data, preamble, MM_PREAMBLE_SIZE);\n\n            if (avio_read(pb, pkt->data + MM_PREAMBLE_SIZE, length) != length)\n\n                return AVERROR(EIO);\n\n            pkt->size = length + MM_PREAMBLE_SIZE;\n\n            pkt->stream_index = 0;\n\n            pkt->pts = mm->video_pts;\n\n            if (type!=MM_TYPE_PALETTE)\n\n                mm->video_pts++;\n\n            return 0;\n\n\n\n        case MM_TYPE_AUDIO :\n\n            if (av_get_packet(s->pb, pkt, length)<0)\n\n                return AVERROR(ENOMEM);\n\n            pkt->size = length;\n\n            pkt->stream_index = 1;\n\n            pkt->pts = mm->audio_pts++;\n\n            return 0;\n\n\n\n        default :\n\n            av_log(s, AV_LOG_INFO, \"unknown chunk type 0x%x\\n\", type);\n\n            avio_skip(pb, length);\n\n        }\n\n    }\n\n}\n", "idx": 26773}
{"project": "FFmpeg", "commit_id": "72a6244b5d554d7fdfdeb04c174750c7a2c52f83", "target": 0, "func": "void ff_ac3_bit_alloc_calc_mask(AC3BitAllocParameters *s, int16_t *band_psd,\n\n                                int start, int end, int fast_gain, int is_lfe,\n\n                                int dba_mode, int dba_nsegs, uint8_t *dba_offsets,\n\n                                uint8_t *dba_lengths, uint8_t *dba_values,\n\n                                int16_t *mask)\n\n{\n\n    int16_t excite[50]; /* excitation */\n\n    int bin, k;\n\n    int bndstrt, bndend, begin, end1, tmp;\n\n    int lowcomp, fastleak, slowleak;\n\n\n\n    /* excitation function */\n\n    bndstrt = bin_to_band_tab[start];\n\n    bndend = bin_to_band_tab[end-1] + 1;\n\n\n\n    if (bndstrt == 0) {\n\n        lowcomp = 0;\n\n        lowcomp = calc_lowcomp1(lowcomp, band_psd[0], band_psd[1], 384);\n\n        excite[0] = band_psd[0] - fast_gain - lowcomp;\n\n        lowcomp = calc_lowcomp1(lowcomp, band_psd[1], band_psd[2], 384);\n\n        excite[1] = band_psd[1] - fast_gain - lowcomp;\n\n        begin = 7;\n\n        for (bin = 2; bin < 7; bin++) {\n\n            if (!(is_lfe && bin == 6))\n\n                lowcomp = calc_lowcomp1(lowcomp, band_psd[bin], band_psd[bin+1], 384);\n\n            fastleak = band_psd[bin] - fast_gain;\n\n            slowleak = band_psd[bin] - s->slow_gain;\n\n            excite[bin] = fastleak - lowcomp;\n\n            if (!(is_lfe && bin == 6)) {\n\n                if (band_psd[bin] <= band_psd[bin+1]) {\n\n                    begin = bin + 1;\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n\n\n        end1=bndend;\n\n        if (end1 > 22) end1=22;\n\n\n\n        for (bin = begin; bin < end1; bin++) {\n\n            if (!(is_lfe && bin == 6))\n\n                lowcomp = calc_lowcomp(lowcomp, band_psd[bin], band_psd[bin+1], bin);\n\n\n\n            fastleak = FFMAX(fastleak - s->fast_decay, band_psd[bin] - fast_gain);\n\n            slowleak = FFMAX(slowleak - s->slow_decay, band_psd[bin] - s->slow_gain);\n\n            excite[bin] = FFMAX(fastleak - lowcomp, slowleak);\n\n        }\n\n        begin = 22;\n\n    } else {\n\n        /* coupling channel */\n\n        begin = bndstrt;\n\n\n\n        fastleak = (s->cpl_fast_leak << 8) + 768;\n\n        slowleak = (s->cpl_slow_leak << 8) + 768;\n\n    }\n\n\n\n    for (bin = begin; bin < bndend; bin++) {\n\n        fastleak = FFMAX(fastleak - s->fast_decay, band_psd[bin] - fast_gain);\n\n        slowleak = FFMAX(slowleak - s->slow_decay, band_psd[bin] - s->slow_gain);\n\n        excite[bin] = FFMAX(fastleak, slowleak);\n\n    }\n\n\n\n    /* compute masking curve */\n\n\n\n    for (bin = bndstrt; bin < bndend; bin++) {\n\n        tmp = s->db_per_bit - band_psd[bin];\n\n        if (tmp > 0) {\n\n            excite[bin] += tmp >> 2;\n\n        }\n\n        mask[bin] = FFMAX(ff_ac3_hearing_threshold_tab[bin >> s->sr_shift][s->sr_code], excite[bin]);\n\n    }\n\n\n\n    /* delta bit allocation */\n\n\n\n    if (dba_mode == DBA_REUSE || dba_mode == DBA_NEW) {\n\n        int band, seg, delta;\n\n        band = 0;\n\n        for (seg = 0; seg < FFMIN(8, dba_nsegs); seg++) {\n\n            band = FFMIN(49, band + dba_offsets[seg]);\n\n            if (dba_values[seg] >= 4) {\n\n                delta = (dba_values[seg] - 3) << 7;\n\n            } else {\n\n                delta = (dba_values[seg] - 4) << 7;\n\n            }\n\n            for (k = 0; k < dba_lengths[seg]; k++) {\n\n                mask[band] += delta;\n\n                band++;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 26774}
{"project": "FFmpeg", "commit_id": "03cef34aa66662e2ab3681d290e7c5a6634f4058", "target": 0, "func": "static mfxIMPL choose_implementation(const InputStream *ist)\n\n{\n\n    static const struct {\n\n        const char *name;\n\n        mfxIMPL     impl;\n\n    } impl_map[] = {\n\n        { \"auto\",     MFX_IMPL_AUTO         },\n\n        { \"sw\",       MFX_IMPL_SOFTWARE     },\n\n        { \"hw\",       MFX_IMPL_HARDWARE     },\n\n        { \"auto_any\", MFX_IMPL_AUTO_ANY     },\n\n        { \"hw_any\",   MFX_IMPL_HARDWARE_ANY },\n\n        { \"hw2\",      MFX_IMPL_HARDWARE2    },\n\n        { \"hw3\",      MFX_IMPL_HARDWARE3    },\n\n        { \"hw4\",      MFX_IMPL_HARDWARE4    },\n\n    };\n\n\n\n    mfxIMPL impl = MFX_IMPL_AUTO_ANY;\n\n    int i;\n\n\n\n    if (ist->hwaccel_device) {\n\n        for (i = 0; i < FF_ARRAY_ELEMS(impl_map); i++)\n\n            if (!strcmp(ist->hwaccel_device, impl_map[i].name)) {\n\n                impl = impl_map[i].impl;\n\n                break;\n\n            }\n\n        if (i == FF_ARRAY_ELEMS(impl_map))\n\n            impl = strtol(ist->hwaccel_device, NULL, 0);\n\n    }\n\n\n\n    return impl;\n\n}\n", "idx": 26785}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(rgb16to15)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n    register const uint8_t* s=src;\n\n    register uint8_t* d=dst;\n\n    register const uint8_t *end;\n\n    const uint8_t *mm_end;\n\n    end = s + src_size;\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*s));\n\n    __asm__ volatile(\"movq        %0, %%mm7\"::\"m\"(mask15rg));\n\n    __asm__ volatile(\"movq        %0, %%mm6\"::\"m\"(mask15b));\n\n    mm_end = end - 15;\n\n    while (s<mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"  32%1         \\n\\t\"\n\n            \"movq        %1, %%mm0  \\n\\t\"\n\n            \"movq       8%1, %%mm2  \\n\\t\"\n\n            \"movq     %%mm0, %%mm1  \\n\\t\"\n\n            \"movq     %%mm2, %%mm3  \\n\\t\"\n\n            \"psrlq       $1, %%mm0  \\n\\t\"\n\n            \"psrlq       $1, %%mm2  \\n\\t\"\n\n            \"pand     %%mm7, %%mm0  \\n\\t\"\n\n            \"pand     %%mm7, %%mm2  \\n\\t\"\n\n            \"pand     %%mm6, %%mm1  \\n\\t\"\n\n            \"pand     %%mm6, %%mm3  \\n\\t\"\n\n            \"por      %%mm1, %%mm0  \\n\\t\"\n\n            \"por      %%mm3, %%mm2  \\n\\t\"\n\n            MOVNTQ\"   %%mm0,  %0    \\n\\t\"\n\n            MOVNTQ\"   %%mm2, 8%0\"\n\n            :\"=m\"(*d)\n\n            :\"m\"(*s)\n\n        );\n\n        d+=16;\n\n        s+=16;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n#endif\n\n    mm_end = end - 3;\n\n    while (s < mm_end) {\n\n        register uint32_t x= *((const uint32_t*)s);\n\n        *((uint32_t *)d) = ((x>>1)&0x7FE07FE0) | (x&0x001F001F);\n\n        s+=4;\n\n        d+=4;\n\n    }\n\n    if (s < end) {\n\n        register uint16_t x= *((const uint16_t*)s);\n\n        *((uint16_t *)d) = ((x>>1)&0x7FE0) | (x&0x001F);\n\n    }\n\n}\n", "idx": 26801}
{"project": "FFmpeg", "commit_id": "6021615bbe393381f23b34a7cd0dcfd1a42687ba", "target": 0, "func": "static void hscroll(AVCodecContext *avctx)\n\n{\n\n    AnsiContext *s = avctx->priv_data;\n\n    int i;\n\n\n\n    if (s->y < avctx->height - s->font_height) {\n\n        s->y += s->font_height;\n\n        return;\n\n    }\n\n\n\n    i = 0;\n\n    for (; i < avctx->height - s->font_height; i++)\n\n        memcpy(s->frame->data[0] + i * s->frame->linesize[0],\n\n               s->frame->data[0] + (i + s->font_height) * s->frame->linesize[0],\n\n               avctx->width);\n\n    for (; i < avctx->height; i++)\n\n        memset(s->frame->data[0] + i * s->frame->linesize[0],\n\n            DEFAULT_BG_COLOR, avctx->width);\n\n}\n", "idx": 26812}
{"project": "FFmpeg", "commit_id": "892bbbcdc171ff0d08d69636a240ffb95f54243c", "target": 0, "func": "static int vaapi_encode_issue(AVCodecContext *avctx,\n\n                              VAAPIEncodePicture *pic)\n\n{\n\n    VAAPIEncodeContext *ctx = avctx->priv_data;\n\n    VAAPIEncodeSlice *slice;\n\n    VAStatus vas;\n\n    int err, i;\n\n    char data[MAX_PARAM_BUFFER_SIZE];\n\n    size_t bit_len;\n\n\n\n    av_log(avctx, AV_LOG_DEBUG, \"Issuing encode for pic %\"PRId64\"/%\"PRId64\" \"\n\n           \"as type %s.\\n\", pic->display_order, pic->encode_order,\n\n           picture_type_name[pic->type]);\n\n    if (pic->nb_refs == 0) {\n\n        av_log(avctx, AV_LOG_DEBUG, \"No reference pictures.\\n\");\n\n    } else {\n\n        av_log(avctx, AV_LOG_DEBUG, \"Refers to:\");\n\n        for (i = 0; i < pic->nb_refs; i++) {\n\n            av_log(avctx, AV_LOG_DEBUG, \" %\"PRId64\"/%\"PRId64,\n\n                   pic->refs[i]->display_order, pic->refs[i]->encode_order);\n\n        }\n\n        av_log(avctx, AV_LOG_DEBUG, \".\\n\");\n\n    }\n\n\n\n    av_assert0(pic->input_available && !pic->encode_issued);\n\n    for (i = 0; i < pic->nb_refs; i++) {\n\n        av_assert0(pic->refs[i]);\n\n        // If we are serialised then the references must have already\n\n        // completed.  If not, they must have been issued but need not\n\n        // have completed yet.\n\n        if (ctx->issue_mode == ISSUE_MODE_SERIALISE_EVERYTHING)\n\n            av_assert0(pic->refs[i]->encode_complete);\n\n        else\n\n            av_assert0(pic->refs[i]->encode_issued);\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_DEBUG, \"Input surface is %#x.\\n\", pic->input_surface);\n\n\n\n    pic->recon_image = av_frame_alloc();\n\n    if (!pic->recon_image) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    err = av_hwframe_get_buffer(ctx->recon_frames_ref, pic->recon_image, 0);\n\n    if (err < 0) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    pic->recon_surface = (VASurfaceID)(uintptr_t)pic->recon_image->data[3];\n\n    av_log(avctx, AV_LOG_DEBUG, \"Recon surface is %#x.\\n\", pic->recon_surface);\n\n\n\n    pic->output_buffer_ref = av_buffer_pool_get(ctx->output_buffer_pool);\n\n    if (!pic->output_buffer_ref) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    pic->output_buffer = (VABufferID)(uintptr_t)pic->output_buffer_ref->data;\n\n    av_log(avctx, AV_LOG_DEBUG, \"Output buffer is %#x.\\n\",\n\n           pic->output_buffer);\n\n\n\n    if (ctx->codec->picture_params_size > 0) {\n\n        pic->codec_picture_params = av_malloc(ctx->codec->picture_params_size);\n\n        if (!pic->codec_picture_params)\n\n            goto fail;\n\n        memcpy(pic->codec_picture_params, ctx->codec_picture_params,\n\n               ctx->codec->picture_params_size);\n\n    } else {\n\n        av_assert0(!ctx->codec_picture_params);\n\n    }\n\n\n\n    pic->nb_param_buffers = 0;\n\n\n\n    if (pic->encode_order == 0) {\n\n        // Global parameter buffers are set on the first picture only.\n\n\n\n        for (i = 0; i < ctx->nb_global_params; i++) {\n\n            err = vaapi_encode_make_param_buffer(avctx, pic,\n\n                                                 VAEncMiscParameterBufferType,\n\n                                                 (char*)ctx->global_params[i],\n\n                                                 ctx->global_params_size[i]);\n\n            if (err < 0)\n\n                goto fail;\n\n        }\n\n    }\n\n\n\n    if (pic->type == PICTURE_TYPE_IDR && ctx->codec->init_sequence_params) {\n\n        err = vaapi_encode_make_param_buffer(avctx, pic,\n\n                                             VAEncSequenceParameterBufferType,\n\n                                             ctx->codec_sequence_params,\n\n                                             ctx->codec->sequence_params_size);\n\n        if (err < 0)\n\n            goto fail;\n\n    }\n\n\n\n    if (ctx->codec->init_picture_params) {\n\n        err = ctx->codec->init_picture_params(avctx, pic);\n\n        if (err < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Failed to initialise picture \"\n\n                   \"parameters: %d.\\n\", err);\n\n            goto fail;\n\n        }\n\n        err = vaapi_encode_make_param_buffer(avctx, pic,\n\n                                             VAEncPictureParameterBufferType,\n\n                                             pic->codec_picture_params,\n\n                                             ctx->codec->picture_params_size);\n\n        if (err < 0)\n\n            goto fail;\n\n    }\n\n\n\n    if (pic->type == PICTURE_TYPE_IDR) {\n\n        if (ctx->codec->write_sequence_header) {\n\n            bit_len = 8 * sizeof(data);\n\n            err = ctx->codec->write_sequence_header(avctx, data, &bit_len);\n\n            if (err < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Failed to write per-sequence \"\n\n                       \"header: %d.\\n\", err);\n\n                goto fail;\n\n            }\n\n            err = vaapi_encode_make_packed_header(avctx, pic,\n\n                                                  ctx->codec->sequence_header_type,\n\n                                                  data, bit_len);\n\n            if (err < 0)\n\n                goto fail;\n\n        }\n\n    }\n\n\n\n    if (ctx->codec->write_picture_header) {\n\n        bit_len = 8 * sizeof(data);\n\n        err = ctx->codec->write_picture_header(avctx, pic, data, &bit_len);\n\n        if (err < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Failed to write per-picture \"\n\n                   \"header: %d.\\n\", err);\n\n            goto fail;\n\n        }\n\n        err = vaapi_encode_make_packed_header(avctx, pic,\n\n                                              ctx->codec->picture_header_type,\n\n                                              data, bit_len);\n\n        if (err < 0)\n\n            goto fail;\n\n    }\n\n\n\n    if (ctx->codec->write_extra_buffer) {\n\n        for (i = 0;; i++) {\n\n            size_t len = sizeof(data);\n\n            int type;\n\n            err = ctx->codec->write_extra_buffer(avctx, pic, i, &type,\n\n                                                 data, &len);\n\n            if (err == AVERROR_EOF)\n\n                break;\n\n            if (err < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Failed to write extra \"\n\n                       \"buffer %d: %d.\\n\", i, err);\n\n                goto fail;\n\n            }\n\n\n\n            err = vaapi_encode_make_param_buffer(avctx, pic, type,\n\n                                                 data, len);\n\n            if (err < 0)\n\n                goto fail;\n\n        }\n\n    }\n\n\n\n    if (ctx->codec->write_extra_header) {\n\n        for (i = 0;; i++) {\n\n            int type;\n\n            bit_len = 8 * sizeof(data);\n\n            err = ctx->codec->write_extra_header(avctx, pic, i, &type,\n\n                                                 data, &bit_len);\n\n            if (err == AVERROR_EOF)\n\n                break;\n\n            if (err < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Failed to write extra \"\n\n                       \"header %d: %d.\\n\", i, err);\n\n                goto fail;\n\n            }\n\n\n\n            err = vaapi_encode_make_packed_header(avctx, pic, type,\n\n                                                  data, bit_len);\n\n            if (err < 0)\n\n                goto fail;\n\n        }\n\n    }\n\n\n\n    av_assert0(pic->nb_slices <= MAX_PICTURE_SLICES);\n\n    for (i = 0; i < pic->nb_slices; i++) {\n\n        slice = av_mallocz(sizeof(*slice));\n\n        if (!slice) {\n\n            err = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n        pic->slices[i] = slice;\n\n\n\n        if (ctx->codec->slice_params_size > 0) {\n\n            slice->codec_slice_params = av_mallocz(ctx->codec->slice_params_size);\n\n            if (!slice->codec_slice_params) {\n\n                err = AVERROR(ENOMEM);\n\n                goto fail;\n\n            }\n\n        }\n\n\n\n        if (ctx->codec->init_slice_params) {\n\n            err = ctx->codec->init_slice_params(avctx, pic, slice);\n\n            if (err < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Failed to initalise slice \"\n\n                       \"parameters: %d.\\n\", err);\n\n                goto fail;\n\n            }\n\n        }\n\n\n\n        if (ctx->codec->write_slice_header) {\n\n            bit_len = 8 * sizeof(data);\n\n            err = ctx->codec->write_slice_header(avctx, pic, slice,\n\n                                                 data, &bit_len);\n\n            if (err < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Failed to write per-slice \"\n\n                       \"header: %d.\\n\", err);\n\n                goto fail;\n\n            }\n\n            err = vaapi_encode_make_packed_header(avctx, pic,\n\n                                                  ctx->codec->slice_header_type,\n\n                                                  data, bit_len);\n\n            if (err < 0)\n\n                goto fail;\n\n        }\n\n\n\n        if (ctx->codec->init_slice_params) {\n\n            err = vaapi_encode_make_param_buffer(avctx, pic,\n\n                                                 VAEncSliceParameterBufferType,\n\n                                                 slice->codec_slice_params,\n\n                                                 ctx->codec->slice_params_size);\n\n            if (err < 0)\n\n                goto fail;\n\n        }\n\n    }\n\n\n\n    vas = vaBeginPicture(ctx->hwctx->display, ctx->va_context,\n\n                         pic->input_surface);\n\n    if (vas != VA_STATUS_SUCCESS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to begin picture encode issue: \"\n\n               \"%d (%s).\\n\", vas, vaErrorStr(vas));\n\n        err = AVERROR(EIO);\n\n        goto fail_with_picture;\n\n    }\n\n\n\n    vas = vaRenderPicture(ctx->hwctx->display, ctx->va_context,\n\n                          pic->param_buffers, pic->nb_param_buffers);\n\n    if (vas != VA_STATUS_SUCCESS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to upload encode parameters: \"\n\n               \"%d (%s).\\n\", vas, vaErrorStr(vas));\n\n        err = AVERROR(EIO);\n\n        goto fail_with_picture;\n\n    }\n\n\n\n    vas = vaEndPicture(ctx->hwctx->display, ctx->va_context);\n\n    if (vas != VA_STATUS_SUCCESS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to end picture encode issue: \"\n\n               \"%d (%s).\\n\", vas, vaErrorStr(vas));\n\n        err = AVERROR(EIO);\n\n        // vaRenderPicture() has been called here, so we should not destroy\n\n        // the parameter buffers unless separate destruction is required.\n\n        if (ctx->hwctx->driver_quirks &\n\n            AV_VAAPI_DRIVER_QUIRK_RENDER_PARAM_BUFFERS)\n\n            goto fail;\n\n        else\n\n            goto fail_at_end;\n\n    }\n\n\n\n    if (ctx->hwctx->driver_quirks &\n\n        AV_VAAPI_DRIVER_QUIRK_RENDER_PARAM_BUFFERS) {\n\n        for (i = 0; i < pic->nb_param_buffers; i++) {\n\n            vas = vaDestroyBuffer(ctx->hwctx->display,\n\n                                  pic->param_buffers[i]);\n\n            if (vas != VA_STATUS_SUCCESS) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Failed to destroy \"\n\n                       \"param buffer %#x: %d (%s).\\n\",\n\n                       pic->param_buffers[i], vas, vaErrorStr(vas));\n\n                // And ignore.\n\n            }\n\n        }\n\n    }\n\n\n\n    pic->encode_issued = 1;\n\n\n\n    if (ctx->issue_mode == ISSUE_MODE_SERIALISE_EVERYTHING)\n\n        return vaapi_encode_wait(avctx, pic);\n\n    else\n\n        return 0;\n\n\n\nfail_with_picture:\n\n    vaEndPicture(ctx->hwctx->display, ctx->va_context);\n\nfail:\n\n    for(i = 0; i < pic->nb_param_buffers; i++)\n\n        vaDestroyBuffer(ctx->hwctx->display, pic->param_buffers[i]);\n\nfail_at_end:\n\n    av_freep(&pic->codec_picture_params);\n\n    av_frame_free(&pic->recon_image);\n\n    return err;\n\n}\n", "idx": 26816}
{"project": "FFmpeg", "commit_id": "2aab7c2dfaca4386c38e5d565cd2bf73096bcc86", "target": 0, "func": "static void avc_luma_hv_qrt_8w_msa(const uint8_t *src_x, const uint8_t *src_y,\n\n                                   int32_t src_stride, uint8_t *dst,\n\n                                   int32_t dst_stride, int32_t height)\n\n{\n\n    uint32_t loop_cnt;\n\n    v16i8 src_hz0, src_hz1, src_hz2, src_hz3;\n\n    v16i8 src_vt0, src_vt1, src_vt2, src_vt3, src_vt4;\n\n    v16i8 src_vt5, src_vt6, src_vt7, src_vt8;\n\n    v16i8 mask0, mask1, mask2;\n\n    v8i16 hz_out0, hz_out1, hz_out2, hz_out3;\n\n    v8i16 vert_out0, vert_out1, vert_out2, vert_out3;\n\n    v8i16 out0, out1, out2, out3;\n\n    v16u8 tmp0, tmp1;\n\n\n\n    LD_SB3(&luma_mask_arr[0], 16, mask0, mask1, mask2);\n\n    LD_SB5(src_y, src_stride, src_vt0, src_vt1, src_vt2, src_vt3, src_vt4);\n\n    src_y += (5 * src_stride);\n\n\n\n    src_vt0 = (v16i8) __msa_insve_d((v2i64) src_vt0, 1, (v2i64) src_vt1);\n\n    src_vt1 = (v16i8) __msa_insve_d((v2i64) src_vt1, 1, (v2i64) src_vt2);\n\n    src_vt2 = (v16i8) __msa_insve_d((v2i64) src_vt2, 1, (v2i64) src_vt3);\n\n    src_vt3 = (v16i8) __msa_insve_d((v2i64) src_vt3, 1, (v2i64) src_vt4);\n\n\n\n    XORI_B4_128_SB(src_vt0, src_vt1, src_vt2, src_vt3);\n\n\n\n    for (loop_cnt = (height >> 2); loop_cnt--;) {\n\n        LD_SB4(src_x, src_stride, src_hz0, src_hz1, src_hz2, src_hz3);\n\n        XORI_B4_128_SB(src_hz0, src_hz1, src_hz2, src_hz3);\n\n        src_x += (4 * src_stride);\n\n\n\n        hz_out0 = AVC_HORZ_FILTER_SH(src_hz0, src_hz0, mask0, mask1, mask2);\n\n        hz_out1 = AVC_HORZ_FILTER_SH(src_hz1, src_hz1, mask0, mask1, mask2);\n\n        hz_out2 = AVC_HORZ_FILTER_SH(src_hz2, src_hz2, mask0, mask1, mask2);\n\n        hz_out3 = AVC_HORZ_FILTER_SH(src_hz3, src_hz3, mask0, mask1, mask2);\n\n\n\n        SRARI_H4_SH(hz_out0, hz_out1, hz_out2, hz_out3, 5);\n\n        SAT_SH4_SH(hz_out0, hz_out1, hz_out2, hz_out3, 7);\n\n\n\n        LD_SB4(src_y, src_stride, src_vt5, src_vt6, src_vt7, src_vt8);\n\n        src_y += (4 * src_stride);\n\n\n\n        src_vt4 = (v16i8) __msa_insve_d((v2i64) src_vt4, 1, (v2i64) src_vt5);\n\n        src_vt5 = (v16i8) __msa_insve_d((v2i64) src_vt5, 1, (v2i64) src_vt6);\n\n        src_vt6 = (v16i8) __msa_insve_d((v2i64) src_vt6, 1, (v2i64) src_vt7);\n\n        src_vt7 = (v16i8) __msa_insve_d((v2i64) src_vt7, 1, (v2i64) src_vt8);\n\n\n\n        XORI_B4_128_SB(src_vt4, src_vt5, src_vt6, src_vt7);\n\n\n\n        /* filter calc */\n\n        AVC_CALC_DPADD_B_6PIX_2COEFF_SH(src_vt0, src_vt1, src_vt2, src_vt3,\n\n                                        src_vt4, src_vt5, vert_out0, vert_out1);\n\n        AVC_CALC_DPADD_B_6PIX_2COEFF_SH(src_vt2, src_vt3, src_vt4, src_vt5,\n\n                                        src_vt6, src_vt7, vert_out2, vert_out3);\n\n\n\n        SRARI_H4_SH(vert_out0, vert_out1, vert_out2, vert_out3, 5);\n\n        SAT_SH4_SH(vert_out0, vert_out1, vert_out2, vert_out3, 7);\n\n\n\n        out0 = __msa_srari_h((hz_out0 + vert_out0), 1);\n\n        out1 = __msa_srari_h((hz_out1 + vert_out1), 1);\n\n        out2 = __msa_srari_h((hz_out2 + vert_out2), 1);\n\n        out3 = __msa_srari_h((hz_out3 + vert_out3), 1);\n\n\n\n        SAT_SH4_SH(out0, out1, out2, out3, 7);\n\n        tmp0 = PCKEV_XORI128_UB(out0, out1);\n\n        tmp1 = PCKEV_XORI128_UB(out2, out3);\n\n        ST8x4_UB(tmp0, tmp1, dst, dst_stride);\n\n\n\n        dst += (4 * dst_stride);\n\n        src_vt3 = src_vt7;\n\n        src_vt1 = src_vt5;\n\n        src_vt5 = src_vt4;\n\n        src_vt4 = src_vt8;\n\n        src_vt2 = src_vt6;\n\n        src_vt0 = src_vt5;\n\n    }\n\n}\n", "idx": 26817}
{"project": "FFmpeg", "commit_id": "240fd8c96f59ebe9dcfc4152a1086cd3f63400c0", "target": 0, "func": "int av_packet_split_side_data(AVPacket *pkt){\n\n    if (!pkt->side_data_elems && pkt->size >12 && AV_RB64(pkt->data + pkt->size - 8) == FF_MERGE_MARKER){\n\n        int i;\n\n        unsigned int size, orig_pktsize = pkt->size;\n\n        uint8_t *p;\n\n\n\n        p = pkt->data + pkt->size - 8 - 5;\n\n        for (i=1; ; i++){\n\n            size = AV_RB32(p);\n\n            if (size>INT_MAX || p - pkt->data < size)\n\n                return 0;\n\n            if (p[4]&128)\n\n                break;\n\n            p-= size+5;\n\n        }\n\n\n\n        pkt->side_data = av_malloc(i * sizeof(*pkt->side_data));\n\n        if (!pkt->side_data)\n\n            return AVERROR(ENOMEM);\n\n\n\n        p= pkt->data + pkt->size - 8 - 5;\n\n        for (i=0; ; i++){\n\n            size= AV_RB32(p);\n\n            av_assert0(size<=INT_MAX && p - pkt->data >= size);\n\n            pkt->side_data[i].data = av_malloc(size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            pkt->side_data[i].size = size;\n\n            pkt->side_data[i].type = p[4]&127;\n\n            if (!pkt->side_data[i].data)\n\n                return AVERROR(ENOMEM);\n\n            memcpy(pkt->side_data[i].data, p-size, size);\n\n            pkt->size -= size + 5;\n\n            if(p[4]&128)\n\n                break;\n\n            p-= size+5;\n\n        }\n\n        pkt->size -= 8;\n\n        /* FFMIN() prevents overflow in case the packet wasn't allocated with\n\n         * proper padding.\n\n         * If the side data is smaller than the buffer padding size, the\n\n         * remaining bytes should have already been filled with zeros by the\n\n         * original packet allocation anyway. */\n\n        memset(pkt->data + pkt->size, 0,\n\n               FFMIN(orig_pktsize - pkt->size, FF_INPUT_BUFFER_PADDING_SIZE));\n\n        pkt->side_data_elems = i+1;\n\n        return 1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 26818}
{"project": "FFmpeg", "commit_id": "8a57ca5c6a1c0ad28afa7ea6f824981e6761cce1", "target": 0, "func": "static int aasc_decode_frame(AVCodecContext *avctx,\n\n                              void *data, int *data_size,\n\n                              AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    AascContext *s = avctx->priv_data;\n\n    int compr, i, stride;\n\n\n\n    s->frame.reference = 3;\n\n    s->frame.buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE;\n\n    if (avctx->reget_buffer(avctx, &s->frame)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    compr = AV_RL32(buf);\n\n    buf += 4;\n\n    buf_size -= 4;\n\n    switch (avctx->codec_tag) {\n\n    case MKTAG('A', 'A', 'S', '4'):\n\n        bytestream2_init(&s->gb, buf - 4, buf_size + 4);\n\n        ff_msrle_decode(avctx, (AVPicture*)&s->frame, 8, &s->gb);\n\n        break;\n\n    case MKTAG('A', 'A', 'S', 'C'):\n\n    switch(compr){\n\n    case 0:\n\n        stride = (avctx->width * 3 + 3) & ~3;\n\n        for(i = avctx->height - 1; i >= 0; i--){\n\n            if(avctx->width*3 > buf_size){\n\n                av_log(avctx, AV_LOG_ERROR, \"Next line is beyond buffer bounds\\n\");\n\n                break;\n\n            }\n\n            memcpy(s->frame.data[0] + i*s->frame.linesize[0], buf, avctx->width*3);\n\n            buf += stride;\n\n            buf_size -= stride;\n\n        }\n\n        break;\n\n    case 1:\n\n        bytestream2_init(&s->gb, buf, buf_size);\n\n        ff_msrle_decode(avctx, (AVPicture*)&s->frame, 8, &s->gb);\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown compression type %d\\n\", compr);\n\n        return -1;\n\n    }\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown FourCC: %X\\n\", avctx->codec_tag);\n\n        return -1;\n\n    }\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame*)data = s->frame;\n\n\n\n    /* report that the buffer was completely consumed */\n\n    return buf_size;\n\n}\n", "idx": 26819}
{"project": "FFmpeg", "commit_id": "e2afcc33e0bcba92ab6c767f09f17a67911a4928", "target": 0, "func": "static int dxva_get_decoder_guid(AVCodecContext *avctx, void *service, void *surface_format,\n\n                                 unsigned guid_count, const GUID *guid_list, GUID *decoder_guid)\n\n{\n\n    FFDXVASharedContext *sctx = DXVA_SHARED_CONTEXT(avctx);\n\n    unsigned i, j;\n\n\n\n    *decoder_guid = ff_GUID_NULL;\n\n    for (i = 0; dxva_modes[i].guid; i++) {\n\n        const dxva_mode *mode = &dxva_modes[i];\n\n        int validate;\n\n        if (mode->codec != avctx->codec_id)\n\n            continue;\n\n\n\n        for (j = 0; j < guid_count; j++) {\n\n            if (IsEqualGUID(mode->guid, &guid_list[j]))\n\n                break;\n\n        }\n\n        if (j == guid_count)\n\n            continue;\n\n\n\n#if CONFIG_D3D11VA\n\n        if (sctx->pix_fmt == AV_PIX_FMT_D3D11)\n\n            validate = d3d11va_validate_output(service, *mode->guid, surface_format);\n\n#endif\n\n#if CONFIG_DXVA2\n\n        if (sctx->pix_fmt == AV_PIX_FMT_DXVA2_VLD)\n\n            validate = dxva2_validate_output(service, *mode->guid, surface_format);\n\n#endif\n\n        if (validate) {\n\n            *decoder_guid = *mode->guid;\n\n            break;\n\n        }\n\n    }\n\n\n\n    if (IsEqualGUID(decoder_guid, &ff_GUID_NULL)) {\n\n        av_log(avctx, AV_LOG_VERBOSE, \"No decoder device for codec found\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (IsEqualGUID(decoder_guid, &ff_DXVADDI_Intel_ModeH264_E))\n\n        sctx->workaround |= FF_DXVA2_WORKAROUND_INTEL_CLEARVIDEO;\n\n\n\n    return 0;\n\n}\n", "idx": 26820}
{"project": "FFmpeg", "commit_id": "9a0f60a0f89a7a71839dfa9def5a26f2037aed62", "target": 0, "func": "static int decode_vol_header(Mpeg4DecContext *ctx, GetBitContext *gb)\n\n{\n\n    MpegEncContext *s = &ctx->m;\n\n    int width, height, vo_ver_id;\n\n\n\n    /* vol header */\n\n    skip_bits(gb, 1);                   /* random access */\n\n    s->vo_type = get_bits(gb, 8);\n\n    if (get_bits1(gb) != 0) {           /* is_ol_id */\n\n        vo_ver_id = get_bits(gb, 4);    /* vo_ver_id */\n\n        skip_bits(gb, 3);               /* vo_priority */\n\n    } else {\n\n        vo_ver_id = 1;\n\n    }\n\n    s->aspect_ratio_info = get_bits(gb, 4);\n\n    if (s->aspect_ratio_info == FF_ASPECT_EXTENDED) {\n\n        s->avctx->sample_aspect_ratio.num = get_bits(gb, 8);  // par_width\n\n        s->avctx->sample_aspect_ratio.den = get_bits(gb, 8);  // par_height\n\n    } else {\n\n        s->avctx->sample_aspect_ratio = ff_h263_pixel_aspect[s->aspect_ratio_info];\n\n    }\n\n\n\n    if ((ctx->vol_control_parameters = get_bits1(gb))) { /* vol control parameter */\n\n        int chroma_format = get_bits(gb, 2);\n\n        if (chroma_format != CHROMA_420)\n\n            av_log(s->avctx, AV_LOG_ERROR, \"illegal chroma format\\n\");\n\n\n\n        s->low_delay = get_bits1(gb);\n\n        if (get_bits1(gb)) {    /* vbv parameters */\n\n            get_bits(gb, 15);   /* first_half_bitrate */\n\n            skip_bits1(gb);     /* marker */\n\n            get_bits(gb, 15);   /* latter_half_bitrate */\n\n            skip_bits1(gb);     /* marker */\n\n            get_bits(gb, 15);   /* first_half_vbv_buffer_size */\n\n            skip_bits1(gb);     /* marker */\n\n            get_bits(gb, 3);    /* latter_half_vbv_buffer_size */\n\n            get_bits(gb, 11);   /* first_half_vbv_occupancy */\n\n            skip_bits1(gb);     /* marker */\n\n            get_bits(gb, 15);   /* latter_half_vbv_occupancy */\n\n            skip_bits1(gb);     /* marker */\n\n        }\n\n    } else {\n\n        /* is setting low delay flag only once the smartest thing to do?\n\n         * low delay detection won't be overridden. */\n\n        if (s->picture_number == 0)\n\n            s->low_delay = 0;\n\n    }\n\n\n\n    ctx->shape = get_bits(gb, 2); /* vol shape */\n\n    if (ctx->shape != RECT_SHAPE)\n\n        av_log(s->avctx, AV_LOG_ERROR, \"only rectangular vol supported\\n\");\n\n    if (ctx->shape == GRAY_SHAPE && vo_ver_id != 1) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Gray shape not supported\\n\");\n\n        skip_bits(gb, 4);  /* video_object_layer_shape_extension */\n\n    }\n\n\n\n    check_marker(gb, \"before time_increment_resolution\");\n\n\n\n    s->avctx->framerate.num = get_bits(gb, 16);\n\n    if (!s->avctx->framerate.num) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"framerate==0\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    ctx->time_increment_bits = av_log2(s->avctx->framerate.num - 1) + 1;\n\n    if (ctx->time_increment_bits < 1)\n\n        ctx->time_increment_bits = 1;\n\n\n\n    check_marker(gb, \"before fixed_vop_rate\");\n\n\n\n    if (get_bits1(gb) != 0)     /* fixed_vop_rate  */\n\n        s->avctx->framerate.den = get_bits(gb, ctx->time_increment_bits);\n\n    else\n\n        s->avctx->framerate.den = 1;\n\n\n\n    s->avctx->time_base = av_inv_q(av_mul_q(s->avctx->framerate, (AVRational){s->avctx->ticks_per_frame, 1}));\n\n\n\n    ctx->t_frame = 0;\n\n\n\n    if (ctx->shape != BIN_ONLY_SHAPE) {\n\n        if (ctx->shape == RECT_SHAPE) {\n\n            check_marker(gb, \"before width\");\n\n            width = get_bits(gb, 13);\n\n            check_marker(gb, \"before height\");\n\n            height = get_bits(gb, 13);\n\n            check_marker(gb, \"after height\");\n\n            if (width && height &&  /* they should be non zero but who knows */\n\n                !(s->width && s->codec_tag == AV_RL32(\"MP4S\"))) {\n\n                if (s->width && s->height &&\n\n                    (s->width != width || s->height != height))\n\n                    s->context_reinit = 1;\n\n                s->width  = width;\n\n                s->height = height;\n\n            }\n\n        }\n\n\n\n        s->progressive_sequence  =\n\n        s->progressive_frame     = get_bits1(gb) ^ 1;\n\n        s->interlaced_dct        = 0;\n\n        if (!get_bits1(gb) && (s->avctx->debug & FF_DEBUG_PICT_INFO))\n\n            av_log(s->avctx, AV_LOG_INFO,           /* OBMC Disable */\n\n                   \"MPEG4 OBMC not supported (very likely buggy encoder)\\n\");\n\n        if (vo_ver_id == 1)\n\n            ctx->vol_sprite_usage = get_bits1(gb);    /* vol_sprite_usage */\n\n        else\n\n            ctx->vol_sprite_usage = get_bits(gb, 2);  /* vol_sprite_usage */\n\n\n\n        if (ctx->vol_sprite_usage == STATIC_SPRITE)\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Static Sprites not supported\\n\");\n\n        if (ctx->vol_sprite_usage == STATIC_SPRITE ||\n\n            ctx->vol_sprite_usage == GMC_SPRITE) {\n\n            if (ctx->vol_sprite_usage == STATIC_SPRITE) {\n\n                skip_bits(gb, 13); // sprite_width\n\n                skip_bits1(gb); /* marker */\n\n                skip_bits(gb, 13); // sprite_height\n\n                skip_bits1(gb); /* marker */\n\n                skip_bits(gb, 13); // sprite_left\n\n                skip_bits1(gb); /* marker */\n\n                skip_bits(gb, 13); // sprite_top\n\n                skip_bits1(gb); /* marker */\n\n            }\n\n            ctx->num_sprite_warping_points = get_bits(gb, 6);\n\n            if (ctx->num_sprite_warping_points > 3) {\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"%d sprite_warping_points\\n\",\n\n                       ctx->num_sprite_warping_points);\n\n                ctx->num_sprite_warping_points = 0;\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            s->sprite_warping_accuracy  = get_bits(gb, 2);\n\n            ctx->sprite_brightness_change = get_bits1(gb);\n\n            if (ctx->vol_sprite_usage == STATIC_SPRITE)\n\n                skip_bits1(gb); // low_latency_sprite\n\n        }\n\n        // FIXME sadct disable bit if verid!=1 && shape not rect\n\n\n\n        if (get_bits1(gb) == 1) {                   /* not_8_bit */\n\n            s->quant_precision = get_bits(gb, 4);   /* quant_precision */\n\n            if (get_bits(gb, 4) != 8)               /* bits_per_pixel */\n\n                av_log(s->avctx, AV_LOG_ERROR, \"N-bit not supported\\n\");\n\n            if (s->quant_precision != 5)\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"quant precision %d\\n\", s->quant_precision);\n\n            if (s->quant_precision<3 || s->quant_precision>9) {\n\n                s->quant_precision = 5;\n\n            }\n\n        } else {\n\n            s->quant_precision = 5;\n\n        }\n\n\n\n        // FIXME a bunch of grayscale shape things\n\n\n\n        if ((s->mpeg_quant = get_bits1(gb))) { /* vol_quant_type */\n\n            int i, v;\n\n\n\n            /* load default matrixes */\n\n            for (i = 0; i < 64; i++) {\n\n                int j = s->idsp.idct_permutation[i];\n\n                v = ff_mpeg4_default_intra_matrix[i];\n\n                s->intra_matrix[j]        = v;\n\n                s->chroma_intra_matrix[j] = v;\n\n\n\n                v = ff_mpeg4_default_non_intra_matrix[i];\n\n                s->inter_matrix[j]        = v;\n\n                s->chroma_inter_matrix[j] = v;\n\n            }\n\n\n\n            /* load custom intra matrix */\n\n            if (get_bits1(gb)) {\n\n                int last = 0;\n\n                for (i = 0; i < 64; i++) {\n\n                    int j;\n\n                    v = get_bits(gb, 8);\n\n                    if (v == 0)\n\n                        break;\n\n\n\n                    last = v;\n\n                    j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n\n                    s->intra_matrix[j]        = last;\n\n                    s->chroma_intra_matrix[j] = last;\n\n                }\n\n\n\n                /* replicate last value */\n\n                for (; i < 64; i++) {\n\n                    int j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n\n                    s->intra_matrix[j]        = last;\n\n                    s->chroma_intra_matrix[j] = last;\n\n                }\n\n            }\n\n\n\n            /* load custom non intra matrix */\n\n            if (get_bits1(gb)) {\n\n                int last = 0;\n\n                for (i = 0; i < 64; i++) {\n\n                    int j;\n\n                    v = get_bits(gb, 8);\n\n                    if (v == 0)\n\n                        break;\n\n\n\n                    last = v;\n\n                    j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n\n                    s->inter_matrix[j]        = v;\n\n                    s->chroma_inter_matrix[j] = v;\n\n                }\n\n\n\n                /* replicate last value */\n\n                for (; i < 64; i++) {\n\n                    int j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n\n                    s->inter_matrix[j]        = last;\n\n                    s->chroma_inter_matrix[j] = last;\n\n                }\n\n            }\n\n\n\n            // FIXME a bunch of grayscale shape things\n\n        }\n\n\n\n        if (vo_ver_id != 1)\n\n            s->quarter_sample = get_bits1(gb);\n\n        else\n\n            s->quarter_sample = 0;\n\n\n\n        if (get_bits_left(gb) < 4) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"VOL Header truncated\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        if (!get_bits1(gb)) {\n\n            int pos               = get_bits_count(gb);\n\n            int estimation_method = get_bits(gb, 2);\n\n            if (estimation_method < 2) {\n\n                if (!get_bits1(gb)) {\n\n                    ctx->cplx_estimation_trash_i += 8 * get_bits1(gb);  /* opaque */\n\n                    ctx->cplx_estimation_trash_i += 8 * get_bits1(gb);  /* transparent */\n\n                    ctx->cplx_estimation_trash_i += 8 * get_bits1(gb);  /* intra_cae */\n\n                    ctx->cplx_estimation_trash_i += 8 * get_bits1(gb);  /* inter_cae */\n\n                    ctx->cplx_estimation_trash_i += 8 * get_bits1(gb);  /* no_update */\n\n                    ctx->cplx_estimation_trash_i += 8 * get_bits1(gb);  /* upampling */\n\n                }\n\n                if (!get_bits1(gb)) {\n\n                    ctx->cplx_estimation_trash_i += 8 * get_bits1(gb);  /* intra_blocks */\n\n                    ctx->cplx_estimation_trash_p += 8 * get_bits1(gb);  /* inter_blocks */\n\n                    ctx->cplx_estimation_trash_p += 8 * get_bits1(gb);  /* inter4v_blocks */\n\n                    ctx->cplx_estimation_trash_i += 8 * get_bits1(gb);  /* not coded blocks */\n\n                }\n\n                if (!check_marker(gb, \"in complexity estimation part 1\")) {\n\n                    skip_bits_long(gb, pos - get_bits_count(gb));\n\n                    goto no_cplx_est;\n\n                }\n\n                if (!get_bits1(gb)) {\n\n                    ctx->cplx_estimation_trash_i += 8 * get_bits1(gb);  /* dct_coeffs */\n\n                    ctx->cplx_estimation_trash_i += 8 * get_bits1(gb);  /* dct_lines */\n\n                    ctx->cplx_estimation_trash_i += 8 * get_bits1(gb);  /* vlc_syms */\n\n                    ctx->cplx_estimation_trash_i += 4 * get_bits1(gb);  /* vlc_bits */\n\n                }\n\n                if (!get_bits1(gb)) {\n\n                    ctx->cplx_estimation_trash_p += 8 * get_bits1(gb);  /* apm */\n\n                    ctx->cplx_estimation_trash_p += 8 * get_bits1(gb);  /* npm */\n\n                    ctx->cplx_estimation_trash_b += 8 * get_bits1(gb);  /* interpolate_mc_q */\n\n                    ctx->cplx_estimation_trash_p += 8 * get_bits1(gb);  /* forwback_mc_q */\n\n                    ctx->cplx_estimation_trash_p += 8 * get_bits1(gb);  /* halfpel2 */\n\n                    ctx->cplx_estimation_trash_p += 8 * get_bits1(gb);  /* halfpel4 */\n\n                }\n\n                if (!check_marker(gb, \"in complexity estimation part 2\")) {\n\n                    skip_bits_long(gb, pos - get_bits_count(gb));\n\n                    goto no_cplx_est;\n\n                }\n\n                if (estimation_method == 1) {\n\n                    ctx->cplx_estimation_trash_i += 8 * get_bits1(gb);  /* sadct */\n\n                    ctx->cplx_estimation_trash_p += 8 * get_bits1(gb);  /* qpel */\n\n                }\n\n            } else\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"Invalid Complexity estimation method %d\\n\",\n\n                       estimation_method);\n\n        } else {\n\n\n\nno_cplx_est:\n\n            ctx->cplx_estimation_trash_i =\n\n            ctx->cplx_estimation_trash_p =\n\n            ctx->cplx_estimation_trash_b = 0;\n\n        }\n\n\n\n        ctx->resync_marker = !get_bits1(gb); /* resync_marker_disabled */\n\n\n\n        s->data_partitioning = get_bits1(gb);\n\n        if (s->data_partitioning)\n\n            ctx->rvlc = get_bits1(gb);\n\n\n\n        if (vo_ver_id != 1) {\n\n            ctx->new_pred = get_bits1(gb);\n\n            if (ctx->new_pred) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"new pred not supported\\n\");\n\n                skip_bits(gb, 2); /* requested upstream message type */\n\n                skip_bits1(gb);   /* newpred segment type */\n\n            }\n\n            if (get_bits1(gb)) // reduced_res_vop\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"reduced resolution VOP not supported\\n\");\n\n        } else {\n\n            ctx->new_pred = 0;\n\n        }\n\n\n\n        ctx->scalability = get_bits1(gb);\n\n\n\n        if (ctx->scalability) {\n\n            GetBitContext bak = *gb;\n\n            int h_sampling_factor_n;\n\n            int h_sampling_factor_m;\n\n            int v_sampling_factor_n;\n\n            int v_sampling_factor_m;\n\n\n\n            skip_bits1(gb);    // hierarchy_type\n\n            skip_bits(gb, 4);  /* ref_layer_id */\n\n            skip_bits1(gb);    /* ref_layer_sampling_dir */\n\n            h_sampling_factor_n = get_bits(gb, 5);\n\n            h_sampling_factor_m = get_bits(gb, 5);\n\n            v_sampling_factor_n = get_bits(gb, 5);\n\n            v_sampling_factor_m = get_bits(gb, 5);\n\n            ctx->enhancement_type = get_bits1(gb);\n\n\n\n            if (h_sampling_factor_n == 0 || h_sampling_factor_m == 0 ||\n\n                v_sampling_factor_n == 0 || v_sampling_factor_m == 0) {\n\n                /* illegal scalability header (VERY broken encoder),\n\n                 * trying to workaround */\n\n                ctx->scalability = 0;\n\n                *gb            = bak;\n\n            } else\n\n                av_log(s->avctx, AV_LOG_ERROR, \"scalability not supported\\n\");\n\n\n\n            // bin shape stuff FIXME\n\n        }\n\n    }\n\n\n\n    if (s->avctx->debug&FF_DEBUG_PICT_INFO) {\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"tb %d/%d, tincrbits:%d, qp_prec:%d, ps:%d,  %s%s%s%s\\n\",\n\n               s->avctx->framerate.den, s->avctx->framerate.num,\n\n               ctx->time_increment_bits,\n\n               s->quant_precision,\n\n               s->progressive_sequence,\n\n               ctx->scalability ? \"scalability \" :\"\" , s->quarter_sample ? \"qpel \" : \"\",\n\n               s->data_partitioning ? \"partition \" : \"\", ctx->rvlc ? \"rvlc \" : \"\"\n\n        );\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26821}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static int mmap_read_frame(AVFormatContext *ctx, AVPacket *pkt)\n\n{\n\n    struct video_data *s = ctx->priv_data;\n\n    struct v4l2_buffer buf = {\n\n        .type   = V4L2_BUF_TYPE_VIDEO_CAPTURE,\n\n        .memory = V4L2_MEMORY_MMAP\n\n    };\n\n    struct pollfd p = { .fd = s->fd, .events = POLLIN };\n\n    int res;\n\n\n\n    res = poll(&p, 1, s->timeout);\n\n    if (res < 0)\n\n        return AVERROR(errno);\n\n\n\n    if (!(p.revents & (POLLIN | POLLERR | POLLHUP)))\n\n        return AVERROR(EAGAIN);\n\n\n\n    /* FIXME: Some special treatment might be needed in case of loss of signal... */\n\n    while ((res = ioctl(s->fd, VIDIOC_DQBUF, &buf)) < 0 && (errno == EINTR));\n\n    if (res < 0) {\n\n        if (errno == EAGAIN) {\n\n            pkt->size = 0;\n\n\n\n            return AVERROR(EAGAIN);\n\n        }\n\n        av_log(ctx, AV_LOG_ERROR, \"ioctl(VIDIOC_DQBUF): %s\\n\",\n\n               strerror(errno));\n\n\n\n        return AVERROR(errno);\n\n    }\n\n\n\n    if (buf.index >= s->buffers) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Invalid buffer index received.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    avpriv_atomic_int_add_and_fetch(&s->buffers_queued, -1);\n\n    // always keep at least one buffer queued\n\n    av_assert0(avpriv_atomic_int_get(&s->buffers_queued) >= 1);\n\n\n\n    if (s->frame_size > 0 && buf.bytesused != s->frame_size) {\n\n        av_log(ctx, AV_LOG_ERROR,\n\n               \"The v4l2 frame is %d bytes, but %d bytes are expected\\n\",\n\n               buf.bytesused, s->frame_size);\n\n\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* Image is at s->buff_start[buf.index] */\n\n    if (avpriv_atomic_int_get(&s->buffers_queued) == FFMAX(s->buffers / 8, 1)) {\n\n        /* when we start getting low on queued buffers, fall back on copying data */\n\n        res = av_new_packet(pkt, buf.bytesused);\n\n        if (res < 0) {\n\n            av_log(ctx, AV_LOG_ERROR, \"Error allocating a packet.\\n\");\n\n            return res;\n\n        }\n\n        memcpy(pkt->data, s->buf_start[buf.index], buf.bytesused);\n\n\n\n        res = ioctl(s->fd, VIDIOC_QBUF, &buf);\n\n        if (res < 0) {\n\n            av_log(ctx, AV_LOG_ERROR, \"ioctl(VIDIOC_QBUF)\\n\");\n\n            av_free_packet(pkt);\n\n            return AVERROR(errno);\n\n        }\n\n        avpriv_atomic_int_add_and_fetch(&s->buffers_queued, 1);\n\n    } else {\n\n        struct buff_data *buf_descriptor;\n\n\n\n        pkt->data     = s->buf_start[buf.index];\n\n        pkt->size     = buf.bytesused;\n\n#if FF_API_DESTRUCT_PACKET\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n        pkt->destruct = dummy_release_buffer;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n\n\n        buf_descriptor = av_malloc(sizeof(struct buff_data));\n\n        if (buf_descriptor == NULL) {\n\n            /* Something went wrong... Since av_malloc() failed, we cannot even\n\n             * allocate a buffer for memcpying into it\n\n             */\n\n            av_log(ctx, AV_LOG_ERROR, \"Failed to allocate a buffer descriptor\\n\");\n\n            res = ioctl(s->fd, VIDIOC_QBUF, &buf);\n\n\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        buf_descriptor->fd    = s->fd;\n\n        buf_descriptor->index = buf.index;\n\n        buf_descriptor->s     = s;\n\n\n\n        pkt->buf = av_buffer_create(pkt->data, pkt->size, mmap_release_buffer,\n\n                                    buf_descriptor, 0);\n\n        if (!pkt->buf) {\n\n            av_freep(&buf_descriptor);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n    }\n\n    pkt->pts = buf.timestamp.tv_sec * INT64_C(1000000) + buf.timestamp.tv_usec;\n\n\n\n    return s->buf_len[buf.index];\n\n}\n", "idx": 26822}
{"project": "FFmpeg", "commit_id": "48d20c11ba8141337e2bbc6a779a29142390556e", "target": 1, "func": "static int aac_encode_frame(AVCodecContext *avctx,\n\n                            uint8_t *frame, int buf_size, void *data)\n\n{\n\n    AACEncContext *s = avctx->priv_data;\n\n    int16_t *samples = s->samples, *samples2, *la;\n\n    ChannelElement *cpe;\n\n    int i, j, chans, tag, start_ch;\n\n    const uint8_t *chan_map = aac_chan_configs[avctx->channels-1];\n\n    int chan_el_counter[4];\n\n    FFPsyWindowInfo windows[avctx->channels];\n\n\n\n    if (s->last_frame)\n\n        return 0;\n\n    if (data) {\n\n        if (!s->psypp) {\n\n            memcpy(s->samples + 1024 * avctx->channels, data,\n\n                   1024 * avctx->channels * sizeof(s->samples[0]));\n\n        } else {\n\n            start_ch = 0;\n\n            samples2 = s->samples + 1024 * avctx->channels;\n\n            for (i = 0; i < chan_map[0]; i++) {\n\n                tag = chan_map[i+1];\n\n                chans = tag == TYPE_CPE ? 2 : 1;\n\n                ff_psy_preprocess(s->psypp, (uint16_t*)data + start_ch,\n\n                                  samples2 + start_ch, start_ch, chans);\n\n                start_ch += chans;\n\n            }\n\n        }\n\n    }\n\n    if (!avctx->frame_number) {\n\n        memcpy(s->samples, s->samples + 1024 * avctx->channels,\n\n               1024 * avctx->channels * sizeof(s->samples[0]));\n\n        return 0;\n\n    }\n\n\n\n    start_ch = 0;\n\n    for (i = 0; i < chan_map[0]; i++) {\n\n        FFPsyWindowInfo* wi = windows + start_ch;\n\n        tag      = chan_map[i+1];\n\n        chans    = tag == TYPE_CPE ? 2 : 1;\n\n        cpe      = &s->cpe[i];\n\n        samples2 = samples + start_ch;\n\n        la       = samples2 + 1024 * avctx->channels + start_ch;\n\n        if (!data)\n\n            la = NULL;\n\n        for (j = 0; j < chans; j++) {\n\n            IndividualChannelStream *ics = &cpe->ch[j].ics;\n\n            int k;\n\n            wi[j] = ff_psy_suggest_window(&s->psy, samples2, la, start_ch + j, ics->window_sequence[0]);\n\n            ics->window_sequence[1] = ics->window_sequence[0];\n\n            ics->window_sequence[0] = wi[j].window_type[0];\n\n            ics->use_kb_window[1]   = ics->use_kb_window[0];\n\n            ics->use_kb_window[0]   = wi[j].window_shape;\n\n            ics->num_windows        = wi[j].num_windows;\n\n            ics->swb_sizes          = s->psy.bands    [ics->num_windows == 8];\n\n            ics->num_swb            = s->psy.num_bands[ics->num_windows == 8];\n\n            for (k = 0; k < ics->num_windows; k++)\n\n                ics->group_len[k] = wi[j].grouping[k];\n\n\n\n            s->cur_channel = start_ch + j;\n\n            apply_window_and_mdct(avctx, s, &cpe->ch[j], samples2, j);\n\n        }\n\n        start_ch += chans;\n\n    }\n\n    init_put_bits(&s->pb, frame, buf_size*8);\n\n    if ((avctx->frame_number & 0xFF)==1 && !(avctx->flags & CODEC_FLAG_BITEXACT))\n\n        put_bitstream_info(avctx, s, LIBAVCODEC_IDENT);\n\n    start_ch = 0;\n\n    memset(chan_el_counter, 0, sizeof(chan_el_counter));\n\n    for (i = 0; i < chan_map[0]; i++) {\n\n        FFPsyWindowInfo* wi = windows + start_ch;\n\n        tag      = chan_map[i+1];\n\n        chans    = tag == TYPE_CPE ? 2 : 1;\n\n        cpe      = &s->cpe[i];\n\n        for (j = 0; j < chans; j++) {\n\n            s->coder->search_for_quantizers(avctx, s, &cpe->ch[j], s->lambda);\n\n        }\n\n        cpe->common_window = 0;\n\n        if (chans > 1\n\n            && wi[0].window_type[0] == wi[1].window_type[0]\n\n            && wi[0].window_shape   == wi[1].window_shape) {\n\n\n\n            cpe->common_window = 1;\n\n            for (j = 0; j < wi[0].num_windows; j++) {\n\n                if (wi[0].grouping[j] != wi[1].grouping[j]) {\n\n                    cpe->common_window = 0;\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n        if (cpe->common_window && s->coder->search_for_ms)\n\n            s->coder->search_for_ms(s, cpe, s->lambda);\n\n        adjust_frame_information(s, cpe, chans);\n\n        put_bits(&s->pb, 3, tag);\n\n        put_bits(&s->pb, 4, chan_el_counter[tag]++);\n\n        if (chans == 2) {\n\n            put_bits(&s->pb, 1, cpe->common_window);\n\n            if (cpe->common_window) {\n\n                put_ics_info(s, &cpe->ch[0].ics);\n\n                encode_ms_info(&s->pb, cpe);\n\n            }\n\n        }\n\n        for (j = 0; j < chans; j++) {\n\n            s->cur_channel = start_ch + j;\n\n            ff_psy_set_band_info(&s->psy, s->cur_channel, cpe->ch[j].coeffs, &wi[j]);\n\n            encode_individual_channel(avctx, s, &cpe->ch[j], cpe->common_window);\n\n        }\n\n        start_ch += chans;\n\n    }\n\n\n\n    put_bits(&s->pb, 3, TYPE_END);\n\n    flush_put_bits(&s->pb);\n\n    avctx->frame_bits = put_bits_count(&s->pb);\n\n\n\n    // rate control stuff\n\n    if (!(avctx->flags & CODEC_FLAG_QSCALE)) {\n\n        float ratio = avctx->bit_rate * 1024.0f / avctx->sample_rate / avctx->frame_bits;\n\n        s->lambda *= ratio;\n\n        s->lambda = fminf(s->lambda, 65536.f);\n\n    }\n\n\n\n    if (avctx->frame_bits > 6144*avctx->channels)\n\n        av_log(avctx, AV_LOG_ERROR, \"input buffer violation %d > %d.\\n\",\n\n               avctx->frame_bits, 6144*avctx->channels);\n\n\n\n    if (!data)\n\n        s->last_frame = 1;\n\n    memcpy(s->samples, s->samples + 1024 * avctx->channels,\n\n           1024 * avctx->channels * sizeof(s->samples[0]));\n\n    return put_bits_count(&s->pb)>>3;\n\n}\n", "idx": 26824}
{"project": "FFmpeg", "commit_id": "f26c2ef53b68f4e7e0f8e4eac8466b4fdeffb8b1", "target": 0, "func": "static int vc1_decode_intra_block(VC1Context *v, DCTELEM block[64], int n, int coded, int mquant, int codingset)\n\n{\n\n    GetBitContext *gb = &v->s.gb;\n\n    MpegEncContext *s = &v->s;\n\n    int dc_pred_dir = 0; /* Direction of the DC prediction used */\n\n    int run_diff, i;\n\n    int16_t *dc_val;\n\n    int16_t *ac_val, *ac_val2;\n\n    int dcdiff;\n\n    int mb_pos = s->mb_x + s->mb_y * s->mb_stride;\n\n    int a_avail, c_avail;\n\n\n\n    /* XXX: Guard against dumb values of mquant */\n\n    mquant = (mquant < 1) ? 0 : ( (mquant>31) ? 31 : mquant );\n\n\n\n    /* Set DC scale - y and c use the same */\n\n    s->y_dc_scale = s->y_dc_scale_table[mquant];\n\n    s->c_dc_scale = s->c_dc_scale_table[mquant];\n\n\n\n    /* check if prediction blocks A and C are available */\n\n    a_avail = c_avail = 0;\n\n    if((n == 2 || n == 3) || (s->mb_y && IS_INTRA(s->current_picture.mb_type[mb_pos - s->mb_stride])))\n\n        a_avail = 1;\n\n    if((n == 1 || n == 3) || (s->mb_x && IS_INTRA(s->current_picture.mb_type[mb_pos - 1])))\n\n        c_avail = 1;\n\n    /* Get DC differential */\n\n    if (n < 4) {\n\n        dcdiff = get_vlc2(&s->gb, ff_msmp4_dc_luma_vlc[s->dc_table_index].table, DC_VLC_BITS, 3);\n\n    } else {\n\n        dcdiff = get_vlc2(&s->gb, ff_msmp4_dc_chroma_vlc[s->dc_table_index].table, DC_VLC_BITS, 3);\n\n    }\n\n    if (dcdiff < 0){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Illegal DC VLC\\n\");\n\n        return -1;\n\n    }\n\n    if (dcdiff)\n\n    {\n\n        if (dcdiff == 119 /* ESC index value */)\n\n        {\n\n            /* TODO: Optimize */\n\n            if (mquant == 1) dcdiff = get_bits(gb, 10);\n\n            else if (mquant == 2) dcdiff = get_bits(gb, 9);\n\n            else dcdiff = get_bits(gb, 8);\n\n        }\n\n        else\n\n        {\n\n            if (mquant == 1)\n\n                dcdiff = (dcdiff<<2) + get_bits(gb, 2) - 3;\n\n            else if (mquant == 2)\n\n                dcdiff = (dcdiff<<1) + get_bits(gb, 1) - 1;\n\n        }\n\n        if (get_bits(gb, 1))\n\n            dcdiff = -dcdiff;\n\n    }\n\n\n\n    /* Prediction */\n\n    dcdiff += vc1_pred_dc(&v->s, v->overlap, mquant, n, a_avail, c_avail, &dc_val, &dc_pred_dir);\n\n    *dc_val = dcdiff;\n\n\n\n    /* Store the quantized DC coeff, used for prediction */\n\n\n\n    if (n < 4) {\n\n        block[0] = dcdiff * s->y_dc_scale;\n\n    } else {\n\n        block[0] = dcdiff * s->c_dc_scale;\n\n    }\n\n    /* Skip ? */\n\n    run_diff = 0;\n\n    i = 0;\n\n    if (!coded) {\n\n        goto not_coded;\n\n    }\n\n\n\n    //AC Decoding\n\n    i = 1;\n\n\n\n    {\n\n        int last = 0, skip, value;\n\n        const int8_t *zz_table;\n\n        int scale;\n\n        int k;\n\n\n\n        scale = mquant * 2 + v->halfpq;\n\n\n\n        zz_table = vc1_simple_progressive_8x8_zz;\n\n\n\n        ac_val = s->ac_val[0][0] + s->block_index[n] * 16;\n\n        ac_val2 = ac_val;\n\n        if(dc_pred_dir) //left\n\n            ac_val -= 16;\n\n        else //top\n\n            ac_val -= 16 * s->block_wrap[n];\n\n\n\n        while (!last) {\n\n            vc1_decode_ac_coeff(v, &last, &skip, &value, codingset);\n\n            i += skip;\n\n            if(i > 63)\n\n                break;\n\n            block[zz_table[i++]] = value;\n\n        }\n\n\n\n        /* apply AC prediction if needed */\n\n        if(s->ac_pred) {\n\n            /* scale predictors if needed*/\n\n            int mb_pos2, q1, q2;\n\n\n\n            mb_pos2 = mb_pos - dc_pred_dir - (1 - dc_pred_dir) * s->mb_stride;\n\n            q1 = s->current_picture.qscale_table[mb_pos];\n\n            q2 = s->current_picture.qscale_table[mb_pos2];\n\n\n\n            if(!c_avail) {\n\n                memset(ac_val, 0, 8 * sizeof(ac_val[0]));\n\n                dc_pred_dir = 0;\n\n            }\n\n            if(!a_avail) {\n\n                memset(ac_val + 8, 0, 8 * sizeof(ac_val[0]));\n\n                dc_pred_dir = 1;\n\n            }\n\n            if(!q1 && q1 && q2 && q1 != q2) {\n\n                q1 = q1 * 2 - 1;\n\n                q2 = q2 * 2 - 1;\n\n\n\n                if(dc_pred_dir) { //left\n\n                    for(k = 1; k < 8; k++)\n\n                        block[k << 3] += (ac_val[k] * q2 * vc1_dqscale[q1 - 1] + 0x20000) >> 18;\n\n                } else { //top\n\n                    for(k = 1; k < 8; k++)\n\n                        block[k] += (ac_val[k + 8] * q2 * vc1_dqscale[q1 - 1] + 0x20000) >> 18;\n\n                }\n\n            } else {\n\n                if(dc_pred_dir) { //left\n\n                    for(k = 1; k < 8; k++)\n\n                        block[k << 3] += ac_val[k];\n\n                } else { //top\n\n                    for(k = 1; k < 8; k++)\n\n                        block[k] += ac_val[k + 8];\n\n                }\n\n            }\n\n        }\n\n        /* save AC coeffs for further prediction */\n\n        for(k = 1; k < 8; k++) {\n\n            ac_val2[k] = block[k << 3];\n\n            ac_val2[k + 8] = block[k];\n\n        }\n\n\n\n        /* scale AC coeffs */\n\n        for(k = 1; k < 64; k++)\n\n            if(block[k]) {\n\n                block[k] *= scale;\n\n                if(!v->pquantizer)\n\n                    block[k] += (block[k] < 0) ? -mquant : mquant;\n\n            }\n\n\n\n        if(s->ac_pred) i = 63;\n\n    }\n\n\n\nnot_coded:\n\n    if(!coded) {\n\n        int k, scale;\n\n        ac_val = s->ac_val[0][0] + s->block_index[n] * 16;\n\n        ac_val2 = ac_val;\n\n\n\n        if(!c_avail) {\n\n            memset(ac_val, 0, 8 * sizeof(ac_val[0]));\n\n            dc_pred_dir = 0;\n\n        }\n\n        if(!a_avail) {\n\n            memset(ac_val + 8, 0, 8 * sizeof(ac_val[0]));\n\n            dc_pred_dir = 1;\n\n        }\n\n\n\n        scale = mquant * 2 + v->halfpq;\n\n        memset(ac_val2, 0, 16 * 2);\n\n        if(dc_pred_dir) {//left\n\n            ac_val -= 16;\n\n            if(s->ac_pred)\n\n                memcpy(ac_val2, ac_val, 8 * 2);\n\n        } else {//top\n\n            ac_val -= 16 * s->block_wrap[n];\n\n            if(s->ac_pred)\n\n                memcpy(ac_val2 + 8, ac_val + 8, 8 * 2);\n\n        }\n\n\n\n        /* apply AC prediction if needed */\n\n        if(s->ac_pred) {\n\n            if(dc_pred_dir) { //left\n\n                for(k = 1; k < 8; k++) {\n\n                    block[k << 3] = ac_val[k] * scale;\n\n                    if(!v->pquantizer)\n\n                        block[k << 3] += (block[k << 3] < 0) ? -mquant : mquant;\n\n                }\n\n            } else { //top\n\n                for(k = 1; k < 8; k++) {\n\n                    block[k] = ac_val[k + 8] * scale;\n\n                    if(!v->pquantizer)\n\n                        block[k] += (block[k] < 0) ? -mquant : mquant;\n\n                }\n\n            }\n\n            i = 63;\n\n        }\n\n    }\n\n    s->block_last_index[n] = i;\n\n\n\n    return 0;\n\n}\n", "idx": 26825}
{"project": "FFmpeg", "commit_id": "892fc83e88a20f9543c6c5be3626712be7a2e6f2", "target": 0, "func": "static int vp3_decode_end(AVCodecContext *avctx)\n\n{\n\n    Vp3DecodeContext *s = avctx->priv_data;\n\n\n\n    av_free(s->all_fragments);\n\n    av_free(s->coded_fragment_list);\n\n    av_free(s->superblock_fragments);\n\n    av_free(s->superblock_macroblocks);\n\n    av_free(s->macroblock_fragments);\n\n    av_free(s->macroblock_coded);\n\n\n\n    /* release all frames */\n\n    avctx->release_buffer(avctx, &s->golden_frame);\n\n    avctx->release_buffer(avctx, &s->last_frame);\n\n    avctx->release_buffer(avctx, &s->current_frame);\n\n\n\n    return 0;\n\n}\n", "idx": 26826}
{"project": "FFmpeg", "commit_id": "5793a6d9f9b35723f4aaeba68630f63b45d915f8", "target": 1, "func": "SchroFrame *ff_create_schro_frame(AVCodecContext *avccontext,\n\n                                  SchroFrameFormat schro_frame_fmt)\n\n{\n\n    AVPicture *p_pic;\n\n    SchroFrame *p_frame;\n\n    int y_width, uv_width;\n\n    int y_height, uv_height;\n\n    int i;\n\n\n\n    y_width   = avccontext->width;\n\n    y_height  = avccontext->height;\n\n    uv_width  = y_width  >> (SCHRO_FRAME_FORMAT_H_SHIFT(schro_frame_fmt));\n\n    uv_height = y_height >> (SCHRO_FRAME_FORMAT_V_SHIFT(schro_frame_fmt));\n\n\n\n    p_pic = av_mallocz(sizeof(AVPicture));\n\n    avpicture_alloc(p_pic, avccontext->pix_fmt, y_width, y_height);\n\n\n\n    p_frame         = schro_frame_new();\n\n    p_frame->format = schro_frame_fmt;\n\n    p_frame->width  = y_width;\n\n    p_frame->height = y_height;\n\n    schro_frame_set_free_callback(p_frame, free_schro_frame, (void *)p_pic);\n\n\n\n    for (i = 0; i < 3; ++i) {\n\n        p_frame->components[i].width  = i ? uv_width : y_width;\n\n        p_frame->components[i].stride = p_pic->linesize[i];\n\n        p_frame->components[i].height = i ? uv_height : y_height;\n\n        p_frame->components[i].length =\n\n                 p_frame->components[i].stride * p_frame->components[i].height;\n\n        p_frame->components[i].data   = p_pic->data[i];\n\n\n\n        if (i) {\n\n            p_frame->components[i].v_shift =\n\n                SCHRO_FRAME_FORMAT_V_SHIFT(p_frame->format);\n\n            p_frame->components[i].h_shift =\n\n                SCHRO_FRAME_FORMAT_H_SHIFT(p_frame->format);\n\n        }\n\n    }\n\n\n\n    return p_frame;\n\n}\n", "idx": 26828}
{"project": "FFmpeg", "commit_id": "229843aa359ae0c9519977d7fa952688db63f559", "target": 0, "func": "static int ffm_seek(AVFormatContext *s, int stream_index, int64_t wanted_pts, int flags)\n\n{\n\n    FFMContext *ffm = s->priv_data;\n\n    int64_t pos_min, pos_max, pos;\n\n    int64_t pts_min, pts_max, pts;\n\n    double pos1;\n\n\n\n    av_dlog(s, \"wanted_pts=%0.6f\\n\", wanted_pts / 1000000.0);\n\n    /* find the position using linear interpolation (better than\n\n       dichotomy in typical cases) */\n\n    if (ffm->write_index && ffm->write_index < ffm->file_size) {\n\n        if (get_dts(s, FFM_PACKET_SIZE) < wanted_pts) {\n\n            pos_min = FFM_PACKET_SIZE;\n\n            pos_max = ffm->write_index - FFM_PACKET_SIZE;\n\n        } else {\n\n            pos_min = ffm->write_index;\n\n            pos_max = ffm->file_size - FFM_PACKET_SIZE;\n\n        }\n\n    } else {\n\n        pos_min = FFM_PACKET_SIZE;\n\n        pos_max = ffm->file_size - FFM_PACKET_SIZE;\n\n    }\n\n    while (pos_min <= pos_max) {\n\n        pts_min = get_dts(s, pos_min);\n\n        pts_max = get_dts(s, pos_max);\n\n        if (pts_min > wanted_pts || pts_max <= wanted_pts) {\n\n            pos = pts_min > wanted_pts ? pos_min : pos_max;\n\n            goto found;\n\n        }\n\n        /* linear interpolation */\n\n        pos1 = (double)(pos_max - pos_min) * (double)(wanted_pts - pts_min) /\n\n            (double)(pts_max - pts_min);\n\n        pos = (((int64_t)pos1) / FFM_PACKET_SIZE) * FFM_PACKET_SIZE;\n\n        if (pos <= pos_min)\n\n            pos = pos_min;\n\n        else if (pos >= pos_max)\n\n            pos = pos_max;\n\n        pts = get_dts(s, pos);\n\n        /* check if we are lucky */\n\n        if (pts == wanted_pts) {\n\n            goto found;\n\n        } else if (pts > wanted_pts) {\n\n            pos_max = pos - FFM_PACKET_SIZE;\n\n        } else {\n\n            pos_min = pos + FFM_PACKET_SIZE;\n\n        }\n\n    }\n\n    pos = (flags & AVSEEK_FLAG_BACKWARD) ? pos_min : pos_max;\n\n\n\n found:\n\n    if (ffm_seek1(s, pos) < 0)\n\n        return -1;\n\n\n\n    /* reset read state */\n\n    ffm->read_state = READ_HEADER;\n\n    ffm->packet_ptr = ffm->packet;\n\n    ffm->packet_end = ffm->packet;\n\n    ffm->first_packet = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 26829}
{"project": "FFmpeg", "commit_id": "90540c2d5ace46a1e9789c75fde0b1f7dbb12a9b", "target": 1, "func": "static inline void RENAME(rgb16tobgr24)(const uint8_t *src, uint8_t *dst, int src_size)\n\n{\n\n    const uint16_t *end;\n\n    const uint16_t *mm_end;\n\n    uint8_t *d = (uint8_t *)dst;\n\n    const uint16_t *s = (const uint16_t *)src;\n\n    end = s + src_size/2;\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*s):\"memory\");\n\n    mm_end = end - 7;\n\n    while (s < mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"    32%1           \\n\\t\"\n\n            \"movq          %1, %%mm0    \\n\\t\"\n\n            \"movq          %1, %%mm1    \\n\\t\"\n\n            \"movq          %1, %%mm2    \\n\\t\"\n\n            \"pand          %2, %%mm0    \\n\\t\"\n\n            \"pand          %3, %%mm1    \\n\\t\"\n\n            \"pand          %4, %%mm2    \\n\\t\"\n\n            \"psllq         $3, %%mm0    \\n\\t\"\n\n            \"psrlq         $3, %%mm1    \\n\\t\"\n\n            \"psrlq         $8, %%mm2    \\n\\t\"\n\n            \"movq       %%mm0, %%mm3    \\n\\t\"\n\n            \"movq       %%mm1, %%mm4    \\n\\t\"\n\n            \"movq       %%mm2, %%mm5    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm0    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm1    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm2    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm3    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm4    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm5    \\n\\t\"\n\n            \"psllq         $8, %%mm1    \\n\\t\"\n\n            \"psllq        $16, %%mm2    \\n\\t\"\n\n            \"por        %%mm1, %%mm0    \\n\\t\"\n\n            \"por        %%mm2, %%mm0    \\n\\t\"\n\n            \"psllq         $8, %%mm4    \\n\\t\"\n\n            \"psllq        $16, %%mm5    \\n\\t\"\n\n            \"por        %%mm4, %%mm3    \\n\\t\"\n\n            \"por        %%mm5, %%mm3    \\n\\t\"\n\n\n\n            \"movq       %%mm0, %%mm6    \\n\\t\"\n\n            \"movq       %%mm3, %%mm7    \\n\\t\"\n\n\n\n            \"movq         8%1, %%mm0    \\n\\t\"\n\n            \"movq         8%1, %%mm1    \\n\\t\"\n\n            \"movq         8%1, %%mm2    \\n\\t\"\n\n            \"pand          %2, %%mm0    \\n\\t\"\n\n            \"pand          %3, %%mm1    \\n\\t\"\n\n            \"pand          %4, %%mm2    \\n\\t\"\n\n            \"psllq         $3, %%mm0    \\n\\t\"\n\n            \"psrlq         $3, %%mm1    \\n\\t\"\n\n            \"psrlq         $8, %%mm2    \\n\\t\"\n\n            \"movq       %%mm0, %%mm3    \\n\\t\"\n\n            \"movq       %%mm1, %%mm4    \\n\\t\"\n\n            \"movq       %%mm2, %%mm5    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm0    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm1    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm2    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm3    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm4    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm5    \\n\\t\"\n\n            \"psllq         $8, %%mm1    \\n\\t\"\n\n            \"psllq        $16, %%mm2    \\n\\t\"\n\n            \"por        %%mm1, %%mm0    \\n\\t\"\n\n            \"por        %%mm2, %%mm0    \\n\\t\"\n\n            \"psllq         $8, %%mm4    \\n\\t\"\n\n            \"psllq        $16, %%mm5    \\n\\t\"\n\n            \"por        %%mm4, %%mm3    \\n\\t\"\n\n            \"por        %%mm5, %%mm3    \\n\\t\"\n\n            :\"=m\"(*d)\n\n            :\"m\"(*s),\"m\"(mask16b),\"m\"(mask16g),\"m\"(mask16r),\"m\"(mmx_null)\n\n            :\"memory\");\n\n        /* borrowed 32 to 24 */\n\n        __asm__ volatile(\n\n            \"movq       %%mm0, %%mm4    \\n\\t\"\n\n            \"movq       %%mm3, %%mm5    \\n\\t\"\n\n            \"movq       %%mm6, %%mm0    \\n\\t\"\n\n            \"movq       %%mm7, %%mm1    \\n\\t\"\n\n\n\n            \"movq       %%mm4, %%mm6    \\n\\t\"\n\n            \"movq       %%mm5, %%mm7    \\n\\t\"\n\n            \"movq       %%mm0, %%mm2    \\n\\t\"\n\n            \"movq       %%mm1, %%mm3    \\n\\t\"\n\n\n\n            STORE_BGR24_MMX\n\n\n\n            :\"=m\"(*d)\n\n            :\"m\"(*s)\n\n            :\"memory\");\n\n        d += 24;\n\n        s += 8;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n    while (s < end) {\n\n        register uint16_t bgr;\n\n        bgr = *s++;\n\n        *d++ = (bgr&0x1F)<<3;\n\n        *d++ = (bgr&0x7E0)>>3;\n\n        *d++ = (bgr&0xF800)>>8;\n\n    }\n\n}\n", "idx": 26832}
{"project": "FFmpeg", "commit_id": "de6df46120367b7d49d9d7c0971cbe36368b840a", "target": 1, "func": "int ff_h264_field_end(H264Context *h, int in_setup)\n{\n    AVCodecContext *const avctx = h->avctx;\n    int err = 0;\n    h->mb_y = 0;\n    if (CONFIG_H264_VDPAU_DECODER &&\n        h->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU)\n        ff_vdpau_h264_set_reference_frames(h);\n    if (in_setup || !(avctx->active_thread_type & FF_THREAD_FRAME)) {\n        if (!h->droppable) {\n            err = ff_h264_execute_ref_pic_marking(h, h->mmco, h->mmco_index);\n            h->prev_poc_msb = h->poc_msb;\n            h->prev_poc_lsb = h->poc_lsb;\n        }\n        h->prev_frame_num_offset = h->frame_num_offset;\n        h->prev_frame_num        = h->frame_num;\n        h->outputed_poc          = h->next_outputed_poc;\n    }\n    if (avctx->hwaccel) {\n        if (avctx->hwaccel->end_frame(avctx) < 0)\n            av_log(avctx, AV_LOG_ERROR,\n                   \"hardware accelerator failed to decode picture\\n\");\n    }\n    if (CONFIG_H264_VDPAU_DECODER &&\n        h->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU)\n        ff_vdpau_h264_picture_complete(h);\n#if CONFIG_ERROR_RESILIENCE\n    /*\n     * FIXME: Error handling code does not seem to support interlaced\n     * when slices span multiple rows\n     * The ff_er_add_slice calls don't work right for bottom\n     * fields; they cause massive erroneous error concealing\n     * Error marking covers both fields (top and bottom).\n     * This causes a mismatched s->error_count\n     * and a bad error table. Further, the error count goes to\n     * INT_MAX when called for bottom field, because mb_y is\n     * past end by one (callers fault) and resync_mb_y != 0\n     * causes problems for the first MB line, too.\n     */\n    if (!FIELD_PICTURE(h) && h->current_slice && !h->sps.new) {\n        ff_h264_set_erpic(&h->er.cur_pic, h->cur_pic_ptr);\n        ff_er_frame_end(&h->er);\n    }\n#endif /* CONFIG_ERROR_RESILIENCE */\n    if (!in_setup && !h->droppable)\n        ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n                                  h->picture_structure == PICT_BOTTOM_FIELD);\n    emms_c();\n    h->current_slice = 0;\n    return err;\n}", "idx": 26836}
{"project": "FFmpeg", "commit_id": "88d1e2b2b0a129365a62efd666db0394e8ffbe08", "target": 1, "func": "double av_int2dbl(int64_t v){\n\n    if(v+v > 0xFFEULL<<52)\n\n        return NAN;\n\n    return ldexp(((v&((1LL<<52)-1)) + (1LL<<52)) * (v>>63|1), (v>>52&0x7FF)-1075);\n\n}\n", "idx": 26837}
{"project": "FFmpeg", "commit_id": "fecb3e82a4ba09dc11a51ad0961ab491881a53a1", "target": 1, "func": "static inline int mxf_read_utf16_string(AVIOContext *pb, int size, char** str, int be)\n\n{\n\n    int ret;\n\n    size_t buf_size;\n\n\n\n    if (size < 0)\n\n        return AVERROR(EINVAL);\n\n\n\n    buf_size = size + size / 2 + 1;\n\n    *str = av_malloc(buf_size);\n\n    if (!*str)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if (be)\n\n        ret = avio_get_str16be(pb, size, *str, buf_size);\n\n    else\n\n        ret = avio_get_str16le(pb, size, *str, buf_size);\n\n\n\n    if (ret < 0) {\n\n        av_freep(str);\n\n        return ret;\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 26838}
{"project": "FFmpeg", "commit_id": "d14a26edb7c4487df581f11e5c6911dc0e623d08", "target": 1, "func": "static void synth_block_fcb_acb(WMAVoiceContext *s, GetBitContext *gb,\n\n                                int block_idx, int size,\n\n                                int block_pitch_sh2,\n\n                                const struct frame_type_desc *frame_desc,\n\n                                float *excitation)\n\n{\n\n    static const float gain_coeff[6] = {\n\n        0.8169, -0.06545, 0.1726, 0.0185, -0.0359, 0.0458\n\n    };\n\n    float pulses[MAX_FRAMESIZE / 2], pred_err, acb_gain, fcb_gain;\n\n    int n, idx, gain_weight;\n\n    AMRFixed fcb;\n\n\n\n    assert(size <= MAX_FRAMESIZE / 2);\n\n    memset(pulses, 0, sizeof(*pulses) * size);\n\n\n\n    fcb.pitch_lag      = block_pitch_sh2 >> 2;\n\n    fcb.pitch_fac      = 1.0;\n\n    fcb.no_repeat_mask = 0;\n\n    fcb.n              = 0;\n\n\n\n    /* For the other frame types, this is where we apply the innovation\n\n     * (fixed) codebook pulses of the speech signal. */\n\n    if (frame_desc->fcb_type == FCB_TYPE_AW_PULSES) {\n\n        aw_pulse_set1(s, gb, block_idx, &fcb);\n\n        aw_pulse_set2(s, gb, block_idx, &fcb);\n\n    } else /* FCB_TYPE_EXC_PULSES */ {\n\n        int offset_nbits = 5 - frame_desc->log_n_blocks;\n\n\n\n        fcb.no_repeat_mask = -1;\n\n        /* similar to ff_decode_10_pulses_35bits(), but with single pulses\n\n         * (instead of double) for a subset of pulses */\n\n        for (n = 0; n < 5; n++) {\n\n            float sign;\n\n            int pos1, pos2;\n\n\n\n            sign           = get_bits1(gb) ? 1.0 : -1.0;\n\n            pos1           = get_bits(gb, offset_nbits);\n\n            fcb.x[fcb.n]   = n + 5 * pos1;\n\n            fcb.y[fcb.n++] = sign;\n\n            if (n < frame_desc->dbl_pulses) {\n\n                pos2           = get_bits(gb, offset_nbits);\n\n                fcb.x[fcb.n]   = n + 5 * pos2;\n\n                fcb.y[fcb.n++] = (pos1 < pos2) ? -sign : sign;\n\n            }\n\n        }\n\n    }\n\n    ff_set_fixed_vector(pulses, &fcb, 1.0, size);\n\n\n\n    /* Calculate gain for adaptive & fixed codebook signal.\n\n     * see ff_amr_set_fixed_gain(). */\n\n    idx = get_bits(gb, 7);\n\n    fcb_gain = expf(avpriv_scalarproduct_float_c(s->gain_pred_err,\n\n                                                 gain_coeff, 6) -\n\n                    5.2409161640 + wmavoice_gain_codebook_fcb[idx]);\n\n    acb_gain = wmavoice_gain_codebook_acb[idx];\n\n    pred_err = av_clipf(wmavoice_gain_codebook_fcb[idx],\n\n                        -2.9957322736 /* log(0.05) */,\n\n                         1.6094379124 /* log(5.0)  */);\n\n\n\n    gain_weight = 8 >> frame_desc->log_n_blocks;\n\n    memmove(&s->gain_pred_err[gain_weight], s->gain_pred_err,\n\n            sizeof(*s->gain_pred_err) * (6 - gain_weight));\n\n    for (n = 0; n < gain_weight; n++)\n\n        s->gain_pred_err[n] = pred_err;\n\n\n\n    /* Calculation of adaptive codebook */\n\n    if (frame_desc->acb_type == ACB_TYPE_ASYMMETRIC) {\n\n        int len;\n\n        for (n = 0; n < size; n += len) {\n\n            int next_idx_sh16;\n\n            int abs_idx    = block_idx * size + n;\n\n            int pitch_sh16 = (s->last_pitch_val << 16) +\n\n                             s->pitch_diff_sh16 * abs_idx;\n\n            int pitch      = (pitch_sh16 + 0x6FFF) >> 16;\n\n            int idx_sh16   = ((pitch << 16) - pitch_sh16) * 8 + 0x58000;\n\n            idx            = idx_sh16 >> 16;\n\n            if (s->pitch_diff_sh16) {\n\n                if (s->pitch_diff_sh16 > 0) {\n\n                    next_idx_sh16 = (idx_sh16) &~ 0xFFFF;\n\n                } else\n\n                    next_idx_sh16 = (idx_sh16 + 0x10000) &~ 0xFFFF;\n\n                len = av_clip((idx_sh16 - next_idx_sh16) / s->pitch_diff_sh16 / 8,\n\n                              1, size - n);\n\n            } else\n\n                len = size;\n\n\n\n            ff_acelp_interpolatef(&excitation[n], &excitation[n - pitch],\n\n                                  wmavoice_ipol1_coeffs, 17,\n\n                                  idx, 9, len);\n\n        }\n\n    } else /* ACB_TYPE_HAMMING */ {\n\n        int block_pitch = block_pitch_sh2 >> 2;\n\n        idx             = block_pitch_sh2 & 3;\n\n        if (idx) {\n\n            ff_acelp_interpolatef(excitation, &excitation[-block_pitch],\n\n                                  wmavoice_ipol2_coeffs, 4,\n\n                                  idx, 8, size);\n\n        } else\n\n            av_memcpy_backptr((uint8_t *) excitation, sizeof(float) * block_pitch,\n\n                              sizeof(float) * size);\n\n    }\n\n\n\n    /* Interpolate ACB/FCB and use as excitation signal */\n\n    ff_weighted_vector_sumf(excitation, excitation, pulses,\n\n                            acb_gain, fcb_gain, size);\n\n}\n", "idx": 26839}
{"project": "FFmpeg", "commit_id": "6ba5cbc699e77cae66bb719354fa142114b64eab", "target": 0, "func": "void url_split(char *proto, int proto_size,\n\n               char *hostname, int hostname_size,\n\n               int *port_ptr,\n\n               char *path, int path_size,\n\n               const char *url)\n\n{\n\n    const char *p;\n\n    char *q;\n\n    int port;\n\n\n\n    port = -1;\n\n\n\n    p = url;\n\n    q = proto;\n\n    while (*p != ':' && *p != '\\0') {\n\n        if ((q - proto) < proto_size - 1)\n\n            *q++ = *p;\n\n        p++;\n\n    }\n\n    if (proto_size > 0)\n\n        *q = '\\0';\n\n    if (*p == '\\0') {\n\n        if (proto_size > 0)\n\n            proto[0] = '\\0';\n\n        if (hostname_size > 0)\n\n            hostname[0] = '\\0';\n\n        p = url;\n\n    } else {\n\n        p++;\n\n        if (*p == '/')\n\n            p++;\n\n        if (*p == '/')\n\n            p++;\n\n        q = hostname;\n\n        while (*p != ':' && *p != '/' && *p != '?' && *p != '\\0') {\n\n            if ((q - hostname) < hostname_size - 1)\n\n                *q++ = *p;\n\n            p++;\n\n        }\n\n        if (hostname_size > 0)\n\n            *q = '\\0';\n\n        if (*p == ':') {\n\n            p++;\n\n            port = strtoul(p, (char **)&p, 10);\n\n        }\n\n    }\n\n    if (port_ptr)\n\n        *port_ptr = port;\n\n    pstrcpy(path, path_size, p);\n\n}\n", "idx": 26842}
{"project": "FFmpeg", "commit_id": "274aa1d02f12aba969b280139cf79907134dcd89", "target": 0, "func": "static unsigned long iv_decode_frame(Indeo3DecodeContext *s,\n\n                                     const uint8_t *buf, int buf_size)\n\n{\n\n    unsigned int image_width, image_height,\n\n                 chroma_width, chroma_height;\n\n    unsigned long flags, cb_offset, data_size,\n\n                  y_offset, v_offset, u_offset, mc_vector_count;\n\n    const uint8_t *hdr_pos, *buf_pos;\n\n\n\n    buf_pos = buf;\n\n    buf_pos += 18; /* skip OS header (16 bytes) and version number */\n\n\n\n    flags = bytestream_get_le16(&buf_pos);\n\n    data_size = bytestream_get_le32(&buf_pos);\n\n    cb_offset = *buf_pos++;\n\n    buf_pos += 3; /* skip reserved byte and checksum */\n\n    image_height = bytestream_get_le16(&buf_pos);\n\n    image_width  = bytestream_get_le16(&buf_pos);\n\n\n\n    if(avcodec_check_dimensions(NULL, image_width, image_height))\n\n        return -1;\n\n\n\n    chroma_height = ((image_height >> 2) + 3) & 0x7ffc;\n\n    chroma_width = ((image_width >> 2) + 3) & 0x7ffc;\n\n    y_offset = bytestream_get_le32(&buf_pos);\n\n    v_offset = bytestream_get_le32(&buf_pos);\n\n    u_offset = bytestream_get_le32(&buf_pos);\n\n    buf_pos += 4; /* reserved */\n\n    hdr_pos = buf_pos;\n\n    if(data_size == 0x80) return 4;\n\n\n\n    if(flags & 0x200) {\n\n        s->cur_frame = s->iv_frame + 1;\n\n        s->ref_frame = s->iv_frame;\n\n    } else {\n\n        s->cur_frame = s->iv_frame;\n\n        s->ref_frame = s->iv_frame + 1;\n\n    }\n\n\n\n    buf_pos = buf + 16 + y_offset;\n\n    mc_vector_count = bytestream_get_le32(&buf_pos);\n\n\n\n    iv_Decode_Chunk(s, s->cur_frame->Ybuf, s->ref_frame->Ybuf, image_width,\n\n                    image_height, buf_pos + mc_vector_count * 2, cb_offset, hdr_pos, buf_pos,\n\n                    FFMIN(image_width, 160));\n\n\n\n    if (!(s->avctx->flags & CODEC_FLAG_GRAY))\n\n    {\n\n\n\n        buf_pos = buf + 16 + v_offset;\n\n        mc_vector_count = bytestream_get_le32(&buf_pos);\n\n\n\n        iv_Decode_Chunk(s, s->cur_frame->Vbuf, s->ref_frame->Vbuf, chroma_width,\n\n                chroma_height, buf_pos + mc_vector_count * 2, cb_offset, hdr_pos, buf_pos,\n\n                FFMIN(chroma_width, 40));\n\n\n\n        buf_pos = buf + 16 + u_offset;\n\n        mc_vector_count = bytestream_get_le32(&buf_pos);\n\n\n\n        iv_Decode_Chunk(s, s->cur_frame->Ubuf, s->ref_frame->Ubuf, chroma_width,\n\n                chroma_height, buf_pos + mc_vector_count * 2, cb_offset, hdr_pos, buf_pos,\n\n                FFMIN(chroma_width, 40));\n\n\n\n    }\n\n\n\n    return 8;\n\n}\n", "idx": 26843}
{"project": "FFmpeg", "commit_id": "c89658008705d949c319df3fa6f400c481ad73e1", "target": 0, "func": "static void rtsp_send_cmd_async (AVFormatContext *s,\n\n                          const char *cmd, RTSPMessageHeader *reply,\n\n                          unsigned char **content_ptr)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    char buf[4096], buf1[1024];\n\n\n\n    rt->seq++;\n\n    av_strlcpy(buf, cmd, sizeof(buf));\n\n    snprintf(buf1, sizeof(buf1), \"CSeq: %d\\r\\n\", rt->seq);\n\n    av_strlcat(buf, buf1, sizeof(buf));\n\n    if (rt->session_id[0] != '\\0' && !strstr(cmd, \"\\nIf-Match:\")) {\n\n        snprintf(buf1, sizeof(buf1), \"Session: %s\\r\\n\", rt->session_id);\n\n        av_strlcat(buf, buf1, sizeof(buf));\n\n    }\n\n    if (rt->auth_b64)\n\n        av_strlcatf(buf, sizeof(buf),\n\n                    \"Authorization: Basic %s\\r\\n\",\n\n                    rt->auth_b64);\n\n    av_strlcat(buf, \"\\r\\n\", sizeof(buf));\n\n\n\n    dprintf(s, \"Sending:\\n%s--\\n\", buf);\n\n\n\n    url_write(rt->rtsp_hd, buf, strlen(buf));\n\n    rt->last_cmd_time = av_gettime();\n\n}\n", "idx": 26844}
{"project": "FFmpeg", "commit_id": "f6fff8e54697ff4418283eb8aa9afd0d9e7e4736", "target": 1, "func": "static void apply_channel_coupling(AC3EncodeContext *s)\n\n{\n\n    LOCAL_ALIGNED_16(CoefType, cpl_coords,      [AC3_MAX_BLOCKS], [AC3_MAX_CHANNELS][16]);\n\n#if CONFIG_AC3ENC_FLOAT\n\n    LOCAL_ALIGNED_16(int32_t, fixed_cpl_coords, [AC3_MAX_BLOCKS], [AC3_MAX_CHANNELS][16]);\n\n#else\n\n    int32_t (*fixed_cpl_coords)[AC3_MAX_CHANNELS][16] = cpl_coords;\n\n#endif\n\n    int blk, ch, bnd, i, j;\n\n    CoefSumType energy[AC3_MAX_BLOCKS][AC3_MAX_CHANNELS][16] = {{{0}}};\n\n    int cpl_start, num_cpl_coefs;\n\n\n\n    memset(cpl_coords,       0, AC3_MAX_BLOCKS * sizeof(*cpl_coords));\n\n#if CONFIG_AC3ENC_FLOAT\n\n    memset(fixed_cpl_coords, 0, AC3_MAX_BLOCKS * sizeof(*cpl_coords));\n\n#endif\n\n\n\n    /* align start to 16-byte boundary. align length to multiple of 32.\n\n        note: coupling start bin % 4 will always be 1 */\n\n    cpl_start     = s->start_freq[CPL_CH] - 1;\n\n    num_cpl_coefs = FFALIGN(s->num_cpl_subbands * 12 + 1, 32);\n\n    cpl_start     = FFMIN(256, cpl_start + num_cpl_coefs) - num_cpl_coefs;\n\n\n\n    /* calculate coupling channel from fbw channels */\n\n    for (blk = 0; blk < s->num_blocks; blk++) {\n\n        AC3Block *block = &s->blocks[blk];\n\n        CoefType *cpl_coef = &block->mdct_coef[CPL_CH][cpl_start];\n\n        if (!block->cpl_in_use)\n\n            continue;\n\n        memset(cpl_coef, 0, num_cpl_coefs * sizeof(*cpl_coef));\n\n        for (ch = 1; ch <= s->fbw_channels; ch++) {\n\n            CoefType *ch_coef = &block->mdct_coef[ch][cpl_start];\n\n            if (!block->channel_in_cpl[ch])\n\n                continue;\n\n            for (i = 0; i < num_cpl_coefs; i++)\n\n                cpl_coef[i] += ch_coef[i];\n\n        }\n\n\n\n        /* coefficients must be clipped in order to be encoded */\n\n        clip_coefficients(&s->dsp, cpl_coef, num_cpl_coefs);\n\n    }\n\n\n\n    /* calculate energy in each band in coupling channel and each fbw channel */\n\n    /* TODO: possibly use SIMD to speed up energy calculation */\n\n    bnd = 0;\n\n    i = s->start_freq[CPL_CH];\n\n    while (i < s->cpl_end_freq) {\n\n        int band_size = s->cpl_band_sizes[bnd];\n\n        for (ch = CPL_CH; ch <= s->fbw_channels; ch++) {\n\n            for (blk = 0; blk < s->num_blocks; blk++) {\n\n                AC3Block *block = &s->blocks[blk];\n\n                if (!block->cpl_in_use || (ch > CPL_CH && !block->channel_in_cpl[ch]))\n\n                    continue;\n\n                for (j = 0; j < band_size; j++) {\n\n                    CoefType v = block->mdct_coef[ch][i+j];\n\n                    MAC_COEF(energy[blk][ch][bnd], v, v);\n\n                }\n\n            }\n\n        }\n\n        i += band_size;\n\n        bnd++;\n\n    }\n\n\n\n    /* calculate coupling coordinates for all blocks for all channels */\n\n    for (blk = 0; blk < s->num_blocks; blk++) {\n\n        AC3Block *block  = &s->blocks[blk];\n\n        if (!block->cpl_in_use)\n\n            continue;\n\n        for (ch = 1; ch <= s->fbw_channels; ch++) {\n\n            if (!block->channel_in_cpl[ch])\n\n                continue;\n\n            for (bnd = 0; bnd < s->num_cpl_bands; bnd++) {\n\n                cpl_coords[blk][ch][bnd] = calc_cpl_coord(energy[blk][ch][bnd],\n\n                                                          energy[blk][CPL_CH][bnd]);\n\n            }\n\n        }\n\n    }\n\n\n\n    /* determine which blocks to send new coupling coordinates for */\n\n    for (blk = 0; blk < s->num_blocks; blk++) {\n\n        AC3Block *block  = &s->blocks[blk];\n\n        AC3Block *block0 = blk ? &s->blocks[blk-1] : NULL;\n\n\n\n        memset(block->new_cpl_coords, 0, sizeof(block->new_cpl_coords));\n\n\n\n        if (block->cpl_in_use) {\n\n            /* send new coordinates if this is the first block, if previous\n\n             * block did not use coupling but this block does, the channels\n\n             * using coupling has changed from the previous block, or the\n\n             * coordinate difference from the last block for any channel is\n\n             * greater than a threshold value. */\n\n            if (blk == 0 || !block0->cpl_in_use) {\n\n                for (ch = 1; ch <= s->fbw_channels; ch++)\n\n                    block->new_cpl_coords[ch] = 1;\n\n            } else {\n\n                for (ch = 1; ch <= s->fbw_channels; ch++) {\n\n                    if (!block->channel_in_cpl[ch])\n\n                        continue;\n\n                    if (!block0->channel_in_cpl[ch]) {\n\n                        block->new_cpl_coords[ch] = 1;\n\n                    } else {\n\n                        CoefSumType coord_diff = 0;\n\n                        for (bnd = 0; bnd < s->num_cpl_bands; bnd++) {\n\n                            coord_diff += FFABS(cpl_coords[blk-1][ch][bnd] -\n\n                                                cpl_coords[blk  ][ch][bnd]);\n\n                        }\n\n                        coord_diff /= s->num_cpl_bands;\n\n                        if (coord_diff > NEW_CPL_COORD_THRESHOLD)\n\n                            block->new_cpl_coords[ch] = 1;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    /* calculate final coupling coordinates, taking into account reusing of\n\n       coordinates in successive blocks */\n\n    for (bnd = 0; bnd < s->num_cpl_bands; bnd++) {\n\n        blk = 0;\n\n        while (blk < s->num_blocks) {\n\n            int av_uninit(blk1);\n\n            AC3Block *block  = &s->blocks[blk];\n\n\n\n            if (!block->cpl_in_use) {\n\n                blk++;\n\n                continue;\n\n            }\n\n\n\n            for (ch = 1; ch <= s->fbw_channels; ch++) {\n\n                CoefSumType energy_ch, energy_cpl;\n\n                if (!block->channel_in_cpl[ch])\n\n                    continue;\n\n                energy_cpl = energy[blk][CPL_CH][bnd];\n\n                energy_ch = energy[blk][ch][bnd];\n\n                blk1 = blk+1;\n\n                while (!s->blocks[blk1].new_cpl_coords[ch] && blk1 < s->num_blocks) {\n\n                    if (s->blocks[blk1].cpl_in_use) {\n\n                        energy_cpl += energy[blk1][CPL_CH][bnd];\n\n                        energy_ch += energy[blk1][ch][bnd];\n\n                    }\n\n                    blk1++;\n\n                }\n\n                cpl_coords[blk][ch][bnd] = calc_cpl_coord(energy_ch, energy_cpl);\n\n            }\n\n            blk = blk1;\n\n        }\n\n    }\n\n\n\n    /* calculate exponents/mantissas for coupling coordinates */\n\n    for (blk = 0; blk < s->num_blocks; blk++) {\n\n        AC3Block *block = &s->blocks[blk];\n\n        if (!block->cpl_in_use)\n\n            continue;\n\n\n\n#if CONFIG_AC3ENC_FLOAT\n\n        s->ac3dsp.float_to_fixed24(fixed_cpl_coords[blk][1],\n\n                                   cpl_coords[blk][1],\n\n                                   s->fbw_channels * 16);\n\n#endif\n\n        s->ac3dsp.extract_exponents(block->cpl_coord_exp[1],\n\n                                    fixed_cpl_coords[blk][1],\n\n                                    s->fbw_channels * 16);\n\n\n\n        for (ch = 1; ch <= s->fbw_channels; ch++) {\n\n            int bnd, min_exp, max_exp, master_exp;\n\n\n\n            if (!block->new_cpl_coords[ch])\n\n                continue;\n\n\n\n            /* determine master exponent */\n\n            min_exp = max_exp = block->cpl_coord_exp[ch][0];\n\n            for (bnd = 1; bnd < s->num_cpl_bands; bnd++) {\n\n                int exp = block->cpl_coord_exp[ch][bnd];\n\n                min_exp = FFMIN(exp, min_exp);\n\n                max_exp = FFMAX(exp, max_exp);\n\n            }\n\n            master_exp = ((max_exp - 15) + 2) / 3;\n\n            master_exp = FFMAX(master_exp, 0);\n\n            while (min_exp < master_exp * 3)\n\n                master_exp--;\n\n            for (bnd = 0; bnd < s->num_cpl_bands; bnd++) {\n\n                block->cpl_coord_exp[ch][bnd] = av_clip(block->cpl_coord_exp[ch][bnd] -\n\n                                                        master_exp * 3, 0, 15);\n\n            }\n\n            block->cpl_master_exp[ch] = master_exp;\n\n\n\n            /* quantize mantissas */\n\n            for (bnd = 0; bnd < s->num_cpl_bands; bnd++) {\n\n                int cpl_exp  = block->cpl_coord_exp[ch][bnd];\n\n                int cpl_mant = (fixed_cpl_coords[blk][ch][bnd] << (5 + cpl_exp + master_exp * 3)) >> 24;\n\n                if (cpl_exp == 15)\n\n                    cpl_mant >>= 1;\n\n                else\n\n                    cpl_mant -= 16;\n\n\n\n                block->cpl_coord_mant[ch][bnd] = cpl_mant;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (CONFIG_EAC3_ENCODER && s->eac3)\n\n        ff_eac3_set_cpl_states(s);\n\n}\n", "idx": 26845}
{"project": "FFmpeg", "commit_id": "87ecefdab0097537c5c30014e57b19113ab05eee", "target": 1, "func": "static int get_high_utility_cell(elbg_data *elbg)\n\n{\n\n    int i=0;\n\n    /* Using linear search, do binary if it ever turns to be speed critical */\n\n    int r = av_lfg_get(elbg->rand_state)%elbg->utility_inc[elbg->numCB-1] + 1;\n\n    while (elbg->utility_inc[i] < r)\n\n        i++;\n\n\n\n    av_assert2(elbg->cells[i]);\n\n\n\n    return i;\n\n}\n", "idx": 26846}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "static void ff_jref_idct1_put(uint8_t *dest, int line_size, DCTELEM *block)\n\n{\n\n    uint8_t *cm = ff_cropTbl + MAX_NEG_CROP;\n\n\n\n    dest[0] = cm[(block[0] + 4)>>3];\n\n}\n", "idx": 26849}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int v410_encode_close(AVCodecContext *avctx)\n\n{\n\n    av_freep(&avctx->coded_frame);\n\n\n\n    return 0;\n\n}\n", "idx": 26851}
{"project": "FFmpeg", "commit_id": "d5e188359e768226cd272669e3f49d7f931abf71", "target": 0, "func": "static int vp3_decode_frame(AVCodecContext *avctx, \n\n                            void *data, int *data_size,\n\n                            uint8_t *buf, int buf_size)\n\n{\n\n    Vp3DecodeContext *s = avctx->priv_data;\n\n    GetBitContext gb;\n\n    static int counter = 0;\n\n\n\n    init_get_bits(&gb, buf, buf_size * 8);\n\n    \n\n    if (s->theora && get_bits1(&gb))\n\n    {\n\n\tint ptype = get_bits(&gb, 7);\n\n\n\n\tskip_bits(&gb, 6*8); /* \"theora\" */\n\n\t\n\n\tswitch(ptype)\n\n\t{\n\n\t    case 1:\n\n\t\ttheora_decode_comments(avctx, gb);\n\n\t\tbreak;\n\n\t    case 2:\n\n\t\ttheora_decode_tables(avctx, gb);\n\n    \t\tinit_dequantizer(s);\n\n\t\tbreak;\n\n\t    default:\n\n\t\tav_log(avctx, AV_LOG_ERROR, \"Unknown Theora config packet: %d\\n\", ptype);\n\n\t}\n\n\treturn buf_size;\n\n    }\n\n\n\n    s->keyframe = !get_bits1(&gb);\n\n    if (!s->theora)\n\n\tskip_bits(&gb, 1);\n\n    s->last_quality_index = s->quality_index;\n\n    s->quality_index = get_bits(&gb, 6);\n\n    if (s->theora >= 0x030200)\n\n        skip_bits1(&gb);\n\n\n\n    if (s->avctx->debug & FF_DEBUG_PICT_INFO)\n\n\tav_log(s->avctx, AV_LOG_INFO, \" VP3 %sframe #%d: Q index = %d\\n\",\n\n\t    s->keyframe?\"key\":\"\", counter, s->quality_index);\n\n    counter++;\n\n\n\n    if (s->quality_index != s->last_quality_index)\n\n        init_dequantizer(s);\n\n\n\n    if (s->keyframe) {\n\n\tif (!s->theora)\n\n\t{\n\n\t    skip_bits(&gb, 4); /* width code */\n\n\t    skip_bits(&gb, 4); /* height code */\n\n\t    if (s->version)\n\n\t    {\n\n\t\ts->version = get_bits(&gb, 5);\n\n\t\tif (counter == 1)\n\n\t\t    av_log(s->avctx, AV_LOG_DEBUG, \"VP version: %d\\n\", s->version);\n\n\t    }\n\n\t}\n\n\tif (s->version || s->theora)\n\n\t{\n\n    \t    if (get_bits1(&gb))\n\n    \t        av_log(s->avctx, AV_LOG_ERROR, \"Warning, unsupported keyframe coding type?!\\n\");\n\n\t    skip_bits(&gb, 2); /* reserved? */\n\n\t}\n\n\n\n        if (s->last_frame.data[0] == s->golden_frame.data[0]) {\n\n            if (s->golden_frame.data[0])\n\n                avctx->release_buffer(avctx, &s->golden_frame);\n\n            s->last_frame= s->golden_frame; /* ensure that we catch any access to this released frame */\n\n        } else {\n\n            if (s->golden_frame.data[0])\n\n                avctx->release_buffer(avctx, &s->golden_frame);\n\n            if (s->last_frame.data[0])\n\n                avctx->release_buffer(avctx, &s->last_frame);\n\n        }\n\n\n\n        s->golden_frame.reference = 3;\n\n        if(avctx->get_buffer(avctx, &s->golden_frame) < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"vp3: get_buffer() failed\\n\");\n\n            return -1;\n\n        }\n\n\n\n        /* golden frame is also the current frame */\n\n        memcpy(&s->current_frame, &s->golden_frame, sizeof(AVFrame));\n\n\n\n        /* time to figure out pixel addresses? */\n\n        if (!s->pixel_addresses_inited)\n\n\t{\n\n\t    if (!s->flipped_image)\n\n        \tvp3_calculate_pixel_addresses(s);\n\n\t    else\n\n\t\ttheora_calculate_pixel_addresses(s);\n\n\t}\n\n    } else {\n\n        /* allocate a new current frame */\n\n        s->current_frame.reference = 3;\n\n        if(avctx->get_buffer(avctx, &s->current_frame) < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"vp3: get_buffer() failed\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    s->current_frame.qscale_table= s->qscale_table; //FIXME allocate individual tables per AVFrame\n\n    s->current_frame.qstride= 0;\n\n\n\n    init_frame(s, &gb);\n\n\n\n#if KEYFRAMES_ONLY\n\nif (!s->keyframe) {\n\n\n\n    memcpy(s->current_frame.data[0], s->golden_frame.data[0],\n\n        s->current_frame.linesize[0] * s->height);\n\n    memcpy(s->current_frame.data[1], s->golden_frame.data[1],\n\n        s->current_frame.linesize[1] * s->height / 2);\n\n    memcpy(s->current_frame.data[2], s->golden_frame.data[2],\n\n        s->current_frame.linesize[2] * s->height / 2);\n\n\n\n} else {\n\n#endif\n\n\n\n    if (unpack_superblocks(s, &gb) ||\n\n        unpack_modes(s, &gb) ||\n\n        unpack_vectors(s, &gb) ||\n\n        unpack_dct_coeffs(s, &gb)) {\n\n\n\n        av_log(s->avctx, AV_LOG_ERROR, \"  vp3: could not decode frame\\n\");\n\n        return -1;\n\n    }\n\n\n\n    reverse_dc_prediction(s, 0, s->fragment_width, s->fragment_height);\n\n    render_fragments(s, 0, s->width, s->height, 0);\n\n//    apply_loop_filter(s);\n\n\n\n    if ((avctx->flags & CODEC_FLAG_GRAY) == 0) {\n\n        reverse_dc_prediction(s, s->u_fragment_start,\n\n            s->fragment_width / 2, s->fragment_height / 2);\n\n        reverse_dc_prediction(s, s->v_fragment_start,\n\n            s->fragment_width / 2, s->fragment_height / 2);\n\n        render_fragments(s, s->u_fragment_start, s->width / 2, s->height / 2, 1);\n\n        render_fragments(s, s->v_fragment_start, s->width / 2, s->height / 2, 2);\n\n    } else {\n\n        memset(s->current_frame.data[1], 0x80, s->width * s->height / 4);\n\n        memset(s->current_frame.data[2], 0x80, s->width * s->height / 4);\n\n    }\n\n\n\n#if KEYFRAMES_ONLY\n\n}\n\n#endif\n\n\n\n    *data_size=sizeof(AVFrame);\n\n    *(AVFrame*)data= s->current_frame;\n\n\n\n    /* release the last frame, if it is allocated and if it is not the\n\n     * golden frame */\n\n    if ((s->last_frame.data[0]) &&\n\n        (s->last_frame.data[0] != s->golden_frame.data[0]))\n\n        avctx->release_buffer(avctx, &s->last_frame);\n\n\n\n    /* shuffle frames (last = current) */\n\n    memcpy(&s->last_frame, &s->current_frame, sizeof(AVFrame));\n\n    s->current_frame.data[0]= NULL; /* ensure that we catch any access to this released frame */\n\n\n\n    return buf_size;\n\n}\n", "idx": 26852}
{"project": "FFmpeg", "commit_id": "3f98848d6e04a11f28e776b665fb14e58d56e015", "target": 0, "func": "static int au_read_header(AVFormatContext *s)\n\n{\n\n    int size;\n\n    unsigned int tag;\n\n    AVIOContext *pb = s->pb;\n\n    unsigned int id, channels, rate;\n\n    enum AVCodecID codec;\n\n    AVStream *st;\n\n\n\n    /* check \".snd\" header */\n\n    tag = avio_rl32(pb);\n\n    if (tag != MKTAG('.', 's', 'n', 'd'))\n\n        return -1;\n\n    size = avio_rb32(pb); /* header size */\n\n    avio_rb32(pb); /* data size */\n\n\n\n    id = avio_rb32(pb);\n\n    rate = avio_rb32(pb);\n\n    channels = avio_rb32(pb);\n\n\n\n    codec = ff_codec_get_id(codec_au_tags, id);\n\n\n\n    if (!av_get_bits_per_sample(codec)) {\n\n        av_log_ask_for_sample(s, \"could not determine bits per sample\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if (channels == 0 || channels > 64) {\n\n        av_log(s, AV_LOG_ERROR, \"Invalid number of channels %d\\n\", channels);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (size >= 24) {\n\n        /* skip unused data */\n\n        avio_skip(pb, size - 24);\n\n    }\n\n\n\n    /* now we are ready: build format streams */\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return -1;\n\n    st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n    st->codec->codec_tag = id;\n\n    st->codec->codec_id = codec;\n\n    st->codec->channels = channels;\n\n    st->codec->sample_rate = rate;\n\n    avpriv_set_pts_info(st, 64, 1, rate);\n\n    return 0;\n\n}\n", "idx": 26853}
{"project": "FFmpeg", "commit_id": "735e36a3e4427b009f27d27baa7541f686c180d4", "target": 0, "func": "static av_always_inline void encode_mb_internal(MpegEncContext *s, int motion_x, int motion_y, int mb_block_height, int mb_block_count)\n\n{\n\n    int16_t weight[8][64];\n\n    DCTELEM orig[8][64];\n\n    const int mb_x= s->mb_x;\n\n    const int mb_y= s->mb_y;\n\n    int i;\n\n    int skip_dct[8];\n\n    int dct_offset   = s->linesize*8; //default for progressive frames\n\n    uint8_t *ptr_y, *ptr_cb, *ptr_cr;\n\n    int wrap_y, wrap_c;\n\n\n\n    for(i=0; i<mb_block_count; i++) skip_dct[i]=s->skipdct;\n\n\n\n    if(s->adaptive_quant){\n\n        const int last_qp= s->qscale;\n\n        const int mb_xy= mb_x + mb_y*s->mb_stride;\n\n\n\n        s->lambda= s->lambda_table[mb_xy];\n\n        update_qscale(s);\n\n\n\n        if(!(s->flags&CODEC_FLAG_QP_RD)){\n\n            s->qscale= s->current_picture_ptr->qscale_table[mb_xy];\n\n            s->dquant= s->qscale - last_qp;\n\n\n\n            if(s->out_format==FMT_H263){\n\n                s->dquant= av_clip(s->dquant, -2, 2);\n\n\n\n                if(s->codec_id==CODEC_ID_MPEG4){\n\n                    if(!s->mb_intra){\n\n                        if(s->pict_type == FF_B_TYPE){\n\n                            if(s->dquant&1 || s->mv_dir&MV_DIRECT)\n\n                                s->dquant= 0;\n\n                        }\n\n                        if(s->mv_type==MV_TYPE_8X8)\n\n                            s->dquant=0;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        ff_set_qscale(s, last_qp + s->dquant);\n\n    }else if(s->flags&CODEC_FLAG_QP_RD)\n\n        ff_set_qscale(s, s->qscale + s->dquant);\n\n\n\n    wrap_y = s->linesize;\n\n    wrap_c = s->uvlinesize;\n\n    ptr_y = s->new_picture.data[0] + (mb_y * 16 * wrap_y) + mb_x * 16;\n\n    ptr_cb = s->new_picture.data[1] + (mb_y * mb_block_height * wrap_c) + mb_x * 8;\n\n    ptr_cr = s->new_picture.data[2] + (mb_y * mb_block_height * wrap_c) + mb_x * 8;\n\n\n\n    if(mb_x*16+16 > s->width || mb_y*16+16 > s->height){\n\n        uint8_t *ebuf= s->edge_emu_buffer + 32;\n\n        ff_emulated_edge_mc(ebuf            , ptr_y , wrap_y,16,16,mb_x*16,mb_y*16, s->width   , s->height);\n\n        ptr_y= ebuf;\n\n        ff_emulated_edge_mc(ebuf+18*wrap_y  , ptr_cb, wrap_c, 8, mb_block_height, mb_x*8, mb_y*8, s->width>>1, s->height>>1);\n\n        ptr_cb= ebuf+18*wrap_y;\n\n        ff_emulated_edge_mc(ebuf+18*wrap_y+8, ptr_cr, wrap_c, 8, mb_block_height, mb_x*8, mb_y*8, s->width>>1, s->height>>1);\n\n        ptr_cr= ebuf+18*wrap_y+8;\n\n    }\n\n\n\n    if (s->mb_intra) {\n\n        if(s->flags&CODEC_FLAG_INTERLACED_DCT){\n\n            int progressive_score, interlaced_score;\n\n\n\n            s->interlaced_dct=0;\n\n            progressive_score= s->dsp.ildct_cmp[4](s, ptr_y           , NULL, wrap_y, 8)\n\n                              +s->dsp.ildct_cmp[4](s, ptr_y + wrap_y*8, NULL, wrap_y, 8) - 400;\n\n\n\n            if(progressive_score > 0){\n\n                interlaced_score = s->dsp.ildct_cmp[4](s, ptr_y           , NULL, wrap_y*2, 8)\n\n                                  +s->dsp.ildct_cmp[4](s, ptr_y + wrap_y  , NULL, wrap_y*2, 8);\n\n                if(progressive_score > interlaced_score){\n\n                    s->interlaced_dct=1;\n\n\n\n                    dct_offset= wrap_y;\n\n                    wrap_y<<=1;\n\n                    if (s->chroma_format == CHROMA_422)\n\n                        wrap_c<<=1;\n\n                }\n\n            }\n\n        }\n\n\n\n        s->dsp.get_pixels(s->block[0], ptr_y                 , wrap_y);\n\n        s->dsp.get_pixels(s->block[1], ptr_y              + 8, wrap_y);\n\n        s->dsp.get_pixels(s->block[2], ptr_y + dct_offset    , wrap_y);\n\n        s->dsp.get_pixels(s->block[3], ptr_y + dct_offset + 8, wrap_y);\n\n\n\n        if(s->flags&CODEC_FLAG_GRAY){\n\n            skip_dct[4]= 1;\n\n            skip_dct[5]= 1;\n\n        }else{\n\n            s->dsp.get_pixels(s->block[4], ptr_cb, wrap_c);\n\n            s->dsp.get_pixels(s->block[5], ptr_cr, wrap_c);\n\n            if(!s->chroma_y_shift){ /* 422 */\n\n                s->dsp.get_pixels(s->block[6], ptr_cb + (dct_offset>>1), wrap_c);\n\n                s->dsp.get_pixels(s->block[7], ptr_cr + (dct_offset>>1), wrap_c);\n\n            }\n\n        }\n\n    }else{\n\n        op_pixels_func (*op_pix)[4];\n\n        qpel_mc_func (*op_qpix)[16];\n\n        uint8_t *dest_y, *dest_cb, *dest_cr;\n\n\n\n        dest_y  = s->dest[0];\n\n        dest_cb = s->dest[1];\n\n        dest_cr = s->dest[2];\n\n\n\n        if ((!s->no_rounding) || s->pict_type==FF_B_TYPE){\n\n            op_pix = s->dsp.put_pixels_tab;\n\n            op_qpix= s->dsp.put_qpel_pixels_tab;\n\n        }else{\n\n            op_pix = s->dsp.put_no_rnd_pixels_tab;\n\n            op_qpix= s->dsp.put_no_rnd_qpel_pixels_tab;\n\n        }\n\n\n\n        if (s->mv_dir & MV_DIR_FORWARD) {\n\n            MPV_motion(s, dest_y, dest_cb, dest_cr, 0, s->last_picture.data, op_pix, op_qpix);\n\n            op_pix = s->dsp.avg_pixels_tab;\n\n            op_qpix= s->dsp.avg_qpel_pixels_tab;\n\n        }\n\n        if (s->mv_dir & MV_DIR_BACKWARD) {\n\n            MPV_motion(s, dest_y, dest_cb, dest_cr, 1, s->next_picture.data, op_pix, op_qpix);\n\n        }\n\n\n\n        if(s->flags&CODEC_FLAG_INTERLACED_DCT){\n\n            int progressive_score, interlaced_score;\n\n\n\n            s->interlaced_dct=0;\n\n            progressive_score= s->dsp.ildct_cmp[0](s, dest_y           , ptr_y           , wrap_y, 8)\n\n                              +s->dsp.ildct_cmp[0](s, dest_y + wrap_y*8, ptr_y + wrap_y*8, wrap_y, 8) - 400;\n\n\n\n            if(s->avctx->ildct_cmp == FF_CMP_VSSE) progressive_score -= 400;\n\n\n\n            if(progressive_score>0){\n\n                interlaced_score = s->dsp.ildct_cmp[0](s, dest_y           , ptr_y           , wrap_y*2, 8)\n\n                                  +s->dsp.ildct_cmp[0](s, dest_y + wrap_y  , ptr_y + wrap_y  , wrap_y*2, 8);\n\n\n\n                if(progressive_score > interlaced_score){\n\n                    s->interlaced_dct=1;\n\n\n\n                    dct_offset= wrap_y;\n\n                    wrap_y<<=1;\n\n                    if (s->chroma_format == CHROMA_422)\n\n                        wrap_c<<=1;\n\n                }\n\n            }\n\n        }\n\n\n\n        s->dsp.diff_pixels(s->block[0], ptr_y                 , dest_y                 , wrap_y);\n\n        s->dsp.diff_pixels(s->block[1], ptr_y              + 8, dest_y              + 8, wrap_y);\n\n        s->dsp.diff_pixels(s->block[2], ptr_y + dct_offset    , dest_y + dct_offset    , wrap_y);\n\n        s->dsp.diff_pixels(s->block[3], ptr_y + dct_offset + 8, dest_y + dct_offset + 8, wrap_y);\n\n\n\n        if(s->flags&CODEC_FLAG_GRAY){\n\n            skip_dct[4]= 1;\n\n            skip_dct[5]= 1;\n\n        }else{\n\n            s->dsp.diff_pixels(s->block[4], ptr_cb, dest_cb, wrap_c);\n\n            s->dsp.diff_pixels(s->block[5], ptr_cr, dest_cr, wrap_c);\n\n            if(!s->chroma_y_shift){ /* 422 */\n\n                s->dsp.diff_pixels(s->block[6], ptr_cb + (dct_offset>>1), dest_cb + (dct_offset>>1), wrap_c);\n\n                s->dsp.diff_pixels(s->block[7], ptr_cr + (dct_offset>>1), dest_cr + (dct_offset>>1), wrap_c);\n\n            }\n\n        }\n\n        /* pre quantization */\n\n        if(s->current_picture.mc_mb_var[s->mb_stride*mb_y+ mb_x]<2*s->qscale*s->qscale){\n\n            //FIXME optimize\n\n            if(s->dsp.sad[1](NULL, ptr_y               , dest_y               , wrap_y, 8) < 20*s->qscale) skip_dct[0]= 1;\n\n            if(s->dsp.sad[1](NULL, ptr_y            + 8, dest_y            + 8, wrap_y, 8) < 20*s->qscale) skip_dct[1]= 1;\n\n            if(s->dsp.sad[1](NULL, ptr_y +dct_offset   , dest_y +dct_offset   , wrap_y, 8) < 20*s->qscale) skip_dct[2]= 1;\n\n            if(s->dsp.sad[1](NULL, ptr_y +dct_offset+ 8, dest_y +dct_offset+ 8, wrap_y, 8) < 20*s->qscale) skip_dct[3]= 1;\n\n            if(s->dsp.sad[1](NULL, ptr_cb              , dest_cb              , wrap_c, 8) < 20*s->qscale) skip_dct[4]= 1;\n\n            if(s->dsp.sad[1](NULL, ptr_cr              , dest_cr              , wrap_c, 8) < 20*s->qscale) skip_dct[5]= 1;\n\n            if(!s->chroma_y_shift){ /* 422 */\n\n                if(s->dsp.sad[1](NULL, ptr_cb +(dct_offset>>1), dest_cb +(dct_offset>>1), wrap_c, 8) < 20*s->qscale) skip_dct[6]= 1;\n\n                if(s->dsp.sad[1](NULL, ptr_cr +(dct_offset>>1), dest_cr +(dct_offset>>1), wrap_c, 8) < 20*s->qscale) skip_dct[7]= 1;\n\n            }\n\n        }\n\n    }\n\n\n\n    if(s->avctx->quantizer_noise_shaping){\n\n        if(!skip_dct[0]) get_visual_weight(weight[0], ptr_y                 , wrap_y);\n\n        if(!skip_dct[1]) get_visual_weight(weight[1], ptr_y              + 8, wrap_y);\n\n        if(!skip_dct[2]) get_visual_weight(weight[2], ptr_y + dct_offset    , wrap_y);\n\n        if(!skip_dct[3]) get_visual_weight(weight[3], ptr_y + dct_offset + 8, wrap_y);\n\n        if(!skip_dct[4]) get_visual_weight(weight[4], ptr_cb                , wrap_c);\n\n        if(!skip_dct[5]) get_visual_weight(weight[5], ptr_cr                , wrap_c);\n\n        if(!s->chroma_y_shift){ /* 422 */\n\n            if(!skip_dct[6]) get_visual_weight(weight[6], ptr_cb + (dct_offset>>1), wrap_c);\n\n            if(!skip_dct[7]) get_visual_weight(weight[7], ptr_cr + (dct_offset>>1), wrap_c);\n\n        }\n\n        memcpy(orig[0], s->block[0], sizeof(DCTELEM)*64*mb_block_count);\n\n    }\n\n\n\n    /* DCT & quantize */\n\n    assert(s->out_format!=FMT_MJPEG || s->qscale==8);\n\n    {\n\n        for(i=0;i<mb_block_count;i++) {\n\n            if(!skip_dct[i]){\n\n                int overflow;\n\n                s->block_last_index[i] = s->dct_quantize(s, s->block[i], i, s->qscale, &overflow);\n\n            // FIXME we could decide to change to quantizer instead of clipping\n\n            // JS: I don't think that would be a good idea it could lower quality instead\n\n            //     of improve it. Just INTRADC clipping deserves changes in quantizer\n\n                if (overflow) clip_coeffs(s, s->block[i], s->block_last_index[i]);\n\n            }else\n\n                s->block_last_index[i]= -1;\n\n        }\n\n        if(s->avctx->quantizer_noise_shaping){\n\n            for(i=0;i<mb_block_count;i++) {\n\n                if(!skip_dct[i]){\n\n                    s->block_last_index[i] = dct_quantize_refine(s, s->block[i], weight[i], orig[i], i, s->qscale);\n\n                }\n\n            }\n\n        }\n\n\n\n        if(s->luma_elim_threshold && !s->mb_intra)\n\n            for(i=0; i<4; i++)\n\n                dct_single_coeff_elimination(s, i, s->luma_elim_threshold);\n\n        if(s->chroma_elim_threshold && !s->mb_intra)\n\n            for(i=4; i<mb_block_count; i++)\n\n                dct_single_coeff_elimination(s, i, s->chroma_elim_threshold);\n\n\n\n        if(s->flags & CODEC_FLAG_CBP_RD){\n\n            for(i=0;i<mb_block_count;i++) {\n\n                if(s->block_last_index[i] == -1)\n\n                    s->coded_score[i]= INT_MAX/256;\n\n            }\n\n        }\n\n    }\n\n\n\n    if((s->flags&CODEC_FLAG_GRAY) && s->mb_intra){\n\n        s->block_last_index[4]=\n\n        s->block_last_index[5]= 0;\n\n        s->block[4][0]=\n\n        s->block[5][0]= (1024 + s->c_dc_scale/2)/ s->c_dc_scale;\n\n    }\n\n\n\n    //non c quantize code returns incorrect block_last_index FIXME\n\n    if(s->alternate_scan && s->dct_quantize != dct_quantize_c){\n\n        for(i=0; i<mb_block_count; i++){\n\n            int j;\n\n            if(s->block_last_index[i]>0){\n\n                for(j=63; j>0; j--){\n\n                    if(s->block[i][ s->intra_scantable.permutated[j] ]) break;\n\n                }\n\n                s->block_last_index[i]= j;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* huffman encode */\n\n    switch(s->codec_id){ //FIXME funct ptr could be slightly faster\n\n    case CODEC_ID_MPEG1VIDEO:\n\n    case CODEC_ID_MPEG2VIDEO:\n\n        if (CONFIG_MPEG1VIDEO_ENCODER || CONFIG_MPEG2VIDEO_ENCODER)\n\n            mpeg1_encode_mb(s, s->block, motion_x, motion_y);\n\n        break;\n\n    case CODEC_ID_MPEG4:\n\n        if (CONFIG_MPEG4_ENCODER)\n\n            mpeg4_encode_mb(s, s->block, motion_x, motion_y);\n\n        break;\n\n    case CODEC_ID_MSMPEG4V2:\n\n    case CODEC_ID_MSMPEG4V3:\n\n    case CODEC_ID_WMV1:\n\n        if (CONFIG_MSMPEG4_ENCODER)\n\n            msmpeg4_encode_mb(s, s->block, motion_x, motion_y);\n\n        break;\n\n    case CODEC_ID_WMV2:\n\n        if (CONFIG_WMV2_ENCODER)\n\n            ff_wmv2_encode_mb(s, s->block, motion_x, motion_y);\n\n        break;\n\n    case CODEC_ID_H261:\n\n        if (CONFIG_H261_ENCODER)\n\n            ff_h261_encode_mb(s, s->block, motion_x, motion_y);\n\n        break;\n\n    case CODEC_ID_H263:\n\n    case CODEC_ID_H263P:\n\n    case CODEC_ID_FLV1:\n\n    case CODEC_ID_RV10:\n\n    case CODEC_ID_RV20:\n\n        if (CONFIG_H263_ENCODER || CONFIG_H263P_ENCODER ||\n\n            CONFIG_FLV_ENCODER  || CONFIG_RV10_ENCODER  || CONFIG_RV20_ENCODER)\n\n            h263_encode_mb(s, s->block, motion_x, motion_y);\n\n        break;\n\n    case CODEC_ID_MJPEG:\n\n        if (CONFIG_MJPEG_ENCODER)\n\n            ff_mjpeg_encode_mb(s, s->block);\n\n        break;\n\n    default:\n\n        assert(0);\n\n    }\n\n}\n", "idx": 26858}
{"project": "FFmpeg", "commit_id": "a91d82b5cc7d828ea9779aae1595f60e7e257d29", "target": 1, "func": "static int sbr_hf_calc_npatches(AACContext *ac, SpectralBandReplication *sbr)\n\n{\n\n    int i, k, sb = 0;\n\n    int msb = sbr->k[0];\n\n    int usb = sbr->kx[1];\n\n    int goal_sb = ((1000 << 11) + (sbr->sample_rate >> 1)) / sbr->sample_rate;\n\n\n\n    sbr->num_patches = 0;\n\n\n\n    if (goal_sb < sbr->kx[1] + sbr->m[1]) {\n\n        for (k = 0; sbr->f_master[k] < goal_sb; k++) ;\n\n    } else\n\n        k = sbr->n_master;\n\n\n\n    do {\n\n        int odd = 0;\n\n        for (i = k; i == k || sb > (sbr->k[0] - 1 + msb - odd); i--) {\n\n            sb = sbr->f_master[i];\n\n            odd = (sb + sbr->k[0]) & 1;\n\n        }\n\n\n\n        sbr->patch_num_subbands[sbr->num_patches]  = FFMAX(sb - usb, 0);\n\n        sbr->patch_start_subband[sbr->num_patches] = sbr->k[0] - odd - sbr->patch_num_subbands[sbr->num_patches];\n\n\n\n        if (sbr->patch_num_subbands[sbr->num_patches] > 0) {\n\n            usb = sb;\n\n            msb = sb;\n\n            sbr->num_patches++;\n\n        } else\n\n            msb = sbr->kx[1];\n\n\n\n        if (sbr->f_master[k] - sb < 3)\n\n            k = sbr->n_master;\n\n    } while (sb != sbr->kx[1] + sbr->m[1]);\n\n\n\n    if (sbr->patch_num_subbands[sbr->num_patches-1] < 3 && sbr->num_patches > 1)\n\n        sbr->num_patches--;\n\n\n\n    // Requirements (14496-3 sp04 p205) sets the maximum number of patches to 5\n\n    // However the Coding Technologies decoder check uses 6 patches\n\n    if (sbr->num_patches > 6) {\n\n        av_log(ac->avccontext, AV_LOG_ERROR, \"Too many patches: %d\\n\", sbr->num_patches);\n\n        return -1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26862}
{"project": "FFmpeg", "commit_id": "258dfff8394d383beaa639d19912b3f068f67e16", "target": 1, "func": "void av_log_format_line(void *ptr, int level, const char *fmt, va_list vl,\n\n                        char *line, int line_size, int *print_prefix)\n\n{\n\n    char part[3][512];\n\n    format_line(ptr, level, fmt, vl, part, sizeof(part[0]), print_prefix, NULL);\n\n    snprintf(line, line_size, \"%s%s%s\", part[0], part[1], part[2]);\n\n}\n", "idx": 26867}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "static inline void RENAME(rgb32tobgr15)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n\tconst uint8_t *s = src;\n\n\tconst uint8_t *end;\n\n#ifdef HAVE_MMX\n\n\tconst uint8_t *mm_end;\n\n#endif\n\n\tuint16_t *d = (uint16_t *)dst;\n\n\tend = s + src_size;\n\n#ifdef HAVE_MMX\n\n\t__asm __volatile(PREFETCH\"\t%0\"::\"m\"(*src):\"memory\");\n\n\t__asm __volatile(\n\n\t    \"movq\t%0, %%mm7\\n\\t\"\n\n\t    \"movq\t%1, %%mm6\\n\\t\"\n\n\t    ::\"m\"(red_15mask),\"m\"(green_15mask));\n\n\tmm_end = end - 15;\n\n\twhile(s < mm_end)\n\n\t{\n\n\t    __asm __volatile(\n\n\t\tPREFETCH\" 32%1\\n\\t\"\n\n\t\t\"movd\t%1, %%mm0\\n\\t\"\n\n\t\t\"movd\t4%1, %%mm3\\n\\t\"\n\n\t\t\"punpckldq 8%1, %%mm0\\n\\t\"\n\n\t\t\"punpckldq 12%1, %%mm3\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm1\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm2\\n\\t\"\n\n\t\t\"movq\t%%mm3, %%mm4\\n\\t\"\n\n\t\t\"movq\t%%mm3, %%mm5\\n\\t\"\n\n\t\t\"psllq\t$7, %%mm0\\n\\t\"\n\n\t\t\"psllq\t$7, %%mm3\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm0\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm3\\n\\t\"\n\n\t\t\"psrlq\t$6, %%mm1\\n\\t\"\n\n\t\t\"psrlq\t$6, %%mm4\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm1\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm4\\n\\t\"\n\n\t\t\"psrlq\t$19, %%mm2\\n\\t\"\n\n\t\t\"psrlq\t$19, %%mm5\\n\\t\"\n\n\t\t\"pand\t%2, %%mm2\\n\\t\"\n\n\t\t\"pand\t%2, %%mm5\\n\\t\"\n\n\t\t\"por\t%%mm1, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm4, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm2, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm5, %%mm3\\n\\t\"\n\n\t\t\"psllq\t$16, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm3, %%mm0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\t:\"=m\"(*d):\"m\"(*s),\"m\"(blue_15mask):\"memory\");\n\n\t\td += 4;\n\n\t\ts += 16;\n\n\t}\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\twhile(s < end)\n\n\t{\n\n\t\tregister int rgb = *(uint32_t*)s; s += 4;\n\n\t\t*d++ = ((rgb&0xF8)<<7) + ((rgb&0xF800)>>6) + ((rgb&0xF80000)>>19);\n\n\t}\n\n}\n", "idx": 26868}
{"project": "FFmpeg", "commit_id": "e6f0deab806f518f55ee54b970f70de1948bbf5d", "target": 0, "func": "static int http_receive_data(HTTPContext *c)\n\n{\n\n    HTTPContext *c1;\n\n\n\n    if (c->buffer_end > c->buffer_ptr) {\n\n        int len;\n\n\n\n        len = recv(c->fd, c->buffer_ptr, c->buffer_end - c->buffer_ptr, 0);\n\n        if (len < 0) {\n\n            if (ff_neterrno() != FF_NETERROR(EAGAIN) &&\n\n                ff_neterrno() != FF_NETERROR(EINTR))\n\n                /* error : close connection */\n\n                goto fail;\n\n        } else if (len == 0)\n\n            /* end of connection : close it */\n\n            goto fail;\n\n        else {\n\n            c->buffer_ptr += len;\n\n            c->data_count += len;\n\n            update_datarate(&c->datarate, c->data_count);\n\n        }\n\n    }\n\n\n\n    if (c->buffer_ptr - c->buffer >= 2 && c->data_count > FFM_PACKET_SIZE) {\n\n        if (c->buffer[0] != 'f' ||\n\n            c->buffer[1] != 'm') {\n\n            http_log(\"Feed stream has become desynchronized -- disconnecting\\n\");\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n    if (c->buffer_ptr >= c->buffer_end) {\n\n        FFStream *feed = c->stream;\n\n        /* a packet has been received : write it in the store, except\n\n           if header */\n\n        if (c->data_count > FFM_PACKET_SIZE) {\n\n\n\n            //            printf(\"writing pos=0x%\"PRIx64\" size=0x%\"PRIx64\"\\n\", feed->feed_write_index, feed->feed_size);\n\n            /* XXX: use llseek or url_seek */\n\n            lseek(c->feed_fd, feed->feed_write_index, SEEK_SET);\n\n            if (write(c->feed_fd, c->buffer, FFM_PACKET_SIZE) < 0) {\n\n                http_log(\"Error writing to feed file: %s\\n\", strerror(errno));\n\n                goto fail;\n\n            }\n\n\n\n            feed->feed_write_index += FFM_PACKET_SIZE;\n\n            /* update file size */\n\n            if (feed->feed_write_index > c->stream->feed_size)\n\n                feed->feed_size = feed->feed_write_index;\n\n\n\n            /* handle wrap around if max file size reached */\n\n            if (c->stream->feed_max_size && feed->feed_write_index >= c->stream->feed_max_size)\n\n                feed->feed_write_index = FFM_PACKET_SIZE;\n\n\n\n            /* write index */\n\n            ffm_write_write_index(c->feed_fd, feed->feed_write_index);\n\n\n\n            /* wake up any waiting connections */\n\n            for(c1 = first_http_ctx; c1 != NULL; c1 = c1->next) {\n\n                if (c1->state == HTTPSTATE_WAIT_FEED &&\n\n                    c1->stream->feed == c->stream->feed)\n\n                    c1->state = HTTPSTATE_SEND_DATA;\n\n            }\n\n        } else {\n\n            /* We have a header in our hands that contains useful data */\n\n            AVFormatContext *s = NULL;\n\n            ByteIOContext *pb;\n\n            AVInputFormat *fmt_in;\n\n            int i;\n\n\n\n            url_open_buf(&pb, c->buffer, c->buffer_end - c->buffer, URL_RDONLY);\n\n            pb->is_streamed = 1;\n\n\n\n            /* use feed output format name to find corresponding input format */\n\n            fmt_in = av_find_input_format(feed->fmt->name);\n\n            if (!fmt_in)\n\n                goto fail;\n\n\n\n            av_open_input_stream(&s, pb, c->stream->feed_filename, fmt_in, NULL);\n\n\n\n            /* Now we have the actual streams */\n\n            if (s->nb_streams != feed->nb_streams) {\n\n                av_close_input_stream(s);\n\n                av_free(pb);\n\n                goto fail;\n\n            }\n\n\n\n            for (i = 0; i < s->nb_streams; i++)\n\n                memcpy(feed->streams[i]->codec,\n\n                       s->streams[i]->codec, sizeof(AVCodecContext));\n\n\n\n            av_close_input_stream(s);\n\n            av_free(pb);\n\n        }\n\n        c->buffer_ptr = c->buffer;\n\n    }\n\n\n\n    return 0;\n\n fail:\n\n    c->stream->feed_opened = 0;\n\n    close(c->feed_fd);\n\n    /* wake up any waiting connections to stop waiting for feed */\n\n    for(c1 = first_http_ctx; c1 != NULL; c1 = c1->next) {\n\n        if (c1->state == HTTPSTATE_WAIT_FEED &&\n\n            c1->stream->feed == c->stream->feed)\n\n            c1->state = HTTPSTATE_SEND_DATA_TRAILER;\n\n    }\n\n    return -1;\n\n}\n", "idx": 26869}
{"project": "FFmpeg", "commit_id": "f6b7f72461673e4d398b1edf9ed2a7fe70d99c47", "target": 0, "func": "static void av_always_inline filter_mb_edgech( uint8_t *pix, int stride, const int16_t bS[4], unsigned int qp, H264Context *h, int intra ) {\n\n    const int qp_bd_offset = 6 * (h->sps.bit_depth_luma - 8);\n\n    const unsigned int index_a = qp - qp_bd_offset + h->slice_alpha_c0_offset;\n\n    const int alpha = alpha_table[index_a];\n\n    const int beta  = beta_table[qp - qp_bd_offset + h->slice_beta_offset];\n\n    if (alpha ==0 || beta == 0) return;\n\n\n\n    if( bS[0] < 4 || !intra ) {\n\n        int8_t tc[4];\n\n        tc[0] = tc0_table[index_a][bS[0]]+1;\n\n        tc[1] = tc0_table[index_a][bS[1]]+1;\n\n        tc[2] = tc0_table[index_a][bS[2]]+1;\n\n        tc[3] = tc0_table[index_a][bS[3]]+1;\n\n        h->h264dsp.h264_v_loop_filter_chroma(pix, stride, alpha, beta, tc);\n\n    } else {\n\n        h->h264dsp.h264_v_loop_filter_chroma_intra(pix, stride, alpha, beta);\n\n    }\n\n}\n", "idx": 26870}
{"project": "FFmpeg", "commit_id": "0de1319ee0109facefe9804ffe0f0d0df36b27ad", "target": 0, "func": "static int http_start_receive_data(HTTPContext *c)\n\n{\n\n    int fd;\n\n\n\n    if (c->stream->feed_opened)\n\n        return -1;\n\n\n\n    /* Don't permit writing to this one */\n\n    if (c->stream->readonly)\n\n        return -1;\n\n\n\n    /* open feed */\n\n    fd = open(c->stream->feed_filename, O_RDWR);\n\n    if (fd < 0) {\n\n        http_log(\"Error opening feeder file: %s\\n\", strerror(errno));\n\n        return -1;\n\n    }\n\n    c->feed_fd = fd;\n\n\n\n    if (c->stream->truncate) {\n\n        /* truncate feed file */\n\n        ffm_write_write_index(c->feed_fd, FFM_PACKET_SIZE);\n\n        ftruncate(c->feed_fd, FFM_PACKET_SIZE);\n\n        http_log(\"Truncating feed file '%s'\\n\", c->stream->feed_filename);\n\n    } else {\n\n        if ((c->stream->feed_write_index = ffm_read_write_index(fd)) < 0) {\n\n            http_log(\"Error reading write index from feed file: %s\\n\", strerror(errno));\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    c->stream->feed_write_index = FFMAX(ffm_read_write_index(fd), FFM_PACKET_SIZE);\n\n    c->stream->feed_size = lseek(fd, 0, SEEK_END);\n\n    lseek(fd, 0, SEEK_SET);\n\n\n\n    /* init buffer input */\n\n    c->buffer_ptr = c->buffer;\n\n    c->buffer_end = c->buffer + FFM_PACKET_SIZE;\n\n    c->stream->feed_opened = 1;\n\n    c->chunked_encoding = !!av_stristr(c->buffer, \"Transfer-Encoding: chunked\");\n\n    return 0;\n\n}\n", "idx": 26880}
{"project": "FFmpeg", "commit_id": "89505f2c3f8ee1b0b68fc220a226c8bf3cef24cd", "target": 0, "func": "static int init_filter_param(AVFilterContext *ctx, FilterParam *fp, const char *effect_type, int width)\n\n{\n\n    int z;\n\n    const char *effect = fp->amount == 0 ? \"none\" : fp->amount < 0 ? \"blur\" : \"sharpen\";\n\n\n\n    if  (!(fp->msize_x & fp->msize_y & 1)) {\n\n        av_log(ctx, AV_LOG_ERROR,\n\n               \"Invalid even size for %s matrix size %dx%d\\n\",\n\n               effect_type, fp->msize_x, fp->msize_y);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    av_log(ctx, AV_LOG_VERBOSE, \"effect:%s type:%s msize_x:%d msize_y:%d amount:%0.2f\\n\",\n\n           effect, effect_type, fp->msize_x, fp->msize_y, fp->amount / 65535.0);\n\n\n\n    for (z = 0; z < 2 * fp->steps_y; z++)\n\n        fp->sc[z] = av_malloc(sizeof(*(fp->sc[z])) * (width + 2 * fp->steps_x));\n\n\n\n    return 0;\n\n}\n", "idx": 26899}
{"project": "FFmpeg", "commit_id": "95af5e1c8158667066e1b39217bbf6e62cedeb4c", "target": 0, "func": "static void do_video_out(AVFormatContext *s,\n\n                         AVOutputStream *ost,\n\n                         AVInputStream *ist,\n\n                         AVFrame *in_picture,\n\n                         int *frame_size)\n\n{\n\n    int nb_frames, i, ret;\n\n    AVFrame *final_picture, *formatted_picture, *resampling_dst, *padding_src;\n\n    AVFrame picture_crop_temp, picture_pad_temp;\n\n    AVCodecContext *enc, *dec;\n\n\n\n    avcodec_get_frame_defaults(&picture_crop_temp);\n\n    avcodec_get_frame_defaults(&picture_pad_temp);\n\n\n\n    enc = ost->st->codec;\n\n    dec = ist->st->codec;\n\n\n\n    /* by default, we output a single frame */\n\n    nb_frames = 1;\n\n\n\n    *frame_size = 0;\n\n\n\n    if(video_sync_method>0 || (video_sync_method && av_q2d(enc->time_base) > 0.001)){\n\n        double vdelta;\n\n        vdelta = get_sync_ipts(ost) / av_q2d(enc->time_base) - ost->sync_opts;\n\n        //FIXME set to 0.5 after we fix some dts/pts bugs like in avidec.c\n\n        if (vdelta < -1.1)\n\n            nb_frames = 0;\n\n        else if (video_sync_method == 2)\n\n            ost->sync_opts= lrintf(get_sync_ipts(ost) / av_q2d(enc->time_base));\n\n        else if (vdelta > 1.1)\n\n            nb_frames = lrintf(vdelta);\n\n//fprintf(stderr, \"vdelta:%f, ost->sync_opts:%\"PRId64\", ost->sync_ipts:%f nb_frames:%d\\n\", vdelta, ost->sync_opts, ost->sync_ipts, nb_frames);\n\n        if (nb_frames == 0){\n\n            ++nb_frames_drop;\n\n            if (verbose>2)\n\n                fprintf(stderr, \"*** drop!\\n\");\n\n        }else if (nb_frames > 1) {\n\n            nb_frames_dup += nb_frames;\n\n            if (verbose>2)\n\n                fprintf(stderr, \"*** %d dup!\\n\", nb_frames-1);\n\n        }\n\n    }else\n\n        ost->sync_opts= lrintf(get_sync_ipts(ost) / av_q2d(enc->time_base));\n\n\n\n    nb_frames= FFMIN(nb_frames, max_frames[CODEC_TYPE_VIDEO] - ost->frame_number);\n\n    if (nb_frames <= 0)\n\n        return;\n\n\n\n    if (ost->video_crop) {\n\n        if (av_picture_crop((AVPicture *)&picture_crop_temp, (AVPicture *)in_picture, dec->pix_fmt, ost->topBand, ost->leftBand) < 0) {\n\n            av_log(NULL, AV_LOG_ERROR, \"error cropping picture\\n\");\n\n            if (exit_on_error)\n\n                av_exit(1);\n\n            return;\n\n        }\n\n        formatted_picture = &picture_crop_temp;\n\n    } else {\n\n        formatted_picture = in_picture;\n\n    }\n\n\n\n    final_picture = formatted_picture;\n\n    padding_src = formatted_picture;\n\n    resampling_dst = &ost->pict_tmp;\n\n    if (ost->video_pad) {\n\n        final_picture = &ost->pict_tmp;\n\n        if (ost->video_resample) {\n\n            if (av_picture_crop((AVPicture *)&picture_pad_temp, (AVPicture *)final_picture, enc->pix_fmt, ost->padtop, ost->padleft) < 0) {\n\n                av_log(NULL, AV_LOG_ERROR, \"error padding picture\\n\");\n\n                if (exit_on_error)\n\n                    av_exit(1);\n\n                return;\n\n            }\n\n            resampling_dst = &picture_pad_temp;\n\n        }\n\n    }\n\n\n\n    if (ost->video_resample) {\n\n        padding_src = NULL;\n\n        final_picture = &ost->pict_tmp;\n\n        sws_scale(ost->img_resample_ctx, formatted_picture->data, formatted_picture->linesize,\n\n              0, ost->resample_height, resampling_dst->data, resampling_dst->linesize);\n\n    }\n\n\n\n    if (ost->video_pad) {\n\n        av_picture_pad((AVPicture*)final_picture, (AVPicture *)padding_src,\n\n                enc->height, enc->width, enc->pix_fmt,\n\n                ost->padtop, ost->padbottom, ost->padleft, ost->padright, padcolor);\n\n    }\n\n\n\n    /* duplicates frame if needed */\n\n    for(i=0;i<nb_frames;i++) {\n\n        AVPacket pkt;\n\n        av_init_packet(&pkt);\n\n        pkt.stream_index= ost->index;\n\n\n\n        if (s->oformat->flags & AVFMT_RAWPICTURE) {\n\n            /* raw pictures are written as AVPicture structure to\n\n               avoid any copies. We support temorarily the older\n\n               method. */\n\n            AVFrame* old_frame = enc->coded_frame;\n\n            enc->coded_frame = dec->coded_frame; //FIXME/XXX remove this hack\n\n            pkt.data= (uint8_t *)final_picture;\n\n            pkt.size=  sizeof(AVPicture);\n\n            pkt.pts= av_rescale_q(ost->sync_opts, enc->time_base, ost->st->time_base);\n\n            pkt.flags |= PKT_FLAG_KEY;\n\n\n\n            write_frame(s, &pkt, ost->st->codec, bitstream_filters[ost->file_index][pkt.stream_index]);\n\n            enc->coded_frame = old_frame;\n\n        } else {\n\n            AVFrame big_picture;\n\n\n\n            big_picture= *final_picture;\n\n            /* better than nothing: use input picture interlaced\n\n               settings */\n\n            big_picture.interlaced_frame = in_picture->interlaced_frame;\n\n            if(avctx_opts[CODEC_TYPE_VIDEO]->flags & (CODEC_FLAG_INTERLACED_DCT|CODEC_FLAG_INTERLACED_ME)){\n\n                if(top_field_first == -1)\n\n                    big_picture.top_field_first = in_picture->top_field_first;\n\n                else\n\n                    big_picture.top_field_first = top_field_first;\n\n            }\n\n\n\n            /* handles sameq here. This is not correct because it may\n\n               not be a global option */\n\n            if (same_quality) {\n\n                big_picture.quality = ist->st->quality;\n\n            }else\n\n                big_picture.quality = ost->st->quality;\n\n            if(!me_threshold)\n\n                big_picture.pict_type = 0;\n\n//            big_picture.pts = AV_NOPTS_VALUE;\n\n            big_picture.pts= ost->sync_opts;\n\n//            big_picture.pts= av_rescale(ost->sync_opts, AV_TIME_BASE*(int64_t)enc->time_base.num, enc->time_base.den);\n\n//av_log(NULL, AV_LOG_DEBUG, \"%\"PRId64\" -> encoder\\n\", ost->sync_opts);\n\n            ret = avcodec_encode_video(enc,\n\n                                       bit_buffer, bit_buffer_size,\n\n                                       &big_picture);\n\n            if (ret == -1) {\n\n                fprintf(stderr, \"Video encoding failed\\n\");\n\n                av_exit(1);\n\n            }\n\n            //enc->frame_number = enc->real_pict_num;\n\n            if(ret>0){\n\n                pkt.data= bit_buffer;\n\n                pkt.size= ret;\n\n                if(enc->coded_frame->pts != AV_NOPTS_VALUE)\n\n                    pkt.pts= av_rescale_q(enc->coded_frame->pts, enc->time_base, ost->st->time_base);\n\n/*av_log(NULL, AV_LOG_DEBUG, \"encoder -> %\"PRId64\"/%\"PRId64\"\\n\",\n\n   pkt.pts != AV_NOPTS_VALUE ? av_rescale(pkt.pts, enc->time_base.den, AV_TIME_BASE*(int64_t)enc->time_base.num) : -1,\n\n   pkt.dts != AV_NOPTS_VALUE ? av_rescale(pkt.dts, enc->time_base.den, AV_TIME_BASE*(int64_t)enc->time_base.num) : -1);*/\n\n\n\n                if(enc->coded_frame->key_frame)\n\n                    pkt.flags |= PKT_FLAG_KEY;\n\n                write_frame(s, &pkt, ost->st->codec, bitstream_filters[ost->file_index][pkt.stream_index]);\n\n                *frame_size = ret;\n\n                video_size += ret;\n\n                //fprintf(stderr,\"\\nFrame: %3d %3d size: %5d type: %d\",\n\n                //        enc->frame_number-1, enc->real_pict_num, ret,\n\n                //        enc->pict_type);\n\n                /* if two pass, output log */\n\n                if (ost->logfile && enc->stats_out) {\n\n                    fprintf(ost->logfile, \"%s\", enc->stats_out);\n\n                }\n\n            }\n\n        }\n\n        ost->sync_opts++;\n\n        ost->frame_number++;\n\n    }\n\n}\n", "idx": 26900}
{"project": "FFmpeg", "commit_id": "f8cab062caacba2982a0d0bccd504b11c073caf6", "target": 0, "func": "static int process_ea_header(AVFormatContext *s) {\n\n    uint32_t blockid, size = 0;\n\n    EaDemuxContext *ea = s->priv_data;\n\n    ByteIOContext *pb = &s->pb;\n\n\n\n    blockid = get_le32(pb);\n\n    if (blockid == MVhd_TAG) {\n\n        size = get_le32(pb);\n\n        process_video_header_vp6(s);\n\n        url_fskip(pb, size-32);\n\n        blockid = get_le32(pb);\n\n    }\n\n    if (blockid != SCHl_TAG)\n\n        return 0;\n\n    size += get_le32(pb);\n\n    blockid = get_le32(pb);\n\n    if (blockid == GSTR_TAG) {\n\n        url_fskip(pb, 4);\n\n    } else if (blockid != PT00_TAG) {\n\n        av_log (s, AV_LOG_ERROR, \"unknown SCHl headerid\\n\");\n\n        return 0;\n\n    }\n\n\n\n    process_audio_header_elements(s);\n\n\n\n    /* skip to the start of the data */\n\n    url_fseek(pb, size, SEEK_SET);\n\n\n\n    return 1;\n\n}\n", "idx": 26910}
{"project": "FFmpeg", "commit_id": "daece4c6745b42e8b1e171fb4bf485d5d64fc53f", "target": 0, "func": "static void check_external_clock_sync(VideoState *is, double pts) {\n\n    if (fabs(get_external_clock(is) - pts) > AV_NOSYNC_THRESHOLD) {\n\n        update_external_clock_pts(is, pts);\n\n    }\n\n}\n", "idx": 26911}
{"project": "FFmpeg", "commit_id": "fd6e513ee1dc13174256de8adaeeb2c2691eee95", "target": 1, "func": "static int mov_read_stsd(MOVContext *c, ByteIOContext *pb, MOV_atom_t atom)\n\n{\n\n    AVStream *st = c->fc->streams[c->fc->nb_streams-1];\n\n    MOVStreamContext *sc = (MOVStreamContext *)st->priv_data;\n\n    int entries, frames_per_sample;\n\n    uint32_t format;\n\n\n\n    print_atom(\"stsd\", atom);\n\n\n\n    get_byte(pb); /* version */\n\n    get_byte(pb); get_byte(pb); get_byte(pb); /* flags */\n\n\n\n    entries = get_be32(pb);\n\n\n\n    while(entries--) {\n\n        enum CodecID id;\n\n\tint size = get_be32(pb); /* size */\n\n        format = get_le32(pb); /* data format */\n\n\n\n        get_be32(pb); /* reserved */\n\n        get_be16(pb); /* reserved */\n\n        get_be16(pb); /* index */\n\n\n\n        /* for MPEG4: set codec type by looking for it */\n\n        id = codec_get_id(mov_video_tags, format);\n\n        if (id >= 0) {\n\n            AVCodec *codec;\n\n\t    codec = avcodec_find_decoder(id);\n\n            if (codec)\n\n\t\tst->codec.codec_type = codec->type;\n\n        }\n\n#ifdef DEBUG\n\n        printf(\"size=%d 4CC= %c%c%c%c codec_type=%d\\n\",\n\n               size,\n\n               (format >> 0) & 0xff,\n\n               (format >> 8) & 0xff,\n\n               (format >> 16) & 0xff,\n\n               (format >> 24) & 0xff,\n\n               st->codec.codec_type);\n\n#endif\n\n\tst->codec.codec_tag = format;\n\n\tif(st->codec.codec_type==CODEC_TYPE_VIDEO) {\n\n\t    MOV_atom_t a = { 0, 0, 0 };\n\n            st->codec.codec_id = id;\n\n            get_be16(pb); /* version */\n\n            get_be16(pb); /* revision level */\n\n            get_be32(pb); /* vendor */\n\n            get_be32(pb); /* temporal quality */\n\n            get_be32(pb); /* spacial quality */\n\n            st->codec.width = get_be16(pb); /* width */\n\n            st->codec.height = get_be16(pb); /* height */\n\n#if 1\n\n            if (st->codec.codec_id == CODEC_ID_MPEG4) {\n\n                /* in some MPEG4 the width/height are not correct, so\n\n                   we ignore this info */\n\n                st->codec.width = 0;\n\n                st->codec.height = 0;\n\n            }\n\n#endif\n\n            get_be32(pb); /* horiz resolution */\n\n            get_be32(pb); /* vert resolution */\n\n            get_be32(pb); /* data size, always 0 */\n\n            frames_per_sample = get_be16(pb); /* frames per samples */\n\n#ifdef DEBUG\n\n\t    printf(\"frames/samples = %d\\n\", frames_per_sample);\n\n#endif\n\n\t    get_buffer(pb, (uint8_t *)st->codec.codec_name, 32); /* codec name */\n\n\n\n\t    st->codec.bits_per_sample = get_be16(pb); /* depth */\n\n            st->codec.color_table_id = get_be16(pb); /* colortable id */\n\n\n\n            st->codec.frame_rate      = 25;\n\n            st->codec.frame_rate_base = 1;\n\n\n\n\t    size -= (16+8*4+2+32+2*2);\n\n#if 0\n\n\t    while (size >= 8) {\n\n\t\tMOV_atom_t a;\n\n                int64_t start_pos;\n\n\n\n\t\ta.size = get_be32(pb);\n\n\t\ta.type = get_le32(pb);\n\n\t\tsize -= 8;\n\n#ifdef DEBUG\n\n                printf(\"VIDEO: atom_type=%c%c%c%c atom.size=%Ld size_left=%d\\n\",\n\n                       (a.type >> 0) & 0xff,\n\n                       (a.type >> 8) & 0xff,\n\n                       (a.type >> 16) & 0xff,\n\n                       (a.type >> 24) & 0xff,\n\n\t\t       a.size, size);\n\n#endif\n\n                start_pos = url_ftell(pb);\n\n\n\n\t\tswitch(a.type) {\n\n                case MKTAG('e', 's', 'd', 's'):\n\n                    {\n\n                        int tag, len;\n\n                        /* Well, broken but suffisant for some MP4 streams */\n\n                        get_be32(pb); /* version + flags */\n\n\t\t\tlen = mov_mp4_read_descr(pb, &tag);\n\n                        if (tag == 0x03) {\n\n                            /* MP4ESDescrTag */\n\n                            get_be16(pb); /* ID */\n\n                            get_byte(pb); /* priority */\n\n\t\t\t    len = mov_mp4_read_descr(pb, &tag);\n\n                            if (tag != 0x04)\n\n                                goto fail;\n\n                            /* MP4DecConfigDescrTag */\n\n                            get_byte(pb); /* objectTypeId */\n\n                            get_be32(pb); /* streamType + buffer size */\n\n\t\t\t    get_be32(pb); /* max bit rate */\n\n                            get_be32(pb); /* avg bit rate */\n\n                            len = mp4_read_descr(pb, &tag);\n\n                            if (tag != 0x05)\n\n                                goto fail;\n\n                            /* MP4DecSpecificDescrTag */\n\n#ifdef DEBUG\n\n                            printf(\"Specific MPEG4 header len=%d\\n\", len);\n\n#endif\n\n                            sc->header_data = av_mallocz(len);\n\n                            if (sc->header_data) {\n\n                                get_buffer(pb, sc->header_data, len);\n\n\t\t\t\tsc->header_len = len;\n\n                            }\n\n                        }\n\n                        /* in any case, skip garbage */\n\n                    }\n\n                    break;\n\n                default:\n\n                    break;\n\n                }\n\n\t    fail:\n\n\t\tprintf(\"ATOMENEWSIZE %Ld   %d\\n\", atom.size, url_ftell(pb) - start_pos);\n\n\t\tif (atom.size > 8) {\n\n\t\t    url_fskip(pb, (atom.size - 8) -\n\n\t\t\t      ((url_ftell(pb) - start_pos)));\n\n\t\t    size -= atom.size - 8;\n\n\t\t}\n\n\t    }\n\n            if (size > 0) {\n\n                /* unknown extension */\n\n                url_fskip(pb, size);\n\n            }\n\n#else\n\n            a.size = size;\n\n\t    mov_read_default(c, pb, a);\n\n#endif\n\n\t} else {\n\n            get_be16(pb); /* version */\n\n            get_be16(pb); /* revision level */\n\n            get_be32(pb); /* vendor */\n\n\n\n            st->codec.channels = get_be16(pb);\t\t/* channel count */\n\n\t    st->codec.bits_per_sample = get_be16(pb);\t/* sample size */\n\n\n\n\t    st->codec.codec_id = codec_get_id(mov_audio_tags, format);\n\n            /* handle specific s8 codec */\n\n            get_be16(pb); /* compression id = 0*/\n\n            get_be16(pb); /* packet size = 0 */\n\n\n\n            st->codec.sample_rate = ((get_be32(pb) >> 16));\n\n\t    //printf(\"CODECID %d  %d  %.4s\\n\", st->codec.codec_id, CODEC_ID_PCM_S16BE, (char*)&format);\n\n\n\n\t    switch (st->codec.codec_id) {\n\n\t    case CODEC_ID_PCM_S16BE:\n\n\t\tif (st->codec.bits_per_sample == 8)\n\n\t\t    st->codec.codec_id = CODEC_ID_PCM_S8;\n\n                /* fall */\n\n\t    case CODEC_ID_PCM_U8:\n\n\t\tst->codec.bit_rate = st->codec.sample_rate * 8;\n\n\t\tbreak;\n\n\t    default:\n\n                ;\n\n\t    }\n\n\t    get_be32(pb); /* samples per packet */\n\n\t    get_be32(pb); /* bytes per packet */\n\n            get_be32(pb); /* bytes per frame */\n\n            get_be32(pb); /* bytes per sample */\n\n\n\n\t    {\n\n\t\tMOV_atom_t a = { format, url_ftell(pb), size - (16 + 20 + 16 + 8) };\n\n\t\tmov_read_default(c, pb, a);\n\n\t    }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26913}
{"project": "FFmpeg", "commit_id": "574929d8b6de32ae712fcca7ab09f01a3e4616be", "target": 1, "func": "int av_packet_add_side_data(AVPacket *pkt, enum AVPacketSideDataType type,\n\n                            uint8_t *data, size_t size)\n\n{\n\n    int elems = pkt->side_data_elems;\n\n\n\n    if ((unsigned)elems + 1 > INT_MAX / sizeof(*pkt->side_data))\n\n        return AVERROR(ERANGE);\n\n\n\n    pkt->side_data = av_realloc(pkt->side_data,\n\n                                (elems + 1) * sizeof(*pkt->side_data));\n\n    if (!pkt->side_data)\n\n        return AVERROR(ENOMEM);\n\n\n\n    pkt->side_data[elems].data = data;\n\n    pkt->side_data[elems].size = size;\n\n    pkt->side_data[elems].type = type;\n\n    pkt->side_data_elems++;\n\n\n\n    return 0;\n\n}\n", "idx": 26917}
{"project": "FFmpeg", "commit_id": "628c9dcca3fb3f46f960f0df8236591653c6e512", "target": 1, "func": "static int get_siz(J2kDecoderContext *s)\n{\n    int i, ret;\n    if (s->buf_end - s->buf < 36)\n                        bytestream_get_be16(&s->buf); // Rsiz (skipped)\n             s->width = bytestream_get_be32(&s->buf); // width\n            s->height = bytestream_get_be32(&s->buf); // height\n    s->image_offset_x = bytestream_get_be32(&s->buf); // X0Siz\n    s->image_offset_y = bytestream_get_be32(&s->buf); // Y0Siz\n        s->tile_width = bytestream_get_be32(&s->buf); // XTSiz\n       s->tile_height = bytestream_get_be32(&s->buf); // YTSiz\n     s->tile_offset_x = bytestream_get_be32(&s->buf); // XT0Siz\n     s->tile_offset_y = bytestream_get_be32(&s->buf); // YT0Siz\n       s->ncomponents = bytestream_get_be16(&s->buf); // CSiz\n    if (s->buf_end - s->buf < 2 * s->ncomponents)\n    for (i = 0; i < s->ncomponents; i++){ // Ssiz_i XRsiz_i, YRsiz_i\n        uint8_t x = bytestream_get_byte(&s->buf);\n        s->cbps[i] = (x & 0x7f) + 1;\n        s->precision = FFMAX(s->cbps[i], s->precision);\n        s->sgnd[i] = !!(x & 0x80);\n        s->cdx[i] = bytestream_get_byte(&s->buf);\n        s->cdy[i] = bytestream_get_byte(&s->buf);\n    }\n    s->numXtiles = ff_j2k_ceildiv(s->width - s->tile_offset_x, s->tile_width);\n    s->numYtiles = ff_j2k_ceildiv(s->height - s->tile_offset_y, s->tile_height);\n    s->tile = av_mallocz(s->numXtiles * s->numYtiles * sizeof(J2kTile));\n    if (!s->tile)\n        return AVERROR(ENOMEM);\n    for (i = 0; i < s->numXtiles * s->numYtiles; i++){\n        J2kTile *tile = s->tile + i;\n        tile->comp = av_mallocz(s->ncomponents * sizeof(J2kComponent));\n        if (!tile->comp)\n            return AVERROR(ENOMEM);\n    }\n    s->avctx->width = s->width - s->image_offset_x;\n    s->avctx->height = s->height - s->image_offset_y;\n    switch(s->ncomponents){\n        case 1: if (s->precision > 8) {\n                    s->avctx->pix_fmt    = PIX_FMT_GRAY16;\n                } else s->avctx->pix_fmt = PIX_FMT_GRAY8;\n                break;\n        case 3: if (s->precision > 8) {\n                    s->avctx->pix_fmt    = PIX_FMT_RGB48;\n                } else s->avctx->pix_fmt = PIX_FMT_RGB24;\n                break;\n        case 4: s->avctx->pix_fmt = PIX_FMT_BGRA; break;\n    }\n    if (s->picture.data[0])\n        s->avctx->release_buffer(s->avctx, &s->picture);\n    if ((ret = s->avctx->get_buffer(s->avctx, &s->picture)) < 0)\n        return ret;\n    s->picture.pict_type = FF_I_TYPE;\n    s->picture.key_frame = 1;\n    return 0;\n}", "idx": 26921}
{"project": "FFmpeg", "commit_id": "d9fe1749fc1009b14252030dda9142de624670c0", "target": 1, "func": "static int decode_ref_pic_marking(H264Context *h, GetBitContext *gb){\n\n    MpegEncContext * const s = &h->s;\n\n    int i;\n\n\n\n\n    if(h->nal_unit_type == NAL_IDR_SLICE){ //FIXME fields\n\n        s->broken_link= get_bits1(gb) -1;\n\n        h->mmco[0].long_arg= get_bits1(gb) - 1; // current_long_term_idx\n\n        if(h->mmco[0].long_arg == -1)\n\n\n        else{\n\n            h->mmco[0].opcode= MMCO_LONG;\n\n            h->mmco_index= 1;\n\n        }\n\n    }else{\n\n        if(get_bits1(gb)){ // adaptive_ref_pic_marking_mode_flag\n\n            for(i= 0; i<MAX_MMCO_COUNT; i++) {\n\n                MMCOOpcode opcode= get_ue_golomb(gb);\n\n\n\n                h->mmco[i].opcode= opcode;\n\n                if(opcode==MMCO_SHORT2UNUSED || opcode==MMCO_SHORT2LONG){\n\n                    h->mmco[i].short_pic_num= (h->curr_pic_num - get_ue_golomb(gb) - 1) & (h->max_pic_num - 1);\n\n/*                    if(h->mmco[i].short_pic_num >= h->short_ref_count || h->short_ref[ h->mmco[i].short_pic_num ] == NULL){\n\n                        av_log(s->avctx, AV_LOG_ERROR, \"illegal short ref in memory management control operation %d\\n\", mmco);\n\n                        return -1;\n\n                    }*/\n\n                }\n\n                if(opcode==MMCO_SHORT2LONG || opcode==MMCO_LONG2UNUSED || opcode==MMCO_LONG || opcode==MMCO_SET_MAX_LONG){\n\n                    unsigned int long_arg= get_ue_golomb(gb);\n\n                    if(long_arg >= 32 || (long_arg >= 16 && !(opcode == MMCO_LONG2UNUSED && FIELD_PICTURE))){\n\n                        av_log(h->s.avctx, AV_LOG_ERROR, \"illegal long ref in memory management control operation %d\\n\", opcode);\n\n                        return -1;\n\n                    }\n\n                    h->mmco[i].long_arg= long_arg;\n\n                }\n\n\n\n                if(opcode > (unsigned)MMCO_LONG){\n\n                    av_log(h->s.avctx, AV_LOG_ERROR, \"illegal memory management control operation %d\\n\", opcode);\n\n                    return -1;\n\n                }\n\n                if(opcode == MMCO_END)\n\n                    break;\n\n            }\n\n            h->mmco_index= i;\n\n        }else{\n\n            assert(h->long_ref_count + h->short_ref_count <= h->sps.ref_frame_count);\n\n\n\n            if(h->short_ref_count && h->long_ref_count + h->short_ref_count == h->sps.ref_frame_count &&\n\n                    !(FIELD_PICTURE && !s->first_field && s->current_picture_ptr->reference)) {\n\n                h->mmco[0].opcode= MMCO_SHORT2UNUSED;\n\n                h->mmco[0].short_pic_num= h->short_ref[ h->short_ref_count - 1 ]->frame_num;\n\n                h->mmco_index= 1;\n\n                if (FIELD_PICTURE) {\n\n                    h->mmco[0].short_pic_num *= 2;\n\n                    h->mmco[1].opcode= MMCO_SHORT2UNUSED;\n\n                    h->mmco[1].short_pic_num= h->mmco[0].short_pic_num + 1;\n\n                    h->mmco_index= 2;\n\n                }\n\n            }else\n\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}", "idx": 26922}
{"project": "FFmpeg", "commit_id": "5d97d9d53ea1cc2c28411ad734565372ddeccc32", "target": 1, "func": "static int decode_main_header(NUTContext *nut){\n\n    AVFormatContext *s= nut->avf;\n\n    ByteIOContext *bc = &s->pb;\n\n    uint64_t tmp, end;\n\n    unsigned int stream_count;\n\n    int i, j, tmp_stream, tmp_mul, tmp_pts, tmp_size, count, tmp_res;\n\n\n\n    end= get_packetheader(nut, bc, 1);\n\n    end += url_ftell(bc) - 4;\n\n\n\n    GET_V(tmp              , tmp >=2 && tmp <= 3)\n\n    GET_V(stream_count     , tmp > 0 && tmp <=MAX_STREAMS)\n\n\n\n    nut->max_distance = get_v(bc);\n\n    if(nut->max_distance > 65536){\n\n        av_log(s, AV_LOG_DEBUG, \"max_distance %d\\n\", nut->max_distance);\n\n        nut->max_distance= 65536;\n\n    }\n\n\n\n    GET_V(nut->time_base_count, tmp>0 && tmp<INT_MAX / sizeof(AVRational))\n\n    nut->time_base= av_malloc(nut->time_base_count * sizeof(AVRational));\n\n\n\n    for(i=0; i<nut->time_base_count; i++){\n\n        GET_V(nut->time_base[i].num, tmp>0 && tmp<(1ULL<<31))\n\n        GET_V(nut->time_base[i].den, tmp>0 && tmp<(1ULL<<31))\n\n        if(ff_gcd(nut->time_base[i].num, nut->time_base[i].den) != 1){\n\n            av_log(s, AV_LOG_ERROR, \"time base invalid\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n    tmp_pts=0;\n\n    tmp_mul=1;\n\n    tmp_stream=0;\n\n    for(i=0; i<256;){\n\n        int tmp_flags = get_v(bc);\n\n        int tmp_fields= get_v(bc);\n\n        if(tmp_fields>0) tmp_pts   = get_s(bc);\n\n        if(tmp_fields>1) tmp_mul   = get_v(bc);\n\n        if(tmp_fields>2) tmp_stream= get_v(bc);\n\n        if(tmp_fields>3) tmp_size  = get_v(bc);\n\n        else             tmp_size  = 0;\n\n        if(tmp_fields>4) tmp_res   = get_v(bc);\n\n        else             tmp_res   = 0;\n\n        if(tmp_fields>5) count     = get_v(bc);\n\n        else             count     = tmp_mul - tmp_size;\n\n\n\n        while(tmp_fields-- > 6)\n\n           get_v(bc);\n\n\n\n        if(count == 0 || i+count > 256){\n\n            av_log(s, AV_LOG_ERROR, \"illegal count %d at %d\\n\", count, i);\n\n            return -1;\n\n        }\n\n        if(tmp_stream >= stream_count){\n\n            av_log(s, AV_LOG_ERROR, \"illegal stream number\\n\");\n\n            return -1;\n\n        }\n\n\n\n        for(j=0; j<count; j++,i++){\n\n            if (i == 'N') {\n\n                nut->frame_code[i].flags= FLAG_INVALID;\n\n                j--;\n\n                continue;\n\n            }\n\n            nut->frame_code[i].flags           = tmp_flags ;\n\n            nut->frame_code[i].pts_delta       = tmp_pts   ;\n\n            nut->frame_code[i].stream_id       = tmp_stream;\n\n            nut->frame_code[i].size_mul        = tmp_mul   ;\n\n            nut->frame_code[i].size_lsb        = tmp_size+j;\n\n            nut->frame_code[i].reserved_count  = tmp_res   ;\n\n        }\n\n    }\n\n    assert(nut->frame_code['N'].flags == FLAG_INVALID);\n\n\n\n    if(skip_reserved(bc, end) || check_checksum(bc)){\n\n        av_log(s, AV_LOG_ERROR, \"Main header checksum mismatch\\n\");\n\n        return -1;\n\n    }\n\n\n\n    nut->stream = av_mallocz(sizeof(StreamContext)*stream_count);\n\n    for(i=0; i<stream_count; i++){\n\n        av_new_stream(s, i);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26923}
{"project": "FFmpeg", "commit_id": "22cc57da64bfd73f2206969486b0aa183ee76479", "target": 1, "func": "static void enqueue_packet(RTPDemuxContext *s, uint8_t *buf, int len)\n\n{\n\n    uint16_t seq   = AV_RB16(buf + 2);\n\n    RTPPacket **cur = &s->queue, *packet;\n\n\n\n    /* Find the correct place in the queue to insert the packet */\n\n    while (*cur) {\n\n        int16_t diff = seq - (*cur)->seq;\n\n        if (diff < 0)\n\n            break;\n\n        cur = &(*cur)->next;\n\n    }\n\n\n\n    packet = av_mallocz(sizeof(*packet));\n\n    if (!packet)\n\n        return;\n\n    packet->recvtime = av_gettime_relative();\n\n    packet->seq      = seq;\n\n    packet->len      = len;\n\n    packet->buf      = buf;\n\n    packet->next     = *cur;\n\n    *cur = packet;\n\n    s->queue_len++;\n\n}\n", "idx": 26926}
{"project": "FFmpeg", "commit_id": "432f1f11ea7f95b1c1f1adb546151f09c1d7a932", "target": 0, "func": "int ff_rv34_decode_frame(AVCodecContext *avctx,\n\n                            void *data, int *data_size,\n\n                            const uint8_t *buf, int buf_size)\n\n{\n\n    RV34DecContext *r = avctx->priv_data;\n\n    MpegEncContext *s = &r->s;\n\n    AVFrame *pict = data;\n\n    SliceInfo si;\n\n    int i;\n\n    int slice_count;\n\n    const uint8_t *slices_hdr = NULL;\n\n    int last = 0;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0) {\n\n        /* special case for last picture */\n\n        if (s->low_delay==0 && s->next_picture_ptr) {\n\n            *pict= *(AVFrame*)s->next_picture_ptr;\n\n            s->next_picture_ptr= NULL;\n\n\n\n            *data_size = sizeof(AVFrame);\n\n        }\n\n        return 0;\n\n    }\n\n\n\n    if(!avctx->slice_count){\n\n        slice_count = (*buf++) + 1;\n\n        slices_hdr = buf + 4;\n\n        buf += 8 * slice_count;\n\n    }else\n\n        slice_count = avctx->slice_count;\n\n\n\n    for(i=0; i<slice_count; i++){\n\n        int offset= get_slice_offset(avctx, slices_hdr, i);\n\n        int size;\n\n        if(i+1 == slice_count)\n\n            size= buf_size - offset;\n\n        else\n\n            size= get_slice_offset(avctx, slices_hdr, i+1) - offset;\n\n\n\n        if(offset > buf_size){\n\n            av_log(avctx, AV_LOG_ERROR, \"Slice offset is greater than frame size\\n\");\n\n            break;\n\n        }\n\n\n\n        r->si.end = s->mb_width * s->mb_height;\n\n        if(i+1 < slice_count){\n\n            init_get_bits(&s->gb, buf+get_slice_offset(avctx, slices_hdr, i+1), (buf_size-get_slice_offset(avctx, slices_hdr, i+1))*8);\n\n            if(r->parse_slice_header(r, &r->s.gb, &si) < 0){\n\n                if(i+2 < slice_count)\n\n                    size = get_slice_offset(avctx, slices_hdr, i+2) - offset;\n\n                else\n\n                    size = buf_size - offset;\n\n            }else\n\n                r->si.end = si.start;\n\n        }\n\n        if(!i && si.type == FF_B_TYPE && (!s->last_picture_ptr || !s->last_picture_ptr->data[0]))\n\n            return -1;\n\n        last = rv34_decode_slice(r, r->si.end, buf + offset, size);\n\n        s->mb_num_left = r->s.mb_x + r->s.mb_y*r->s.mb_width - r->si.start;\n\n        if(last)\n\n            break;\n\n    }\n\n\n\n    if(last){\n\n        if(r->loop_filter)\n\n            r->loop_filter(r, s->mb_height - 1);\n\n        ff_er_frame_end(s);\n\n        MPV_frame_end(s);\n\n        if (s->pict_type == FF_B_TYPE || s->low_delay) {\n\n            *pict= *(AVFrame*)s->current_picture_ptr;\n\n        } else if (s->last_picture_ptr != NULL) {\n\n            *pict= *(AVFrame*)s->last_picture_ptr;\n\n        }\n\n\n\n        if(s->last_picture_ptr || s->low_delay){\n\n            *data_size = sizeof(AVFrame);\n\n            ff_print_debug_info(s, pict);\n\n        }\n\n        s->current_picture_ptr= NULL; //so we can detect if frame_end wasnt called (find some nicer solution...)\n\n    }\n\n    return buf_size;\n\n}\n", "idx": 26927}
{"project": "FFmpeg", "commit_id": "802713c4e7b41bc2deed754d78649945c3442063", "target": 1, "func": "static av_cold int mss2_decode_init(AVCodecContext *avctx)\n\n{\n\n    MSS2Context * const ctx = avctx->priv_data;\n\n    MSS12Context *c = &ctx->c;\n\n    int ret;\n\n    c->avctx = avctx;\n\n    avctx->coded_frame = &ctx->pic;\n\n    if (ret = ff_mss12_decode_init(c, 1, &ctx->sc[0], &ctx->sc[1]))\n\n        return ret;\n\n    c->pal_stride   = c->mask_stride;\n\n    c->pal_pic      = av_malloc(c->pal_stride * avctx->height);\n\n    c->last_pal_pic = av_malloc(c->pal_stride * avctx->height);\n\n    if (!c->pal_pic || !c->last_pal_pic) {\n\n        mss2_decode_end(avctx);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    if (ret = wmv9_init(avctx)) {\n\n        mss2_decode_end(avctx);\n\n        return ret;\n\n    }\n\n    ff_mss2dsp_init(&ctx->dsp);\n\n\n\n    avctx->pix_fmt = c->free_colours == 127 ? AV_PIX_FMT_RGB555\n\n                                            : AV_PIX_FMT_RGB24;\n\n\n\n    return 0;\n\n}\n", "idx": 26928}
{"project": "FFmpeg", "commit_id": "25e3e53d4092e7b69a4d681824fa0f7b2731bb1e", "target": 1, "func": "static void build_file_streams(void)\n\n{\n\n    FFStream *stream, *stream_next;\n\n    AVFormatContext *infile;\n\n    int i;\n\n\n\n    /* gather all streams */\n\n    for(stream = first_stream; stream != NULL; stream = stream_next) {\n\n        stream_next = stream->next;\n\n        if (stream->stream_type == STREAM_TYPE_LIVE &&\n\n            !stream->feed) {\n\n            /* the stream comes from a file */\n\n            /* try to open the file */\n\n            /* open stream */\n\n            stream->ap_in = av_mallocz(sizeof(AVFormatParameters));\n\n            if (!strcmp(stream->fmt->name, \"rtp\")) {\n\n                /* specific case : if transport stream output to RTP,\n\n                   we use a raw transport stream reader */\n\n                stream->ap_in->mpeg2ts_raw = 1;\n\n                stream->ap_in->mpeg2ts_compute_pcr = 1;\n\n            }\n\n\n\n            if (av_open_input_file(&infile, stream->feed_filename,\n\n                                   stream->ifmt, 0, stream->ap_in) < 0) {\n\n                http_log(\"%s not found\", stream->feed_filename);\n\n                /* remove stream (no need to spend more time on it) */\n\n            fail:\n\n                remove_stream(stream);\n\n            } else {\n\n                /* find all the AVStreams inside and reference them in\n\n                   'stream' */\n\n                if (av_find_stream_info(infile) < 0) {\n\n                    http_log(\"Could not find codec parameters from '%s'\",\n\n                             stream->feed_filename);\n\n                    av_close_input_file(infile);\n\n                    goto fail;\n\n                }\n\n                extract_mpeg4_header(infile);\n\n\n\n                for(i=0;i<infile->nb_streams;i++)\n\n                    add_av_stream1(stream, infile->streams[i]->codec);\n\n\n\n                av_close_input_file(infile);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 26929}
{"project": "FFmpeg", "commit_id": "ca16618b01abfde44b4eaf92dc89b01aa1b4a91e", "target": 0, "func": "static void xan_unpack(unsigned char *dest, unsigned char *src)\n\n{\n\n    unsigned char opcode;\n\n    int size;\n\n    int offset;\n\n    int byte1, byte2, byte3;\n\n\n\n    for (;;) {\n\n        opcode = *src++;\n\n\n\n        if ( (opcode & 0x80) == 0 ) {\n\n\n\n            offset = *src++;\n\n\n\n            size = opcode & 3;\n\n            bytecopy(dest, src, size);  dest += size;  src += size;\n\n\n\n            size = ((opcode & 0x1c) >> 2) + 3;\n\n            bytecopy (dest, dest - (((opcode & 0x60) << 3) + offset + 1), size);\n\n            dest += size;\n\n\n\n        } else if ( (opcode & 0x40) == 0 ) {\n\n\n\n            byte1 = *src++;\n\n            byte2 = *src++;\n\n\n\n            size = byte1 >> 6;\n\n            bytecopy (dest, src, size);  dest += size;  src += size;\n\n\n\n            size = (opcode & 0x3f) + 4;\n\n            bytecopy (dest, dest - (((byte1 & 0x3f) << 8) + byte2 + 1), size);\n\n            dest += size;\n\n\n\n        } else if ( (opcode & 0x20) == 0 ) {\n\n\n\n            byte1 = *src++;\n\n            byte2 = *src++;\n\n            byte3 = *src++;\n\n\n\n            size = opcode & 3;\n\n            bytecopy (dest, src, size);  dest += size;  src += size;\n\n\n\n            size = byte3 + 5 + ((opcode & 0xc) << 6);\n\n            bytecopy (dest,\n\n                dest - ((((opcode & 0x10) >> 4) << 0x10) + 1 + (byte1 << 8) + byte2),\n\n                size);\n\n            dest += size;\n\n        } else {\n\n            size = ((opcode & 0x1f) << 2) + 4;\n\n\n\n            if (size > 0x70)\n\n                break;\n\n\n\n            bytecopy (dest, src, size);  dest += size;  src += size;\n\n        }\n\n    }\n\n\n\n    size = opcode & 3;\n\n    bytecopy(dest, src, size);  dest += size;  src += size;\n\n}\n", "idx": 26936}
{"project": "FFmpeg", "commit_id": "39f7620d76c7a133535ed7a535f7a74fefa6e435", "target": 0, "func": "static av_cold int dcadec_init(AVCodecContext *avctx)\n\n{\n\n    DCAContext *s = avctx->priv_data;\n\n\n\n    s->avctx = avctx;\n\n    s->core.avctx = avctx;\n\n    s->exss.avctx = avctx;\n\n    s->xll.avctx = avctx;\n\n    s->lbr.avctx = avctx;\n\n\n\n    ff_dca_init_vlcs();\n\n\n\n    if (ff_dca_core_init(&s->core) < 0)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if (ff_dca_lbr_init(&s->lbr) < 0)\n\n        return AVERROR(ENOMEM);\n\n\n\n    ff_dcadsp_init(&s->dcadsp);\n\n    s->core.dcadsp = &s->dcadsp;\n\n    s->xll.dcadsp = &s->dcadsp;\n\n    s->lbr.dcadsp = &s->dcadsp;\n\n\n\n    s->crctab = av_crc_get_table(AV_CRC_16_CCITT);\n\n\n\n    switch (avctx->request_channel_layout & ~AV_CH_LAYOUT_NATIVE) {\n\n    case 0:\n\n        s->request_channel_layout = 0;\n\n        break;\n\n    case AV_CH_LAYOUT_STEREO:\n\n    case AV_CH_LAYOUT_STEREO_DOWNMIX:\n\n        s->request_channel_layout = DCA_SPEAKER_LAYOUT_STEREO;\n\n        break;\n\n    case AV_CH_LAYOUT_5POINT0:\n\n        s->request_channel_layout = DCA_SPEAKER_LAYOUT_5POINT0;\n\n        break;\n\n    case AV_CH_LAYOUT_5POINT1:\n\n        s->request_channel_layout = DCA_SPEAKER_LAYOUT_5POINT1;\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_WARNING, \"Invalid request_channel_layout\\n\");\n\n        break;\n\n    }\n\n\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_S32P;\n\n    avctx->bits_per_raw_sample = 24;\n\n\n\n    return 0;\n\n}\n", "idx": 26947}
{"project": "FFmpeg", "commit_id": "0d194ee51ed477f843900e657a7edbcbecdffa42", "target": 0, "func": "static void vc1_decode_b_mb_intfi(VC1Context *v)\n\n{\n\n    MpegEncContext *s = &v->s;\n\n    GetBitContext *gb = &s->gb;\n\n    int i, j;\n\n    int mb_pos = s->mb_x + s->mb_y * s->mb_stride;\n\n    int cbp = 0; /* cbp decoding stuff */\n\n    int mqdiff, mquant; /* MB quantization */\n\n    int ttmb = v->ttfrm; /* MB Transform type */\n\n    int mb_has_coeffs = 0; /* last_flag */\n\n    int val; /* temp value */\n\n    int first_block = 1;\n\n    int dst_idx, off;\n\n    int fwd;\n\n    int dmv_x[2], dmv_y[2], pred_flag[2];\n\n    int bmvtype = BMV_TYPE_BACKWARD;\n\n    int idx_mbmode, interpmvp;\n\n\n\n    mquant      = v->pq; /* Lossy initialization */\n\n    s->mb_intra = 0;\n\n\n\n    idx_mbmode = get_vlc2(gb, v->mbmode_vlc->table, VC1_IF_MBMODE_VLC_BITS, 2);\n\n    if (idx_mbmode <= 1) { // intra MB\n\n        s->mb_intra = v->is_intra[s->mb_x] = 1;\n\n        s->current_picture.f.motion_val[1][s->block_index[0]][0] = 0;\n\n        s->current_picture.f.motion_val[1][s->block_index[0]][1] = 0;\n\n        s->current_picture.f.mb_type[mb_pos + v->mb_off]         = MB_TYPE_INTRA;\n\n        GET_MQUANT();\n\n        s->current_picture.f.qscale_table[mb_pos] = mquant;\n\n        /* Set DC scale - y and c use the same (not sure if necessary here) */\n\n        s->y_dc_scale = s->y_dc_scale_table[mquant];\n\n        s->c_dc_scale = s->c_dc_scale_table[mquant];\n\n        v->s.ac_pred  = v->acpred_plane[mb_pos] = get_bits1(gb);\n\n        mb_has_coeffs = idx_mbmode & 1;\n\n        if (mb_has_coeffs)\n\n            cbp = 1 + get_vlc2(&v->s.gb, v->cbpcy_vlc->table, VC1_ICBPCY_VLC_BITS, 2);\n\n        dst_idx = 0;\n\n        for (i = 0; i < 6; i++) {\n\n            s->dc_val[0][s->block_index[i]] = 0;\n\n            dst_idx += i >> 2;\n\n            val = ((cbp >> (5 - i)) & 1);\n\n            v->mb_type[0][s->block_index[i]] = s->mb_intra;\n\n            v->a_avail                       = v->c_avail = 0;\n\n            if (i == 2 || i == 3 || !s->first_slice_line)\n\n                v->a_avail = v->mb_type[0][s->block_index[i] - s->block_wrap[i]];\n\n            if (i == 1 || i == 3 || s->mb_x)\n\n                v->c_avail = v->mb_type[0][s->block_index[i] - 1];\n\n\n\n            vc1_decode_intra_block(v, s->block[i], i, val, mquant,\n\n                                   (i & 4) ? v->codingset2 : v->codingset);\n\n            if ((i>3) && (s->flags & CODEC_FLAG_GRAY))\n\n                continue;\n\n            v->vc1dsp.vc1_inv_trans_8x8(s->block[i]);\n\n            if (v->rangeredfrm)\n\n                for (j = 0; j < 64; j++)\n\n                    s->block[i][j] <<= 1;\n\n            off  = (i & 4) ? 0 : ((i & 1) * 8 + (i & 2) * 4 * s->linesize);\n\n            off += v->second_field ? ((i & 4) ? s->current_picture_ptr->f.linesize[1] : s->current_picture_ptr->f.linesize[0]) : 0;\n\n            s->dsp.put_signed_pixels_clamped(s->block[i], s->dest[dst_idx] + off, (i & 4) ? s->uvlinesize : s->linesize);\n\n            // TODO: yet to perform loop filter\n\n        }\n\n    } else {\n\n        s->mb_intra = v->is_intra[s->mb_x] = 0;\n\n        s->current_picture.f.mb_type[mb_pos + v->mb_off] = MB_TYPE_16x16;\n\n        for (i = 0; i < 6; i++) v->mb_type[0][s->block_index[i]] = 0;\n\n        if (v->fmb_is_raw)\n\n            fwd = v->forward_mb_plane[mb_pos] = get_bits1(gb);\n\n        else\n\n            fwd = v->forward_mb_plane[mb_pos];\n\n        if (idx_mbmode <= 5) { // 1-MV\n\n            dmv_x[0]     = dmv_x[1] = dmv_y[0] = dmv_y[1] = 0;\n\n            pred_flag[0] = pred_flag[1] = 0;\n\n            if (fwd)\n\n                bmvtype = BMV_TYPE_FORWARD;\n\n            else {\n\n                bmvtype = decode012(gb);\n\n                switch (bmvtype) {\n\n                case 0:\n\n                    bmvtype = BMV_TYPE_BACKWARD;\n\n                    break;\n\n                case 1:\n\n                    bmvtype = BMV_TYPE_DIRECT;\n\n                    break;\n\n                case 2:\n\n                    bmvtype   = BMV_TYPE_INTERPOLATED;\n\n                    interpmvp = get_bits1(gb);\n\n                }\n\n            }\n\n            v->bmvtype = bmvtype;\n\n            if (bmvtype != BMV_TYPE_DIRECT && idx_mbmode & 1) {\n\n                get_mvdata_interlaced(v, &dmv_x[bmvtype == BMV_TYPE_BACKWARD], &dmv_y[bmvtype == BMV_TYPE_BACKWARD], &pred_flag[bmvtype == BMV_TYPE_BACKWARD]);\n\n            }\n\n            if (bmvtype == BMV_TYPE_INTERPOLATED && interpmvp) {\n\n                get_mvdata_interlaced(v, &dmv_x[1], &dmv_y[1], &pred_flag[1]);\n\n            }\n\n            if (bmvtype == BMV_TYPE_DIRECT) {\n\n                dmv_x[0] = dmv_y[0] = pred_flag[0] = 0;\n\n                dmv_x[1] = dmv_y[1] = pred_flag[0] = 0;\n\n            }\n\n            vc1_pred_b_mv_intfi(v, 0, dmv_x, dmv_y, 1, pred_flag);\n\n            vc1_b_mc(v, dmv_x, dmv_y, (bmvtype == BMV_TYPE_DIRECT), bmvtype);\n\n            mb_has_coeffs = !(idx_mbmode & 2);\n\n        } else { // 4-MV\n\n            if (fwd)\n\n                bmvtype = BMV_TYPE_FORWARD;\n\n            v->bmvtype  = bmvtype;\n\n            v->fourmvbp = get_vlc2(gb, v->fourmvbp_vlc->table, VC1_4MV_BLOCK_PATTERN_VLC_BITS, 1);\n\n            for (i = 0; i < 6; i++) {\n\n                if (i < 4) {\n\n                    dmv_x[0] = dmv_y[0] = pred_flag[0] = 0;\n\n                    dmv_x[1] = dmv_y[1] = pred_flag[1] = 0;\n\n                    val = ((v->fourmvbp >> (3 - i)) & 1);\n\n                    if (val) {\n\n                        get_mvdata_interlaced(v, &dmv_x[bmvtype == BMV_TYPE_BACKWARD],\n\n                                                 &dmv_y[bmvtype == BMV_TYPE_BACKWARD],\n\n                                             &pred_flag[bmvtype == BMV_TYPE_BACKWARD]);\n\n                    }\n\n                    vc1_pred_b_mv_intfi(v, i, dmv_x, dmv_y, 0, pred_flag);\n\n                    vc1_mc_4mv_luma(v, i, bmvtype == BMV_TYPE_BACKWARD);\n\n                } else if (i == 4)\n\n                    vc1_mc_4mv_chroma(v, bmvtype == BMV_TYPE_BACKWARD);\n\n            }\n\n            mb_has_coeffs = idx_mbmode & 1;\n\n        }\n\n        if (mb_has_coeffs)\n\n            cbp = 1 + get_vlc2(&v->s.gb, v->cbpcy_vlc->table, VC1_CBPCY_P_VLC_BITS, 2);\n\n        if (cbp) {\n\n            GET_MQUANT();\n\n        }\n\n        s->current_picture.f.qscale_table[mb_pos] = mquant;\n\n        if (!v->ttmbf && cbp) {\n\n            ttmb = get_vlc2(gb, ff_vc1_ttmb_vlc[v->tt_index].table, VC1_TTMB_VLC_BITS, 2);\n\n        }\n\n        dst_idx = 0;\n\n        for (i = 0; i < 6; i++) {\n\n            s->dc_val[0][s->block_index[i]] = 0;\n\n            dst_idx += i >> 2;\n\n            val = ((cbp >> (5 - i)) & 1);\n\n            off = (i & 4) ? 0 : (i & 1) * 8 + (i & 2) * 4 * s->linesize;\n\n            if (v->second_field)\n\n                off += (i & 4) ? s->current_picture_ptr->f.linesize[1] : s->current_picture_ptr->f.linesize[0];\n\n            if (val) {\n\n                vc1_decode_p_block(v, s->block[i], i, mquant, ttmb,\n\n                                   first_block, s->dest[dst_idx] + off,\n\n                                   (i & 4) ? s->uvlinesize : s->linesize,\n\n                                   (i & 4) && (s->flags & CODEC_FLAG_GRAY), NULL);\n\n                if (!v->ttmbf && ttmb < 8)\n\n                    ttmb = -1;\n\n                first_block = 0;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 26956}
{"project": "FFmpeg", "commit_id": "9f61abc8111c7c43f49ca012e957a108b9cc7610", "target": 0, "func": "static int hls_window(AVFormatContext *s, int last)\n\n{\n\n    HLSContext *hls = s->priv_data;\n\n    ListEntry *en;\n\n    int64_t target_duration = 0;\n\n    int ret = 0;\n\n    AVIOContext *out = NULL;\n\n    char temp_filename[1024];\n\n    int64_t sequence = FFMAX(hls->start_sequence, hls->sequence - hls->size);\n\n\n\n    snprintf(temp_filename, sizeof(temp_filename), \"%s.tmp\", s->filename);\n\n    if ((ret = avio_open2(&out, temp_filename, AVIO_FLAG_WRITE,\n\n                          &s->interrupt_callback, NULL)) < 0)\n\n        goto fail;\n\n\n\n    for (en = hls->list; en; en = en->next) {\n\n        if (target_duration < en->duration)\n\n            target_duration = en->duration;\n\n    }\n\n\n\n    avio_printf(out, \"#EXTM3U\\n\");\n\n    avio_printf(out, \"#EXT-X-VERSION:%d\\n\", hls->version);\n\n    if (hls->allowcache == 0 || hls->allowcache == 1) {\n\n        avio_printf(out, \"#EXT-X-ALLOW-CACHE:%s\\n\", hls->allowcache == 0 ? \"NO\" : \"YES\");\n\n    }\n\n    avio_printf(out, \"#EXT-X-TARGETDURATION:%\"PRId64\"\\n\",\n\n                av_rescale_rnd(target_duration, 1, AV_TIME_BASE,\n\n                               AV_ROUND_UP));\n\n    avio_printf(out, \"#EXT-X-MEDIA-SEQUENCE:%\"PRId64\"\\n\", sequence);\n\n\n\n    av_log(s, AV_LOG_VERBOSE, \"EXT-X-MEDIA-SEQUENCE:%\"PRId64\"\\n\",\n\n           sequence);\n\n\n\n    for (en = hls->list; en; en = en->next) {\n\n        if (hls->version > 2)\n\n            avio_printf(out, \"#EXTINF:%f\\n\",\n\n                        (double)en->duration / AV_TIME_BASE);\n\n        else\n\n            avio_printf(out, \"#EXTINF:%\"PRId64\",\\n\",\n\n                        av_rescale(en->duration, 1, AV_TIME_BASE));\n\n        if (hls->baseurl)\n\n            avio_printf(out, \"%s\", hls->baseurl);\n\n        avio_printf(out, \"%s\\n\", en->name);\n\n    }\n\n\n\n    if (last)\n\n        avio_printf(out, \"#EXT-X-ENDLIST\\n\");\n\n\n\nfail:\n\n    avio_closep(&out);\n\n    if (ret >= 0)\n\n        ff_rename(temp_filename, s->filename);\n\n    return ret;\n\n}\n", "idx": 26957}
{"project": "FFmpeg", "commit_id": "1c7a0161538a9e8417086759a5d6d3295337c433", "target": 0, "func": "static av_cold int imc_decode_init(AVCodecContext *avctx)\n\n{\n\n    int i, j, ret;\n\n    IMCContext *q = avctx->priv_data;\n\n    double r1, r2;\n\n\n\n    if ((avctx->codec_id == AV_CODEC_ID_IMC && avctx->channels != 1)\n\n        || (avctx->codec_id == AV_CODEC_ID_IAC && avctx->channels > 2)) {\n\n        av_log_ask_for_sample(avctx, \"Number of channels is not supported\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    for (j = 0; j < avctx->channels; j++) {\n\n        q->chctx[j].decoder_reset = 1;\n\n\n\n        for (i = 0; i < BANDS; i++)\n\n            q->chctx[j].old_floor[i] = 1.0;\n\n\n\n        for (i = 0; i < COEFFS / 2; i++)\n\n            q->chctx[j].last_fft_im[i] = 0;\n\n    }\n\n\n\n    /* Build mdct window, a simple sine window normalized with sqrt(2) */\n\n    ff_sine_window_init(q->mdct_sine_window, COEFFS);\n\n    for (i = 0; i < COEFFS; i++)\n\n        q->mdct_sine_window[i] *= sqrt(2.0);\n\n    for (i = 0; i < COEFFS / 2; i++) {\n\n        q->post_cos[i] = (1.0f / 32768) * cos(i / 256.0 * M_PI);\n\n        q->post_sin[i] = (1.0f / 32768) * sin(i / 256.0 * M_PI);\n\n\n\n        r1 = sin((i * 4.0 + 1.0) / 1024.0 * M_PI);\n\n        r2 = cos((i * 4.0 + 1.0) / 1024.0 * M_PI);\n\n\n\n        if (i & 0x1) {\n\n            q->pre_coef1[i] =  (r1 + r2) * sqrt(2.0);\n\n            q->pre_coef2[i] = -(r1 - r2) * sqrt(2.0);\n\n        } else {\n\n            q->pre_coef1[i] = -(r1 + r2) * sqrt(2.0);\n\n            q->pre_coef2[i] =  (r1 - r2) * sqrt(2.0);\n\n        }\n\n    }\n\n\n\n    /* Generate a square root table */\n\n\n\n    for (i = 0; i < 30; i++)\n\n        q->sqrt_tab[i] = sqrt(i);\n\n\n\n    /* initialize the VLC tables */\n\n    for (i = 0; i < 4 ; i++) {\n\n        for (j = 0; j < 4; j++) {\n\n            huffman_vlc[i][j].table = &vlc_tables[vlc_offsets[i * 4 + j]];\n\n            huffman_vlc[i][j].table_allocated = vlc_offsets[i * 4 + j + 1] - vlc_offsets[i * 4 + j];\n\n            init_vlc(&huffman_vlc[i][j], 9, imc_huffman_sizes[i],\n\n                     imc_huffman_lens[i][j], 1, 1,\n\n                     imc_huffman_bits[i][j], 2, 2, INIT_VLC_USE_NEW_STATIC);\n\n        }\n\n    }\n\n\n\n    if (avctx->codec_id == AV_CODEC_ID_IAC) {\n\n        iac_generate_tabs(q, avctx->sample_rate);\n\n    } else {\n\n        memcpy(q->cyclTab,  cyclTab,  sizeof(cyclTab));\n\n        memcpy(q->cyclTab2, cyclTab2, sizeof(cyclTab2));\n\n        memcpy(q->weights1, imc_weights1, sizeof(imc_weights1));\n\n        memcpy(q->weights2, imc_weights2, sizeof(imc_weights2));\n\n    }\n\n\n\n    if ((ret = ff_fft_init(&q->fft, 7, 1))) {\n\n        av_log(avctx, AV_LOG_INFO, \"FFT init failed\\n\");\n\n        return ret;\n\n    }\n\n    ff_dsputil_init(&q->dsp, avctx);\n\n    avctx->sample_fmt     = AV_SAMPLE_FMT_FLTP;\n\n    avctx->channel_layout = avctx->channels == 1 ? AV_CH_LAYOUT_MONO\n\n                                                 : AV_CH_LAYOUT_STEREO;\n\n\n\n    avcodec_get_frame_defaults(&q->frame);\n\n    avctx->coded_frame = &q->frame;\n\n\n\n    return 0;\n\n}\n", "idx": 26960}
{"project": "FFmpeg", "commit_id": "90901860c21468d6e9ae437c2bacb099c7bd3acf", "target": 0, "func": "static int vorbis_parse_setup_hdr_mappings(vorbis_context *vc) {\n\n    GetBitContext *gb=&vc->gb;\n\n    uint_fast8_t i, j;\n\n\n\n    vc->mapping_count=get_bits(gb, 6)+1;\n\n    vc->mappings=(vorbis_mapping *)av_mallocz(vc->mapping_count * sizeof(vorbis_mapping));\n\n\n\n    AV_DEBUG(\" There are %d mappings. \\n\", vc->mapping_count);\n\n\n\n    for(i=0;i<vc->mapping_count;++i) {\n\n        vorbis_mapping *mapping_setup=&vc->mappings[i];\n\n\n\n        if (get_bits(gb, 16)) {\n\n            av_log(vc->avccontext, AV_LOG_ERROR, \"Other mappings than type 0 are not compliant with the Vorbis I specification. \\n\");\n\n            return 1;\n\n        }\n\n        if (get_bits1(gb)) {\n\n            mapping_setup->submaps=get_bits(gb, 4)+1;\n\n        } else {\n\n            mapping_setup->submaps=1;\n\n        }\n\n\n\n        if (get_bits1(gb)) {\n\n            mapping_setup->coupling_steps=get_bits(gb, 8)+1;\n\n            mapping_setup->magnitude=(uint_fast8_t *)av_mallocz(mapping_setup->coupling_steps * sizeof(uint_fast8_t));\n\n            mapping_setup->angle=(uint_fast8_t *)av_mallocz(mapping_setup->coupling_steps * sizeof(uint_fast8_t));\n\n            for(j=0;j<mapping_setup->coupling_steps;++j) {\n\n                mapping_setup->magnitude[j]=get_bits(gb, ilog(vc->audio_channels-1));\n\n                mapping_setup->angle[j]=get_bits(gb, ilog(vc->audio_channels-1));\n\n                // FIXME: sanity checks\n\n            }\n\n        } else {\n\n            mapping_setup->coupling_steps=0;\n\n        }\n\n\n\n        AV_DEBUG(\"   %d mapping coupling steps: %d \\n\", i, mapping_setup->coupling_steps);\n\n\n\n        if(get_bits(gb, 2)) {\n\n            av_log(vc->avccontext, AV_LOG_ERROR, \"%d. mapping setup data invalid. \\n\", i);\n\n            return 1; // following spec.\n\n        }\n\n\n\n        if (mapping_setup->submaps>1) {\n\n            mapping_setup->mux=(uint_fast8_t *)av_mallocz(vc->audio_channels * sizeof(uint_fast8_t));\n\n            for(j=0;j<vc->audio_channels;++j) {\n\n                mapping_setup->mux[j]=get_bits(gb, 4);\n\n            }\n\n        }\n\n\n\n        for(j=0;j<mapping_setup->submaps;++j) {\n\n            skip_bits(gb, 8); // FIXME check?\n\n            mapping_setup->submap_floor[j]=get_bits(gb, 8);\n\n            mapping_setup->submap_residue[j]=get_bits(gb, 8);\n\n\n\n            AV_DEBUG(\"   %d mapping %d submap : floor %d, residue %d \\n\", i, j, mapping_setup->submap_floor[j], mapping_setup->submap_residue[j]);\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 26971}
{"project": "FFmpeg", "commit_id": "5eb765ef341c3ec1bea31914c897750f88476ede", "target": 1, "func": "static int http_prepare_data(HTTPContext *c, long cur_time)\n\n{\n\n    int i;\n\n\n\n    switch(c->state) {\n\n    case HTTPSTATE_SEND_DATA_HEADER:\n\n        memset(&c->fmt_ctx, 0, sizeof(c->fmt_ctx));\n\n        pstrcpy(c->fmt_ctx.author, sizeof(c->fmt_ctx.author), c->stream->author);\n\n        pstrcpy(c->fmt_ctx.comment, sizeof(c->fmt_ctx.comment), c->stream->comment);\n\n        pstrcpy(c->fmt_ctx.copyright, sizeof(c->fmt_ctx.copyright), c->stream->copyright);\n\n        pstrcpy(c->fmt_ctx.title, sizeof(c->fmt_ctx.title), c->stream->title);\n\n\n\n        if (c->stream->feed) {\n\n            /* open output stream by using specified codecs */\n\n            c->fmt_ctx.oformat = c->stream->fmt;\n\n            c->fmt_ctx.nb_streams = c->stream->nb_streams;\n\n            for(i=0;i<c->fmt_ctx.nb_streams;i++) {\n\n                AVStream *st;\n\n                st = av_mallocz(sizeof(AVStream));\n\n                c->fmt_ctx.streams[i] = st;\n\n                if (c->stream->feed == c->stream)\n\n                    memcpy(st, c->stream->streams[i], sizeof(AVStream));\n\n                else\n\n                    memcpy(st, c->stream->feed->streams[c->stream->feed_streams[i]], sizeof(AVStream));\n\n\n\n                st->codec.frame_number = 0; /* XXX: should be done in\n\n                                               AVStream, not in codec */\n\n            }\n\n            c->got_key_frame = 0;\n\n        } else {\n\n            /* open output stream by using codecs in specified file */\n\n            c->fmt_ctx.oformat = c->stream->fmt;\n\n            c->fmt_ctx.nb_streams = c->fmt_in->nb_streams;\n\n            for(i=0;i<c->fmt_ctx.nb_streams;i++) {\n\n                AVStream *st;\n\n                st = av_mallocz(sizeof(AVStream));\n\n                c->fmt_ctx.streams[i] = st;\n\n                memcpy(st, c->fmt_in->streams[i], sizeof(AVStream));\n\n                st->codec.frame_number = 0; /* XXX: should be done in\n\n                                               AVStream, not in codec */\n\n            }\n\n            c->got_key_frame = 0;\n\n        }\n\n        init_put_byte(&c->fmt_ctx.pb, c->pbuffer, c->pbuffer_size,\n\n                      1, c, NULL, http_write_packet, NULL);\n\n        c->fmt_ctx.pb.is_streamed = 1;\n\n        /* prepare header */\n\n        av_write_header(&c->fmt_ctx);\n\n        c->state = HTTPSTATE_SEND_DATA;\n\n        c->last_packet_sent = 0;\n\n        break;\n\n    case HTTPSTATE_SEND_DATA:\n\n        /* find a new packet */\n\n#if 0\n\n        fifo_total_size = http_fifo_write_count - c->last_http_fifo_write_count;\n\n        if (fifo_total_size >= ((3 * FIFO_MAX_SIZE) / 4)) {\n\n            /* overflow : resync. We suppose that wptr is at this\n\n               point a pointer to a valid packet */\n\n            c->rptr = http_fifo.wptr;\n\n            c->got_key_frame = 0;\n\n        }\n\n        \n\n        start_rptr = c->rptr;\n\n        if (fifo_read(&http_fifo, (UINT8 *)&hdr, sizeof(hdr), &c->rptr) < 0)\n\n            return 0;\n\n        payload_size = ntohs(hdr.payload_size);\n\n        payload = av_malloc(payload_size);\n\n        if (fifo_read(&http_fifo, payload, payload_size, &c->rptr) < 0) {\n\n            /* cannot read all the payload */\n\n            av_free(payload);\n\n            c->rptr = start_rptr;\n\n            return 0;\n\n        }\n\n        \n\n        c->last_http_fifo_write_count = http_fifo_write_count - \n\n            fifo_size(&http_fifo, c->rptr);\n\n        \n\n        if (c->stream->stream_type != STREAM_TYPE_MASTER) {\n\n            /* test if the packet can be handled by this format */\n\n            ret = 0;\n\n            for(i=0;i<c->fmt_ctx.nb_streams;i++) {\n\n                AVStream *st = c->fmt_ctx.streams[i];\n\n                if (test_header(&hdr, &st->codec)) {\n\n                    /* only begin sending when got a key frame */\n\n                    if (st->codec.key_frame)\n\n                        c->got_key_frame |= 1 << i;\n\n                    if (c->got_key_frame & (1 << i)) {\n\n                        ret = c->fmt_ctx.format->write_packet(&c->fmt_ctx, i,\n\n                                                                   payload, payload_size);\n\n                    }\n\n                    break;\n\n                }\n\n            }\n\n            if (ret) {\n\n                /* must send trailer now */\n\n                c->state = HTTPSTATE_SEND_DATA_TRAILER;\n\n            }\n\n        } else {\n\n            /* master case : send everything */\n\n            char *q;\n\n            q = c->buffer;\n\n            memcpy(q, &hdr, sizeof(hdr));\n\n            q += sizeof(hdr);\n\n            memcpy(q, payload, payload_size);\n\n            q += payload_size;\n\n            c->buffer_ptr = c->buffer;\n\n            c->buffer_end = q;\n\n        }\n\n        av_free(payload);\n\n#endif\n\n        {\n\n            AVPacket pkt;\n\n\n\n            /* read a packet from the input stream */\n\n            if (c->stream->feed) {\n\n                ffm_set_write_index(c->fmt_in, \n\n                                    c->stream->feed->feed_write_index,\n\n                                    c->stream->feed->feed_size);\n\n            }\n\n\n\n            if (c->stream->max_time && \n\n                c->stream->max_time + c->start_time - cur_time < 0) {\n\n                /* We have timed out */\n\n                c->state = HTTPSTATE_SEND_DATA_TRAILER;\n\n            } else if (av_read_packet(c->fmt_in, &pkt) < 0) {\n\n                if (c->stream->feed && c->stream->feed->feed_opened) {\n\n                    /* if coming from feed, it means we reached the end of the\n\n                       ffm file, so must wait for more data */\n\n                    c->state = HTTPSTATE_WAIT_FEED;\n\n                    return 1; /* state changed */\n\n                } else {\n\n                    /* must send trailer now because eof or error */\n\n                    c->state = HTTPSTATE_SEND_DATA_TRAILER;\n\n                }\n\n            } else {\n\n                /* send it to the appropriate stream */\n\n                if (c->stream->feed) {\n\n                    /* if coming from a feed, select the right stream */\n\n                    if (c->switch_pending) {\n\n                        c->switch_pending = 0;\n\n                        for(i=0;i<c->stream->nb_streams;i++) {\n\n                            if (c->switch_feed_streams[i] == pkt.stream_index) {\n\n                                if (pkt.flags & PKT_FLAG_KEY) {\n\n                                    do_switch_stream(c, i);\n\n                                }\n\n                            }\n\n                            if (c->switch_feed_streams[i] >= 0) {\n\n                                c->switch_pending = 1;\n\n                            }\n\n                        }\n\n                    }\n\n                    for(i=0;i<c->stream->nb_streams;i++) {\n\n                        if (c->feed_streams[i] == pkt.stream_index) {\n\n                            pkt.stream_index = i;\n\n                            if (pkt.flags & PKT_FLAG_KEY) {\n\n                                c->got_key_frame |= 1 << i;\n\n                            }\n\n                            /* See if we have all the key frames, then \n\n                             * we start to send. This logic is not quite\n\n                             * right, but it works for the case of a \n\n                             * single video stream with one or more\n\n                             * audio streams (for which every frame is \n\n                             * typically a key frame). \n\n                             */\n\n                            if (!c->stream->send_on_key || ((c->got_key_frame + 1) >> c->stream->nb_streams)) {\n\n                                goto send_it;\n\n                            }\n\n                        }\n\n                    }\n\n                } else {\n\n                    AVCodecContext *codec;\n\n                send_it:\n\n                    /* Fudge here */\n\n                    codec = &c->fmt_ctx.streams[pkt.stream_index]->codec;\n\n\n\n                    codec->key_frame = ((pkt.flags & PKT_FLAG_KEY) != 0);\n\n\n\n#ifdef PJSG\n\n                    if (codec->codec_type == CODEC_TYPE_AUDIO) {\n\n                        codec->frame_size = (codec->sample_rate * pkt.duration + 500000) / 1000000;\n\n                        /* printf(\"Calculated size %d, from sr %d, duration %d\\n\", codec->frame_size, codec->sample_rate, pkt.duration); */\n\n                    }\n\n#endif\n\n\n\n                    if (av_write_packet(&c->fmt_ctx, &pkt, 0))\n\n                        c->state = HTTPSTATE_SEND_DATA_TRAILER;\n\n\n\n                    codec->frame_number++;\n\n                }\n\n\n\n                av_free_packet(&pkt);\n\n            }\n\n        }\n\n        break;\n\n    default:\n\n    case HTTPSTATE_SEND_DATA_TRAILER:\n\n        /* last packet test ? */\n\n        if (c->last_packet_sent)\n\n            return -1;\n\n        /* prepare header */\n\n        av_write_trailer(&c->fmt_ctx);\n\n        c->last_packet_sent = 1;\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 26977}
{"project": "FFmpeg", "commit_id": "bb29fee3a6a289f6b191177098ddce3720d8c417", "target": 1, "func": "static int decode_frame(AVCodecContext *avctx, void *data, int *data_size, AVPacket *pkt)\n\n{\n\n    BinkContext * const c = avctx->priv_data;\n\n    GetBitContext gb;\n\n    int blk;\n\n    int i, j, plane, plane_idx, bx, by;\n\n    uint8_t *dst, *prev, *ref, *ref_start, *ref_end;\n\n    int v, col[2];\n\n    const uint8_t *scan;\n\n    int xoff, yoff;\n\n    DECLARE_ALIGNED_16(DCTELEM, block[64]);\n\n    DECLARE_ALIGNED_16(uint8_t, ublock[64]);\n\n    int coordmap[64];\n\n\n\n    if(c->pic.data[0])\n\n        avctx->release_buffer(avctx, &c->pic);\n\n\n\n    if(avctx->get_buffer(avctx, &c->pic) < 0){\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    init_get_bits(&gb, pkt->data, pkt->size*8);\n\n    if (c->version >= 'i')\n\n        skip_bits_long(&gb, 32);\n\n\n\n    for (plane = 0; plane < 3; plane++) {\n\n        const int stride = c->pic.linesize[plane];\n\n        int bw = plane ? (avctx->width  + 15) >> 4 : (avctx->width  + 7) >> 3;\n\n        int bh = plane ? (avctx->height + 15) >> 4 : (avctx->height + 7) >> 3;\n\n        int width = avctx->width >> !!plane;\n\n\n\n        init_lengths(c, FFMAX(width, 8), bw);\n\n        for (i = 0; i < BINK_NB_SRC; i++)\n\n            read_bundle(&gb, c, i);\n\n\n\n        plane_idx = (!plane || !c->swap_planes) ? plane : (plane ^ 3);\n\n        ref_start = c->last.data[plane_idx];\n\n        ref_end   = c->last.data[plane_idx]\n\n                    + (bw - 1 + c->last.linesize[plane_idx] * (bh - 1)) * 8;\n\n\n\n        for (i = 0; i < 64; i++)\n\n            coordmap[i] = (i & 7) + (i >> 3) * stride;\n\n\n\n        for (by = 0; by < bh; by++) {\n\n            if (read_block_types(avctx, &gb, &c->bundle[BINK_SRC_BLOCK_TYPES]) < 0)\n\n                return -1;\n\n            if (read_block_types(avctx, &gb, &c->bundle[BINK_SRC_SUB_BLOCK_TYPES]) < 0)\n\n                return -1;\n\n            if (read_colors(&gb, &c->bundle[BINK_SRC_COLORS], c) < 0)\n\n                return -1;\n\n            if (read_patterns(avctx, &gb, &c->bundle[BINK_SRC_PATTERN]) < 0)\n\n                return -1;\n\n            if (read_motion_values(avctx, &gb, &c->bundle[BINK_SRC_X_OFF]) < 0)\n\n                return -1;\n\n            if (read_motion_values(avctx, &gb, &c->bundle[BINK_SRC_Y_OFF]) < 0)\n\n                return -1;\n\n            if (read_dcs(avctx, &gb, &c->bundle[BINK_SRC_INTRA_DC], DC_START_BITS, 0) < 0)\n\n                return -1;\n\n            if (read_dcs(avctx, &gb, &c->bundle[BINK_SRC_INTER_DC], DC_START_BITS, 1) < 0)\n\n                return -1;\n\n            if (read_runs(avctx, &gb, &c->bundle[BINK_SRC_RUN]) < 0)\n\n                return -1;\n\n\n\n            if (by == bh)\n\n                break;\n\n            dst  = c->pic.data[plane_idx]  + 8*by*stride;\n\n            prev = c->last.data[plane_idx] + 8*by*stride;\n\n            for (bx = 0; bx < bw; bx++, dst += 8, prev += 8) {\n\n                blk = get_value(c, BINK_SRC_BLOCK_TYPES);\n\n                // 16x16 block type on odd line means part of the already decoded block, so skip it\n\n                if ((by & 1) && blk == SCALED_BLOCK) {\n\n                    bx++;\n\n                    dst  += 8;\n\n                    prev += 8;\n\n                    continue;\n\n                }\n\n                switch (blk) {\n\n                case SKIP_BLOCK:\n\n                    c->dsp.put_pixels_tab[1][0](dst, prev, stride, 8);\n\n                    break;\n\n                case SCALED_BLOCK:\n\n                    blk = get_value(c, BINK_SRC_SUB_BLOCK_TYPES);\n\n                    switch (blk) {\n\n                    case RUN_BLOCK:\n\n                        scan = bink_patterns[get_bits(&gb, 4)];\n\n                        i = 0;\n\n                        do {\n\n                            int run = get_value(c, BINK_SRC_RUN) + 1;\n\n\n\n                            i += run;\n\n                            if (i > 64) {\n\n                                av_log(avctx, AV_LOG_ERROR, \"Run went out of bounds\\n\");\n\n                                return -1;\n\n                            }\n\n                            if (get_bits1(&gb)) {\n\n                                v = get_value(c, BINK_SRC_COLORS);\n\n                                for (j = 0; j < run; j++)\n\n                                    ublock[*scan++] = v;\n\n                            } else {\n\n                                for (j = 0; j < run; j++)\n\n                                    ublock[*scan++] = get_value(c, BINK_SRC_COLORS);\n\n                            }\n\n                        } while (i < 63);\n\n                        if (i == 63)\n\n                            ublock[*scan++] = get_value(c, BINK_SRC_COLORS);\n\n                        break;\n\n                    case INTRA_BLOCK:\n\n                        c->dsp.clear_block(block);\n\n                        block[0] = get_value(c, BINK_SRC_INTRA_DC);\n\n                        read_dct_coeffs(&gb, block, c->scantable.permutated, 1);\n\n                        c->dsp.idct(block);\n\n                        c->dsp.put_pixels_nonclamped(block, ublock, 8);\n\n                        break;\n\n                    case FILL_BLOCK:\n\n                        v = get_value(c, BINK_SRC_COLORS);\n\n                        c->dsp.fill_block_tab[0](dst, v, stride, 16);\n\n                        break;\n\n                    case PATTERN_BLOCK:\n\n                        for (i = 0; i < 2; i++)\n\n                            col[i] = get_value(c, BINK_SRC_COLORS);\n\n                        for (j = 0; j < 8; j++) {\n\n                            v = get_value(c, BINK_SRC_PATTERN);\n\n                            for (i = 0; i < 8; i++, v >>= 1)\n\n                                ublock[i + j*8] = col[v & 1];\n\n                        }\n\n                        break;\n\n                    case RAW_BLOCK:\n\n                        for (j = 0; j < 8; j++)\n\n                            for (i = 0; i < 8; i++)\n\n                                ublock[i + j*8] = get_value(c, BINK_SRC_COLORS);\n\n                        break;\n\n                    default:\n\n                        av_log(avctx, AV_LOG_ERROR, \"Incorrect 16x16 block type %d\\n\", blk);\n\n                        return -1;\n\n                    }\n\n                    if (blk != FILL_BLOCK)\n\n                        c->dsp.scale_block(ublock, dst, stride);\n\n                    bx++;\n\n                    dst  += 8;\n\n                    prev += 8;\n\n                    break;\n\n                case MOTION_BLOCK:\n\n                    xoff = get_value(c, BINK_SRC_X_OFF);\n\n                    yoff = get_value(c, BINK_SRC_Y_OFF);\n\n                    ref = prev + xoff + yoff * stride;\n\n                    if (ref < ref_start || ref > ref_end) {\n\n                        av_log(avctx, AV_LOG_ERROR, \"Copy out of bounds @%d, %d\\n\",\n\n                               bx*8 + xoff, by*8 + yoff);\n\n                        return -1;\n\n                    }\n\n                    c->dsp.put_pixels_tab[1][0](dst, ref, stride, 8);\n\n                    break;\n\n                case RUN_BLOCK:\n\n                    scan = bink_patterns[get_bits(&gb, 4)];\n\n                    i = 0;\n\n                    do {\n\n                        int run = get_value(c, BINK_SRC_RUN) + 1;\n\n\n\n                        i += run;\n\n                        if (i > 64) {\n\n                            av_log(avctx, AV_LOG_ERROR, \"Run went out of bounds\\n\");\n\n                            return -1;\n\n                        }\n\n                        if (get_bits1(&gb)) {\n\n                            v = get_value(c, BINK_SRC_COLORS);\n\n                            for (j = 0; j < run; j++)\n\n                                dst[coordmap[*scan++]] = v;\n\n                        } else {\n\n                            for (j = 0; j < run; j++)\n\n                                dst[coordmap[*scan++]] = get_value(c, BINK_SRC_COLORS);\n\n                        }\n\n                    } while (i < 63);\n\n                    if (i == 63)\n\n                        dst[coordmap[*scan++]] = get_value(c, BINK_SRC_COLORS);\n\n                    break;\n\n                case RESIDUE_BLOCK:\n\n                    xoff = get_value(c, BINK_SRC_X_OFF);\n\n                    yoff = get_value(c, BINK_SRC_Y_OFF);\n\n                    ref = prev + xoff + yoff * stride;\n\n                    if (ref < ref_start || ref > ref_end) {\n\n                        av_log(avctx, AV_LOG_ERROR, \"Copy out of bounds @%d, %d\\n\",\n\n                               bx*8 + xoff, by*8 + yoff);\n\n                        return -1;\n\n                    }\n\n                    c->dsp.put_pixels_tab[1][0](dst, ref, stride, 8);\n\n                    c->dsp.clear_block(block);\n\n                    v = get_bits(&gb, 7);\n\n                    read_residue(&gb, block, v);\n\n                    c->dsp.add_pixels8(dst, block, stride);\n\n                    break;\n\n                case INTRA_BLOCK:\n\n                    c->dsp.clear_block(block);\n\n                    block[0] = get_value(c, BINK_SRC_INTRA_DC);\n\n                    read_dct_coeffs(&gb, block, c->scantable.permutated, 1);\n\n                    c->dsp.idct_put(dst, stride, block);\n\n                    break;\n\n                case FILL_BLOCK:\n\n                    v = get_value(c, BINK_SRC_COLORS);\n\n                    c->dsp.fill_block_tab[1](dst, v, stride, 8);\n\n                    break;\n\n                case INTER_BLOCK:\n\n                    xoff = get_value(c, BINK_SRC_X_OFF);\n\n                    yoff = get_value(c, BINK_SRC_Y_OFF);\n\n                    ref = prev + xoff + yoff * stride;\n\n                    c->dsp.put_pixels_tab[1][0](dst, ref, stride, 8);\n\n                    c->dsp.clear_block(block);\n\n                    block[0] = get_value(c, BINK_SRC_INTER_DC);\n\n                    read_dct_coeffs(&gb, block, c->scantable.permutated, 0);\n\n                    c->dsp.idct_add(dst, stride, block);\n\n                    break;\n\n                case PATTERN_BLOCK:\n\n                    for (i = 0; i < 2; i++)\n\n                        col[i] = get_value(c, BINK_SRC_COLORS);\n\n                    for (i = 0; i < 8; i++) {\n\n                        v = get_value(c, BINK_SRC_PATTERN);\n\n                        for (j = 0; j < 8; j++, v >>= 1)\n\n                            dst[i*stride + j] = col[v & 1];\n\n                    }\n\n                    break;\n\n                case RAW_BLOCK:\n\n                    for (i = 0; i < 8; i++)\n\n                        memcpy(dst + i*stride, c->bundle[BINK_SRC_COLORS].cur_ptr + i*8, 8);\n\n                    c->bundle[BINK_SRC_COLORS].cur_ptr += 64;\n\n                    break;\n\n                default:\n\n                    av_log(avctx, AV_LOG_ERROR, \"Unknown block type %d\\n\", blk);\n\n                    return -1;\n\n                }\n\n            }\n\n        }\n\n        if (get_bits_count(&gb) & 0x1F) //next plane data starts at 32-bit boundary\n\n            skip_bits_long(&gb, 32 - (get_bits_count(&gb) & 0x1F));\n\n    }\n\n    emms_c();\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame*)data = c->pic;\n\n\n\n    FFSWAP(AVFrame, c->pic, c->last);\n\n\n\n    /* always report that the buffer was completely consumed */\n\n    return pkt->size;\n\n}\n", "idx": 26979}
{"project": "FFmpeg", "commit_id": "0ecca7a49f8e254c12a3a1de048d738bfbb614c6", "target": 1, "func": "static int png_write_row(PNGContext *s, const uint8_t *data, int size)\n\n{\n\n    int ret;\n\n\n\n    s->zstream.avail_in = size;\n\n    s->zstream.next_in = (uint8_t *)data;\n\n    while (s->zstream.avail_in > 0) {\n\n        ret = deflate(&s->zstream, Z_NO_FLUSH);\n\n        if (ret != Z_OK)\n\n            return -1;\n\n        if (s->zstream.avail_out == 0) {\n\n            png_write_chunk(&s->bytestream, MKTAG('I', 'D', 'A', 'T'), s->buf, IOBUF_SIZE);\n\n            s->zstream.avail_out = IOBUF_SIZE;\n\n            s->zstream.next_out = s->buf;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 26981}
{"project": "FFmpeg", "commit_id": "fbd6c97f9ca858140df16dd07200ea0d4bdc1a83", "target": 1, "func": "AVBufferRef *av_buffer_pool_get(AVBufferPool *pool)\n\n{\n\n    AVBufferRef *ret;\n\n    BufferPoolEntry *buf;\n\n\n\n    /* check whether the pool is empty */\n\n    buf = get_pool(pool);\n\n    if (!buf)\n\n        return pool_alloc_buffer(pool);\n\n\n\n    /* keep the first entry, return the rest of the list to the pool */\n\n    add_to_pool(buf->next);\n\n    buf->next = NULL;\n\n\n\n    ret = av_buffer_create(buf->data, pool->size, pool_release_buffer,\n\n                           buf, 0);\n\n    if (!ret) {\n\n        add_to_pool(buf);\n\n        return NULL;\n\n    }\n\n    avpriv_atomic_int_add_and_fetch(&pool->refcount, 1);\n\n\n\n    return ret;\n\n}\n", "idx": 26983}
{"project": "FFmpeg", "commit_id": "2caf19e90f270abe1e80a3e85acaf0eb5c9d0aac", "target": 1, "func": "static void FUNCC(pred4x4_127_dc)(uint8_t *_src, const uint8_t *topright, int _stride){\n\n    pixel *src = (pixel*)_src;\n\n    int stride = _stride/sizeof(pixel);\n\n    ((pixel4*)(src+0*stride))[0]=\n\n    ((pixel4*)(src+1*stride))[0]=\n\n    ((pixel4*)(src+2*stride))[0]=\n\n    ((pixel4*)(src+3*stride))[0]= PIXEL_SPLAT_X4((1<<(BIT_DEPTH-1))-1);\n\n}\n", "idx": 26985}
{"project": "FFmpeg", "commit_id": "2bfa067d0b636e7b2004fb0ad5a53d0d48c6de32", "target": 1, "func": "av_cold int ff_vaapi_encode_close(AVCodecContext *avctx)\n\n{\n\n    VAAPIEncodeContext *ctx = avctx->priv_data;\n\n    VAAPIEncodePicture *pic, *next;\n\n\n\n    for (pic = ctx->pic_start; pic; pic = next) {\n\n        next = pic->next;\n\n        vaapi_encode_free(avctx, pic);\n\n    }\n\n\n\n    if (ctx->va_context != VA_INVALID_ID)\n\n        vaDestroyContext(ctx->hwctx->display, ctx->va_context);\n\n\n\n    if (ctx->va_config != VA_INVALID_ID)\n\n        vaDestroyConfig(ctx->hwctx->display, ctx->va_config);\n\n\n\n    if (ctx->codec->close)\n\n        ctx->codec->close(avctx);\n\n\n\n    av_freep(&ctx->codec_sequence_params);\n\n    av_freep(&ctx->codec_picture_params);\n\n\n\n    av_buffer_unref(&ctx->recon_frames_ref);\n\n    av_buffer_unref(&ctx->input_frames_ref);\n\n    av_buffer_unref(&ctx->device_ref);\n\n\n\n    av_freep(&ctx->priv_data);\n\n\n\n    return 0;\n\n}\n", "idx": 26986}
{"project": "FFmpeg", "commit_id": "066fff755a5d8edc660c010ddb08474d208eeade", "target": 0, "func": "static void vp6_parse_coeff_models(VP56Context *s)\n\n{\n\n    VP56RangeCoder *c = &s->c;\n\n    VP56Model *model = s->modelp;\n\n    int def_prob[11];\n\n    int node, cg, ctx, pos;\n\n    int ct;    /* code type */\n\n    int pt;    /* plane type (0 for Y, 1 for U or V) */\n\n\n\n    memset(def_prob, 0x80, sizeof(def_prob));\n\n\n\n    for (pt=0; pt<2; pt++)\n\n        for (node=0; node<11; node++)\n\n            if (vp56_rac_get_prob(c, vp6_dccv_pct[pt][node])) {\n\n                def_prob[node] = vp56_rac_gets_nn(c, 7);\n\n                model->coeff_dccv[pt][node] = def_prob[node];\n\n            } else if (s->framep[VP56_FRAME_CURRENT]->key_frame) {\n\n                model->coeff_dccv[pt][node] = def_prob[node];\n\n            }\n\n\n\n    if (vp56_rac_get(c)) {\n\n        for (pos=1; pos<64; pos++)\n\n            if (vp56_rac_get_prob(c, vp6_coeff_reorder_pct[pos]))\n\n                model->coeff_reorder[pos] = vp56_rac_gets(c, 4);\n\n        vp6_coeff_order_table_init(s);\n\n    }\n\n\n\n    for (cg=0; cg<2; cg++)\n\n        for (node=0; node<14; node++)\n\n            if (vp56_rac_get_prob(c, vp6_runv_pct[cg][node]))\n\n                model->coeff_runv[cg][node] = vp56_rac_gets_nn(c, 7);\n\n\n\n    for (ct=0; ct<3; ct++)\n\n        for (pt=0; pt<2; pt++)\n\n            for (cg=0; cg<6; cg++)\n\n                for (node=0; node<11; node++)\n\n                    if (vp56_rac_get_prob(c, vp6_ract_pct[ct][pt][cg][node])) {\n\n                        def_prob[node] = vp56_rac_gets_nn(c, 7);\n\n                        model->coeff_ract[pt][ct][cg][node] = def_prob[node];\n\n                    } else if (s->framep[VP56_FRAME_CURRENT]->key_frame) {\n\n                        model->coeff_ract[pt][ct][cg][node] = def_prob[node];\n\n                    }\n\n\n\n    if (s->use_huffman) {\n\n        for (pt=0; pt<2; pt++) {\n\n            vp6_build_huff_tree(s, model->coeff_dccv[pt],\n\n                                vp6_huff_coeff_map, 12, &s->dccv_vlc[pt]);\n\n            vp6_build_huff_tree(s, model->coeff_runv[pt],\n\n                                vp6_huff_run_map, 9, &s->runv_vlc[pt]);\n\n            for (ct=0; ct<3; ct++)\n\n                for (cg = 0; cg < 6; cg++)\n\n                    vp6_build_huff_tree(s, model->coeff_ract[pt][ct][cg],\n\n                                        vp6_huff_coeff_map, 12,\n\n                                        &s->ract_vlc[pt][ct][cg]);\n\n        }\n\n        memset(s->nb_null, 0, sizeof(s->nb_null));\n\n    } else {\n\n    /* coeff_dcct is a linear combination of coeff_dccv */\n\n    for (pt=0; pt<2; pt++)\n\n        for (ctx=0; ctx<3; ctx++)\n\n            for (node=0; node<5; node++)\n\n                model->coeff_dcct[pt][ctx][node] = av_clip(((model->coeff_dccv[pt][node] * vp6_dccv_lc[ctx][node][0] + 128) >> 8) + vp6_dccv_lc[ctx][node][1], 1, 255);\n\n    }\n\n}\n", "idx": 26988}
{"project": "FFmpeg", "commit_id": "ed1c83508ec920bfef773e3aa3ac1764a65826ec", "target": 0, "func": "static int trim_filter_frame(AVFilterLink *inlink, AVFrame *frame)\n\n{\n\n    AVFilterContext *ctx = inlink->dst;\n\n    TrimContext       *s = ctx->priv;\n\n    int drop;\n\n\n\n    /* drop everything if EOF has already been returned */\n\n    if (s->eof) {\n\n        av_frame_free(&frame);\n\n        return 0;\n\n    }\n\n\n\n    if (s->start_frame >= 0 || s->start_pts != AV_NOPTS_VALUE) {\n\n        drop = 1;\n\n        if (s->start_frame >= 0 && s->nb_frames >= s->start_frame)\n\n            drop = 0;\n\n        if (s->start_pts != AV_NOPTS_VALUE && frame->pts != AV_NOPTS_VALUE &&\n\n            frame->pts >= s->start_pts)\n\n            drop = 0;\n\n        if (drop)\n\n            goto drop;\n\n    }\n\n\n\n    if (s->first_pts == AV_NOPTS_VALUE && frame->pts != AV_NOPTS_VALUE)\n\n        s->first_pts = frame->pts;\n\n\n\n    if (s->end_frame != INT64_MAX || s->end_pts != AV_NOPTS_VALUE || s->duration_tb) {\n\n        drop = 1;\n\n\n\n        if (s->end_frame != INT64_MAX && s->nb_frames < s->end_frame)\n\n            drop = 0;\n\n        if (s->end_pts != AV_NOPTS_VALUE && frame->pts != AV_NOPTS_VALUE &&\n\n            frame->pts < s->end_pts)\n\n            drop = 0;\n\n        if (s->duration_tb && frame->pts != AV_NOPTS_VALUE &&\n\n            frame->pts - s->first_pts < s->duration_tb)\n\n            drop = 0;\n\n\n\n        if (drop) {\n\n            s->eof = 1;\n\n            goto drop;\n\n        }\n\n    }\n\n\n\n    s->nb_frames++;\n\n    s->got_output = 1;\n\n\n\n    return ff_filter_frame(ctx->outputs[0], frame);\n\n\n\ndrop:\n\n    s->nb_frames++;\n\n    av_frame_free(&frame);\n\n    return 0;\n\n}\n", "idx": 26989}
{"project": "FFmpeg", "commit_id": "13a099799e89a76eb921ca452e1b04a7a28a9855", "target": 0, "func": "static void RENAME(yuv2rgb32_2)(SwsContext *c, const uint16_t *buf0,\n\n                                const uint16_t *buf1, const uint16_t *ubuf0,\n\n                                const uint16_t *ubuf1, const uint16_t *vbuf0,\n\n                                const uint16_t *vbuf1, const uint16_t *abuf0,\n\n                                const uint16_t *abuf1, uint8_t *dest,\n\n                                int dstW, int yalpha, int uvalpha, int y)\n\n{\n\n    if (CONFIG_SWSCALE_ALPHA && c->alpPixBuf) {\n\n#if ARCH_X86_64\n\n        __asm__ volatile(\n\n            YSCALEYUV2RGB(%%r8, %5)\n\n            YSCALEYUV2RGB_YA(%%r8, %5, %6, %7)\n\n            \"psraw                  $3, %%mm1       \\n\\t\" /* abuf0[eax] - abuf1[eax] >>7*/\n\n            \"psraw                  $3, %%mm7       \\n\\t\" /* abuf0[eax] - abuf1[eax] >>7*/\n\n            \"packuswb            %%mm7, %%mm1       \\n\\t\"\n\n            WRITEBGR32(%4, 8280(%5), %%r8, %%mm2, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm3, %%mm6)\n\n            :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"r\" (dest),\n\n               \"a\" (&c->redDither),\n\n               \"r\" (abuf0), \"r\" (abuf1)\n\n            : \"%r8\"\n\n        );\n\n#else\n\n        *(const uint16_t **)(&c->u_temp)=abuf0;\n\n        *(const uint16_t **)(&c->v_temp)=abuf1;\n\n        __asm__ volatile(\n\n            \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n            \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n            \"push %%\"REG_BP\"                        \\n\\t\"\n\n            YSCALEYUV2RGB(%%REGBP, %5)\n\n            \"push                   %0              \\n\\t\"\n\n            \"push                   %1              \\n\\t\"\n\n            \"mov          \"U_TEMP\"(%5), %0          \\n\\t\"\n\n            \"mov          \"V_TEMP\"(%5), %1          \\n\\t\"\n\n            YSCALEYUV2RGB_YA(%%REGBP, %5, %0, %1)\n\n            \"psraw                  $3, %%mm1       \\n\\t\" /* abuf0[eax] - abuf1[eax] >>7*/\n\n            \"psraw                  $3, %%mm7       \\n\\t\" /* abuf0[eax] - abuf1[eax] >>7*/\n\n            \"packuswb            %%mm7, %%mm1       \\n\\t\"\n\n            \"pop                    %1              \\n\\t\"\n\n            \"pop                    %0              \\n\\t\"\n\n            WRITEBGR32(%%REGb, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm3, %%mm6)\n\n            \"pop %%\"REG_BP\"                         \\n\\t\"\n\n            \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n            :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n               \"a\" (&c->redDither)\n\n        );\n\n#endif\n\n    } else {\n\n        __asm__ volatile(\n\n            \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n            \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n            \"push %%\"REG_BP\"                        \\n\\t\"\n\n            YSCALEYUV2RGB(%%REGBP, %5)\n\n            \"pcmpeqd %%mm7, %%mm7                   \\n\\t\"\n\n            WRITEBGR32(%%REGb, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)\n\n            \"pop %%\"REG_BP\"                         \\n\\t\"\n\n            \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n            :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n               \"a\" (&c->redDither)\n\n        );\n\n    }\n\n}\n", "idx": 26990}
{"project": "FFmpeg", "commit_id": "43abef9fde0cf87153cc9031cad61f75b02cfa01", "target": 0, "func": "static int read_line(AVIOContext * pb, char* line, int bufsize)\n\n{\n\n    int i;\n\n    for (i = 0; i < bufsize - 1; i++) {\n\n        int b = avio_r8(pb);\n\n        if (b == 0)\n\n            break;\n\n        if (b == '\\n') {\n\n            line[i] = '\\0';\n\n            return 0;\n\n        }\n\n        line[i] = b;\n\n    }\n\n    line[i] = '\\0';\n\n    return -1;\n\n}\n", "idx": 26991}
{"project": "FFmpeg", "commit_id": "0e3dacb11eacf6a944691bb4a12f4dd56b6d7ce6", "target": 0, "func": "static int tiff_decode_tag(TiffContext *s)\n\n{\n\n    unsigned tag, type, count, off, value = 0;\n\n    int i, j, k, pos, start;\n\n    int ret;\n\n    uint32_t *pal;\n\n    double *dp;\n\n\n\n    tag   = tget_short(&s->gb, s->le);\n\n    type  = tget_short(&s->gb, s->le);\n\n    count = tget_long(&s->gb, s->le);\n\n    off   = tget_long(&s->gb, s->le);\n\n    start = bytestream2_tell(&s->gb);\n\n\n\n    if (type == 0 || type >= FF_ARRAY_ELEMS(type_sizes)) {\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"Unknown tiff type (%u) encountered\\n\",\n\n               type);\n\n        return 0;\n\n    }\n\n\n\n    if (count == 1) {\n\n        switch (type) {\n\n        case TIFF_BYTE:\n\n        case TIFF_SHORT:\n\n            bytestream2_seek(&s->gb, -4, SEEK_CUR);\n\n            value = tget(&s->gb, type, s->le);\n\n            break;\n\n        case TIFF_LONG:\n\n            value = off;\n\n            break;\n\n        case TIFF_STRING:\n\n            if (count <= 4) {\n\n                bytestream2_seek(&s->gb, -4, SEEK_CUR);\n\n                break;\n\n            }\n\n        default:\n\n            value = UINT_MAX;\n\n            bytestream2_seek(&s->gb, off, SEEK_SET);\n\n        }\n\n    } else {\n\n        if (count <= 4 && type_sizes[type] * count <= 4) {\n\n            bytestream2_seek(&s->gb, -4, SEEK_CUR);\n\n        } else {\n\n            bytestream2_seek(&s->gb, off, SEEK_SET);\n\n        }\n\n    }\n\n\n\n    switch (tag) {\n\n    case TIFF_WIDTH:\n\n        s->width = value;\n\n        break;\n\n    case TIFF_HEIGHT:\n\n        s->height = value;\n\n        break;\n\n    case TIFF_BPP:\n\n        s->bppcount = count;\n\n        if (count > 4) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"This format is not supported (bpp=%d, %d components)\\n\",\n\n                   s->bpp, count);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (count == 1)\n\n            s->bpp = value;\n\n        else {\n\n            switch (type) {\n\n            case TIFF_BYTE:\n\n                s->bpp = (off & 0xFF) + ((off >> 8) & 0xFF) +\n\n                         ((off >> 16) & 0xFF) + ((off >> 24) & 0xFF);\n\n                break;\n\n            case TIFF_SHORT:\n\n            case TIFF_LONG:\n\n                s->bpp = 0;\n\n                if (bytestream2_get_bytes_left(&s->gb) < type_sizes[type] * count)\n\n                    return AVERROR_INVALIDDATA;\n\n                for (i = 0; i < count; i++)\n\n                    s->bpp += tget(&s->gb, type, s->le);\n\n                break;\n\n            default:\n\n                s->bpp = -1;\n\n            }\n\n        }\n\n        break;\n\n    case TIFF_SAMPLES_PER_PIXEL:\n\n        if (count != 1) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Samples per pixel requires a single value, many provided\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (s->bppcount == 1)\n\n            s->bpp *= value;\n\n        s->bppcount = value;\n\n        break;\n\n    case TIFF_COMPR:\n\n        s->compr = value;\n\n        s->predictor = 0;\n\n        switch (s->compr) {\n\n        case TIFF_RAW:\n\n        case TIFF_PACKBITS:\n\n        case TIFF_LZW:\n\n        case TIFF_CCITT_RLE:\n\n            break;\n\n        case TIFF_G3:\n\n        case TIFF_G4:\n\n            s->fax_opts = 0;\n\n            break;\n\n        case TIFF_DEFLATE:\n\n        case TIFF_ADOBE_DEFLATE:\n\n#if CONFIG_ZLIB\n\n            break;\n\n#else\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Deflate: ZLib not compiled in\\n\");\n\n            return AVERROR(ENOSYS);\n\n#endif\n\n        case TIFF_JPEG:\n\n        case TIFF_NEWJPEG:\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"JPEG compression is not supported\\n\");\n\n            return AVERROR_PATCHWELCOME;\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Unknown compression method %i\\n\",\n\n                   s->compr);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        break;\n\n    case TIFF_ROWSPERSTRIP:\n\n        if (type == TIFF_LONG && value == UINT_MAX)\n\n            value = s->height;\n\n        if (value < 1) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Incorrect value of rows per strip\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        s->rps = value;\n\n        break;\n\n    case TIFF_STRIP_OFFS:\n\n        if (count == 1) {\n\n            s->strippos = 0;\n\n            s->stripoff = value;\n\n        } else\n\n            s->strippos = off;\n\n        s->strips = count;\n\n        if (s->strips == 1)\n\n            s->rps = s->height;\n\n        s->sot = type;\n\n        if (s->strippos > bytestream2_size(&s->gb)) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Tag referencing position outside the image\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        break;\n\n    case TIFF_STRIP_SIZE:\n\n        if (count == 1) {\n\n            s->stripsizesoff = 0;\n\n            s->stripsize = value;\n\n            s->strips = 1;\n\n        } else {\n\n            s->stripsizesoff = off;\n\n        }\n\n        s->strips = count;\n\n        s->sstype = type;\n\n        if (s->stripsizesoff > bytestream2_size(&s->gb)) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Tag referencing position outside the image\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        break;\n\n    case TIFF_TILE_BYTE_COUNTS:\n\n    case TIFF_TILE_LENGTH:\n\n    case TIFF_TILE_OFFSETS:\n\n    case TIFF_TILE_WIDTH:\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Tiled images are not supported\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n        break;\n\n    case TIFF_PREDICTOR:\n\n        s->predictor = value;\n\n        break;\n\n    case TIFF_INVERT:\n\n        switch (value) {\n\n        case 0:\n\n            s->invert = 1;\n\n            break;\n\n        case 1:\n\n            s->invert = 0;\n\n            break;\n\n        case 2:\n\n        case 3:\n\n            break;\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Color mode %d is not supported\\n\",\n\n                   value);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        break;\n\n    case TIFF_FILL_ORDER:\n\n        if (value < 1 || value > 2) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Unknown FillOrder value %d, trying default one\\n\", value);\n\n            value = 1;\n\n        }\n\n        s->fill_order = value - 1;\n\n        break;\n\n    case TIFF_PAL:\n\n        pal = (uint32_t *) s->palette;\n\n        off = type_sizes[type];\n\n        if (count / 3 > 256 || bytestream2_get_bytes_left(&s->gb) < count / 3 * off * 3)\n\n            return AVERROR_INVALIDDATA;\n\n        off = (type_sizes[type] - 1) << 3;\n\n        for (k = 2; k >= 0; k--) {\n\n            for (i = 0; i < count / 3; i++) {\n\n                if (k == 2)\n\n                    pal[i] = 0xFFU << 24;\n\n                j =  (tget(&s->gb, type, s->le) >> off) << (k * 8);\n\n                pal[i] |= j;\n\n            }\n\n        }\n\n        s->palette_is_set = 1;\n\n        break;\n\n    case TIFF_PLANAR:\n\n        if (value == 2) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Planar format is not supported\\n\");\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n        break;\n\n    case TIFF_T4OPTIONS:\n\n        if (s->compr == TIFF_G3)\n\n            s->fax_opts = value;\n\n        break;\n\n    case TIFF_T6OPTIONS:\n\n        if (s->compr == TIFF_G4)\n\n            s->fax_opts = value;\n\n        break;\n\n#define ADD_METADATA(count, name, sep)\\\n\n    if ((ret = add_metadata(count, type, name, sep, s)) < 0) {\\\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\\\n\n        return ret;\\\n\n    }\n\n    case TIFF_MODEL_PIXEL_SCALE:\n\n        ADD_METADATA(count, \"ModelPixelScaleTag\", NULL);\n\n        break;\n\n    case TIFF_MODEL_TRANSFORMATION:\n\n        ADD_METADATA(count, \"ModelTransformationTag\", NULL);\n\n        break;\n\n    case TIFF_MODEL_TIEPOINT:\n\n        ADD_METADATA(count, \"ModelTiepointTag\", NULL);\n\n        break;\n\n    case TIFF_GEO_KEY_DIRECTORY:\n\n        ADD_METADATA(1, \"GeoTIFF_Version\", NULL);\n\n        ADD_METADATA(2, \"GeoTIFF_Key_Revision\", \".\");\n\n        s->geotag_count   = tget_short(&s->gb, s->le);\n\n        if (s->geotag_count > count / 4 - 1) {\n\n            s->geotag_count = count / 4 - 1;\n\n            av_log(s->avctx, AV_LOG_WARNING, \"GeoTIFF key directory buffer shorter than specified\\n\");\n\n        }\n\n        if (bytestream2_get_bytes_left(&s->gb) < s->geotag_count * sizeof(int16_t) * 4)\n\n            return -1;\n\n        s->geotags = av_mallocz(sizeof(TiffGeoTag) * s->geotag_count);\n\n        if (!s->geotags) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        for (i = 0; i < s->geotag_count; i++) {\n\n            s->geotags[i].key    = tget_short(&s->gb, s->le);\n\n            s->geotags[i].type   = tget_short(&s->gb, s->le);\n\n            s->geotags[i].count  = tget_short(&s->gb, s->le);\n\n\n\n            if (!s->geotags[i].type)\n\n                s->geotags[i].val  = get_geokey_val(s->geotags[i].key, tget_short(&s->gb, s->le));\n\n            else\n\n                s->geotags[i].offset = tget_short(&s->gb, s->le);\n\n        }\n\n        break;\n\n    case TIFF_GEO_DOUBLE_PARAMS:\n\n        if (count >= INT_MAX / sizeof(int64_t))\n\n            return AVERROR_INVALIDDATA;\n\n        if (bytestream2_get_bytes_left(&s->gb) < count * sizeof(int64_t))\n\n            return AVERROR_INVALIDDATA;\n\n        dp = av_malloc(count * sizeof(double));\n\n        if (!dp) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        for (i = 0; i < count; i++)\n\n            dp[i] = tget_double(&s->gb, s->le);\n\n        for (i = 0; i < s->geotag_count; i++) {\n\n            if (s->geotags[i].type == TIFF_GEO_DOUBLE_PARAMS) {\n\n                if (s->geotags[i].count == 0\n\n                    || s->geotags[i].offset + s->geotags[i].count > count) {\n\n                    av_log(s->avctx, AV_LOG_WARNING, \"Invalid GeoTIFF key %d\\n\", s->geotags[i].key);\n\n                } else {\n\n                    char *ap = doubles2str(&dp[s->geotags[i].offset], s->geotags[i].count, \", \");\n\n                    if (!ap) {\n\n                        av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n                        av_freep(&dp);\n\n                        return AVERROR(ENOMEM);\n\n                    }\n\n                    s->geotags[i].val = ap;\n\n                }\n\n            }\n\n        }\n\n        av_freep(&dp);\n\n        break;\n\n    case TIFF_GEO_ASCII_PARAMS:\n\n        pos = bytestream2_tell(&s->gb);\n\n        for (i = 0; i < s->geotag_count; i++) {\n\n            if (s->geotags[i].type == TIFF_GEO_ASCII_PARAMS) {\n\n                if (s->geotags[i].count == 0\n\n                    || s->geotags[i].offset +  s->geotags[i].count > count) {\n\n                    av_log(s->avctx, AV_LOG_WARNING, \"Invalid GeoTIFF key %d\\n\", s->geotags[i].key);\n\n                } else {\n\n                    char *ap;\n\n\n\n                    bytestream2_seek(&s->gb, pos + s->geotags[i].offset, SEEK_SET);\n\n                    if (bytestream2_get_bytes_left(&s->gb) < s->geotags[i].count)\n\n                        return AVERROR_INVALIDDATA;\n\n                    ap = av_malloc(s->geotags[i].count);\n\n                    if (!ap) {\n\n                        av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n                        return AVERROR(ENOMEM);\n\n                    }\n\n                    bytestream2_get_bufferu(&s->gb, ap, s->geotags[i].count);\n\n                    ap[s->geotags[i].count - 1] = '\\0'; //replace the \"|\" delimiter with a 0 byte\n\n                    s->geotags[i].val = ap;\n\n                }\n\n            }\n\n        }\n\n        break;\n\n    case TIFF_ARTIST:\n\n        ADD_METADATA(count, \"artist\", NULL);\n\n        break;\n\n    case TIFF_COPYRIGHT:\n\n        ADD_METADATA(count, \"copyright\", NULL);\n\n        break;\n\n    case TIFF_DATE:\n\n        ADD_METADATA(count, \"date\", NULL);\n\n        break;\n\n    case TIFF_DOCUMENT_NAME:\n\n        ADD_METADATA(count, \"document_name\", NULL);\n\n        break;\n\n    case TIFF_HOST_COMPUTER:\n\n        ADD_METADATA(count, \"computer\", NULL);\n\n        break;\n\n    case TIFF_IMAGE_DESCRIPTION:\n\n        ADD_METADATA(count, \"description\", NULL);\n\n        break;\n\n    case TIFF_MAKE:\n\n        ADD_METADATA(count, \"make\", NULL);\n\n        break;\n\n    case TIFF_MODEL:\n\n        ADD_METADATA(count, \"model\", NULL);\n\n        break;\n\n    case TIFF_PAGE_NAME:\n\n        ADD_METADATA(count, \"page_name\", NULL);\n\n        break;\n\n    case TIFF_PAGE_NUMBER:\n\n        ADD_METADATA(count, \"page_number\", \" / \");\n\n        break;\n\n    case TIFF_SOFTWARE_NAME:\n\n        ADD_METADATA(count, \"software\", NULL);\n\n        break;\n\n    default:\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"Unknown or unsupported tag %d/0X%0X\\n\",\n\n               tag, tag);\n\n    }\n\n    bytestream2_seek(&s->gb, start, SEEK_SET);\n\n    return 0;\n\n}\n", "idx": 26992}
{"project": "FFmpeg", "commit_id": "28b9ac4e48f3405a82e8e87ead336188215cf1e6", "target": 1, "func": "void av_log_default_callback(void *avcl, int level, const char *fmt, va_list vl)\n\n{\n\n    static int print_prefix = 1;\n\n    static int count;\n\n    static char prev[1024];\n\n    char line[1024];\n\n    static int is_atty;\n\n    AVClass* avc = avcl ? *(AVClass **) avcl : NULL;\n\n    int tint = av_clip(level >> 8, 0, 256);\n\n\n\n    level &= 0xff;\n\n\n\n    if (level > av_log_level)\n\n        return;\n\n    line[0] = 0;\n\n    if (print_prefix && avc) {\n\n        if (avc->parent_log_context_offset) {\n\n            AVClass** parent = *(AVClass ***) (((uint8_t *) avcl) +\n\n                                   avc->parent_log_context_offset);\n\n            if (parent && *parent) {\n\n                snprintf(line, sizeof(line), \"[%s @ %p] \",\n\n                         (*parent)->item_name(parent), parent);\n\n            }\n\n        }\n\n        snprintf(line + strlen(line), sizeof(line) - strlen(line), \"[%s @ %p] \",\n\n                 avc->item_name(avcl), avcl);\n\n    }\n\n\n\n    vsnprintf(line + strlen(line), sizeof(line) - strlen(line), fmt, vl);\n\n\n\n    print_prefix = strlen(line) && line[strlen(line) - 1] == '\\n';\n\n\n\n#if HAVE_ISATTY\n\n    if (!is_atty)\n\n        is_atty = isatty(2) ? 1 : -1;\n\n#endif\n\n\n\n    if (print_prefix && (flags & AV_LOG_SKIP_REPEATED) &&\n\n        !strncmp(line, prev, sizeof line)) {\n\n        count++;\n\n        if (is_atty == 1)\n\n            fprintf(stderr, \"    Last message repeated %d times\\r\", count);\n\n        return;\n\n    }\n\n    if (count > 0) {\n\n        fprintf(stderr, \"    Last message repeated %d times\\n\", count);\n\n        count = 0;\n\n    }\n\n    colored_fputs(av_clip(level >> 3, 0, 6), tint, line);\n\n    av_strlcpy(prev, line, sizeof line);\n\n}\n", "idx": 26994}
{"project": "FFmpeg", "commit_id": "20035fa24103da9199de3515ca75ba1f6bb275aa", "target": 1, "func": "static int scale_vector(int16_t *dst, const int16_t *vector, int length)\n\n{\n\n    int bits, max = 0;\n\n    int i;\n\n\n\n    for (i = 0; i < length; i++)\n\n        max |= FFABS(vector[i]);\n\n\n\n    bits  = normalize_bits(max, 15);\n\n\n\n    if (bits == 15)\n\n        for (i = 0; i < length; i++)\n\n            dst[i] = vector[i] * 0x7fff >> 3;\n\n    else\n\n        for (i = 0; i < length; i++)\n\n            dst[i] = vector[i] << bits >> 3;\n\n\n\n    return bits - 3;\n\n}\n", "idx": 26997}
{"project": "FFmpeg", "commit_id": "0a39c9ac0bfd7345fe676b4e2707d9cec3cbb553", "target": 0, "func": "av_cold void ff_hpeldsp_vp3_init_x86(HpelDSPContext *c, int cpu_flags, int flags)\n\n{\n\n    if (EXTERNAL_AMD3DNOW(cpu_flags)) {\n\n        if (flags & AV_CODEC_FLAG_BITEXACT) {\n\n            c->put_no_rnd_pixels_tab[1][1] = ff_put_no_rnd_pixels8_x2_exact_3dnow;\n\n            c->put_no_rnd_pixels_tab[1][2] = ff_put_no_rnd_pixels8_y2_exact_3dnow;\n\n        }\n\n    }\n\n\n\n    if (EXTERNAL_MMXEXT(cpu_flags)) {\n\n        if (flags & AV_CODEC_FLAG_BITEXACT) {\n\n            c->put_no_rnd_pixels_tab[1][1] = ff_put_no_rnd_pixels8_x2_exact_mmxext;\n\n            c->put_no_rnd_pixels_tab[1][2] = ff_put_no_rnd_pixels8_y2_exact_mmxext;\n\n        }\n\n    }\n\n}\n", "idx": 27005}
{"project": "FFmpeg", "commit_id": "205046420d5a4d389adb705538df3d6158be1fdb", "target": 0, "func": "static int expand(AVFilterContext *ctx, double *pz, int nb, double *coeffs)\n\n{\n\n    int i;\n\n\n\n    coeffs[0] = 1.0;\n\n    coeffs[1] = 0.0;\n\n\n\n    for (i = 0; i < nb; i++) {\n\n        coeffs[2 * (i + 1)    ] = 0.0;\n\n        coeffs[2 * (i + 1) + 1] = 0.0;\n\n    }\n\n\n\n    for (i = 0; i < nb; i++)\n\n        multiply(pz[2 * i], pz[2 * i + 1], nb, coeffs);\n\n\n\n    for (i = 0; i < nb + 1; i++) {\n\n        if (fabs(coeffs[2 * i + 1]) > DBL_EPSILON) {\n\n            av_log(ctx, AV_LOG_ERROR, \"coeff: %lf of z^%d is not real; poles/zeros are not complex conjugates.\\n\",\n\n                   coeffs[2 * i + i], i);\n\n            return AVERROR(EINVAL);\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 27016}
{"project": "FFmpeg", "commit_id": "229843aa359ae0c9519977d7fa952688db63f559", "target": 0, "func": "static int64_t ffm_seek1(AVFormatContext *s, int64_t pos1)\n\n{\n\n    FFMContext *ffm = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int64_t pos;\n\n\n\n    pos = FFMIN(pos1, ffm->file_size - FFM_PACKET_SIZE);\n\n    pos = FFMAX(pos, FFM_PACKET_SIZE);\n\n    av_dlog(s, \"seek to %\"PRIx64\" -> %\"PRIx64\"\\n\", pos1, pos);\n\n    return avio_seek(pb, pos, SEEK_SET);\n\n}\n", "idx": 27018}
{"project": "FFmpeg", "commit_id": "c04c3282b4334ff64cfd69d40fea010602e830fd", "target": 0, "func": "static int raw_read_header(AVFormatContext *s, AVFormatParameters *ap)\n\n{\n\n    AVStream *st;\n\n    int id;\n\n\n\n    st = av_new_stream(s, 0);\n\n    if (!st)\n\n        return AVERROR_NOMEM;\n\n    if (ap) {\n\n        id = s->iformat->value;\n\n        if (id == CODEC_ID_RAWVIDEO) {\n\n            st->codec->codec_type = CODEC_TYPE_VIDEO;\n\n        } else {\n\n            st->codec->codec_type = CODEC_TYPE_AUDIO;\n\n        }\n\n        st->codec->codec_id = id;\n\n\n\n        switch(st->codec->codec_type) {\n\n        case CODEC_TYPE_AUDIO:\n\n            st->codec->sample_rate = ap->sample_rate;\n\n            st->codec->channels = ap->channels;\n\n            av_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n            break;\n\n        case CODEC_TYPE_VIDEO:\n\n            av_set_pts_info(st, 64, ap->time_base.num, ap->time_base.den);\n\n            st->codec->width = ap->width;\n\n            st->codec->height = ap->height;\n\n            st->codec->pix_fmt = ap->pix_fmt;\n\n            if(st->codec->pix_fmt == PIX_FMT_NONE)\n\n                st->codec->pix_fmt= PIX_FMT_YUV420P;\n\n            break;\n\n        default:\n\n            return -1;\n\n        }\n\n    } else {\n\n        return -1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 27019}
{"project": "FFmpeg", "commit_id": "a8a6da4a0e059b2aab66627a96b63c3632c477c2", "target": 1, "func": "static av_cold int twin_decode_close(AVCodecContext *avctx)\n\n{\n\n    TwinContext *tctx = avctx->priv_data;\n\n    int i;\n\n\n\n    for (i = 0; i < 3; i++) {\n\n        ff_mdct_end(&tctx->mdct_ctx[i]);\n\n        av_free(tctx->cos_tabs[i]);\n\n    }\n\n\n\n\n\n    av_free(tctx->curr_frame);\n\n    av_free(tctx->spectrum);\n\n    av_free(tctx->prev_frame);\n\n    av_free(tctx->tmp_buf);\n\n\n\n    return 0;\n\n}\n", "idx": 27022}
{"project": "FFmpeg", "commit_id": "c04643a2c24564aed96a5b0760de8bf02eb305c6", "target": 0, "func": "void prepare_grab(void)\n\n{\n\n    int has_video, has_audio, i, j;\n\n    AVFormatContext *oc;\n\n    AVFormatContext *ic;\n\n    AVFormatParameters ap1, *ap = &ap1;\n\n\n\n    /* see if audio/video inputs are needed */\n\n    has_video = 0;\n\n    has_audio = 0;\n\n    memset(ap, 0, sizeof(*ap));\n\n    for(j=0;j<nb_output_files;j++) {\n\n        oc = output_files[j];\n\n        for(i=0;i<oc->nb_streams;i++) {\n\n            AVCodecContext *enc = &oc->streams[i]->codec;\n\n            switch(enc->codec_type) {\n\n            case CODEC_TYPE_AUDIO:\n\n                if (enc->sample_rate > ap->sample_rate)\n\n                    ap->sample_rate = enc->sample_rate;\n\n                if (enc->channels > ap->channels)\n\n                    ap->channels = enc->channels;\n\n                has_audio = 1;\n\n                break;\n\n            case CODEC_TYPE_VIDEO:\n\n                if (enc->width > ap->width)\n\n                    ap->width = enc->width;\n\n                if (enc->height > ap->height)\n\n                    ap->height = enc->height;\n\n                if (enc->frame_rate > ap->frame_rate)\n\n                    ap->frame_rate = enc->frame_rate;\n\n                has_video = 1;\n\n                break;\n\n            default:\n\n                abort();\n\n            }\n\n        }\n\n    }\n\n    \n\n    if (has_video == 0 && has_audio == 0) {\n\n        fprintf(stderr, \"Output file must have at least one audio or video stream\\n\");\n\n        exit(1);\n\n    }\n\n    \n\n    if (has_video) {\n\n        AVInputFormat *fmt1;\n\n        fmt1 = av_find_input_format(\"video_grab_device\");\n\n        if (av_open_input_file(&ic, \"\", fmt1, 0, ap) < 0) {\n\n            fprintf(stderr, \"Could not find video grab device\\n\");\n\n            exit(1);\n\n        }\n\n        /* by now video grab has one stream */\n\n        ic->streams[0]->r_frame_rate = ap->frame_rate;\n\n        input_files[nb_input_files] = ic;\n\n        dump_format(ic, nb_input_files, v4l_device, 0);\n\n        nb_input_files++;\n\n    }\n\n    if (has_audio) {\n\n        AVInputFormat *fmt1;\n\n        fmt1 = av_find_input_format(\"audio_device\");\n\n        if (av_open_input_file(&ic, \"\", fmt1, 0, ap) < 0) {\n\n            fprintf(stderr, \"Could not find audio grab device\\n\");\n\n            exit(1);\n\n        }\n\n        input_files[nb_input_files] = ic;\n\n        dump_format(ic, nb_input_files, audio_device, 0);\n\n        nb_input_files++;\n\n    }\n\n}\n", "idx": 27025}
{"project": "FFmpeg", "commit_id": "9156a5ad72e989e0fa2735741edf894fffad33b9", "target": 0, "func": "static void ipvideo_decode_opcodes(IpvideoContext *s)\n\n{\n\n    int x, y;\n\n    unsigned char opcode;\n\n    int ret;\n\n    static int frame = 0;\n\n    GetBitContext gb;\n\n\n\n    debug_interplay(\"------------------ frame %d\\n\", frame);\n\n    frame++;\n\n\n\n    /* this is PAL8, so make the palette available */\n\n    memcpy(s->current_frame.data[1], s->avctx->palctrl->palette, PALETTE_COUNT * 4);\n\n\n\n    s->stride = s->current_frame.linesize[0];\n\n    s->stream_ptr = s->buf + 14;  /* data starts 14 bytes in */\n\n    s->stream_end = s->buf + s->size;\n\n    s->line_inc = s->stride - 8;\n\n    s->upper_motion_limit_offset = (s->avctx->height - 8) * s->stride\n\n        + s->avctx->width - 8;\n\n\n\n    init_get_bits(&gb, s->decoding_map, s->decoding_map_size * 8);\n\n    for (y = 0; y < (s->stride * s->avctx->height); y += s->stride * 8) {\n\n        for (x = y; x < y + s->avctx->width; x += 8) {\n\n            opcode = get_bits(&gb, 4);\n\n\n\n            debug_interplay(\"  block @ (%3d, %3d): encoding 0x%X, data ptr @ %p\\n\",\n\n                            x - y, y / s->stride, opcode, s->stream_ptr);\n\n\n\n            s->pixel_ptr = s->current_frame.data[0] + x;\n\n            ret = ipvideo_decode_block[opcode](s);\n\n            if (ret != 0) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \" Interplay video: decode problem on frame %d, @ block (%d, %d)\\n\",\n\n                       frame, x - y, y / s->stride);\n\n                return;\n\n            }\n\n        }\n\n    }\n\n    if (s->stream_end - s->stream_ptr > 1) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \" Interplay video: decode finished with %td bytes left over\\n\",\n\n               s->stream_end - s->stream_ptr);\n\n    }\n\n}\n", "idx": 27026}
{"project": "FFmpeg", "commit_id": "0ebb523f072322972ea446616676fff32e9603c6", "target": 1, "func": "static int asf_read_seek(AVFormatContext *s, int stream_index,\n\n                         int64_t pts, int flags)\n\n{\n\n    ASFContext *asf = s->priv_data;\n\n    AVStream *st    = s->streams[stream_index];\n\n    int64_t pos;\n\n    int index;\n\n\n\n    if (s->packet_size <= 0)\n\n        return -1;\n\n\n\n    /* Try using the protocol's read_seek if available */\n\n    if (s->pb) {\n\n        int ret = avio_seek_time(s->pb, stream_index, pts, flags);\n\n        if (ret >= 0)\n\n            asf_reset_header(s);\n\n        if (ret != AVERROR(ENOSYS))\n\n            return ret;\n\n    }\n\n\n\n    if (!asf->index_read)\n\n        asf_build_simple_index(s, stream_index);\n\n\n\n    if ((asf->index_read && st->index_entries)) {\n\n        index = av_index_search_timestamp(st, pts, flags);\n\n        if (index >= 0) {\n\n            /* find the position */\n\n            pos = st->index_entries[index].pos;\n\n\n\n            /* do the seek */\n\n            av_log(s, AV_LOG_DEBUG, \"SEEKTO: %\"PRId64\"\\n\", pos);\n\n            avio_seek(s->pb, pos, SEEK_SET);\n\n            asf_reset_header(s);\n\n            return 0;\n\n        }\n\n    }\n\n    /* no index or seeking by index failed */\n\n    if (ff_seek_frame_binary(s, stream_index, pts, flags) < 0)\n\n        return -1;\n\n    asf_reset_header(s);\n\n    return 0;\n\n}\n", "idx": 27028}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "void ff_mpeg_unref_picture(MpegEncContext *s, Picture *pic)\n\n{\n\n    int off = offsetof(Picture, mb_mean) + sizeof(pic->mb_mean);\n\n\n\n    pic->tf.f = &pic->f;\n\n    /* WM Image / Screen codecs allocate internal buffers with different\n\n     * dimensions / colorspaces; ignore user-defined callbacks for these. */\n\n    if (s->codec_id != AV_CODEC_ID_WMV3IMAGE &&\n\n        s->codec_id != AV_CODEC_ID_VC1IMAGE  &&\n\n        s->codec_id != AV_CODEC_ID_MSS2)\n\n        ff_thread_release_buffer(s->avctx, &pic->tf);\n\n    else\n\n        av_frame_unref(&pic->f);\n\n\n\n    av_buffer_unref(&pic->hwaccel_priv_buf);\n\n\n\n    if (pic->needs_realloc)\n\n        ff_free_picture_tables(pic);\n\n\n\n    memset((uint8_t*)pic + off, 0, sizeof(*pic) - off);\n\n}\n", "idx": 27029}
{"project": "FFmpeg", "commit_id": "ad22767cb61cdc75541b21154d65fd1ad6351025", "target": 1, "func": "static int shorten_decode_frame(AVCodecContext *avctx, void *data,\n\n                                int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    AVFrame *frame     = data;\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    ShortenContext *s  = avctx->priv_data;\n\n    int i, input_buf_size = 0;\n\n    int ret;\n\n\n\n    /* allocate internal bitstream buffer */\n\n    if (s->max_framesize == 0) {\n\n        void *tmp_ptr;\n\n        s->max_framesize = 8192; // should hopefully be enough for the first header\n\n        tmp_ptr = av_fast_realloc(s->bitstream, &s->allocated_bitstream_size,\n\n                                  s->max_framesize + FF_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!tmp_ptr) {\n\n            av_log(avctx, AV_LOG_ERROR, \"error allocating bitstream buffer\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        s->bitstream = tmp_ptr;\n\n    }\n\n\n\n    /* append current packet data to bitstream buffer */\n\n    if (1 && s->max_framesize) { //FIXME truncated\n\n        buf_size       = FFMIN(buf_size, s->max_framesize - s->bitstream_size);\n\n        input_buf_size = buf_size;\n\n\n\n        if (s->bitstream_index + s->bitstream_size + buf_size >\n\n            s->allocated_bitstream_size) {\n\n            memmove(s->bitstream, &s->bitstream[s->bitstream_index],\n\n                    s->bitstream_size);\n\n            s->bitstream_index = 0;\n\n        }\n\n        if (buf)\n\n            memcpy(&s->bitstream[s->bitstream_index + s->bitstream_size], buf,\n\n                   buf_size);\n\n        buf               = &s->bitstream[s->bitstream_index];\n\n        buf_size         += s->bitstream_size;\n\n        s->bitstream_size = buf_size;\n\n\n\n        /* do not decode until buffer has at least max_framesize bytes or\n\n         * the end of the file has been reached */\n\n        if (buf_size < s->max_framesize && avpkt->data) {\n\n            *got_frame_ptr = 0;\n\n            return input_buf_size;\n\n        }\n\n    }\n\n    /* init and position bitstream reader */\n\n    init_get_bits(&s->gb, buf, buf_size * 8);\n\n    skip_bits(&s->gb, s->bitindex);\n\n\n\n    /* process header or next subblock */\n\n    if (!s->got_header) {\n\n        if ((ret = read_header(s)) < 0)\n\n            return ret;\n\n        *got_frame_ptr = 0;\n\n        goto finish_frame;\n\n    }\n\n\n\n    /* if quit command was read previously, don't decode anything */\n\n    if (s->got_quit_command) {\n\n        *got_frame_ptr = 0;\n\n        return avpkt->size;\n\n    }\n\n\n\n    s->cur_chan = 0;\n\n    while (s->cur_chan < s->channels) {\n\n        unsigned cmd;\n\n        int len;\n\n\n\n        if (get_bits_left(&s->gb) < 3 + FNSIZE) {\n\n            *got_frame_ptr = 0;\n\n            break;\n\n        }\n\n\n\n        cmd = get_ur_golomb_shorten(&s->gb, FNSIZE);\n\n\n\n        if (cmd > FN_VERBATIM) {\n\n            av_log(avctx, AV_LOG_ERROR, \"unknown shorten function %d\\n\", cmd);\n\n            *got_frame_ptr = 0;\n\n            break;\n\n        }\n\n\n\n        if (!is_audio_command[cmd]) {\n\n            /* process non-audio command */\n\n            switch (cmd) {\n\n            case FN_VERBATIM:\n\n                len = get_ur_golomb_shorten(&s->gb, VERBATIM_CKSIZE_SIZE);\n\n                while (len--)\n\n                    get_ur_golomb_shorten(&s->gb, VERBATIM_BYTE_SIZE);\n\n                break;\n\n            case FN_BITSHIFT:\n\n                s->bitshift = get_ur_golomb_shorten(&s->gb, BITSHIFTSIZE);\n\n                break;\n\n            case FN_BLOCKSIZE: {\n\n                unsigned blocksize = get_uint(s, av_log2(s->blocksize));\n\n                if (blocksize > s->blocksize) {\n\n                    av_log(avctx, AV_LOG_ERROR,\n\n                           \"Increasing block size is not supported\\n\");\n\n                    return AVERROR_PATCHWELCOME;\n\n                }\n\n                if (!blocksize || blocksize > MAX_BLOCKSIZE) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"invalid or unsupported \"\n\n                                                \"block size: %d\\n\", blocksize);\n\n                    return AVERROR(EINVAL);\n\n                }\n\n                s->blocksize = blocksize;\n\n                break;\n\n            }\n\n            case FN_QUIT:\n\n                s->got_quit_command = 1;\n\n                break;\n\n            }\n\n            if (cmd == FN_BLOCKSIZE || cmd == FN_QUIT) {\n\n                *got_frame_ptr = 0;\n\n                break;\n\n            }\n\n        } else {\n\n            /* process audio command */\n\n            int residual_size = 0;\n\n            int channel = s->cur_chan;\n\n            int32_t coffset;\n\n\n\n            /* get Rice code for residual decoding */\n\n            if (cmd != FN_ZERO) {\n\n                residual_size = get_ur_golomb_shorten(&s->gb, ENERGYSIZE);\n\n                /* This is a hack as version 0 differed in the definition\n\n                 * of get_sr_golomb_shorten(). */\n\n                if (s->version == 0)\n\n                    residual_size--;\n\n            }\n\n\n\n            /* calculate sample offset using means from previous blocks */\n\n            if (s->nmean == 0)\n\n                coffset = s->offset[channel][0];\n\n            else {\n\n                int32_t sum = (s->version < 2) ? 0 : s->nmean / 2;\n\n                for (i = 0; i < s->nmean; i++)\n\n                    sum += s->offset[channel][i];\n\n                coffset = sum / s->nmean;\n\n                if (s->version >= 2)\n\n                    coffset = s->bitshift == 0 ? coffset : coffset >> s->bitshift - 1 >> 1;\n\n            }\n\n\n\n            /* decode samples for this channel */\n\n            if (cmd == FN_ZERO) {\n\n                for (i = 0; i < s->blocksize; i++)\n\n                    s->decoded[channel][i] = 0;\n\n            } else {\n\n                if ((ret = decode_subframe_lpc(s, cmd, channel,\n\n                                               residual_size, coffset)) < 0)\n\n                    return ret;\n\n            }\n\n\n\n            /* update means with info from the current block */\n\n            if (s->nmean > 0) {\n\n                int32_t sum = (s->version < 2) ? 0 : s->blocksize / 2;\n\n                for (i = 0; i < s->blocksize; i++)\n\n                    sum += s->decoded[channel][i];\n\n\n\n                for (i = 1; i < s->nmean; i++)\n\n                    s->offset[channel][i - 1] = s->offset[channel][i];\n\n\n\n                if (s->version < 2)\n\n                    s->offset[channel][s->nmean - 1] = sum / s->blocksize;\n\n                else\n\n                    s->offset[channel][s->nmean - 1] = (sum / s->blocksize) << s->bitshift;\n\n            }\n\n\n\n            /* copy wrap samples for use with next block */\n\n            for (i = -s->nwrap; i < 0; i++)\n\n                s->decoded[channel][i] = s->decoded[channel][i + s->blocksize];\n\n\n\n            /* shift samples to add in unused zero bits which were removed\n\n             * during encoding */\n\n            fix_bitshift(s, s->decoded[channel]);\n\n\n\n            /* if this is the last channel in the block, output the samples */\n\n            s->cur_chan++;\n\n            if (s->cur_chan == s->channels) {\n\n                uint8_t *samples_u8;\n\n                int16_t *samples_s16;\n\n                int chan;\n\n\n\n                /* get output buffer */\n\n                frame->nb_samples = s->blocksize;\n\n                if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n\n                    return ret;\n\n\n\n                for (chan = 0; chan < s->channels; chan++) {\n\n                    samples_u8  = ((uint8_t **)frame->extended_data)[chan];\n\n                    samples_s16 = ((int16_t **)frame->extended_data)[chan];\n\n                    for (i = 0; i < s->blocksize; i++) {\n\n                        switch (s->internal_ftype) {\n\n                        case TYPE_U8:\n\n                            *samples_u8++ = av_clip_uint8(s->decoded[chan][i]);\n\n                            break;\n\n                        case TYPE_S16HL:\n\n                        case TYPE_S16LH:\n\n                            *samples_s16++ = av_clip_int16(s->decoded[chan][i]);\n\n                            break;\n\n                        }\n\n                    }\n\n                }\n\n\n\n                *got_frame_ptr = 1;\n\n            }\n\n        }\n\n    }\n\n    if (s->cur_chan < s->channels)\n\n        *got_frame_ptr = 0;\n\n\n\nfinish_frame:\n\n    s->bitindex = get_bits_count(&s->gb) - 8 * (get_bits_count(&s->gb) / 8);\n\n    i           = get_bits_count(&s->gb) / 8;\n\n    if (i > buf_size) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"overread: %d\\n\", i - buf_size);\n\n        s->bitstream_size  = 0;\n\n        s->bitstream_index = 0;\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (s->bitstream_size) {\n\n        s->bitstream_index += i;\n\n        s->bitstream_size  -= i;\n\n        return input_buf_size;\n\n    } else\n\n        return i;\n\n}\n", "idx": 27032}
{"project": "FFmpeg", "commit_id": "de6c150444159a26fe2555089d384ddd2d6459aa", "target": 1, "func": "int64_t ff_lsb2full(StreamContext *stream, int64_t lsb){\n\n    int64_t mask = (1<<stream->msb_pts_shift)-1;\n\n    int64_t delta= stream->last_pts - mask/2;\n\n    return  ((lsb - delta)&mask) + delta;\n\n}\n", "idx": 27033}
{"project": "FFmpeg", "commit_id": "324ff59444ff5470bb325ff1e2be7c4b054fc944", "target": 0, "func": "int ff_audio_rechunk_interleave(AVFormatContext *s, AVPacket *out, AVPacket *pkt, int flush,\n\n                        int (*get_packet)(AVFormatContext *, AVPacket *, AVPacket *, int),\n\n                        int (*compare_ts)(AVFormatContext *, AVPacket *, AVPacket *))\n\n{\n\n    int i;\n\n\n\n    if (pkt) {\n\n        AVStream *st = s->streams[pkt->stream_index];\n\n        AudioInterleaveContext *aic = st->priv_data;\n\n        if (st->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            unsigned new_size = av_fifo_size(aic->fifo) + pkt->size;\n\n            if (new_size > aic->fifo_size) {\n\n                if (av_fifo_realloc2(aic->fifo, new_size) < 0)\n\n                    return -1;\n\n                aic->fifo_size = new_size;\n\n            }\n\n            av_fifo_generic_write(aic->fifo, pkt->data, pkt->size, NULL);\n\n        } else {\n\n            // rewrite pts and dts to be decoded time line position\n\n            pkt->pts = pkt->dts = aic->dts;\n\n            aic->dts += pkt->duration;\n\n            ff_interleave_add_packet(s, pkt, compare_ts);\n\n        }\n\n        pkt = NULL;\n\n    }\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVStream *st = s->streams[i];\n\n        if (st->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            AVPacket new_pkt;\n\n            while (interleave_new_audio_packet(s, &new_pkt, i, flush))\n\n                ff_interleave_add_packet(s, &new_pkt, compare_ts);\n\n        }\n\n    }\n\n\n\n    return get_packet(s, out, NULL, flush);\n\n}\n", "idx": 27041}
{"project": "FFmpeg", "commit_id": "d150a147dac67faeaf6b1f25a523ae330168ee1e", "target": 0, "func": "static av_cold int init_decoder(AVCodecContext *avctx)\n\n{\n\n    avctx->pix_fmt = PIX_FMT_PAL8;\n\n\n\n    return 0;\n\n}\n", "idx": 27042}
{"project": "FFmpeg", "commit_id": "55815edca038997ec283569a192a3eca7f2143bc", "target": 0, "func": "static void opt_output_file(const char *filename)\n\n{\n\n    AVFormatContext *oc;\n\n    int err, use_video, use_audio, use_subtitle;\n\n    int input_has_video, input_has_audio, input_has_subtitle;\n\n    AVFormatParameters params, *ap = &params;\n\n    AVOutputFormat *file_oformat;\n\n\n\n    if (!strcmp(filename, \"-\"))\n\n        filename = \"pipe:\";\n\n\n\n    oc = avformat_alloc_context();\n\n    if (!oc) {\n\n        print_error(filename, AVERROR(ENOMEM));\n\n        ffmpeg_exit(1);\n\n    }\n\n\n\n    if (last_asked_format) {\n\n        file_oformat = av_guess_format(last_asked_format, NULL, NULL);\n\n        if (!file_oformat) {\n\n            fprintf(stderr, \"Requested output format '%s' is not a suitable output format\\n\", last_asked_format);\n\n            ffmpeg_exit(1);\n\n        }\n\n        last_asked_format = NULL;\n\n    } else {\n\n        file_oformat = av_guess_format(NULL, filename, NULL);\n\n        if (!file_oformat) {\n\n            fprintf(stderr, \"Unable to find a suitable output format for '%s'\\n\",\n\n                    filename);\n\n            ffmpeg_exit(1);\n\n        }\n\n    }\n\n\n\n    oc->oformat = file_oformat;\n\n    av_strlcpy(oc->filename, filename, sizeof(oc->filename));\n\n\n\n    if (!strcmp(file_oformat->name, \"ffm\") &&\n\n        av_strstart(filename, \"http:\", NULL)) {\n\n        /* special case for files sent to ffserver: we get the stream\n\n           parameters from ffserver */\n\n        int err = read_ffserver_streams(oc, filename);\n\n        if (err < 0) {\n\n            print_error(filename, err);\n\n            ffmpeg_exit(1);\n\n        }\n\n    } else {\n\n        use_video = file_oformat->video_codec != CODEC_ID_NONE || video_stream_copy || video_codec_name;\n\n        use_audio = file_oformat->audio_codec != CODEC_ID_NONE || audio_stream_copy || audio_codec_name;\n\n        use_subtitle = file_oformat->subtitle_codec != CODEC_ID_NONE || subtitle_stream_copy || subtitle_codec_name;\n\n\n\n        /* disable if no corresponding type found and at least one\n\n           input file */\n\n        if (nb_input_files > 0) {\n\n            check_audio_video_sub_inputs(&input_has_video, &input_has_audio,\n\n                                         &input_has_subtitle);\n\n            if (!input_has_video)\n\n                use_video = 0;\n\n            if (!input_has_audio)\n\n                use_audio = 0;\n\n            if (!input_has_subtitle)\n\n                use_subtitle = 0;\n\n        }\n\n\n\n        /* manual disable */\n\n        if (audio_disable)    use_audio    = 0;\n\n        if (video_disable)    use_video    = 0;\n\n        if (subtitle_disable) use_subtitle = 0;\n\n\n\n        if (use_video)    new_video_stream(oc, nb_output_files);\n\n        if (use_audio)    new_audio_stream(oc, nb_output_files);\n\n        if (use_subtitle) new_subtitle_stream(oc, nb_output_files);\n\n\n\n        oc->timestamp = recording_timestamp;\n\n\n\n        av_metadata_copy(&oc->metadata, metadata, 0);\n\n        av_metadata_free(&metadata);\n\n    }\n\n\n\n    output_files[nb_output_files++] = oc;\n\n\n\n    /* check filename in case of an image number is expected */\n\n    if (oc->oformat->flags & AVFMT_NEEDNUMBER) {\n\n        if (!av_filename_number_test(oc->filename)) {\n\n            print_error(oc->filename, AVERROR_NUMEXPECTED);\n\n            ffmpeg_exit(1);\n\n        }\n\n    }\n\n\n\n    if (!(oc->oformat->flags & AVFMT_NOFILE)) {\n\n        /* test if it already exists to avoid loosing precious files */\n\n        if (!file_overwrite &&\n\n            (strchr(filename, ':') == NULL ||\n\n             filename[1] == ':' ||\n\n             av_strstart(filename, \"file:\", NULL))) {\n\n            if (url_exist(filename)) {\n\n                if (!using_stdin) {\n\n                    fprintf(stderr,\"File '%s' already exists. Overwrite ? [y/N] \", filename);\n\n                    fflush(stderr);\n\n                    if (!read_yesno()) {\n\n                        fprintf(stderr, \"Not overwriting - exiting\\n\");\n\n                        ffmpeg_exit(1);\n\n                    }\n\n                }\n\n                else {\n\n                    fprintf(stderr,\"File '%s' already exists. Exiting.\\n\", filename);\n\n                    ffmpeg_exit(1);\n\n                }\n\n            }\n\n        }\n\n\n\n        /* open the file */\n\n        if ((err = avio_open(&oc->pb, filename, AVIO_FLAG_WRITE)) < 0) {\n\n            print_error(filename, err);\n\n            ffmpeg_exit(1);\n\n        }\n\n    }\n\n\n\n    memset(ap, 0, sizeof(*ap));\n\n    if (av_set_parameters(oc, ap) < 0) {\n\n        fprintf(stderr, \"%s: Invalid encoding parameters\\n\",\n\n                oc->filename);\n\n        ffmpeg_exit(1);\n\n    }\n\n\n\n    oc->preload= (int)(mux_preload*AV_TIME_BASE);\n\n    oc->max_delay= (int)(mux_max_delay*AV_TIME_BASE);\n\n    oc->loop_output = loop_output;\n\n    oc->flags |= AVFMT_FLAG_NONBLOCK;\n\n\n\n    set_context_opts(oc, avformat_opts, AV_OPT_FLAG_ENCODING_PARAM, NULL);\n\n\n\n    av_freep(&forced_key_frames);\n\n}\n", "idx": 27043}
{"project": "FFmpeg", "commit_id": "140f48b90fbe32a88423aad473bccc72c3bb450e", "target": 0, "func": "static int smc_decode_frame(AVCodecContext *avctx,\n\n                             void *data, int *got_frame,\n\n                             AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    SmcContext *s = avctx->priv_data;\n\n    const uint8_t *pal = av_packet_get_side_data(avpkt, AV_PKT_DATA_PALETTE, NULL);\n\n    int ret;\n\n\n\n    bytestream2_init(&s->gb, buf, buf_size);\n\n\n\n    if ((ret = ff_reget_buffer(avctx, s->frame)) < 0)\n\n        return ret;\n\n\n\n    if (pal) {\n\n        s->frame->palette_has_changed = 1;\n\n        memcpy(s->pal, pal, AVPALETTE_SIZE);\n\n    }\n\n\n\n    smc_decode_stream(s);\n\n\n\n    *got_frame      = 1;\n\n    if ((ret = av_frame_ref(data, s->frame)) < 0)\n\n        return ret;\n\n\n\n    /* always report that the buffer was completely consumed */\n\n    return buf_size;\n\n}\n", "idx": 27051}
{"project": "FFmpeg", "commit_id": "8849c4ceac0f35e88b2dc406bf5ffc4173a38ffe", "target": 0, "func": "static inline void apply_8x8(MpegEncContext *s,\n\n                             uint8_t *dest_y,\n\n                             uint8_t *dest_cb,\n\n                             uint8_t *dest_cr,\n\n                             int dir,\n\n                             uint8_t **ref_picture,\n\n                             qpel_mc_func (*qpix_op)[16],\n\n                             op_pixels_func (*pix_op)[4])\n\n{\n\n    int dxy, mx, my, src_x, src_y;\n\n    int i;\n\n    int mb_x = s->mb_x;\n\n    int mb_y = s->mb_y;\n\n    uint8_t *ptr, *dest;\n\n\n\n    mx = 0;\n\n    my = 0;\n\n    if (s->quarter_sample) {\n\n        for (i = 0; i < 4; i++) {\n\n            int motion_x = s->mv[dir][i][0];\n\n            int motion_y = s->mv[dir][i][1];\n\n\n\n            dxy   = ((motion_y & 3) << 2) | (motion_x & 3);\n\n            src_x = mb_x * 16 + (motion_x >> 2) + (i & 1) * 8;\n\n            src_y = mb_y * 16 + (motion_y >> 2) + (i >> 1) * 8;\n\n\n\n            /* WARNING: do no forget half pels */\n\n            src_x = av_clip(src_x, -16, s->width);\n\n            if (src_x == s->width)\n\n                dxy &= ~3;\n\n            src_y = av_clip(src_y, -16, s->height);\n\n            if (src_y == s->height)\n\n                dxy &= ~12;\n\n\n\n            ptr = ref_picture[0] + (src_y * s->linesize) + (src_x);\n\n            if ((unsigned)src_x > FFMAX(s->h_edge_pos - (motion_x & 3) - 8, 0) ||\n\n                (unsigned)src_y > FFMAX(s->v_edge_pos - (motion_y & 3) - 8, 0)) {\n\n                s->vdsp.emulated_edge_mc(s->edge_emu_buffer, ptr,\n\n                                         s->linesize, s->linesize,\n\n                                         9, 9,\n\n                                         src_x, src_y,\n\n                                         s->h_edge_pos,\n\n                                         s->v_edge_pos);\n\n                ptr = s->edge_emu_buffer;\n\n            }\n\n            dest = dest_y + ((i & 1) * 8) + (i >> 1) * 8 * s->linesize;\n\n            qpix_op[1][dxy](dest, ptr, s->linesize);\n\n\n\n            mx += s->mv[dir][i][0] / 2;\n\n            my += s->mv[dir][i][1] / 2;\n\n        }\n\n    } else {\n\n        for (i = 0; i < 4; i++) {\n\n            hpel_motion(s,\n\n                        dest_y + ((i & 1) * 8) + (i >> 1) * 8 * s->linesize,\n\n                        ref_picture[0],\n\n                        mb_x * 16 + (i & 1) * 8,\n\n                        mb_y * 16 + (i >> 1) * 8,\n\n                        pix_op[1],\n\n                        s->mv[dir][i][0],\n\n                        s->mv[dir][i][1]);\n\n\n\n            mx += s->mv[dir][i][0];\n\n            my += s->mv[dir][i][1];\n\n        }\n\n    }\n\n\n\n    if (!CONFIG_GRAY || !(s->flags & CODEC_FLAG_GRAY))\n\n        chroma_4mv_motion(s, dest_cb, dest_cr,\n\n                          ref_picture, pix_op[1], mx, my);\n\n}\n", "idx": 27062}
{"project": "FFmpeg", "commit_id": "0242351390643d176b10600c2eb854414f9559e6", "target": 0, "func": "void mpeg_motion_internal(MpegEncContext *s,\n\n                          uint8_t *dest_y,\n\n                          uint8_t *dest_cb,\n\n                          uint8_t *dest_cr,\n\n                          int field_based,\n\n                          int bottom_field,\n\n                          int field_select,\n\n                          uint8_t **ref_picture,\n\n                          op_pixels_func (*pix_op)[4],\n\n                          int motion_x,\n\n                          int motion_y,\n\n                          int h,\n\n                          int is_mpeg12,\n\n                          int mb_y)\n\n{\n\n    uint8_t *ptr_y, *ptr_cb, *ptr_cr;\n\n    int dxy, uvdxy, mx, my, src_x, src_y,\n\n        uvsrc_x, uvsrc_y, v_edge_pos;\n\n    ptrdiff_t uvlinesize, linesize;\n\n\n\n#if 0\n\n    if (s->quarter_sample) {\n\n        motion_x >>= 1;\n\n        motion_y >>= 1;\n\n    }\n\n#endif\n\n\n\n    v_edge_pos = s->v_edge_pos >> field_based;\n\n    linesize   = s->current_picture.f->linesize[0] << field_based;\n\n    uvlinesize = s->current_picture.f->linesize[1] << field_based;\n\n\n\n    dxy   = ((motion_y & 1) << 1) | (motion_x & 1);\n\n    src_x = s->mb_x * 16 + (motion_x >> 1);\n\n    src_y = (mb_y << (4 - field_based)) + (motion_y >> 1);\n\n\n\n    if (!is_mpeg12 && s->out_format == FMT_H263) {\n\n        if ((s->workaround_bugs & FF_BUG_HPEL_CHROMA) && field_based) {\n\n            mx      = (motion_x >> 1) | (motion_x & 1);\n\n            my      = motion_y >> 1;\n\n            uvdxy   = ((my & 1) << 1) | (mx & 1);\n\n            uvsrc_x = s->mb_x * 8 + (mx >> 1);\n\n            uvsrc_y = (mb_y << (3 - field_based)) + (my >> 1);\n\n        } else {\n\n            uvdxy   = dxy | (motion_y & 2) | ((motion_x & 2) >> 1);\n\n            uvsrc_x = src_x >> 1;\n\n            uvsrc_y = src_y >> 1;\n\n        }\n\n    // Even chroma mv's are full pel in H261\n\n    } else if (!is_mpeg12 && s->out_format == FMT_H261) {\n\n        mx      = motion_x / 4;\n\n        my      = motion_y / 4;\n\n        uvdxy   = 0;\n\n        uvsrc_x = s->mb_x * 8 + mx;\n\n        uvsrc_y = mb_y * 8 + my;\n\n    } else {\n\n        if (s->chroma_y_shift) {\n\n            mx      = motion_x / 2;\n\n            my      = motion_y / 2;\n\n            uvdxy   = ((my & 1) << 1) | (mx & 1);\n\n            uvsrc_x = s->mb_x * 8 + (mx >> 1);\n\n            uvsrc_y = (mb_y << (3 - field_based)) + (my >> 1);\n\n        } else {\n\n            if (s->chroma_x_shift) {\n\n                // Chroma422\n\n                mx      = motion_x / 2;\n\n                uvdxy   = ((motion_y & 1) << 1) | (mx & 1);\n\n                uvsrc_x = s->mb_x * 8 + (mx >> 1);\n\n                uvsrc_y = src_y;\n\n            } else {\n\n                // Chroma444\n\n                uvdxy   = dxy;\n\n                uvsrc_x = src_x;\n\n                uvsrc_y = src_y;\n\n            }\n\n        }\n\n    }\n\n\n\n    ptr_y  = ref_picture[0] + src_y * linesize + src_x;\n\n    ptr_cb = ref_picture[1] + uvsrc_y * uvlinesize + uvsrc_x;\n\n    ptr_cr = ref_picture[2] + uvsrc_y * uvlinesize + uvsrc_x;\n\n\n\n    if ((unsigned)src_x > FFMAX(s->h_edge_pos - (motion_x & 1) - 16, 0) ||\n\n        (unsigned)src_y > FFMAX(v_edge_pos - (motion_y & 1) - h, 0)) {\n\n        if (is_mpeg12 ||\n\n            s->codec_id == AV_CODEC_ID_MPEG2VIDEO ||\n\n            s->codec_id == AV_CODEC_ID_MPEG1VIDEO) {\n\n            av_log(s->avctx, AV_LOG_DEBUG,\n\n                   \"MPEG motion vector out of boundary (%d %d)\\n\", src_x,\n\n                   src_y);\n\n            return;\n\n        }\n\n        s->vdsp.emulated_edge_mc(s->sc.edge_emu_buffer, ptr_y,\n\n                                 s->linesize, s->linesize,\n\n                                 17, 17 + field_based,\n\n                                 src_x, src_y << field_based,\n\n                                 s->h_edge_pos, s->v_edge_pos);\n\n        ptr_y = s->sc.edge_emu_buffer;\n\n        if (!CONFIG_GRAY || !(s->avctx->flags & AV_CODEC_FLAG_GRAY)) {\n\n            uint8_t *uvbuf = s->sc.edge_emu_buffer + 18 * s->linesize;\n\n            s->vdsp.emulated_edge_mc(uvbuf, ptr_cb,\n\n                                     s->uvlinesize, s->uvlinesize,\n\n                                     9, 9 + field_based,\n\n                                     uvsrc_x, uvsrc_y << field_based,\n\n                                     s->h_edge_pos >> 1, s->v_edge_pos >> 1);\n\n            s->vdsp.emulated_edge_mc(uvbuf + 16, ptr_cr,\n\n                                     s->uvlinesize, s->uvlinesize,\n\n                                     9, 9 + field_based,\n\n                                     uvsrc_x, uvsrc_y << field_based,\n\n                                     s->h_edge_pos >> 1, s->v_edge_pos >> 1);\n\n            ptr_cb = uvbuf;\n\n            ptr_cr = uvbuf + 16;\n\n        }\n\n    }\n\n\n\n    /* FIXME use this for field pix too instead of the obnoxious hack which\n\n     * changes picture.data */\n\n    if (bottom_field) {\n\n        dest_y  += s->linesize;\n\n        dest_cb += s->uvlinesize;\n\n        dest_cr += s->uvlinesize;\n\n    }\n\n\n\n    if (field_select) {\n\n        ptr_y  += s->linesize;\n\n        ptr_cb += s->uvlinesize;\n\n        ptr_cr += s->uvlinesize;\n\n    }\n\n\n\n    pix_op[0][dxy](dest_y, ptr_y, linesize, h);\n\n\n\n    if (!CONFIG_GRAY || !(s->avctx->flags & AV_CODEC_FLAG_GRAY)) {\n\n        pix_op[s->chroma_x_shift][uvdxy]\n\n            (dest_cb, ptr_cb, uvlinesize, h >> s->chroma_y_shift);\n\n        pix_op[s->chroma_x_shift][uvdxy]\n\n            (dest_cr, ptr_cr, uvlinesize, h >> s->chroma_y_shift);\n\n    }\n\n    if (!is_mpeg12 && (CONFIG_H261_ENCODER || CONFIG_H261_DECODER) &&\n\n        s->out_format == FMT_H261) {\n\n        ff_h261_loop_filter(s);\n\n    }\n\n}\n", "idx": 27063}
{"project": "FFmpeg", "commit_id": "253d0be6a1ecc343d29ff8e1df0ddf961ab9c772", "target": 0, "func": "static void parse_palette_segment(AVCodecContext *avctx,\n\n                                  const uint8_t *buf, int buf_size)\n\n{\n\n    PGSSubContext *ctx = avctx->priv_data;\n\n\n\n    const uint8_t *buf_end = buf + buf_size;\n\n    const uint8_t *cm      = ff_crop_tab + MAX_NEG_CROP;\n\n    int color_id;\n\n    int y, cb, cr, alpha;\n\n    int r, g, b, r_add, g_add, b_add;\n\n\n\n    /* Skip two null bytes */\n\n    buf += 2;\n\n\n\n    while (buf < buf_end) {\n\n        color_id  = bytestream_get_byte(&buf);\n\n        y         = bytestream_get_byte(&buf);\n\n        cr        = bytestream_get_byte(&buf);\n\n        cb        = bytestream_get_byte(&buf);\n\n        alpha     = bytestream_get_byte(&buf);\n\n\n\n        YUV_TO_RGB1(cb, cr);\n\n        YUV_TO_RGB2(r, g, b, y);\n\n\n\n        av_dlog(avctx, \"Color %d := (%d,%d,%d,%d)\\n\", color_id, r, g, b, alpha);\n\n\n\n        /* Store color in palette */\n\n        ctx->clut[color_id] = RGBA(r,g,b,alpha);\n\n    }\n\n}\n", "idx": 27064}
{"project": "FFmpeg", "commit_id": "29034e65039ef6b1854ceeb76ffe4092992d9fd5", "target": 0, "func": "static int transcode(OutputFile *output_files, int nb_output_files,\n\n                     InputFile  *input_files,  int nb_input_files)\n\n{\n\n    int ret, i;\n\n    AVFormatContext *is, *os;\n\n    OutputStream *ost;\n\n    InputStream *ist;\n\n    uint8_t *no_packet;\n\n    int no_packet_count = 0;\n\n    int64_t timer_start;\n\n    int key;\n\n\n\n    if (!(no_packet = av_mallocz(nb_input_files)))\n\n        exit_program(1);\n\n\n\n    ret = transcode_init(output_files, nb_output_files, input_files, nb_input_files);\n\n    if (ret < 0)\n\n        goto fail;\n\n\n\n    if (!using_stdin) {\n\n        av_log(NULL, AV_LOG_INFO, \"Press [q] to stop, [?] for help\\n\");\n\n    }\n\n\n\n    timer_start = av_gettime();\n\n\n\n    for (; received_sigterm == 0;) {\n\n        int file_index, ist_index;\n\n        AVPacket pkt;\n\n        int64_t ipts_min;\n\n        double opts_min;\n\n        int64_t cur_time= av_gettime();\n\n\n\n        ipts_min = INT64_MAX;\n\n        opts_min = 1e100;\n\n        /* if 'q' pressed, exits */\n\n        if (!using_stdin) {\n\n            static int64_t last_time;\n\n            if (received_nb_signals)\n\n                break;\n\n            /* read_key() returns 0 on EOF */\n\n            if(cur_time - last_time >= 100000 && !run_as_daemon){\n\n                key =  read_key();\n\n                last_time = cur_time;\n\n            }else\n\n                key = -1;\n\n            if (key == 'q')\n\n                break;\n\n            if (key == '+') av_log_set_level(av_log_get_level()+10);\n\n            if (key == '-') av_log_set_level(av_log_get_level()-10);\n\n            if (key == 's') qp_hist     ^= 1;\n\n            if (key == 'h'){\n\n                if (do_hex_dump){\n\n                    do_hex_dump = do_pkt_dump = 0;\n\n                } else if(do_pkt_dump){\n\n                    do_hex_dump = 1;\n\n                } else\n\n                    do_pkt_dump = 1;\n\n                av_log_set_level(AV_LOG_DEBUG);\n\n            }\n\n#if CONFIG_AVFILTER\n\n            if (key == 'c' || key == 'C'){\n\n                char buf[4096], target[64], command[256], arg[256] = {0};\n\n                double time;\n\n                int k, n = 0;\n\n                fprintf(stderr, \"\\nEnter command: <target> <time> <command>[ <argument>]\\n\");\n\n                i = 0;\n\n                while ((k = read_key()) != '\\n' && k != '\\r' && i < sizeof(buf)-1)\n\n                    if (k > 0)\n\n                        buf[i++] = k;\n\n                buf[i] = 0;\n\n                if (k > 0 &&\n\n                    (n = sscanf(buf, \"%63[^ ] %lf %255[^ ] %255[^\\n]\", target, &time, command, arg)) >= 3) {\n\n                    av_log(NULL, AV_LOG_DEBUG, \"Processing command target:%s time:%f command:%s arg:%s\",\n\n                           target, time, command, arg);\n\n                    for (i = 0; i < nb_output_streams; i++) {\n\n                        ost = &output_streams[i];\n\n                        if (ost->graph) {\n\n                            if (time < 0) {\n\n                                ret = avfilter_graph_send_command(ost->graph, target, command, arg, buf, sizeof(buf),\n\n                                                                  key == 'c' ? AVFILTER_CMD_FLAG_ONE : 0);\n\n                                fprintf(stderr, \"Command reply for stream %d: ret:%d res:%s\\n\", i, ret, buf);\n\n                            } else {\n\n                                ret = avfilter_graph_queue_command(ost->graph, target, command, arg, 0, time);\n\n                            }\n\n                        }\n\n                    }\n\n                } else {\n\n                    av_log(NULL, AV_LOG_ERROR,\n\n                           \"Parse error, at least 3 arguments were expected, \"\n\n                           \"only %d given in string '%s'\\n\", n, buf);\n\n                }\n\n            }\n\n#endif\n\n            if (key == 'd' || key == 'D'){\n\n                int debug=0;\n\n                if(key == 'D') {\n\n                    debug = input_streams[0].st->codec->debug<<1;\n\n                    if(!debug) debug = 1;\n\n                    while(debug & (FF_DEBUG_DCT_COEFF|FF_DEBUG_VIS_QP|FF_DEBUG_VIS_MB_TYPE)) //unsupported, would just crash\n\n                        debug += debug;\n\n                }else\n\n                    if(scanf(\"%d\", &debug)!=1)\n\n                        fprintf(stderr,\"error parsing debug value\\n\");\n\n                for(i=0;i<nb_input_streams;i++) {\n\n                    input_streams[i].st->codec->debug = debug;\n\n                }\n\n                for(i=0;i<nb_output_streams;i++) {\n\n                    ost = &output_streams[i];\n\n                    ost->st->codec->debug = debug;\n\n                }\n\n                if(debug) av_log_set_level(AV_LOG_DEBUG);\n\n                fprintf(stderr,\"debug=%d\\n\", debug);\n\n            }\n\n            if (key == '?'){\n\n                fprintf(stderr, \"key    function\\n\"\n\n                                \"?      show this help\\n\"\n\n                                \"+      increase verbosity\\n\"\n\n                                \"-      decrease verbosity\\n\"\n\n                                \"c      Send command to filtergraph\\n\"\n\n                                \"D      cycle through available debug modes\\n\"\n\n                                \"h      dump packets/hex press to cycle through the 3 states\\n\"\n\n                                \"q      quit\\n\"\n\n                                \"s      Show QP histogram\\n\"\n\n                );\n\n            }\n\n        }\n\n\n\n        /* select the stream that we must read now by looking at the\n\n           smallest output pts */\n\n        file_index = -1;\n\n        for (i = 0; i < nb_output_streams; i++) {\n\n            OutputFile *of;\n\n            int64_t ipts;\n\n            double  opts;\n\n            ost = &output_streams[i];\n\n            of = &output_files[ost->file_index];\n\n            os = output_files[ost->file_index].ctx;\n\n            ist = &input_streams[ost->source_index];\n\n            if (ost->is_past_recording_time || no_packet[ist->file_index] ||\n\n                (os->pb && avio_tell(os->pb) >= of->limit_filesize))\n\n                continue;\n\n            opts = ost->st->pts.val * av_q2d(ost->st->time_base);\n\n            ipts = ist->pts;\n\n            if (!input_files[ist->file_index].eof_reached) {\n\n                if (ipts < ipts_min) {\n\n                    ipts_min = ipts;\n\n                    if (input_sync)\n\n                        file_index = ist->file_index;\n\n                }\n\n                if (opts < opts_min) {\n\n                    opts_min = opts;\n\n                    if (!input_sync) file_index = ist->file_index;\n\n                }\n\n            }\n\n            if (ost->frame_number >= ost->max_frames) {\n\n                int j;\n\n                for (j = 0; j < of->ctx->nb_streams; j++)\n\n                    output_streams[of->ost_index + j].is_past_recording_time = 1;\n\n                continue;\n\n            }\n\n        }\n\n        /* if none, if is finished */\n\n        if (file_index < 0) {\n\n            if (no_packet_count) {\n\n                no_packet_count = 0;\n\n                memset(no_packet, 0, nb_input_files);\n\n                usleep(10000);\n\n                continue;\n\n            }\n\n            break;\n\n        }\n\n\n\n        /* read a frame from it and output it in the fifo */\n\n        is  = input_files[file_index].ctx;\n\n        ret = av_read_frame(is, &pkt);\n\n        if (ret == AVERROR(EAGAIN)) {\n\n            no_packet[file_index] = 1;\n\n            no_packet_count++;\n\n            continue;\n\n        }\n\n        if (ret < 0) {\n\n            input_files[file_index].eof_reached = 1;\n\n            if (opt_shortest)\n\n                break;\n\n            else\n\n                continue;\n\n        }\n\n\n\n        no_packet_count = 0;\n\n        memset(no_packet, 0, nb_input_files);\n\n\n\n        if (do_pkt_dump) {\n\n            av_pkt_dump_log2(NULL, AV_LOG_DEBUG, &pkt, do_hex_dump,\n\n                             is->streams[pkt.stream_index]);\n\n        }\n\n        /* the following test is needed in case new streams appear\n\n           dynamically in stream : we ignore them */\n\n        if (pkt.stream_index >= input_files[file_index].nb_streams)\n\n            goto discard_packet;\n\n        ist_index = input_files[file_index].ist_index + pkt.stream_index;\n\n        ist = &input_streams[ist_index];\n\n        if (ist->discard)\n\n            goto discard_packet;\n\n\n\n        if (pkt.dts != AV_NOPTS_VALUE)\n\n            pkt.dts += av_rescale_q(input_files[ist->file_index].ts_offset, AV_TIME_BASE_Q, ist->st->time_base);\n\n        if (pkt.pts != AV_NOPTS_VALUE)\n\n            pkt.pts += av_rescale_q(input_files[ist->file_index].ts_offset, AV_TIME_BASE_Q, ist->st->time_base);\n\n\n\n        if (pkt.pts != AV_NOPTS_VALUE)\n\n            pkt.pts *= ist->ts_scale;\n\n        if (pkt.dts != AV_NOPTS_VALUE)\n\n            pkt.dts *= ist->ts_scale;\n\n\n\n        //fprintf(stderr, \"next:%\"PRId64\" dts:%\"PRId64\"/%\"PRId64\" off:%\"PRId64\" %d\\n\",\n\n        //        ist->next_dts,\n\n        //        ist->dts, av_rescale_q(pkt.dts, ist->st->time_base, AV_TIME_BASE_Q), input_files[ist->file_index].ts_offset,\n\n        //        ist->st->codec->codec_type);\n\n        if (pkt.dts != AV_NOPTS_VALUE && ist->next_dts != AV_NOPTS_VALUE\n\n            && (is->iformat->flags & AVFMT_TS_DISCONT)) {\n\n            int64_t pkt_dts = av_rescale_q(pkt.dts, ist->st->time_base, AV_TIME_BASE_Q);\n\n            int64_t delta   = pkt_dts - ist->next_dts;\n\n            if((delta < -1LL*dts_delta_threshold*AV_TIME_BASE ||\n\n                (delta > 1LL*dts_delta_threshold*AV_TIME_BASE &&\n\n                 ist->st->codec->codec_type != AVMEDIA_TYPE_SUBTITLE) ||\n\n                pkt_dts+1<ist->pts)&& !copy_ts){\n\n                input_files[ist->file_index].ts_offset -= delta;\n\n                av_log(NULL, AV_LOG_DEBUG,\n\n                       \"timestamp discontinuity %\"PRId64\", new offset= %\"PRId64\"\\n\",\n\n                       delta, input_files[ist->file_index].ts_offset);\n\n                pkt.dts-= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);\n\n                if (pkt.pts != AV_NOPTS_VALUE)\n\n                    pkt.pts-= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);\n\n            }\n\n        }\n\n\n\n        // fprintf(stderr,\"read #%d.%d size=%d\\n\", ist->file_index, ist->st->index, pkt.size);\n\n        if (output_packet(ist, output_streams, nb_output_streams, &pkt) < 0) {\n\n\n\n            av_log(NULL, AV_LOG_ERROR, \"Error while decoding stream #%d:%d\\n\",\n\n                   ist->file_index, ist->st->index);\n\n            if (exit_on_error)\n\n                exit_program(1);\n\n            av_free_packet(&pkt);\n\n            continue;\n\n        }\n\n\n\n    discard_packet:\n\n        av_free_packet(&pkt);\n\n\n\n        /* dump report by using the output first video and audio streams */\n\n        print_report(output_files, output_streams, nb_output_streams, 0, timer_start, cur_time);\n\n    }\n\n\n\n    /* at the end of stream, we must flush the decoder buffers */\n\n    for (i = 0; i < nb_input_streams; i++) {\n\n        ist = &input_streams[i];\n\n        if (ist->decoding_needed) {\n\n            output_packet(ist, output_streams, nb_output_streams, NULL);\n\n        }\n\n    }\n\n    flush_encoders(output_streams, nb_output_streams);\n\n\n\n    term_exit();\n\n\n\n    /* write the trailer if needed and close file */\n\n    for (i = 0; i < nb_output_files; i++) {\n\n        os = output_files[i].ctx;\n\n        av_write_trailer(os);\n\n    }\n\n\n\n    /* dump report by using the first video and audio streams */\n\n    print_report(output_files, output_streams, nb_output_streams, 1, timer_start, av_gettime());\n\n\n\n    /* close each encoder */\n\n    for (i = 0; i < nb_output_streams; i++) {\n\n        ost = &output_streams[i];\n\n        if (ost->encoding_needed) {\n\n            av_freep(&ost->st->codec->stats_in);\n\n            avcodec_close(ost->st->codec);\n\n        }\n\n#if CONFIG_AVFILTER\n\n        avfilter_graph_free(&ost->graph);\n\n#endif\n\n    }\n\n\n\n    /* close each decoder */\n\n    for (i = 0; i < nb_input_streams; i++) {\n\n        ist = &input_streams[i];\n\n        if (ist->decoding_needed) {\n\n            avcodec_close(ist->st->codec);\n\n        }\n\n    }\n\n\n\n    /* finished ! */\n\n    ret = 0;\n\n\n\n fail:\n\n    av_freep(&no_packet);\n\n\n\n    if (output_streams) {\n\n        for (i = 0; i < nb_output_streams; i++) {\n\n            ost = &output_streams[i];\n\n            if (ost) {\n\n                if (ost->stream_copy)\n\n                    av_freep(&ost->st->codec->extradata);\n\n                if (ost->logfile) {\n\n                    fclose(ost->logfile);\n\n                    ost->logfile = NULL;\n\n                }\n\n                av_fifo_free(ost->fifo); /* works even if fifo is not\n\n                                             initialized but set to zero */\n\n                av_freep(&ost->st->codec->subtitle_header);\n\n                av_free(ost->resample_frame.data[0]);\n\n                av_free(ost->forced_kf_pts);\n\n                if (ost->video_resample)\n\n                    sws_freeContext(ost->img_resample_ctx);\n\n                swr_free(&ost->swr);\n\n                av_dict_free(&ost->opts);\n\n            }\n\n        }\n\n    }\n\n    return ret;\n\n}\n", "idx": 27065}
{"project": "FFmpeg", "commit_id": "fc11927890f38445a950b453d24928525da0e61a", "target": 0, "func": "void *av_realloc(void *ptr, size_t size)\n\n{\n\n#if CONFIG_MEMALIGN_HACK\n\n    int diff;\n\n#endif\n\n\n\n    /* let's disallow possible ambiguous cases */\n\n    if (size > (MAX_MALLOC_SIZE-16))\n\n        return NULL;\n\n\n\n#if CONFIG_MEMALIGN_HACK\n\n    //FIXME this isn't aligned correctly, though it probably isn't needed\n\n    if(!ptr) return av_malloc(size);\n\n    diff= ((char*)ptr)[-1];\n\n    return (char*)realloc((char*)ptr - diff, size + diff) + diff;\n\n#else\n\n    return realloc(ptr, size + !size);\n\n#endif\n\n}\n", "idx": 27066}
{"project": "FFmpeg", "commit_id": "229843aa359ae0c9519977d7fa952688db63f559", "target": 0, "func": "static void handle_char(CCaptionSubContext *ctx, char hi, char lo, int64_t pts)\n\n{\n\n    struct Screen *screen = get_writing_screen(ctx);\n\n    char *row = screen->characters[ctx->cursor_row];\n\n    int ret;\n\n\n\n    SET_FLAG(screen->row_used,ctx->cursor_row);\n\n\n\n    ret = write_char(ctx, row, ctx->cursor_column, hi);\n\n    if( ret == 0 )\n\n        ctx->cursor_column++;\n\n\n\n    if(lo) {\n\n        ret = write_char(ctx, row, ctx->cursor_column, lo);\n\n        if ( ret == 0 )\n\n            ctx->cursor_column++;\n\n    }\n\n    write_char(ctx, row, ctx->cursor_column, 0);\n\n\n\n    /* reset prev command since character can repeat */\n\n    ctx->prev_cmd[0] = 0;\n\n    ctx->prev_cmd[1] = 0;\n\n    if (lo)\n\n       av_dlog(ctx, \"(%c,%c)\\n\",hi,lo);\n\n    else\n\n       av_dlog(ctx, \"(%c)\\n\",hi);\n\n}\n", "idx": 27067}
{"project": "FFmpeg", "commit_id": "6184fa2067ccf88e68a7009442cf01440e59d99c", "target": 0, "func": "static av_cold int raw_close_decoder(AVCodecContext *avctx)\n\n{\n\n    RawVideoContext *context = avctx->priv_data;\n\n\n\n    av_freep(&context->buffer);\n\n    return 0;\n\n}\n", "idx": 27068}
{"project": "FFmpeg", "commit_id": "b8598f6ce61ccda3f2ff0c730b009fb650e42986", "target": 1, "func": "static int mc_subpel(DiracContext *s, DiracBlock *block, const uint8_t *src[5],\n\n                     int x, int y, int ref, int plane)\n\n{\n\n    Plane *p = &s->plane[plane];\n\n    uint8_t **ref_hpel = s->ref_pics[ref]->hpel[plane];\n\n    int motion_x = block->u.mv[ref][0];\n\n    int motion_y = block->u.mv[ref][1];\n\n    int mx, my, i, epel, nplanes = 0;\n\n\n\n    if (plane) {\n\n        motion_x >>= s->chroma_x_shift;\n\n        motion_y >>= s->chroma_y_shift;\n\n    }\n\n\n\n    mx         = motion_x & ~(-1 << s->mv_precision);\n\n    my         = motion_y & ~(-1 << s->mv_precision);\n\n    motion_x >>= s->mv_precision;\n\n    motion_y >>= s->mv_precision;\n\n    /* normalize subpel coordinates to epel */\n\n    /* TODO: template this function? */\n\n    mx      <<= 3 - s->mv_precision;\n\n    my      <<= 3 - s->mv_precision;\n\n\n\n    x += motion_x;\n\n    y += motion_y;\n\n    epel = (mx|my)&1;\n\n\n\n    /* hpel position */\n\n    if (!((mx|my)&3)) {\n\n        nplanes = 1;\n\n        src[0] = ref_hpel[(my>>1)+(mx>>2)] + y*p->stride + x;\n\n    } else {\n\n        /* qpel or epel */\n\n        nplanes = 4;\n\n        for (i = 0; i < 4; i++)\n\n            src[i] = ref_hpel[i] + y*p->stride + x;\n\n\n\n        /* if we're interpolating in the right/bottom halves, adjust the planes as needed\n\n           we increment x/y because the edge changes for half of the pixels */\n\n        if (mx > 4) {\n\n            src[0] += 1;\n\n            src[2] += 1;\n\n            x++;\n\n        }\n\n        if (my > 4) {\n\n            src[0] += p->stride;\n\n            src[1] += p->stride;\n\n            y++;\n\n        }\n\n\n\n        /* hpel planes are:\n\n           [0]: F  [1]: H\n\n           [2]: V  [3]: C */\n\n        if (!epel) {\n\n            /* check if we really only need 2 planes since either mx or my is\n\n               a hpel position. (epel weights of 0 handle this there) */\n\n            if (!(mx&3)) {\n\n                /* mx == 0: average [0] and [2]\n\n                   mx == 4: average [1] and [3] */\n\n                src[!mx] = src[2 + !!mx];\n\n                nplanes = 2;\n\n            } else if (!(my&3)) {\n\n                src[0] = src[(my>>1)  ];\n\n                src[1] = src[(my>>1)+1];\n\n                nplanes = 2;\n\n            }\n\n        } else {\n\n            /* adjust the ordering if needed so the weights work */\n\n            if (mx > 4) {\n\n                FFSWAP(const uint8_t *, src[0], src[1]);\n\n                FFSWAP(const uint8_t *, src[2], src[3]);\n\n            }\n\n            if (my > 4) {\n\n                FFSWAP(const uint8_t *, src[0], src[2]);\n\n                FFSWAP(const uint8_t *, src[1], src[3]);\n\n            }\n\n            src[4] = epel_weights[my&3][mx&3];\n\n        }\n\n    }\n\n\n\n    /* fixme: v/h _edge_pos */\n\n    if (x + p->xblen > p->width +EDGE_WIDTH/2 ||\n\n        y + p->yblen > p->height+EDGE_WIDTH/2 ||\n\n        x < 0 || y < 0) {\n\n        for (i = 0; i < nplanes; i++) {\n\n            ff_emulated_edge_mc(s->edge_emu_buffer[i], src[i],\n\n                                p->stride, p->stride,\n\n                                p->xblen, p->yblen, x, y,\n\n                                p->width+EDGE_WIDTH/2, p->height+EDGE_WIDTH/2);\n\n            src[i] = s->edge_emu_buffer[i];\n\n        }\n\n    }\n\n    return (nplanes>>1) + epel;\n\n}\n", "idx": 27070}
{"project": "FFmpeg", "commit_id": "c9220d5b06536ac359166214b4131a1f15244617", "target": 1, "func": "static int decode_block_progressive(MJpegDecodeContext *s, int16_t *block,\n\n                                    uint8_t *last_nnz, int ac_index,\n\n                                    int16_t *quant_matrix,\n\n                                    int ss, int se, int Al, int *EOBRUN)\n\n{\n\n    int code, i, j, level, val, run;\n\n\n\n    if (*EOBRUN) {\n\n        (*EOBRUN)--;\n\n        return 0;\n\n    }\n\n\n\n    {\n\n        OPEN_READER(re, &s->gb);\n\n        for (i = ss; ; i++) {\n\n            UPDATE_CACHE(re, &s->gb);\n\n            GET_VLC(code, re, &s->gb, s->vlcs[2][ac_index].table, 9, 2);\n\n\n\n            run = ((unsigned) code) >> 4;\n\n            code &= 0xF;\n\n            if (code) {\n\n                i += run;\n\n                if (code > MIN_CACHE_BITS - 16)\n\n                    UPDATE_CACHE(re, &s->gb);\n\n\n\n                {\n\n                    int cache = GET_CACHE(re, &s->gb);\n\n                    int sign  = (~cache) >> 31;\n\n                    level     = (NEG_USR32(sign ^ cache,code) ^ sign) - sign;\n\n                }\n\n\n\n                LAST_SKIP_BITS(re, &s->gb, code);\n\n\n\n                if (i >= se) {\n\n                    if (i == se) {\n\n                        j = s->scantable.permutated[se];\n\n                        block[j] = level * quant_matrix[j] << Al;\n\n                        break;\n\n                    }\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"error count: %d\\n\", i);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                j = s->scantable.permutated[i];\n\n                block[j] = level * quant_matrix[j] << Al;\n\n            } else {\n\n                if (run == 0xF) {// ZRL - skip 15 coefficients\n\n                    i += 15;\n\n                    if (i >= se) {\n\n                        av_log(s->avctx, AV_LOG_ERROR, \"ZRL overflow: %d\\n\", i);\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                } else {\n\n                    val = (1 << run);\n\n                    if (run) {\n\n                        UPDATE_CACHE(re, &s->gb);\n\n                        val += NEG_USR32(GET_CACHE(re, &s->gb), run);\n\n                        LAST_SKIP_BITS(re, &s->gb, run);\n\n                    }\n\n                    *EOBRUN = val - 1;\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n        CLOSE_READER(re, &s->gb);\n\n    }\n\n\n\n    if (i > *last_nnz)\n\n        *last_nnz = i;\n\n\n\n    return 0;\n\n}\n", "idx": 27074}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "void rgb32tobgr24(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n\tlong i;\n\n\tlong num_pixels = src_size >> 2;\n\n\tfor(i=0; i<num_pixels; i++)\n\n\t{\n\n\t\t#ifdef WORDS_BIGENDIAN\n\n\t\t\t/* RGB32 (= A,B,G,R) -> BGR24 (= B,G,R) */\n\n\t\t\tdst[3*i + 0] = src[4*i + 1];\n\n\t\t\tdst[3*i + 1] = src[4*i + 2];\n\n\t\t\tdst[3*i + 2] = src[4*i + 3];\n\n\t\t#else\n\n\t\t\tdst[3*i + 0] = src[4*i + 2];\n\n\t\t\tdst[3*i + 1] = src[4*i + 1];\n\n\t\t\tdst[3*i + 2] = src[4*i + 0];\n\n\t\t#endif\n\n\t}\n\n}\n", "idx": 27076}
{"project": "FFmpeg", "commit_id": "dae2ce361a2b5fd9be1d43e5e8c00bdbc5f03e3d", "target": 1, "func": "static int initFilter(int16_t **outFilter, int16_t **filterPos, int *outFilterSize, int xInc,\n\n                      int srcW, int dstW, int filterAlign, int one, int flags, int cpu_flags,\n\n                      SwsVector *srcFilter, SwsVector *dstFilter, double param[2], int is_horizontal)\n\n{\n\n    int i;\n\n    int filterSize;\n\n    int filter2Size;\n\n    int minFilterSize;\n\n    int64_t *filter=NULL;\n\n    int64_t *filter2=NULL;\n\n    const int64_t fone= 1LL<<54;\n\n    int ret= -1;\n\n\n\n    emms_c(); //FIXME this should not be required but it IS (even for non-MMX versions)\n\n\n\n    // NOTE: the +3 is for the MMX(+1)/SSE(+3) scaler which reads over the end\n\n    FF_ALLOC_OR_GOTO(NULL, *filterPos, (dstW+3)*sizeof(int16_t), fail);\n\n\n\n    if (FFABS(xInc - 0x10000) <10) { // unscaled\n\n        int i;\n\n        filterSize= 1;\n\n        FF_ALLOCZ_OR_GOTO(NULL, filter, dstW*sizeof(*filter)*filterSize, fail);\n\n\n\n        for (i=0; i<dstW; i++) {\n\n            filter[i*filterSize]= fone;\n\n            (*filterPos)[i]=i;\n\n        }\n\n\n\n    } else if (flags&SWS_POINT) { // lame looking point sampling mode\n\n        int i;\n\n        int xDstInSrc;\n\n        filterSize= 1;\n\n        FF_ALLOC_OR_GOTO(NULL, filter, dstW*sizeof(*filter)*filterSize, fail);\n\n\n\n        xDstInSrc= xInc/2 - 0x8000;\n\n        for (i=0; i<dstW; i++) {\n\n            int xx= (xDstInSrc - ((filterSize-1)<<15) + (1<<15))>>16;\n\n\n\n            (*filterPos)[i]= xx;\n\n            filter[i]= fone;\n\n            xDstInSrc+= xInc;\n\n        }\n\n    } else if ((xInc <= (1<<16) && (flags&SWS_AREA)) || (flags&SWS_FAST_BILINEAR)) { // bilinear upscale\n\n        int i;\n\n        int xDstInSrc;\n\n        filterSize= 2;\n\n        FF_ALLOC_OR_GOTO(NULL, filter, dstW*sizeof(*filter)*filterSize, fail);\n\n\n\n        xDstInSrc= xInc/2 - 0x8000;\n\n        for (i=0; i<dstW; i++) {\n\n            int xx= (xDstInSrc - ((filterSize-1)<<15) + (1<<15))>>16;\n\n            int j;\n\n\n\n            (*filterPos)[i]= xx;\n\n            //bilinear upscale / linear interpolate / area averaging\n\n            for (j=0; j<filterSize; j++) {\n\n                int64_t coeff= fone - FFABS((xx<<16) - xDstInSrc)*(fone>>16);\n\n                if (coeff<0) coeff=0;\n\n                filter[i*filterSize + j]= coeff;\n\n                xx++;\n\n            }\n\n            xDstInSrc+= xInc;\n\n        }\n\n    } else {\n\n        int xDstInSrc;\n\n        int sizeFactor;\n\n\n\n        if      (flags&SWS_BICUBIC)      sizeFactor=  4;\n\n        else if (flags&SWS_X)            sizeFactor=  8;\n\n        else if (flags&SWS_AREA)         sizeFactor=  1; //downscale only, for upscale it is bilinear\n\n        else if (flags&SWS_GAUSS)        sizeFactor=  8;   // infinite ;)\n\n        else if (flags&SWS_LANCZOS)      sizeFactor= param[0] != SWS_PARAM_DEFAULT ? ceil(2*param[0]) : 6;\n\n        else if (flags&SWS_SINC)         sizeFactor= 20; // infinite ;)\n\n        else if (flags&SWS_SPLINE)       sizeFactor= 20;  // infinite ;)\n\n        else if (flags&SWS_BILINEAR)     sizeFactor=  2;\n\n        else {\n\n            sizeFactor= 0; //GCC warning killer\n\n            assert(0);\n\n        }\n\n\n\n        if (xInc <= 1<<16)      filterSize= 1 + sizeFactor; // upscale\n\n        else                    filterSize= 1 + (sizeFactor*srcW + dstW - 1)/ dstW;\n\n\n\n        if (filterSize > srcW-2) filterSize=srcW-2;\n\n\n\n        FF_ALLOC_OR_GOTO(NULL, filter, dstW*sizeof(*filter)*filterSize, fail);\n\n\n\n        xDstInSrc= xInc - 0x10000;\n\n        for (i=0; i<dstW; i++) {\n\n            int xx= (xDstInSrc - ((filterSize-2)<<16)) / (1<<17);\n\n            int j;\n\n            (*filterPos)[i]= xx;\n\n            for (j=0; j<filterSize; j++) {\n\n                int64_t d= ((int64_t)FFABS((xx<<17) - xDstInSrc))<<13;\n\n                double floatd;\n\n                int64_t coeff;\n\n\n\n                if (xInc > 1<<16)\n\n                    d= d*dstW/srcW;\n\n                floatd= d * (1.0/(1<<30));\n\n\n\n                if (flags & SWS_BICUBIC) {\n\n                    int64_t B= (param[0] != SWS_PARAM_DEFAULT ? param[0] :   0) * (1<<24);\n\n                    int64_t C= (param[1] != SWS_PARAM_DEFAULT ? param[1] : 0.6) * (1<<24);\n\n\n\n                    if (d >= 1LL<<31) {\n\n                        coeff = 0.0;\n\n                    } else {\n\n                        int64_t dd  = (d  * d) >> 30;\n\n                        int64_t ddd = (dd * d) >> 30;\n\n\n\n                        if (d < 1LL<<30)\n\n                            coeff = (12*(1<<24)-9*B-6*C)*ddd + (-18*(1<<24)+12*B+6*C)*dd + (6*(1<<24)-2*B)*(1<<30);\n\n                        else\n\n                            coeff = (-B-6*C)*ddd + (6*B+30*C)*dd + (-12*B-48*C)*d + (8*B+24*C)*(1<<30);\n\n                    }\n\n                    coeff *= fone>>(30+24);\n\n                }\n\n/*                else if (flags & SWS_X) {\n\n                    double p= param ? param*0.01 : 0.3;\n\n                    coeff = d ? sin(d*M_PI)/(d*M_PI) : 1.0;\n\n                    coeff*= pow(2.0, - p*d*d);\n\n                }*/\n\n                else if (flags & SWS_X) {\n\n                    double A= param[0] != SWS_PARAM_DEFAULT ? param[0] : 1.0;\n\n                    double c;\n\n\n\n                    if (floatd<1.0)\n\n                        c = cos(floatd*M_PI);\n\n                    else\n\n                        c=-1.0;\n\n                    if (c<0.0)      c= -pow(-c, A);\n\n                    else            c=  pow( c, A);\n\n                    coeff= (c*0.5 + 0.5)*fone;\n\n                } else if (flags & SWS_AREA) {\n\n                    int64_t d2= d - (1<<29);\n\n                    if      (d2*xInc < -(1LL<<(29+16))) coeff= 1.0 * (1LL<<(30+16));\n\n                    else if (d2*xInc <  (1LL<<(29+16))) coeff= -d2*xInc + (1LL<<(29+16));\n\n                    else coeff=0.0;\n\n                    coeff *= fone>>(30+16);\n\n                } else if (flags & SWS_GAUSS) {\n\n                    double p= param[0] != SWS_PARAM_DEFAULT ? param[0] : 3.0;\n\n                    coeff = (pow(2.0, - p*floatd*floatd))*fone;\n\n                } else if (flags & SWS_SINC) {\n\n                    coeff = (d ? sin(floatd*M_PI)/(floatd*M_PI) : 1.0)*fone;\n\n                } else if (flags & SWS_LANCZOS) {\n\n                    double p= param[0] != SWS_PARAM_DEFAULT ? param[0] : 3.0;\n\n                    coeff = (d ? sin(floatd*M_PI)*sin(floatd*M_PI/p)/(floatd*floatd*M_PI*M_PI/p) : 1.0)*fone;\n\n                    if (floatd>p) coeff=0;\n\n                } else if (flags & SWS_BILINEAR) {\n\n                    coeff= (1<<30) - d;\n\n                    if (coeff<0) coeff=0;\n\n                    coeff *= fone >> 30;\n\n                } else if (flags & SWS_SPLINE) {\n\n                    double p=-2.196152422706632;\n\n                    coeff = getSplineCoeff(1.0, 0.0, p, -p-1.0, floatd) * fone;\n\n                } else {\n\n                    coeff= 0.0; //GCC warning killer\n\n                    assert(0);\n\n                }\n\n\n\n                filter[i*filterSize + j]= coeff;\n\n                xx++;\n\n            }\n\n            xDstInSrc+= 2*xInc;\n\n        }\n\n    }\n\n\n\n    /* apply src & dst Filter to filter -> filter2\n\n       av_free(filter);\n\n    */\n\n    assert(filterSize>0);\n\n    filter2Size= filterSize;\n\n    if (srcFilter) filter2Size+= srcFilter->length - 1;\n\n    if (dstFilter) filter2Size+= dstFilter->length - 1;\n\n    assert(filter2Size>0);\n\n    FF_ALLOCZ_OR_GOTO(NULL, filter2, filter2Size*dstW*sizeof(*filter2), fail);\n\n\n\n    for (i=0; i<dstW; i++) {\n\n        int j, k;\n\n\n\n        if(srcFilter) {\n\n            for (k=0; k<srcFilter->length; k++) {\n\n                for (j=0; j<filterSize; j++)\n\n                    filter2[i*filter2Size + k + j] += srcFilter->coeff[k]*filter[i*filterSize + j];\n\n            }\n\n        } else {\n\n            for (j=0; j<filterSize; j++)\n\n                filter2[i*filter2Size + j]= filter[i*filterSize + j];\n\n        }\n\n        //FIXME dstFilter\n\n\n\n        (*filterPos)[i]+= (filterSize-1)/2 - (filter2Size-1)/2;\n\n    }\n\n    av_freep(&filter);\n\n\n\n    /* try to reduce the filter-size (step1 find size and shift left) */\n\n    // Assume it is near normalized (*0.5 or *2.0 is OK but * 0.001 is not).\n\n    minFilterSize= 0;\n\n    for (i=dstW-1; i>=0; i--) {\n\n        int min= filter2Size;\n\n        int j;\n\n        int64_t cutOff=0.0;\n\n\n\n        /* get rid of near zero elements on the left by shifting left */\n\n        for (j=0; j<filter2Size; j++) {\n\n            int k;\n\n            cutOff += FFABS(filter2[i*filter2Size]);\n\n\n\n            if (cutOff > SWS_MAX_REDUCE_CUTOFF*fone) break;\n\n\n\n            /* preserve monotonicity because the core can't handle the filter otherwise */\n\n            if (i<dstW-1 && (*filterPos)[i] >= (*filterPos)[i+1]) break;\n\n\n\n            // move filter coefficients left\n\n            for (k=1; k<filter2Size; k++)\n\n                filter2[i*filter2Size + k - 1]= filter2[i*filter2Size + k];\n\n            filter2[i*filter2Size + k - 1]= 0;\n\n            (*filterPos)[i]++;\n\n        }\n\n\n\n        cutOff=0;\n\n        /* count near zeros on the right */\n\n        for (j=filter2Size-1; j>0; j--) {\n\n            cutOff += FFABS(filter2[i*filter2Size + j]);\n\n\n\n            if (cutOff > SWS_MAX_REDUCE_CUTOFF*fone) break;\n\n            min--;\n\n        }\n\n\n\n        if (min>minFilterSize) minFilterSize= min;\n\n    }\n\n\n\n    if (HAVE_ALTIVEC && cpu_flags & AV_CPU_FLAG_ALTIVEC) {\n\n        // we can handle the special case 4,\n\n        // so we don't want to go to the full 8\n\n        if (minFilterSize < 5)\n\n            filterAlign = 4;\n\n\n\n        // We really don't want to waste our time\n\n        // doing useless computation, so fall back on\n\n        // the scalar C code for very small filters.\n\n        // Vectorizing is worth it only if you have a\n\n        // decent-sized vector.\n\n        if (minFilterSize < 3)\n\n            filterAlign = 1;\n\n    }\n\n\n\n    if (HAVE_MMX && cpu_flags & AV_CPU_FLAG_MMX) {\n\n        // special case for unscaled vertical filtering\n\n        if (minFilterSize == 1 && filterAlign == 2)\n\n            filterAlign= 1;\n\n    }\n\n\n\n    assert(minFilterSize > 0);\n\n    filterSize= (minFilterSize +(filterAlign-1)) & (~(filterAlign-1));\n\n    assert(filterSize > 0);\n\n    filter= av_malloc(filterSize*dstW*sizeof(*filter));\n\n    if (filterSize >= MAX_FILTER_SIZE*16/((flags&SWS_ACCURATE_RND) ? APCK_SIZE : 16) || !filter)\n\n        goto fail;\n\n    *outFilterSize= filterSize;\n\n\n\n    if (flags&SWS_PRINT_INFO)\n\n        av_log(NULL, AV_LOG_VERBOSE, \"SwScaler: reducing / aligning filtersize %d -> %d\\n\", filter2Size, filterSize);\n\n    /* try to reduce the filter-size (step2 reduce it) */\n\n    for (i=0; i<dstW; i++) {\n\n        int j;\n\n\n\n        for (j=0; j<filterSize; j++) {\n\n            if (j>=filter2Size) filter[i*filterSize + j]= 0;\n\n            else               filter[i*filterSize + j]= filter2[i*filter2Size + j];\n\n            if((flags & SWS_BITEXACT) && j>=minFilterSize)\n\n                filter[i*filterSize + j]= 0;\n\n        }\n\n    }\n\n\n\n    //FIXME try to align filterPos if possible\n\n\n\n    //fix borders\n\n    if (is_horizontal) {\n\n        for (i = 0; i < dstW; i++) {\n\n            int j;\n\n            if ((*filterPos)[i] < 0) {\n\n                // move filter coefficients left to compensate for filterPos\n\n                for (j = 1; j < filterSize; j++) {\n\n                    int left = FFMAX(j + (*filterPos)[i], 0);\n\n                    filter[i * filterSize + left] += filter[i * filterSize + j];\n\n                    filter[i * filterSize + j   ]  = 0;\n\n                }\n\n                (*filterPos)[i] = 0;\n\n            }\n\n\n\n            if ((*filterPos)[i] + filterSize > srcW) {\n\n                int shift = (*filterPos)[i] + filterSize - srcW;\n\n                // move filter coefficients right to compensate for filterPos\n\n                for (j = filterSize - 2; j >= 0; j--) {\n\n                    int right = FFMIN(j + shift, filterSize - 1);\n\n                    filter[i * filterSize + right] += filter[i * filterSize + j];\n\n                    filter[i * filterSize + j    ]  = 0;\n\n                }\n\n                (*filterPos)[i] = srcW - filterSize;\n\n            }\n\n        }\n\n    }\n\n\n\n    // Note the +1 is for the MMX scaler which reads over the end\n\n    /* align at 16 for AltiVec (needed by hScale_altivec_real) */\n\n    FF_ALLOCZ_OR_GOTO(NULL, *outFilter, *outFilterSize*(dstW+3)*sizeof(int16_t), fail);\n\n\n\n    /* normalize & store in outFilter */\n\n    for (i=0; i<dstW; i++) {\n\n        int j;\n\n        int64_t error=0;\n\n        int64_t sum=0;\n\n\n\n        for (j=0; j<filterSize; j++) {\n\n            sum+= filter[i*filterSize + j];\n\n        }\n\n        sum= (sum + one/2)/ one;\n\n        for (j=0; j<*outFilterSize; j++) {\n\n            int64_t v= filter[i*filterSize + j] + error;\n\n            int intV= ROUNDED_DIV(v, sum);\n\n            (*outFilter)[i*(*outFilterSize) + j]= intV;\n\n            error= v - intV*sum;\n\n        }\n\n    }\n\n\n\n    (*filterPos)[dstW+0] =\n\n    (*filterPos)[dstW+1] =\n\n    (*filterPos)[dstW+2] = (*filterPos)[dstW-1]; // the MMX/SSE scaler will read over the end\n\n    for (i=0; i<*outFilterSize; i++) {\n\n        int k= (dstW - 1) * (*outFilterSize) + i;\n\n        (*outFilter)[k + 1 * (*outFilterSize)] =\n\n        (*outFilter)[k + 2 * (*outFilterSize)] =\n\n        (*outFilter)[k + 3 * (*outFilterSize)] = (*outFilter)[k];\n\n    }\n\n\n\n    ret=0;\n\nfail:\n\n    av_free(filter);\n\n    av_free(filter2);\n\n    return ret;\n\n}\n", "idx": 27077}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "void FUNCC(ff_h264_idct_add)(uint8_t *_dst, DCTELEM *_block, int stride)\n\n{\n\n    int i;\n\n    INIT_CLIP\n\n    pixel *dst = (pixel*)_dst;\n\n    dctcoef *block = (dctcoef*)_block;\n\n    stride /= sizeof(pixel);\n\n\n\n    block[0] += 1 << 5;\n\n\n\n    for(i=0; i<4; i++){\n\n        const int z0=  block[i + 4*0]     +  block[i + 4*2];\n\n        const int z1=  block[i + 4*0]     -  block[i + 4*2];\n\n        const int z2= (block[i + 4*1]>>1) -  block[i + 4*3];\n\n        const int z3=  block[i + 4*1]     + (block[i + 4*3]>>1);\n\n\n\n        block[i + 4*0]= z0 + z3;\n\n        block[i + 4*1]= z1 + z2;\n\n        block[i + 4*2]= z1 - z2;\n\n        block[i + 4*3]= z0 - z3;\n\n    }\n\n\n\n    for(i=0; i<4; i++){\n\n        const int z0=  block[0 + 4*i]     +  block[2 + 4*i];\n\n        const int z1=  block[0 + 4*i]     -  block[2 + 4*i];\n\n        const int z2= (block[1 + 4*i]>>1) -  block[3 + 4*i];\n\n        const int z3=  block[1 + 4*i]     + (block[3 + 4*i]>>1);\n\n\n\n        dst[i + 0*stride]= CLIP(dst[i + 0*stride] + ((z0 + z3) >> 6));\n\n        dst[i + 1*stride]= CLIP(dst[i + 1*stride] + ((z1 + z2) >> 6));\n\n        dst[i + 2*stride]= CLIP(dst[i + 2*stride] + ((z1 - z2) >> 6));\n\n        dst[i + 3*stride]= CLIP(dst[i + 3*stride] + ((z0 - z3) >> 6));\n\n    }\n\n}\n", "idx": 27081}
{"project": "FFmpeg", "commit_id": "0e6c8532215790bbe560a9eea4f3cc82bb55cf92", "target": 0, "func": "static int select_input_picture(MpegEncContext *s)\n\n{\n\n    int i, ret;\n\n\n\n    for (i = 1; i < MAX_PICTURE_COUNT; i++)\n\n        s->reordered_input_picture[i - 1] = s->reordered_input_picture[i];\n\n    s->reordered_input_picture[MAX_PICTURE_COUNT - 1] = NULL;\n\n\n\n    /* set next picture type & ordering */\n\n    if (!s->reordered_input_picture[0] && s->input_picture[0]) {\n\n        if (/*s->picture_in_gop_number >= s->gop_size ||*/\n\n            !s->next_picture_ptr || s->intra_only) {\n\n            s->reordered_input_picture[0] = s->input_picture[0];\n\n            s->reordered_input_picture[0]->f->pict_type = AV_PICTURE_TYPE_I;\n\n            s->reordered_input_picture[0]->f->coded_picture_number =\n\n                s->coded_picture_number++;\n\n        } else {\n\n            int b_frames;\n\n\n\n            if (s->avctx->frame_skip_threshold || s->avctx->frame_skip_factor) {\n\n                if (s->picture_in_gop_number < s->gop_size &&\n\n                    skip_check(s, s->input_picture[0], s->next_picture_ptr)) {\n\n                    // FIXME check that te gop check above is +-1 correct\n\n                    av_frame_unref(s->input_picture[0]->f);\n\n\n\n                    emms_c();\n\n                    ff_vbv_update(s, 0);\n\n\n\n                    goto no_output_pic;\n\n                }\n\n            }\n\n\n\n            if (s->avctx->flags & AV_CODEC_FLAG_PASS2) {\n\n                for (i = 0; i < s->max_b_frames + 1; i++) {\n\n                    int pict_num = s->input_picture[0]->f->display_picture_number + i;\n\n\n\n                    if (pict_num >= s->rc_context.num_entries)\n\n                        break;\n\n                    if (!s->input_picture[i]) {\n\n                        s->rc_context.entry[pict_num - 1].new_pict_type = AV_PICTURE_TYPE_P;\n\n                        break;\n\n                    }\n\n\n\n                    s->input_picture[i]->f->pict_type =\n\n                        s->rc_context.entry[pict_num].new_pict_type;\n\n                }\n\n            }\n\n\n\n            if (s->avctx->b_frame_strategy == 0) {\n\n                b_frames = s->max_b_frames;\n\n                while (b_frames && !s->input_picture[b_frames])\n\n                    b_frames--;\n\n            } else if (s->avctx->b_frame_strategy == 1) {\n\n                for (i = 1; i < s->max_b_frames + 1; i++) {\n\n                    if (s->input_picture[i] &&\n\n                        s->input_picture[i]->b_frame_score == 0) {\n\n                        s->input_picture[i]->b_frame_score =\n\n                            get_intra_count(s,\n\n                                            s->input_picture[i    ]->f->data[0],\n\n                                            s->input_picture[i - 1]->f->data[0],\n\n                                            s->linesize) + 1;\n\n                    }\n\n                }\n\n                for (i = 0; i < s->max_b_frames + 1; i++) {\n\n                    if (!s->input_picture[i] ||\n\n                        s->input_picture[i]->b_frame_score - 1 >\n\n                            s->mb_num / s->avctx->b_sensitivity)\n\n                        break;\n\n                }\n\n\n\n                b_frames = FFMAX(0, i - 1);\n\n\n\n                /* reset scores */\n\n                for (i = 0; i < b_frames + 1; i++) {\n\n                    s->input_picture[i]->b_frame_score = 0;\n\n                }\n\n            } else if (s->avctx->b_frame_strategy == 2) {\n\n                b_frames = estimate_best_b_count(s);\n\n            } else {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"illegal b frame strategy\\n\");\n\n                b_frames = 0;\n\n            }\n\n\n\n            emms_c();\n\n\n\n            for (i = b_frames - 1; i >= 0; i--) {\n\n                int type = s->input_picture[i]->f->pict_type;\n\n                if (type && type != AV_PICTURE_TYPE_B)\n\n                    b_frames = i;\n\n            }\n\n            if (s->input_picture[b_frames]->f->pict_type == AV_PICTURE_TYPE_B &&\n\n                b_frames == s->max_b_frames) {\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"warning, too many b frames in a row\\n\");\n\n            }\n\n\n\n            if (s->picture_in_gop_number + b_frames >= s->gop_size) {\n\n                if ((s->mpv_flags & FF_MPV_FLAG_STRICT_GOP) &&\n\n                    s->gop_size > s->picture_in_gop_number) {\n\n                    b_frames = s->gop_size - s->picture_in_gop_number - 1;\n\n                } else {\n\n                    if (s->avctx->flags & AV_CODEC_FLAG_CLOSED_GOP)\n\n                        b_frames = 0;\n\n                    s->input_picture[b_frames]->f->pict_type = AV_PICTURE_TYPE_I;\n\n                }\n\n            }\n\n\n\n            if ((s->avctx->flags & AV_CODEC_FLAG_CLOSED_GOP) && b_frames &&\n\n                s->input_picture[b_frames]->f->pict_type == AV_PICTURE_TYPE_I)\n\n                b_frames--;\n\n\n\n            s->reordered_input_picture[0] = s->input_picture[b_frames];\n\n            if (s->reordered_input_picture[0]->f->pict_type != AV_PICTURE_TYPE_I)\n\n                s->reordered_input_picture[0]->f->pict_type = AV_PICTURE_TYPE_P;\n\n            s->reordered_input_picture[0]->f->coded_picture_number =\n\n                s->coded_picture_number++;\n\n            for (i = 0; i < b_frames; i++) {\n\n                s->reordered_input_picture[i + 1] = s->input_picture[i];\n\n                s->reordered_input_picture[i + 1]->f->pict_type =\n\n                    AV_PICTURE_TYPE_B;\n\n                s->reordered_input_picture[i + 1]->f->coded_picture_number =\n\n                    s->coded_picture_number++;\n\n            }\n\n        }\n\n    }\n\nno_output_pic:\n\n    ff_mpeg_unref_picture(s->avctx, &s->new_picture);\n\n\n\n    if (s->reordered_input_picture[0]) {\n\n        s->reordered_input_picture[0]->reference =\n\n           s->reordered_input_picture[0]->f->pict_type !=\n\n               AV_PICTURE_TYPE_B ? 3 : 0;\n\n\n\n        if ((ret = ff_mpeg_ref_picture(s->avctx, &s->new_picture, s->reordered_input_picture[0])))\n\n            return ret;\n\n\n\n        if (s->reordered_input_picture[0]->shared || s->avctx->rc_buffer_size) {\n\n            // input is a shared pix, so we can't modifiy it -> alloc a new\n\n            // one & ensure that the shared one is reuseable\n\n\n\n            Picture *pic;\n\n            int i = ff_find_unused_picture(s->avctx, s->picture, 0);\n\n            if (i < 0)\n\n                return i;\n\n            pic = &s->picture[i];\n\n\n\n            pic->reference = s->reordered_input_picture[0]->reference;\n\n            if (alloc_picture(s, pic, 0) < 0) {\n\n                return -1;\n\n            }\n\n\n\n            ret = av_frame_copy_props(pic->f, s->reordered_input_picture[0]->f);\n\n            if (ret < 0)\n\n                return ret;\n\n\n\n            /* mark us unused / free shared pic */\n\n            av_frame_unref(s->reordered_input_picture[0]->f);\n\n            s->reordered_input_picture[0]->shared = 0;\n\n\n\n            s->current_picture_ptr = pic;\n\n        } else {\n\n            // input is not a shared pix -> reuse buffer for current_pix\n\n            s->current_picture_ptr = s->reordered_input_picture[0];\n\n            for (i = 0; i < 4; i++) {\n\n                s->new_picture.f->data[i] += INPLACE_OFFSET;\n\n            }\n\n        }\n\n        ff_mpeg_unref_picture(s->avctx, &s->current_picture);\n\n        if ((ret = ff_mpeg_ref_picture(s->avctx, &s->current_picture,\n\n                                       s->current_picture_ptr)) < 0)\n\n            return ret;\n\n\n\n        s->picture_number = s->new_picture.f->display_picture_number;\n\n    }\n\n    return 0;\n\n}\n", "idx": 27086}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "static int h264_slice_header_init(H264Context *h)\n\n{\n\n    int nb_slices = (HAVE_THREADS &&\n\n                     h->avctx->active_thread_type & FF_THREAD_SLICE) ?\n\n                    h->avctx->thread_count : 1;\n\n    int i, ret;\n\n\n\n    ff_set_sar(h->avctx, h->sps.sar);\n\n    av_pix_fmt_get_chroma_sub_sample(h->avctx->pix_fmt,\n\n                                     &h->chroma_x_shift, &h->chroma_y_shift);\n\n\n\n    if (h->sps.timing_info_present_flag) {\n\n        int64_t den = h->sps.time_scale;\n\n        if (h->x264_build < 44U)\n\n            den *= 2;\n\n        av_reduce(&h->avctx->framerate.den, &h->avctx->framerate.num,\n\n                  h->sps.num_units_in_tick, den, 1 << 30);\n\n    }\n\n\n\n    ff_h264_free_tables(h);\n\n\n\n    h->first_field           = 0;\n\n    h->prev_interlaced_frame = 1;\n\n\n\n    init_scan_tables(h);\n\n    ret = ff_h264_alloc_tables(h);\n\n    if (ret < 0) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"Could not allocate memory\\n\");\n\n        return ret;\n\n    }\n\n\n\n    if (h->sps.bit_depth_luma < 8 || h->sps.bit_depth_luma > 10) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"Unsupported bit depth %d\\n\",\n\n               h->sps.bit_depth_luma);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    h->avctx->bits_per_raw_sample = h->sps.bit_depth_luma;\n\n    h->pixel_shift                = h->sps.bit_depth_luma > 8;\n\n    h->chroma_format_idc          = h->sps.chroma_format_idc;\n\n    h->bit_depth_luma             = h->sps.bit_depth_luma;\n\n\n\n    ff_h264dsp_init(&h->h264dsp, h->sps.bit_depth_luma,\n\n                    h->sps.chroma_format_idc);\n\n    ff_h264chroma_init(&h->h264chroma, h->sps.bit_depth_chroma);\n\n    ff_h264qpel_init(&h->h264qpel, h->sps.bit_depth_luma);\n\n    ff_h264_pred_init(&h->hpc, h->avctx->codec_id, h->sps.bit_depth_luma,\n\n                      h->sps.chroma_format_idc);\n\n    ff_videodsp_init(&h->vdsp, h->sps.bit_depth_luma);\n\n\n\n    if (nb_slices > H264_MAX_THREADS || (nb_slices > h->mb_height && h->mb_height)) {\n\n        int max_slices;\n\n        if (h->mb_height)\n\n            max_slices = FFMIN(H264_MAX_THREADS, h->mb_height);\n\n        else\n\n            max_slices = H264_MAX_THREADS;\n\n        av_log(h->avctx, AV_LOG_WARNING, \"too many threads/slices %d,\"\n\n               \" reducing to %d\\n\", nb_slices, max_slices);\n\n        nb_slices = max_slices;\n\n    }\n\n    h->slice_context_count = nb_slices;\n\n\n\n    if (!HAVE_THREADS || !(h->avctx->active_thread_type & FF_THREAD_SLICE)) {\n\n        ret = ff_h264_slice_context_init(h, &h->slice_ctx[0]);\n\n        if (ret < 0) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"context_init() failed.\\n\");\n\n            return ret;\n\n        }\n\n    } else {\n\n        for (i = 0; i < h->slice_context_count; i++) {\n\n            H264SliceContext *sl = &h->slice_ctx[i];\n\n\n\n            sl->h264               = h;\n\n            sl->intra4x4_pred_mode = h->intra4x4_pred_mode + i * 8 * 2 * h->mb_stride;\n\n            sl->mvd_table[0]       = h->mvd_table[0]       + i * 8 * 2 * h->mb_stride;\n\n            sl->mvd_table[1]       = h->mvd_table[1]       + i * 8 * 2 * h->mb_stride;\n\n\n\n            if ((ret = ff_h264_slice_context_init(h, sl)) < 0) {\n\n                av_log(h->avctx, AV_LOG_ERROR, \"context_init() failed.\\n\");\n\n                return ret;\n\n            }\n\n        }\n\n    }\n\n\n\n    h->context_initialized = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 27097}
{"project": "FFmpeg", "commit_id": "dcc39ee10e82833ce24aa57926c00ffeb1948198", "target": 0, "func": "int ff_mpv_frame_start(MpegEncContext *s, AVCodecContext *avctx)\n\n{\n\n    int i, ret;\n\n    Picture *pic;\n\n    s->mb_skipped = 0;\n\n\n\n    /* mark & release old frames */\n\n    if (s->pict_type != AV_PICTURE_TYPE_B && s->last_picture_ptr &&\n\n        s->last_picture_ptr != s->next_picture_ptr &&\n\n        s->last_picture_ptr->f->buf[0]) {\n\n        ff_mpeg_unref_picture(s->avctx, s->last_picture_ptr);\n\n    }\n\n\n\n    /* release forgotten pictures */\n\n    /* if (MPEG-124 / H.263) */\n\n    for (i = 0; i < MAX_PICTURE_COUNT; i++) {\n\n        if (&s->picture[i] != s->last_picture_ptr &&\n\n            &s->picture[i] != s->next_picture_ptr &&\n\n            s->picture[i].reference && !s->picture[i].needs_realloc) {\n\n            ff_mpeg_unref_picture(s->avctx, &s->picture[i]);\n\n        }\n\n    }\n\n\n\n    ff_mpeg_unref_picture(s->avctx, &s->current_picture);\n\n\n\n    /* release non reference frames */\n\n    for (i = 0; i < MAX_PICTURE_COUNT; i++) {\n\n        if (!s->picture[i].reference)\n\n            ff_mpeg_unref_picture(s->avctx, &s->picture[i]);\n\n    }\n\n\n\n    if (s->current_picture_ptr && !s->current_picture_ptr->f->buf[0]) {\n\n        // we already have a unused image\n\n        // (maybe it was set before reading the header)\n\n        pic = s->current_picture_ptr;\n\n    } else {\n\n        i   = ff_find_unused_picture(s->avctx, s->picture, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        pic = &s->picture[i];\n\n    }\n\n\n\n    pic->reference = 0;\n\n    if (!s->droppable) {\n\n        if (s->pict_type != AV_PICTURE_TYPE_B)\n\n            pic->reference = 3;\n\n    }\n\n\n\n    pic->f->coded_picture_number = s->coded_picture_number++;\n\n\n\n    if (alloc_picture(s, pic, 0) < 0)\n\n        return -1;\n\n\n\n    s->current_picture_ptr = pic;\n\n    // FIXME use only the vars from current_pic\n\n    s->current_picture_ptr->f->top_field_first = s->top_field_first;\n\n    if (s->codec_id == AV_CODEC_ID_MPEG1VIDEO ||\n\n        s->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n        if (s->picture_structure != PICT_FRAME)\n\n            s->current_picture_ptr->f->top_field_first =\n\n                (s->picture_structure == PICT_TOP_FIELD) == s->first_field;\n\n    }\n\n    s->current_picture_ptr->f->interlaced_frame = !s->progressive_frame &&\n\n                                                 !s->progressive_sequence;\n\n    s->current_picture_ptr->field_picture      =  s->picture_structure != PICT_FRAME;\n\n\n\n    s->current_picture_ptr->f->pict_type = s->pict_type;\n\n    // if (s->avctx->flags && AV_CODEC_FLAG_QSCALE)\n\n    //     s->current_picture_ptr->quality = s->new_picture_ptr->quality;\n\n    s->current_picture_ptr->f->key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n\n\n    if ((ret = ff_mpeg_ref_picture(s->avctx, &s->current_picture,\n\n                                   s->current_picture_ptr)) < 0)\n\n        return ret;\n\n\n\n    if (s->pict_type != AV_PICTURE_TYPE_B) {\n\n        s->last_picture_ptr = s->next_picture_ptr;\n\n        if (!s->droppable)\n\n            s->next_picture_ptr = s->current_picture_ptr;\n\n    }\n\n    ff_dlog(s->avctx, \"L%p N%p C%p L%p N%p C%p type:%d drop:%d\\n\",\n\n            s->last_picture_ptr, s->next_picture_ptr,s->current_picture_ptr,\n\n            s->last_picture_ptr    ? s->last_picture_ptr->f->data[0]    : NULL,\n\n            s->next_picture_ptr    ? s->next_picture_ptr->f->data[0]    : NULL,\n\n            s->current_picture_ptr ? s->current_picture_ptr->f->data[0] : NULL,\n\n            s->pict_type, s->droppable);\n\n\n\n    if ((!s->last_picture_ptr || !s->last_picture_ptr->f->buf[0]) &&\n\n        (s->pict_type != AV_PICTURE_TYPE_I ||\n\n         s->picture_structure != PICT_FRAME)) {\n\n        int h_chroma_shift, v_chroma_shift;\n\n        av_pix_fmt_get_chroma_sub_sample(s->avctx->pix_fmt,\n\n                                         &h_chroma_shift, &v_chroma_shift);\n\n        if (s->pict_type != AV_PICTURE_TYPE_I)\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"warning: first frame is no keyframe\\n\");\n\n        else if (s->picture_structure != PICT_FRAME)\n\n            av_log(avctx, AV_LOG_INFO,\n\n                   \"allocate dummy last picture for field based first keyframe\\n\");\n\n\n\n        /* Allocate a dummy frame */\n\n        i = ff_find_unused_picture(s->avctx, s->picture, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        s->last_picture_ptr = &s->picture[i];\n\n\n\n        s->last_picture_ptr->reference   = 3;\n\n        s->last_picture_ptr->f->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n        if (alloc_picture(s, s->last_picture_ptr, 0) < 0) {\n\n            s->last_picture_ptr = NULL;\n\n            return -1;\n\n        }\n\n\n\n        memset(s->last_picture_ptr->f->data[0], 0,\n\n               avctx->height * s->last_picture_ptr->f->linesize[0]);\n\n        memset(s->last_picture_ptr->f->data[1], 0x80,\n\n               (avctx->height >> v_chroma_shift) *\n\n               s->last_picture_ptr->f->linesize[1]);\n\n        memset(s->last_picture_ptr->f->data[2], 0x80,\n\n               (avctx->height >> v_chroma_shift) *\n\n               s->last_picture_ptr->f->linesize[2]);\n\n\n\n        ff_thread_report_progress(&s->last_picture_ptr->tf, INT_MAX, 0);\n\n        ff_thread_report_progress(&s->last_picture_ptr->tf, INT_MAX, 1);\n\n    }\n\n    if ((!s->next_picture_ptr || !s->next_picture_ptr->f->buf[0]) &&\n\n        s->pict_type == AV_PICTURE_TYPE_B) {\n\n        /* Allocate a dummy frame */\n\n        i = ff_find_unused_picture(s->avctx, s->picture, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        s->next_picture_ptr = &s->picture[i];\n\n\n\n        s->next_picture_ptr->reference   = 3;\n\n        s->next_picture_ptr->f->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n        if (alloc_picture(s, s->next_picture_ptr, 0) < 0) {\n\n            s->next_picture_ptr = NULL;\n\n            return -1;\n\n        }\n\n        ff_thread_report_progress(&s->next_picture_ptr->tf, INT_MAX, 0);\n\n        ff_thread_report_progress(&s->next_picture_ptr->tf, INT_MAX, 1);\n\n    }\n\n\n\n    if (s->last_picture_ptr) {\n\n        ff_mpeg_unref_picture(s->avctx, &s->last_picture);\n\n        if (s->last_picture_ptr->f->buf[0] &&\n\n            (ret = ff_mpeg_ref_picture(s->avctx, &s->last_picture,\n\n                                       s->last_picture_ptr)) < 0)\n\n            return ret;\n\n    }\n\n    if (s->next_picture_ptr) {\n\n        ff_mpeg_unref_picture(s->avctx, &s->next_picture);\n\n        if (s->next_picture_ptr->f->buf[0] &&\n\n            (ret = ff_mpeg_ref_picture(s->avctx, &s->next_picture,\n\n                                       s->next_picture_ptr)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    if (s->pict_type != AV_PICTURE_TYPE_I &&\n\n        !(s->last_picture_ptr && s->last_picture_ptr->f->buf[0])) {\n\n        av_log(s, AV_LOG_ERROR,\n\n               \"Non-reference picture received and no reference available\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->picture_structure!= PICT_FRAME) {\n\n        int i;\n\n        for (i = 0; i < 4; i++) {\n\n            if (s->picture_structure == PICT_BOTTOM_FIELD) {\n\n                s->current_picture.f->data[i] +=\n\n                    s->current_picture.f->linesize[i];\n\n            }\n\n            s->current_picture.f->linesize[i] *= 2;\n\n            s->last_picture.f->linesize[i]    *= 2;\n\n            s->next_picture.f->linesize[i]    *= 2;\n\n        }\n\n    }\n\n\n\n    /* set dequantizer, we can't do it during init as\n\n     * it might change for MPEG-4 and we can't do it in the header\n\n     * decode as init is not called for MPEG-4 there yet */\n\n    if (s->mpeg_quant || s->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n        s->dct_unquantize_intra = s->dct_unquantize_mpeg2_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_mpeg2_inter;\n\n    } else if (s->out_format == FMT_H263 || s->out_format == FMT_H261) {\n\n        s->dct_unquantize_intra = s->dct_unquantize_h263_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_h263_inter;\n\n    } else {\n\n        s->dct_unquantize_intra = s->dct_unquantize_mpeg1_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_mpeg1_inter;\n\n    }\n\n\n\n#if FF_API_XVMC\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    if (CONFIG_MPEG_XVMC_DECODER && s->avctx->xvmc_acceleration)\n\n        return ff_xvmc_field_start(s, avctx);\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif /* FF_API_XVMC */\n\n\n\n    return 0;\n\n}\n", "idx": 27098}
{"project": "FFmpeg", "commit_id": "1f630b97178cdf1637c96f0eecd0975cde30bb7c", "target": 0, "func": "static inline void h264_loop_filter_luma_mmx2(uint8_t *pix, int stride, int alpha1, int beta1, int8_t *tc0)\n\n{\n\n    DECLARE_ALIGNED_8(uint64_t, tmp0[2]);\n\n\n\n    __asm__ volatile(\n\n        \"movq    (%1,%3), %%mm0    \\n\\t\" //p1\n\n        \"movq    (%1,%3,2), %%mm1  \\n\\t\" //p0\n\n        \"movq    (%2),    %%mm2    \\n\\t\" //q0\n\n        \"movq    (%2,%3), %%mm3    \\n\\t\" //q1\n\n        H264_DEBLOCK_MASK(%6, %7)\n\n\n\n        \"movd      %5,    %%mm4    \\n\\t\"\n\n        \"punpcklbw %%mm4, %%mm4    \\n\\t\"\n\n        \"punpcklwd %%mm4, %%mm4    \\n\\t\"\n\n        \"pcmpeqb   %%mm3, %%mm3    \\n\\t\"\n\n        \"movq      %%mm4, %%mm6    \\n\\t\"\n\n        \"pcmpgtb   %%mm3, %%mm4    \\n\\t\"\n\n        \"movq      %%mm6, 8+%0     \\n\\t\"\n\n        \"pand      %%mm4, %%mm7    \\n\\t\"\n\n        \"movq      %%mm7, %0       \\n\\t\"\n\n\n\n        /* filter p1 */\n\n        \"movq     (%1),   %%mm3    \\n\\t\" //p2\n\n        DIFF_GT2_MMX(%%mm1, %%mm3, %%mm5, %%mm6, %%mm4) // |p2-p0|>beta-1\n\n        \"pand     %%mm7,  %%mm6    \\n\\t\" // mask & |p2-p0|<beta\n\n        \"pand     8+%0,   %%mm7    \\n\\t\" // mask & tc0\n\n        \"movq     %%mm7,  %%mm4    \\n\\t\"\n\n        \"psubb    %%mm6,  %%mm7    \\n\\t\"\n\n        \"pand     %%mm4,  %%mm6    \\n\\t\" // mask & |p2-p0|<beta & tc0\n\n        H264_DEBLOCK_Q1(%%mm0, %%mm3, \"(%1)\", \"(%1,%3)\", %%mm6, %%mm4)\n\n\n\n        /* filter q1 */\n\n        \"movq    (%2,%3,2), %%mm4  \\n\\t\" //q2\n\n        DIFF_GT2_MMX(%%mm2, %%mm4, %%mm5, %%mm6, %%mm3) // |q2-q0|>beta-1\n\n        \"pand     %0,     %%mm6    \\n\\t\"\n\n        \"movq     8+%0,   %%mm5    \\n\\t\" // can be merged with the and below but is slower then\n\n        \"pand     %%mm6,  %%mm5    \\n\\t\"\n\n        \"psubb    %%mm6,  %%mm7    \\n\\t\"\n\n        \"movq    (%2,%3), %%mm3    \\n\\t\"\n\n        H264_DEBLOCK_Q1(%%mm3, %%mm4, \"(%2,%3,2)\", \"(%2,%3)\", %%mm5, %%mm6)\n\n\n\n        /* filter p0, q0 */\n\n        H264_DEBLOCK_P0_Q0(%8, unused)\n\n        \"movq      %%mm1, (%1,%3,2) \\n\\t\"\n\n        \"movq      %%mm2, (%2)      \\n\\t\"\n\n\n\n        : \"=m\"(*tmp0)\n\n        : \"r\"(pix-3*stride), \"r\"(pix), \"r\"((x86_reg)stride),\n\n          \"m\"(*tmp0/*unused*/), \"m\"(*(uint32_t*)tc0), \"m\"(alpha1), \"m\"(beta1),\n\n          \"m\"(ff_bone)\n\n    );\n\n}\n", "idx": 27102}
{"project": "FFmpeg", "commit_id": "3a48e38ad0e37d89065843548414d367e70593bf", "target": 0, "func": "int ff_init_me(MpegEncContext *s){\n\n    MotionEstContext * const c= &s->me;\n\n    int cache_size= FFMIN(ME_MAP_SIZE>>ME_MAP_SHIFT, 1<<ME_MAP_SHIFT);\n\n    int dia_size= FFMAX(FFABS(s->avctx->dia_size)&255, FFABS(s->avctx->pre_dia_size)&255);\n\n\n\n    if(FFMIN(s->avctx->dia_size, s->avctx->pre_dia_size) < -ME_MAP_SIZE){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"ME_MAP size is too small for SAB diamond\\n\");\n\n        return -1;\n\n    }\n\n    //special case of snow is needed because snow uses its own iterative ME code\n\n    if(s->me_method!=ME_ZERO && s->me_method!=ME_EPZS && s->me_method!=ME_X1 && s->avctx->codec_id != AV_CODEC_ID_SNOW){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"me_method is only allowed to be set to zero and epzs; for hex,umh,full and others see dia_size\\n\");\n\n        return -1;\n\n    }\n\n\n\n    c->avctx= s->avctx;\n\n\n\n    if(cache_size < 2*dia_size && !c->stride){\n\n        av_log(s->avctx, AV_LOG_INFO, \"ME_MAP size may be a little small for the selected diamond size\\n\");\n\n    }\n\n\n\n    ff_set_cmp(&s->dsp, s->dsp.me_pre_cmp, c->avctx->me_pre_cmp);\n\n    ff_set_cmp(&s->dsp, s->dsp.me_cmp, c->avctx->me_cmp);\n\n    ff_set_cmp(&s->dsp, s->dsp.me_sub_cmp, c->avctx->me_sub_cmp);\n\n    ff_set_cmp(&s->dsp, s->dsp.mb_cmp, c->avctx->mb_cmp);\n\n\n\n    c->flags    = get_flags(c, 0, c->avctx->me_cmp    &FF_CMP_CHROMA);\n\n    c->sub_flags= get_flags(c, 0, c->avctx->me_sub_cmp&FF_CMP_CHROMA);\n\n    c->mb_flags = get_flags(c, 0, c->avctx->mb_cmp    &FF_CMP_CHROMA);\n\n\n\n/*FIXME s->no_rounding b_type*/\n\n    if(s->flags&CODEC_FLAG_QPEL){\n\n        c->sub_motion_search= qpel_motion_search;\n\n        c->qpel_avg= s->dsp.avg_qpel_pixels_tab;\n\n        if(s->no_rounding) c->qpel_put= s->dsp.put_no_rnd_qpel_pixels_tab;\n\n        else               c->qpel_put= s->dsp.put_qpel_pixels_tab;\n\n    }else{\n\n        if(c->avctx->me_sub_cmp&FF_CMP_CHROMA)\n\n            c->sub_motion_search= hpel_motion_search;\n\n        else if(   c->avctx->me_sub_cmp == FF_CMP_SAD\n\n                && c->avctx->    me_cmp == FF_CMP_SAD\n\n                && c->avctx->    mb_cmp == FF_CMP_SAD)\n\n            c->sub_motion_search= sad_hpel_motion_search; // 2050 vs. 2450 cycles\n\n        else\n\n            c->sub_motion_search= hpel_motion_search;\n\n    }\n\n    c->hpel_avg= s->dsp.avg_pixels_tab;\n\n    if(s->no_rounding) c->hpel_put= s->dsp.put_no_rnd_pixels_tab;\n\n    else               c->hpel_put= s->dsp.put_pixels_tab;\n\n\n\n    if(s->linesize){\n\n        c->stride  = s->linesize;\n\n        c->uvstride= s->uvlinesize;\n\n    }else{\n\n        c->stride  = 16*s->mb_width + 32;\n\n        c->uvstride=  8*s->mb_width + 16;\n\n    }\n\n\n\n    /* 8x8 fullpel search would need a 4x4 chroma compare, which we do\n\n     * not have yet, and even if we had, the motion estimation code\n\n     * does not expect it. */\n\n    if(s->codec_id != AV_CODEC_ID_SNOW){\n\n        if((c->avctx->me_cmp&FF_CMP_CHROMA)/* && !s->dsp.me_cmp[2]*/){\n\n            s->dsp.me_cmp[2]= zero_cmp;\n\n        }\n\n        if((c->avctx->me_sub_cmp&FF_CMP_CHROMA) && !s->dsp.me_sub_cmp[2]){\n\n            s->dsp.me_sub_cmp[2]= zero_cmp;\n\n        }\n\n        c->hpel_put[2][0]= c->hpel_put[2][1]=\n\n        c->hpel_put[2][2]= c->hpel_put[2][3]= zero_hpel;\n\n    }\n\n\n\n    if(s->codec_id == AV_CODEC_ID_H261){\n\n        c->sub_motion_search= no_sub_motion_search;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 27103}
{"project": "FFmpeg", "commit_id": "4c55144ee969a63bb5e469e3ebd7179b7b3616e8", "target": 0, "func": "static int filter_frame(AVFilterLink *inlink, AVFrame *buf)\n\n{\n\n    AVFilterContext *ctx = inlink->dst;\n\n    AVFilterLink *outlink = ctx->outputs[0];\n\n    DeflickerContext *s = ctx->priv;\n\n    AVDictionary **metadata;\n\n    AVFrame *out, *in;\n\n    float f;\n\n    int y;\n\n\n\n    if (s->q.available < s->size && !s->eof) {\n\n        s->luminance[s->available] = s->calc_avgy(ctx, buf);\n\n        ff_bufqueue_add(ctx, &s->q, buf);\n\n        s->available++;\n\n        return 0;\n\n    }\n\n\n\n    in = ff_bufqueue_peek(&s->q, 0);\n\n\n\n    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);\n\n    if (!out) {\n\n        av_frame_free(&buf);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    s->get_factor(ctx, &f);\n\n    s->deflicker(ctx, in->data[0], in->linesize[0], out->data[0], out->linesize[0],\n\n                 outlink->w, outlink->h, f);\n\n    for (y = 1; y < s->nb_planes; y++) {\n\n        av_image_copy_plane(out->data[y], out->linesize[y],\n\n                            in->data[y], in->linesize[y],\n\n                            s->planewidth[y] * (1 + (s->depth > 8)), s->planeheight[y]);\n\n    }\n\n\n\n    av_frame_copy_props(out, in);\n\n    metadata = &out->metadata;\n\n    if (metadata) {\n\n        uint8_t value[128];\n\n\n\n        snprintf(value, sizeof(value), \"%f\", s->luminance[0]);\n\n        av_dict_set(metadata, \"lavfi.deflicker.luminance\", value, 0);\n\n\n\n        snprintf(value, sizeof(value), \"%f\", s->luminance[0] * f);\n\n        av_dict_set(metadata, \"lavfi.deflicker.new_luminance\", value, 0);\n\n\n\n        snprintf(value, sizeof(value), \"%f\", f - 1.0f);\n\n        av_dict_set(metadata, \"lavfi.deflicker.relative_change\", value, 0);\n\n    }\n\n\n\n    in = ff_bufqueue_get(&s->q);\n\n    av_frame_free(&in);\n\n    memmove(&s->luminance[0], &s->luminance[1], sizeof(*s->luminance) * (s->size - 1));\n\n    s->luminance[s->available - 1] = s->calc_avgy(ctx, buf);\n\n    ff_bufqueue_add(ctx, &s->q, buf);\n\n\n\n    return ff_filter_frame(outlink, out);\n\n}\n", "idx": 27104}
{"project": "FFmpeg", "commit_id": "55078332495d879ad4aeb23ae2bada75130431c6", "target": 1, "func": "static inline int msmpeg4_decode_block(MpegEncContext * s, DCTELEM * block,\n\n                              int n, int coded)\n\n{\n\n    int level, i, last, run, run_diff;\n\n    int dc_pred_dir;\n\n    RLTable *rl;\n\n    RL_VLC_ELEM *rl_vlc;\n\n    const UINT8 *scan_table;\n\n    int qmul, qadd;\n\n\n\n    if (s->mb_intra) {\n\n        qmul=1;\n\n        qadd=0;\n\n\n\n\t/* DC coef */\n\n        set_stat(ST_DC);\n\n        level = msmpeg4_decode_dc(s, n, &dc_pred_dir);\n\n#ifdef PRINT_MB\n\n{\n\n    static int c;\n\n    if(n==0) c=0;\n\n    if(n==4) printf(\"%X\", c);\n\n    c+= c +dc_pred_dir;\n\n}\n\n#endif\n\n        if (level < 0){\n\n            fprintf(stderr, \"dc overflow- block: %d qscale: %d//\\n\", n, s->qscale);\n\n            if(s->inter_intra_pred) level=0;\n\n            else                    return -1;\n\n        }\n\n        if (n < 4) {\n\n            rl = &rl_table[s->rl_table_index];\n\n            if(level > 256*s->y_dc_scale){\n\n                fprintf(stderr, \"dc overflow+ L qscale: %d//\\n\", s->qscale);\n\n                if(!s->inter_intra_pred) return -1;\n\n            }\n\n        } else {\n\n            rl = &rl_table[3 + s->rl_chroma_table_index];\n\n            if(level > 256*s->c_dc_scale){\n\n                fprintf(stderr, \"dc overflow+ C qscale: %d//\\n\", s->qscale);\n\n                if(!s->inter_intra_pred) return -1;\n\n            }\n\n        }\n\n        block[0] = level;\n\n\n\n        run_diff = 0;\n\n        i = 0;\n\n        if (!coded) {\n\n            goto not_coded;\n\n        }\n\n        if (s->ac_pred) {\n\n            if (dc_pred_dir == 0) \n\n                scan_table = s->intra_v_scantable; /* left */\n\n            else\n\n                scan_table = s->intra_h_scantable; /* top */\n\n        } else {\n\n            scan_table = s->intra_scantable;\n\n        }\n\n        set_stat(ST_INTRA_AC);\n\n        rl_vlc= rl->rl_vlc[0];\n\n    } else {\n\n        qmul = s->qscale << 1;\n\n        qadd = (s->qscale - 1) | 1;\n\n        i = -1;\n\n        rl = &rl_table[3 + s->rl_table_index];\n\n\n\n        if(s->msmpeg4_version==2)\n\n            run_diff = 0;\n\n        else\n\n            run_diff = 1;\n\n\n\n        if (!coded) {\n\n            s->block_last_index[n] = i;\n\n            return 0;\n\n        }\n\n        scan_table = s->inter_scantable;\n\n        set_stat(ST_INTER_AC);\n\n        rl_vlc= rl->rl_vlc[s->qscale];\n\n    }\n\n  {\n\n    OPEN_READER(re, &s->gb);\n\n    for(;;) {\n\n        UPDATE_CACHE(re, &s->gb);\n\n        GET_RL_VLC(level, run, re, &s->gb, rl_vlc, TEX_VLC_BITS, 2);\n\n        if (level==0) {\n\n            int cache;\n\n            cache= GET_CACHE(re, &s->gb);\n\n            /* escape */\n\n            if (s->msmpeg4_version==1 || (cache&0x80000000)==0) {\n\n                if (s->msmpeg4_version==1 || (cache&0x40000000)==0) {\n\n                    /* third escape */\n\n                    if(s->msmpeg4_version!=1) LAST_SKIP_BITS(re, &s->gb, 2);\n\n                    UPDATE_CACHE(re, &s->gb);\n\n                    if(s->msmpeg4_version<=3){\n\n                        last=  SHOW_UBITS(re, &s->gb, 1); SKIP_CACHE(re, &s->gb, 1);\n\n                        run=   SHOW_UBITS(re, &s->gb, 6); SKIP_CACHE(re, &s->gb, 6);\n\n                        level= SHOW_SBITS(re, &s->gb, 8); LAST_SKIP_CACHE(re, &s->gb, 8);\n\n                        SKIP_COUNTER(re, &s->gb, 1+6+8);\n\n                    }else{                        \n\n                        int sign;\n\n                        last=  SHOW_UBITS(re, &s->gb, 1); SKIP_BITS(re, &s->gb, 1);\n\n                        if(!s->esc3_level_length){\n\n                            int ll;\n\n                            //printf(\"ESC-3 %X at %d %d\\n\", show_bits(&s->gb, 24), s->mb_x, s->mb_y);\n\n                            if(s->qscale<8){\n\n                                ll= SHOW_UBITS(re, &s->gb, 3); SKIP_BITS(re, &s->gb, 3);\n\n                                if(ll==0){\n\n                                    if(SHOW_UBITS(re, &s->gb, 1)) printf(\"cool a new vlc code ,contact the ffmpeg developers and upload the file\\n\");\n\n                                    SKIP_BITS(re, &s->gb, 1);\n\n                                    ll=8;\n\n                                }\n\n                            }else{\n\n                                ll=2;\n\n                                while(ll<8 && SHOW_UBITS(re, &s->gb, 1)==0){\n\n                                    ll++;\n\n                                    SKIP_BITS(re, &s->gb, 1);\n\n                                }\n\n                                if(ll<8) SKIP_BITS(re, &s->gb, 1);\n\n                            }\n\n\n\n                            s->esc3_level_length= ll;\n\n                            s->esc3_run_length= SHOW_UBITS(re, &s->gb, 2) + 3; SKIP_BITS(re, &s->gb, 2);\n\n//printf(\"level length:%d, run length: %d\\n\", ll, s->esc3_run_length);\n\n                            UPDATE_CACHE(re, &s->gb);\n\n                        }\n\n                        run=   SHOW_UBITS(re, &s->gb, s->esc3_run_length); \n\n                        SKIP_BITS(re, &s->gb, s->esc3_run_length);\n\n                        \n\n                        sign=  SHOW_UBITS(re, &s->gb, 1); \n\n                        SKIP_BITS(re, &s->gb, 1);\n\n                        \n\n                        level= SHOW_UBITS(re, &s->gb, s->esc3_level_length); \n\n                        SKIP_BITS(re, &s->gb, s->esc3_level_length);\n\n                        if(sign) level= -level;\n\n                    }\n\n//printf(\"level: %d, run: %d at %d %d\\n\", level, run, s->mb_x, s->mb_y);\n\n#if 0 // waste of time / this will detect very few errors\n\n                    {\n\n                        const int abs_level= ABS(level);\n\n                        const int run1= run - rl->max_run[last][abs_level] - run_diff;\n\n                        if(abs_level<=MAX_LEVEL && run<=MAX_RUN){\n\n                            if(abs_level <= rl->max_level[last][run]){\n\n                                fprintf(stderr, \"illegal 3. esc, vlc encoding possible\\n\");\n\n                                return DECODING_AC_LOST;\n\n                            }\n\n                            if(abs_level <= rl->max_level[last][run]*2){\n\n                                fprintf(stderr, \"illegal 3. esc, esc 1 encoding possible\\n\");\n\n                                return DECODING_AC_LOST;\n\n                            }\n\n                            if(run1>=0 && abs_level <= rl->max_level[last][run1]){\n\n                                fprintf(stderr, \"illegal 3. esc, esc 2 encoding possible\\n\");\n\n                                return DECODING_AC_LOST;\n\n                            }\n\n                        }\n\n                    }\n\n#endif\n\n\t\t    //level = level * qmul + (level>0) * qadd - (level<=0) * qadd ;\n\n\t\t    if (level>0) level= level * qmul + qadd;\n\n                    else         level= level * qmul - qadd;\n\n#if 0 // waste of time too :(\n\n                    if(level>2048 || level<-2048){\n\n                        fprintf(stderr, \"|level| overflow in 3. esc\\n\");\n\n                        return DECODING_AC_LOST;\n\n                    }\n\n#endif\n\n                    i+= run + 1;\n\n                    if(last) i+=192;\n\n#ifdef ERROR_DETAILS\n\n                if(run==66)\n\n                    fprintf(stderr, \"illegal vlc code in ESC3 level=%d\\n\", level);\n\n                else if((i>62 && i<192) || i>192+63)\n\n                    fprintf(stderr, \"run overflow in ESC3 i=%d run=%d level=%d\\n\", i, run, level);\n\n#endif\n\n                } else {\n\n                    /* second escape */\n\n#if MIN_CACHE_BITS < 23\n\n                    LAST_SKIP_BITS(re, &s->gb, 2);\n\n                    UPDATE_CACHE(re, &s->gb);\n\n#else\n\n                    SKIP_BITS(re, &s->gb, 2);\n\n#endif\n\n                    GET_RL_VLC(level, run, re, &s->gb, rl_vlc, TEX_VLC_BITS, 2);\n\n                    i+= run + rl->max_run[run>>7][level/qmul] + run_diff; //FIXME opt indexing\n\n                    level = (level ^ SHOW_SBITS(re, &s->gb, 1)) - SHOW_SBITS(re, &s->gb, 1);\n\n                    LAST_SKIP_BITS(re, &s->gb, 1);\n\n#ifdef ERROR_DETAILS\n\n                if(run==66)\n\n                    fprintf(stderr, \"illegal vlc code in ESC2 level=%d\\n\", level);\n\n                else if((i>62 && i<192) || i>192+63)\n\n                    fprintf(stderr, \"run overflow in ESC2 i=%d run=%d level=%d\\n\", i, run, level);\n\n#endif\n\n                }\n\n            } else {\n\n                /* first escape */\n\n#if MIN_CACHE_BITS < 22\n\n                LAST_SKIP_BITS(re, &s->gb, 1);\n\n                UPDATE_CACHE(re, &s->gb);\n\n#else\n\n                SKIP_BITS(re, &s->gb, 1);\n\n#endif\n\n                GET_RL_VLC(level, run, re, &s->gb, rl_vlc, TEX_VLC_BITS, 2);\n\n                i+= run;\n\n                level = level + rl->max_level[run>>7][(run-1)&63] * qmul;//FIXME opt indexing\n\n                level = (level ^ SHOW_SBITS(re, &s->gb, 1)) - SHOW_SBITS(re, &s->gb, 1);\n\n                LAST_SKIP_BITS(re, &s->gb, 1);\n\n#ifdef ERROR_DETAILS\n\n                if(run==66)\n\n                    fprintf(stderr, \"illegal vlc code in ESC1 level=%d\\n\", level);\n\n                else if((i>62 && i<192) || i>192+63)\n\n                    fprintf(stderr, \"run overflow in ESC1 i=%d run=%d level=%d\\n\", i, run, level);\n\n#endif\n\n            }\n\n        } else {\n\n            i+= run;\n\n            level = (level ^ SHOW_SBITS(re, &s->gb, 1)) - SHOW_SBITS(re, &s->gb, 1);\n\n            LAST_SKIP_BITS(re, &s->gb, 1);\n\n#ifdef ERROR_DETAILS\n\n                if(run==66)\n\n                    fprintf(stderr, \"illegal vlc code level=%d\\n\", level);\n\n                else if((i>62 && i<192) || i>192+63)\n\n                    fprintf(stderr, \"run overflow i=%d run=%d level=%d\\n\", i, run, level);\n\n#endif\n\n        }\n\n        if (i > 62){\n\n            i-= 192;\n\n            if(i&(~63)){\n\n                if(s->error_resilience<0){\n\n                    fprintf(stderr, \"ignoring overflow at %d %d\\n\", s->mb_x, s->mb_y);\n\n                    break;\n\n                }else{\n\n                    fprintf(stderr, \"ac-tex damaged at %d %d\\n\", s->mb_x, s->mb_y);\n\n                    return -1;\n\n                }\n\n            }\n\n\n\n            block[scan_table[i]] = level;\n\n            break;\n\n        }\n\n\n\n        block[scan_table[i]] = level;\n\n    }\n\n    CLOSE_READER(re, &s->gb);\n\n  }\n\n not_coded:\n\n    if (s->mb_intra) {\n\n        mpeg4_pred_ac(s, block, n, dc_pred_dir);\n\n        if (s->ac_pred) {\n\n            i = 63; /* XXX: not optimal */\n\n        }\n\n    }\n\n    if(s->msmpeg4_version==4 && i>0) i=63; //FIXME/XXX optimize\n\n    s->block_last_index[n] = i;\n\n    \n\n    return 0;\n\n}\n", "idx": 27113}
{"project": "FFmpeg", "commit_id": "7c2fa13df9a6130b3f258c7513933cbdca2fe23b", "target": 1, "func": "static int oma_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    OMAContext *oc  = s->priv_data;\n\n    AVStream *st    = s->streams[0];\n\n    int packet_size = st->codec->block_align;\n\n    int byte_rate   = st->codec->bit_rate >> 3;\n\n    int64_t pos     = avio_tell(s->pb);\n\n    int ret         = av_get_packet(s->pb, pkt, packet_size);\n\n\n\n    if (ret < packet_size)\n\n        pkt->flags |= AV_PKT_FLAG_CORRUPT;\n\n\n\n    if (ret < 0)\n\n        return ret;\n\n    if (!ret)\n\n        return AVERROR_EOF;\n\n\n\n    pkt->stream_index = 0;\n\n\n\n    if (pos > 0) {\n\n        pkt->pts =\n\n        pkt->dts = av_rescale(pos, st->time_base.den,\n\n                              byte_rate * (int64_t)st->time_base.num);\n\n    }\n\n\n\n    if (oc->encrypted) {\n\n        /* previous unencrypted block saved in IV for\n\n         * the next packet (CBC mode) */\n\n        if (ret == packet_size)\n\n            av_des_crypt(&oc->av_des, pkt->data, pkt->data,\n\n                         (packet_size >> 3), oc->iv, 1);\n\n        else\n\n            memset(oc->iv, 0, 8);\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 27117}
{"project": "FFmpeg", "commit_id": "08d0969c1402ccec4dce44bd430128fb59d7b790", "target": 0, "func": "void av_opt_set_defaults2(void *s, int mask, int flags)\n\n{\n\n#endif\n\n    const AVOption *opt = NULL;\n\n    while ((opt = av_opt_next(s, opt)) != NULL) {\n\n#if FF_API_OLD_AVOPTIONS\n\n        if ((opt->flags & mask) != flags)\n\n            continue;\n\n#endif\n\n        switch (opt->type) {\n\n            case AV_OPT_TYPE_CONST:\n\n                /* Nothing to be done here */\n\n            break;\n\n            case AV_OPT_TYPE_FLAGS:\n\n            case AV_OPT_TYPE_INT:\n\n            case AV_OPT_TYPE_INT64:\n\n                av_opt_set_int(s, opt->name, opt->default_val.i64, 0);\n\n            break;\n\n            case AV_OPT_TYPE_DOUBLE:\n\n            case AV_OPT_TYPE_FLOAT: {\n\n                double val;\n\n                val = opt->default_val.dbl;\n\n                av_opt_set_double(s, opt->name, val, 0);\n\n            }\n\n            break;\n\n            case AV_OPT_TYPE_RATIONAL: {\n\n                AVRational val;\n\n                val = av_d2q(opt->default_val.dbl, INT_MAX);\n\n                av_opt_set_q(s, opt->name, val, 0);\n\n            }\n\n            break;\n\n            case AV_OPT_TYPE_STRING:\n\n            case AV_OPT_TYPE_IMAGE_SIZE:\n\n            case AV_OPT_TYPE_PIXEL_FMT:\n\n            case AV_OPT_TYPE_SAMPLE_FMT:\n\n                av_opt_set(s, opt->name, opt->default_val.str, 0);\n\n                break;\n\n            case AV_OPT_TYPE_BINARY:\n\n                /* Cannot set default for binary */\n\n            break;\n\n            default:\n\n                av_log(s, AV_LOG_DEBUG, \"AVOption type %d of option %s not implemented yet\\n\", opt->type, opt->name);\n\n        }\n\n    }\n\n}\n", "idx": 27118}
{"project": "FFmpeg", "commit_id": "65e33d8e23277bb96809842656482e0e3fe8746f", "target": 1, "func": "static int RENAME(resample_common)(ResampleContext *c,\n\n                                   void *dest, const void *source,\n\n                                   int n, int update_ctx)\n\n{\n\n    DELEM *dst = dest;\n\n    const DELEM *src = source;\n\n    int dst_index;\n\n    int index= c->index;\n\n    int frac= c->frac;\n\n    int sample_index = 0;\n\n\n\n    while (index >= c->phase_count) {\n\n        sample_index++;\n\n        index -= c->phase_count;\n\n    }\n\n\n\n    for (dst_index = 0; dst_index < n; dst_index++) {\n\n        FELEM *filter = ((FELEM *) c->filter_bank) + c->filter_alloc * index;\n\n\n\n        FELEM2 val= FOFFSET;\n\n        int i;\n\n        for (i = 0; i < c->filter_length; i++) {\n\n            val += src[sample_index + i] * (FELEM2)filter[i];\n\n        }\n\n        OUT(dst[dst_index], val);\n\n\n\n        frac  += c->dst_incr_mod;\n\n        index += c->dst_incr_div;\n\n        if (frac >= c->src_incr) {\n\n            frac -= c->src_incr;\n\n            index++;\n\n        }\n\n\n\n        while (index >= c->phase_count) {\n\n            sample_index++;\n\n            index -= c->phase_count;\n\n        }\n\n    }\n\n\n\n    if(update_ctx){\n\n        c->frac= frac;\n\n        c->index= index;\n\n    }\n\n\n\n    return sample_index;\n\n}\n", "idx": 27119}
{"project": "FFmpeg", "commit_id": "1afd7a118fd71536971f991b823c89f1c9e87509", "target": 1, "func": "static int channelmap_filter_samples(AVFilterLink *inlink, AVFilterBufferRef *buf)\n\n{\n\n    AVFilterContext  *ctx = inlink->dst;\n\n    AVFilterLink *outlink = ctx->outputs[0];\n\n    const ChannelMapContext *s = ctx->priv;\n\n    const int nch_in = av_get_channel_layout_nb_channels(inlink->channel_layout);\n\n    const int nch_out = s->nch;\n\n    int ch;\n\n    uint8_t *source_planes[MAX_CH];\n\n\n\n    memcpy(source_planes, buf->extended_data,\n\n           nch_in * sizeof(source_planes[0]));\n\n\n\n    if (nch_out > nch_in) {\n\n        if (nch_out > FF_ARRAY_ELEMS(buf->data)) {\n\n            uint8_t **new_extended_data =\n\n                av_mallocz(nch_out * sizeof(*buf->extended_data));\n\n            if (!new_extended_data) {\n\n                avfilter_unref_buffer(buf);\n\n                return AVERROR(ENOMEM);\n\n            }\n\n            if (buf->extended_data == buf->data) {\n\n                buf->extended_data = new_extended_data;\n\n            } else {\n\n                buf->extended_data = new_extended_data;\n\n                av_free(buf->extended_data);\n\n            }\n\n        } else if (buf->extended_data != buf->data) {\n\n            av_free(buf->extended_data);\n\n            buf->extended_data = buf->data;\n\n        }\n\n    }\n\n\n\n    for (ch = 0; ch < nch_out; ch++) {\n\n        buf->extended_data[s->map[ch].out_channel_idx] =\n\n            source_planes[s->map[ch].in_channel_idx];\n\n    }\n\n\n\n    if (buf->data != buf->extended_data)\n\n        memcpy(buf->data, buf->extended_data,\n\n           FFMIN(FF_ARRAY_ELEMS(buf->data), nch_out) * sizeof(buf->data[0]));\n\n\n\n    return ff_filter_samples(outlink, buf);\n\n}\n", "idx": 27121}
{"project": "FFmpeg", "commit_id": "0bd485300e1a8bb0ba95df53da34562816120e31", "target": 0, "func": "static int encode_thread(AVCodecContext *c, void *arg){\n\n    MpegEncContext *s= *(void**)arg;\n\n    int mb_x, mb_y, pdif = 0;\n\n    int chr_h= 16>>s->chroma_y_shift;\n\n    int i, j;\n\n    MpegEncContext best_s, backup_s;\n\n    uint8_t bit_buf[2][MAX_MB_BYTES];\n\n    uint8_t bit_buf2[2][MAX_MB_BYTES];\n\n    uint8_t bit_buf_tex[2][MAX_MB_BYTES];\n\n    PutBitContext pb[2], pb2[2], tex_pb[2];\n\n//printf(\"%d->%d\\n\", s->resync_mb_y, s->end_mb_y);\n\n\n\n    ff_check_alignment();\n\n\n\n    for(i=0; i<2; i++){\n\n        init_put_bits(&pb    [i], bit_buf    [i], MAX_MB_BYTES);\n\n        init_put_bits(&pb2   [i], bit_buf2   [i], MAX_MB_BYTES);\n\n        init_put_bits(&tex_pb[i], bit_buf_tex[i], MAX_MB_BYTES);\n\n    }\n\n\n\n    s->last_bits= put_bits_count(&s->pb);\n\n    s->mv_bits=0;\n\n    s->misc_bits=0;\n\n    s->i_tex_bits=0;\n\n    s->p_tex_bits=0;\n\n    s->i_count=0;\n\n    s->f_count=0;\n\n    s->b_count=0;\n\n    s->skip_count=0;\n\n\n\n    for(i=0; i<3; i++){\n\n        /* init last dc values */\n\n        /* note: quant matrix value (8) is implied here */\n\n        s->last_dc[i] = 128 << s->intra_dc_precision;\n\n\n\n        s->current_picture.error[i] = 0;\n\n    }\n\n    s->mb_skip_run = 0;\n\n    memset(s->last_mv, 0, sizeof(s->last_mv));\n\n\n\n    s->last_mv_dir = 0;\n\n\n\n    switch(s->codec_id){\n\n    case CODEC_ID_H263:\n\n    case CODEC_ID_H263P:\n\n    case CODEC_ID_FLV1:\n\n        if (CONFIG_H263_ENCODER || CONFIG_FLV_ENCODER)\n\n            s->gob_index = ff_h263_get_gob_height(s);\n\n        break;\n\n    case CODEC_ID_MPEG4:\n\n        if(CONFIG_MPEG4_ENCODER && s->partitioned_frame)\n\n            ff_mpeg4_init_partitions(s);\n\n        break;\n\n    }\n\n\n\n    s->resync_mb_x=0;\n\n    s->resync_mb_y=0;\n\n    s->first_slice_line = 1;\n\n    s->ptr_lastgob = s->pb.buf;\n\n    for(mb_y= s->start_mb_y; mb_y < s->end_mb_y; mb_y++) {\n\n//    printf(\"row %d at %X\\n\", s->mb_y, (int)s);\n\n        s->mb_x=0;\n\n        s->mb_y= mb_y;\n\n\n\n        ff_set_qscale(s, s->qscale);\n\n        ff_init_block_index(s);\n\n\n\n        for(mb_x=0; mb_x < s->mb_width; mb_x++) {\n\n            int xy= mb_y*s->mb_stride + mb_x; // removed const, H261 needs to adjust this\n\n            int mb_type= s->mb_type[xy];\n\n//            int d;\n\n            int dmin= INT_MAX;\n\n            int dir;\n\n\n\n            if(s->pb.buf_end - s->pb.buf - (put_bits_count(&s->pb)>>3) < MAX_MB_BYTES){\n\n                av_log(s->avctx, AV_LOG_ERROR, \"encoded frame too large\\n\");\n\n                return -1;\n\n            }\n\n            if(s->data_partitioning){\n\n                if(   s->pb2   .buf_end - s->pb2   .buf - (put_bits_count(&s->    pb2)>>3) < MAX_MB_BYTES\n\n                   || s->tex_pb.buf_end - s->tex_pb.buf - (put_bits_count(&s->tex_pb )>>3) < MAX_MB_BYTES){\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"encoded frame too large\\n\");\n\n                    return -1;\n\n                }\n\n            }\n\n\n\n            s->mb_x = mb_x;\n\n            s->mb_y = mb_y;  // moved into loop, can get changed by H.261\n\n            ff_update_block_index(s);\n\n\n\n            if(CONFIG_H261_ENCODER && s->codec_id == CODEC_ID_H261){\n\n                ff_h261_reorder_mb_index(s);\n\n                xy= s->mb_y*s->mb_stride + s->mb_x;\n\n                mb_type= s->mb_type[xy];\n\n            }\n\n\n\n            /* write gob / video packet header  */\n\n            if(s->rtp_mode){\n\n                int current_packet_size, is_gob_start;\n\n\n\n                current_packet_size= ((put_bits_count(&s->pb)+7)>>3) - (s->ptr_lastgob - s->pb.buf);\n\n\n\n                is_gob_start= s->avctx->rtp_payload_size && current_packet_size >= s->avctx->rtp_payload_size && mb_y + mb_x>0;\n\n\n\n                if(s->start_mb_y == mb_y && mb_y > 0 && mb_x==0) is_gob_start=1;\n\n\n\n                switch(s->codec_id){\n\n                case CODEC_ID_H263:\n\n                case CODEC_ID_H263P:\n\n                    if(!s->h263_slice_structured)\n\n                        if(s->mb_x || s->mb_y%s->gob_index) is_gob_start=0;\n\n                    break;\n\n                case CODEC_ID_MPEG2VIDEO:\n\n                    if(s->mb_x==0 && s->mb_y!=0) is_gob_start=1;\n\n                case CODEC_ID_MPEG1VIDEO:\n\n                    if(s->mb_skip_run) is_gob_start=0;\n\n                    break;\n\n                }\n\n\n\n                if(is_gob_start){\n\n                    if(s->start_mb_y != mb_y || mb_x!=0){\n\n                        write_slice_end(s);\n\n\n\n                        if(CONFIG_MPEG4_ENCODER && s->codec_id==CODEC_ID_MPEG4 && s->partitioned_frame){\n\n                            ff_mpeg4_init_partitions(s);\n\n                        }\n\n                    }\n\n\n\n                    assert((put_bits_count(&s->pb)&7) == 0);\n\n                    current_packet_size= put_bits_ptr(&s->pb) - s->ptr_lastgob;\n\n\n\n                    if(s->avctx->error_rate && s->resync_mb_x + s->resync_mb_y > 0){\n\n                        int r= put_bits_count(&s->pb)/8 + s->picture_number + 16 + s->mb_x + s->mb_y;\n\n                        int d= 100 / s->avctx->error_rate;\n\n                        if(r % d == 0){\n\n                            current_packet_size=0;\n\n#ifndef ALT_BITSTREAM_WRITER\n\n                            s->pb.buf_ptr= s->ptr_lastgob;\n\n#endif\n\n                            assert(put_bits_ptr(&s->pb) == s->ptr_lastgob);\n\n                        }\n\n                    }\n\n\n\n                    if (s->avctx->rtp_callback){\n\n                        int number_mb = (mb_y - s->resync_mb_y)*s->mb_width + mb_x - s->resync_mb_x;\n\n                        s->avctx->rtp_callback(s->avctx, s->ptr_lastgob, current_packet_size, number_mb);\n\n                    }\n\n\n\n                    switch(s->codec_id){\n\n                    case CODEC_ID_MPEG4:\n\n                        if (CONFIG_MPEG4_ENCODER) {\n\n                            ff_mpeg4_encode_video_packet_header(s);\n\n                            ff_mpeg4_clean_buffers(s);\n\n                        }\n\n                    break;\n\n                    case CODEC_ID_MPEG1VIDEO:\n\n                    case CODEC_ID_MPEG2VIDEO:\n\n                        if (CONFIG_MPEG1VIDEO_ENCODER || CONFIG_MPEG2VIDEO_ENCODER) {\n\n                            ff_mpeg1_encode_slice_header(s);\n\n                            ff_mpeg1_clean_buffers(s);\n\n                        }\n\n                    break;\n\n                    case CODEC_ID_H263:\n\n                    case CODEC_ID_H263P:\n\n                        if (CONFIG_H263_ENCODER)\n\n                            h263_encode_gob_header(s, mb_y);\n\n                    break;\n\n                    }\n\n\n\n                    if(s->flags&CODEC_FLAG_PASS1){\n\n                        int bits= put_bits_count(&s->pb);\n\n                        s->misc_bits+= bits - s->last_bits;\n\n                        s->last_bits= bits;\n\n                    }\n\n\n\n                    s->ptr_lastgob += current_packet_size;\n\n                    s->first_slice_line=1;\n\n                    s->resync_mb_x=mb_x;\n\n                    s->resync_mb_y=mb_y;\n\n                }\n\n            }\n\n\n\n            if(  (s->resync_mb_x   == s->mb_x)\n\n               && s->resync_mb_y+1 == s->mb_y){\n\n                s->first_slice_line=0;\n\n            }\n\n\n\n            s->mb_skipped=0;\n\n            s->dquant=0; //only for QP_RD\n\n\n\n            if(mb_type & (mb_type-1) || (s->flags & CODEC_FLAG_QP_RD)){ // more than 1 MB type possible or CODEC_FLAG_QP_RD\n\n                int next_block=0;\n\n                int pb_bits_count, pb2_bits_count, tex_pb_bits_count;\n\n\n\n                copy_context_before_encode(&backup_s, s, -1);\n\n                backup_s.pb= s->pb;\n\n                best_s.data_partitioning= s->data_partitioning;\n\n                best_s.partitioned_frame= s->partitioned_frame;\n\n                if(s->data_partitioning){\n\n                    backup_s.pb2= s->pb2;\n\n                    backup_s.tex_pb= s->tex_pb;\n\n                }\n\n\n\n                if(mb_type&CANDIDATE_MB_TYPE_INTER){\n\n                    s->mv_dir = MV_DIR_FORWARD;\n\n                    s->mv_type = MV_TYPE_16X16;\n\n                    s->mb_intra= 0;\n\n                    s->mv[0][0][0] = s->p_mv_table[xy][0];\n\n                    s->mv[0][0][1] = s->p_mv_table[xy][1];\n\n                    encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_INTER, pb, pb2, tex_pb,\n\n                                 &dmin, &next_block, s->mv[0][0][0], s->mv[0][0][1]);\n\n                }\n\n                if(mb_type&CANDIDATE_MB_TYPE_INTER_I){\n\n                    s->mv_dir = MV_DIR_FORWARD;\n\n                    s->mv_type = MV_TYPE_FIELD;\n\n                    s->mb_intra= 0;\n\n                    for(i=0; i<2; i++){\n\n                        j= s->field_select[0][i] = s->p_field_select_table[i][xy];\n\n                        s->mv[0][i][0] = s->p_field_mv_table[i][j][xy][0];\n\n                        s->mv[0][i][1] = s->p_field_mv_table[i][j][xy][1];\n\n                    }\n\n                    encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_INTER_I, pb, pb2, tex_pb,\n\n                                 &dmin, &next_block, 0, 0);\n\n                }\n\n                if(mb_type&CANDIDATE_MB_TYPE_SKIPPED){\n\n                    s->mv_dir = MV_DIR_FORWARD;\n\n                    s->mv_type = MV_TYPE_16X16;\n\n                    s->mb_intra= 0;\n\n                    s->mv[0][0][0] = 0;\n\n                    s->mv[0][0][1] = 0;\n\n                    encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_SKIPPED, pb, pb2, tex_pb,\n\n                                 &dmin, &next_block, s->mv[0][0][0], s->mv[0][0][1]);\n\n                }\n\n                if(mb_type&CANDIDATE_MB_TYPE_INTER4V){\n\n                    s->mv_dir = MV_DIR_FORWARD;\n\n                    s->mv_type = MV_TYPE_8X8;\n\n                    s->mb_intra= 0;\n\n                    for(i=0; i<4; i++){\n\n                        s->mv[0][i][0] = s->current_picture.motion_val[0][s->block_index[i]][0];\n\n                        s->mv[0][i][1] = s->current_picture.motion_val[0][s->block_index[i]][1];\n\n                    }\n\n                    encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_INTER4V, pb, pb2, tex_pb,\n\n                                 &dmin, &next_block, 0, 0);\n\n                }\n\n                if(mb_type&CANDIDATE_MB_TYPE_FORWARD){\n\n                    s->mv_dir = MV_DIR_FORWARD;\n\n                    s->mv_type = MV_TYPE_16X16;\n\n                    s->mb_intra= 0;\n\n                    s->mv[0][0][0] = s->b_forw_mv_table[xy][0];\n\n                    s->mv[0][0][1] = s->b_forw_mv_table[xy][1];\n\n                    encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_FORWARD, pb, pb2, tex_pb,\n\n                                 &dmin, &next_block, s->mv[0][0][0], s->mv[0][0][1]);\n\n                }\n\n                if(mb_type&CANDIDATE_MB_TYPE_BACKWARD){\n\n                    s->mv_dir = MV_DIR_BACKWARD;\n\n                    s->mv_type = MV_TYPE_16X16;\n\n                    s->mb_intra= 0;\n\n                    s->mv[1][0][0] = s->b_back_mv_table[xy][0];\n\n                    s->mv[1][0][1] = s->b_back_mv_table[xy][1];\n\n                    encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_BACKWARD, pb, pb2, tex_pb,\n\n                                 &dmin, &next_block, s->mv[1][0][0], s->mv[1][0][1]);\n\n                }\n\n                if(mb_type&CANDIDATE_MB_TYPE_BIDIR){\n\n                    s->mv_dir = MV_DIR_FORWARD | MV_DIR_BACKWARD;\n\n                    s->mv_type = MV_TYPE_16X16;\n\n                    s->mb_intra= 0;\n\n                    s->mv[0][0][0] = s->b_bidir_forw_mv_table[xy][0];\n\n                    s->mv[0][0][1] = s->b_bidir_forw_mv_table[xy][1];\n\n                    s->mv[1][0][0] = s->b_bidir_back_mv_table[xy][0];\n\n                    s->mv[1][0][1] = s->b_bidir_back_mv_table[xy][1];\n\n                    encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_BIDIR, pb, pb2, tex_pb,\n\n                                 &dmin, &next_block, 0, 0);\n\n                }\n\n                if(mb_type&CANDIDATE_MB_TYPE_FORWARD_I){\n\n                    s->mv_dir = MV_DIR_FORWARD;\n\n                    s->mv_type = MV_TYPE_FIELD;\n\n                    s->mb_intra= 0;\n\n                    for(i=0; i<2; i++){\n\n                        j= s->field_select[0][i] = s->b_field_select_table[0][i][xy];\n\n                        s->mv[0][i][0] = s->b_field_mv_table[0][i][j][xy][0];\n\n                        s->mv[0][i][1] = s->b_field_mv_table[0][i][j][xy][1];\n\n                    }\n\n                    encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_FORWARD_I, pb, pb2, tex_pb,\n\n                                 &dmin, &next_block, 0, 0);\n\n                }\n\n                if(mb_type&CANDIDATE_MB_TYPE_BACKWARD_I){\n\n                    s->mv_dir = MV_DIR_BACKWARD;\n\n                    s->mv_type = MV_TYPE_FIELD;\n\n                    s->mb_intra= 0;\n\n                    for(i=0; i<2; i++){\n\n                        j= s->field_select[1][i] = s->b_field_select_table[1][i][xy];\n\n                        s->mv[1][i][0] = s->b_field_mv_table[1][i][j][xy][0];\n\n                        s->mv[1][i][1] = s->b_field_mv_table[1][i][j][xy][1];\n\n                    }\n\n                    encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_BACKWARD_I, pb, pb2, tex_pb,\n\n                                 &dmin, &next_block, 0, 0);\n\n                }\n\n                if(mb_type&CANDIDATE_MB_TYPE_BIDIR_I){\n\n                    s->mv_dir = MV_DIR_FORWARD | MV_DIR_BACKWARD;\n\n                    s->mv_type = MV_TYPE_FIELD;\n\n                    s->mb_intra= 0;\n\n                    for(dir=0; dir<2; dir++){\n\n                        for(i=0; i<2; i++){\n\n                            j= s->field_select[dir][i] = s->b_field_select_table[dir][i][xy];\n\n                            s->mv[dir][i][0] = s->b_field_mv_table[dir][i][j][xy][0];\n\n                            s->mv[dir][i][1] = s->b_field_mv_table[dir][i][j][xy][1];\n\n                        }\n\n                    }\n\n                    encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_BIDIR_I, pb, pb2, tex_pb,\n\n                                 &dmin, &next_block, 0, 0);\n\n                }\n\n                if(mb_type&CANDIDATE_MB_TYPE_INTRA){\n\n                    s->mv_dir = 0;\n\n                    s->mv_type = MV_TYPE_16X16;\n\n                    s->mb_intra= 1;\n\n                    s->mv[0][0][0] = 0;\n\n                    s->mv[0][0][1] = 0;\n\n                    encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_INTRA, pb, pb2, tex_pb,\n\n                                 &dmin, &next_block, 0, 0);\n\n                    if(s->h263_pred || s->h263_aic){\n\n                        if(best_s.mb_intra)\n\n                            s->mbintra_table[mb_x + mb_y*s->mb_stride]=1;\n\n                        else\n\n                            ff_clean_intra_table_entries(s); //old mode?\n\n                    }\n\n                }\n\n\n\n                if((s->flags & CODEC_FLAG_QP_RD) && dmin < INT_MAX){\n\n                    if(best_s.mv_type==MV_TYPE_16X16){ //FIXME move 4mv after QPRD\n\n                        const int last_qp= backup_s.qscale;\n\n                        int qpi, qp, dc[6];\n\n                        DCTELEM ac[6][16];\n\n                        const int mvdir= (best_s.mv_dir&MV_DIR_BACKWARD) ? 1 : 0;\n\n                        static const int dquant_tab[4]={-1,1,-2,2};\n\n\n\n                        assert(backup_s.dquant == 0);\n\n\n\n                        //FIXME intra\n\n                        s->mv_dir= best_s.mv_dir;\n\n                        s->mv_type = MV_TYPE_16X16;\n\n                        s->mb_intra= best_s.mb_intra;\n\n                        s->mv[0][0][0] = best_s.mv[0][0][0];\n\n                        s->mv[0][0][1] = best_s.mv[0][0][1];\n\n                        s->mv[1][0][0] = best_s.mv[1][0][0];\n\n                        s->mv[1][0][1] = best_s.mv[1][0][1];\n\n\n\n                        qpi = s->pict_type == FF_B_TYPE ? 2 : 0;\n\n                        for(; qpi<4; qpi++){\n\n                            int dquant= dquant_tab[qpi];\n\n                            qp= last_qp + dquant;\n\n                            if(qp < s->avctx->qmin || qp > s->avctx->qmax)\n\n                                continue;\n\n                            backup_s.dquant= dquant;\n\n                            if(s->mb_intra && s->dc_val[0]){\n\n                                for(i=0; i<6; i++){\n\n                                    dc[i]= s->dc_val[0][ s->block_index[i] ];\n\n                                    memcpy(ac[i], s->ac_val[0][s->block_index[i]], sizeof(DCTELEM)*16);\n\n                                }\n\n                            }\n\n\n\n                            encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_INTER /* wrong but unused */, pb, pb2, tex_pb,\n\n                                         &dmin, &next_block, s->mv[mvdir][0][0], s->mv[mvdir][0][1]);\n\n                            if(best_s.qscale != qp){\n\n                                if(s->mb_intra && s->dc_val[0]){\n\n                                    for(i=0; i<6; i++){\n\n                                        s->dc_val[0][ s->block_index[i] ]= dc[i];\n\n                                        memcpy(s->ac_val[0][s->block_index[i]], ac[i], sizeof(DCTELEM)*16);\n\n                                    }\n\n                                }\n\n                            }\n\n                        }\n\n                    }\n\n                }\n\n                if(CONFIG_MPEG4_ENCODER && mb_type&CANDIDATE_MB_TYPE_DIRECT){\n\n                    int mx= s->b_direct_mv_table[xy][0];\n\n                    int my= s->b_direct_mv_table[xy][1];\n\n\n\n                    backup_s.dquant = 0;\n\n                    s->mv_dir = MV_DIR_FORWARD | MV_DIR_BACKWARD | MV_DIRECT;\n\n                    s->mb_intra= 0;\n\n                    ff_mpeg4_set_direct_mv(s, mx, my);\n\n                    encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_DIRECT, pb, pb2, tex_pb,\n\n                                 &dmin, &next_block, mx, my);\n\n                }\n\n                if(CONFIG_MPEG4_ENCODER && mb_type&CANDIDATE_MB_TYPE_DIRECT0){\n\n                    backup_s.dquant = 0;\n\n                    s->mv_dir = MV_DIR_FORWARD | MV_DIR_BACKWARD | MV_DIRECT;\n\n                    s->mb_intra= 0;\n\n                    ff_mpeg4_set_direct_mv(s, 0, 0);\n\n                    encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_DIRECT, pb, pb2, tex_pb,\n\n                                 &dmin, &next_block, 0, 0);\n\n                }\n\n                if(!best_s.mb_intra && s->flags2&CODEC_FLAG2_SKIP_RD){\n\n                    int coded=0;\n\n                    for(i=0; i<6; i++)\n\n                        coded |= s->block_last_index[i];\n\n                    if(coded){\n\n                        int mx,my;\n\n                        memcpy(s->mv, best_s.mv, sizeof(s->mv));\n\n                        if(CONFIG_MPEG4_ENCODER && best_s.mv_dir & MV_DIRECT){\n\n                            mx=my=0; //FIXME find the one we actually used\n\n                            ff_mpeg4_set_direct_mv(s, mx, my);\n\n                        }else if(best_s.mv_dir&MV_DIR_BACKWARD){\n\n                            mx= s->mv[1][0][0];\n\n                            my= s->mv[1][0][1];\n\n                        }else{\n\n                            mx= s->mv[0][0][0];\n\n                            my= s->mv[0][0][1];\n\n                        }\n\n\n\n                        s->mv_dir= best_s.mv_dir;\n\n                        s->mv_type = best_s.mv_type;\n\n                        s->mb_intra= 0;\n\n/*                        s->mv[0][0][0] = best_s.mv[0][0][0];\n\n                        s->mv[0][0][1] = best_s.mv[0][0][1];\n\n                        s->mv[1][0][0] = best_s.mv[1][0][0];\n\n                        s->mv[1][0][1] = best_s.mv[1][0][1];*/\n\n                        backup_s.dquant= 0;\n\n                        s->skipdct=1;\n\n                        encode_mb_hq(s, &backup_s, &best_s, CANDIDATE_MB_TYPE_INTER /* wrong but unused */, pb, pb2, tex_pb,\n\n                                        &dmin, &next_block, mx, my);\n\n                        s->skipdct=0;\n\n                    }\n\n                }\n\n\n\n                s->current_picture.qscale_table[xy]= best_s.qscale;\n\n\n\n                copy_context_after_encode(s, &best_s, -1);\n\n\n\n                pb_bits_count= put_bits_count(&s->pb);\n\n                flush_put_bits(&s->pb);\n\n                ff_copy_bits(&backup_s.pb, bit_buf[next_block^1], pb_bits_count);\n\n                s->pb= backup_s.pb;\n\n\n\n                if(s->data_partitioning){\n\n                    pb2_bits_count= put_bits_count(&s->pb2);\n\n                    flush_put_bits(&s->pb2);\n\n                    ff_copy_bits(&backup_s.pb2, bit_buf2[next_block^1], pb2_bits_count);\n\n                    s->pb2= backup_s.pb2;\n\n\n\n                    tex_pb_bits_count= put_bits_count(&s->tex_pb);\n\n                    flush_put_bits(&s->tex_pb);\n\n                    ff_copy_bits(&backup_s.tex_pb, bit_buf_tex[next_block^1], tex_pb_bits_count);\n\n                    s->tex_pb= backup_s.tex_pb;\n\n                }\n\n                s->last_bits= put_bits_count(&s->pb);\n\n\n\n                if (CONFIG_ANY_H263_ENCODER &&\n\n                    s->out_format == FMT_H263 && s->pict_type!=FF_B_TYPE)\n\n                    ff_h263_update_motion_val(s);\n\n\n\n                if(next_block==0){ //FIXME 16 vs linesize16\n\n                    s->dsp.put_pixels_tab[0][0](s->dest[0], s->rd_scratchpad                     , s->linesize  ,16);\n\n                    s->dsp.put_pixels_tab[1][0](s->dest[1], s->rd_scratchpad + 16*s->linesize    , s->uvlinesize, 8);\n\n                    s->dsp.put_pixels_tab[1][0](s->dest[2], s->rd_scratchpad + 16*s->linesize + 8, s->uvlinesize, 8);\n\n                }\n\n\n\n                if(s->avctx->mb_decision == FF_MB_DECISION_BITS)\n\n                    MPV_decode_mb(s, s->block);\n\n            } else {\n\n                int motion_x = 0, motion_y = 0;\n\n                s->mv_type=MV_TYPE_16X16;\n\n                // only one MB-Type possible\n\n\n\n                switch(mb_type){\n\n                case CANDIDATE_MB_TYPE_INTRA:\n\n                    s->mv_dir = 0;\n\n                    s->mb_intra= 1;\n\n                    motion_x= s->mv[0][0][0] = 0;\n\n                    motion_y= s->mv[0][0][1] = 0;\n\n                    break;\n\n                case CANDIDATE_MB_TYPE_INTER:\n\n                    s->mv_dir = MV_DIR_FORWARD;\n\n                    s->mb_intra= 0;\n\n                    motion_x= s->mv[0][0][0] = s->p_mv_table[xy][0];\n\n                    motion_y= s->mv[0][0][1] = s->p_mv_table[xy][1];\n\n                    break;\n\n                case CANDIDATE_MB_TYPE_INTER_I:\n\n                    s->mv_dir = MV_DIR_FORWARD;\n\n                    s->mv_type = MV_TYPE_FIELD;\n\n                    s->mb_intra= 0;\n\n                    for(i=0; i<2; i++){\n\n                        j= s->field_select[0][i] = s->p_field_select_table[i][xy];\n\n                        s->mv[0][i][0] = s->p_field_mv_table[i][j][xy][0];\n\n                        s->mv[0][i][1] = s->p_field_mv_table[i][j][xy][1];\n\n                    }\n\n                    break;\n\n                case CANDIDATE_MB_TYPE_INTER4V:\n\n                    s->mv_dir = MV_DIR_FORWARD;\n\n                    s->mv_type = MV_TYPE_8X8;\n\n                    s->mb_intra= 0;\n\n                    for(i=0; i<4; i++){\n\n                        s->mv[0][i][0] = s->current_picture.motion_val[0][s->block_index[i]][0];\n\n                        s->mv[0][i][1] = s->current_picture.motion_val[0][s->block_index[i]][1];\n\n                    }\n\n                    break;\n\n                case CANDIDATE_MB_TYPE_DIRECT:\n\n                    if (CONFIG_MPEG4_ENCODER) {\n\n                        s->mv_dir = MV_DIR_FORWARD|MV_DIR_BACKWARD|MV_DIRECT;\n\n                        s->mb_intra= 0;\n\n                        motion_x=s->b_direct_mv_table[xy][0];\n\n                        motion_y=s->b_direct_mv_table[xy][1];\n\n                        ff_mpeg4_set_direct_mv(s, motion_x, motion_y);\n\n                    }\n\n                    break;\n\n                case CANDIDATE_MB_TYPE_DIRECT0:\n\n                    if (CONFIG_MPEG4_ENCODER) {\n\n                        s->mv_dir = MV_DIR_FORWARD|MV_DIR_BACKWARD|MV_DIRECT;\n\n                        s->mb_intra= 0;\n\n                        ff_mpeg4_set_direct_mv(s, 0, 0);\n\n                    }\n\n                    break;\n\n                case CANDIDATE_MB_TYPE_BIDIR:\n\n                    s->mv_dir = MV_DIR_FORWARD | MV_DIR_BACKWARD;\n\n                    s->mb_intra= 0;\n\n                    s->mv[0][0][0] = s->b_bidir_forw_mv_table[xy][0];\n\n                    s->mv[0][0][1] = s->b_bidir_forw_mv_table[xy][1];\n\n                    s->mv[1][0][0] = s->b_bidir_back_mv_table[xy][0];\n\n                    s->mv[1][0][1] = s->b_bidir_back_mv_table[xy][1];\n\n                    break;\n\n                case CANDIDATE_MB_TYPE_BACKWARD:\n\n                    s->mv_dir = MV_DIR_BACKWARD;\n\n                    s->mb_intra= 0;\n\n                    motion_x= s->mv[1][0][0] = s->b_back_mv_table[xy][0];\n\n                    motion_y= s->mv[1][0][1] = s->b_back_mv_table[xy][1];\n\n                    break;\n\n                case CANDIDATE_MB_TYPE_FORWARD:\n\n                    s->mv_dir = MV_DIR_FORWARD;\n\n                    s->mb_intra= 0;\n\n                    motion_x= s->mv[0][0][0] = s->b_forw_mv_table[xy][0];\n\n                    motion_y= s->mv[0][0][1] = s->b_forw_mv_table[xy][1];\n\n//                    printf(\" %d %d \", motion_x, motion_y);\n\n                    break;\n\n                case CANDIDATE_MB_TYPE_FORWARD_I:\n\n                    s->mv_dir = MV_DIR_FORWARD;\n\n                    s->mv_type = MV_TYPE_FIELD;\n\n                    s->mb_intra= 0;\n\n                    for(i=0; i<2; i++){\n\n                        j= s->field_select[0][i] = s->b_field_select_table[0][i][xy];\n\n                        s->mv[0][i][0] = s->b_field_mv_table[0][i][j][xy][0];\n\n                        s->mv[0][i][1] = s->b_field_mv_table[0][i][j][xy][1];\n\n                    }\n\n                    break;\n\n                case CANDIDATE_MB_TYPE_BACKWARD_I:\n\n                    s->mv_dir = MV_DIR_BACKWARD;\n\n                    s->mv_type = MV_TYPE_FIELD;\n\n                    s->mb_intra= 0;\n\n                    for(i=0; i<2; i++){\n\n                        j= s->field_select[1][i] = s->b_field_select_table[1][i][xy];\n\n                        s->mv[1][i][0] = s->b_field_mv_table[1][i][j][xy][0];\n\n                        s->mv[1][i][1] = s->b_field_mv_table[1][i][j][xy][1];\n\n                    }\n\n                    break;\n\n                case CANDIDATE_MB_TYPE_BIDIR_I:\n\n                    s->mv_dir = MV_DIR_FORWARD | MV_DIR_BACKWARD;\n\n                    s->mv_type = MV_TYPE_FIELD;\n\n                    s->mb_intra= 0;\n\n                    for(dir=0; dir<2; dir++){\n\n                        for(i=0; i<2; i++){\n\n                            j= s->field_select[dir][i] = s->b_field_select_table[dir][i][xy];\n\n                            s->mv[dir][i][0] = s->b_field_mv_table[dir][i][j][xy][0];\n\n                            s->mv[dir][i][1] = s->b_field_mv_table[dir][i][j][xy][1];\n\n                        }\n\n                    }\n\n                    break;\n\n                default:\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"illegal MB type\\n\");\n\n                }\n\n\n\n                encode_mb(s, motion_x, motion_y);\n\n\n\n                // RAL: Update last macroblock type\n\n                s->last_mv_dir = s->mv_dir;\n\n\n\n                if (CONFIG_ANY_H263_ENCODER &&\n\n                    s->out_format == FMT_H263 && s->pict_type!=FF_B_TYPE)\n\n                    ff_h263_update_motion_val(s);\n\n\n\n                MPV_decode_mb(s, s->block);\n\n            }\n\n\n\n            /* clean the MV table in IPS frames for direct mode in B frames */\n\n            if(s->mb_intra /* && I,P,S_TYPE */){\n\n                s->p_mv_table[xy][0]=0;\n\n                s->p_mv_table[xy][1]=0;\n\n            }\n\n\n\n            if(s->flags&CODEC_FLAG_PSNR){\n\n                int w= 16;\n\n                int h= 16;\n\n\n\n                if(s->mb_x*16 + 16 > s->width ) w= s->width - s->mb_x*16;\n\n                if(s->mb_y*16 + 16 > s->height) h= s->height- s->mb_y*16;\n\n\n\n                s->current_picture.error[0] += sse(\n\n                    s, s->new_picture.data[0] + s->mb_x*16 + s->mb_y*s->linesize*16,\n\n                    s->dest[0], w, h, s->linesize);\n\n                s->current_picture.error[1] += sse(\n\n                    s, s->new_picture.data[1] + s->mb_x*8  + s->mb_y*s->uvlinesize*chr_h,\n\n                    s->dest[1], w>>1, h>>s->chroma_y_shift, s->uvlinesize);\n\n                s->current_picture.error[2] += sse(\n\n                    s, s->new_picture.data[2] + s->mb_x*8  + s->mb_y*s->uvlinesize*chr_h,\n\n                    s->dest[2], w>>1, h>>s->chroma_y_shift, s->uvlinesize);\n\n            }\n\n            if(s->loop_filter){\n\n                if(CONFIG_ANY_H263_ENCODER && s->out_format == FMT_H263)\n\n                    ff_h263_loop_filter(s);\n\n            }\n\n//printf(\"MB %d %d bits\\n\", s->mb_x+s->mb_y*s->mb_stride, put_bits_count(&s->pb));\n\n        }\n\n    }\n\n\n\n    //not beautiful here but we must write it before flushing so it has to be here\n\n    if (CONFIG_MSMPEG4_ENCODER && s->msmpeg4_version && s->msmpeg4_version<4 && s->pict_type == FF_I_TYPE)\n\n        msmpeg4_encode_ext_header(s);\n\n\n\n    write_slice_end(s);\n\n\n\n    /* Send the last GOB if RTP */\n\n    if (s->avctx->rtp_callback) {\n\n        int number_mb = (mb_y - s->resync_mb_y)*s->mb_width - s->resync_mb_x;\n\n        pdif = put_bits_ptr(&s->pb) - s->ptr_lastgob;\n\n        /* Call the RTP callback to send the last GOB */\n\n        emms_c();\n\n        s->avctx->rtp_callback(s->avctx, s->ptr_lastgob, pdif, number_mb);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 27122}
{"project": "FFmpeg", "commit_id": "a9eb4f0899de04a3093a04f461611c6f0664398e", "target": 0, "func": "static void new_audio_stream(AVFormatContext *oc, int file_idx)\n\n{\n\n    AVStream *st;\n\n    OutputStream *ost;\n\n    AVCodec *codec= NULL;\n\n    AVCodecContext *audio_enc;\n\n    enum CodecID codec_id = CODEC_ID_NONE;\n\n\n\n    if(!audio_stream_copy){\n\n        if (audio_codec_name) {\n\n            codec_id = find_codec_or_die(audio_codec_name, AVMEDIA_TYPE_AUDIO, 1,\n\n                                         avcodec_opts[AVMEDIA_TYPE_AUDIO]->strict_std_compliance);\n\n            codec = avcodec_find_encoder_by_name(audio_codec_name);\n\n        } else {\n\n            codec_id = av_guess_codec(oc->oformat, NULL, oc->filename, NULL, AVMEDIA_TYPE_AUDIO);\n\n            codec = avcodec_find_encoder(codec_id);\n\n        }\n\n    }\n\n    ost = new_output_stream(oc, file_idx, codec);\n\n    st  = ost->st;\n\n\n\n    ost->bitstream_filters = audio_bitstream_filters;\n\n    audio_bitstream_filters= NULL;\n\n\n\n    st->codec->thread_count= thread_count;\n\n\n\n    audio_enc = st->codec;\n\n    audio_enc->codec_type = AVMEDIA_TYPE_AUDIO;\n\n\n\n    if(audio_codec_tag)\n\n        audio_enc->codec_tag= audio_codec_tag;\n\n\n\n    if (oc->oformat->flags & AVFMT_GLOBALHEADER) {\n\n        audio_enc->flags |= CODEC_FLAG_GLOBAL_HEADER;\n\n    }\n\n    if (audio_stream_copy) {\n\n        st->stream_copy = 1;\n\n    } else {\n\n        audio_enc->codec_id = codec_id;\n\n        set_context_opts(audio_enc, avcodec_opts[AVMEDIA_TYPE_AUDIO], AV_OPT_FLAG_AUDIO_PARAM | AV_OPT_FLAG_ENCODING_PARAM, codec);\n\n\n\n        if (audio_qscale > QSCALE_NONE) {\n\n            audio_enc->flags |= CODEC_FLAG_QSCALE;\n\n            audio_enc->global_quality = FF_QP2LAMBDA * audio_qscale;\n\n        }\n\n        if (audio_channels)\n\n            audio_enc->channels = audio_channels;\n\n        if (audio_sample_fmt != AV_SAMPLE_FMT_NONE)\n\n            audio_enc->sample_fmt = audio_sample_fmt;\n\n        if (audio_sample_rate)\n\n            audio_enc->sample_rate = audio_sample_rate;\n\n    }\n\n    if (audio_language) {\n\n        av_dict_set(&st->metadata, \"language\", audio_language, 0);\n\n        av_freep(&audio_language);\n\n    }\n\n\n\n    /* reset some key parameters */\n\n    audio_disable = 0;\n\n    av_freep(&audio_codec_name);\n\n    audio_stream_copy = 0;\n\n}\n", "idx": 27123}
{"project": "FFmpeg", "commit_id": "4bff9ef9d0781c4de228bf1f85634d2706fc589b", "target": 0, "func": "inline static void RENAME(hcscale)(uint16_t *dst, long dstWidth, uint8_t *src1, uint8_t *src2,\n\n\t\t\t\t   int srcW, int xInc, int flags, int canMMX2BeUsed, int16_t *hChrFilter,\n\n\t\t\t\t   int16_t *hChrFilterPos, int hChrFilterSize, void *funnyUVCode,\n\n\t\t\t\t   int srcFormat, uint8_t *formatConvBuffer, int16_t *mmx2Filter,\n\n\t\t\t\t   int32_t *mmx2FilterPos)\n\n{\n\n    if(srcFormat==IMGFMT_YUY2)\n\n    {\n\n\tRENAME(yuy2ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_UYVY)\n\n    {\n\n\tRENAME(uyvyToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_BGR32)\n\n    {\n\n\tRENAME(bgr32ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_BGR24)\n\n    {\n\n\tRENAME(bgr24ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_BGR16)\n\n    {\n\n\tRENAME(bgr16ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_BGR15)\n\n    {\n\n\tRENAME(bgr15ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_RGB32)\n\n    {\n\n\tRENAME(rgb32ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_RGB24)\n\n    {\n\n\tRENAME(rgb24ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(isGray(srcFormat))\n\n    {\n\n    \treturn;\n\n    }\n\n\n\n#ifdef HAVE_MMX\n\n\t// use the new MMX scaler if the mmx2 can't be used (its faster than the x86asm one)\n\n    if(!(flags&SWS_FAST_BILINEAR) || (!canMMX2BeUsed))\n\n#else\n\n    if(!(flags&SWS_FAST_BILINEAR))\n\n#endif\n\n    {\n\n    \tRENAME(hScale)(dst     , dstWidth, src1, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n    \tRENAME(hScale)(dst+2048, dstWidth, src2, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n    }\n\n    else // Fast Bilinear upscale / crap downscale\n\n    {\n\n#if defined(ARCH_X86) || defined(ARCH_X86_64)\n\n#ifdef HAVE_MMX2\n\n\tint i;\n\n\tif(canMMX2BeUsed)\n\n\t{\n\n\t\tasm volatile(\n\n\t\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"mov %0, %%\"REG_c\"\t\t\\n\\t\"\n\n\t\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\t\"mov %2, %%\"REG_d\"\t\t\\n\\t\"\n\n\t\t\t\"mov %3, %%\"REG_b\"\t\t\\n\\t\"\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\" // i\n\n\t\t\tPREFETCH\" (%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%%\"REG_c\")\t\t\\n\\t\"\n\n\n\n#ifdef ARCH_X86_64\n\n\n\n#define FUNNY_UV_CODE \\\n\n\t\t\t\"movl (%%\"REG_b\"), %%esi\t\\n\\t\"\\\n\n\t\t\t\"call *%4\t\t\t\\n\\t\"\\\n\n\t\t\t\"movl (%%\"REG_b\", %%\"REG_a\"), %%esi\\n\\t\"\\\n\n\t\t\t\"add %%\"REG_S\", %%\"REG_c\"\t\\n\\t\"\\\n\n\t\t\t\"add %%\"REG_a\", %%\"REG_D\"\t\\n\\t\"\\\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\"\\\n\n\n\n#else\n\n\n\n#define FUNNY_UV_CODE \\\n\n\t\t\t\"movl (%%\"REG_b\"), %%esi\t\\n\\t\"\\\n\n\t\t\t\"call *%4\t\t\t\\n\\t\"\\\n\n\t\t\t\"addl (%%\"REG_b\", %%\"REG_a\"), %%\"REG_c\"\\n\\t\"\\\n\n\t\t\t\"add %%\"REG_a\", %%\"REG_D\"\t\\n\\t\"\\\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\"\\\n\n\n\n#endif\n\n\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\" // i\n\n\t\t\t\"mov %5, %%\"REG_c\"\t\t\\n\\t\" // src\n\n\t\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\" // buf1\n\n\t\t\t\"add $4096, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" (%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%%\"REG_c\")\t\t\\n\\t\"\n\n\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\n\n\n\t\t\t:: \"m\" (src1), \"m\" (dst), \"m\" (mmx2Filter), \"m\" (mmx2FilterPos),\n\n\t\t\t\"m\" (funnyUVCode), \"m\" (src2)\n\n\t\t\t: \"%\"REG_a, \"%\"REG_b, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S, \"%\"REG_D\n\n\t\t);\n\n\t\tfor(i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--)\n\n\t\t{\n\n//\t\t\tprintf(\"%d %d %d\\n\", dstWidth, i, srcW);\n\n\t\t\tdst[i] = src1[srcW-1]*128;\n\n\t\t\tdst[i+2048] = src2[srcW-1]*128;\n\n\t\t}\n\n\t}\n\n\telse\n\n\t{\n\n#endif\n\n\tlong xInc_shr16 = (long) (xInc >> 16);\n\n\tuint16_t xInc_mask = xInc & 0xffff; \n\n\tasm volatile(\n\n\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\" // i\n\n\t\t\"xor %%\"REG_b\", %%\"REG_b\"\t\t\\n\\t\" // xx\n\n\t\t\"xorl %%ecx, %%ecx\t\t\\n\\t\" // 2*xalpha\n\n\t\tASMALIGN16\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\"mov %0, %%\"REG_S\"\t\t\\n\\t\"\n\n\t\t\"movzbl  (%%\"REG_S\", %%\"REG_b\"), %%edi\t\\n\\t\" //src[xx]\n\n\t\t\"movzbl 1(%%\"REG_S\", %%\"REG_b\"), %%esi\t\\n\\t\" //src[xx+1]\n\n\t\t\"subl %%edi, %%esi\t\t\\n\\t\" //src[xx+1] - src[xx]\n\n\t\t\"imull %%ecx, %%esi\t\t\\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n\t\t\"shll $16, %%edi\t\t\\n\\t\"\n\n\t\t\"addl %%edi, %%esi\t\t\\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\"shrl $9, %%esi\t\t\t\\n\\t\"\n\n\t\t\"movw %%si, (%%\"REG_D\", %%\"REG_a\", 2)\\n\\t\"\n\n\n\n\t\t\"movzbl  (%5, %%\"REG_b\"), %%edi\t\\n\\t\" //src[xx]\n\n\t\t\"movzbl 1(%5, %%\"REG_b\"), %%esi\t\\n\\t\" //src[xx+1]\n\n\t\t\"subl %%edi, %%esi\t\t\\n\\t\" //src[xx+1] - src[xx]\n\n\t\t\"imull %%ecx, %%esi\t\t\\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n\t\t\"shll $16, %%edi\t\t\\n\\t\"\n\n\t\t\"addl %%edi, %%esi\t\t\\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\"shrl $9, %%esi\t\t\t\\n\\t\"\n\n\t\t\"movw %%si, 4096(%%\"REG_D\", %%\"REG_a\", 2)\\n\\t\"\n\n\n\n\t\t\"addw %4, %%cx\t\t\t\\n\\t\" //2*xalpha += xInc&0xFF\n\n\t\t\"adc %3, %%\"REG_b\"\t\t\\n\\t\" //xx+= xInc>>8 + carry\n\n\t\t\"add $1, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\"cmp %2, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\n\n/* GCC-3.3 makes MPlayer crash on IA-32 machines when using \"g\" operand here,\n\n   which is needed to support GCC-4.0 */\n\n#if defined(ARCH_X86_64) && ((__GNUC__ > 3) || ( __GNUC__ == 3 && __GNUC_MINOR__ >= 4))\n\n\t\t:: \"m\" (src1), \"m\" (dst), \"g\" ((long)dstWidth), \"m\" (xInc_shr16), \"m\" (xInc_mask),\n\n#else\n\n\t\t:: \"m\" (src1), \"m\" (dst), \"m\" ((long)dstWidth), \"m\" (xInc_shr16), \"m\" (xInc_mask),\n\n#endif\n\n\t\t\"r\" (src2)\n\n\t\t: \"%\"REG_a, \"%\"REG_b, \"%ecx\", \"%\"REG_D, \"%esi\"\n\n\t\t);\n\n#ifdef HAVE_MMX2\n\n\t} //if MMX2 can't be used\n\n#endif\n\n#else\n\n\tint i;\n\n\tunsigned int xpos=0;\n\n\tfor(i=0;i<dstWidth;i++)\n\n\t{\n\n\t\tregister unsigned int xx=xpos>>16;\n\n\t\tregister unsigned int xalpha=(xpos&0xFFFF)>>9;\n\n\t\tdst[i]=(src1[xx]*(xalpha^127)+src1[xx+1]*xalpha);\n\n\t\tdst[i+2048]=(src2[xx]*(xalpha^127)+src2[xx+1]*xalpha);\n\n/* slower\n\n\t  dst[i]= (src1[xx]<<7) + (src1[xx+1] - src1[xx])*xalpha;\n\n\t  dst[i+2048]=(src2[xx]<<7) + (src2[xx+1] - src2[xx])*xalpha;\n\n*/\n\n\t\txpos+=xInc;\n\n\t}\n\n#endif\n\n   }\n\n}\n", "idx": 27131}
{"project": "FFmpeg", "commit_id": "015da965a68bdb48819dc98317888fc84eced599", "target": 1, "func": "int attribute_align_arg avcodec_decode_audio3(AVCodecContext *avctx, int16_t *samples,\n\n                                              int *frame_size_ptr,\n\n                                              AVPacket *avpkt)\n\n{\n\n    AVFrame frame = {0};\n\n    int ret, got_frame = 0;\n\n\n\n    if (avctx->get_buffer != avcodec_default_get_buffer) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Custom get_buffer() for use with\"\n\n                                    \"avcodec_decode_audio3() detected. Overriding with avcodec_default_get_buffer\\n\");\n\n        av_log(avctx, AV_LOG_ERROR, \"Please port your application to \"\n\n                                    \"avcodec_decode_audio4()\\n\");\n\n        avctx->get_buffer = avcodec_default_get_buffer;\n\n    }\n\n\n\n    ret = avcodec_decode_audio4(avctx, &frame, &got_frame, avpkt);\n\n\n\n    if (ret >= 0 && got_frame) {\n\n        int ch, plane_size;\n\n        int planar    = av_sample_fmt_is_planar(avctx->sample_fmt);\n\n        int data_size = av_samples_get_buffer_size(&plane_size, avctx->channels,\n\n                                                   frame.nb_samples,\n\n                                                   avctx->sample_fmt, 1);\n\n        if (*frame_size_ptr < data_size) {\n\n            av_log(avctx, AV_LOG_ERROR, \"output buffer size is too small for \"\n\n                                        \"the current frame (%d < %d)\\n\", *frame_size_ptr, data_size);\n\n            return AVERROR(EINVAL);\n\n        }\n\n\n\n        memcpy(samples, frame.extended_data[0], plane_size);\n\n\n\n        if (planar && avctx->channels > 1) {\n\n            uint8_t *out = ((uint8_t *)samples) + plane_size;\n\n            for (ch = 1; ch < avctx->channels; ch++) {\n\n                memcpy(out, frame.extended_data[ch], plane_size);\n\n                out += plane_size;\n\n            }\n\n        }\n\n        *frame_size_ptr = data_size;\n\n    } else {\n\n        *frame_size_ptr = 0;\n\n    }\n\n    return ret;\n\n}\n", "idx": 27132}
{"project": "FFmpeg", "commit_id": "3cfa310c5de526dbc40d7b33eb6234cff29d8f8c", "target": 1, "func": "static int ape_read_header(AVFormatContext * s)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    APEContext *ape = s->priv_data;\n\n    AVStream *st;\n\n    uint32_t tag;\n\n    int i;\n\n    int total_blocks, final_size = 0;\n\n    int64_t pts, file_size;\n\n\n\n    /* Skip any leading junk such as id3v2 tags */\n\n    ape->junklength = avio_tell(pb);\n\n\n\n    tag = avio_rl32(pb);\n\n    if (tag != MKTAG('M', 'A', 'C', ' '))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    ape->fileversion = avio_rl16(pb);\n\n\n\n    if (ape->fileversion < APE_MIN_VERSION || ape->fileversion > APE_MAX_VERSION) {\n\n        av_log(s, AV_LOG_ERROR, \"Unsupported file version - %d.%02d\\n\",\n\n               ape->fileversion / 1000, (ape->fileversion % 1000) / 10);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if (ape->fileversion >= 3980) {\n\n        ape->padding1             = avio_rl16(pb);\n\n        ape->descriptorlength     = avio_rl32(pb);\n\n        ape->headerlength         = avio_rl32(pb);\n\n        ape->seektablelength      = avio_rl32(pb);\n\n        ape->wavheaderlength      = avio_rl32(pb);\n\n        ape->audiodatalength      = avio_rl32(pb);\n\n        ape->audiodatalength_high = avio_rl32(pb);\n\n        ape->wavtaillength        = avio_rl32(pb);\n\n        avio_read(pb, ape->md5, 16);\n\n\n\n        /* Skip any unknown bytes at the end of the descriptor.\n\n           This is for future compatibility */\n\n        if (ape->descriptorlength > 52)\n\n            avio_skip(pb, ape->descriptorlength - 52);\n\n\n\n        /* Read header data */\n\n        ape->compressiontype      = avio_rl16(pb);\n\n        ape->formatflags          = avio_rl16(pb);\n\n        ape->blocksperframe       = avio_rl32(pb);\n\n        ape->finalframeblocks     = avio_rl32(pb);\n\n        ape->totalframes          = avio_rl32(pb);\n\n        ape->bps                  = avio_rl16(pb);\n\n        ape->channels             = avio_rl16(pb);\n\n        ape->samplerate           = avio_rl32(pb);\n\n    } else {\n\n        ape->descriptorlength = 0;\n\n        ape->headerlength = 32;\n\n\n\n        ape->compressiontype      = avio_rl16(pb);\n\n        ape->formatflags          = avio_rl16(pb);\n\n        ape->channels             = avio_rl16(pb);\n\n        ape->samplerate           = avio_rl32(pb);\n\n        ape->wavheaderlength      = avio_rl32(pb);\n\n        ape->wavtaillength        = avio_rl32(pb);\n\n        ape->totalframes          = avio_rl32(pb);\n\n        ape->finalframeblocks     = avio_rl32(pb);\n\n\n\n        if (ape->formatflags & MAC_FORMAT_FLAG_HAS_PEAK_LEVEL) {\n\n            avio_skip(pb, 4); /* Skip the peak level */\n\n            ape->headerlength += 4;\n\n        }\n\n\n\n        if (ape->formatflags & MAC_FORMAT_FLAG_HAS_SEEK_ELEMENTS) {\n\n            ape->seektablelength = avio_rl32(pb);\n\n            ape->headerlength += 4;\n\n            ape->seektablelength *= sizeof(int32_t);\n\n        } else\n\n            ape->seektablelength = ape->totalframes * sizeof(int32_t);\n\n\n\n        if (ape->formatflags & MAC_FORMAT_FLAG_8_BIT)\n\n            ape->bps = 8;\n\n        else if (ape->formatflags & MAC_FORMAT_FLAG_24_BIT)\n\n            ape->bps = 24;\n\n        else\n\n            ape->bps = 16;\n\n\n\n        if (ape->fileversion >= 3950)\n\n            ape->blocksperframe = 73728 * 4;\n\n        else if (ape->fileversion >= 3900 || (ape->fileversion >= 3800  && ape->compressiontype >= 4000))\n\n            ape->blocksperframe = 73728;\n\n        else\n\n            ape->blocksperframe = 9216;\n\n\n\n        /* Skip any stored wav header */\n\n        if (!(ape->formatflags & MAC_FORMAT_FLAG_CREATE_WAV_HEADER))\n\n            avio_skip(pb, ape->wavheaderlength);\n\n    }\n\n\n\n    if(!ape->totalframes){\n\n        av_log(s, AV_LOG_ERROR, \"No frames in the file!\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    if(ape->totalframes > UINT_MAX / sizeof(APEFrame)){\n\n        av_log(s, AV_LOG_ERROR, \"Too many frames: %\"PRIu32\"\\n\",\n\n               ape->totalframes);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (ape->seektablelength / sizeof(*ape->seektable) < ape->totalframes) {\n\n        av_log(s, AV_LOG_ERROR,\n\n               \"Number of seek entries is less than number of frames: %zu vs. %\"PRIu32\"\\n\",\n\n               ape->seektablelength / sizeof(*ape->seektable), ape->totalframes);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    ape->frames       = av_malloc(ape->totalframes * sizeof(APEFrame));\n\n    if(!ape->frames)\n\n        return AVERROR(ENOMEM);\n\n    ape->firstframe   = ape->junklength + ape->descriptorlength + ape->headerlength + ape->seektablelength + ape->wavheaderlength;\n\n    if (ape->fileversion < 3810)\n\n        ape->firstframe += ape->totalframes;\n\n    ape->currentframe = 0;\n\n\n\n\n\n    ape->totalsamples = ape->finalframeblocks;\n\n    if (ape->totalframes > 1)\n\n        ape->totalsamples += ape->blocksperframe * (ape->totalframes - 1);\n\n\n\n    if (ape->seektablelength > 0) {\n\n        ape->seektable = av_malloc(ape->seektablelength);\n\n        if (!ape->seektable)\n\n            return AVERROR(ENOMEM);\n\n        for (i = 0; i < ape->seektablelength / sizeof(uint32_t) && !pb->eof_reached; i++)\n\n            ape->seektable[i] = avio_rl32(pb);\n\n        if (ape->fileversion < 3810) {\n\n            ape->bittable = av_malloc(ape->totalframes);\n\n            if (!ape->bittable)\n\n                return AVERROR(ENOMEM);\n\n            for (i = 0; i < ape->totalframes && !pb->eof_reached; i++)\n\n                ape->bittable[i] = avio_r8(pb);\n\n        }\n\n    }\n\n\n\n    ape->frames[0].pos     = ape->firstframe;\n\n    ape->frames[0].nblocks = ape->blocksperframe;\n\n    ape->frames[0].skip    = 0;\n\n    for (i = 1; i < ape->totalframes; i++) {\n\n        ape->frames[i].pos      = ape->seektable[i] + ape->junklength;\n\n        ape->frames[i].nblocks  = ape->blocksperframe;\n\n        ape->frames[i - 1].size = ape->frames[i].pos - ape->frames[i - 1].pos;\n\n        ape->frames[i].skip     = (ape->frames[i].pos - ape->frames[0].pos) & 3;\n\n    }\n\n    ape->frames[ape->totalframes - 1].nblocks = ape->finalframeblocks;\n\n    /* calculate final packet size from total file size, if available */\n\n    file_size = avio_size(pb);\n\n    if (file_size > 0) {\n\n        final_size = file_size - ape->frames[ape->totalframes - 1].pos -\n\n                     ape->wavtaillength;\n\n        final_size -= final_size & 3;\n\n    }\n\n    if (file_size <= 0 || final_size <= 0)\n\n        final_size = ape->finalframeblocks * 8;\n\n    ape->frames[ape->totalframes - 1].size = final_size;\n\n\n\n    for (i = 0; i < ape->totalframes; i++) {\n\n        if(ape->frames[i].skip){\n\n            ape->frames[i].pos  -= ape->frames[i].skip;\n\n            ape->frames[i].size += ape->frames[i].skip;\n\n        }\n\n        ape->frames[i].size = (ape->frames[i].size + 3) & ~3;\n\n    }\n\n    if (ape->fileversion < 3810) {\n\n        for (i = 0; i < ape->totalframes; i++) {\n\n            if (i < ape->totalframes - 1 && ape->bittable[i + 1])\n\n                ape->frames[i].size += 4;\n\n            ape->frames[i].skip <<= 3;\n\n            ape->frames[i].skip  += ape->bittable[i];\n\n        }\n\n    }\n\n\n\n    ape_dumpinfo(s, ape);\n\n\n\n    av_log(s, AV_LOG_DEBUG, \"Decoding file - v%d.%02d, compression level %\"PRIu16\"\\n\",\n\n           ape->fileversion / 1000, (ape->fileversion % 1000) / 10,\n\n           ape->compressiontype);\n\n\n\n    /* now we are ready: build format streams */\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    total_blocks = (ape->totalframes == 0) ? 0 : ((ape->totalframes - 1) * ape->blocksperframe) + ape->finalframeblocks;\n\n\n\n    st->codec->codec_type      = AVMEDIA_TYPE_AUDIO;\n\n    st->codec->codec_id        = AV_CODEC_ID_APE;\n\n    st->codec->codec_tag       = MKTAG('A', 'P', 'E', ' ');\n\n    st->codec->channels        = ape->channels;\n\n    st->codec->sample_rate     = ape->samplerate;\n\n    st->codec->bits_per_coded_sample = ape->bps;\n\n\n\n    st->nb_frames = ape->totalframes;\n\n    st->start_time = 0;\n\n    st->duration  = total_blocks;\n\n    avpriv_set_pts_info(st, 64, 1, ape->samplerate);\n\n\n\n    if (ff_alloc_extradata(st->codec, APE_EXTRADATA_SIZE))\n\n        return AVERROR(ENOMEM);\n\n    AV_WL16(st->codec->extradata + 0, ape->fileversion);\n\n    AV_WL16(st->codec->extradata + 2, ape->compressiontype);\n\n    AV_WL16(st->codec->extradata + 4, ape->formatflags);\n\n\n\n    pts = 0;\n\n    for (i = 0; i < ape->totalframes; i++) {\n\n        ape->frames[i].pts = pts;\n\n        av_add_index_entry(st, ape->frames[i].pos, ape->frames[i].pts, 0, 0, AVINDEX_KEYFRAME);\n\n        pts += ape->blocksperframe;\n\n    }\n\n\n\n    /* try to read APE tags */\n\n    if (pb->seekable) {\n\n        ff_ape_parse_tag(s);\n\n        avio_seek(pb, 0, SEEK_SET);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 27133}
{"project": "FFmpeg", "commit_id": "64ecb78b7179cab2dbdf835463104679dbb7c895", "target": 1, "func": "int ff_vdpau_common_init(AVCodecContext *avctx, VdpDecoderProfile profile,\n\n                         int level)\n\n{\n\n    VDPAUHWContext *hwctx = avctx->hwaccel_context;\n\n    VDPAUContext *vdctx = avctx->internal->hwaccel_priv_data;\n\n    VdpVideoSurfaceQueryCapabilities *surface_query_caps;\n\n    VdpDecoderQueryCapabilities *decoder_query_caps;\n\n    VdpDecoderCreate *create;\n\n\n\n    void *func;\n\n    VdpStatus status;\n\n    VdpBool supported;\n\n    uint32_t max_level, max_mb, max_width, max_height;\n\n    VdpChromaType type;\n\n    uint32_t width;\n\n    uint32_t height;\n\n\n\n    vdctx->width            = UINT32_MAX;\n\n    vdctx->height           = UINT32_MAX;\n\n\n\n    if (av_vdpau_get_surface_parameters(avctx, &type, &width, &height))\n\n        return AVERROR(ENOSYS);\n\n\n\n    if (hwctx) {\n\n        hwctx->reset            = 0;\n\n\n\n        if (hwctx->context.decoder != VDP_INVALID_HANDLE) {\n\n            vdctx->decoder = hwctx->context.decoder;\n\n            vdctx->render  = hwctx->context.render;\n\n            vdctx->device  = VDP_INVALID_HANDLE;\n\n            return 0; /* Decoder created by user */\n\n        }\n\n\n\n        vdctx->device           = hwctx->device;\n\n        vdctx->get_proc_address = hwctx->get_proc_address;\n\n\n\n        if (hwctx->flags & AV_HWACCEL_FLAG_IGNORE_LEVEL)\n\n            level = 0;\n\n\n\n        if (!(hwctx->flags & AV_HWACCEL_FLAG_ALLOW_HIGH_DEPTH) &&\n\n            type != VDP_CHROMA_TYPE_420)\n\n            return AVERROR(ENOSYS);\n\n    } else {\n\n        AVHWFramesContext *frames_ctx = NULL;\n\n        AVVDPAUDeviceContext *dev_ctx;\n\n\n\n        // We assume the hw_frames_ctx always survives until ff_vdpau_common_uninit\n\n        // is called. This holds true as the user is not allowed to touch\n\n        // hw_device_ctx, or hw_frames_ctx after get_format (and ff_get_format\n\n        // itself also uninits before unreffing hw_frames_ctx).\n\n        if (avctx->hw_frames_ctx) {\n\n            frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n\n        } else if (avctx->hw_device_ctx) {\n\n            int ret;\n\n\n\n            avctx->hw_frames_ctx = av_hwframe_ctx_alloc(avctx->hw_device_ctx);\n\n            if (!avctx->hw_frames_ctx)\n\n                return AVERROR(ENOMEM);\n\n\n\n            frames_ctx            = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n\n            frames_ctx->format    = AV_PIX_FMT_VDPAU;\n\n            frames_ctx->sw_format = avctx->sw_pix_fmt;\n\n            frames_ctx->width     = avctx->coded_width;\n\n            frames_ctx->height    = avctx->coded_height;\n\n\n\n            ret = av_hwframe_ctx_init(avctx->hw_frames_ctx);\n\n            if (ret < 0) {\n\n                av_buffer_unref(&avctx->hw_frames_ctx);\n\n                return ret;\n\n            }\n\n        }\n\n\n\n        if (!frames_ctx) {\n\n            av_log(avctx, AV_LOG_ERROR, \"A hardware frames context is \"\n\n                   \"required for VDPAU decoding.\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n\n\n        dev_ctx = frames_ctx->device_ctx->hwctx;\n\n\n\n        vdctx->device           = dev_ctx->device;\n\n        vdctx->get_proc_address = dev_ctx->get_proc_address;\n\n\n\n        if (avctx->hwaccel_flags & AV_HWACCEL_FLAG_IGNORE_LEVEL)\n\n            level = 0;\n\n    }\n\n\n\n    if (level < 0)\n\n        return AVERROR(ENOTSUP);\n\n\n\n    status = vdctx->get_proc_address(vdctx->device,\n\n                                     VDP_FUNC_ID_GET_INFORMATION_STRING,\n\n                                     &func);\n\n    if (status != VDP_STATUS_OK)\n\n        return vdpau_error(status);\n\n    else\n\n        info = func;\n\n\n\n    status = info(&info_string);\n\n    if (status != VDP_STATUS_OK)\n\n        return vdpau_error(status);\n\n    if (avctx->codec_id == AV_CODEC_ID_HEVC && strncmp(info_string, \"NVIDIA \", 7) == 0 &&\n\n        !(avctx->hwaccel_flags & AV_HWACCEL_FLAG_ALLOW_PROFILE_MISMATCH)) {\n\n        av_log(avctx, AV_LOG_VERBOSE, \"HEVC with NVIDIA VDPAU drivers is buggy, skipping.\\n\");\n\n        return AVERROR(ENOTSUP);\n\n    }\n\n\n\n    status = vdctx->get_proc_address(vdctx->device,\n\n                                     VDP_FUNC_ID_VIDEO_SURFACE_QUERY_CAPABILITIES,\n\n                                     &func);\n\n    if (status != VDP_STATUS_OK)\n\n        return vdpau_error(status);\n\n    else\n\n        surface_query_caps = func;\n\n\n\n    status = surface_query_caps(vdctx->device, type, &supported,\n\n                                &max_width, &max_height);\n\n    if (status != VDP_STATUS_OK)\n\n        return vdpau_error(status);\n\n    if (supported != VDP_TRUE ||\n\n        max_width < width || max_height < height)\n\n        return AVERROR(ENOTSUP);\n\n\n\n    status = vdctx->get_proc_address(vdctx->device,\n\n                                     VDP_FUNC_ID_DECODER_QUERY_CAPABILITIES,\n\n                                     &func);\n\n    if (status != VDP_STATUS_OK)\n\n        return vdpau_error(status);\n\n    else\n\n        decoder_query_caps = func;\n\n\n\n    status = decoder_query_caps(vdctx->device, profile, &supported, &max_level,\n\n                                &max_mb, &max_width, &max_height);\n\n#ifdef VDP_DECODER_PROFILE_H264_CONSTRAINED_BASELINE\n\n    if ((status != VDP_STATUS_OK || supported != VDP_TRUE) && profile == VDP_DECODER_PROFILE_H264_CONSTRAINED_BASELINE) {\n\n        profile = VDP_DECODER_PROFILE_H264_MAIN;\n\n        status = decoder_query_caps(vdctx->device, profile, &supported,\n\n                                    &max_level, &max_mb,\n\n                                    &max_width, &max_height);\n\n    }\n\n#endif\n\n    if (status != VDP_STATUS_OK)\n\n        return vdpau_error(status);\n\n\n\n    if (supported != VDP_TRUE || max_level < level ||\n\n        max_width < width || max_height < height)\n\n        return AVERROR(ENOTSUP);\n\n\n\n    status = vdctx->get_proc_address(vdctx->device, VDP_FUNC_ID_DECODER_CREATE,\n\n                                     &func);\n\n    if (status != VDP_STATUS_OK)\n\n        return vdpau_error(status);\n\n    else\n\n        create = func;\n\n\n\n    status = vdctx->get_proc_address(vdctx->device, VDP_FUNC_ID_DECODER_RENDER,\n\n                                     &func);\n\n    if (status != VDP_STATUS_OK)\n\n        return vdpau_error(status);\n\n    else\n\n        vdctx->render = func;\n\n\n\n    status = create(vdctx->device, profile, width, height, avctx->refs,\n\n                    &vdctx->decoder);\n\n    if (status == VDP_STATUS_OK) {\n\n        vdctx->width  = avctx->coded_width;\n\n        vdctx->height = avctx->coded_height;\n\n    }\n\n\n\n    return vdpau_error(status);\n\n}", "idx": 27134}
{"project": "FFmpeg", "commit_id": "ffa1de8a3b93139097214bc600d356ab62bfdf05", "target": 1, "func": "static void dequantization_int_97(int x, int y, Jpeg2000Cblk *cblk,\n\n                               Jpeg2000Component *comp,\n\n                               Jpeg2000T1Context *t1, Jpeg2000Band *band)\n\n{\n\n    int i, j;\n\n    int w = cblk->coord[0][1] - cblk->coord[0][0];\n\n    for (j = 0; j < (cblk->coord[1][1] - cblk->coord[1][0]); ++j) {\n\n        int32_t *datap = &comp->i_data[(comp->coord[0][1] - comp->coord[0][0]) * (y + j) + x];\n\n        int *src = t1->data[j];\n\n        for (i = 0; i < w; ++i)\n\n            datap[i] = (src[i] * band->i_stepsize + (1<<14)) >> 15;\n\n    }\n\n}\n", "idx": 27135}
{"project": "FFmpeg", "commit_id": "4c439f6e3999ae534991ecde943e45b00c80b8d2", "target": 1, "func": "static int idcin_probe(AVProbeData *p)\n\n{\n\n    unsigned int number, sample_rate;\n\n\n\n    /*\n\n     * This is what you could call a \"probabilistic\" file check: id CIN\n\n     * files don't have a definite file signature. In lieu of such a marker,\n\n     * perform sanity checks on the 5 32-bit header fields:\n\n     *  width, height: greater than 0, less than or equal to 1024\n\n     * audio sample rate: greater than or equal to 8000, less than or\n\n     *  equal to 48000, or 0 for no audio\n\n     * audio sample width (bytes/sample): 0 for no audio, or 1 or 2\n\n     * audio channels: 0 for no audio, or 1 or 2\n\n     */\n\n\n\n    /* check we have enough data to do all checks, otherwise the\n\n       0-padding may cause a wrong recognition */\n\n    if (p->buf_size < 20)\n\n        return 0;\n\n\n\n    /* check the video width */\n\n    number = AV_RL32(&p->buf[0]);\n\n    if ((number == 0) || (number > 1024))\n\n       return 0;\n\n\n\n    /* check the video height */\n\n    number = AV_RL32(&p->buf[4]);\n\n    if ((number == 0) || (number > 1024))\n\n       return 0;\n\n\n\n    /* check the audio sample rate */\n\n    sample_rate = AV_RL32(&p->buf[8]);\n\n    if (sample_rate && (sample_rate < 8000 || sample_rate > 48000))\n\n        return 0;\n\n\n\n    /* check the audio bytes/sample */\n\n    number = AV_RL32(&p->buf[12]);\n\n    if (number > 2 || sample_rate && !number)\n\n        return 0;\n\n\n\n    /* check the audio channels */\n\n    number = AV_RL32(&p->buf[16]);\n\n    if (number > 2 || sample_rate && !number)\n\n        return 0;\n\n\n\n    /* return half certainty since this check is a bit sketchy */\n\n    return AVPROBE_SCORE_EXTENSION;\n\n}\n", "idx": 27136}
{"project": "FFmpeg", "commit_id": "bdcd36a4c81c50254f6204e83e0c14adc1391e66", "target": 0, "func": "yuv2rgb_full_1_c_template(SwsContext *c, const int16_t *buf0,\n\n                     const int16_t *ubuf[2], const int16_t *vbuf[2],\n\n                     const int16_t *abuf0, uint8_t *dest, int dstW,\n\n                     int uvalpha, int y, enum AVPixelFormat target,\n\n                     int hasAlpha)\n\n{\n\n    const int16_t *ubuf0 = ubuf[0], *vbuf0 = vbuf[0];\n\n    int i;\n\n    int step = (target == AV_PIX_FMT_RGB24 || target == AV_PIX_FMT_BGR24) ? 3 : 4;\n\n    int err[4] = {0};\n\n\n\n    if(   target == AV_PIX_FMT_BGR4_BYTE || target == AV_PIX_FMT_RGB4_BYTE\n\n       || target == AV_PIX_FMT_BGR8      || target == AV_PIX_FMT_RGB8)\n\n        step = 1;\n\n\n\n    if (uvalpha < 2048) {\n\n        int A = 0; //init to silence warning\n\n        for (i = 0; i < dstW; i++) {\n\n            int Y = buf0[i] << 2;\n\n            int U = (ubuf0[i] - (128<<7)) << 2;\n\n            int V = (vbuf0[i] - (128<<7)) << 2;\n\n\n\n            if (hasAlpha) {\n\n                A = (abuf0[i] + 64) >> 7;\n\n                if (A & 0x100)\n\n                    A = av_clip_uint8(A);\n\n            }\n\n\n\n            yuv2rgb_write_full(c, dest, i, Y, A, U, V, y, target, hasAlpha, err);\n\n            dest += step;\n\n        }\n\n    } else {\n\n        const int16_t *ubuf1 = ubuf[1], *vbuf1 = vbuf[1];\n\n        int A = 0; //init to silence warning\n\n        for (i = 0; i < dstW; i++) {\n\n            int Y = buf0[i] << 2;\n\n            int U = (ubuf0[i] + ubuf1[i] - (128<<8)) << 1;\n\n            int V = (vbuf0[i] + vbuf1[i] - (128<<8)) << 1;\n\n\n\n            if (hasAlpha) {\n\n                A = (abuf0[i] + 64) >> 7;\n\n                if (A & 0x100)\n\n                    A = av_clip_uint8(A);\n\n            }\n\n\n\n            yuv2rgb_write_full(c, dest, i, Y, A, U, V, y, target, hasAlpha, err);\n\n            dest += step;\n\n        }\n\n    }\n\n\n\n    c->dither_error[0][i] = err[0];\n\n    c->dither_error[1][i] = err[1];\n\n    c->dither_error[2][i] = err[2];\n\n}\n", "idx": 27137}
{"project": "FFmpeg", "commit_id": "9f0eaf792a8560a089643489403e549c30fb3170", "target": 0, "func": "static inline int hpel_motion(MpegEncContext *s,\n\n                              uint8_t *dest, uint8_t *src,\n\n                              int src_x, int src_y,\n\n                              op_pixels_func *pix_op,\n\n                              int motion_x, int motion_y)\n\n{\n\n    int dxy = 0;\n\n    int emu = 0;\n\n\n\n    src_x += motion_x >> 1;\n\n    src_y += motion_y >> 1;\n\n\n\n    /* WARNING: do no forget half pels */\n\n    src_x = av_clip(src_x, -16, s->width); // FIXME unneeded for emu?\n\n    if (src_x != s->width)\n\n        dxy |= motion_x & 1;\n\n    src_y = av_clip(src_y, -16, s->height);\n\n    if (src_y != s->height)\n\n        dxy |= (motion_y & 1) << 1;\n\n    src += src_y * s->linesize + src_x;\n\n\n\n        if ((unsigned)src_x > FFMAX(s->h_edge_pos - (motion_x & 1) - 8, 0) ||\n\n            (unsigned)src_y > FFMAX(s->v_edge_pos - (motion_y & 1) - 8, 0)) {\n\n            s->vdsp.emulated_edge_mc(s->edge_emu_buffer, src,\n\n                                     s->linesize, s->linesize,\n\n                                     9, 9,\n\n                                     src_x, src_y,\n\n                                     s->h_edge_pos, s->v_edge_pos);\n\n            src = s->edge_emu_buffer;\n\n            emu = 1;\n\n        }\n\n    pix_op[dxy](dest, src, s->linesize, 8);\n\n    return emu;\n\n}\n", "idx": 27138}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static inline void downmix_dualmono_to_mono(float *samples)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        samples[i] += samples[i + 256];\n\n        samples[i + 256] = 0;\n\n    }\n\n}\n", "idx": 27139}
{"project": "FFmpeg", "commit_id": "6892d145a0c80249bd61ee7dd31ec851c5076bcd", "target": 1, "func": "static int film_read_close(AVFormatContext *s)\n\n{\n\n    FilmDemuxContext *film = s->priv_data;\n\n\n\n    av_free(film->sample_table);\n\n    av_free(film->stereo_buffer);\n\n\n\n    return 0;\n\n}\n", "idx": 27141}
{"project": "FFmpeg", "commit_id": "3fd2d1c4bc43aab583f97afbb63ab91145f9e7ba", "target": 1, "func": "void Process(void *ctx, AVPicture *picture, enum PixelFormat pix_fmt, int width, int height, int64_t pts)\n\n{\n\n    int err = 0;\n\n    ContextInfo *ci = (ContextInfo *) ctx;\n\n    AVPicture picture1;\n\n    AVPicture picture2;\n\n    AVPicture *pict = picture;\n\n    int out_width;\n\n    int out_height;\n\n    int i;\n\n    uint8_t *ptr = NULL;\n\n    FILE *in = rwpipe_reader( ci->rw );\n\n    FILE *out = rwpipe_writer( ci->rw );\n\n\n\n    /* Check that we have a pipe to talk to. */\n\n    if ( in == NULL || out == NULL )\n\n        err = 1;\n\n\n\n    /* Convert to RGB24 if necessary */\n\n    if ( !err && pix_fmt != PIX_FMT_RGB24 )\n\n    {\n\n        int size = avpicture_get_size(PIX_FMT_RGB24, width, height);\n\n\n\n        if ( size != ci->size1 )\n\n        {\n\n            av_free( ci->buf1 );\n\n            ci->buf1 = av_malloc(size);\n\n            ci->size1 = size;\n\n            err = ci->buf1 == NULL;\n\n        }\n\n\n\n        if ( !err )\n\n        {\n\n            avpicture_fill(&picture1, ci->buf1, PIX_FMT_RGB24, width, height);\n\n\n\n            // if we already got a SWS context, let's realloc if is not re-useable\n\n            ci->toRGB_convert_ctx = sws_getCachedContext(ci->toRGB_convert_ctx,\n\n                                        width, height, pix_fmt,\n\n                                        width, height, PIX_FMT_RGB24,\n\n                                        sws_flags, NULL, NULL, NULL);\n\n            if (ci->toRGB_convert_ctx == NULL) {\n\n                av_log(NULL, AV_LOG_ERROR,\n\n                       \"Cannot initialize the toRGB conversion context\\n\");\n\n                return;\n\n            }\n\n\n\n// img_convert parameters are          2 first destination, then 4 source\n\n// sws_scale   parameters are context, 4 first source,      then 2 destination\n\n            sws_scale(ci->toRGB_convert_ctx,\n\n                     picture->data, picture->linesize, 0, height,\n\n                     picture1.data, picture1.linesize);\n\n\n\n            pict = &picture1;\n\n        }\n\n    }\n\n\n\n    /* Write out the PPM */\n\n    if ( !err )\n\n    {\n\n        ptr = pict->data[ 0 ];\n\n        fprintf( out, \"P6\\n%d %d\\n255\\n\", width, height );\n\n        for ( i = 0; !err && i < height; i ++ )\n\n        {\n\n            err = !fwrite( ptr, width * 3, 1, out );\n\n            ptr += pict->linesize[ 0 ];\n\n        }\n\n        if ( !err )\n\n            err = fflush( out );\n\n    }\n\n\n\n    /* Read the PPM returned. */\n\n    if ( !err && !rwpipe_read_ppm_header( ci->rw, &out_width, &out_height ) )\n\n    {\n\n        int size = avpicture_get_size(PIX_FMT_RGB24, out_width, out_height);\n\n\n\n        if ( size != ci->size2 )\n\n        {\n\n            av_free( ci->buf2 );\n\n            ci->buf2 = av_malloc(size);\n\n            ci->size2 = size;\n\n            err = ci->buf2 == NULL;\n\n        }\n\n\n\n        if ( !err )\n\n        {\n\n            avpicture_fill(&picture2, ci->buf2, PIX_FMT_RGB24, out_width, out_height);\n\n            ptr = picture2.data[ 0 ];\n\n            for ( i = 0; !err && i < out_height; i ++ )\n\n            {\n\n                err = !fread( ptr, out_width * 3, 1, in );\n\n                ptr += picture2.linesize[ 0 ];\n\n            }\n\n        }\n\n    }\n\n\n\n    /* Convert the returned PPM back to the input format */\n\n    if ( !err )\n\n    {\n\n        /* The out_width/out_height returned from the PPM\n\n         * filter won't necessarily be the same as width and height\n\n         * but it will be scaled anyway to width/height.\n\n         */\n\n        av_log(NULL, AV_LOG_DEBUG,\n\n                  \"PPM vhook: Input dimensions: %d x %d Output dimensions: %d x %d\\n\",\n\n                  width, height, out_width, out_height);\n\n        ci->fromRGB_convert_ctx = sws_getCachedContext(ci->fromRGB_convert_ctx,\n\n                                        out_width, out_height, PIX_FMT_RGB24,\n\n                                        width,     height,     pix_fmt,\n\n                                        sws_flags, NULL, NULL, NULL);\n\n        if (ci->fromRGB_convert_ctx == NULL) {\n\n            av_log(NULL, AV_LOG_ERROR,\n\n                   \"Cannot initialize the fromRGB conversion context\\n\");\n\n            return;\n\n        }\n\n\n\n// img_convert parameters are          2 first destination, then 4 source\n\n// sws_scale   parameters are context, 4 first source,      then 2 destination\n\n        sws_scale(ci->fromRGB_convert_ctx,\n\n                 picture2.data, picture2.linesize, 0, out_height,\n\n                 picture->data, picture->linesize);\n\n    }\n\n}\n", "idx": 27142}
{"project": "FFmpeg", "commit_id": "220b24c7c97dc033ceab1510549f66d0e7b52ef1", "target": 1, "func": "static av_cold int libschroedinger_decode_init(AVCodecContext *avctx)\n\n{\n\n\n\n    SchroDecoderParams *p_schro_params = avctx->priv_data;\n\n    /* First of all, initialize our supporting libraries. */\n\n    schro_init();\n\n\n\n    schro_debug_set_level(avctx->debug);\n\n    p_schro_params->decoder = schro_decoder_new();\n\n    schro_decoder_set_skip_ratio(p_schro_params->decoder, 1);\n\n\n\n    if (!p_schro_params->decoder)\n\n        return -1;\n\n\n\n    /* Initialize the decoded frame queue. */\n\n    ff_schro_queue_init(&p_schro_params->dec_frame_queue);\n\n    return 0;\n\n}\n", "idx": 27143}
{"project": "FFmpeg", "commit_id": "7992bdbeb4ba72a9d28e72acc2b3bc0d198401ec", "target": 1, "func": "static void update_stream_timings(AVFormatContext *ic)\n\n{\n\n    int64_t start_time, start_time1, start_time_text, end_time, end_time1;\n\n    int64_t duration, duration1, filesize;\n\n    int i;\n\n    AVStream *st;\n\n    AVProgram *p;\n\n\n\n    start_time = INT64_MAX;\n\n    start_time_text = INT64_MAX;\n\n    end_time = INT64_MIN;\n\n    duration = INT64_MIN;\n\n    for(i = 0;i < ic->nb_streams; i++) {\n\n        st = ic->streams[i];\n\n        if (st->start_time != AV_NOPTS_VALUE && st->time_base.den) {\n\n            start_time1= av_rescale_q(st->start_time, st->time_base, AV_TIME_BASE_Q);\n\n            if (st->codec->codec_type == AVMEDIA_TYPE_SUBTITLE || st->codec->codec_type == AVMEDIA_TYPE_DATA) {\n\n                if (start_time1 < start_time_text)\n\n                    start_time_text = start_time1;\n\n            } else\n\n                start_time = FFMIN(start_time, start_time1);\n\n            end_time1 = AV_NOPTS_VALUE;\n\n            if (st->duration != AV_NOPTS_VALUE) {\n\n                end_time1 = start_time1\n\n                          + av_rescale_q(st->duration, st->time_base, AV_TIME_BASE_Q);\n\n                end_time = FFMAX(end_time, end_time1);\n\n            }\n\n            for(p = NULL; (p = av_find_program_from_stream(ic, p, i)); ){\n\n                if(p->start_time == AV_NOPTS_VALUE || p->start_time > start_time1)\n\n                    p->start_time = start_time1;\n\n                if(p->end_time < end_time1)\n\n                    p->end_time = end_time1;\n\n            }\n\n        }\n\n        if (st->duration != AV_NOPTS_VALUE) {\n\n            duration1 = av_rescale_q(st->duration, st->time_base, AV_TIME_BASE_Q);\n\n            duration = FFMAX(duration, duration1);\n\n        }\n\n    }\n\n    if (start_time == INT64_MAX || (start_time > start_time_text && start_time - start_time_text < AV_TIME_BASE))\n\n        start_time = start_time_text;\n\n    else if(start_time > start_time_text)\n\n        av_log(ic, AV_LOG_VERBOSE, \"Ignoring outlier non primary stream starttime %f\\n\", start_time_text / (float)AV_TIME_BASE);\n\n\n\n    if (start_time != INT64_MAX) {\n\n        ic->start_time = start_time;\n\n        if (end_time != INT64_MIN) {\n\n            if (ic->nb_programs) {\n\n                for (i=0; i<ic->nb_programs; i++) {\n\n                    p = ic->programs[i];\n\n                    if(p->start_time != AV_NOPTS_VALUE && p->end_time > p->start_time)\n\n                        duration = FFMAX(duration, p->end_time - p->start_time);\n\n                }\n\n            } else\n\n                duration = FFMAX(duration, end_time - start_time);\n\n        }\n\n    }\n\n    if (duration != INT64_MIN && duration > 0 && ic->duration == AV_NOPTS_VALUE) {\n\n        ic->duration = duration;\n\n    }\n\n        if (ic->pb && (filesize = avio_size(ic->pb)) > 0 && ic->duration != AV_NOPTS_VALUE) {\n\n            /* compute the bitrate */\n\n            ic->bit_rate = (double)filesize * 8.0 * AV_TIME_BASE /\n\n                (double)ic->duration;\n\n        }\n\n}\n", "idx": 27144}
{"project": "FFmpeg", "commit_id": "4d87001096ff1d4e3ee6f88f8caddbd8ccb2c816", "target": 1, "func": "static int decode_frame_header(VP8Context *s, const uint8_t *buf, int buf_size)\n\n{\n\n    VP56RangeCoder *c = &s->c;\n\n    int header_size, hscale, vscale, i, j, k, l, m, ret;\n\n    int width  = s->avctx->width;\n\n    int height = s->avctx->height;\n\n\n\n    s->keyframe  = !(buf[0] & 1);\n\n    s->profile   =  (buf[0]>>1) & 7;\n\n    s->invisible = !(buf[0] & 0x10);\n\n    header_size  = AV_RL24(buf) >> 5;\n\n    buf      += 3;\n\n    buf_size -= 3;\n\n\n\n    if (s->profile > 3)\n\n        av_log(s->avctx, AV_LOG_WARNING, \"Unknown profile %d\\n\", s->profile);\n\n\n\n    if (!s->profile)\n\n        memcpy(s->put_pixels_tab, s->vp8dsp.put_vp8_epel_pixels_tab, sizeof(s->put_pixels_tab));\n\n    else    // profile 1-3 use bilinear, 4+ aren't defined so whatever\n\n        memcpy(s->put_pixels_tab, s->vp8dsp.put_vp8_bilinear_pixels_tab, sizeof(s->put_pixels_tab));\n\n\n\n    if (header_size > buf_size - 7*s->keyframe) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Header size larger than data provided\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->keyframe) {\n\n        if (AV_RL24(buf) != 0x2a019d) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Invalid start code 0x%x\\n\", AV_RL24(buf));\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        width  = AV_RL16(buf+3) & 0x3fff;\n\n        height = AV_RL16(buf+5) & 0x3fff;\n\n        hscale = buf[4] >> 6;\n\n        vscale = buf[6] >> 6;\n\n        buf      += 7;\n\n        buf_size -= 7;\n\n\n\n        if (hscale || vscale)\n\n            av_log_missing_feature(s->avctx, \"Upscaling\", 1);\n\n\n\n        s->update_golden = s->update_altref = VP56_FRAME_CURRENT;\n\n        for (i = 0; i < 4; i++)\n\n            for (j = 0; j < 16; j++)\n\n                memcpy(s->prob->token[i][j], vp8_token_default_probs[i][vp8_coeff_band[j]],\n\n                       sizeof(s->prob->token[i][j]));\n\n        memcpy(s->prob->pred16x16, vp8_pred16x16_prob_inter, sizeof(s->prob->pred16x16));\n\n        memcpy(s->prob->pred8x8c , vp8_pred8x8c_prob_inter , sizeof(s->prob->pred8x8c));\n\n        memcpy(s->prob->mvc      , vp8_mv_default_prob     , sizeof(s->prob->mvc));\n\n        memset(&s->segmentation, 0, sizeof(s->segmentation));\n\n    }\n\n\n\n    if (!s->macroblocks_base || /* first frame */\n\n        width != s->avctx->width || height != s->avctx->height) {\n\n        if ((ret = update_dimensions(s, width, height)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    ff_vp56_init_range_decoder(c, buf, header_size);\n\n    buf      += header_size;\n\n    buf_size -= header_size;\n\n\n\n    if (s->keyframe) {\n\n        if (vp8_rac_get(c))\n\n            av_log(s->avctx, AV_LOG_WARNING, \"Unspecified colorspace\\n\");\n\n        vp8_rac_get(c); // whether we can skip clamping in dsp functions\n\n    }\n\n\n\n    if ((s->segmentation.enabled = vp8_rac_get(c)))\n\n        parse_segment_info(s);\n\n    else\n\n        s->segmentation.update_map = 0; // FIXME: move this to some init function?\n\n\n\n    s->filter.simple    = vp8_rac_get(c);\n\n    s->filter.level     = vp8_rac_get_uint(c, 6);\n\n    s->filter.sharpness = vp8_rac_get_uint(c, 3);\n\n\n\n    if ((s->lf_delta.enabled = vp8_rac_get(c)))\n\n        if (vp8_rac_get(c))\n\n            update_lf_deltas(s);\n\n\n\n    if (setup_partitions(s, buf, buf_size)) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid partitions\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    get_quants(s);\n\n\n\n    if (!s->keyframe) {\n\n        update_refs(s);\n\n        s->sign_bias[VP56_FRAME_GOLDEN]               = vp8_rac_get(c);\n\n        s->sign_bias[VP56_FRAME_GOLDEN2 /* altref */] = vp8_rac_get(c);\n\n    }\n\n\n\n    // if we aren't saving this frame's probabilities for future frames,\n\n    // make a copy of the current probabilities\n\n    if (!(s->update_probabilities = vp8_rac_get(c)))\n\n        s->prob[1] = s->prob[0];\n\n\n\n    s->update_last = s->keyframe || vp8_rac_get(c);\n\n\n\n    for (i = 0; i < 4; i++)\n\n        for (j = 0; j < 8; j++)\n\n            for (k = 0; k < 3; k++)\n\n                for (l = 0; l < NUM_DCT_TOKENS-1; l++)\n\n                    if (vp56_rac_get_prob_branchy(c, vp8_token_update_probs[i][j][k][l])) {\n\n                        int prob = vp8_rac_get_uint(c, 8);\n\n                        for (m = 0; vp8_coeff_band_indexes[j][m] >= 0; m++)\n\n                            s->prob->token[i][vp8_coeff_band_indexes[j][m]][k][l] = prob;\n\n                    }\n\n\n\n    if ((s->mbskip_enabled = vp8_rac_get(c)))\n\n        s->prob->mbskip = vp8_rac_get_uint(c, 8);\n\n\n\n    if (!s->keyframe) {\n\n        s->prob->intra  = vp8_rac_get_uint(c, 8);\n\n        s->prob->last   = vp8_rac_get_uint(c, 8);\n\n        s->prob->golden = vp8_rac_get_uint(c, 8);\n\n\n\n        if (vp8_rac_get(c))\n\n            for (i = 0; i < 4; i++)\n\n                s->prob->pred16x16[i] = vp8_rac_get_uint(c, 8);\n\n        if (vp8_rac_get(c))\n\n            for (i = 0; i < 3; i++)\n\n                s->prob->pred8x8c[i]  = vp8_rac_get_uint(c, 8);\n\n\n\n        // 17.2 MV probability update\n\n        for (i = 0; i < 2; i++)\n\n            for (j = 0; j < 19; j++)\n\n                if (vp56_rac_get_prob_branchy(c, vp8_mv_update_prob[i][j]))\n\n                    s->prob->mvc[i][j] = vp8_rac_get_nn(c);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 27147}
{"project": "FFmpeg", "commit_id": "0ecca7a49f8e254c12a3a1de048d738bfbb614c6", "target": 1, "func": "static unsigned long iv_decode_frame(Indeo3DecodeContext *s, \n                                     unsigned char *buf, int buf_size) \n{\n  unsigned int hdr_width, hdr_height,\n    chroma_width, chroma_height;\n  unsigned long fflags1, fflags2, fflags3, offs1, offs2, offs3, offs;\n  unsigned char *hdr_pos, *buf_pos;\n  buf_pos = buf;\n  buf_pos += 18;\n  fflags1 = le2me_16(*(uint16_t *)buf_pos);\n  buf_pos += 2;\n  fflags3 = le2me_32(*(uint32_t *)buf_pos);\n  buf_pos += 4;\n  fflags2 = *buf_pos++;\n  buf_pos += 3;\n  hdr_height = le2me_16(*(uint16_t *)buf_pos);\n  buf_pos += 2;\n  hdr_width = le2me_16(*(uint16_t *)buf_pos);\n  buf_pos += 2;\n  chroma_height = ((hdr_height >> 2) + 3) & 0x7ffc;\n  chroma_width = ((hdr_width >> 2) + 3) & 0x7ffc;\n  offs1 = le2me_32(*(uint32_t *)buf_pos);\n  buf_pos += 4;\n  offs2 = le2me_32(*(uint32_t *)buf_pos);\n  buf_pos += 4;\n  offs3 = le2me_32(*(uint32_t *)buf_pos);\n  buf_pos += 8;\n  hdr_pos = buf_pos;\n  if(fflags3 == 0x80) return 4;\n  if(fflags1 & 0x200) {\n    s->cur_frame = s->iv_frame + 1;\n    s->ref_frame = s->iv_frame;\n  } else {\n    s->cur_frame = s->iv_frame;\n    s->ref_frame = s->iv_frame + 1;\n  }\n  buf_pos = buf + 16 + offs1;\n  offs = le2me_32(*(uint32_t *)buf_pos);\n  buf_pos += 4;\n  iv_Decode_Chunk(s, s->cur_frame->Ybuf, s->ref_frame->Ybuf, hdr_width, \n    hdr_height, buf_pos + offs * 2, fflags2, hdr_pos, buf_pos, \n    min(hdr_width, 160));\n  if (!(s->avctx->flags & CODEC_FLAG_GRAY))\n  {\n  buf_pos = buf + 16 + offs2;\n  offs = le2me_32(*(uint32_t *)buf_pos);\n  buf_pos += 4;\n  iv_Decode_Chunk(s, s->cur_frame->Vbuf, s->ref_frame->Vbuf, chroma_width, \n    chroma_height, buf_pos + offs * 2, fflags2, hdr_pos, buf_pos, \n    min(chroma_width, 40));\n  buf_pos = buf + 16 + offs3;\n  offs = le2me_32(*(uint32_t *)buf_pos);\n  buf_pos += 4;\n  iv_Decode_Chunk(s, s->cur_frame->Ubuf, s->ref_frame->Ubuf, chroma_width, \n    chroma_height, buf_pos + offs * 2, fflags2, hdr_pos, buf_pos, \n    min(chroma_width, 40));\n  }\n  return 8;\n}", "idx": 27151}
{"project": "FFmpeg", "commit_id": "7444cf9a9c0b8b2bba8198af2823521c654a48f4", "target": 1, "func": "static int imc_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    AVFrame *frame     = data;\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    int ret, i;\n\n\n\n    IMCContext *q = avctx->priv_data;\n\n\n\n    LOCAL_ALIGNED_16(uint16_t, buf16, [IMC_BLOCK_SIZE / 2]);\n\n\n\n    if (buf_size < IMC_BLOCK_SIZE * avctx->channels) {\n\n        av_log(avctx, AV_LOG_ERROR, \"frame too small!\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* get output buffer */\n\n    frame->nb_samples = COEFFS;\n\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n\n        return ret;\n\n\n\n    for (i = 0; i < avctx->channels; i++) {\n\n        q->out_samples = (float *)frame->extended_data[i];\n\n\n\n        q->bdsp.bswap16_buf(buf16, (const uint16_t *) buf, IMC_BLOCK_SIZE / 2);\n\n\n\n        init_get_bits(&q->gb, (const uint8_t*)buf16, IMC_BLOCK_SIZE * 8);\n\n\n\n        buf += IMC_BLOCK_SIZE;\n\n\n\n        if ((ret = imc_decode_block(avctx, q, i)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    if (avctx->channels == 2) {\n\n        q->fdsp.butterflies_float((float *)frame->extended_data[0],\n\n                                  (float *)frame->extended_data[1], COEFFS);\n\n    }\n\n\n\n    *got_frame_ptr = 1;\n\n\n\n    return IMC_BLOCK_SIZE * avctx->channels;\n\n}\n", "idx": 27152}
{"project": "FFmpeg", "commit_id": "073c2593c9f0aa4445a6fc1b9b24e6e52a8cc2c1", "target": 1, "func": "int init_vlc(VLC *vlc, int nb_bits, int nb_codes,\n\n             const void *bits, int bits_wrap, int bits_size,\n\n             const void *codes, int codes_wrap, int codes_size)\n\n{\n\n    vlc->bits = nb_bits;\n\n    vlc->table = NULL;\n\n    vlc->table_allocated = 0;\n\n    vlc->table_size = 0;\n\n#ifdef DEBUG_VLC\n\n    printf(\"build table nb_codes=%d\\n\", nb_codes);\n\n#endif\n\n\n\n    if (build_table(vlc, nb_bits, nb_codes,\n\n                    bits, bits_wrap, bits_size,\n\n                    codes, codes_wrap, codes_size,\n\n                    0, 0) < 0) {\n\n        av_free(vlc->table);\n\n        return -1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 27153}
{"project": "FFmpeg", "commit_id": "31fdf3065daceb31e12fd26a367445676d761180", "target": 1, "func": "static void filter(AVFilterContext *ctx)\n\n{\n\n    IDETContext *idet = ctx->priv;\n\n    int y, i;\n\n    int64_t alpha[2]={0};\n\n    int64_t delta=0;\n\n    Type type, best_type;\n\n    int match = 0;\n\n\n\n    for (i = 0; i < idet->csp->nb_components; i++) {\n\n        int w = idet->cur->video->w;\n\n        int h = idet->cur->video->h;\n\n        int refs = idet->cur->linesize[i];\n\n\n\n        if (i && i<3) {\n\n            w >>= idet->csp->log2_chroma_w;\n\n            h >>= idet->csp->log2_chroma_h;\n\n        }\n\n\n\n        for (y = 2; y < h - 2; y++) {\n\n            uint8_t *prev = &idet->prev->data[i][y*refs];\n\n            uint8_t *cur  = &idet->cur ->data[i][y*refs];\n\n            uint8_t *next = &idet->next->data[i][y*refs];\n\n            alpha[ y   &1] += idet->filter_line(cur-refs, prev, cur+refs, w);\n\n            alpha[(y^1)&1] += idet->filter_line(cur-refs, next, cur+refs, w);\n\n            delta          += idet->filter_line(cur-refs,  cur, cur+refs, w);\n\n        }\n\n    }\n\n\n\n    if      (alpha[0] / (float)alpha[1] > idet->interlace_threshold){\n\n        type = TFF;\n\n    }else if(alpha[1] / (float)alpha[0] > idet->interlace_threshold){\n\n        type = BFF;\n\n    }else if(alpha[1] / (float)delta    > idet->progressive_threshold){\n\n        type = PROGRSSIVE;\n\n    }else{\n\n        type = UNDETERMINED;\n\n    }\n\n\n\n    memmove(idet->history+1, idet->history, HIST_SIZE-1);\n\n    idet->history[0] = type;\n\n    best_type = UNDETERMINED;\n\n    for(i=0; i<HIST_SIZE; i++){\n\n        if(idet->history[i] != UNDETERMINED){\n\n            if(best_type == UNDETERMINED)\n\n                best_type = idet->history[i];\n\n\n\n            if(idet->history[i] == best_type) {\n\n                match++;\n\n            }else{\n\n                match=0;\n\n                break;\n\n            }\n\n        }\n\n    }\n\n    if(idet->last_type == UNDETERMINED){\n\n        if(match  ) idet->last_type = best_type;\n\n    }else{\n\n        if(match>2) idet->last_type = best_type;\n\n    }\n\n\n\n    if      (idet->last_type == TFF){\n\n        idet->cur->video->top_field_first = 1;\n\n        idet->cur->video->interlaced = 1;\n\n    }else if(idet->last_type == BFF){\n\n        idet->cur->video->top_field_first = 0;\n\n        idet->cur->video->interlaced = 1;\n\n    }else if(idet->last_type == PROGRSSIVE){\n\n        idet->cur->video->interlaced = 0;\n\n    }\n\n\n\n    idet->prestat [           type] ++;\n\n    idet->poststat[idet->last_type] ++;\n\n    av_log(ctx, AV_LOG_DEBUG, \"Single frame:%s, Multi frame:%s\\n\", type2str(type), type2str(idet->last_type));\n\n}\n", "idx": 27154}
{"project": "FFmpeg", "commit_id": "01ecb7172b684f1c4b3e748f95c5a9a494ca36ec", "target": 1, "func": "static float get_band_cost_UPAIR12_mips(struct AACEncContext *s,\n\n                                        PutBitContext *pb, const float *in,\n\n                                        const float *scaled, int size, int scale_idx,\n\n                                        int cb, const float lambda, const float uplim,\n\n                                        int *bits)\n\n{\n\n    const float Q34 = ff_aac_pow34sf_tab[POW_SF2_ZERO - scale_idx + SCALE_ONE_POS - SCALE_DIV_512];\n\n    const float IQ  = ff_aac_pow2sf_tab [POW_SF2_ZERO + scale_idx - SCALE_ONE_POS + SCALE_DIV_512];\n\n    int i;\n\n    float cost = 0;\n\n    int qc1, qc2, qc3, qc4;\n\n    int curbits = 0;\n\n\n\n    uint8_t *p_bits  = (uint8_t *)ff_aac_spectral_bits[cb-1];\n\n    float   *p_codes = (float   *)ff_aac_codebook_vectors[cb-1];\n\n\n\n    for (i = 0; i < size; i += 4) {\n\n        const float *vec, *vec2;\n\n        int curidx, curidx2;\n\n        int sign1, count1, sign2, count2;\n\n        int   *in_int = (int   *)&in[i];\n\n        float *in_pos = (float *)&in[i];\n\n        float di0, di1, di2, di3;\n\n        int t0, t1, t2, t3, t4;\n\n\n\n        qc1 = scaled[i  ] * Q34 + ROUND_STANDARD;\n\n        qc2 = scaled[i+1] * Q34 + ROUND_STANDARD;\n\n        qc3 = scaled[i+2] * Q34 + ROUND_STANDARD;\n\n        qc4 = scaled[i+3] * Q34 + ROUND_STANDARD;\n\n\n\n        __asm__ volatile (\n\n            \".set push                                          \\n\\t\"\n\n            \".set noreorder                                     \\n\\t\"\n\n\n\n            \"ori        %[t4],      $zero,      12              \\n\\t\"\n\n            \"ori        %[sign1],   $zero,      0               \\n\\t\"\n\n            \"ori        %[sign2],   $zero,      0               \\n\\t\"\n\n            \"slt        %[t0],      %[t4],      %[qc1]          \\n\\t\"\n\n            \"slt        %[t1],      %[t4],      %[qc2]          \\n\\t\"\n\n            \"slt        %[t2],      %[t4],      %[qc3]          \\n\\t\"\n\n            \"slt        %[t3],      %[t4],      %[qc4]          \\n\\t\"\n\n            \"movn       %[qc1],     %[t4],      %[t0]           \\n\\t\"\n\n            \"movn       %[qc2],     %[t4],      %[t1]           \\n\\t\"\n\n            \"movn       %[qc3],     %[t4],      %[t2]           \\n\\t\"\n\n            \"movn       %[qc4],     %[t4],      %[t3]           \\n\\t\"\n\n            \"lw         %[t0],      0(%[in_int])                \\n\\t\"\n\n            \"lw         %[t1],      4(%[in_int])                \\n\\t\"\n\n            \"lw         %[t2],      8(%[in_int])                \\n\\t\"\n\n            \"lw         %[t3],      12(%[in_int])               \\n\\t\"\n\n            \"slt        %[t0],      %[t0],      $zero           \\n\\t\"\n\n            \"movn       %[sign1],   %[t0],      %[qc1]          \\n\\t\"\n\n            \"slt        %[t2],      %[t2],      $zero           \\n\\t\"\n\n            \"movn       %[sign2],   %[t2],      %[qc3]          \\n\\t\"\n\n            \"slt        %[t1],      %[t1],      $zero           \\n\\t\"\n\n            \"sll        %[t0],      %[sign1],   1               \\n\\t\"\n\n            \"or         %[t0],      %[t0],      %[t1]           \\n\\t\"\n\n            \"movn       %[sign1],   %[t0],      %[qc2]          \\n\\t\"\n\n            \"slt        %[t3],      %[t3],      $zero           \\n\\t\"\n\n            \"sll        %[t0],      %[sign2],   1               \\n\\t\"\n\n            \"or         %[t0],      %[t0],      %[t3]           \\n\\t\"\n\n            \"movn       %[sign2],   %[t0],      %[qc4]          \\n\\t\"\n\n            \"slt        %[count1],  $zero,      %[qc1]          \\n\\t\"\n\n            \"slt        %[t1],      $zero,      %[qc2]          \\n\\t\"\n\n            \"slt        %[count2],  $zero,      %[qc3]          \\n\\t\"\n\n            \"slt        %[t2],      $zero,      %[qc4]          \\n\\t\"\n\n            \"addu       %[count1],  %[count1],  %[t1]           \\n\\t\"\n\n            \"addu       %[count2],  %[count2],  %[t2]           \\n\\t\"\n\n\n\n            \".set pop                                           \\n\\t\"\n\n\n\n            : [qc1]\"+r\"(qc1), [qc2]\"+r\"(qc2),\n\n              [qc3]\"+r\"(qc3), [qc4]\"+r\"(qc4),\n\n              [sign1]\"=&r\"(sign1), [count1]\"=&r\"(count1),\n\n              [sign2]\"=&r\"(sign2), [count2]\"=&r\"(count2),\n\n              [t0]\"=&r\"(t0), [t1]\"=&r\"(t1), [t2]\"=&r\"(t2), [t3]\"=&r\"(t3),\n\n              [t4]\"=&r\"(t4)\n\n            : [in_int]\"r\"(in_int)\n\n            : \"memory\"\n\n        );\n\n\n\n        curidx = 13 * qc1;\n\n        curidx += qc2;\n\n\n\n        curidx2 = 13 * qc3;\n\n        curidx2 += qc4;\n\n\n\n        curbits += p_bits[curidx];\n\n        curbits += p_bits[curidx2];\n\n        curbits += upair12_sign_bits[curidx];\n\n        curbits += upair12_sign_bits[curidx2];\n\n        vec     = &p_codes[curidx*2];\n\n        vec2    = &p_codes[curidx2*2];\n\n\n\n        __asm__ volatile (\n\n            \".set push                                          \\n\\t\"\n\n            \".set noreorder                                     \\n\\t\"\n\n\n\n            \"lwc1       %[di0],     0(%[in_pos])                \\n\\t\"\n\n            \"lwc1       %[di1],     4(%[in_pos])                \\n\\t\"\n\n            \"lwc1       %[di2],     8(%[in_pos])                \\n\\t\"\n\n            \"lwc1       %[di3],     12(%[in_pos])               \\n\\t\"\n\n            \"abs.s      %[di0],     %[di0]                      \\n\\t\"\n\n            \"abs.s      %[di1],     %[di1]                      \\n\\t\"\n\n            \"abs.s      %[di2],     %[di2]                      \\n\\t\"\n\n            \"abs.s      %[di3],     %[di3]                      \\n\\t\"\n\n            \"lwc1       $f0,        0(%[vec])                   \\n\\t\"\n\n            \"lwc1       $f1,        4(%[vec])                   \\n\\t\"\n\n            \"lwc1       $f2,        0(%[vec2])                  \\n\\t\"\n\n            \"lwc1       $f3,        4(%[vec2])                  \\n\\t\"\n\n            \"nmsub.s    %[di0],     %[di0],     $f0,    %[IQ]   \\n\\t\"\n\n            \"nmsub.s    %[di1],     %[di1],     $f1,    %[IQ]   \\n\\t\"\n\n            \"nmsub.s    %[di2],     %[di2],     $f2,    %[IQ]   \\n\\t\"\n\n            \"nmsub.s    %[di3],     %[di3],     $f3,    %[IQ]   \\n\\t\"\n\n\n\n            \".set pop                                           \\n\\t\"\n\n\n\n            : [di0]\"=&f\"(di0), [di1]\"=&f\"(di1),\n\n              [di2]\"=&f\"(di2), [di3]\"=&f\"(di3)\n\n            : [in_pos]\"r\"(in_pos), [vec]\"r\"(vec),\n\n              [vec2]\"r\"(vec2), [IQ]\"f\"(IQ)\n\n            : \"$f0\", \"$f1\", \"$f2\", \"$f3\",\n\n              \"memory\"\n\n        );\n\n\n\n        cost += di0 * di0 + di1 * di1\n\n                + di2 * di2 + di3 * di3;\n\n    }\n\n\n\n    if (bits)\n\n        *bits = curbits;\n\n    return cost * lambda + curbits;\n\n}\n", "idx": 27156}
{"project": "FFmpeg", "commit_id": "56706ac0d5723cb549fec2602e798ab1bf6004cd", "target": 1, "func": "static int libopenjpeg_copy_unpacked16(AVCodecContext *avctx, const AVFrame *frame, opj_image_t *image)\n\n{\n\n    int compno;\n\n    int x;\n\n    int y;\n\n    int width;\n\n    int height;\n\n    int *image_line;\n\n    int frame_index;\n\n    const int numcomps = image->numcomps;\n\n    uint16_t *frame_ptr;\n\n\n\n    for (compno = 0; compno < numcomps; ++compno) {\n\n        if (image->comps[compno].w > frame->linesize[compno]) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Error: frame's linesize is too small for the image\\n\");\n\n            return 0;\n\n        }\n\n    }\n\n\n\n    for (compno = 0; compno < numcomps; ++compno) {\n\n        width     = avctx->width / image->comps[compno].dx;\n\n        height    = avctx->height / image->comps[compno].dy;\n\n        frame_ptr = (uint16_t *)frame->data[compno];\n\n        for (y = 0; y < height; ++y) {\n\n            image_line = image->comps[compno].data + y * image->comps[compno].w;\n\n            frame_index = y * (frame->linesize[compno] / 2);\n\n            for (x = 0; x < width; ++x)\n\n                image_line[x] = frame_ptr[frame_index++];\n\n            for (; x < image->comps[compno].w; ++x) {\n\n                image_line[x] = image_line[x - 1];\n\n            }\n\n        }\n\n        for (; y < image->comps[compno].h; ++y) {\n\n            image_line = image->comps[compno].data + y * image->comps[compno].w;\n\n            for (x = 0; x < image->comps[compno].w; ++x) {\n\n                image_line[x] = image_line[x - image->comps[compno].w];\n\n            }\n\n        }\n\n    }\n\n\n\n    return 1;\n\n}\n", "idx": 27157}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "inline static void RENAME(hcscale)(uint16_t *dst, int dstWidth, uint8_t *src1, uint8_t *src2,\n\n\t\t\t\t   int srcW, int xInc, int flags, int canMMX2BeUsed, int16_t *hChrFilter,\n\n\t\t\t\t   int16_t *hChrFilterPos, int hChrFilterSize, void *funnyUVCode,\n\n\t\t\t\t   int srcFormat, uint8_t *formatConvBuffer, int16_t *mmx2Filter,\n\n\t\t\t\t   int32_t *mmx2FilterPos)\n\n{\n\n    if(srcFormat==IMGFMT_YUY2)\n\n    {\n\n\tRENAME(yuy2ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_UYVY)\n\n    {\n\n\tRENAME(uyvyToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_BGR32)\n\n    {\n\n\tRENAME(bgr32ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_BGR24)\n\n    {\n\n\tRENAME(bgr24ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_BGR16)\n\n    {\n\n\tRENAME(bgr16ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_BGR15)\n\n    {\n\n\tRENAME(bgr15ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_RGB32)\n\n    {\n\n\tRENAME(rgb32ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_RGB24)\n\n    {\n\n\tRENAME(rgb24ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(isGray(srcFormat))\n\n    {\n\n    \treturn;\n\n    }\n\n\n\n#ifdef HAVE_MMX\n\n\t// use the new MMX scaler if the mmx2 can't be used (its faster than the x86asm one)\n\n    if(!(flags&SWS_FAST_BILINEAR) || (!canMMX2BeUsed))\n\n#else\n\n    if(!(flags&SWS_FAST_BILINEAR))\n\n#endif\n\n    {\n\n    \tRENAME(hScale)(dst     , dstWidth, src1, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n    \tRENAME(hScale)(dst+2048, dstWidth, src2, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n    }\n\n    else // Fast Bilinear upscale / crap downscale\n\n    {\n\n#if defined(ARCH_X86) || defined(ARCH_X86_64)\n\n#ifdef HAVE_MMX2\n\n\tint i;\n\n\tif(canMMX2BeUsed)\n\n\t{\n\n\t\tasm volatile(\n\n\t\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"mov %0, %%\"REG_c\"\t\t\\n\\t\"\n\n\t\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\t\"mov %2, %%\"REG_d\"\t\t\\n\\t\"\n\n\t\t\t\"mov %3, %%\"REG_b\"\t\t\\n\\t\"\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\" // i\n\n\t\t\tPREFETCH\" (%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%%\"REG_c\")\t\t\\n\\t\"\n\n\n\n#ifdef ARCH_X86_64\n\n\n\n#define FUNNY_UV_CODE \\\n\n\t\t\t\"movl (%%\"REG_b\"), %%esi\t\\n\\t\"\\\n\n\t\t\t\"call *%4\t\t\t\\n\\t\"\\\n\n\t\t\t\"movl (%%\"REG_b\", %%\"REG_a\"), %%esi\\n\\t\"\\\n\n\t\t\t\"add %%\"REG_S\", %%\"REG_c\"\t\\n\\t\"\\\n\n\t\t\t\"add %%\"REG_a\", %%\"REG_D\"\t\\n\\t\"\\\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\"\\\n\n\n\n#else\n\n\n\n#define FUNNY_UV_CODE \\\n\n\t\t\t\"movl (%%\"REG_b\"), %%esi\t\\n\\t\"\\\n\n\t\t\t\"call *%4\t\t\t\\n\\t\"\\\n\n\t\t\t\"addl (%%\"REG_b\", %%\"REG_a\"), %%\"REG_c\"\\n\\t\"\\\n\n\t\t\t\"add %%\"REG_a\", %%\"REG_D\"\t\\n\\t\"\\\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\"\\\n\n\n\n#endif\n\n\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\" // i\n\n\t\t\t\"mov %5, %%\"REG_c\"\t\t\\n\\t\" // src\n\n\t\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\" // buf1\n\n\t\t\t\"add $4096, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" (%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%%\"REG_c\")\t\t\\n\\t\"\n\n\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\n\n\n\t\t\t:: \"m\" (src1), \"m\" (dst), \"m\" (mmx2Filter), \"m\" (mmx2FilterPos),\n\n\t\t\t\"m\" (funnyUVCode), \"m\" (src2)\n\n\t\t\t: \"%\"REG_a, \"%\"REG_b, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S, \"%\"REG_D\n\n\t\t);\n\n\t\tfor(i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--)\n\n\t\t{\n\n//\t\t\tprintf(\"%d %d %d\\n\", dstWidth, i, srcW);\n\n\t\t\tdst[i] = src1[srcW-1]*128;\n\n\t\t\tdst[i+2048] = src2[srcW-1]*128;\n\n\t\t}\n\n\t}\n\n\telse\n\n\t{\n\n#endif\n\n\tlong xInc_shr16 = (long) (xInc >> 16);\n\n\tint xInc_mask = xInc & 0xffff; \n\n\tasm volatile(\n\n\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\" // i\n\n\t\t\"xor %%\"REG_b\", %%\"REG_b\"\t\t\\n\\t\" // xx\n\n\t\t\"xorl %%ecx, %%ecx\t\t\\n\\t\" // 2*xalpha\n\n\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\"mov %0, %%\"REG_S\"\t\t\\n\\t\"\n\n\t\t\"movzbl  (%%\"REG_S\", %%\"REG_b\"), %%edi\t\\n\\t\" //src[xx]\n\n\t\t\"movzbl 1(%%\"REG_S\", %%\"REG_b\"), %%esi\t\\n\\t\" //src[xx+1]\n\n\t\t\"subl %%edi, %%esi\t\t\\n\\t\" //src[xx+1] - src[xx]\n\n\t\t\"imull %%ecx, %%esi\t\t\\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n\t\t\"shll $16, %%edi\t\t\\n\\t\"\n\n\t\t\"addl %%edi, %%esi\t\t\\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\"shrl $9, %%esi\t\t\t\\n\\t\"\n\n\t\t\"movw %%si, (%%\"REG_D\", %%\"REG_a\", 2)\\n\\t\"\n\n\n\n\t\t\"movzbl  (%5, %%\"REG_b\"), %%edi\t\\n\\t\" //src[xx]\n\n\t\t\"movzbl 1(%5, %%\"REG_b\"), %%esi\t\\n\\t\" //src[xx+1]\n\n\t\t\"subl %%edi, %%esi\t\t\\n\\t\" //src[xx+1] - src[xx]\n\n\t\t\"imull %%ecx, %%esi\t\t\\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n\t\t\"shll $16, %%edi\t\t\\n\\t\"\n\n\t\t\"addl %%edi, %%esi\t\t\\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\"shrl $9, %%esi\t\t\t\\n\\t\"\n\n\t\t\"movw %%si, 4096(%%\"REG_D\", %%\"REG_a\", 2)\\n\\t\"\n\n\n\n\t\t\"addw %4, %%cx\t\t\t\\n\\t\" //2*xalpha += xInc&0xFF\n\n\t\t\"adc %3, %%\"REG_b\"\t\t\\n\\t\" //xx+= xInc>>8 + carry\n\n\t\t\"add $1, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\"cmp %2, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\n\n/* GCC-3.3 makes MPlayer crash on IA-32 machines when using \"g\" operand here,\n\n   which is needed to support GCC-4.0 */\n\n#if defined(ARCH_X86_64) && ((__GNUC__ > 3) || ( __GNUC__ == 3 && __GNUC_MINOR__ >= 4))\n\n\t\t:: \"m\" (src1), \"m\" (dst), \"g\" ((long)dstWidth), \"m\" (xInc_shr16), \"m\" (xInc_mask),\n\n#else\n\n\t\t:: \"m\" (src1), \"m\" (dst), \"m\" ((long)dstWidth), \"m\" (xInc_shr16), \"m\" (xInc_mask),\n\n#endif\n\n\t\t\"r\" (src2)\n\n\t\t: \"%\"REG_a, \"%\"REG_b, \"%ecx\", \"%\"REG_D, \"%esi\"\n\n\t\t);\n\n#ifdef HAVE_MMX2\n\n\t} //if MMX2 can't be used\n\n#endif\n\n#else\n\n\tint i;\n\n\tunsigned int xpos=0;\n\n\tfor(i=0;i<dstWidth;i++)\n\n\t{\n\n\t\tregister unsigned int xx=xpos>>16;\n\n\t\tregister unsigned int xalpha=(xpos&0xFFFF)>>9;\n\n\t\tdst[i]=(src1[xx]*(xalpha^127)+src1[xx+1]*xalpha);\n\n\t\tdst[i+2048]=(src2[xx]*(xalpha^127)+src2[xx+1]*xalpha);\n\n/* slower\n\n\t  dst[i]= (src1[xx]<<7) + (src1[xx+1] - src1[xx])*xalpha;\n\n\t  dst[i+2048]=(src2[xx]<<7) + (src2[xx+1] - src2[xx])*xalpha;\n\n*/\n\n\t\txpos+=xInc;\n\n\t}\n\n#endif\n\n   }\n\n}\n", "idx": 27158}
{"project": "FFmpeg", "commit_id": "243b9fea90aade8cf8197fb8f362ccc03c7f6295", "target": 1, "func": "static int tak_read_header(AVFormatContext *s)\n\n{\n\n    TAKDemuxContext *tc = s->priv_data;\n\n    AVIOContext *pb     = s->pb;\n\n    GetBitContext gb;\n\n    AVStream *st;\n\n    uint8_t *buffer = NULL;\n\n    int ret;\n\n\n\n    st = avformat_new_stream(s, 0);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n    st->codec->codec_id   = AV_CODEC_ID_TAK;\n\n    st->need_parsing      = AVSTREAM_PARSE_FULL_RAW;\n\n\n\n    tc->mlast_frame = 0;\n\n    if (avio_rl32(pb) != MKTAG('t', 'B', 'a', 'K')) {\n\n        avio_seek(pb, -4, SEEK_CUR);\n\n        return 0;\n\n    }\n\n\n\n    while (!url_feof(pb)) {\n\n        enum TAKMetaDataType type;\n\n        int size;\n\n\n\n        type = avio_r8(pb) & 0x7f;\n\n        size = avio_rl24(pb);\n\n\n\n        switch (type) {\n\n        case TAK_METADATA_STREAMINFO:\n\n        case TAK_METADATA_LAST_FRAME:\n\n        case TAK_METADATA_ENCODER:\n\n            if (size <= 3)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            buffer = av_malloc(size - 3 + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (!buffer)\n\n                return AVERROR(ENOMEM);\n\n\n\n\n            ffio_init_checksum(pb, tak_check_crc, 0xCE04B7U);\n\n            if (avio_read(pb, buffer, size - 3) != size - 3) {\n\n                av_freep(&buffer);\n\n                return AVERROR(EIO);\n\n            }\n\n            if (ffio_get_checksum(s->pb) != avio_rb24(pb)) {\n\n                av_log(s, AV_LOG_ERROR, \"%d metadata block CRC error.\\n\", type);\n\n                if (s->error_recognition & AV_EF_EXPLODE) {\n\n                    av_freep(&buffer);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n            }\n\n\n\n            init_get_bits8(&gb, buffer, size - 3);\n\n            break;\n\n        case TAK_METADATA_MD5: {\n\n            uint8_t md5[16];\n\n            int i;\n\n\n\n            if (size != 19)\n\n                return AVERROR_INVALIDDATA;\n\n            ffio_init_checksum(pb, tak_check_crc, 0xCE04B7U);\n\n            avio_read(pb, md5, 16);\n\n            if (ffio_get_checksum(s->pb) != avio_rb24(pb)) {\n\n                av_log(s, AV_LOG_ERROR, \"MD5 metadata block CRC error.\\n\");\n\n                if (s->error_recognition & AV_EF_EXPLODE)\n\n                    return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            av_log(s, AV_LOG_VERBOSE, \"MD5=\");\n\n            for (i = 0; i < 16; i++)\n\n                av_log(s, AV_LOG_VERBOSE, \"%02x\", md5[i]);\n\n            av_log(s, AV_LOG_VERBOSE, \"\\n\");\n\n            break;\n\n        }\n\n        case TAK_METADATA_END: {\n\n            int64_t curpos = avio_tell(pb);\n\n\n\n            if (pb->seekable) {\n\n                ff_ape_parse_tag(s);\n\n                avio_seek(pb, curpos, SEEK_SET);\n\n            }\n\n\n\n            tc->data_end += curpos;\n\n            return 0;\n\n        }\n\n        default:\n\n            ret = avio_skip(pb, size);\n\n            if (ret < 0)\n\n                return ret;\n\n        }\n\n\n\n        if (type == TAK_METADATA_STREAMINFO) {\n\n            TAKStreamInfo ti;\n\n\n\n            avpriv_tak_parse_streaminfo(&gb, &ti);\n\n            if (ti.samples > 0)\n\n                st->duration = ti.samples;\n\n            st->codec->bits_per_coded_sample = ti.bps;\n\n            if (ti.ch_layout)\n\n                st->codec->channel_layout = ti.ch_layout;\n\n            st->codec->sample_rate           = ti.sample_rate;\n\n            st->codec->channels              = ti.channels;\n\n            st->start_time                   = 0;\n\n            avpriv_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n            st->codec->extradata             = buffer;\n\n            st->codec->extradata_size        = size - 3;\n\n            buffer                           = NULL;\n\n        } else if (type == TAK_METADATA_LAST_FRAME) {\n\n            if (size != 11)\n\n                return AVERROR_INVALIDDATA;\n\n            tc->mlast_frame = 1;\n\n            tc->data_end    = get_bits64(&gb, TAK_LAST_FRAME_POS_BITS) +\n\n                              get_bits(&gb, TAK_LAST_FRAME_SIZE_BITS);\n\n            av_freep(&buffer);\n\n        } else if (type == TAK_METADATA_ENCODER) {\n\n            av_log(s, AV_LOG_VERBOSE, \"encoder version: %0X\\n\",\n\n                   get_bits_long(&gb, TAK_ENCODER_VERSION_BITS));\n\n            av_freep(&buffer);\n\n        }\n\n    }\n\n\n\n    return AVERROR_EOF;\n\n}", "idx": 27159}
{"project": "FFmpeg", "commit_id": "9d656110966fbdde0fd1d2e685f3ed3633ba3596", "target": 0, "func": "static int decode_subframe_fixed(FLACContext *s, int channel, int pred_order)\n\n{\n\n    int i;\n\n        \n\n    av_log(s->avctx, AV_LOG_DEBUG, \"  SUBFRAME FIXED\\n\");\n\n        \n\n    /* warm up samples */\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"   warm up samples: %d\\n\", pred_order);\n\n        \n\n    for (i = 0; i < pred_order; i++)\n\n    {\n\n        s->decoded[channel][i] = get_sbits(&s->gb, s->curr_bps);\n\n//        av_log(s->avctx, AV_LOG_DEBUG, \"    %d: %d\\n\", i, s->decoded[channel][i]);\n\n    }\n\n    \n\n    if (decode_residuals(s, channel, pred_order) < 0)\n\n        return -1;\n\n\n\n    switch(pred_order)\n\n    {\n\n        case 0:\n\n            break;\n\n        case 1:\n\n            for (i = pred_order; i < s->blocksize; i++)\n\n                s->decoded[channel][i] +=   s->decoded[channel][i-1];\n\n            break;\n\n        case 2:\n\n            for (i = pred_order; i < s->blocksize; i++)\n\n                s->decoded[channel][i] += 2*s->decoded[channel][i-1]\n\n                                          - s->decoded[channel][i-2];\n\n            break;\n\n        case 3:\n\n            for (i = pred_order; i < s->blocksize; i++)\n\n                s->decoded[channel][i] += 3*s->decoded[channel][i-1] \n\n                                        - 3*s->decoded[channel][i-2]\n\n                                        +   s->decoded[channel][i-3];\n\n            break;\n\n        case 4:\n\n            for (i = pred_order; i < s->blocksize; i++)\n\n                s->decoded[channel][i] += 4*s->decoded[channel][i-1] \n\n                                        - 6*s->decoded[channel][i-2]\n\n                                        + 4*s->decoded[channel][i-3]\n\n                                        -   s->decoded[channel][i-4];\n\n            break;\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"illegal pred order %d\\n\", pred_order);\n\n            return -1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 27163}
{"project": "FFmpeg", "commit_id": "b6db385922b79939b0dc124d53ddb4824afac040", "target": 0, "func": "static int v4l2_set_parameters(AVFormatContext *s1, AVFormatParameters *ap)\n\n{\n\n    struct video_data *s = s1->priv_data;\n\n    struct v4l2_input input;\n\n    struct v4l2_standard standard;\n\n    struct v4l2_streamparm streamparm = { 0 };\n\n    struct v4l2_fract *tpf = &streamparm.parm.capture.timeperframe;\n\n    int i, ret;\n\n    AVRational framerate_q;\n\n\n\n    streamparm.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;\n\n\n\n    if (s->framerate &&\n\n        (ret = av_parse_video_rate(&framerate_q, s->framerate)) < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"Could not parse framerate '%s'.\\n\",\n\n               s->framerate);\n\n        return ret;\n\n    }\n\n\n\n    /* set tv video input */\n\n    memset (&input, 0, sizeof (input));\n\n    input.index = s->channel;\n\n    if (ioctl(s->fd, VIDIOC_ENUMINPUT, &input) < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"The V4L2 driver ioctl enum input failed:\\n\");\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    av_log(s1, AV_LOG_DEBUG, \"The V4L2 driver set input_id: %d, input: %s\\n\",\n\n            s->channel, input.name);\n\n    if (ioctl(s->fd, VIDIOC_S_INPUT, &input.index) < 0) {\n\n        av_log(s1, AV_LOG_ERROR,\n\n               \"The V4L2 driver ioctl set input(%d) failed\\n\",\n\n                s->channel);\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    if (s->standard) {\n\n        av_log(s1, AV_LOG_DEBUG, \"The V4L2 driver set standard: %s\\n\",\n\n               s->standard);\n\n        /* set tv standard */\n\n        memset (&standard, 0, sizeof (standard));\n\n        for(i=0;;i++) {\n\n            standard.index = i;\n\n            if (ioctl(s->fd, VIDIOC_ENUMSTD, &standard) < 0) {\n\n                av_log(s1, AV_LOG_ERROR,\n\n                       \"The V4L2 driver ioctl set standard(%s) failed\\n\",\n\n                       s->standard);\n\n                return AVERROR(EIO);\n\n            }\n\n\n\n            if (!av_strcasecmp(standard.name, s->standard)) {\n\n                break;\n\n            }\n\n        }\n\n\n\n        av_log(s1, AV_LOG_DEBUG,\n\n               \"The V4L2 driver set standard: %s, id: %\"PRIu64\"\\n\",\n\n               s->standard, (uint64_t)standard.id);\n\n        if (ioctl(s->fd, VIDIOC_S_STD, &standard.id) < 0) {\n\n            av_log(s1, AV_LOG_ERROR,\n\n                   \"The V4L2 driver ioctl set standard(%s) failed\\n\",\n\n                   s->standard);\n\n            return AVERROR(EIO);\n\n        }\n\n    }\n\n\n\n    if (framerate_q.num && framerate_q.den) {\n\n        av_log(s1, AV_LOG_DEBUG, \"Setting time per frame to %d/%d\\n\",\n\n               framerate_q.den, framerate_q.num);\n\n        tpf->numerator   = framerate_q.den;\n\n        tpf->denominator = framerate_q.num;\n\n\n\n        if (ioctl(s->fd, VIDIOC_S_PARM, &streamparm) != 0) {\n\n            av_log(s1, AV_LOG_ERROR,\n\n                   \"ioctl set time per frame(%d/%d) failed\\n\",\n\n                   framerate_q.den, framerate_q.num);\n\n            return AVERROR(EIO);\n\n        }\n\n\n\n        if (framerate_q.num != tpf->denominator ||\n\n            framerate_q.den != tpf->numerator) {\n\n            av_log(s1, AV_LOG_INFO,\n\n                   \"The driver changed the time per frame from \"\n\n                   \"%d/%d to %d/%d\\n\",\n\n                   framerate_q.den, framerate_q.num,\n\n                   tpf->numerator, tpf->denominator);\n\n        }\n\n    } else {\n\n        if (ioctl(s->fd, VIDIOC_G_PARM, &streamparm) != 0) {\n\n            av_log(s1, AV_LOG_ERROR, \"ioctl(VIDIOC_G_PARM): %s\\n\",\n\n                   strerror(errno));\n\n            return AVERROR(errno);\n\n        }\n\n    }\n\n    s1->streams[0]->codec->time_base.den = tpf->denominator;\n\n    s1->streams[0]->codec->time_base.num = tpf->numerator;\n\n\n\n    s->timeout = 100 +\n\n        av_rescale_q(1, s1->streams[0]->codec->time_base,\n\n                        (AVRational){1, 1000});\n\n\n\n    return 0;\n\n}\n", "idx": 27164}
{"project": "FFmpeg", "commit_id": "0634c5425306547e593bedbbbd2d982d7f0a27cf", "target": 0, "func": "static int aac_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n\n                            const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    AACEncContext *s = avctx->priv_data;\n\n    float **samples = s->planar_samples, *samples2, *la, *overlap;\n\n    ChannelElement *cpe;\n\n    SingleChannelElement *sce;\n\n    IndividualChannelStream *ics;\n\n    int i, its, ch, w, chans, tag, start_ch, ret, frame_bits;\n\n    int target_bits, rate_bits, too_many_bits, too_few_bits;\n\n    int ms_mode = 0, is_mode = 0, tns_mode = 0, pred_mode = 0;\n\n    int chan_el_counter[4];\n\n    FFPsyWindowInfo windows[AAC_MAX_CHANNELS];\n\n\n\n    if (s->last_frame == 2)\n\n        return 0;\n\n\n\n    /* add current frame to queue */\n\n    if (frame) {\n\n        if ((ret = ff_af_queue_add(&s->afq, frame)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    copy_input_samples(s, frame);\n\n    if (s->psypp)\n\n        ff_psy_preprocess(s->psypp, s->planar_samples, s->channels);\n\n\n\n    if (!avctx->frame_number)\n\n        return 0;\n\n\n\n    start_ch = 0;\n\n    for (i = 0; i < s->chan_map[0]; i++) {\n\n        FFPsyWindowInfo* wi = windows + start_ch;\n\n        tag      = s->chan_map[i+1];\n\n        chans    = tag == TYPE_CPE ? 2 : 1;\n\n        cpe      = &s->cpe[i];\n\n        for (ch = 0; ch < chans; ch++) {\n\n            float clip_avoidance_factor;\n\n            sce = &cpe->ch[ch];\n\n            ics = &sce->ics;\n\n            s->cur_channel = start_ch + ch;\n\n            overlap  = &samples[s->cur_channel][0];\n\n            samples2 = overlap + 1024;\n\n            la       = samples2 + (448+64);\n\n            if (!frame)\n\n                la = NULL;\n\n            if (tag == TYPE_LFE) {\n\n                wi[ch].window_type[0] = ONLY_LONG_SEQUENCE;\n\n                wi[ch].window_shape   = 0;\n\n                wi[ch].num_windows    = 1;\n\n                wi[ch].grouping[0]    = 1;\n\n\n\n                /* Only the lowest 12 coefficients are used in a LFE channel.\n\n                 * The expression below results in only the bottom 8 coefficients\n\n                 * being used for 11.025kHz to 16kHz sample rates.\n\n                 */\n\n                ics->num_swb = s->samplerate_index >= 8 ? 1 : 3;\n\n            } else {\n\n                wi[ch] = s->psy.model->window(&s->psy, samples2, la, s->cur_channel,\n\n                                              ics->window_sequence[0]);\n\n            }\n\n            ics->window_sequence[1] = ics->window_sequence[0];\n\n            ics->window_sequence[0] = wi[ch].window_type[0];\n\n            ics->use_kb_window[1]   = ics->use_kb_window[0];\n\n            ics->use_kb_window[0]   = wi[ch].window_shape;\n\n            ics->num_windows        = wi[ch].num_windows;\n\n            ics->swb_sizes          = s->psy.bands    [ics->num_windows == 8];\n\n            ics->num_swb            = tag == TYPE_LFE ? ics->num_swb : s->psy.num_bands[ics->num_windows == 8];\n\n            ics->max_sfb            = FFMIN(ics->max_sfb, ics->num_swb);\n\n            ics->swb_offset         = wi[ch].window_type[0] == EIGHT_SHORT_SEQUENCE ?\n\n                                        ff_swb_offset_128 [s->samplerate_index]:\n\n                                        ff_swb_offset_1024[s->samplerate_index];\n\n            ics->tns_max_bands      = wi[ch].window_type[0] == EIGHT_SHORT_SEQUENCE ?\n\n                                        ff_tns_max_bands_128 [s->samplerate_index]:\n\n                                        ff_tns_max_bands_1024[s->samplerate_index];\n\n            clip_avoidance_factor = 0.0f;\n\n            for (w = 0; w < ics->num_windows; w++)\n\n                ics->group_len[w] = wi[ch].grouping[w];\n\n            for (w = 0; w < ics->num_windows; w++) {\n\n                if (wi[ch].clipping[w] > CLIP_AVOIDANCE_FACTOR) {\n\n                    ics->window_clipping[w] = 1;\n\n                    clip_avoidance_factor = FFMAX(clip_avoidance_factor, wi[ch].clipping[w]);\n\n                } else {\n\n                    ics->window_clipping[w] = 0;\n\n                }\n\n            }\n\n            if (clip_avoidance_factor > CLIP_AVOIDANCE_FACTOR) {\n\n                ics->clip_avoidance_factor = CLIP_AVOIDANCE_FACTOR / clip_avoidance_factor;\n\n            } else {\n\n                ics->clip_avoidance_factor = 1.0f;\n\n            }\n\n\n\n            apply_window_and_mdct(s, sce, overlap);\n\n\n\n            if (s->options.ltp && s->coder->update_ltp) {\n\n                s->coder->update_ltp(s, sce);\n\n                apply_window[sce->ics.window_sequence[0]](s->fdsp, sce, &sce->ltp_state[0]);\n\n                s->mdct1024.mdct_calc(&s->mdct1024, sce->lcoeffs, sce->ret_buf);\n\n            }\n\n\n\n            if (isnan(cpe->ch->coeffs[0])) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Input contains NaN\\n\");\n\n                return AVERROR(EINVAL);\n\n            }\n\n            avoid_clipping(s, sce);\n\n        }\n\n        start_ch += chans;\n\n    }\n\n    if ((ret = ff_alloc_packet2(avctx, avpkt, 8192 * s->channels, 0)) < 0)\n\n        return ret;\n\n    frame_bits = its = 0;\n\n    do {\n\n        init_put_bits(&s->pb, avpkt->data, avpkt->size);\n\n\n\n        if ((avctx->frame_number & 0xFF)==1 && !(avctx->flags & AV_CODEC_FLAG_BITEXACT))\n\n            put_bitstream_info(s, LIBAVCODEC_IDENT);\n\n        start_ch = 0;\n\n        target_bits = 0;\n\n        memset(chan_el_counter, 0, sizeof(chan_el_counter));\n\n        for (i = 0; i < s->chan_map[0]; i++) {\n\n            FFPsyWindowInfo* wi = windows + start_ch;\n\n            const float *coeffs[2];\n\n            tag      = s->chan_map[i+1];\n\n            chans    = tag == TYPE_CPE ? 2 : 1;\n\n            cpe      = &s->cpe[i];\n\n            cpe->common_window = 0;\n\n            memset(cpe->is_mask, 0, sizeof(cpe->is_mask));\n\n            memset(cpe->ms_mask, 0, sizeof(cpe->ms_mask));\n\n            put_bits(&s->pb, 3, tag);\n\n            put_bits(&s->pb, 4, chan_el_counter[tag]++);\n\n            for (ch = 0; ch < chans; ch++) {\n\n                sce = &cpe->ch[ch];\n\n                coeffs[ch] = sce->coeffs;\n\n                sce->ics.predictor_present = 0;\n\n                sce->ics.ltp.present = 0;\n\n                memset(sce->ics.ltp.used, 0, sizeof(sce->ics.ltp.used));\n\n                memset(sce->ics.prediction_used, 0, sizeof(sce->ics.prediction_used));\n\n                memset(&sce->tns, 0, sizeof(TemporalNoiseShaping));\n\n                for (w = 0; w < 128; w++)\n\n                    if (sce->band_type[w] > RESERVED_BT)\n\n                        sce->band_type[w] = 0;\n\n            }\n\n            s->psy.bitres.alloc = -1;\n\n            s->psy.bitres.bits = s->last_frame_pb_count / s->channels;\n\n            s->psy.model->analyze(&s->psy, start_ch, coeffs, wi);\n\n            if (s->psy.bitres.alloc > 0) {\n\n                /* Lambda unused here on purpose, we need to take psy's unscaled allocation */\n\n                target_bits += s->psy.bitres.alloc\n\n                    * (s->lambda / (avctx->global_quality ? avctx->global_quality : 120));\n\n                s->psy.bitres.alloc /= chans;\n\n            }\n\n            s->cur_type = tag;\n\n            for (ch = 0; ch < chans; ch++) {\n\n                s->cur_channel = start_ch + ch;\n\n                if (s->options.pns && s->coder->mark_pns)\n\n                    s->coder->mark_pns(s, avctx, &cpe->ch[ch]);\n\n                s->coder->search_for_quantizers(avctx, s, &cpe->ch[ch], s->lambda);\n\n            }\n\n            if (chans > 1\n\n                && wi[0].window_type[0] == wi[1].window_type[0]\n\n                && wi[0].window_shape   == wi[1].window_shape) {\n\n\n\n                cpe->common_window = 1;\n\n                for (w = 0; w < wi[0].num_windows; w++) {\n\n                    if (wi[0].grouping[w] != wi[1].grouping[w]) {\n\n                        cpe->common_window = 0;\n\n                        break;\n\n                    }\n\n                }\n\n            }\n\n            for (ch = 0; ch < chans; ch++) { /* TNS and PNS */\n\n                sce = &cpe->ch[ch];\n\n                s->cur_channel = start_ch + ch;\n\n                if (s->options.tns && s->coder->search_for_tns)\n\n                    s->coder->search_for_tns(s, sce);\n\n                if (s->options.tns && s->coder->apply_tns_filt)\n\n                    s->coder->apply_tns_filt(s, sce);\n\n                if (sce->tns.present)\n\n                    tns_mode = 1;\n\n                if (s->options.pns && s->coder->search_for_pns)\n\n                    s->coder->search_for_pns(s, avctx, sce);\n\n            }\n\n            s->cur_channel = start_ch;\n\n            if (s->options.intensity_stereo) { /* Intensity Stereo */\n\n                if (s->coder->search_for_is)\n\n                    s->coder->search_for_is(s, avctx, cpe);\n\n                if (cpe->is_mode) is_mode = 1;\n\n                apply_intensity_stereo(cpe);\n\n            }\n\n            if (s->options.pred) { /* Prediction */\n\n                for (ch = 0; ch < chans; ch++) {\n\n                    sce = &cpe->ch[ch];\n\n                    s->cur_channel = start_ch + ch;\n\n                    if (s->options.pred && s->coder->search_for_pred)\n\n                        s->coder->search_for_pred(s, sce);\n\n                    if (cpe->ch[ch].ics.predictor_present) pred_mode = 1;\n\n                }\n\n                if (s->coder->adjust_common_pred)\n\n                    s->coder->adjust_common_pred(s, cpe);\n\n                for (ch = 0; ch < chans; ch++) {\n\n                    sce = &cpe->ch[ch];\n\n                    s->cur_channel = start_ch + ch;\n\n                    if (s->options.pred && s->coder->apply_main_pred)\n\n                        s->coder->apply_main_pred(s, sce);\n\n                }\n\n                s->cur_channel = start_ch;\n\n            }\n\n            if (s->options.mid_side) { /* Mid/Side stereo */\n\n                if (s->options.mid_side == -1 && s->coder->search_for_ms)\n\n                    s->coder->search_for_ms(s, cpe);\n\n                else if (cpe->common_window)\n\n                    memset(cpe->ms_mask, 1, sizeof(cpe->ms_mask));\n\n                apply_mid_side_stereo(cpe);\n\n            }\n\n            adjust_frame_information(cpe, chans);\n\n            if (s->options.ltp) { /* LTP */\n\n                for (ch = 0; ch < chans; ch++) {\n\n                    sce = &cpe->ch[ch];\n\n                    s->cur_channel = start_ch + ch;\n\n                    if (s->coder->search_for_ltp)\n\n                        s->coder->search_for_ltp(s, sce, cpe->common_window);\n\n                    if (sce->ics.ltp.present) pred_mode = 1;\n\n                }\n\n                s->cur_channel = start_ch;\n\n                if (s->coder->adjust_common_ltp)\n\n                    s->coder->adjust_common_ltp(s, cpe);\n\n            }\n\n            if (chans == 2) {\n\n                put_bits(&s->pb, 1, cpe->common_window);\n\n                if (cpe->common_window) {\n\n                    put_ics_info(s, &cpe->ch[0].ics);\n\n                    if (s->coder->encode_main_pred)\n\n                        s->coder->encode_main_pred(s, &cpe->ch[0]);\n\n                    if (s->coder->encode_ltp_info)\n\n                        s->coder->encode_ltp_info(s, &cpe->ch[0], 1);\n\n                    encode_ms_info(&s->pb, cpe);\n\n                    if (cpe->ms_mode) ms_mode = 1;\n\n                }\n\n            }\n\n            for (ch = 0; ch < chans; ch++) {\n\n                s->cur_channel = start_ch + ch;\n\n                encode_individual_channel(avctx, s, &cpe->ch[ch], cpe->common_window);\n\n            }\n\n            start_ch += chans;\n\n        }\n\n\n\n        if (avctx->flags & CODEC_FLAG_QSCALE) {\n\n            /* When using a constant Q-scale, don't mess with lambda */\n\n            break;\n\n        }\n\n\n\n        /* rate control stuff\n\n         * allow between the nominal bitrate, and what psy's bit reservoir says to target\n\n         * but drift towards the nominal bitrate always\n\n         */\n\n        frame_bits = put_bits_count(&s->pb);\n\n        rate_bits = avctx->bit_rate * 1024 / avctx->sample_rate;\n\n        rate_bits = FFMIN(rate_bits, 6144 * s->channels - 3);\n\n        too_many_bits = FFMAX(target_bits, rate_bits);\n\n        too_many_bits = FFMIN(too_many_bits, 6144 * s->channels - 3);\n\n        too_few_bits = FFMIN(FFMAX(rate_bits - rate_bits/4, target_bits), too_many_bits);\n\n\n\n        /* When using ABR, be strict (but only for increasing) */\n\n        too_few_bits = too_few_bits - too_few_bits/8;\n\n        too_many_bits = too_many_bits + too_many_bits/2;\n\n\n\n        if (   its == 0 /* for steady-state Q-scale tracking */\n\n            || (its < 5 && (frame_bits < too_few_bits || frame_bits > too_many_bits))\n\n            || frame_bits >= 6144 * s->channels - 3  )\n\n        {\n\n            float ratio = ((float)rate_bits) / frame_bits;\n\n\n\n            if (frame_bits >= too_few_bits && frame_bits <= too_many_bits) {\n\n                /*\n\n                 * This path is for steady-state Q-scale tracking\n\n                 * When frame bits fall within the stable range, we still need to adjust\n\n                 * lambda to maintain it like so in a stable fashion (large jumps in lambda\n\n                 * create artifacts and should be avoided), but slowly\n\n                 */\n\n                ratio = sqrtf(sqrtf(ratio));\n\n                ratio = av_clipf(ratio, 0.9f, 1.1f);\n\n            } else {\n\n                /* Not so fast though */\n\n                ratio = sqrtf(ratio);\n\n            }\n\n            s->lambda = FFMIN(s->lambda * ratio, 65536.f);\n\n\n\n            /* Keep iterating if we must reduce and lambda is in the sky */\n\n            if (ratio > 0.9f && ratio < 1.1f) {\n\n                break;\n\n            } else {\n\n                if (is_mode || ms_mode || tns_mode || pred_mode) {\n\n                    for (i = 0; i < s->chan_map[0]; i++) {\n\n                        // Must restore coeffs\n\n                        chans = tag == TYPE_CPE ? 2 : 1;\n\n                        cpe = &s->cpe[i];\n\n                        for (ch = 0; ch < chans; ch++)\n\n                            memcpy(cpe->ch[ch].coeffs, cpe->ch[ch].pcoeffs, sizeof(cpe->ch[ch].coeffs));\n\n                    }\n\n                }\n\n                its++;\n\n            }\n\n        } else {\n\n            break;\n\n        }\n\n    } while (1);\n\n\n\n    if (s->options.ltp && s->coder->ltp_insert_new_frame)\n\n        s->coder->ltp_insert_new_frame(s);\n\n\n\n    put_bits(&s->pb, 3, TYPE_END);\n\n    flush_put_bits(&s->pb);\n\n\n\n    s->last_frame_pb_count = put_bits_count(&s->pb);\n\n\n\n    s->lambda_sum += s->lambda;\n\n    s->lambda_count++;\n\n\n\n    if (!frame)\n\n        s->last_frame++;\n\n\n\n    ff_af_queue_remove(&s->afq, avctx->frame_size, &avpkt->pts,\n\n                       &avpkt->duration);\n\n\n\n    avpkt->size = put_bits_count(&s->pb) >> 3;\n\n    *got_packet_ptr = 1;\n\n    return 0;\n\n}\n", "idx": 27165}
{"project": "FFmpeg", "commit_id": "64b164f44abc232dbb125b36e2d00b54e1531ba7", "target": 1, "func": "static AVFilterContext *parse_filter(const char **buf, AVFilterGraph *graph,\n\n                                     int index, AVClass *log_ctx)\n\n{\n\n    char *opts = NULL;\n\n    char *name = consume_string(buf);\n\n\n\n    if(**buf == '=') {\n\n        (*buf)++;\n\n        opts = consume_string(buf);\n\n    }\n\n\n\n    return create_filter(graph, index, name, opts, log_ctx);\n\n}\n", "idx": 27173}
{"project": "FFmpeg", "commit_id": "dec2fa8cc7089605d1d934d65dd2709cfe8aece2", "target": 1, "func": "static AVCodec *AVCodecInitialize(enum AVCodecID codec_id)\n\n{\n\n    AVCodec *res;\n\n    avcodec_register_all();\n\n    av_log_set_level(AV_LOG_PANIC);\n\n    res = avcodec_find_decoder(codec_id);\n\n    if (!res)\n\n        error(\"Failed to find decoder\");\n\n    return res;\n\n}\n", "idx": 27174}
{"project": "FFmpeg", "commit_id": "38c48be213b86baa04e64762622afefbba1afa70", "target": 0, "func": "static int mpegts_read_packet(AVFormatContext *s,\n\n                              AVPacket *pkt)\n\n{\n\n    MpegTSContext *ts = s->priv_data;\n\n\n\n    if (!ts->mpeg2ts_raw) {\n\n        ts->pkt = pkt;\n\n        return handle_packets(ts, 0);\n\n    } else {\n\n        return mpegts_raw_read_packet(s, pkt);\n\n    }\n\n}\n", "idx": 27183}
{"project": "FFmpeg", "commit_id": "1dc42050185d63c1de5d16146fbaee92640af187", "target": 0, "func": "static int start_frame(AVFilterLink *link, AVFilterBufferRef *picref)\n\n{\n\n    AVFilterContext *ctx = link->dst;\n\n    YADIFContext *yadif = ctx->priv;\n\n\n\n    if (yadif->frame_pending)\n\n        return_frame(ctx, 1);\n\n\n\n    if (yadif->prev)\n\n        avfilter_unref_buffer(yadif->prev);\n\n    yadif->prev = yadif->cur;\n\n    yadif->cur  = yadif->next;\n\n    yadif->next = picref;\n\n\n\n    if (!yadif->cur)\n\n        return 0;\n\n\n\n    if (yadif->auto_enable && !yadif->cur->video->interlaced) {\n\n        yadif->out  = avfilter_ref_buffer(yadif->cur, AV_PERM_READ);\n\n        avfilter_unref_bufferp(&yadif->prev);\n\n        if (yadif->out->pts != AV_NOPTS_VALUE)\n\n            yadif->out->pts *= 2;\n\n        return ff_start_frame(ctx->outputs[0], yadif->out);\n\n    }\n\n\n\n    if (!yadif->prev)\n\n        yadif->prev = avfilter_ref_buffer(yadif->cur, AV_PERM_READ);\n\n\n\n    yadif->out = ff_get_video_buffer(ctx->outputs[0], AV_PERM_WRITE | AV_PERM_PRESERVE |\n\n                                     AV_PERM_REUSE, link->w, link->h);\n\n\n\n    avfilter_copy_buffer_ref_props(yadif->out, yadif->cur);\n\n    yadif->out->video->interlaced = 0;\n\n    if (yadif->out->pts != AV_NOPTS_VALUE)\n\n        yadif->out->pts *= 2;\n\n    return ff_start_frame(ctx->outputs[0], yadif->out);\n\n}\n", "idx": 27194}
{"project": "FFmpeg", "commit_id": "83fd377c94d8fbffdb3e69fb3efe1976ff897a88", "target": 0, "func": "static void truncpasses(Jpeg2000EncoderContext *s, Jpeg2000Tile *tile)\n\n{\n\n    int precno, compno, reslevelno, bandno, cblkno, lev;\n\n    Jpeg2000CodingStyle *codsty = &s->codsty;\n\n\n\n    for (compno = 0; compno < s->ncomponents; compno++){\n\n        Jpeg2000Component *comp = tile->comp + compno;\n\n\n\n        for (reslevelno = 0, lev = codsty->nreslevels-1; reslevelno < codsty->nreslevels; reslevelno++, lev--){\n\n            Jpeg2000ResLevel *reslevel = comp->reslevel + reslevelno;\n\n\n\n            for (precno = 0; precno < reslevel->num_precincts_x * reslevel->num_precincts_y; precno++){\n\n                for (bandno = 0; bandno < reslevel->nbands ; bandno++){\n\n                    int bandpos = bandno + (reslevelno > 0);\n\n                    Jpeg2000Band *band = reslevel->band + bandno;\n\n                    Jpeg2000Prec *prec = band->prec + precno;\n\n\n\n                    for (cblkno = 0; cblkno < prec->nb_codeblocks_height * prec->nb_codeblocks_width; cblkno++){\n\n                        Jpeg2000Cblk *cblk = prec->cblk + cblkno;\n\n\n\n                        cblk->ninclpasses = getcut(cblk, s->lambda,\n\n                                (int64_t)dwt_norms[codsty->transform][bandpos][lev] * (int64_t)band->i_stepsize >> 16);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 27195}
{"project": "FFmpeg", "commit_id": "65d3359fb366ea265a8468d76a111cb7352f0b55", "target": 1, "func": "static int init_tile(Jpeg2000DecoderContext *s, int tileno)\n\n{\n\n    int compno;\n\n    int tilex = tileno % s->numXtiles;\n\n    int tiley = tileno / s->numXtiles;\n\n    Jpeg2000Tile *tile = s->tile + tileno;\n\n\n\n    if (!tile->comp)\n\n        return AVERROR(ENOMEM);\n\n\n\n    tile->coord[0][0] = av_clip(tilex       * s->tile_width  + s->tile_offset_x, s->image_offset_x, s->width);\n\n    tile->coord[0][1] = av_clip((tilex + 1) * s->tile_width  + s->tile_offset_x, s->image_offset_x, s->width);\n\n    tile->coord[1][0] = av_clip(tiley       * s->tile_height + s->tile_offset_y, s->image_offset_y, s->height);\n\n    tile->coord[1][1] = av_clip((tiley + 1) * s->tile_height + s->tile_offset_y, s->image_offset_y, s->height);\n\n\n\n    for (compno = 0; compno < s->ncomponents; compno++) {\n\n        Jpeg2000Component *comp = tile->comp + compno;\n\n        Jpeg2000CodingStyle *codsty = tile->codsty + compno;\n\n        Jpeg2000QuantStyle  *qntsty = tile->qntsty + compno;\n\n        int ret; // global bandno\n\n\n\n        comp->coord_o[0][0] = tile->coord[0][0];\n\n        comp->coord_o[0][1] = tile->coord[0][1];\n\n        comp->coord_o[1][0] = tile->coord[1][0];\n\n        comp->coord_o[1][1] = tile->coord[1][1];\n\n        if (compno) {\n\n            comp->coord_o[0][0] /= s->cdx[compno];\n\n            comp->coord_o[0][1] /= s->cdx[compno];\n\n            comp->coord_o[1][0] /= s->cdy[compno];\n\n            comp->coord_o[1][1] /= s->cdy[compno];\n\n        }\n\n\n\n        comp->coord[0][0] = ff_jpeg2000_ceildivpow2(comp->coord_o[0][0], s->reduction_factor);\n\n        comp->coord[0][1] = ff_jpeg2000_ceildivpow2(comp->coord_o[0][1], s->reduction_factor);\n\n        comp->coord[1][0] = ff_jpeg2000_ceildivpow2(comp->coord_o[1][0], s->reduction_factor);\n\n        comp->coord[1][1] = ff_jpeg2000_ceildivpow2(comp->coord_o[1][1], s->reduction_factor);\n\n\n\n        if (ret = ff_jpeg2000_init_component(comp, codsty, qntsty,\n\n                                             s->cbps[compno], s->cdx[compno],\n\n                                             s->cdy[compno], s->avctx))\n\n            return ret;\n\n    }\n\n    return 0;\n\n}\n", "idx": 27197}
{"project": "FFmpeg", "commit_id": "e56b0984103b981ec25fe8a22ef9c4905b9751dd", "target": 1, "func": "static int srt_write_packet(AVFormatContext *avf, AVPacket *pkt)\n\n{\n\n    SRTContext *srt = avf->priv_data;\n\n    int write_ts = avf->streams[0]->codec->codec_id != AV_CODEC_ID_SRT;\n\n\n\n    srt->index++;\n\n    if (write_ts) {\n\n        int64_t s = pkt->pts, e, d = pkt->duration;\n\n\n\n        if (d <= 0)\n\n            /* For backward compatibility, fallback to convergence_duration. */\n\n            d = pkt->convergence_duration;\n\n        if (s == AV_NOPTS_VALUE || d < 0) {\n\n            av_log(avf, AV_LOG_ERROR, \"Insufficient timestamps.\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n        e = s + d;\n\n        avio_printf(avf->pb, \"%d\\n%02d:%02d:%02d,%03d --> %02d:%02d:%02d,%03d\\n\",\n\n                       srt->index,\n\n                       (int)(s / 3600000),      (int)(s / 60000) % 60,\n\n                       (int)(s /    1000) % 60, (int)(s %  1000),\n\n                       (int)(e / 3600000),      (int)(e / 60000) % 60,\n\n                       (int)(e /    1000) % 60, (int)(e %  1000));\n\n    }\n\n    avio_write(avf->pb, pkt->data, pkt->size);\n\n    if (write_ts)\n\n        avio_write(avf->pb, \"\\n\\n\", 2);\n\n    avio_flush(avf->pb);\n\n    return 0;\n\n}\n", "idx": 27198}
{"project": "FFmpeg", "commit_id": "f6b7f72461673e4d398b1edf9ed2a7fe70d99c47", "target": 0, "func": "static void av_always_inline filter_mb_edgeh( uint8_t *pix, int stride, const int16_t bS[4], unsigned int qp, H264Context *h, int intra ) {\n\n    const int qp_bd_offset = 6 * (h->sps.bit_depth_luma - 8);\n\n    const unsigned int index_a = qp - qp_bd_offset + h->slice_alpha_c0_offset;\n\n    const int alpha = alpha_table[index_a];\n\n    const int beta  = beta_table[qp - qp_bd_offset + h->slice_beta_offset];\n\n    if (alpha ==0 || beta == 0) return;\n\n\n\n    if( bS[0] < 4 || !intra ) {\n\n        int8_t tc[4];\n\n        tc[0] = tc0_table[index_a][bS[0]];\n\n        tc[1] = tc0_table[index_a][bS[1]];\n\n        tc[2] = tc0_table[index_a][bS[2]];\n\n        tc[3] = tc0_table[index_a][bS[3]];\n\n        h->h264dsp.h264_v_loop_filter_luma(pix, stride, alpha, beta, tc);\n\n    } else {\n\n        h->h264dsp.h264_v_loop_filter_luma_intra(pix, stride, alpha, beta);\n\n    }\n\n}\n", "idx": 27199}
{"project": "FFmpeg", "commit_id": "bcaf64b605442e1622d16da89d4ec0e7730b8a8c", "target": 0, "func": "static int flac_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n\n                             const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    FlacEncodeContext *s;\n\n    int frame_bytes, out_bytes, ret;\n\n\n\n    s = avctx->priv_data;\n\n\n\n    /* when the last block is reached, update the header in extradata */\n\n    if (!frame) {\n\n        s->max_framesize = s->max_encoded_framesize;\n\n        av_md5_final(s->md5ctx, s->md5sum);\n\n        write_streaminfo(s, avctx->extradata);\n\n        return 0;\n\n    }\n\n\n\n    /* change max_framesize for small final frame */\n\n    if (frame->nb_samples < s->frame.blocksize) {\n\n        s->max_framesize = ff_flac_get_max_frame_size(frame->nb_samples,\n\n                                                      s->channels,\n\n                                                      avctx->bits_per_raw_sample);\n\n    }\n\n\n\n    init_frame(s, frame->nb_samples);\n\n\n\n    copy_samples(s, frame->data[0]);\n\n\n\n    channel_decorrelation(s);\n\n\n\n    remove_wasted_bits(s);\n\n\n\n    frame_bytes = encode_frame(s);\n\n\n\n    /* fallback to verbatim mode if the compressed frame is larger than it\n\n       would be if encoded uncompressed. */\n\n    if (frame_bytes < 0 || frame_bytes > s->max_framesize) {\n\n        s->frame.verbatim_only = 1;\n\n        frame_bytes = encode_frame(s);\n\n        if (frame_bytes < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Bad frame count\\n\");\n\n            return frame_bytes;\n\n        }\n\n    }\n\n\n\n    if ((ret = ff_alloc_packet2(avctx, avpkt, frame_bytes)))\n\n        return ret;\n\n\n\n    out_bytes = write_frame(s, avpkt);\n\n\n\n    s->frame_count++;\n\n    s->sample_count += frame->nb_samples;\n\n    if ((ret = update_md5_sum(s, frame->data[0])) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error updating MD5 checksum\\n\");\n\n        return ret;\n\n    }\n\n    if (out_bytes > s->max_encoded_framesize)\n\n        s->max_encoded_framesize = out_bytes;\n\n    if (out_bytes < s->min_framesize)\n\n        s->min_framesize = out_bytes;\n\n\n\n    avpkt->pts      = frame->pts;\n\n    avpkt->duration = ff_samples_to_time_base(avctx, frame->nb_samples);\n\n    avpkt->size     = out_bytes;\n\n    *got_packet_ptr = 1;\n\n    return 0;\n\n}\n", "idx": 27200}
{"project": "FFmpeg", "commit_id": "e13f860ac8a5a7d803059d1553773cf2a446d3f2", "target": 0, "func": "static int decode_vol_header(MpegEncContext *s, GetBitContext *gb){\n\n    int width, height, vo_ver_id;\n\n\n\n    /* vol header */\n\n    skip_bits(gb, 1); /* random access */\n\n    s->vo_type= get_bits(gb, 8);\n\n    if (get_bits1(gb) != 0) { /* is_ol_id */\n\n        vo_ver_id = get_bits(gb, 4); /* vo_ver_id */\n\n        skip_bits(gb, 3); /* vo_priority */\n\n    } else {\n\n        vo_ver_id = 1;\n\n    }\n\n//printf(\"vo type:%d\\n\",s->vo_type);\n\n    s->aspect_ratio_info= get_bits(gb, 4);\n\n    if(s->aspect_ratio_info == FF_ASPECT_EXTENDED){\t    \n\n        s->aspected_width = get_bits(gb, 8); // par_width\n\n        s->aspected_height = get_bits(gb, 8); // par_height\n\n    }else{\n\n        s->aspected_width = pixel_aspect[s->aspect_ratio_info][0];\n\n        s->aspected_height= pixel_aspect[s->aspect_ratio_info][1];\n\n    }\n\n\n\n    if ((s->vol_control_parameters=get_bits1(gb))) { /* vol control parameter */\n\n        int chroma_format= get_bits(gb, 2);\n\n        if(chroma_format!=1){\n\n            printf(\"illegal chroma format\\n\");\n\n        }\n\n        s->low_delay= get_bits1(gb);\n\n        if(get_bits1(gb)){ /* vbv parameters */\n\n            get_bits(gb, 15);\t/* first_half_bitrate */\n\n            skip_bits1(gb);\t/* marker */\n\n            get_bits(gb, 15);\t/* latter_half_bitrate */\n\n            skip_bits1(gb);\t/* marker */\n\n            get_bits(gb, 15);\t/* first_half_vbv_buffer_size */\n\n            skip_bits1(gb);\t/* marker */\n\n            get_bits(gb, 3);\t/* latter_half_vbv_buffer_size */\n\n            get_bits(gb, 11);\t/* first_half_vbv_occupancy */\n\n            skip_bits1(gb);\t/* marker */\n\n            get_bits(gb, 15);\t/* latter_half_vbv_occupancy */\n\n            skip_bits1(gb);\t/* marker */               \n\n        }\n\n    }else{\n\n        // set low delay flag only once so the smart? low delay detection wont be overriden\n\n        if(s->picture_number==0)\n\n            s->low_delay=0;\n\n    }\n\n\n\n    s->shape = get_bits(gb, 2); /* vol shape */\n\n    if(s->shape != RECT_SHAPE) printf(\"only rectangular vol supported\\n\");\n\n    if(s->shape == GRAY_SHAPE && vo_ver_id != 1){\n\n        printf(\"Gray shape not supported\\n\");\n\n        skip_bits(gb, 4);  //video_object_layer_shape_extension\n\n    }\n\n\n\n    skip_bits1(gb);   /* marker */\n\n    \n\n    s->time_increment_resolution = get_bits(gb, 16);\n\n    \n\n    s->time_increment_bits = av_log2(s->time_increment_resolution - 1) + 1;\n\n    if (s->time_increment_bits < 1)\n\n        s->time_increment_bits = 1;\n\n    skip_bits1(gb);   /* marker */\n\n\n\n    if (get_bits1(gb) != 0) {   /* fixed_vop_rate  */\n\n        skip_bits(gb, s->time_increment_bits);\n\n    }\n\n\n\n    if (s->shape != BIN_ONLY_SHAPE) {\n\n        if (s->shape == RECT_SHAPE) {\n\n            skip_bits1(gb);   /* marker */\n\n            width = get_bits(gb, 13);\n\n            skip_bits1(gb);   /* marker */\n\n            height = get_bits(gb, 13);\n\n            skip_bits1(gb);   /* marker */\n\n            if(width && height){ /* they should be non zero but who knows ... */\n\n                s->width = width;\n\n                s->height = height;\n\n//                printf(\"width/height: %d %d\\n\", width, height);\n\n            }\n\n        }\n\n        \n\n        s->progressive_sequence= get_bits1(gb)^1;\n\n        if(!get_bits1(gb)) printf(\"OBMC not supported (very likely buggy encoder)\\n\");   /* OBMC Disable */\n\n        if (vo_ver_id == 1) {\n\n            s->vol_sprite_usage = get_bits1(gb); /* vol_sprite_usage */\n\n        } else {\n\n            s->vol_sprite_usage = get_bits(gb, 2); /* vol_sprite_usage */\n\n        }\n\n        if(s->vol_sprite_usage==STATIC_SPRITE) printf(\"Static Sprites not supported\\n\");\n\n        if(s->vol_sprite_usage==STATIC_SPRITE || s->vol_sprite_usage==GMC_SPRITE){\n\n            if(s->vol_sprite_usage==STATIC_SPRITE){\n\n                s->sprite_width = get_bits(gb, 13);\n\n                skip_bits1(gb); /* marker */\n\n                s->sprite_height= get_bits(gb, 13);\n\n                skip_bits1(gb); /* marker */\n\n                s->sprite_left  = get_bits(gb, 13);\n\n                skip_bits1(gb); /* marker */\n\n                s->sprite_top   = get_bits(gb, 13);\n\n                skip_bits1(gb); /* marker */\n\n            }\n\n            s->num_sprite_warping_points= get_bits(gb, 6);\n\n            s->sprite_warping_accuracy = get_bits(gb, 2);\n\n            s->sprite_brightness_change= get_bits1(gb);\n\n            if(s->vol_sprite_usage==STATIC_SPRITE)\n\n                s->low_latency_sprite= get_bits1(gb);            \n\n        }\n\n        // FIXME sadct disable bit if verid!=1 && shape not rect\n\n        \n\n        if (get_bits1(gb) == 1) {   /* not_8_bit */\n\n            s->quant_precision = get_bits(gb, 4); /* quant_precision */\n\n            if(get_bits(gb, 4)!=8) printf(\"N-bit not supported\\n\"); /* bits_per_pixel */\n\n            if(s->quant_precision!=5) printf(\"quant precission %d\\n\", s->quant_precision);\n\n        } else {\n\n            s->quant_precision = 5;\n\n        }\n\n        \n\n        // FIXME a bunch of grayscale shape things\n\n\n\n        if((s->mpeg_quant=get_bits1(gb))){ /* vol_quant_type */\n\n            int i, v;\n\n            \n\n            /* load default matrixes */\n\n            for(i=0; i<64; i++){\n\n                int j= s->dsp.idct_permutation[i];\n\n                v= ff_mpeg4_default_intra_matrix[i];\n\n                s->intra_matrix[j]= v;\n\n                s->chroma_intra_matrix[j]= v;\n\n                \n\n                v= ff_mpeg4_default_non_intra_matrix[i];\n\n                s->inter_matrix[j]= v;\n\n                s->chroma_inter_matrix[j]= v;\n\n            }\n\n\n\n            /* load custom intra matrix */\n\n            if(get_bits1(gb)){\n\n                int last=0;\n\n\t\tfor(i=0; i<64; i++){\n\n                    int j;\n\n                    v= get_bits(gb, 8);\n\n                    if(v==0) break;\n\n                    \n\n                    last= v;\n\n                    j= s->dsp.idct_permutation[ ff_zigzag_direct[i] ];\n\n                    s->intra_matrix[j]= v;\n\n                    s->chroma_intra_matrix[j]= v;\n\n                }\n\n\n\n                /* replicate last value */\n\n                for(; i<64; i++){\n\n\t\t    int j= s->dsp.idct_permutation[ ff_zigzag_direct[i] ];\n\n                    s->intra_matrix[j]= v;\n\n                    s->chroma_intra_matrix[j]= v;\n\n                }\n\n            }\n\n\n\n            /* load custom non intra matrix */\n\n            if(get_bits1(gb)){\n\n                int last=0;\n\n\t\tfor(i=0; i<64; i++){\n\n                    int j;\n\n                    v= get_bits(gb, 8);\n\n                    if(v==0) break;\n\n\n\n                    last= v;\n\n                    j= s->dsp.idct_permutation[ ff_zigzag_direct[i] ];\n\n                    s->inter_matrix[j]= v;\n\n                    s->chroma_inter_matrix[j]= v;\n\n                }\n\n\n\n                /* replicate last value */\n\n                for(; i<64; i++){\n\n\t\t    int j= s->dsp.idct_permutation[ ff_zigzag_direct[i] ];\n\n                    s->inter_matrix[j]= last;\n\n                    s->chroma_inter_matrix[j]= last;\n\n                }\n\n            }\n\n\n\n            // FIXME a bunch of grayscale shape things\n\n        }\n\n\n\n        if(vo_ver_id != 1)\n\n             s->quarter_sample= get_bits1(gb);\n\n        else s->quarter_sample=0;\n\n\n\n        if(!get_bits1(gb)) printf(\"Complexity estimation not supported\\n\");\n\n\n\n        s->resync_marker= !get_bits1(gb); /* resync_marker_disabled */\n\n\n\n        s->data_partitioning= get_bits1(gb);\n\n        if(s->data_partitioning){\n\n            s->rvlc= get_bits1(gb);\n\n            if(s->rvlc){\n\n                printf(\"reversible vlc not supported\\n\");\n\n            }\n\n        }\n\n        \n\n        if(vo_ver_id != 1) {\n\n            s->new_pred= get_bits1(gb);\n\n            if(s->new_pred){\n\n                printf(\"new pred not supported\\n\");\n\n                skip_bits(gb, 2); /* requested upstream message type */\n\n                skip_bits1(gb); /* newpred segment type */\n\n            }\n\n            s->reduced_res_vop= get_bits1(gb);\n\n            if(s->reduced_res_vop) printf(\"reduced resolution VOP not supported\\n\");\n\n        }\n\n        else{\n\n            s->new_pred=0;\n\n            s->reduced_res_vop= 0;\n\n        }\n\n\n\n        s->scalability= get_bits1(gb);\n\n\n\n        if (s->scalability) {\n\n            GetBitContext bak= *gb;\n\n            int ref_layer_id;\n\n            int ref_layer_sampling_dir;\n\n            int h_sampling_factor_n;\n\n            int h_sampling_factor_m;\n\n            int v_sampling_factor_n;\n\n            int v_sampling_factor_m;\n\n            \n\n            s->hierachy_type= get_bits1(gb);\n\n            ref_layer_id= get_bits(gb, 4);\n\n            ref_layer_sampling_dir= get_bits1(gb);\n\n            h_sampling_factor_n= get_bits(gb, 5);\n\n            h_sampling_factor_m= get_bits(gb, 5);\n\n            v_sampling_factor_n= get_bits(gb, 5);\n\n            v_sampling_factor_m= get_bits(gb, 5);\n\n            s->enhancement_type= get_bits1(gb);\n\n            \n\n            if(   h_sampling_factor_n==0 || h_sampling_factor_m==0 \n\n               || v_sampling_factor_n==0 || v_sampling_factor_m==0){\n\n               \n\n//                fprintf(stderr, \"illegal scalability header (VERY broken encoder), trying to workaround\\n\");\n\n                s->scalability=0;\n\n               \n\n                *gb= bak;\n\n            }else\n\n                printf(\"scalability not supported\\n\");\n\n            \n\n            // bin shape stuff FIXME\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 27201}
{"project": "FFmpeg", "commit_id": "daa1ea049a9445b7bed03963cb789497065dd1eb", "target": 0, "func": "void ff_vp3_v_loop_filter_mmx(uint8_t *src, int stride, int *bounding_values)\n\n{\n\n    __asm__ volatile(\n\n        \"movq          %0, %%mm6 \\n\\t\"\n\n        \"movq          %1, %%mm4 \\n\\t\"\n\n        \"movq          %2, %%mm2 \\n\\t\"\n\n        \"movq          %3, %%mm1 \\n\\t\"\n\n\n\n        VP3_LOOP_FILTER(%4)\n\n\n\n        \"movq       %%mm4, %1    \\n\\t\"\n\n        \"movq       %%mm3, %2    \\n\\t\"\n\n\n\n        : \"+m\" (*(uint64_t*)(src - 2*stride)),\n\n          \"+m\" (*(uint64_t*)(src - 1*stride)),\n\n          \"+m\" (*(uint64_t*)(src + 0*stride)),\n\n          \"+m\" (*(uint64_t*)(src + 1*stride))\n\n        : \"m\"(*(uint64_t*)(bounding_values+129))\n\n    );\n\n}\n", "idx": 27202}
{"project": "FFmpeg", "commit_id": "155ec6edf82692bcf3a5f87d2bc697404f4e5aaf", "target": 0, "func": "void ff_init_me(MpegEncContext *s){\n\n    MotionEstContext * const c= &s->me;\n\n    c->avctx= s->avctx;\n\n\n\n    ff_set_cmp(&s->dsp, s->dsp.me_pre_cmp, c->avctx->me_pre_cmp);\n\n    ff_set_cmp(&s->dsp, s->dsp.me_cmp, c->avctx->me_cmp);\n\n    ff_set_cmp(&s->dsp, s->dsp.me_sub_cmp, c->avctx->me_sub_cmp);\n\n    ff_set_cmp(&s->dsp, s->dsp.mb_cmp, c->avctx->mb_cmp);\n\n    \n\n    c->flags    = get_flags(c, 0, c->avctx->me_cmp    &FF_CMP_CHROMA);\n\n    c->sub_flags= get_flags(c, 0, c->avctx->me_sub_cmp&FF_CMP_CHROMA);\n\n    c->mb_flags = get_flags(c, 0, c->avctx->mb_cmp    &FF_CMP_CHROMA);\n\n\n\n/*FIXME s->no_rounding b_type*/\n\n    if(s->flags&CODEC_FLAG_QPEL){\n\n        c->sub_motion_search= qpel_motion_search;\n\n        c->qpel_avg= s->dsp.avg_qpel_pixels_tab;\n\n        if(s->no_rounding) c->qpel_put= s->dsp.put_no_rnd_qpel_pixels_tab;\n\n        else               c->qpel_put= s->dsp.put_qpel_pixels_tab;\n\n    }else{\n\n        if(c->avctx->me_sub_cmp&FF_CMP_CHROMA)\n\n            c->sub_motion_search= hpel_motion_search;\n\n        else if(   c->avctx->me_sub_cmp == FF_CMP_SAD \n\n                && c->avctx->    me_cmp == FF_CMP_SAD \n\n                && c->avctx->    mb_cmp == FF_CMP_SAD)\n\n            c->sub_motion_search= sad_hpel_motion_search; // 2050 vs. 2450 cycles\n\n        else\n\n            c->sub_motion_search= hpel_motion_search;\n\n    }\n\n    c->hpel_avg= s->dsp.avg_pixels_tab;\n\n    if(s->no_rounding) c->hpel_put= s->dsp.put_no_rnd_pixels_tab;\n\n    else               c->hpel_put= s->dsp.put_pixels_tab;\n\n\n\n    if(s->linesize){\n\n        c->stride  = s->linesize; \n\n        c->uvstride= s->uvlinesize;\n\n    }else{\n\n        c->stride  = 16*s->mb_width + 32;\n\n        c->uvstride=  8*s->mb_width + 16;\n\n    }\n\n\n\n    // 8x8 fullpel search would need a 4x4 chroma compare, which we dont have yet, and even if we had the motion estimation code doesnt expect it\n\n    if((c->avctx->me_cmp&FF_CMP_CHROMA) && !s->dsp.me_cmp[2]){\n\n        s->dsp.me_cmp[2]= zero_cmp;\n\n    }\n\n    if((c->avctx->me_sub_cmp&FF_CMP_CHROMA) && !s->dsp.me_sub_cmp[2]){\n\n        s->dsp.me_sub_cmp[2]= zero_cmp;\n\n    }\n\n    c->hpel_put[2][0]= c->hpel_put[2][1]=\n\n    c->hpel_put[2][2]= c->hpel_put[2][3]= zero_hpel;\n\n\n\n    c->temp= c->scratchpad;\n\n}\n", "idx": 27203}
{"project": "FFmpeg", "commit_id": "253d0be6a1ecc343d29ff8e1df0ddf961ab9c772", "target": 0, "func": "static int decode(AVCodecContext *avctx, void *data, int *data_size,\n\n                  AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n\n\n    const uint8_t *buf_end;\n\n    uint8_t       segment_type;\n\n    int           segment_length;\n\n    int i, ret;\n\n\n\n    av_dlog(avctx, \"PGS sub packet:\\n\");\n\n\n\n    for (i = 0; i < buf_size; i++) {\n\n        av_dlog(avctx, \"%02x \", buf[i]);\n\n        if (i % 16 == 15)\n\n            av_dlog(avctx, \"\\n\");\n\n    }\n\n\n\n    if (i & 15)\n\n        av_dlog(avctx, \"\\n\");\n\n\n\n    *data_size = 0;\n\n\n\n    /* Ensure that we have received at a least a segment code and segment length */\n\n    if (buf_size < 3)\n\n        return -1;\n\n\n\n    buf_end = buf + buf_size;\n\n\n\n    /* Step through buffer to identify segments */\n\n    while (buf < buf_end) {\n\n        segment_type   = bytestream_get_byte(&buf);\n\n        segment_length = bytestream_get_be16(&buf);\n\n\n\n        av_dlog(avctx, \"Segment Length %d, Segment Type %x\\n\", segment_length, segment_type);\n\n\n\n        if (segment_type != DISPLAY_SEGMENT && segment_length > buf_end - buf)\n\n            break;\n\n\n\n        switch (segment_type) {\n\n        case PALETTE_SEGMENT:\n\n            parse_palette_segment(avctx, buf, segment_length);\n\n            break;\n\n        case PICTURE_SEGMENT:\n\n            parse_picture_segment(avctx, buf, segment_length);\n\n            break;\n\n        case PRESENTATION_SEGMENT:\n\n            ret = parse_presentation_segment(avctx, buf, segment_length, avpkt->pts);\n\n            if (ret < 0)\n\n                return ret;\n\n            break;\n\n        case WINDOW_SEGMENT:\n\n            /*\n\n             * Window Segment Structure (No new information provided):\n\n             *     2 bytes: Unknown,\n\n             *     2 bytes: X position of subtitle,\n\n             *     2 bytes: Y position of subtitle,\n\n             *     2 bytes: Width of subtitle,\n\n             *     2 bytes: Height of subtitle.\n\n             */\n\n            break;\n\n        case DISPLAY_SEGMENT:\n\n            *data_size = display_end_segment(avctx, data, buf, segment_length);\n\n            break;\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unknown subtitle segment type 0x%x, length %d\\n\",\n\n                   segment_type, segment_length);\n\n            break;\n\n        }\n\n\n\n        buf += segment_length;\n\n    }\n\n\n\n    return buf_size;\n\n}\n", "idx": 27204}
{"project": "FFmpeg", "commit_id": "6ec688e1bc76dd93151cbca1c340162ae4b10d77", "target": 0, "func": "static int mov_finalize_stsd_codec(MOVContext *c, AVIOContext *pb,\n\n                                   AVStream *st, MOVStreamContext *sc)\n\n{\n\n    if (st->codec->codec_type == AVMEDIA_TYPE_AUDIO &&\n\n        !st->codec->sample_rate && sc->time_scale > 1)\n\n        st->codec->sample_rate = sc->time_scale;\n\n\n\n    /* special codec parameters handling */\n\n    switch (st->codec->codec_id) {\n\n#if CONFIG_DV_DEMUXER\n\n    case AV_CODEC_ID_DVAUDIO:\n\n        c->dv_fctx = avformat_alloc_context();\n\n        if (!c->dv_fctx) {\n\n            av_log(c->fc, AV_LOG_ERROR, \"dv demux context alloc error\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        c->dv_demux = avpriv_dv_init_demux(c->dv_fctx);\n\n        if (!c->dv_demux) {\n\n            av_log(c->fc, AV_LOG_ERROR, \"dv demux context init error\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        sc->dv_audio_container = 1;\n\n        st->codec->codec_id    = AV_CODEC_ID_PCM_S16LE;\n\n        break;\n\n#endif\n\n    /* no ifdef since parameters are always those */\n\n    case AV_CODEC_ID_QCELP:\n\n        st->codec->channels = 1;\n\n        // force sample rate for qcelp when not stored in mov\n\n        if (st->codec->codec_tag != MKTAG('Q','c','l','p'))\n\n            st->codec->sample_rate = 8000;\n\n        break;\n\n    case AV_CODEC_ID_AMR_NB:\n\n        st->codec->channels    = 1;\n\n        /* force sample rate for amr, stsd in 3gp does not store sample rate */\n\n        st->codec->sample_rate = 8000;\n\n        break;\n\n    case AV_CODEC_ID_AMR_WB:\n\n        st->codec->channels    = 1;\n\n        st->codec->sample_rate = 16000;\n\n        break;\n\n    case AV_CODEC_ID_MP2:\n\n    case AV_CODEC_ID_MP3:\n\n        /* force type after stsd for m1a hdlr */\n\n        st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n        st->need_parsing      = AVSTREAM_PARSE_FULL;\n\n        break;\n\n    case AV_CODEC_ID_GSM:\n\n    case AV_CODEC_ID_ADPCM_MS:\n\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n\n    case AV_CODEC_ID_ILBC:\n\n        st->codec->block_align = sc->bytes_per_frame;\n\n        break;\n\n    case AV_CODEC_ID_ALAC:\n\n        if (st->codec->extradata_size == 36) {\n\n            st->codec->channels    = AV_RB8 (st->codec->extradata + 21);\n\n            st->codec->sample_rate = AV_RB32(st->codec->extradata + 32);\n\n        }\n\n        break;\n\n    case AV_CODEC_ID_VC1:\n\n        st->need_parsing = AVSTREAM_PARSE_FULL;\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 27205}
{"project": "FFmpeg", "commit_id": "23b203014f5dbd85b75a6b97597be9c877cd3a1b", "target": 1, "func": "static int decode_pic_hdr(IVI45DecContext *ctx, AVCodecContext *avctx)\n\n{\n\n    int             pic_size_indx, i, p;\n\n    IVIPicConfig    pic_conf;\n\n\n\n    if (get_bits(&ctx->gb, 18) != 0x3FFF8) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid picture start code!\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    ctx->prev_frame_type = ctx->frame_type;\n\n    ctx->frame_type      = get_bits(&ctx->gb, 3);\n\n    if (ctx->frame_type == 7) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid frame type: %d\\n\", ctx->frame_type);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n#if IVI4_STREAM_ANALYSER\n\n    if (ctx->frame_type == FRAMETYPE_BIDIR)\n\n        ctx->has_b_frames = 1;\n\n#endif\n\n\n\n    ctx->transp_status = get_bits1(&ctx->gb);\n\n#if IVI4_STREAM_ANALYSER\n\n    if (ctx->transp_status) {\n\n        ctx->has_transp = 1;\n\n    }\n\n#endif\n\n\n\n    /* unknown bit: Mac decoder ignores this bit, XANIM returns error */\n\n    if (get_bits1(&ctx->gb)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Sync bit is set!\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    ctx->data_size = get_bits1(&ctx->gb) ? get_bits(&ctx->gb, 24) : 0;\n\n\n\n    /* null frames don't contain anything else so we just return */\n\n    if (ctx->frame_type >= FRAMETYPE_NULL_FIRST) {\n\n        av_dlog(avctx, \"Null frame encountered!\\n\");\n\n        return 0;\n\n    }\n\n\n\n    /* Check key lock status. If enabled - ignore lock word.         */\n\n    /* Usually we have to prompt the user for the password, but      */\n\n    /* we don't do that because Indeo 4 videos can be decoded anyway */\n\n    if (get_bits1(&ctx->gb)) {\n\n        skip_bits_long(&ctx->gb, 32);\n\n        av_dlog(avctx, \"Password-protected clip!\\n\");\n\n    }\n\n\n\n    pic_size_indx = get_bits(&ctx->gb, 3);\n\n    if (pic_size_indx == IVI4_PIC_SIZE_ESC) {\n\n        pic_conf.pic_height = get_bits(&ctx->gb, 16);\n\n        pic_conf.pic_width  = get_bits(&ctx->gb, 16);\n\n    } else {\n\n        pic_conf.pic_height = ivi4_common_pic_sizes[pic_size_indx * 2 + 1];\n\n        pic_conf.pic_width  = ivi4_common_pic_sizes[pic_size_indx * 2    ];\n\n    }\n\n\n\n    /* Decode tile dimensions. */\n\n    if (get_bits1(&ctx->gb)) {\n\n        pic_conf.tile_height = scale_tile_size(pic_conf.pic_height, get_bits(&ctx->gb, 4));\n\n        pic_conf.tile_width  = scale_tile_size(pic_conf.pic_width,  get_bits(&ctx->gb, 4));\n\n#if IVI4_STREAM_ANALYSER\n\n        ctx->uses_tiling = 1;\n\n#endif\n\n    } else {\n\n        pic_conf.tile_height = pic_conf.pic_height;\n\n        pic_conf.tile_width  = pic_conf.pic_width;\n\n    }\n\n\n\n    /* Decode chroma subsampling. We support only 4:4 aka YVU9. */\n\n    if (get_bits(&ctx->gb, 2)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Only YVU9 picture format is supported!\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    pic_conf.chroma_height = (pic_conf.pic_height + 3) >> 2;\n\n    pic_conf.chroma_width  = (pic_conf.pic_width  + 3) >> 2;\n\n\n\n    /* decode subdivision of the planes */\n\n    pic_conf.luma_bands = decode_plane_subdivision(&ctx->gb);\n\n\n    if (pic_conf.luma_bands)\n\n        pic_conf.chroma_bands = decode_plane_subdivision(&ctx->gb);\n\n    ctx->is_scalable = pic_conf.luma_bands != 1 || pic_conf.chroma_bands != 1;\n\n    if (ctx->is_scalable && (pic_conf.luma_bands != 4 || pic_conf.chroma_bands != 1)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Scalability: unsupported subdivision! Luma bands: %d, chroma bands: %d\\n\",\n\n               pic_conf.luma_bands, pic_conf.chroma_bands);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* check if picture layout was changed and reallocate buffers */\n\n    if (ivi_pic_config_cmp(&pic_conf, &ctx->pic_conf)) {\n\n        if (ff_ivi_init_planes(ctx->planes, &pic_conf)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Couldn't reallocate color planes!\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n\n\n        ctx->pic_conf = pic_conf;\n\n\n\n        /* set default macroblock/block dimensions */\n\n        for (p = 0; p <= 2; p++) {\n\n            for (i = 0; i < (!p ? pic_conf.luma_bands : pic_conf.chroma_bands); i++) {\n\n                ctx->planes[p].bands[i].mb_size  = !p ? (!ctx->is_scalable ? 16 : 8) : 4;\n\n                ctx->planes[p].bands[i].blk_size = !p ? 8 : 4;\n\n            }\n\n        }\n\n\n\n        if (ff_ivi_init_tiles(ctx->planes, ctx->pic_conf.tile_width,\n\n                              ctx->pic_conf.tile_height)) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Couldn't reallocate internal structures!\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n    }\n\n\n\n    ctx->frame_num = get_bits1(&ctx->gb) ? get_bits(&ctx->gb, 20) : 0;\n\n\n\n    /* skip decTimeEst field if present */\n\n    if (get_bits1(&ctx->gb))\n\n        skip_bits(&ctx->gb, 8);\n\n\n\n    /* decode macroblock and block huffman codebooks */\n\n    if (ff_ivi_dec_huff_desc(&ctx->gb, get_bits1(&ctx->gb), IVI_MB_HUFF,  &ctx->mb_vlc,  avctx) ||\n\n        ff_ivi_dec_huff_desc(&ctx->gb, get_bits1(&ctx->gb), IVI_BLK_HUFF, &ctx->blk_vlc, avctx))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    ctx->rvmap_sel = get_bits1(&ctx->gb) ? get_bits(&ctx->gb, 3) : 8;\n\n\n\n    ctx->in_imf = get_bits1(&ctx->gb);\n\n    ctx->in_q   = get_bits1(&ctx->gb);\n\n\n\n    ctx->pic_glob_quant = get_bits(&ctx->gb, 5);\n\n\n\n    /* TODO: ignore this parameter if unused */\n\n    ctx->unknown1 = get_bits1(&ctx->gb) ? get_bits(&ctx->gb, 3) : 0;\n\n\n\n    ctx->checksum = get_bits1(&ctx->gb) ? get_bits(&ctx->gb, 16) : 0;\n\n\n\n    /* skip picture header extension if any */\n\n    while (get_bits1(&ctx->gb)) {\n\n        av_dlog(avctx, \"Pic hdr extension encountered!\\n\");\n\n        skip_bits(&ctx->gb, 8);\n\n    }\n\n\n\n    if (get_bits1(&ctx->gb)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Bad blocks bits encountered!\\n\");\n\n    }\n\n\n\n    align_get_bits(&ctx->gb);\n\n\n\n    return 0;\n\n}", "idx": 27207}
{"project": "FFmpeg", "commit_id": "28f9ab7029bd1a02f659995919f899f84ee7361b", "target": 0, "func": "void ff_vp3_idct_add_altivec(uint8_t *dst, int stride, DCTELEM block[64])\n\n{\n\n    LOAD_ZERO;\n\n    vec_u8 t, vdst;\n\n    vec_s16 vdst_16;\n\n    vec_u8 vdst_mask = vec_mergeh(vec_splat_u8(-1), vec_lvsl(0, dst));\n\n\n\n    IDCT_START\n\n\n\n    IDCT_1D(NOP, NOP)\n\n    TRANSPOSE8(b0, b1, b2, b3, b4, b5, b6, b7);\n\n    IDCT_1D(ADD8, SHIFT4)\n\n\n\n#define ADD(a)\\\n\n    vdst = vec_ld(0, dst);\\\n\n    vdst_16 = (vec_s16)vec_perm(vdst, zero_u8v, vdst_mask);\\\n\n    vdst_16 = vec_adds(a, vdst_16);\\\n\n    t = vec_packsu(vdst_16, vdst_16);\\\n\n    vec_ste((vec_u32)t, 0, (unsigned int *)dst);\\\n\n    vec_ste((vec_u32)t, 4, (unsigned int *)dst);\n\n\n\n    ADD(b0)     dst += stride;\n\n    ADD(b1)     dst += stride;\n\n    ADD(b2)     dst += stride;\n\n    ADD(b3)     dst += stride;\n\n    ADD(b4)     dst += stride;\n\n    ADD(b5)     dst += stride;\n\n    ADD(b6)     dst += stride;\n\n    ADD(b7)\n\n}\n", "idx": 27208}
{"project": "FFmpeg", "commit_id": "c69461d73797e02e7a3ab4316050c241fa91f53f", "target": 1, "func": "static int asf_read_replicated_data(AVFormatContext *s, ASFPacket *asf_pkt)\n\n{\n\n    ASFContext *asf = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int ret;\n\n\n\n    if (!asf_pkt->data_size) {\n\n        asf_pkt->data_size = asf_pkt->size_left = avio_rl32(pb); // read media object size\n\n        if (asf_pkt->data_size <= 0)\n\n            return AVERROR_INVALIDDATA;\n\n        if ((ret = av_new_packet(&asf_pkt->avpkt, asf_pkt->data_size)) < 0)\n\n            return ret;\n\n    } else\n\n        avio_skip(pb, 4); // reading of media object size is already done\n\n    asf_pkt->dts = avio_rl32(pb); // read presentation time\n\n    if (asf->rep_data_len && (asf->rep_data_len >= 8))\n\n        avio_skip(pb, asf->rep_data_len - 8); // skip replicated data\n\n\n\n    return 0;\n\n}\n", "idx": 27210}
{"project": "FFmpeg", "commit_id": "ca203e9985cd2dcf42a0c0853940850d3a8edf3a", "target": 1, "func": "static void calc_thr_3gpp(const FFPsyWindowInfo *wi, const int num_bands, AacPsyChannel *pch,\n\n                          const uint8_t *band_sizes, const float *coefs)\n\n{\n\n    int i, w, g;\n\n    int start = 0;\n\n    for (w = 0; w < wi->num_windows*16; w += 16) {\n\n        for (g = 0; g < num_bands; g++) {\n\n            AacPsyBand *band = &pch->band[w+g];\n\n\n\n            float form_factor = 0.0f;\n\n            float Temp;\n\n            band->energy = 0.0f;\n\n            for (i = 0; i < band_sizes[g]; i++) {\n\n                band->energy += coefs[start+i] * coefs[start+i];\n\n                form_factor  += sqrtf(fabs(coefs[start+i]));\n\n            }\n\n            Temp = band->energy > 0 ? sqrtf((float)band_sizes[g] / band->energy) : 0;\n\n            band->thr      = band->energy * 0.001258925f;\n\n            band->nz_lines = form_factor * sqrtf(Temp);\n\n\n\n            start += band_sizes[g];\n\n        }\n\n    }\n\n}\n", "idx": 27216}
{"project": "FFmpeg", "commit_id": "3d2cd42f8a19460d1fd44771646b4411c3148383", "target": 0, "func": "static int flac_encode_frame(AVCodecContext *avctx, uint8_t *frame,\n\n                             int buf_size, void *data)\n\n{\n\n    FlacEncodeContext *s;\n\n    const int16_t *samples = data;\n\n    int frame_bytes, out_bytes;\n\n\n\n    s = avctx->priv_data;\n\n\n\n    /* when the last block is reached, update the header in extradata */\n\n    if (!data) {\n\n        s->max_framesize = s->max_encoded_framesize;\n\n        av_md5_final(s->md5ctx, s->md5sum);\n\n        write_streaminfo(s, avctx->extradata);\n\n        return 0;\n\n    }\n\n\n\n    /* change max_framesize for small final frame */\n\n    if (avctx->frame_size < s->frame.blocksize) {\n\n        s->max_framesize = ff_flac_get_max_frame_size(avctx->frame_size,\n\n                                                      s->channels, 16);\n\n    }\n\n\n\n    init_frame(s);\n\n\n\n    copy_samples(s, samples);\n\n\n\n    channel_decorrelation(s);\n\n\n\n    frame_bytes = encode_frame(s);\n\n    if (buf_size < frame_bytes) {\n\n        av_log(avctx, AV_LOG_ERROR, \"output buffer too small\\n\");\n\n        return 0;\n\n    }\n\n    out_bytes = write_frame(s, frame, buf_size);\n\n\n\n    /* fallback to verbatim mode if the compressed frame is larger than it\n\n       would be if encoded uncompressed. */\n\n    if (out_bytes > s->max_framesize) {\n\n        s->frame.verbatim_only = 1;\n\n        frame_bytes = encode_frame(s);\n\n        if (buf_size < frame_bytes) {\n\n            av_log(avctx, AV_LOG_ERROR, \"output buffer too small\\n\");\n\n            return 0;\n\n        }\n\n        out_bytes = write_frame(s, frame, buf_size);\n\n    }\n\n\n\n    s->frame_count++;\n\n    avctx->coded_frame->pts = s->sample_count;\n\n    s->sample_count += avctx->frame_size;\n\n    update_md5_sum(s, samples);\n\n    if (out_bytes > s->max_encoded_framesize)\n\n        s->max_encoded_framesize = out_bytes;\n\n    if (out_bytes < s->min_framesize)\n\n        s->min_framesize = out_bytes;\n\n\n\n    return out_bytes;\n\n}\n", "idx": 27217}
{"project": "FFmpeg", "commit_id": "6f1ccca4ae3b93b6a2a820a7a0e72081ab35767c", "target": 0, "func": "static int dnxhd_decode_frame(AVCodecContext *avctx, void *data,\n\n                              int *got_frame, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    DNXHDContext *ctx = avctx->priv_data;\n\n    ThreadFrame frame = { .f = data };\n\n    AVFrame *picture = data;\n\n    int first_field = 1;\n\n    int ret, i;\n\n\n\n    ff_dlog(avctx, \"frame size %d\\n\", buf_size);\n\n\n\ndecode_coding_unit:\n\n    if ((ret = dnxhd_decode_header(ctx, picture, buf, buf_size, first_field)) < 0)\n\n        return ret;\n\n\n\n    if ((avctx->width || avctx->height) &&\n\n        (ctx->width != avctx->width || ctx->height != avctx->height)) {\n\n        av_log(avctx, AV_LOG_WARNING, \"frame size changed: %dx%d -> %dx%d\\n\",\n\n               avctx->width, avctx->height, ctx->width, ctx->height);\n\n        first_field = 1;\n\n    }\n\n    if (avctx->pix_fmt != AV_PIX_FMT_NONE && avctx->pix_fmt != ctx->pix_fmt) {\n\n        av_log(avctx, AV_LOG_WARNING, \"pix_fmt changed: %s -> %s\\n\",\n\n               av_get_pix_fmt_name(avctx->pix_fmt), av_get_pix_fmt_name(ctx->pix_fmt));\n\n        first_field = 1;\n\n    }\n\n\n\n    avctx->pix_fmt = ctx->pix_fmt;\n\n    ret = ff_set_dimensions(avctx, ctx->width, ctx->height);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (first_field) {\n\n        if ((ret = ff_thread_get_buffer(avctx, &frame, 0)) < 0)\n\n            return ret;\n\n        picture->pict_type = AV_PICTURE_TYPE_I;\n\n        picture->key_frame = 1;\n\n    }\n\n\n\n    ctx->buf_size = buf_size - 0x280;\n\n    ctx->buf = buf + 0x280;\n\n    avctx->execute2(avctx, dnxhd_decode_row, picture, NULL, ctx->mb_height);\n\n\n\n    if (first_field && picture->interlaced_frame) {\n\n        buf      += ctx->cid_table->coding_unit_size;\n\n        buf_size -= ctx->cid_table->coding_unit_size;\n\n        first_field = 0;\n\n        goto decode_coding_unit;\n\n    }\n\n\n\n    ret = 0;\n\n    for (i = 0; i < avctx->thread_count; i++) {\n\n        ret += ctx->rows[i].errors;\n\n        ctx->rows[i].errors = 0;\n\n    }\n\n\n\n    if (ret) {\n\n        av_log(ctx->avctx, AV_LOG_ERROR, \"%d lines with errors\\n\", ret);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    *got_frame = 1;\n\n    return avpkt->size;\n\n}\n", "idx": 27218}
{"project": "FFmpeg", "commit_id": "0ecca7a49f8e254c12a3a1de048d738bfbb614c6", "target": 1, "func": "static void encode_gray_bitstream(HYuvContext *s, int count){\n\n    int i;\n\n    \n\n    count/=2;\n\n    if(s->flags&CODEC_FLAG_PASS1){\n\n        for(i=0; i<count; i++){\n\n            s->stats[0][ s->temp[0][2*i  ] ]++;\n\n            s->stats[0][ s->temp[0][2*i+1] ]++;\n\n        }\n\n    }else if(s->context){\n\n        for(i=0; i<count; i++){\n\n            s->stats[0][ s->temp[0][2*i  ] ]++;\n\n            put_bits(&s->pb, s->len[0][ s->temp[0][2*i  ] ], s->bits[0][ s->temp[0][2*i  ] ]);\n\n            s->stats[0][ s->temp[0][2*i+1] ]++;\n\n            put_bits(&s->pb, s->len[0][ s->temp[0][2*i+1] ], s->bits[0][ s->temp[0][2*i+1] ]);\n\n        }\n\n    }else{\n\n        for(i=0; i<count; i++){\n\n            put_bits(&s->pb, s->len[0][ s->temp[0][2*i  ] ], s->bits[0][ s->temp[0][2*i  ] ]);\n\n            put_bits(&s->pb, s->len[0][ s->temp[0][2*i+1] ], s->bits[0][ s->temp[0][2*i+1] ]);\n\n        }\n\n    }\n\n}\n", "idx": 27219}
{"project": "FFmpeg", "commit_id": "53918a1c54b49e76c3ca517e2caada8372995712", "target": 1, "func": "static int dca_exss_parse_asset_header(DCAContext *s)\n\n{\n\n    int header_pos = get_bits_count(&s->gb);\n\n    int header_size;\n\n    int channels;\n\n    int embedded_stereo = 0;\n\n    int embedded_6ch    = 0;\n\n    int drc_code_present;\n\n    int extensions_mask;\n\n    int i, j;\n\n\n\n    if (get_bits_left(&s->gb) < 16)\n\n        return -1;\n\n\n\n    /* We will parse just enough to get to the extensions bitmask with which\n\n     * we can set the profile value. */\n\n\n\n    header_size = get_bits(&s->gb, 9) + 1;\n\n    skip_bits(&s->gb, 3); // asset index\n\n\n\n    if (s->static_fields) {\n\n        if (get_bits1(&s->gb))\n\n            skip_bits(&s->gb, 4); // asset type descriptor\n\n        if (get_bits1(&s->gb))\n\n            skip_bits_long(&s->gb, 24); // language descriptor\n\n\n\n        if (get_bits1(&s->gb)) {\n\n            /* How can one fit 1024 bytes of text here if the maximum value\n\n             * for the asset header size field above was 512 bytes? */\n\n            int text_length = get_bits(&s->gb, 10) + 1;\n\n            if (get_bits_left(&s->gb) < text_length * 8)\n\n                return -1;\n\n            skip_bits_long(&s->gb, text_length * 8); // info text\n\n        }\n\n\n\n        skip_bits(&s->gb, 5); // bit resolution - 1\n\n        skip_bits(&s->gb, 4); // max sample rate code\n\n        channels = get_bits(&s->gb, 8) + 1;\n\n\n\n        if (get_bits1(&s->gb)) { // 1-to-1 channels to speakers\n\n            int spkr_remap_sets;\n\n            int spkr_mask_size = 16;\n\n            int num_spkrs[7];\n\n\n\n            if (channels > 2)\n\n                embedded_stereo = get_bits1(&s->gb);\n\n            if (channels > 6)\n\n                embedded_6ch = get_bits1(&s->gb);\n\n\n\n            if (get_bits1(&s->gb)) {\n\n                spkr_mask_size = (get_bits(&s->gb, 2) + 1) << 2;\n\n                skip_bits(&s->gb, spkr_mask_size); // spkr activity mask\n\n            }\n\n\n\n            spkr_remap_sets = get_bits(&s->gb, 3);\n\n\n\n            for (i = 0; i < spkr_remap_sets; i++) {\n\n                /* std layout mask for each remap set */\n\n                num_spkrs[i] = dca_exss_mask2count(get_bits(&s->gb, spkr_mask_size));\n\n            }\n\n\n\n            for (i = 0; i < spkr_remap_sets; i++) {\n\n                int num_dec_ch_remaps = get_bits(&s->gb, 5) + 1;\n\n                if (get_bits_left(&s->gb) < 0)\n\n                    return -1;\n\n\n\n                for (j = 0; j < num_spkrs[i]; j++) {\n\n                    int remap_dec_ch_mask = get_bits_long(&s->gb, num_dec_ch_remaps);\n\n                    int num_dec_ch = av_popcount(remap_dec_ch_mask);\n\n                    skip_bits_long(&s->gb, num_dec_ch * 5); // remap codes\n\n                }\n\n            }\n\n\n\n        } else {\n\n            skip_bits(&s->gb, 3); // representation type\n\n        }\n\n    }\n\n\n\n    drc_code_present = get_bits1(&s->gb);\n\n    if (drc_code_present)\n\n        get_bits(&s->gb, 8); // drc code\n\n\n\n    if (get_bits1(&s->gb))\n\n        skip_bits(&s->gb, 5); // dialog normalization code\n\n\n\n    if (drc_code_present && embedded_stereo)\n\n        get_bits(&s->gb, 8); // drc stereo code\n\n\n\n    if (s->mix_metadata && get_bits1(&s->gb)) {\n\n        skip_bits(&s->gb, 1); // external mix\n\n        skip_bits(&s->gb, 6); // post mix gain code\n\n\n\n        if (get_bits(&s->gb, 2) != 3) // mixer drc code\n\n            skip_bits(&s->gb, 3); // drc limit\n\n        else\n\n            skip_bits(&s->gb, 8); // custom drc code\n\n\n\n        if (get_bits1(&s->gb)) // channel specific scaling\n\n            for (i = 0; i < s->num_mix_configs; i++)\n\n                skip_bits_long(&s->gb, s->mix_config_num_ch[i] * 6); // scale codes\n\n        else\n\n            skip_bits_long(&s->gb, s->num_mix_configs * 6); // scale codes\n\n\n\n        for (i = 0; i < s->num_mix_configs; i++) {\n\n            if (get_bits_left(&s->gb) < 0)\n\n                return -1;\n\n            dca_exss_skip_mix_coeffs(&s->gb, channels, s->mix_config_num_ch[i]);\n\n            if (embedded_6ch)\n\n                dca_exss_skip_mix_coeffs(&s->gb, 6, s->mix_config_num_ch[i]);\n\n            if (embedded_stereo)\n\n                dca_exss_skip_mix_coeffs(&s->gb, 2, s->mix_config_num_ch[i]);\n\n        }\n\n    }\n\n\n\n    switch (get_bits(&s->gb, 2)) {\n\n    case 0: extensions_mask = get_bits(&s->gb, 12); break;\n\n    case 1: extensions_mask = DCA_EXT_EXSS_XLL;     break;\n\n    case 2: extensions_mask = DCA_EXT_EXSS_LBR;     break;\n\n    case 3: extensions_mask = 0; /* aux coding */   break;\n\n    }\n\n\n\n    /* not parsed further, we were only interested in the extensions mask */\n\n\n\n    if (get_bits_left(&s->gb) < 0)\n\n        return -1;\n\n\n\n    if (get_bits_count(&s->gb) - header_pos > header_size * 8) {\n\n        av_log(s->avctx, AV_LOG_WARNING, \"Asset header size mismatch.\\n\");\n\n        return -1;\n\n    }\n\n    skip_bits_long(&s->gb, header_pos + header_size * 8 - get_bits_count(&s->gb));\n\n\n\n    if (extensions_mask & DCA_EXT_EXSS_XLL)\n\n        s->profile = FF_PROFILE_DTS_HD_MA;\n\n    else if (extensions_mask & (DCA_EXT_EXSS_XBR | DCA_EXT_EXSS_X96 |\n\n                                DCA_EXT_EXSS_XXCH))\n\n        s->profile = FF_PROFILE_DTS_HD_HRA;\n\n\n\n    if (!(extensions_mask & DCA_EXT_CORE))\n\n        av_log(s->avctx, AV_LOG_WARNING, \"DTS core detection mismatch.\\n\");\n\n    if ((extensions_mask & DCA_CORE_EXTS) != s->core_ext_mask)\n\n        av_log(s->avctx, AV_LOG_WARNING,\n\n               \"DTS extensions detection mismatch (%d, %d)\\n\",\n\n               extensions_mask & DCA_CORE_EXTS, s->core_ext_mask);\n\n\n\n    return 0;\n\n}\n", "idx": 27221}
{"project": "FFmpeg", "commit_id": "ed08cbd7b172a1dba74230527ef761aafaf2fcce", "target": 1, "func": "void ff_aac_search_for_ltp(AACEncContext *s, SingleChannelElement *sce,\n\n                           int common_window)\n\n{\n\n    int w, g, w2, i, start = 0, count = 0;\n\n    int saved_bits = -(15 + FFMIN(sce->ics.max_sfb, MAX_LTP_LONG_SFB));\n\n    float *C34 = &s->scoefs[128*0], *PCD = &s->scoefs[128*1];\n\n    float *PCD34 = &s->scoefs[128*2];\n\n    const int max_ltp = FFMIN(sce->ics.max_sfb, MAX_LTP_LONG_SFB);\n\n\n\n    if (sce->ics.window_sequence[0] == EIGHT_SHORT_SEQUENCE) {\n\n        if (sce->ics.ltp.lag) {\n\n            memset(&sce->lcoeffs[0], 0.0f, 3072*sizeof(sce->lcoeffs[0]));\n\n            memset(&sce->ics.ltp, 0, sizeof(LongTermPrediction));\n\n        }\n\n        return;\n\n    }\n\n\n\n    if (!sce->ics.ltp.lag)\n\n        return;\n\n\n\n    for (w = 0; w < sce->ics.num_windows; w += sce->ics.group_len[w]) {\n\n        start = 0;\n\n        for (g = 0;  g < sce->ics.num_swb; g++) {\n\n            int bits1 = 0, bits2 = 0;\n\n            float dist1 = 0.0f, dist2 = 0.0f;\n\n            if (w*16+g > max_ltp) {\n\n                start += sce->ics.swb_sizes[g];\n\n                continue;\n\n            }\n\n            for (w2 = 0; w2 < sce->ics.group_len[w]; w2++) {\n\n                int bits_tmp1, bits_tmp2;\n\n                FFPsyBand *band = &s->psy.ch[s->cur_channel].psy_bands[(w+w2)*16+g];\n\n                for (i = 0; i < sce->ics.swb_sizes[g]; i++)\n\n                    PCD[i] = sce->coeffs[start+(w+w2)*128+i] - sce->lcoeffs[start+(w+w2)*128+i];\n\n                abs_pow34_v(C34,  &sce->coeffs[start+(w+w2)*128],  sce->ics.swb_sizes[g]);\n\n                abs_pow34_v(PCD34, PCD, sce->ics.swb_sizes[g]);\n\n                dist1 += quantize_band_cost(s, &sce->coeffs[start+(w+w2)*128], C34, sce->ics.swb_sizes[g],\n\n                                            sce->sf_idx[(w+w2)*16+g], sce->band_type[(w+w2)*16+g],\n\n                                            s->lambda/band->threshold, INFINITY, &bits_tmp1, NULL, 0);\n\n                dist2 += quantize_band_cost(s, PCD, PCD34, sce->ics.swb_sizes[g],\n\n                                            sce->sf_idx[(w+w2)*16+g],\n\n                                            sce->band_type[(w+w2)*16+g],\n\n                                            s->lambda/band->threshold, INFINITY, &bits_tmp2, NULL, 0);\n\n                bits1 += bits_tmp1;\n\n                bits2 += bits_tmp2;\n\n            }\n\n            if (dist2 < dist1 && bits2 < bits1) {\n\n                for (w2 = 0; w2 < sce->ics.group_len[w]; w2++)\n\n                    for (i = 0; i < sce->ics.swb_sizes[g]; i++)\n\n                        sce->coeffs[start+(w+w2)*128+i] -= sce->lcoeffs[start+(w+w2)*128+i];\n\n                sce->ics.ltp.used[w*16+g] = 1;\n\n                saved_bits += bits1 - bits2;\n\n                count++;\n\n            }\n\n            start += sce->ics.swb_sizes[g];\n\n        }\n\n    }\n\n\n\n    sce->ics.ltp.present = !!count && (saved_bits >= 0);\n\n    sce->ics.predictor_present = !!sce->ics.ltp.present;\n\n\n\n    /* Reset any marked sfbs */\n\n    if (!sce->ics.ltp.present && !!count) {\n\n        for (w = 0; w < sce->ics.num_windows; w += sce->ics.group_len[w]) {\n\n            start = 0;\n\n            for (g = 0;  g < sce->ics.num_swb; g++) {\n\n                if (sce->ics.ltp.used[w*16+g]) {\n\n                    for (w2 = 0; w2 < sce->ics.group_len[w]; w2++) {\n\n                        for (i = 0; i < sce->ics.swb_sizes[g]; i++) {\n\n                            sce->coeffs[start+(w+w2)*128+i] += sce->lcoeffs[start+(w+w2)*128+i];\n\n                        }\n\n                    }\n\n                }\n\n                start += sce->ics.swb_sizes[g];\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 27222}
{"project": "FFmpeg", "commit_id": "d256ed78ffe202a4dcc8d625becffc716bfa3977", "target": 1, "func": "static int parse_vtrk(AVFormatContext *s,\n\n                      FourxmDemuxContext *fourxm, uint8_t *buf, int size,\n\n                      int left)\n\n{\n\n    AVStream *st;\n\n    /* check that there is enough data */\n\n    if (size != vtrk_SIZE || left < size + 8) {\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* allocate a new AVStream */\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avpriv_set_pts_info(st, 60, 1, fourxm->fps);\n\n\n\n    fourxm->video_stream_index = st->index;\n\n\n\n    st->codec->codec_type     = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id       = AV_CODEC_ID_4XM;\n\n    st->codec->extradata_size = 4;\n\n    st->codec->extradata      = av_malloc(4);\n\n    AV_WL32(st->codec->extradata, AV_RL32(buf + 16));\n\n    st->codec->width  = AV_RL32(buf + 36);\n\n    st->codec->height = AV_RL32(buf + 40);\n\n\n\n    return 0;\n\n}\n", "idx": 27224}
{"project": "FFmpeg", "commit_id": "7ab631261033a71a52563c3b23b6eef826eb5994", "target": 1, "func": "static void draw_digit(int digit, uint8_t *dst, unsigned dst_linesize,\n\n                       unsigned segment_width)\n\n{\n\n#define TOP_HBAR        1\n\n#define MID_HBAR        2\n\n#define BOT_HBAR        4\n\n#define LEFT_TOP_VBAR   8\n\n#define LEFT_BOT_VBAR  16\n\n#define RIGHT_TOP_VBAR 32\n\n#define RIGHT_BOT_VBAR 64\n\n    struct {\n\n        int x, y, w, h;\n\n    } segments[] = {\n\n        { 1,  0, 5, 1 }, /* TOP_HBAR */\n\n        { 1,  6, 5, 1 }, /* MID_HBAR */\n\n        { 1, 12, 5, 1 }, /* BOT_HBAR */\n\n        { 0,  1, 1, 5 }, /* LEFT_TOP_VBAR */\n\n        { 0,  7, 1, 5 }, /* LEFT_BOT_VBAR */\n\n        { 6,  1, 1, 5 }, /* RIGHT_TOP_VBAR */\n\n        { 6,  7, 1, 5 }  /* RIGHT_BOT_VBAR */\n\n    };\n\n    static const unsigned char masks[10] = {\n\n        /* 0 */ TOP_HBAR         |BOT_HBAR|LEFT_TOP_VBAR|LEFT_BOT_VBAR|RIGHT_TOP_VBAR|RIGHT_BOT_VBAR,\n\n        /* 1 */                                                        RIGHT_TOP_VBAR|RIGHT_BOT_VBAR,\n\n        /* 2 */ TOP_HBAR|MID_HBAR|BOT_HBAR|LEFT_BOT_VBAR                             |RIGHT_TOP_VBAR,\n\n        /* 3 */ TOP_HBAR|MID_HBAR|BOT_HBAR                            |RIGHT_TOP_VBAR|RIGHT_BOT_VBAR,\n\n        /* 4 */          MID_HBAR         |LEFT_TOP_VBAR              |RIGHT_TOP_VBAR|RIGHT_BOT_VBAR,\n\n        /* 5 */ TOP_HBAR|BOT_HBAR|MID_HBAR|LEFT_TOP_VBAR                             |RIGHT_BOT_VBAR,\n\n        /* 6 */ TOP_HBAR|BOT_HBAR|MID_HBAR|LEFT_TOP_VBAR|LEFT_BOT_VBAR               |RIGHT_BOT_VBAR,\n\n        /* 7 */ TOP_HBAR                                              |RIGHT_TOP_VBAR|RIGHT_BOT_VBAR,\n\n        /* 8 */ TOP_HBAR|BOT_HBAR|MID_HBAR|LEFT_TOP_VBAR|LEFT_BOT_VBAR|RIGHT_TOP_VBAR|RIGHT_BOT_VBAR,\n\n        /* 9 */ TOP_HBAR|BOT_HBAR|MID_HBAR|LEFT_TOP_VBAR              |RIGHT_TOP_VBAR|RIGHT_BOT_VBAR,\n\n    };\n\n    unsigned mask = masks[digit];\n\n    int i;\n\n\n\n    draw_rectangle(0, dst, dst_linesize, segment_width, 0, 0, 8, 13);\n\n    for (i = 0; i < FF_ARRAY_ELEMS(segments); i++)\n\n        if (mask & (1<<i))\n\n            draw_rectangle(255, dst, dst_linesize, segment_width,\n\n                           segments[i].x, segments[i].y, segments[i].w, segments[i].h);\n\n}\n", "idx": 27226}
{"project": "FFmpeg", "commit_id": "4582e4c086bc36e20e3c0b85c8108cfa352e0d88", "target": 0, "func": "static int query_formats(AVFilterGraph *graph, AVClass *log_ctx)\n\n{\n\n    int i, j, ret;\n\n    int scaler_count = 0, resampler_count = 0;\n\n    int count_queried = 0, count_merged = 0, count_already_merged = 0,\n\n        count_delayed = 0;\n\n\n\n    for (i = 0; i < graph->nb_filters; i++) {\n\n        AVFilterContext *f = graph->filters[i];\n\n        if (formats_declared(f))\n\n            continue;\n\n        if (f->filter->query_formats)\n\n            ret = filter_query_formats(f);\n\n        else\n\n            ret = ff_default_query_formats(f);\n\n        if (ret < 0 && ret != AVERROR(EAGAIN))\n\n            return ret;\n\n        /* note: EAGAIN could indicate a partial success, not counted yet */\n\n        count_queried += ret >= 0;\n\n    }\n\n\n\n    /* go through and merge as many format lists as possible */\n\n    for (i = 0; i < graph->nb_filters; i++) {\n\n        AVFilterContext *filter = graph->filters[i];\n\n\n\n        for (j = 0; j < filter->nb_inputs; j++) {\n\n            AVFilterLink *link = filter->inputs[j];\n\n            int convert_needed = 0;\n\n\n\n            if (!link)\n\n                continue;\n\n\n\n#define MERGE_DISPATCH(field, statement)                                     \\\n\n            if (!(link->in_ ## field && link->out_ ## field)) {              \\\n\n                count_delayed++;                                             \\\n\n            } else if (link->in_ ## field == link->out_ ## field) {          \\\n\n                count_already_merged++;                                      \\\n\n            } else {                                                         \\\n\n                count_merged++;                                              \\\n\n                statement                                                    \\\n\n            }\n\n            MERGE_DISPATCH(formats,\n\n                if (!ff_merge_formats(link->in_formats, link->out_formats,\n\n                                      link->type))\n\n                    convert_needed = 1;\n\n            )\n\n            if (link->type == AVMEDIA_TYPE_AUDIO) {\n\n                MERGE_DISPATCH(channel_layouts,\n\n                    if (!ff_merge_channel_layouts(link->in_channel_layouts,\n\n                                                  link->out_channel_layouts))\n\n                        convert_needed = 1;\n\n                )\n\n                MERGE_DISPATCH(samplerates,\n\n                    if (!ff_merge_samplerates(link->in_samplerates,\n\n                                              link->out_samplerates))\n\n                        convert_needed = 1;\n\n                )\n\n            }\n\n#undef MERGE_DISPATCH\n\n\n\n            if (convert_needed) {\n\n                AVFilterContext *convert;\n\n                AVFilter *filter;\n\n                AVFilterLink *inlink, *outlink;\n\n                char scale_args[256];\n\n                char inst_name[30];\n\n\n\n                /* couldn't merge format lists. auto-insert conversion filter */\n\n                switch (link->type) {\n\n                case AVMEDIA_TYPE_VIDEO:\n\n                    if (!(filter = avfilter_get_by_name(\"scale\"))) {\n\n                        av_log(log_ctx, AV_LOG_ERROR, \"'scale' filter \"\n\n                               \"not present, cannot convert pixel formats.\\n\");\n\n                        return AVERROR(EINVAL);\n\n                    }\n\n\n\n                    snprintf(inst_name, sizeof(inst_name), \"auto-inserted scaler %d\",\n\n                             scaler_count++);\n\n                    av_strlcpy(scale_args, \"0:0\", sizeof(scale_args));\n\n                    if (graph->scale_sws_opts) {\n\n                        av_strlcat(scale_args, \":\", sizeof(scale_args));\n\n                        av_strlcat(scale_args, graph->scale_sws_opts, sizeof(scale_args));\n\n                    }\n\n                    if ((ret = avfilter_graph_create_filter(&convert, filter,\n\n                                                            inst_name, scale_args, NULL,\n\n                                                            graph)) < 0)\n\n                        return ret;\n\n                    break;\n\n                case AVMEDIA_TYPE_AUDIO:\n\n                    if (!(filter = avfilter_get_by_name(\"aresample\"))) {\n\n                        av_log(log_ctx, AV_LOG_ERROR, \"'aresample' filter \"\n\n                               \"not present, cannot convert audio formats.\\n\");\n\n                        return AVERROR(EINVAL);\n\n                    }\n\n\n\n                    snprintf(inst_name, sizeof(inst_name), \"auto-inserted resampler %d\",\n\n                             resampler_count++);\n\n                    scale_args[0] = '\\0';\n\n                    if (graph->aresample_swr_opts)\n\n                        snprintf(scale_args, sizeof(scale_args), \"%s\",\n\n                                 graph->aresample_swr_opts);\n\n                    if ((ret = avfilter_graph_create_filter(&convert, filter,\n\n                                                            inst_name, graph->aresample_swr_opts,\n\n                                                            NULL, graph)) < 0)\n\n                        return ret;\n\n                    break;\n\n                default:\n\n                    return AVERROR(EINVAL);\n\n                }\n\n\n\n                if ((ret = avfilter_insert_filter(link, convert, 0, 0)) < 0)\n\n                    return ret;\n\n\n\n                filter_query_formats(convert);\n\n                inlink  = convert->inputs[0];\n\n                outlink = convert->outputs[0];\n\n                if (!ff_merge_formats( inlink->in_formats,  inlink->out_formats,  inlink->type) ||\n\n                    !ff_merge_formats(outlink->in_formats, outlink->out_formats, outlink->type))\n\n                    ret |= AVERROR(ENOSYS);\n\n                if (inlink->type == AVMEDIA_TYPE_AUDIO &&\n\n                    (!ff_merge_samplerates(inlink->in_samplerates,\n\n                                           inlink->out_samplerates) ||\n\n                     !ff_merge_channel_layouts(inlink->in_channel_layouts,\n\n                                               inlink->out_channel_layouts)))\n\n                    ret |= AVERROR(ENOSYS);\n\n                if (outlink->type == AVMEDIA_TYPE_AUDIO &&\n\n                    (!ff_merge_samplerates(outlink->in_samplerates,\n\n                                           outlink->out_samplerates) ||\n\n                     !ff_merge_channel_layouts(outlink->in_channel_layouts,\n\n                                               outlink->out_channel_layouts)))\n\n                    ret |= AVERROR(ENOSYS);\n\n\n\n                if (ret < 0) {\n\n                    av_log(log_ctx, AV_LOG_ERROR,\n\n                           \"Impossible to convert between the formats supported by the filter \"\n\n                           \"'%s' and the filter '%s'\\n\", link->src->name, link->dst->name);\n\n                    return ret;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    av_log(graph, AV_LOG_DEBUG, \"query_formats: \"\n\n           \"%d queried, %d merged, %d already done, %d delayed\\n\",\n\n           count_queried, count_merged, count_already_merged, count_delayed);\n\n    if (count_delayed) {\n\n        AVBPrint bp;\n\n\n\n        if (count_queried || count_merged)\n\n            return AVERROR(EAGAIN);\n\n        av_bprint_init(&bp, 0, AV_BPRINT_SIZE_AUTOMATIC);\n\n        for (i = 0; i < graph->nb_filters; i++)\n\n            if (!formats_declared(graph->filters[i]))\n\n                av_bprintf(&bp, \"%s%s\", bp.len ? \", \" : \"\",\n\n                          graph->filters[i]->name);\n\n        av_log(graph, AV_LOG_ERROR,\n\n               \"The following filters could not choose their formats: %s\\n\"\n\n               \"Consider inserting the (a)format filter near their input or \"\n\n               \"output.\\n\", bp.str);\n\n        return AVERROR(EIO);\n\n    }\n\n    return 0;\n\n}\n", "idx": 27227}
{"project": "FFmpeg", "commit_id": "486637af8ef29ec215e0e0b7ecd3b5470f0e04e5", "target": 0, "func": "static inline void mix_2f_1r_to_stereo(AC3DecodeContext *ctx)\n\n{\n\n    int i;\n\n    float (*output)[256] = ctx->audio_block.block_output;\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        output[1][i] += output[2][i];\n\n        output[2][i] += output[3][i];\n\n    }\n\n    memset(output[3], 0, sizeof(output[3]));\n\n}\n", "idx": 27228}
{"project": "FFmpeg", "commit_id": "851ded8918c977d8160c6617b69604f758cabf50", "target": 0, "func": "static int decode_cabac_mb_cbp_chroma( H264Context *h) {\n\n    int ctx;\n\n    int cbp_a, cbp_b;\n\n\n\n    cbp_a = (h->left_cbp>>4)&0x03;\n\n    cbp_b = (h-> top_cbp>>4)&0x03;\n\n\n\n    ctx = 0;\n\n    if( cbp_a > 0 ) ctx++;\n\n    if( cbp_b > 0 ) ctx += 2;\n\n    if( get_cabac( &h->cabac, &h->cabac_state[77 + ctx] ) == 0 )\n\n        return 0;\n\n\n\n    ctx = 4;\n\n    if( cbp_a == 2 ) ctx++;\n\n    if( cbp_b == 2 ) ctx += 2;\n\n    return 1 + get_cabac( &h->cabac, &h->cabac_state[77 + ctx] );\n\n}\n", "idx": 27229}
{"project": "FFmpeg", "commit_id": "cb65b32c97b06fc611b53c1ab77a2edbaadee84f", "target": 0, "func": "static int mp3_write_audio_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    MP3Context  *mp3 = s->priv_data;\n\n\n\n    if (pkt && pkt->data && pkt->size >= 4) {\n\n        MPADecodeHeader c;\n\n        int av_unused base;\n\n\n\n        avpriv_mpegaudio_decode_header(&c, AV_RB32(pkt->data));\n\n\n\n        if (!mp3->initial_bitrate)\n\n            mp3->initial_bitrate = c.bit_rate;\n\n        if ((c.bit_rate == 0) || (mp3->initial_bitrate != c.bit_rate))\n\n            mp3->has_variable_bitrate = 1;\n\n\n\n#ifdef FILTER_VBR_HEADERS\n\n        /* filter out XING and INFO headers. */\n\n        base = 4 + xing_offtbl[c.lsf == 1][c.nb_channels == 1];\n\n\n\n        if (base + 4 <= pkt->size) {\n\n            uint32_t v = AV_RB32(pkt->data + base);\n\n\n\n            if (MKBETAG('X','i','n','g') == v || MKBETAG('I','n','f','o') == v)\n\n                return 0;\n\n        }\n\n\n\n        /* filter out VBRI headers. */\n\n        base = 4 + 32;\n\n\n\n        if (base + 4 <= pkt->size && MKBETAG('V','B','R','I') == AV_RB32(pkt->data + base))\n\n            return 0;\n\n#endif\n\n\n\n        if (mp3->xing_offset)\n\n            mp3_xing_add_frame(mp3, pkt);\n\n    }\n\n\n\n    return ff_raw_write_packet(s, pkt);\n\n}\n", "idx": 27230}
{"project": "FFmpeg", "commit_id": "c97f54020d5d55511e28622551f13233bd8ceb56", "target": 0, "func": "int has_altivec(void)\n\n{\n\n#ifdef __AMIGAOS4__\n\n    ULONG result = 0;\n\n    extern struct ExecIFace *IExec;\n\n\n\n    IExec->GetCPUInfoTags(GCIT_VectorUnit, &result, TAG_DONE);\n\n    if (result == VECTORTYPE_ALTIVEC) return 1;\n\n    return 0;\n\n#else /* __AMIGAOS4__ */\n\n\n\n#ifdef SYS_DARWIN\n\n    int sels[2] = {CTL_HW, HW_VECTORUNIT};\n\n    int has_vu = 0;\n\n    size_t len = sizeof(has_vu);\n\n    int err;\n\n\n\n    err = sysctl(sels, 2, &has_vu, &len, NULL, 0);\n\n\n\n    if (err == 0) return (has_vu != 0);\n\n#else /* SYS_DARWIN */\n\n/* no Darwin, do it the brute-force way */\n\n/* this is borrowed from the libmpeg2 library */\n\n    {\n\n      signal (SIGILL, sigill_handler);\n\n      if (sigsetjmp (jmpbuf, 1)) {\n\n        signal (SIGILL, SIG_DFL);\n\n      } else {\n\n        canjump = 1;\n\n\n\n        asm volatile (\"mtspr 256, %0\\n\\t\"\n\n                      \"vand %%v0, %%v0, %%v0\"\n\n                      :\n\n                      : \"r\" (-1));\n\n\n\n        signal (SIGILL, SIG_DFL);\n\n        return 1;\n\n      }\n\n    }\n\n#endif /* SYS_DARWIN */\n\n    return 0;\n\n#endif /* __AMIGAOS4__ */\n\n}\n", "idx": 27231}
{"project": "FFmpeg", "commit_id": "dcc39ee10e82833ce24aa57926c00ffeb1948198", "target": 0, "func": "static int mpeg_field_start(MpegEncContext *s, const uint8_t *buf, int buf_size)\n\n{\n\n    AVCodecContext *avctx = s->avctx;\n\n    Mpeg1Context *s1      = (Mpeg1Context *) s;\n\n    int ret;\n\n\n\n    if (s->picture_structure == PICT_FRAME)\n\n        s->first_field = 0;\n\n    else\n\n        s->first_field ^= 1;\n\n\n\n    /* start frame decoding */\n\n    if (s->first_field || s->picture_structure == PICT_FRAME) {\n\n        AVFrameSideData *pan_scan;\n\n\n\n        if ((ret = ff_mpv_frame_start(s, avctx)) < 0)\n\n            return ret;\n\n\n\n        ff_mpeg_er_frame_start(s);\n\n\n\n        /* first check if we must repeat the frame */\n\n        s->current_picture_ptr->f->repeat_pict = 0;\n\n        if (s->repeat_first_field) {\n\n            if (s->progressive_sequence) {\n\n                if (s->top_field_first)\n\n                    s->current_picture_ptr->f->repeat_pict = 4;\n\n                else\n\n                    s->current_picture_ptr->f->repeat_pict = 2;\n\n            } else if (s->progressive_frame) {\n\n                s->current_picture_ptr->f->repeat_pict = 1;\n\n            }\n\n        }\n\n\n\n        pan_scan = av_frame_new_side_data(s->current_picture_ptr->f,\n\n                                          AV_FRAME_DATA_PANSCAN,\n\n                                          sizeof(s1->pan_scan));\n\n        if (!pan_scan)\n\n            return AVERROR(ENOMEM);\n\n        memcpy(pan_scan->data, &s1->pan_scan, sizeof(s1->pan_scan));\n\n\n\n        if (s1->a53_caption) {\n\n            AVFrameSideData *sd = av_frame_new_side_data(\n\n                s->current_picture_ptr->f, AV_FRAME_DATA_A53_CC,\n\n                s1->a53_caption_size);\n\n            if (sd)\n\n                memcpy(sd->data, s1->a53_caption, s1->a53_caption_size);\n\n            av_freep(&s1->a53_caption);\n\n        }\n\n\n\n        if (s1->has_stereo3d) {\n\n            AVStereo3D *stereo = av_stereo3d_create_side_data(s->current_picture_ptr->f);\n\n            if (!stereo)\n\n                return AVERROR(ENOMEM);\n\n\n\n            *stereo = s1->stereo3d;\n\n            s1->has_stereo3d = 0;\n\n        }\n\n\n\n        if (s1->has_afd) {\n\n            AVFrameSideData *sd =\n\n                av_frame_new_side_data(s->current_picture_ptr->f,\n\n                                       AV_FRAME_DATA_AFD, 1);\n\n            if (!sd)\n\n                return AVERROR(ENOMEM);\n\n\n\n            *sd->data   = s1->afd;\n\n            s1->has_afd = 0;\n\n        }\n\n\n\n        if (HAVE_THREADS && (avctx->active_thread_type & FF_THREAD_FRAME))\n\n            ff_thread_finish_setup(avctx);\n\n    } else { // second field\n\n        int i;\n\n\n\n        if (!s->current_picture_ptr) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"first field missing\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        if (s->avctx->hwaccel &&\n\n            (s->avctx->slice_flags & SLICE_FLAG_ALLOW_FIELD)) {\n\n            if (s->avctx->hwaccel->end_frame(s->avctx) < 0)\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"hardware accelerator failed to decode first field\\n\");\n\n        }\n\n\n\n        for (i = 0; i < 4; i++) {\n\n            s->current_picture.f->data[i] = s->current_picture_ptr->f->data[i];\n\n            if (s->picture_structure == PICT_BOTTOM_FIELD)\n\n                s->current_picture.f->data[i] +=\n\n                    s->current_picture_ptr->f->linesize[i];\n\n        }\n\n    }\n\n\n\n    if (avctx->hwaccel) {\n\n        if ((ret = avctx->hwaccel->start_frame(avctx, buf, buf_size)) < 0)\n\n            return ret;\n\n    }\n\n\n\n#if FF_API_XVMC\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n// ff_mpv_frame_start will call this function too,\n\n// but we need to call it on every field\n\n    if (CONFIG_MPEG_XVMC_DECODER && s->avctx->xvmc_acceleration)\n\n        if (ff_xvmc_field_start(s, avctx) < 0)\n\n            return -1;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif /* FF_API_XVMC */\n\n\n\n    return 0;\n\n}\n", "idx": 27232}
{"project": "FFmpeg", "commit_id": "1cb0edb40b8e94e1a50ad40c40d43e34ed8435fe", "target": 1, "func": "static void mpeg_decode_picture_coding_extension(MpegEncContext *s)\n\n{\n\n    s->full_pel[0] = s->full_pel[1] = 0;\n\n    s->mpeg_f_code[0][0] = get_bits(&s->gb, 4);\n\n    s->mpeg_f_code[0][1] = get_bits(&s->gb, 4);\n\n    s->mpeg_f_code[1][0] = get_bits(&s->gb, 4);\n\n    s->mpeg_f_code[1][1] = get_bits(&s->gb, 4);\n\n    s->intra_dc_precision = get_bits(&s->gb, 2);\n\n    s->picture_structure = get_bits(&s->gb, 2);\n\n    s->top_field_first = get_bits1(&s->gb);\n\n    s->frame_pred_frame_dct = get_bits1(&s->gb);\n\n    s->concealment_motion_vectors = get_bits1(&s->gb);\n\n    s->q_scale_type = get_bits1(&s->gb);\n\n    s->intra_vlc_format = get_bits1(&s->gb);\n\n    s->alternate_scan = get_bits1(&s->gb);\n\n    s->repeat_first_field = get_bits1(&s->gb);\n\n    s->chroma_420_type = get_bits1(&s->gb);\n\n    s->progressive_frame = get_bits1(&s->gb);\n\n    /* composite display not parsed */\n\n    dprintf(\"intra_dc_precion=%d\\n\", s->intra_dc_precision);\n\n    dprintf(\"picture_structure=%d\\n\", s->picture_structure);\n\n    dprintf(\"conceal=%d\\n\", s->concealment_motion_vectors);\n\n    dprintf(\"intra_vlc_format=%d\\n\", s->intra_vlc_format);\n\n    dprintf(\"alternate_scan=%d\\n\", s->alternate_scan);\n\n    dprintf(\"frame_pred_frame_dct=%d\\n\", s->frame_pred_frame_dct);\n\n}\n", "idx": 27234}
{"project": "FFmpeg", "commit_id": "3836af476534e6f84be7b3a19afce3530af50703", "target": 1, "func": "static int mpegvideo_probe(AVProbeData *p)\n\n{\n\n    uint32_t code= -1;\n\n    int pic=0, seq=0, slice=0, pspack=0, vpes=0, apes=0, res=0, sicle=0;\n\n    int i;\n\n    uint32_t last = 0;\n\n\n\n    for(i=0; i<p->buf_size; i++){\n\n        code = (code<<8) + p->buf[i];\n\n        if ((code & 0xffffff00) == 0x100) {\n\n            switch(code){\n\n            case     SEQ_START_CODE:   seq++; break;\n\n            case PICTURE_START_CODE:   pic++; break;\n\n            case    PACK_START_CODE: pspack++; break;\n\n            case              0x1b6:\n\n                                        res++; break;\n\n            }\n\n            if (code >= SLICE_START_CODE && code <= 0x1af) {\n\n                if (last >= SLICE_START_CODE && last <= 0x1af) {\n\n                    if (code >= last) slice++;\n\n                    else              sicle++;\n\n                }else{\n\n                    if (code == SLICE_START_CODE) slice++;\n\n                    else                          sicle++;\n\n                }\n\n            }\n\n            if     ((code & 0x1f0) == VIDEO_ID)   vpes++;\n\n            else if((code & 0x1e0) == AUDIO_ID)   apes++;\n\n            last = code;\n\n        }\n\n    }\n\n    if(seq && seq*9<=pic*10 && pic*9<=slice*10 && !pspack && !apes && !res && slice > sicle) {\n\n        if(vpes) return AVPROBE_SCORE_EXTENSION / 4;\n\n        else     return pic>1 ? AVPROBE_SCORE_EXTENSION + 1 : AVPROBE_SCORE_EXTENSION / 2; // +1 for .mpg\n\n    }\n\n    return 0;\n\n}\n", "idx": 27236}
{"project": "FFmpeg", "commit_id": "afa982fdae1b49a8aee00a27da876bba10ba1073", "target": 1, "func": "static void filter(MpegAudioContext *s, int ch, short *samples, int incr)\n\n{\n\n    short *p, *q;\n\n    int sum, offset, i, j, norm, n;\n\n    short tmp[64];\n\n    int tmp1[32];\n\n    int *out;\n\n\n\n    //    print_pow1(samples, 1152);\n\n\n\n    offset = s->samples_offset[ch];\n\n    out = &s->sb_samples[ch][0][0][0];\n\n    for(j=0;j<36;j++) {\n\n        /* 32 samples at once */\n\n        for(i=0;i<32;i++) {\n\n            s->samples_buf[ch][offset + (31 - i)] = samples[0];\n\n            samples += incr;\n\n        }\n\n\n\n        /* filter */\n\n        p = s->samples_buf[ch] + offset;\n\n        q = filter_bank;\n\n        /* maxsum = 23169 */\n\n        for(i=0;i<64;i++) {\n\n            sum = p[0*64] * q[0*64];\n\n            sum += p[1*64] * q[1*64];\n\n            sum += p[2*64] * q[2*64];\n\n            sum += p[3*64] * q[3*64];\n\n            sum += p[4*64] * q[4*64];\n\n            sum += p[5*64] * q[5*64];\n\n            sum += p[6*64] * q[6*64];\n\n            sum += p[7*64] * q[7*64];\n\n            tmp[i] = sum >> 14;\n\n            p++;\n\n            q++;\n\n        }\n\n        tmp1[0] = tmp[16];\n\n        for( i=1; i<=16; i++ ) tmp1[i] = tmp[i+16]+tmp[16-i];\n\n        for( i=17; i<=31; i++ ) tmp1[i] = tmp[i+16]-tmp[80-i];\n\n\n\n        /* integer IDCT 32 with normalization. XXX: There may be some\n\n           overflow left */\n\n        norm = 0;\n\n        for(i=0;i<32;i++) {\n\n            norm |= abs(tmp1[i]);\n\n        }\n\n        n = av_log2(norm) - 12;\n\n        if (n > 0) {\n\n            for(i=0;i<32;i++) \n\n                tmp1[i] >>= n;\n\n        } else {\n\n            n = 0;\n\n        }\n\n\n\n        idct32(out, tmp1, s->sblimit, n);\n\n\n\n        /* advance of 32 samples */\n\n        offset -= 32;\n\n        out += 32;\n\n        /* handle the wrap around */\n\n        if (offset < 0) {\n\n            memmove(s->samples_buf[ch] + SAMPLES_BUF_SIZE - (512 - 32), \n\n                    s->samples_buf[ch], (512 - 32) * 2);\n\n            offset = SAMPLES_BUF_SIZE - 512;\n\n        }\n\n    }\n\n    s->samples_offset[ch] = offset;\n\n\n\n    //    print_pow(s->sb_samples, 1152);\n\n}\n", "idx": 27237}
{"project": "FFmpeg", "commit_id": "59163139679b0aa2cb84cd6d7a3f696ed5a5813a", "target": 0, "func": "static int get_std_framerate(int i){\n\n    if(i<60*12) return i*1001;\n\n    else        return ((const int[]){24,30,60,12,15,48})[i-60*12]*1000*12;\n\n}\n", "idx": 27243}
{"project": "FFmpeg", "commit_id": "912ce9dd2080c5837285a471d750fa311e09b555", "target": 0, "func": "void ff_jpeg2000_cleanup(Jpeg2000Component *comp, Jpeg2000CodingStyle *codsty)\n\n{\n\n    int reslevelno, bandno, precno;\n\n    for (reslevelno = 0;\n\n         comp->reslevel && reslevelno < codsty->nreslevels;\n\n         reslevelno++) {\n\n        Jpeg2000ResLevel *reslevel = comp->reslevel + reslevelno;\n\n\n\n        for (bandno = 0; bandno < reslevel->nbands; bandno++) {\n\n            Jpeg2000Band *band = reslevel->band + bandno;\n\n            for (precno = 0; precno < reslevel->num_precincts_x * reslevel->num_precincts_y; precno++) {\n\n                Jpeg2000Prec *prec = band->prec + precno;\n\n                av_freep(&prec->zerobits);\n\n                av_freep(&prec->cblkincl);\n\n                av_freep(&prec->cblk);\n\n            }\n\n\n\n            av_freep(&band->prec);\n\n        }\n\n        av_freep(&reslevel->band);\n\n    }\n\n\n\n    ff_dwt_destroy(&comp->dwt);\n\n    av_freep(&comp->reslevel);\n\n    av_freep(&comp->i_data);\n\n    av_freep(&comp->f_data);\n\n}\n", "idx": 27244}
{"project": "FFmpeg", "commit_id": "3a2b9911bffeffc3fc0541df3b4f6d492e122714", "target": 0, "func": "static void filter(struct vf_priv_s *p, uint8_t *dst[3], uint8_t *src[3], int dst_stride[3], int src_stride[3], int width, int height){\n\n    int x, y, i;\n\n\n\n    for(i=0; i<3; i++){\n\n        p->frame->data[i]= src[i];\n\n        p->frame->linesize[i]= src_stride[i];\n\n    }\n\n\n\n    p->avctx_enc->me_cmp=\n\n    p->avctx_enc->me_sub_cmp= FF_CMP_SAD /*| (p->parity ? FF_CMP_ODD : FF_CMP_EVEN)*/;\n\n    p->frame->quality= p->qp*FF_QP2LAMBDA;\n\n    avcodec_encode_video(p->avctx_enc, p->outbuf, p->outbuf_size, p->frame);\n\n    p->frame_dec = p->avctx_enc->coded_frame;\n\n\n\n    for(i=0; i<3; i++){\n\n        int is_chroma= !!i;\n\n        int w= width >>is_chroma;\n\n        int h= height>>is_chroma;\n\n        int fils= p->frame_dec->linesize[i];\n\n        int srcs= src_stride[i];\n\n\n\n        for(y=0; y<h; y++){\n\n            if((y ^ p->parity) & 1){\n\n                for(x=0; x<w; x++){\n\n                    if((x-2)+(y-1)*w>=0 && (x+2)+(y+1)*w<w*h){ //FIXME either alloc larger images or optimize this\n\n                        uint8_t *filp= &p->frame_dec->data[i][x + y*fils];\n\n                        uint8_t *srcp= &src[i][x + y*srcs];\n\n                        int diff0= filp[-fils] - srcp[-srcs];\n\n                        int diff1= filp[+fils] - srcp[+srcs];\n\n                        int spatial_score= ABS(srcp[-srcs-1] - srcp[+srcs-1])\n\n                                          +ABS(srcp[-srcs  ] - srcp[+srcs  ])\n\n                                          +ABS(srcp[-srcs+1] - srcp[+srcs+1]) - 1;\n\n                        int temp= filp[0];\n\n\n\n#define CHECK(j)\\\n\n    {   int score= ABS(srcp[-srcs-1+(j)] - srcp[+srcs-1-(j)])\\\n\n                 + ABS(srcp[-srcs  +(j)] - srcp[+srcs  -(j)])\\\n\n                 + ABS(srcp[-srcs+1+(j)] - srcp[+srcs+1-(j)]);\\\n\n        if(score < spatial_score){\\\n\n            spatial_score= score;\\\n\n            diff0= filp[-fils+(j)] - srcp[-srcs+(j)];\\\n\n            diff1= filp[+fils-(j)] - srcp[+srcs-(j)];\n\n\n\n                        CHECK(-1) CHECK(-2) }} }}\n\n                        CHECK( 1) CHECK( 2) }} }}\n", "idx": 27255}
{"project": "FFmpeg", "commit_id": "7effbee66cf457c62f795d9b9ed3a1110b364b89", "target": 1, "func": "static int apc_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    if (av_get_packet(s->pb, pkt, MAX_READ_SIZE) <= 0)\n\n        return AVERROR(EIO);\n\n\n    pkt->stream_index = 0;\n\n    return 0;\n\n}", "idx": 27260}
{"project": "FFmpeg", "commit_id": "607ad990d31e6be52980970e5ce8cd25ab3de812", "target": 0, "func": "static int dvbsub_decode(AVCodecContext *avctx,\n\n                         void *data, int *data_size,\n\n                         AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    DVBSubContext *ctx = avctx->priv_data;\n\n    AVSubtitle *sub = data;\n\n    const uint8_t *p, *p_end;\n\n    int segment_type;\n\n    int page_id;\n\n    int segment_length;\n\n    int i;\n\n\n\n    av_dlog(avctx, \"DVB sub packet:\\n\");\n\n\n\n    for (i=0; i < buf_size; i++) {\n\n        av_dlog(avctx, \"%02x \", buf[i]);\n\n        if (i % 16 == 15)\n\n            av_dlog(avctx, \"\\n\");\n\n    }\n\n\n\n    if (i % 16)\n\n        av_dlog(avctx, \"\\n\");\n\n\n\n    if (buf_size <= 6 || *buf != 0x0f) {\n\n        av_dlog(avctx, \"incomplete or broken packet\");\n\n        return -1;\n\n    }\n\n\n\n    p = buf;\n\n    p_end = buf + buf_size;\n\n\n\n    while (p_end - p >= 6 && *p == 0x0f) {\n\n        p += 1;\n\n        segment_type = *p++;\n\n        page_id = AV_RB16(p);\n\n        p += 2;\n\n        segment_length = AV_RB16(p);\n\n        p += 2;\n\n\n\n        if (p_end - p < segment_length) {\n\n            av_dlog(avctx, \"incomplete or broken packet\");\n\n            return -1;\n\n        }\n\n\n\n        if (page_id == ctx->composition_id || page_id == ctx->ancillary_id ||\n\n            ctx->composition_id == -1 || ctx->ancillary_id == -1) {\n\n            switch (segment_type) {\n\n            case DVBSUB_PAGE_SEGMENT:\n\n                dvbsub_parse_page_segment(avctx, p, segment_length);\n\n                break;\n\n            case DVBSUB_REGION_SEGMENT:\n\n                dvbsub_parse_region_segment(avctx, p, segment_length);\n\n                break;\n\n            case DVBSUB_CLUT_SEGMENT:\n\n                dvbsub_parse_clut_segment(avctx, p, segment_length);\n\n                break;\n\n            case DVBSUB_OBJECT_SEGMENT:\n\n                dvbsub_parse_object_segment(avctx, p, segment_length);\n\n                break;\n\n            case DVBSUB_DISPLAYDEFINITION_SEGMENT:\n\n                dvbsub_parse_display_definition_segment(avctx, p, segment_length);\n\n                break;\n\n            case DVBSUB_DISPLAY_SEGMENT:\n\n                *data_size = dvbsub_display_end_segment(avctx, p, segment_length, sub);\n\n                break;\n\n            default:\n\n                av_dlog(avctx, \"Subtitling segment type 0x%x, page id %d, length %d\\n\",\n\n                        segment_type, page_id, segment_length);\n\n                break;\n\n            }\n\n        }\n\n\n\n        p += segment_length;\n\n    }\n\n\n\n    return p - buf;\n\n}\n", "idx": 27261}
{"project": "FFmpeg", "commit_id": "3a25c707fae3c6e99fdda40474c3d74be24cc4c3", "target": 0, "func": "static int mov_read_trak(MOVContext *c, ByteIOContext *pb, MOV_atom_t atom)\n\n{\n\n    AVStream *st;\n\n    MOVStreamContext *sc;\n\n    int ret;\n\n\n\n    st = av_new_stream(c->fc, c->fc->nb_streams);\n\n    if (!st) return AVERROR(ENOMEM);\n\n    sc = av_mallocz(sizeof(MOVStreamContext));\n\n    if (!sc) return AVERROR(ENOMEM);\n\n\n\n    st->priv_data = sc;\n\n    st->codec->codec_type = CODEC_TYPE_DATA;\n\n    st->start_time = 0; /* XXX: check */\n\n\n\n    if ((ret = mov_read_default(c, pb, atom)) < 0)\n\n        return ret;\n\n\n\n    /* sanity checks */\n\n    if(sc->chunk_count && (!sc->stts_count || !sc->sample_to_chunk_sz ||\n\n                           (!sc->sample_size && !sc->sample_count))){\n\n        av_log(c->fc, AV_LOG_ERROR, \"stream %d, missing mandatory atoms, broken header\\n\",\n\n               st->index);\n\n        sc->sample_count = 0; //ignore track\n\n        return 0;\n\n    }\n\n    if(!sc->time_rate)\n\n        sc->time_rate=1;\n\n    if(!sc->time_scale)\n\n        sc->time_scale= c->time_scale;\n\n    av_set_pts_info(st, 64, sc->time_rate, sc->time_scale);\n\n\n\n    if (st->codec->codec_type == CODEC_TYPE_AUDIO &&\n\n        !st->codec->frame_size && sc->stts_count == 1)\n\n        st->codec->frame_size = av_rescale(sc->time_rate, st->codec->sample_rate, sc->time_scale);\n\n\n\n    if(st->duration != AV_NOPTS_VALUE){\n\n        assert(st->duration % sc->time_rate == 0);\n\n        st->duration /= sc->time_rate;\n\n    }\n\n    sc->ffindex = st->index;\n\n    mov_build_index(c, st);\n\n\n\n    if (sc->dref_id-1 < sc->drefs_count && sc->drefs[sc->dref_id-1].path) {\n\n        if (url_fopen(&sc->pb, sc->drefs[sc->dref_id-1].path, URL_RDONLY) < 0)\n\n            av_log(c->fc, AV_LOG_ERROR, \"stream %d, error opening file %s: %s\\n\",\n\n                   st->index, sc->drefs[sc->dref_id-1].path, strerror(errno));\n\n    } else\n\n        sc->pb = c->fc->pb;\n\n\n\n    switch (st->codec->codec_id) {\n\n#ifdef CONFIG_H261_DECODER\n\n    case CODEC_ID_H261:\n\n#endif\n\n#ifdef CONFIG_H263_DECODER\n\n    case CODEC_ID_H263:\n\n#endif\n\n#ifdef CONFIG_MPEG4_DECODER\n\n    case CODEC_ID_MPEG4:\n\n#endif\n\n        st->codec->width= 0; /* let decoder init width/height */\n\n        st->codec->height= 0;\n\n        break;\n\n#ifdef CONFIG_VORBIS_DECODER\n\n    case CODEC_ID_VORBIS:\n\n#endif\n\n        st->codec->sample_rate= 0; /* let decoder init parameters properly */\n\n        break;\n\n    }\n\n\n\n    /* Do not need those anymore. */\n\n    av_freep(&sc->chunk_offsets);\n\n    av_freep(&sc->sample_to_chunk);\n\n    av_freep(&sc->sample_sizes);\n\n    av_freep(&sc->keyframes);\n\n    av_freep(&sc->stts_data);\n\n\n\n    return 0;\n\n}\n", "idx": 27272}
{"project": "FFmpeg", "commit_id": "c89658008705d949c319df3fa6f400c481ad73e1", "target": 0, "func": "static int sdp_parse(AVFormatContext *s, const char *content)\n\n{\n\n    const char *p;\n\n    int letter;\n\n    /* Some SDP lines, particularly for Realmedia or ASF RTSP streams,\n\n     * contain long SDP lines containing complete ASF Headers (several\n\n     * kB) or arrays of MDPR (RM stream descriptor) headers plus\n\n     * \"rulebooks\" describing their properties. Therefore, the SDP line\n\n     * buffer is large.\n\n     *\n\n     * The Vorbis FMTP line can be up to 16KB - see sdp_parse_fmtp. */\n\n    char buf[16384], *q;\n\n    SDPParseState sdp_parse_state, *s1 = &sdp_parse_state;\n\n\n\n    memset(s1, 0, sizeof(SDPParseState));\n\n    p = content;\n\n    for(;;) {\n\n        skip_spaces(&p);\n\n        letter = *p;\n\n        if (letter == '\\0')\n\n            break;\n\n        p++;\n\n        if (*p != '=')\n\n            goto next_line;\n\n        p++;\n\n        /* get the content */\n\n        q = buf;\n\n        while (*p != '\\n' && *p != '\\r' && *p != '\\0') {\n\n            if ((q - buf) < sizeof(buf) - 1)\n\n                *q++ = *p;\n\n            p++;\n\n        }\n\n        *q = '\\0';\n\n        sdp_parse_line(s, s1, letter, buf);\n\n    next_line:\n\n        while (*p != '\\n' && *p != '\\0')\n\n            p++;\n\n        if (*p == '\\n')\n\n            p++;\n\n    }\n\n    return 0;\n\n}\n", "idx": 27282}
{"project": "FFmpeg", "commit_id": "aaa7d2fafcc375d8cdef25a289008821c9c2fbaa", "target": 1, "func": "static void flush_change(H264Context *h)\n\n{\n\n    h->outputed_poc = h->next_outputed_poc = INT_MIN;\n\n    h->prev_interlaced_frame = 1;\n\n    idr(h);\n\n    h->prev_frame_num = -1;\n\n    if (h->s.current_picture_ptr)\n\n        h->s.current_picture_ptr->f.reference = 0;\n\n    h->s.first_field = 0;\n\n    memset(h->ref_list[0], 0, sizeof(h->ref_list[0]));\n\n    memset(h->ref_list[1], 0, sizeof(h->ref_list[1]));\n\n    memset(h->default_ref_list[0], 0, sizeof(h->default_ref_list[0]));\n\n    memset(h->default_ref_list[1], 0, sizeof(h->default_ref_list[1]));\n\n    ff_h264_reset_sei(h);\n\n    h->recovery_frame= -1;\n\n    h->sync= 0;\n\n    h->list_count = 0;\n\n    h->current_slice = 0;\n\n}\n", "idx": 27283}
{"project": "FFmpeg", "commit_id": "f9158b01d0f3effb58e87fb07db0382bc1e47de5", "target": 1, "func": "static ResampleContext *resample_init(ResampleContext *c, int out_rate, int in_rate, int filter_size, int phase_shift, int linear,\n                                    double cutoff0, enum AVSampleFormat format, enum SwrFilterType filter_type, int kaiser_beta,\n                                    double precision, int cheby){\n    double cutoff = cutoff0? cutoff0 : 0.97;\n    double factor= FFMIN(out_rate * cutoff / in_rate, 1.0);\n    int phase_count= 1<<phase_shift;\n    if (!c || c->phase_shift != phase_shift || c->linear!=linear || c->factor != factor\n           || c->filter_length != FFMAX((int)ceil(filter_size/factor), 1) || c->format != format\n           || c->filter_type != filter_type || c->kaiser_beta != kaiser_beta) {\n        c = av_mallocz(sizeof(*c));\n        if (!c)\n            return NULL;\n        c->format= format;\n        c->felem_size= av_get_bytes_per_sample(c->format);\n        switch(c->format){\n        case AV_SAMPLE_FMT_S16P:\n            c->filter_shift = 15;\n            break;\n        case AV_SAMPLE_FMT_S32P:\n            c->filter_shift = 30;\n            break;\n        case AV_SAMPLE_FMT_FLTP:\n        case AV_SAMPLE_FMT_DBLP:\n            c->filter_shift = 0;\n            break;\n        default:\n            av_log(NULL, AV_LOG_ERROR, \"Unsupported sample format\\n\");\n            av_assert0(0);\n        c->phase_shift   = phase_shift;\n        c->phase_mask    = phase_count - 1;\n        c->linear        = linear;\n        c->factor        = factor;\n        c->filter_length = FFMAX((int)ceil(filter_size/factor), 1);\n        c->filter_alloc  = FFALIGN(c->filter_length, 8);\n        c->filter_bank   = av_calloc(c->filter_alloc, (phase_count+1)*c->felem_size);\n        c->filter_type   = filter_type;\n        c->kaiser_beta   = kaiser_beta;\n        if (!c->filter_bank)\n        if (build_filter(c, (void*)c->filter_bank, factor, c->filter_length, c->filter_alloc, phase_count, 1<<c->filter_shift, filter_type, kaiser_beta))\n        memcpy(c->filter_bank + (c->filter_alloc*phase_count+1)*c->felem_size, c->filter_bank, (c->filter_alloc-1)*c->felem_size);\n        memcpy(c->filter_bank + (c->filter_alloc*phase_count  )*c->felem_size, c->filter_bank + (c->filter_alloc - 1)*c->felem_size, c->felem_size);\n    c->compensation_distance= 0;\n    if(!av_reduce(&c->src_incr, &c->dst_incr, out_rate, in_rate * (int64_t)phase_count, INT32_MAX/2))\n    c->ideal_dst_incr= c->dst_incr;\n    c->index= -phase_count*((c->filter_length-1)/2);\n    c->frac= 0;\n    return c;\nerror:\n    av_freep(&c->filter_bank);\n    av_free(c);\n    return NULL;", "idx": 27289}
{"project": "FFmpeg", "commit_id": "3ca5df36a50e3ffd3b24734725bf545617a627a8", "target": 1, "func": "static int decode_packet(AVCodecContext *avctx, void *data, int *got_frame_ptr,\n\n                         AVPacket* avpkt)\n\n{\n\n    WmallDecodeCtx *s = avctx->priv_data;\n\n    GetBitContext* gb  = &s->pgb;\n\n    const uint8_t* buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    int num_bits_prev_frame, packet_sequence_number, spliced_packet;\n\n\n\n    s->frame.nb_samples = 0;\n\n\n\n    if (s->packet_done || s->packet_loss) {\n\n        s->packet_done = 0;\n\n\n\n        /* sanity check for the buffer length */\n\n        if (buf_size < avctx->block_align)\n\n            return 0;\n\n\n\n        s->next_packet_start = buf_size - avctx->block_align;\n\n        buf_size             = avctx->block_align;\n\n        s->buf_bit_size      = buf_size << 3;\n\n\n\n        /* parse packet header */\n\n        init_get_bits(gb, buf, s->buf_bit_size);\n\n        packet_sequence_number = get_bits(gb, 4);\n\n        skip_bits(gb, 1);   // Skip seekable_frame_in_packet, currently ununused\n\n        spliced_packet = get_bits1(gb);\n\n        if (spliced_packet)\n\n            avpriv_request_sample(avctx, \"Bitstream splicing\");\n\n\n\n        /* get number of bits that need to be added to the previous frame */\n\n        num_bits_prev_frame = get_bits(gb, s->log2_frame_size);\n\n\n\n        /* check for packet loss */\n\n        if (!s->packet_loss &&\n\n            ((s->packet_sequence_number + 1) & 0xF) != packet_sequence_number) {\n\n            s->packet_loss = 1;\n\n            av_log(avctx, AV_LOG_ERROR, \"Packet loss detected! seq %x vs %x\\n\",\n\n                   s->packet_sequence_number, packet_sequence_number);\n\n        }\n\n        s->packet_sequence_number = packet_sequence_number;\n\n\n\n        if (num_bits_prev_frame > 0) {\n\n            int remaining_packet_bits = s->buf_bit_size - get_bits_count(gb);\n\n            if (num_bits_prev_frame >= remaining_packet_bits) {\n\n                num_bits_prev_frame = remaining_packet_bits;\n\n                s->packet_done = 1;\n\n            }\n\n\n\n            /* Append the previous frame data to the remaining data from the\n\n             * previous packet to create a full frame. */\n\n            save_bits(s, gb, num_bits_prev_frame, 1);\n\n\n\n            /* decode the cross packet frame if it is valid */\n\n            if (num_bits_prev_frame < remaining_packet_bits && !s->packet_loss)\n\n                decode_frame(s);\n\n        } else if (s->num_saved_bits - s->frame_offset) {\n\n            av_dlog(avctx, \"ignoring %x previously saved bits\\n\",\n\n                    s->num_saved_bits - s->frame_offset);\n\n        }\n\n\n\n        if (s->packet_loss) {\n\n            /* Reset number of saved bits so that the decoder does not start\n\n             * to decode incomplete frames in the s->len_prefix == 0 case. */\n\n            s->num_saved_bits = 0;\n\n            s->packet_loss    = 0;\n\n            init_put_bits(&s->pb, s->frame_data, MAX_FRAMESIZE);\n\n        }\n\n\n\n    } else {\n\n        int frame_size;\n\n\n\n        s->buf_bit_size = (avpkt->size - s->next_packet_start) << 3;\n\n        init_get_bits(gb, avpkt->data, s->buf_bit_size);\n\n        skip_bits(gb, s->packet_offset);\n\n\n\n        if (s->len_prefix && remaining_bits(s, gb) > s->log2_frame_size &&\n\n            (frame_size = show_bits(gb, s->log2_frame_size)) &&\n\n            frame_size <= remaining_bits(s, gb)) {\n\n            save_bits(s, gb, frame_size, 0);\n\n            s->packet_done = !decode_frame(s);\n\n        } else if (!s->len_prefix\n\n                   && s->num_saved_bits > get_bits_count(&s->gb)) {\n\n            /* when the frames do not have a length prefix, we don't know the\n\n             * compressed length of the individual frames however, we know what\n\n             * part of a new packet belongs to the previous frame therefore we\n\n             * save the incoming packet first, then we append the \"previous\n\n             * frame\" data from the next packet so that we get a buffer that\n\n             * only contains full frames */\n\n            s->packet_done = !decode_frame(s);\n\n        } else {\n\n            s->packet_done = 1;\n\n        }\n\n    }\n\n\n\n    if (s->packet_done && !s->packet_loss &&\n\n        remaining_bits(s, gb) > 0) {\n\n        /* save the rest of the data so that it can be decoded\n\n         * with the next packet */\n\n        save_bits(s, gb, remaining_bits(s, gb), 0);\n\n    }\n\n\n\n    *(AVFrame *)data = s->frame;\n\n    *got_frame_ptr   = s->frame.nb_samples > 0;\n\n    s->packet_offset = get_bits_count(gb) & 7;\n\n\n\n    return (s->packet_loss) ? AVERROR_INVALIDDATA : get_bits_count(gb) >> 3;\n\n}\n", "idx": 27292}
{"project": "FFmpeg", "commit_id": "60fcc19b9068614f25cf64dff5e4aa0e8dbff6a5", "target": 1, "func": "static void mpegts_write_pes(AVFormatContext *s, AVStream *st,\n\n                             const uint8_t *payload, int payload_size,\n\n                             int64_t pts, int64_t dts, int key)\n\n{\n\n    MpegTSWriteStream *ts_st = st->priv_data;\n\n    MpegTSWrite *ts = s->priv_data;\n\n    uint8_t buf[TS_PACKET_SIZE];\n\n    uint8_t *q;\n\n    int val, is_start, len, header_len, write_pcr, is_dvb_subtitle, is_dvb_teletext, flags;\n\n    int afc_len, stuffing_len;\n\n    int64_t pcr = -1; /* avoid warning */\n\n    int64_t delay = av_rescale(s->max_delay, 90000, AV_TIME_BASE);\n\n    int force_pat = st->codec->codec_type == AVMEDIA_TYPE_VIDEO && key && !ts_st->prev_payload_key;\n\n\n\n    is_start = 1;\n\n    while (payload_size > 0) {\n\n        retransmit_si_info(s, force_pat);\n\n        force_pat = 0;\n\n\n\n        write_pcr = 0;\n\n        if (ts_st->pid == ts_st->service->pcr_pid) {\n\n            if (ts->mux_rate > 1 || is_start) // VBR pcr period is based on frames\n\n                ts_st->service->pcr_packet_count++;\n\n            if (ts_st->service->pcr_packet_count >=\n\n                ts_st->service->pcr_packet_period) {\n\n                ts_st->service->pcr_packet_count = 0;\n\n                write_pcr = 1;\n\n\n\n\n\n        if (ts->mux_rate > 1 && dts != AV_NOPTS_VALUE &&\n\n            (dts - get_pcr(ts, s->pb)/300) > delay) {\n\n            /* pcr insert gets priority over null packet insert */\n\n            if (write_pcr)\n\n                mpegts_insert_pcr_only(s, st);\n\n            else\n\n                mpegts_insert_null_packet(s);\n\n            continue; /* recalculate write_pcr and possibly retransmit si_info */\n\n\n\n\n        /* prepare packet header */\n\n        q = buf;\n\n        *q++ = 0x47;\n\n        val = (ts_st->pid >> 8);\n\n        if (is_start)\n\n            val |= 0x40;\n\n        *q++ = val;\n\n        *q++ = ts_st->pid;\n\n        ts_st->cc = (ts_st->cc + 1) & 0xf;\n\n        *q++ = 0x10 | ts_st->cc; // payload indicator + CC\n\n        if (key && is_start && pts != AV_NOPTS_VALUE) {\n\n            // set Random Access for key frames\n\n            if (ts_st->pid == ts_st->service->pcr_pid)\n\n                write_pcr = 1;\n\n            set_af_flag(buf, 0x40);\n\n            q = get_ts_payload_start(buf);\n\n\n        if (write_pcr) {\n\n            set_af_flag(buf, 0x10);\n\n            q = get_ts_payload_start(buf);\n\n            // add 11, pcr references the last byte of program clock reference base\n\n            if (ts->mux_rate > 1)\n\n                pcr = get_pcr(ts, s->pb);\n\n            else\n\n                pcr = (dts - delay)*300;\n\n            if (dts != AV_NOPTS_VALUE && dts < pcr / 300)\n\n                av_log(s, AV_LOG_WARNING, \"dts < pcr, TS is invalid\\n\");\n\n            extend_af(buf, write_pcr_bits(q, pcr));\n\n            q = get_ts_payload_start(buf);\n\n\n        if (is_start) {\n\n            int pes_extension = 0;\n\n            int pes_header_stuffing_bytes = 0;\n\n            /* write PES header */\n\n            *q++ = 0x00;\n\n            *q++ = 0x00;\n\n            *q++ = 0x01;\n\n            is_dvb_subtitle = 0;\n\n            is_dvb_teletext = 0;\n\n\n                if (st->codec->codec_id == AV_CODEC_ID_DIRAC) {\n\n                    *q++ = 0xfd;\n\n                } else\n\n                    *q++ = 0xe0;\n\n            } else if (st->codec->codec_type == AVMEDIA_TYPE_AUDIO &&\n\n                       (st->codec->codec_id == AV_CODEC_ID_MP2 ||\n\n                        st->codec->codec_id == AV_CODEC_ID_MP3 ||\n\n                        st->codec->codec_id == AV_CODEC_ID_AAC)) {\n\n                *q++ = 0xc0;\n\n            } else if (st->codec->codec_type == AVMEDIA_TYPE_AUDIO &&\n\n                        st->codec->codec_id == AV_CODEC_ID_AC3 &&\n\n                        ts->m2ts_mode) {\n\n                *q++ = 0xfd;\n\n            } else {\n\n                *q++ = 0xbd;\n\n                if(st->codec->codec_type == AVMEDIA_TYPE_SUBTITLE) {\n\n                    if (st->codec->codec_id == AV_CODEC_ID_DVB_SUBTITLE) {\n\n                        is_dvb_subtitle = 1;\n\n                    } else if (st->codec->codec_id == AV_CODEC_ID_DVB_TELETEXT) {\n\n                        is_dvb_teletext = 1;\n\n\n\n\n            header_len = 0;\n\n            flags = 0;\n\n            if (pts != AV_NOPTS_VALUE) {\n\n                header_len += 5;\n\n                flags |= 0x80;\n\n\n            if (dts != AV_NOPTS_VALUE && pts != AV_NOPTS_VALUE && dts != pts) {\n\n                header_len += 5;\n\n                flags |= 0x40;\n\n\n            if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO &&\n\n                st->codec->codec_id == AV_CODEC_ID_DIRAC) {\n\n                /* set PES_extension_flag */\n\n                pes_extension = 1;\n\n                flags |= 0x01;\n\n\n\n                /*\n\n                * One byte for PES2 extension flag +\n\n                * one byte for extension length +\n\n                * one byte for extension id\n\n                */\n\n                header_len += 3;\n\n\n            /* for Blu-ray AC3 Audio the PES Extension flag should be as follow\n\n             * otherwise it will not play sound on blu-ray\n\n             */\n\n            if (ts->m2ts_mode &&\n\n                st->codec->codec_type == AVMEDIA_TYPE_AUDIO &&\n\n                st->codec->codec_id == AV_CODEC_ID_AC3) {\n\n                        /* set PES_extension_flag */\n\n                        pes_extension = 1;\n\n                        flags |= 0x01;\n\n                        header_len += 3;\n\n\n            if (is_dvb_teletext) {\n\n                pes_header_stuffing_bytes = 0x24 - header_len;\n\n                header_len = 0x24;\n\n\n            len = payload_size + header_len + 3;\n\n            /* 3 extra bytes should be added to DVB subtitle payload: 0x20 0x00 at the beginning and trailing 0xff */\n\n            if (is_dvb_subtitle) {\n\n                len += 3;\n\n                payload_size++;\n\n\n            if (len > 0xffff)\n\n\n\n\n\n            *q++ = len >> 8;\n\n            *q++ = len;\n\n            val = 0x80;\n\n            /* data alignment indicator is required for subtitle and data streams */\n\n            if (st->codec->codec_type == AVMEDIA_TYPE_SUBTITLE || st->codec->codec_type == AVMEDIA_TYPE_DATA)\n\n                val |= 0x04;\n\n            *q++ = val;\n\n            *q++ = flags;\n\n            *q++ = header_len;\n\n            if (pts != AV_NOPTS_VALUE) {\n\n                write_pts(q, flags >> 6, pts);\n\n                q += 5;\n\n\n            if (dts != AV_NOPTS_VALUE && pts != AV_NOPTS_VALUE && dts != pts) {\n\n                write_pts(q, 1, dts);\n\n                q += 5;\n\n\n            if (pes_extension && st->codec->codec_id == AV_CODEC_ID_DIRAC) {\n\n                flags = 0x01;  /* set PES_extension_flag_2 */\n\n                *q++ = flags;\n\n                *q++ = 0x80 | 0x01;  /* marker bit + extension length */\n\n                /*\n\n                * Set the stream id extension flag bit to 0 and\n\n                * write the extended stream id\n\n                */\n\n                *q++ = 0x00 | 0x60;\n\n\n            /* For Blu-ray AC3 Audio Setting extended flags */\n\n          if (ts->m2ts_mode &&\n\n              pes_extension &&\n\n              st->codec->codec_id == AV_CODEC_ID_AC3) {\n\n                      flags = 0x01; /* set PES_extension_flag_2 */\n\n                      *q++ = flags;\n\n                      *q++ = 0x80 | 0x01; /* marker bit + extension length */\n\n                      *q++ = 0x00 | 0x71; /* for AC3 Audio (specifically on blue-rays) */\n\n\n\n\n\n\n            if (is_dvb_subtitle) {\n\n                /* First two fields of DVB subtitles PES data:\n\n                 * data_identifier: for DVB subtitle streams shall be coded with the value 0x20\n\n                 * subtitle_stream_id: for DVB subtitle stream shall be identified by the value 0x00 */\n\n                *q++ = 0x20;\n\n                *q++ = 0x00;\n\n\n            if (is_dvb_teletext) {\n\n                memset(q, 0xff, pes_header_stuffing_bytes);\n\n                q += pes_header_stuffing_bytes;\n\n\n            is_start = 0;\n\n\n        /* header size */\n\n        header_len = q - buf;\n\n        /* data len */\n\n        len = TS_PACKET_SIZE - header_len;\n\n        if (len > payload_size)\n\n            len = payload_size;\n\n        stuffing_len = TS_PACKET_SIZE - header_len - len;\n\n        if (stuffing_len > 0) {\n\n            /* add stuffing with AFC */\n\n            if (buf[3] & 0x20) {\n\n                /* stuffing already present: increase its size */\n\n                afc_len = buf[4] + 1;\n\n                memmove(buf + 4 + afc_len + stuffing_len,\n\n                        buf + 4 + afc_len,\n\n                        header_len - (4 + afc_len));\n\n                buf[4] += stuffing_len;\n\n                memset(buf + 4 + afc_len, 0xff, stuffing_len);\n\n            } else {\n\n                /* add stuffing */\n\n                memmove(buf + 4 + stuffing_len, buf + 4, header_len - 4);\n\n                buf[3] |= 0x20;\n\n                buf[4] = stuffing_len - 1;\n\n                if (stuffing_len >= 2) {\n\n                    buf[5] = 0x00;\n\n                    memset(buf + 6, 0xff, stuffing_len - 2);\n\n\n\n\n\n\n        if (is_dvb_subtitle && payload_size == len) {\n\n            memcpy(buf + TS_PACKET_SIZE - len, payload, len - 1);\n\n            buf[TS_PACKET_SIZE - 1] = 0xff; /* end_of_PES_data_field_marker: an 8-bit field with fixed contents 0xff for DVB subtitle */\n\n        } else {\n\n            memcpy(buf + TS_PACKET_SIZE - len, payload, len);\n\n\n\n\n        payload += len;\n\n        payload_size -= len;\n\n        mpegts_prefix_m2ts_header(s);\n\n        avio_write(s->pb, buf, TS_PACKET_SIZE);\n\n\n    avio_flush(s->pb);\n\n    ts_st->prev_payload_key = key;\n", "idx": 27293}
{"project": "FFmpeg", "commit_id": "93f4538363069b721c24417f3d38575274394845", "target": 0, "func": "static void RENAME(postProcess)(const uint8_t src[], int srcStride, uint8_t dst[], int dstStride, int width, int height,\n\n                                const QP_STORE_T QPs[], int QPStride, int isColor, PPContext *c2)\n\n{\n\n    DECLARE_ALIGNED(8, PPContext, c)= *c2; //copy to stack for faster access\n\n    int x,y;\n\n#ifdef TEMPLATE_PP_TIME_MODE\n\n    const int mode= TEMPLATE_PP_TIME_MODE;\n\n#else\n\n    const int mode= isColor ? c.ppMode.chromMode : c.ppMode.lumMode;\n\n#endif\n\n    int black=0, white=255; // blackest black and whitest white in the picture\n\n    int QPCorrecture= 256*256;\n\n\n\n    int copyAhead;\n\n#if TEMPLATE_PP_MMX\n\n    int i;\n\n#endif\n\n\n\n    const int qpHShift= isColor ? 4-c.hChromaSubSample : 4;\n\n    const int qpVShift= isColor ? 4-c.vChromaSubSample : 4;\n\n\n\n    //FIXME remove\n\n    uint64_t * const yHistogram= c.yHistogram;\n\n    uint8_t * const tempSrc= srcStride > 0 ? c.tempSrc : c.tempSrc - 23*srcStride;\n\n    uint8_t * const tempDst= (dstStride > 0 ? c.tempDst : c.tempDst - 23*dstStride) + 32;\n\n    //const int mbWidth= isColor ? (width+7)>>3 : (width+15)>>4;\n\n\n\n    if (mode & VISUALIZE){\n\n        if(!(mode & (V_A_DEBLOCK | H_A_DEBLOCK)) || TEMPLATE_PP_MMX) {\n\n            av_log(c2, AV_LOG_WARNING, \"Visualization is currently only supported with the accurate deblock filter without SIMD\\n\");\n\n        }\n\n    }\n\n\n\n#if TEMPLATE_PP_MMX\n\n    for(i=0; i<57; i++){\n\n        int offset= ((i*c.ppMode.baseDcDiff)>>8) + 1;\n\n        int threshold= offset*2 + 1;\n\n        c.mmxDcOffset[i]= 0x7F - offset;\n\n        c.mmxDcThreshold[i]= 0x7F - threshold;\n\n        c.mmxDcOffset[i]*= 0x0101010101010101LL;\n\n        c.mmxDcThreshold[i]*= 0x0101010101010101LL;\n\n    }\n\n#endif\n\n\n\n    if(mode & CUBIC_IPOL_DEINT_FILTER) copyAhead=16;\n\n    else if(   (mode & LINEAR_BLEND_DEINT_FILTER)\n\n            || (mode & FFMPEG_DEINT_FILTER)\n\n            || (mode & LOWPASS5_DEINT_FILTER)) copyAhead=14;\n\n    else if(   (mode & V_DEBLOCK)\n\n            || (mode & LINEAR_IPOL_DEINT_FILTER)\n\n            || (mode & MEDIAN_DEINT_FILTER)\n\n            || (mode & V_A_DEBLOCK)) copyAhead=13;\n\n    else if(mode & V_X1_FILTER) copyAhead=11;\n\n//    else if(mode & V_RK1_FILTER) copyAhead=10;\n\n    else if(mode & DERING) copyAhead=9;\n\n    else copyAhead=8;\n\n\n\n    copyAhead-= 8;\n\n\n\n    if(!isColor){\n\n        uint64_t sum= 0;\n\n        int i;\n\n        uint64_t maxClipped;\n\n        uint64_t clipped;\n\n        double scale;\n\n\n\n        c.frameNum++;\n\n        // first frame is fscked so we ignore it\n\n        if(c.frameNum == 1) yHistogram[0]= width*(uint64_t)height/64*15/256;\n\n\n\n        for(i=0; i<256; i++){\n\n            sum+= yHistogram[i];\n\n        }\n\n\n\n        /* We always get a completely black picture first. */\n\n        maxClipped= (uint64_t)(sum * c.ppMode.maxClippedThreshold);\n\n\n\n        clipped= sum;\n\n        for(black=255; black>0; black--){\n\n            if(clipped < maxClipped) break;\n\n            clipped-= yHistogram[black];\n\n        }\n\n\n\n        clipped= sum;\n\n        for(white=0; white<256; white++){\n\n            if(clipped < maxClipped) break;\n\n            clipped-= yHistogram[white];\n\n        }\n\n\n\n        scale= (double)(c.ppMode.maxAllowedY - c.ppMode.minAllowedY) / (double)(white-black);\n\n\n\n#if TEMPLATE_PP_MMXEXT\n\n        c.packedYScale= (uint16_t)(scale*256.0 + 0.5);\n\n        c.packedYOffset= (((black*c.packedYScale)>>8) - c.ppMode.minAllowedY) & 0xFFFF;\n\n#else\n\n        c.packedYScale= (uint16_t)(scale*1024.0 + 0.5);\n\n        c.packedYOffset= (black - c.ppMode.minAllowedY) & 0xFFFF;\n\n#endif\n\n\n\n        c.packedYOffset|= c.packedYOffset<<32;\n\n        c.packedYOffset|= c.packedYOffset<<16;\n\n\n\n        c.packedYScale|= c.packedYScale<<32;\n\n        c.packedYScale|= c.packedYScale<<16;\n\n\n\n        if(mode & LEVEL_FIX)        QPCorrecture= (int)(scale*256*256 + 0.5);\n\n        else                        QPCorrecture= 256*256;\n\n    }else{\n\n        c.packedYScale= 0x0100010001000100LL;\n\n        c.packedYOffset= 0;\n\n        QPCorrecture= 256*256;\n\n    }\n\n\n\n    /* copy & deinterlace first row of blocks */\n\n    y=-BLOCK_SIZE;\n\n    {\n\n        const uint8_t *srcBlock= &(src[y*srcStride]);\n\n        uint8_t *dstBlock= tempDst + dstStride;\n\n\n\n        // From this point on it is guaranteed that we can read and write 16 lines downward\n\n        // finish 1 block before the next otherwise we might have a problem\n\n        // with the L1 Cache of the P4 ... or only a few blocks at a time or something\n\n        for(x=0; x<width; x+=BLOCK_SIZE){\n\n\n\n#if TEMPLATE_PP_MMXEXT && HAVE_6REGS\n\n/*\n\n            prefetchnta(srcBlock + (((x>>2)&6) + 5)*srcStride + 32);\n\n            prefetchnta(srcBlock + (((x>>2)&6) + 6)*srcStride + 32);\n\n            prefetcht0(dstBlock + (((x>>2)&6) + 5)*dstStride + 32);\n\n            prefetcht0(dstBlock + (((x>>2)&6) + 6)*dstStride + 32);\n\n*/\n\n\n\n            __asm__(\n\n                \"mov %4, %%\"REG_a\"              \\n\\t\"\n\n                \"shr $2, %%\"REG_a\"              \\n\\t\"\n\n                \"and $6, %%\"REG_a\"              \\n\\t\"\n\n                \"add %5, %%\"REG_a\"              \\n\\t\"\n\n                \"mov %%\"REG_a\", %%\"REG_d\"       \\n\\t\"\n\n                \"imul %1, %%\"REG_a\"             \\n\\t\"\n\n                \"imul %3, %%\"REG_d\"             \\n\\t\"\n\n                \"prefetchnta 32(%%\"REG_a\", %0)  \\n\\t\"\n\n                \"prefetcht0 32(%%\"REG_d\", %2)   \\n\\t\"\n\n                \"add %1, %%\"REG_a\"              \\n\\t\"\n\n                \"add %3, %%\"REG_d\"              \\n\\t\"\n\n                \"prefetchnta 32(%%\"REG_a\", %0)  \\n\\t\"\n\n                \"prefetcht0 32(%%\"REG_d\", %2)   \\n\\t\"\n\n                :: \"r\" (srcBlock), \"r\" ((x86_reg)srcStride), \"r\" (dstBlock), \"r\" ((x86_reg)dstStride),\n\n                \"g\" ((x86_reg)x), \"g\" ((x86_reg)copyAhead)\n\n                : \"%\"REG_a, \"%\"REG_d\n\n            );\n\n\n\n#elif TEMPLATE_PP_3DNOW\n\n//FIXME check if this is faster on an 3dnow chip or if it is faster without the prefetch or ...\n\n/*          prefetch(srcBlock + (((x>>3)&3) + 5)*srcStride + 32);\n\n            prefetch(srcBlock + (((x>>3)&3) + 9)*srcStride + 32);\n\n            prefetchw(dstBlock + (((x>>3)&3) + 5)*dstStride + 32);\n\n            prefetchw(dstBlock + (((x>>3)&3) + 9)*dstStride + 32);\n\n*/\n\n#endif\n\n\n\n            RENAME(blockCopy)(dstBlock + dstStride*8, dstStride,\n\n                              srcBlock + srcStride*8, srcStride, mode & LEVEL_FIX, &c.packedYOffset);\n\n\n\n            RENAME(duplicate)(dstBlock + dstStride*8, dstStride);\n\n\n\n            if(mode & LINEAR_IPOL_DEINT_FILTER)\n\n                RENAME(deInterlaceInterpolateLinear)(dstBlock, dstStride);\n\n            else if(mode & LINEAR_BLEND_DEINT_FILTER)\n\n                RENAME(deInterlaceBlendLinear)(dstBlock, dstStride, c.deintTemp + x);\n\n            else if(mode & MEDIAN_DEINT_FILTER)\n\n                RENAME(deInterlaceMedian)(dstBlock, dstStride);\n\n            else if(mode & CUBIC_IPOL_DEINT_FILTER)\n\n                RENAME(deInterlaceInterpolateCubic)(dstBlock, dstStride);\n\n            else if(mode & FFMPEG_DEINT_FILTER)\n\n                RENAME(deInterlaceFF)(dstBlock, dstStride, c.deintTemp + x);\n\n            else if(mode & LOWPASS5_DEINT_FILTER)\n\n                RENAME(deInterlaceL5)(dstBlock, dstStride, c.deintTemp + x, c.deintTemp + width + x);\n\n/*          else if(mode & CUBIC_BLEND_DEINT_FILTER)\n\n                RENAME(deInterlaceBlendCubic)(dstBlock, dstStride);\n\n*/\n\n            dstBlock+=8;\n\n            srcBlock+=8;\n\n        }\n\n        if(width==FFABS(dstStride))\n\n            linecpy(dst, tempDst + 9*dstStride, copyAhead, dstStride);\n\n        else{\n\n            int i;\n\n            for(i=0; i<copyAhead; i++){\n\n                memcpy(dst + i*dstStride, tempDst + (9+i)*dstStride, width);\n\n            }\n\n        }\n\n    }\n\n\n\n    for(y=0; y<height; y+=BLOCK_SIZE){\n\n        //1% speedup if these are here instead of the inner loop\n\n        const uint8_t *srcBlock= &(src[y*srcStride]);\n\n        uint8_t *dstBlock= &(dst[y*dstStride]);\n\n#if TEMPLATE_PP_MMX\n\n        uint8_t *tempBlock1= c.tempBlocks;\n\n        uint8_t *tempBlock2= c.tempBlocks + 8;\n\n#endif\n\n        const int8_t *QPptr= &QPs[(y>>qpVShift)*QPStride];\n\n        int8_t *nonBQPptr= &c.nonBQPTable[(y>>qpVShift)*FFABS(QPStride)];\n\n        int QP=0;\n\n        /* can we mess with a 8x16 block from srcBlock/dstBlock downwards and 1 line upwards\n\n           if not than use a temporary buffer */\n\n        if(y+15 >= height){\n\n            int i;\n\n            /* copy from line (copyAhead) to (copyAhead+7) of src, these will be copied with\n\n               blockcopy to dst later */\n\n            linecpy(tempSrc + srcStride*copyAhead, srcBlock + srcStride*copyAhead,\n\n                    FFMAX(height-y-copyAhead, 0), srcStride);\n\n\n\n            /* duplicate last line of src to fill the void up to line (copyAhead+7) */\n\n            for(i=FFMAX(height-y, 8); i<copyAhead+8; i++)\n\n                    memcpy(tempSrc + srcStride*i, src + srcStride*(height-1), FFABS(srcStride));\n\n\n\n            /* copy up to (copyAhead+1) lines of dst (line -1 to (copyAhead-1))*/\n\n            linecpy(tempDst, dstBlock - dstStride, FFMIN(height-y+1, copyAhead+1), dstStride);\n\n\n\n            /* duplicate last line of dst to fill the void up to line (copyAhead) */\n\n            for(i=height-y+1; i<=copyAhead; i++)\n\n                    memcpy(tempDst + dstStride*i, dst + dstStride*(height-1), FFABS(dstStride));\n\n\n\n            dstBlock= tempDst + dstStride;\n\n            srcBlock= tempSrc;\n\n        }\n\n\n\n        // From this point on it is guaranteed that we can read and write 16 lines downward\n\n        // finish 1 block before the next otherwise we might have a problem\n\n        // with the L1 Cache of the P4 ... or only a few blocks at a time or something\n\n        for(x=0; x<width; x+=BLOCK_SIZE){\n\n            const int stride= dstStride;\n\n#if TEMPLATE_PP_MMX\n\n            uint8_t *tmpXchg;\n\n#endif\n\n            if(isColor){\n\n                QP= QPptr[x>>qpHShift];\n\n                c.nonBQP= nonBQPptr[x>>qpHShift];\n\n            }else{\n\n                QP= QPptr[x>>4];\n\n                QP= (QP* QPCorrecture + 256*128)>>16;\n\n                c.nonBQP= nonBQPptr[x>>4];\n\n                c.nonBQP= (c.nonBQP* QPCorrecture + 256*128)>>16;\n\n                yHistogram[ srcBlock[srcStride*12 + 4] ]++;\n\n            }\n\n            c.QP= QP;\n\n#if TEMPLATE_PP_MMX\n\n            __asm__ volatile(\n\n                \"movd %1, %%mm7         \\n\\t\"\n\n                \"packuswb %%mm7, %%mm7  \\n\\t\" // 0, 0, 0, QP, 0, 0, 0, QP\n\n                \"packuswb %%mm7, %%mm7  \\n\\t\" // 0,QP, 0, QP, 0,QP, 0, QP\n\n                \"packuswb %%mm7, %%mm7  \\n\\t\" // QP,..., QP\n\n                \"movq %%mm7, %0         \\n\\t\"\n\n                : \"=m\" (c.pQPb)\n\n                : \"r\" (QP)\n\n            );\n\n#endif\n\n\n\n\n\n#if TEMPLATE_PP_MMXEXT && HAVE_6REGS\n\n/*\n\n            prefetchnta(srcBlock + (((x>>2)&6) + 5)*srcStride + 32);\n\n            prefetchnta(srcBlock + (((x>>2)&6) + 6)*srcStride + 32);\n\n            prefetcht0(dstBlock + (((x>>2)&6) + 5)*dstStride + 32);\n\n            prefetcht0(dstBlock + (((x>>2)&6) + 6)*dstStride + 32);\n\n*/\n\n\n\n            __asm__(\n\n                \"mov %4, %%\"REG_a\"              \\n\\t\"\n\n                \"shr $2, %%\"REG_a\"              \\n\\t\"\n\n                \"and $6, %%\"REG_a\"              \\n\\t\"\n\n                \"add %5, %%\"REG_a\"              \\n\\t\"\n\n                \"mov %%\"REG_a\", %%\"REG_d\"       \\n\\t\"\n\n                \"imul %1, %%\"REG_a\"             \\n\\t\"\n\n                \"imul %3, %%\"REG_d\"             \\n\\t\"\n\n                \"prefetchnta 32(%%\"REG_a\", %0)  \\n\\t\"\n\n                \"prefetcht0 32(%%\"REG_d\", %2)   \\n\\t\"\n\n                \"add %1, %%\"REG_a\"              \\n\\t\"\n\n                \"add %3, %%\"REG_d\"              \\n\\t\"\n\n                \"prefetchnta 32(%%\"REG_a\", %0)  \\n\\t\"\n\n                \"prefetcht0 32(%%\"REG_d\", %2)   \\n\\t\"\n\n                :: \"r\" (srcBlock), \"r\" ((x86_reg)srcStride), \"r\" (dstBlock), \"r\" ((x86_reg)dstStride),\n\n                \"g\" ((x86_reg)x), \"g\" ((x86_reg)copyAhead)\n\n                : \"%\"REG_a, \"%\"REG_d\n\n            );\n\n\n\n#elif TEMPLATE_PP_3DNOW\n\n//FIXME check if this is faster on an 3dnow chip or if it is faster without the prefetch or ...\n\n/*          prefetch(srcBlock + (((x>>3)&3) + 5)*srcStride + 32);\n\n            prefetch(srcBlock + (((x>>3)&3) + 9)*srcStride + 32);\n\n            prefetchw(dstBlock + (((x>>3)&3) + 5)*dstStride + 32);\n\n            prefetchw(dstBlock + (((x>>3)&3) + 9)*dstStride + 32);\n\n*/\n\n#endif\n\n\n\n            RENAME(blockCopy)(dstBlock + dstStride*copyAhead, dstStride,\n\n                              srcBlock + srcStride*copyAhead, srcStride, mode & LEVEL_FIX, &c.packedYOffset);\n\n\n\n            if(mode & LINEAR_IPOL_DEINT_FILTER)\n\n                RENAME(deInterlaceInterpolateLinear)(dstBlock, dstStride);\n\n            else if(mode & LINEAR_BLEND_DEINT_FILTER)\n\n                RENAME(deInterlaceBlendLinear)(dstBlock, dstStride, c.deintTemp + x);\n\n            else if(mode & MEDIAN_DEINT_FILTER)\n\n                RENAME(deInterlaceMedian)(dstBlock, dstStride);\n\n            else if(mode & CUBIC_IPOL_DEINT_FILTER)\n\n                RENAME(deInterlaceInterpolateCubic)(dstBlock, dstStride);\n\n            else if(mode & FFMPEG_DEINT_FILTER)\n\n                RENAME(deInterlaceFF)(dstBlock, dstStride, c.deintTemp + x);\n\n            else if(mode & LOWPASS5_DEINT_FILTER)\n\n                RENAME(deInterlaceL5)(dstBlock, dstStride, c.deintTemp + x, c.deintTemp + width + x);\n\n/*          else if(mode & CUBIC_BLEND_DEINT_FILTER)\n\n                RENAME(deInterlaceBlendCubic)(dstBlock, dstStride);\n\n*/\n\n\n\n            /* only deblock if we have 2 blocks */\n\n            if(y + 8 < height){\n\n                if(mode & V_X1_FILTER)\n\n                    RENAME(vertX1Filter)(dstBlock, stride, &c);\n\n                else if(mode & V_DEBLOCK){\n\n                    const int t= RENAME(vertClassify)(dstBlock, stride, &c);\n\n\n\n                    if(t==1)\n\n                        RENAME(doVertLowPass)(dstBlock, stride, &c);\n\n                    else if(t==2)\n\n                        RENAME(doVertDefFilter)(dstBlock, stride, &c);\n\n                }else if(mode & V_A_DEBLOCK){\n\n                    RENAME(do_a_deblock)(dstBlock, stride, 1, &c, mode);\n\n                }\n\n            }\n\n\n\n#if TEMPLATE_PP_MMX\n\n            RENAME(transpose1)(tempBlock1, tempBlock2, dstBlock, dstStride);\n\n#endif\n\n            /* check if we have a previous block to deblock it with dstBlock */\n\n            if(x - 8 >= 0){\n\n#if TEMPLATE_PP_MMX\n\n                if(mode & H_X1_FILTER)\n\n                        RENAME(vertX1Filter)(tempBlock1, 16, &c);\n\n                else if(mode & H_DEBLOCK){\n\n//START_TIMER\n\n                    const int t= RENAME(vertClassify)(tempBlock1, 16, &c);\n\n//STOP_TIMER(\"dc & minmax\")\n\n                    if(t==1)\n\n                        RENAME(doVertLowPass)(tempBlock1, 16, &c);\n\n                    else if(t==2)\n\n                        RENAME(doVertDefFilter)(tempBlock1, 16, &c);\n\n                }else if(mode & H_A_DEBLOCK){\n\n                        RENAME(do_a_deblock)(tempBlock1, 16, 1, &c, mode);\n\n                }\n\n\n\n                RENAME(transpose2)(dstBlock-4, dstStride, tempBlock1 + 4*16);\n\n\n\n#else\n\n                if(mode & H_X1_FILTER)\n\n                    horizX1Filter(dstBlock-4, stride, QP);\n\n                else if(mode & H_DEBLOCK){\n\n#if TEMPLATE_PP_ALTIVEC\n\n                    DECLARE_ALIGNED(16, unsigned char, tempBlock)[272];\n\n                    int t;\n\n                    transpose_16x8_char_toPackedAlign_altivec(tempBlock, dstBlock - (4 + 1), stride);\n\n\n\n                    t = vertClassify_altivec(tempBlock-48, 16, &c);\n\n                    if(t==1) {\n\n                        doVertLowPass_altivec(tempBlock-48, 16, &c);\n\n                        transpose_8x16_char_fromPackedAlign_altivec(dstBlock - (4 + 1), tempBlock, stride);\n\n                    }\n\n                    else if(t==2) {\n\n                        doVertDefFilter_altivec(tempBlock-48, 16, &c);\n\n                        transpose_8x16_char_fromPackedAlign_altivec(dstBlock - (4 + 1), tempBlock, stride);\n\n                    }\n\n#else\n\n                    const int t= RENAME(horizClassify)(dstBlock-4, stride, &c);\n\n\n\n                    if(t==1)\n\n                        RENAME(doHorizLowPass)(dstBlock-4, stride, &c);\n\n                    else if(t==2)\n\n                        RENAME(doHorizDefFilter)(dstBlock-4, stride, &c);\n\n#endif\n\n                }else if(mode & H_A_DEBLOCK){\n\n                    RENAME(do_a_deblock)(dstBlock-8, 1, stride, &c, mode);\n\n                }\n\n#endif //TEMPLATE_PP_MMX\n\n                if(mode & DERING){\n\n                //FIXME filter first line\n\n                    if(y>0) RENAME(dering)(dstBlock - stride - 8, stride, &c);\n\n                }\n\n\n\n                if(mode & TEMP_NOISE_FILTER)\n\n                {\n\n                    RENAME(tempNoiseReducer)(dstBlock-8, stride,\n\n                            c.tempBlurred[isColor] + y*dstStride + x,\n\n                            c.tempBlurredPast[isColor] + (y>>3)*256 + (x>>3) + 256,\n\n                            c.ppMode.maxTmpNoise);\n\n                }\n\n            }\n\n\n\n            dstBlock+=8;\n\n            srcBlock+=8;\n\n\n\n#if TEMPLATE_PP_MMX\n\n            tmpXchg= tempBlock1;\n\n            tempBlock1= tempBlock2;\n\n            tempBlock2 = tmpXchg;\n\n#endif\n\n        }\n\n\n\n        if(mode & DERING){\n\n            if(y > 0) RENAME(dering)(dstBlock - dstStride - 8, dstStride, &c);\n\n        }\n\n\n\n        if((mode & TEMP_NOISE_FILTER)){\n\n            RENAME(tempNoiseReducer)(dstBlock-8, dstStride,\n\n                    c.tempBlurred[isColor] + y*dstStride + x,\n\n                    c.tempBlurredPast[isColor] + (y>>3)*256 + (x>>3) + 256,\n\n                    c.ppMode.maxTmpNoise);\n\n        }\n\n\n\n        /* did we use a tmp buffer for the last lines*/\n\n        if(y+15 >= height){\n\n            uint8_t *dstBlock= &(dst[y*dstStride]);\n\n            if(width==FFABS(dstStride))\n\n                linecpy(dstBlock, tempDst + dstStride, height-y, dstStride);\n\n            else{\n\n                int i;\n\n                for(i=0; i<height-y; i++){\n\n                    memcpy(dstBlock + i*dstStride, tempDst + (i+1)*dstStride, width);\n\n                }\n\n            }\n\n        }\n\n/*\n\n        for(x=0; x<width; x+=32){\n\n            volatile int i;\n\n            i+=   dstBlock[x + 7*dstStride] + dstBlock[x + 8*dstStride]\n\n                + dstBlock[x + 9*dstStride] + dstBlock[x +10*dstStride]\n\n                + dstBlock[x +11*dstStride] + dstBlock[x +12*dstStride];\n\n                + dstBlock[x +13*dstStride]\n\n                + dstBlock[x +14*dstStride] + dstBlock[x +15*dstStride];\n\n        }*/\n\n    }\n\n#if   TEMPLATE_PP_3DNOW\n\n    __asm__ volatile(\"femms\");\n\n#elif TEMPLATE_PP_MMX\n\n    __asm__ volatile(\"emms\");\n\n#endif\n\n\n\n#ifdef DEBUG_BRIGHTNESS\n\n    if(!isColor){\n\n        int max=1;\n\n        int i;\n\n        for(i=0; i<256; i++)\n\n            if(yHistogram[i] > max) max=yHistogram[i];\n\n\n\n        for(i=1; i<256; i++){\n\n            int x;\n\n            int start=yHistogram[i-1]/(max/256+1);\n\n            int end=yHistogram[i]/(max/256+1);\n\n            int inc= end > start ? 1 : -1;\n\n            for(x=start; x!=end+inc; x+=inc)\n\n                dst[ i*dstStride + x]+=128;\n\n        }\n\n\n\n        for(i=0; i<100; i+=2){\n\n            dst[ (white)*dstStride + i]+=128;\n\n            dst[ (black)*dstStride + i]+=128;\n\n        }\n\n    }\n\n#endif\n\n\n\n    *c2= c; //copy local context back\n\n\n\n}\n", "idx": 27294}
{"project": "FFmpeg", "commit_id": "432fe9a38afca9104c1c11942d21739e2a48ba96", "target": 1, "func": "static char *choose_pix_fmts(OutputStream *ost)\n\n{\n\n     if (ost->keep_pix_fmt) {\n\n        if (ost->filter)\n\n            avfilter_graph_set_auto_convert(ost->filter->graph->graph,\n\n                                            AVFILTER_AUTO_CONVERT_NONE);\n\n        if (ost->st->codec->pix_fmt == PIX_FMT_NONE)\n\n            return NULL;\n\n        return av_strdup(av_get_pix_fmt_name(ost->st->codec->pix_fmt));\n\n    }\n\n    if (ost->st->codec->pix_fmt != PIX_FMT_NONE) {\n\n        return av_strdup(av_get_pix_fmt_name(choose_pixel_fmt(ost->st, ost->enc, ost->st->codec->pix_fmt)));\n\n    } else if (ost->enc->pix_fmts) {\n\n        const enum PixelFormat *p;\n\n        AVIOContext *s = NULL;\n\n        uint8_t *ret;\n\n        int len;\n\n\n\n        if (avio_open_dyn_buf(&s) < 0)\n\n            exit_program(1);\n\n\n\n        p = ost->enc->pix_fmts;\n\n        if (ost->st->codec->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL) {\n\n            if (ost->st->codec->codec_id == CODEC_ID_MJPEG) {\n\n                p = (const enum PixelFormat[]) { PIX_FMT_YUVJ420P, PIX_FMT_YUVJ422P, PIX_FMT_YUV420P, PIX_FMT_YUV422P, PIX_FMT_NONE };\n\n            } else if (ost->st->codec->codec_id == CODEC_ID_LJPEG) {\n\n                p = (const enum PixelFormat[]) { PIX_FMT_YUVJ420P, PIX_FMT_YUVJ422P, PIX_FMT_YUVJ444P, PIX_FMT_YUV420P,\n\n                                                    PIX_FMT_YUV422P, PIX_FMT_YUV444P, PIX_FMT_BGRA, PIX_FMT_NONE };\n\n            }\n\n        }\n\n\n\n        for (; *p != PIX_FMT_NONE; p++) {\n\n            const char *name = av_get_pix_fmt_name(*p);\n\n            avio_printf(s, \"%s:\", name);\n\n        }\n\n        len = avio_close_dyn_buf(s, &ret);\n\n        ret[len - 1] = 0;\n\n        return ret;\n\n    } else\n\n        return NULL;\n\n}\n", "idx": 27295}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int libschroedinger_encode_init(AVCodecContext *avctx)\n\n{\n\n    SchroEncoderParams *p_schro_params = avctx->priv_data;\n\n    SchroVideoFormatEnum preset;\n\n\n\n    /* Initialize the libraries that libschroedinger depends on. */\n\n    schro_init();\n\n\n\n    /* Create an encoder object. */\n\n    p_schro_params->encoder = schro_encoder_new();\n\n\n\n    if (!p_schro_params->encoder) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Unrecoverable Error: schro_encoder_new failed. \");\n\n        return -1;\n\n    }\n\n\n\n    /* Initialize the format. */\n\n    preset = ff_get_schro_video_format_preset(avctx);\n\n    p_schro_params->format =\n\n                    schro_encoder_get_video_format(p_schro_params->encoder);\n\n    schro_video_format_set_std_video_format(p_schro_params->format, preset);\n\n    p_schro_params->format->width  = avctx->width;\n\n    p_schro_params->format->height = avctx->height;\n\n\n\n    if (set_chroma_format(avctx) == -1)\n\n        return -1;\n\n\n\n    if (avctx->color_primaries == AVCOL_PRI_BT709) {\n\n        p_schro_params->format->colour_primaries = SCHRO_COLOUR_PRIMARY_HDTV;\n\n    } else if (avctx->color_primaries == AVCOL_PRI_BT470BG) {\n\n        p_schro_params->format->colour_primaries = SCHRO_COLOUR_PRIMARY_SDTV_625;\n\n    } else if (avctx->color_primaries == AVCOL_PRI_SMPTE170M) {\n\n        p_schro_params->format->colour_primaries = SCHRO_COLOUR_PRIMARY_SDTV_525;\n\n    }\n\n\n\n    if (avctx->colorspace == AVCOL_SPC_BT709) {\n\n        p_schro_params->format->colour_matrix = SCHRO_COLOUR_MATRIX_HDTV;\n\n    } else if (avctx->colorspace == AVCOL_SPC_BT470BG) {\n\n        p_schro_params->format->colour_matrix = SCHRO_COLOUR_MATRIX_SDTV;\n\n    }\n\n\n\n    if (avctx->color_trc == AVCOL_TRC_BT709) {\n\n        p_schro_params->format->transfer_function = SCHRO_TRANSFER_CHAR_TV_GAMMA;\n\n    }\n\n\n\n    if (ff_get_schro_frame_format(p_schro_params->format->chroma_format,\n\n                                  &p_schro_params->frame_format) == -1) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"This codec currently supports only planar YUV 4:2:0, 4:2:2\"\n\n               \" and 4:4:4 formats.\\n\");\n\n        return -1;\n\n    }\n\n\n\n    p_schro_params->format->frame_rate_numerator   = avctx->time_base.den;\n\n    p_schro_params->format->frame_rate_denominator = avctx->time_base.num;\n\n\n\n    p_schro_params->frame_size = avpicture_get_size(avctx->pix_fmt,\n\n                                                    avctx->width,\n\n                                                    avctx->height);\n\n\n\n    avctx->coded_frame = av_frame_alloc();\n\n    if (!avctx->coded_frame)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if (!avctx->gop_size) {\n\n        schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                         \"gop_structure\",\n\n                                         SCHRO_ENCODER_GOP_INTRA_ONLY);\n\n\n\n        if (avctx->coder_type == FF_CODER_TYPE_VLC)\n\n            schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                             \"enable_noarith\", 1);\n\n    } else {\n\n        schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                         \"au_distance\", avctx->gop_size);\n\n        avctx->has_b_frames = 1;\n\n        p_schro_params->dts = -1;\n\n    }\n\n\n\n    /* FIXME - Need to handle SCHRO_ENCODER_RATE_CONTROL_LOW_DELAY. */\n\n    if (avctx->flags & CODEC_FLAG_QSCALE) {\n\n        if (!avctx->global_quality) {\n\n            /* lossless coding */\n\n            schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                             \"rate_control\",\n\n                                             SCHRO_ENCODER_RATE_CONTROL_LOSSLESS);\n\n        } else {\n\n            int quality;\n\n            schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                             \"rate_control\",\n\n                                             SCHRO_ENCODER_RATE_CONTROL_CONSTANT_QUALITY);\n\n\n\n            quality = avctx->global_quality / FF_QP2LAMBDA;\n\n            if (quality > 10)\n\n                quality = 10;\n\n            schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                             \"quality\", quality);\n\n        }\n\n    } else {\n\n        schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                         \"rate_control\",\n\n                                         SCHRO_ENCODER_RATE_CONTROL_CONSTANT_BITRATE);\n\n\n\n        schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                         \"bitrate\", avctx->bit_rate);\n\n    }\n\n\n\n    if (avctx->flags & CODEC_FLAG_INTERLACED_ME)\n\n        /* All material can be coded as interlaced or progressive\n\n           irrespective of the type of source material. */\n\n        schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                         \"interlaced_coding\", 1);\n\n\n\n    schro_encoder_setting_set_double(p_schro_params->encoder, \"open_gop\",\n\n                                     !(avctx->flags & CODEC_FLAG_CLOSED_GOP));\n\n\n\n    /* FIXME: Signal range hardcoded to 8-bit data until both libschroedinger\n\n     * and libdirac support other bit-depth data. */\n\n    schro_video_format_set_std_signal_range(p_schro_params->format,\n\n                                            SCHRO_SIGNAL_RANGE_8BIT_VIDEO);\n\n\n\n    /* Set the encoder format. */\n\n    schro_encoder_set_video_format(p_schro_params->encoder,\n\n                                   p_schro_params->format);\n\n\n\n    /* Set the debug level. */\n\n    schro_debug_set_level(avctx->debug);\n\n\n\n    schro_encoder_start(p_schro_params->encoder);\n\n\n\n    /* Initialize the encoded frame queue. */\n\n    ff_schro_queue_init(&p_schro_params->enc_frame_queue);\n\n    return 0;\n\n}\n", "idx": 27296}
{"project": "FFmpeg", "commit_id": "a23379a0a68a6dd9a0e0d583e11b0c6f9b33f9ae", "target": 0, "func": "static int xiph_handle_packet(AVFormatContext *ctx, PayloadContext *data,\n\n                              AVStream *st, AVPacket *pkt, uint32_t *timestamp,\n\n                              const uint8_t *buf, int len, uint16_t seq,\n\n                              int flags)\n\n{\n\n\n\n    int ident, fragmented, tdt, num_pkts, pkt_len;\n\n\n\n    if (!buf) {\n\n        if (!data->split_buf || data->split_pos + 2 > data->split_buf_len ||\n\n            data->split_pkts <= 0) {\n\n            av_log(ctx, AV_LOG_ERROR, \"No more data to return\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        pkt_len = AV_RB16(data->split_buf + data->split_pos);\n\n        data->split_pos += 2;\n\n        if (data->split_pos + pkt_len > data->split_buf_len) {\n\n            av_log(ctx, AV_LOG_ERROR, \"Not enough data to return\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (av_new_packet(pkt, pkt_len)) {\n\n            av_log(ctx, AV_LOG_ERROR, \"Out of memory.\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        pkt->stream_index = st->index;\n\n        memcpy(pkt->data, data->split_buf + data->split_pos, pkt_len);\n\n        data->split_pos += pkt_len;\n\n        data->split_pkts--;\n\n        return data->split_pkts > 0;\n\n    }\n\n\n\n    if (len < 6 || len > INT_MAX/2) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Invalid %d byte packet\\n\", len);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    // read xiph rtp headers\n\n    ident       = AV_RB24(buf);\n\n    fragmented  = buf[3] >> 6;\n\n    tdt         = (buf[3] >> 4) & 3;\n\n    num_pkts    = buf[3] & 0xf;\n\n    pkt_len     = AV_RB16(buf + 4);\n\n\n\n    if (pkt_len > len - 6) {\n\n        av_log(ctx, AV_LOG_ERROR,\n\n               \"Invalid packet length %d in %d byte packet\\n\", pkt_len,\n\n               len);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (ident != data->ident) {\n\n        av_log(ctx, AV_LOG_ERROR,\n\n               \"Unimplemented Xiph SDP configuration change detected\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if (tdt) {\n\n        av_log(ctx, AV_LOG_ERROR,\n\n               \"Unimplemented RTP Xiph packet settings (%d,%d,%d)\\n\",\n\n               fragmented, tdt, num_pkts);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    buf += 6; // move past header bits\n\n    len -= 6;\n\n\n\n    if (fragmented == 0) {\n\n        if (av_new_packet(pkt, pkt_len)) {\n\n            av_log(ctx, AV_LOG_ERROR, \"Out of memory.\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        pkt->stream_index = st->index;\n\n        memcpy(pkt->data, buf, pkt_len);\n\n        buf += pkt_len;\n\n        len -= pkt_len;\n\n        num_pkts--;\n\n\n\n        if (num_pkts > 0) {\n\n            if (len > data->split_buf_size || !data->split_buf) {\n\n                av_freep(&data->split_buf);\n\n                data->split_buf_size = 2 * len;\n\n                data->split_buf = av_malloc(data->split_buf_size);\n\n                if (!data->split_buf) {\n\n                    av_log(ctx, AV_LOG_ERROR, \"Out of memory.\\n\");\n\n                    av_free_packet(pkt);\n\n                    return AVERROR(ENOMEM);\n\n                }\n\n            }\n\n            memcpy(data->split_buf, buf, len);\n\n            data->split_buf_len = len;\n\n            data->split_pos = 0;\n\n            data->split_pkts = num_pkts;\n\n            return 1;\n\n        }\n\n\n\n        return 0;\n\n\n\n    } else if (fragmented == 1) {\n\n        // start of xiph data fragment\n\n        int res;\n\n\n\n        // end packet has been lost somewhere, so drop buffered data\n\n        ffio_free_dyn_buf(&data->fragment);\n\n\n\n        if((res = avio_open_dyn_buf(&data->fragment)) < 0)\n\n            return res;\n\n\n\n        avio_write(data->fragment, buf, pkt_len);\n\n        data->timestamp = *timestamp;\n\n\n\n    } else {\n\n        av_assert1(fragmented < 4);\n\n        if (data->timestamp != *timestamp) {\n\n            // skip if fragmented timestamp is incorrect;\n\n            // a start packet has been lost somewhere\n\n            ffio_free_dyn_buf(&data->fragment);\n\n            av_log(ctx, AV_LOG_ERROR, \"RTP timestamps don't match!\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (!data->fragment) {\n\n            av_log(ctx, AV_LOG_WARNING,\n\n                   \"Received packet without a start fragment; dropping.\\n\");\n\n            return AVERROR(EAGAIN);\n\n        }\n\n\n\n        // copy data to fragment buffer\n\n        avio_write(data->fragment, buf, pkt_len);\n\n\n\n        if (fragmented == 3) {\n\n            // end of xiph data packet\n\n            int ret = ff_rtp_finalize_packet(pkt, &data->fragment, st->index);\n\n            if (ret < 0) {\n\n                av_log(ctx, AV_LOG_ERROR,\n\n                       \"Error occurred when getting fragment buffer.\");\n\n                return ret;\n\n            }\n\n\n\n            return 0;\n\n        }\n\n    }\n\n\n\n   return AVERROR(EAGAIN);\n\n}\n", "idx": 27297}
{"project": "FFmpeg", "commit_id": "37f573543c4fd7f44339e04d8d15b95118493ddd", "target": 0, "func": "static int check_image_pointers(uint8_t *data[4], enum AVPixelFormat pix_fmt,\n\n                                const int linesizes[4])\n\n{\n\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(pix_fmt);\n\n    int i;\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        int plane = desc->comp[i].plane;\n\n        if (!data[plane] || !linesizes[plane])\n\n            return 0;\n\n    }\n\n\n\n    return 1;\n\n}\n", "idx": 27298}
{"project": "FFmpeg", "commit_id": "ae591aeea58d64399b8281be31dacec0de85ae04", "target": 0, "func": "static void vc1_mc_4mv_luma(VC1Context *v, int n, int dir)\n\n{\n\n    MpegEncContext *s = &v->s;\n\n    DSPContext *dsp = &v->s.dsp;\n\n    uint8_t *srcY;\n\n    int dxy, mx, my, src_x, src_y;\n\n    int off;\n\n    int fieldmv = (v->fcm == ILACE_FRAME) ? v->blk_mv_type[s->block_index[n]] : 0;\n\n    int v_edge_pos = s->v_edge_pos >> v->field_mode;\n\n\n\n    if (!v->field_mode && !v->s.last_picture.f.data[0])\n\n        return;\n\n\n\n    mx = s->mv[dir][n][0];\n\n    my = s->mv[dir][n][1];\n\n\n\n    if (!dir) {\n\n        if (v->field_mode) {\n\n            if ((v->cur_field_type != v->ref_field_type[dir]) && v->cur_field_type)\n\n                srcY = s->current_picture.f.data[0];\n\n            else\n\n                srcY = s->last_picture.f.data[0];\n\n        } else\n\n            srcY = s->last_picture.f.data[0];\n\n    } else\n\n        srcY = s->next_picture.f.data[0];\n\n\n\n    if (v->field_mode) {\n\n        if (v->cur_field_type != v->ref_field_type[dir])\n\n            my = my - 2 + 4 * v->cur_field_type;\n\n    }\n\n\n\n    if (s->pict_type == AV_PICTURE_TYPE_P && n == 3 && v->field_mode) {\n\n        int same_count = 0, opp_count = 0, k;\n\n        int chosen_mv[2][4][2], f;\n\n        int tx, ty;\n\n        for (k = 0; k < 4; k++) {\n\n            f = v->mv_f[0][s->block_index[k] + v->blocks_off];\n\n            chosen_mv[f][f ? opp_count : same_count][0] = s->mv[0][k][0];\n\n            chosen_mv[f][f ? opp_count : same_count][1] = s->mv[0][k][1];\n\n            opp_count  += f;\n\n            same_count += 1 - f;\n\n        }\n\n        f = opp_count > same_count;\n\n        switch (f ? opp_count : same_count) {\n\n        case 4:\n\n            tx = median4(chosen_mv[f][0][0], chosen_mv[f][1][0],\n\n                         chosen_mv[f][2][0], chosen_mv[f][3][0]);\n\n            ty = median4(chosen_mv[f][0][1], chosen_mv[f][1][1],\n\n                         chosen_mv[f][2][1], chosen_mv[f][3][1]);\n\n            break;\n\n        case 3:\n\n            tx = mid_pred(chosen_mv[f][0][0], chosen_mv[f][1][0], chosen_mv[f][2][0]);\n\n            ty = mid_pred(chosen_mv[f][0][1], chosen_mv[f][1][1], chosen_mv[f][2][1]);\n\n            break;\n\n        case 2:\n\n            tx = (chosen_mv[f][0][0] + chosen_mv[f][1][0]) / 2;\n\n            ty = (chosen_mv[f][0][1] + chosen_mv[f][1][1]) / 2;\n\n            break;\n\n        }\n\n        s->current_picture.f.motion_val[1][s->block_index[0] + v->blocks_off][0] = tx;\n\n        s->current_picture.f.motion_val[1][s->block_index[0] + v->blocks_off][1] = ty;\n\n        for (k = 0; k < 4; k++)\n\n            v->mv_f[1][s->block_index[k] + v->blocks_off] = f;\n\n    }\n\n\n\n    if (v->fcm == ILACE_FRAME) {  // not sure if needed for other types of picture\n\n        int qx, qy;\n\n        int width  = s->avctx->coded_width;\n\n        int height = s->avctx->coded_height >> 1;\n\n        qx = (s->mb_x * 16) + (mx >> 2);\n\n        qy = (s->mb_y *  8) + (my >> 3);\n\n\n\n        if (qx < -17)\n\n            mx -= 4 * (qx + 17);\n\n        else if (qx > width)\n\n            mx -= 4 * (qx - width);\n\n        if (qy < -18)\n\n            my -= 8 * (qy + 18);\n\n        else if (qy > height + 1)\n\n            my -= 8 * (qy - height - 1);\n\n    }\n\n\n\n    if ((v->fcm == ILACE_FRAME) && fieldmv)\n\n        off = ((n > 1) ? s->linesize : 0) + (n & 1) * 8;\n\n    else\n\n        off = s->linesize * 4 * (n & 2) + (n & 1) * 8;\n\n    if (v->field_mode && v->cur_field_type)\n\n        off += s->current_picture_ptr->f.linesize[0];\n\n\n\n    src_x = s->mb_x * 16 + (n & 1) * 8 + (mx >> 2);\n\n    if (!fieldmv)\n\n        src_y = s->mb_y * 16 + (n & 2) * 4 + (my >> 2);\n\n    else\n\n        src_y = s->mb_y * 16 + ((n > 1) ? 1 : 0) + (my >> 2);\n\n\n\n    if (v->profile != PROFILE_ADVANCED) {\n\n        src_x = av_clip(src_x, -16, s->mb_width  * 16);\n\n        src_y = av_clip(src_y, -16, s->mb_height * 16);\n\n    } else {\n\n        src_x = av_clip(src_x, -17, s->avctx->coded_width);\n\n        if (v->fcm == ILACE_FRAME) {\n\n            if (src_y & 1)\n\n                src_y = av_clip(src_y, -17, s->avctx->coded_height + 1);\n\n            else\n\n                src_y = av_clip(src_y, -18, s->avctx->coded_height);\n\n        } else {\n\n            src_y = av_clip(src_y, -18, s->avctx->coded_height + 1);\n\n        }\n\n    }\n\n\n\n    srcY += src_y * s->linesize + src_x;\n\n    if (v->field_mode && v->ref_field_type[dir])\n\n        srcY += s->current_picture_ptr->f.linesize[0];\n\n\n\n    if (fieldmv && !(src_y & 1))\n\n        v_edge_pos--;\n\n    if (fieldmv && (src_y & 1) && src_y < 4)\n\n        src_y--;\n\n    if (v->rangeredfrm || (v->mv_mode == MV_PMODE_INTENSITY_COMP)\n\n        || s->h_edge_pos < 13 || v_edge_pos < 23\n\n        || (unsigned)(src_x - s->mspel) > s->h_edge_pos - (mx & 3) - 8 - s->mspel * 2\n\n        || (unsigned)(src_y - (s->mspel << fieldmv)) > v_edge_pos - (my & 3) - ((8 + s->mspel * 2) << fieldmv)) {\n\n        srcY -= s->mspel * (1 + (s->linesize << fieldmv));\n\n        /* check emulate edge stride and offset */\n\n        s->dsp.emulated_edge_mc(s->edge_emu_buffer, srcY, s->linesize,\n\n                                9 + s->mspel * 2, (9 + s->mspel * 2) << fieldmv,\n\n                                src_x - s->mspel, src_y - (s->mspel << fieldmv),\n\n                                s->h_edge_pos, v_edge_pos);\n\n        srcY = s->edge_emu_buffer;\n\n        /* if we deal with range reduction we need to scale source blocks */\n\n        if (v->rangeredfrm) {\n\n            int i, j;\n\n            uint8_t *src;\n\n\n\n            src = srcY;\n\n            for (j = 0; j < 9 + s->mspel * 2; j++) {\n\n                for (i = 0; i < 9 + s->mspel * 2; i++)\n\n                    src[i] = ((src[i] - 128) >> 1) + 128;\n\n                src += s->linesize << fieldmv;\n\n            }\n\n        }\n\n        /* if we deal with intensity compensation we need to scale source blocks */\n\n        if (v->mv_mode == MV_PMODE_INTENSITY_COMP) {\n\n            int i, j;\n\n            uint8_t *src;\n\n\n\n            src = srcY;\n\n            for (j = 0; j < 9 + s->mspel * 2; j++) {\n\n                for (i = 0; i < 9 + s->mspel * 2; i++)\n\n                    src[i] = v->luty[src[i]];\n\n                src += s->linesize << fieldmv;\n\n            }\n\n        }\n\n        srcY += s->mspel * (1 + (s->linesize << fieldmv));\n\n    }\n\n\n\n    if (s->mspel) {\n\n        dxy = ((my & 3) << 2) | (mx & 3);\n\n        v->vc1dsp.put_vc1_mspel_pixels_tab[dxy](s->dest[0] + off, srcY, s->linesize << fieldmv, v->rnd);\n\n    } else { // hpel mc - always used for luma\n\n        dxy = (my & 2) | ((mx & 2) >> 1);\n\n        if (!v->rnd)\n\n            dsp->put_pixels_tab[1][dxy](s->dest[0] + off, srcY, s->linesize, 8);\n\n        else\n\n            dsp->put_no_rnd_pixels_tab[1][dxy](s->dest[0] + off, srcY, s->linesize, 8);\n\n    }\n\n}\n", "idx": 27299}
{"project": "FFmpeg", "commit_id": "84be80698227366d970e045001e4b59e4f99f0a1", "target": 0, "func": "static void pool_release_buffer(void *opaque, uint8_t *data)\n\n{\n\n    BufferPoolEntry *buf = opaque;\n\n    AVBufferPool *pool = buf->pool;\n\n\n\n    if(CONFIG_MEMORY_POISONING)\n\n        memset(buf->data, 0x2a, pool->size);\n\n\n\n    add_to_pool(buf);\n\n    if (!avpriv_atomic_int_add_and_fetch(&pool->refcount, -1))\n\n        buffer_pool_free(pool);\n\n}\n", "idx": 27306}
{"project": "FFmpeg", "commit_id": "7104c23bd1a1dcb8a7d9e2c8838c7ce55c30a331", "target": 0, "func": "static void rv34_pred_mv(RV34DecContext *r, int block_type, int subblock_no, int dmv_no)\n\n{\n\n    MpegEncContext *s = &r->s;\n\n    int mv_pos = s->mb_x * 2 + s->mb_y * 2 * s->b8_stride;\n\n    int A[2] = {0}, B[2], C[2];\n\n    int i, j;\n\n    int mx, my;\n\n    int avail_index = avail_indexes[subblock_no];\n\n    int c_off = part_sizes_w[block_type];\n\n\n\n    mv_pos += (subblock_no & 1) + (subblock_no >> 1)*s->b8_stride;\n\n    if(subblock_no == 3)\n\n        c_off = -1;\n\n\n\n    if(r->avail_cache[avail_index - 1]){\n\n        A[0] = s->current_picture_ptr->f.motion_val[0][mv_pos-1][0];\n\n        A[1] = s->current_picture_ptr->f.motion_val[0][mv_pos-1][1];\n\n    }\n\n    if(r->avail_cache[avail_index - 4]){\n\n        B[0] = s->current_picture_ptr->f.motion_val[0][mv_pos-s->b8_stride][0];\n\n        B[1] = s->current_picture_ptr->f.motion_val[0][mv_pos-s->b8_stride][1];\n\n    }else{\n\n        B[0] = A[0];\n\n        B[1] = A[1];\n\n    }\n\n    if(!r->avail_cache[avail_index - 4 + c_off]){\n\n        if(r->avail_cache[avail_index - 4] && (r->avail_cache[avail_index - 1] || r->rv30)){\n\n            C[0] = s->current_picture_ptr->f.motion_val[0][mv_pos-s->b8_stride-1][0];\n\n            C[1] = s->current_picture_ptr->f.motion_val[0][mv_pos-s->b8_stride-1][1];\n\n        }else{\n\n            C[0] = A[0];\n\n            C[1] = A[1];\n\n        }\n\n    }else{\n\n        C[0] = s->current_picture_ptr->f.motion_val[0][mv_pos-s->b8_stride+c_off][0];\n\n        C[1] = s->current_picture_ptr->f.motion_val[0][mv_pos-s->b8_stride+c_off][1];\n\n    }\n\n    mx = mid_pred(A[0], B[0], C[0]);\n\n    my = mid_pred(A[1], B[1], C[1]);\n\n    mx += r->dmv[dmv_no][0];\n\n    my += r->dmv[dmv_no][1];\n\n    for(j = 0; j < part_sizes_h[block_type]; j++){\n\n        for(i = 0; i < part_sizes_w[block_type]; i++){\n\n            s->current_picture_ptr->f.motion_val[0][mv_pos + i + j*s->b8_stride][0] = mx;\n\n            s->current_picture_ptr->f.motion_val[0][mv_pos + i + j*s->b8_stride][1] = my;\n\n        }\n\n    }\n\n}\n", "idx": 27317}
