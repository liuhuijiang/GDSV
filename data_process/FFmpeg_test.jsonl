{"project": "FFmpeg", "commit_id": "5e6ce28dabe002a6130f17b59c454bdee33088f7", "target": 0, "func": "static int mp3_seek(AVFormatContext *s, int stream_index, int64_t timestamp,\n\n                    int flags)\n\n{\n\n    MP3DecContext *mp3 = s->priv_data;\n\n    AVIndexEntry *ie, ie1;\n\n    AVStream *st = s->streams[0];\n\n    int64_t ret  = av_index_search_timestamp(st, timestamp, flags);\n\n    int64_t best_pos;\n\n    int fast_seek = (s->flags & AVFMT_FLAG_FAST_SEEK) ? 1 : 0;\n\n    int64_t filesize = mp3->header_filesize;\n\n\n\n    if (mp3->usetoc == 2)\n\n        return -1; // generic index code\n\n\n\n    if (filesize <= 0) {\n\n        int64_t size = avio_size(s->pb);\n\n        if (size > 0 && size > s->internal->data_offset)\n\n            filesize = size - s->internal->data_offset;\n\n    }\n\n\n\n    if (   (mp3->is_cbr || fast_seek)\n\n        && (mp3->usetoc == 0 || !mp3->xing_toc)\n\n        && st->duration > 0\n\n        && filesize > 0) {\n\n        ie = &ie1;\n\n        timestamp = av_clip64(timestamp, 0, st->duration);\n\n        ie->timestamp = timestamp;\n\n        ie->pos       = av_rescale(timestamp, filesize, st->duration) + s->internal->data_offset;\n\n    } else if (mp3->xing_toc) {\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        ie = &st->index_entries[ret];\n\n    } else {\n\n        return -1;\n\n    }\n\n\n\n    best_pos = mp3_sync(s, ie->pos, flags);\n\n    if (best_pos < 0)\n\n        return best_pos;\n\n\n\n    if (mp3->is_cbr && ie == &ie1 && mp3->frames) {\n\n        int frame_duration = av_rescale(st->duration, 1, mp3->frames);\n\n        ie1.timestamp = frame_duration * av_rescale(best_pos - s->internal->data_offset, mp3->frames, mp3->header_filesize);\n\n    }\n\n\n\n    ff_update_cur_dts(s, st, ie->timestamp);\n\n    return 0;\n\n}\n", "idx": 22015}
{"project": "FFmpeg", "commit_id": "b5f45208fbe5373c7f9112a8169933b73a8478e1", "target": 1, "func": "static inline CopyRet copy_frame(AVCodecContext *avctx,\n\n                                 BC_DTS_PROC_OUT *output,\n\n                                 void *data, int *got_frame)\n\n{\n\n    BC_STATUS ret;\n\n    BC_DTS_STATUS decoder_status = { 0, };\n\n    uint8_t trust_interlaced;\n\n    uint8_t interlaced;\n\n\n\n    CHDContext *priv = avctx->priv_data;\n\n    int64_t pkt_pts  = AV_NOPTS_VALUE;\n\n    uint8_t pic_type = 0;\n\n\n\n    uint8_t bottom_field = (output->PicInfo.flags & VDEC_FLAG_BOTTOMFIELD) ==\n\n                           VDEC_FLAG_BOTTOMFIELD;\n\n    uint8_t bottom_first = !!(output->PicInfo.flags & VDEC_FLAG_BOTTOM_FIRST);\n\n\n\n    int width    = output->PicInfo.width;\n\n    int height   = output->PicInfo.height;\n\n    int bwidth;\n\n    uint8_t *src = output->Ybuff;\n\n    int sStride;\n\n    uint8_t *dst;\n\n    int dStride;\n\n\n\n    if (output->PicInfo.timeStamp != 0) {\n\n        OpaqueList *node = opaque_list_pop(priv, output->PicInfo.timeStamp);\n\n        if (node) {\n\n            pkt_pts = node->reordered_opaque;\n\n            pic_type = node->pic_type;\n\n            av_free(node);\n\n        } else {\n\n            /*\n\n             * We will encounter a situation where a timestamp cannot be\n\n             * popped if a second field is being returned. In this case,\n\n             * each field has the same timestamp and the first one will\n\n             * cause it to be popped. To keep subsequent calculations\n\n             * simple, pic_type should be set a FIELD value - doesn't\n\n             * matter which, but I chose BOTTOM.\n\n             */\n\n            pic_type = PICT_BOTTOM_FIELD;\n\n        }\n\n        av_log(avctx, AV_LOG_VERBOSE, \"output \\\"pts\\\": %\"PRIu64\"\\n\",\n\n               output->PicInfo.timeStamp);\n\n        av_log(avctx, AV_LOG_VERBOSE, \"output picture type %d\\n\",\n\n               pic_type);\n\n    }\n\n\n\n    ret = DtsGetDriverStatus(priv->dev, &decoder_status);\n\n    if (ret != BC_STS_SUCCESS) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"CrystalHD: GetDriverStatus failed: %u\\n\", ret);\n\n       return RET_ERROR;\n\n    }\n\n\n\n    /*\n\n     * For most content, we can trust the interlaced flag returned\n\n     * by the hardware, but sometimes we can't. These are the\n\n     * conditions under which we can trust the flag:\n\n     *\n\n     * 1) It's not h.264 content\n\n     * 2) The UNKNOWN_SRC flag is not set\n\n     * 3) We know we're expecting a second field\n\n     * 4) The hardware reports this picture and the next picture\n\n     *    have the same picture number.\n\n     *\n\n     * Note that there can still be interlaced content that will\n\n     * fail this check, if the hardware hasn't decoded the next\n\n     * picture or if there is a corruption in the stream. (In either\n\n     * case a 0 will be returned for the next picture number)\n\n     */\n\n    trust_interlaced = avctx->codec->id != AV_CODEC_ID_H264 ||\n\n                       !(output->PicInfo.flags & VDEC_FLAG_UNKNOWN_SRC) ||\n\n                       priv->need_second_field ||\n\n                       (decoder_status.picNumFlags & ~0x40000000) ==\n\n                       output->PicInfo.picture_number;\n\n\n\n    /*\n\n     * If we got a false negative for trust_interlaced on the first field,\n\n     * we will realise our mistake here when we see that the picture number is that\n\n     * of the previous picture. We cannot recover the frame and should discard the\n\n     * second field to keep the correct number of output frames.\n\n     */\n\n    if (output->PicInfo.picture_number == priv->last_picture && !priv->need_second_field) {\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"Incorrectly guessed progressive frame. Discarding second field\\n\");\n\n        /* Returning without providing a picture. */\n\n        return RET_OK;\n\n    }\n\n\n\n    interlaced = (output->PicInfo.flags & VDEC_FLAG_INTERLACED_SRC) &&\n\n                 trust_interlaced;\n\n\n\n    if (!trust_interlaced && (decoder_status.picNumFlags & ~0x40000000) == 0) {\n\n        av_log(avctx, AV_LOG_VERBOSE,\n\n               \"Next picture number unknown. Assuming progressive frame.\\n\");\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_VERBOSE, \"Interlaced state: %d | trust_interlaced %d\\n\",\n\n           interlaced, trust_interlaced);\n\n\n\n    if (priv->pic->data[0] && !priv->need_second_field)\n\n        av_frame_unref(priv->pic);\n\n\n\n    priv->need_second_field = interlaced && !priv->need_second_field;\n\n\n\n    if (!priv->pic->data[0]) {\n\n        if (ff_get_buffer(avctx, priv->pic, AV_GET_BUFFER_FLAG_REF) < 0)\n\n            return RET_ERROR;\n\n    }\n\n\n\n    bwidth = av_image_get_linesize(avctx->pix_fmt, width, 0);\n\n    if (priv->is_70012) {\n\n        int pStride;\n\n\n\n        if (width <= 720)\n\n            pStride = 720;\n\n        else if (width <= 1280)\n\n            pStride = 1280;\n\n        else pStride = 1920;\n\n        sStride = av_image_get_linesize(avctx->pix_fmt, pStride, 0);\n\n    } else {\n\n        sStride = bwidth;\n\n    }\n\n\n\n    dStride = priv->pic->linesize[0];\n\n    dst     = priv->pic->data[0];\n\n\n\n    av_log(priv->avctx, AV_LOG_VERBOSE, \"CrystalHD: Copying out frame\\n\");\n\n\n\n    if (interlaced) {\n\n        int dY = 0;\n\n        int sY = 0;\n\n\n\n        height /= 2;\n\n        if (bottom_field) {\n\n            av_log(priv->avctx, AV_LOG_VERBOSE, \"Interlaced: bottom field\\n\");\n\n            dY = 1;\n\n        } else {\n\n            av_log(priv->avctx, AV_LOG_VERBOSE, \"Interlaced: top field\\n\");\n\n            dY = 0;\n\n        }\n\n\n\n        for (sY = 0; sY < height; dY++, sY++) {\n\n            memcpy(&(dst[dY * dStride]), &(src[sY * sStride]), bwidth);\n\n            dY++;\n\n        }\n\n    } else {\n\n        av_image_copy_plane(dst, dStride, src, sStride, bwidth, height);\n\n    }\n\n\n\n    priv->pic->interlaced_frame = interlaced;\n\n    if (interlaced)\n\n        priv->pic->top_field_first = !bottom_first;\n\n\n\n    priv->pic->pts = pkt_pts;\n\n#if FF_API_PKT_PTS\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    priv->pic->pkt_pts = pkt_pts;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n\n\n    if (!priv->need_second_field) {\n\n        *got_frame       = 1;\n\n        if ((ret = av_frame_ref(data, priv->pic)) < 0) {\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    /*\n\n     * Two types of PAFF content have been observed. One form causes the\n\n     * hardware to return a field pair and the other individual fields,\n\n     * even though the input is always individual fields. We must skip\n\n     * copying on the next decode() call to maintain pipeline length in\n\n     * the first case.\n\n     */\n\n    if (!interlaced && (output->PicInfo.flags & VDEC_FLAG_UNKNOWN_SRC) &&\n\n        (pic_type == PICT_TOP_FIELD || pic_type == PICT_BOTTOM_FIELD)) {\n\n        av_log(priv->avctx, AV_LOG_VERBOSE, \"Fieldpair from two packets.\\n\");\n\n        return RET_SKIP_NEXT_COPY;\n\n    }\n\n\n\n    /*\n\n     * The logic here is purely based on empirical testing with samples.\n\n     * If we need a second field, it could come from a second input packet,\n\n     * or it could come from the same field-pair input packet at the current\n\n     * field. In the first case, we should return and wait for the next time\n\n     * round to get the second field, while in the second case, we should\n\n     * ask the decoder for it immediately.\n\n     *\n\n     * Testing has shown that we are dealing with the fieldpair -> two fields\n\n     * case if the VDEC_FLAG_UNKNOWN_SRC is not set or if the input picture\n\n     * type was PICT_FRAME (in this second case, the flag might still be set)\n\n     */\n\n    return priv->need_second_field &&\n\n           (!(output->PicInfo.flags & VDEC_FLAG_UNKNOWN_SRC) ||\n\n            pic_type == PICT_FRAME) ?\n\n           RET_COPY_NEXT_FIELD : RET_OK;\n\n}\n", "idx": 22019}
{"project": "FFmpeg", "commit_id": "d9f4dc52a0fe3edb93f153cf13e750f7c46243d1", "target": 1, "func": "static av_cold int prores_encode_init(AVCodecContext *avctx)\n\n{\n\n    int i;\n\n    ProresContext* ctx = avctx->priv_data;\n\n\n\n    if (avctx->pix_fmt != PIX_FMT_YUV422P10LE) {\n\n        av_log(avctx, AV_LOG_ERROR, \"need YUV422P10\\n\");\n\n        return -1;\n\n    }\n\n    if (avctx->width & 0x1) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n                \"frame width needs to be multiple of 2\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if ((avctx->height & 0xf) || (avctx->width & 0xf)) {\n\n        ctx->fill_y = av_malloc(DEFAULT_SLICE_MB_WIDTH << 9);\n\n        ctx->fill_u = av_malloc(DEFAULT_SLICE_MB_WIDTH << 8);\n\n        ctx->fill_v = av_malloc(DEFAULT_SLICE_MB_WIDTH << 8);\n\n    }\n\n\n\n    if (avctx->profile == FF_PROFILE_UNKNOWN) {\n\n        avctx->profile = FF_PROFILE_PRORES_STANDARD;\n\n        av_log(avctx, AV_LOG_INFO,\n\n                \"encoding with ProRes standard (apcn) profile\\n\");\n\n\n\n    } else if (avctx->profile < FF_PROFILE_PRORES_PROXY\n\n            || avctx->profile > FF_PROFILE_PRORES_HQ) {\n\n        av_log(\n\n                avctx,\n\n                AV_LOG_ERROR,\n\n                \"unknown profile %d, use [0 - apco, 1 - apcs, 2 - apcn (default), 3 - apch]\\n\",\n\n                avctx->profile);\n\n        return -1;\n\n    }\n\n\n\n    avctx->codec_tag = AV_RL32((const uint8_t*)profiles[avctx->profile].name);\n\n\n\n    for (i = 1; i <= 16; i++) {\n\n        scale_mat(QMAT_LUMA[avctx->profile]  , ctx->qmat_luma[i - 1]  , i);\n\n        scale_mat(QMAT_CHROMA[avctx->profile], ctx->qmat_chroma[i - 1], i);\n\n    }\n\n\n\n    avctx->coded_frame = avcodec_alloc_frame();\n\n    avctx->coded_frame->key_frame = 1;\n\n    avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    return 0;\n\n}\n", "idx": 22020}
{"project": "FFmpeg", "commit_id": "11ce88346b1ae4da21b581baf1b4eb784d842547", "target": 1, "func": "int estimate_motion(MpegEncContext * s,\n\n\t\t    int mb_x, int mb_y,\n\n\t\t    int *mx_ptr, int *my_ptr)\n\n{\n\n    UINT8 *pix, *ppix;\n\n    int sum, varc, vard, mx, my, range, dmin, xx, yy;\n\n    int xmin, ymin, xmax, ymax;\n\n    int rel_xmin, rel_ymin, rel_xmax, rel_ymax;\n\n    int pred_x=0, pred_y=0;\n\n    int P[5][2];\n\n    const int shift= 1+s->quarter_sample;\n\n    \n\n    range = 8 * (1 << (s->f_code - 1));\n\n    /* XXX: temporary kludge to avoid overflow for msmpeg4 */\n\n    if (s->out_format == FMT_H263 && !s->h263_msmpeg4)\n\n\trange = range * 2;\n\n\n\n    if (s->unrestricted_mv) {\n\n        xmin = -16;\n\n        ymin = -16;\n\n        if (s->h263_plus)\n\n            range *= 2;\n\n        if(s->avctx==NULL || s->avctx->codec->id!=CODEC_ID_MPEG4){\n\n            xmax = s->mb_width*16;\n\n            ymax = s->mb_height*16;\n\n        }else {\n\n            /* XXX: dunno if this is correct but ffmpeg4 decoder wont like it otherwise \n\n\t            (cuz the drawn edge isnt large enough))*/\n\n            xmax = s->width;\n\n            ymax = s->height;\n\n        }\n\n    } else {\n\n        xmin = 0;\n\n        ymin = 0;\n\n        xmax = s->mb_width*16 - 16;\n\n        ymax = s->mb_height*16 - 16;\n\n    }\n\n    switch(s->full_search) {\n\n    case ME_ZERO:\n\n    default:\n\n\tno_motion_search(s, &mx, &my);\n\n        dmin = 0;\n\n        break;\n\n    case ME_FULL:\n\n\tdmin = full_motion_search(s, &mx, &my, range, xmin, ymin, xmax, ymax);\n\n        break;\n\n    case ME_LOG:\n\n\tdmin = log_motion_search(s, &mx, &my, range / 2, xmin, ymin, xmax, ymax);\n\n        break;\n\n    case ME_PHODS:\n\n\tdmin = phods_motion_search(s, &mx, &my, range / 2, xmin, ymin, xmax, ymax);\n\n        break;\n\n    case ME_X1: // just reserving some space for experiments ...\n\n    case ME_EPZS:\n\n        rel_xmin= xmin - s->mb_x*16;\n\n        rel_xmax= xmax - s->mb_x*16;\n\n        rel_ymin= ymin - s->mb_y*16;\n\n        rel_ymax= ymax - s->mb_y*16;\n\n        if(s->out_format == FMT_H263){\n\n            static const int off[4]= {2, 1, 1, -1};\n\n            const int mot_stride = s->block_wrap[0];\n\n            const int mot_xy = s->block_index[0];\n\n         \n\n            P[0][0] = s->motion_val[mot_xy    ][0];\n\n            P[0][1] = s->motion_val[mot_xy    ][1];\n\n            P[1][0] = s->motion_val[mot_xy - 1][0];\n\n            P[1][1] = s->motion_val[mot_xy - 1][1];\n\n            if(P[1][0] > (rel_xmax<<shift)) P[1][0]= (rel_xmax<<shift);\n\n\n\n            /* special case for first line */\n\n            if ((s->mb_y == 0 || s->first_slice_line || s->first_gob_line)) {\n\n                pred_x = P[1][0];\n\n                pred_y = P[1][1];\n\n            } else {\n\n                P[2][0] = s->motion_val[mot_xy - mot_stride             ][0];\n\n                P[2][1] = s->motion_val[mot_xy - mot_stride             ][1];\n\n                P[3][0] = s->motion_val[mot_xy - mot_stride + off[0]    ][0];\n\n                P[3][1] = s->motion_val[mot_xy - mot_stride + off[0]    ][1];\n\n                if(P[2][1] > (rel_ymax<<shift)) P[2][1]= (rel_ymax<<shift);\n\n                if(P[3][0] < (rel_xmin<<shift)) P[3][0]= (rel_xmin<<shift);\n\n                if(P[3][1] > (rel_ymax<<shift)) P[3][1]= (rel_ymax<<shift);\n\n        \n\n                P[4][0]= pred_x = mid_pred(P[1][0], P[2][0], P[3][0]);\n\n                P[4][1]= pred_y = mid_pred(P[1][1], P[2][1], P[3][1]);\n\n            }\n\n        }else {\n\n            const int xy= s->mb_y*s->mb_width + s->mb_x;\n\n            pred_x= s->last_mv[0][0][0];\n\n            pred_y= s->last_mv[0][0][1];\n\n\n\n            P[0][0]= s->mv_table[0][xy  ];\n\n            P[0][1]= s->mv_table[1][xy  ];\n\n            if(s->mb_x == 0){\n\n                P[1][0]= 0;\n\n                P[1][1]= 0;\n\n            }else{\n\n                P[1][0]= s->mv_table[0][xy-1];\n\n                P[1][1]= s->mv_table[1][xy-1];\n\n                if(P[1][0] > (rel_xmax<<shift)) P[1][0]= (rel_xmax<<shift);\n\n            }\n\n    \n\n            if (!(s->mb_y == 0 || s->first_slice_line || s->first_gob_line)) {\n\n                P[2][0] = s->mv_table[0][xy - s->mb_width];\n\n                P[2][1] = s->mv_table[1][xy - s->mb_width];\n\n                P[3][0] = s->mv_table[0][xy - s->mb_width+1];\n\n                P[3][1] = s->mv_table[1][xy - s->mb_width+1];\n\n                if(P[2][1] > (rel_ymax<<shift)) P[2][1]= (rel_ymax<<shift);\n\n                if(P[3][0] > (rel_xmax<<shift)) P[3][0]= (rel_xmax<<shift);\n\n                if(P[3][0] < (rel_xmin<<shift)) P[3][0]= (rel_xmin<<shift);\n\n                if(P[3][1] > (rel_ymax<<shift)) P[3][1]= (rel_ymax<<shift);\n\n        \n\n                P[4][0]= mid_pred(P[1][0], P[2][0], P[3][0]);\n\n                P[4][1]= mid_pred(P[1][1], P[2][1], P[3][1]);\n\n            }\n\n        }\n\n\tdmin = epzs_motion_search(s, &mx, &my, P, pred_x, pred_y, rel_xmin, rel_ymin, rel_xmax, rel_ymax);\n\n        mx+= s->mb_x*16;\n\n        my+= s->mb_y*16;\n\n        break;\n\n    }\n\n\n\n    /* intra / predictive decision */\n\n    xx = mb_x * 16;\n\n    yy = mb_y * 16;\n\n\n\n    pix = s->new_picture[0] + (yy * s->linesize) + xx;\n\n    /* At this point (mx,my) are full-pell and the absolute displacement */\n\n    ppix = s->last_picture[0] + (my * s->linesize) + mx;\n\n\n\n    sum = pix_sum(pix, s->linesize);\n\n    varc = pix_norm1(pix, s->linesize);\n\n    vard = pix_norm(pix, ppix, s->linesize);\n\n\n\n    vard = vard >> 8;\n\n    sum = sum >> 8;\n\n    varc = (varc >> 8) - (sum * sum);\n\n    s->mb_var[s->mb_width * mb_y + mb_x] = varc;\n\n    s->avg_mb_var += varc;\n\n    s->mc_mb_var += vard;\n\n     \n\n#if 0\n\n    printf(\"varc=%4d avg_var=%4d (sum=%4d) vard=%4d mx=%2d my=%2d\\n\",\n\n\t   varc, s->avg_mb_var, sum, vard, mx - xx, my - yy);\n\n#endif\n\n    if (vard <= 64 || vard < varc) {\n\n        if (s->full_search != ME_ZERO) {\n\n            halfpel_motion_search(s, &mx, &my, dmin, xmin, ymin, xmax, ymax, pred_x, pred_y);\n\n        } else {\n\n            mx -= 16 * s->mb_x;\n\n            my -= 16 * s->mb_y;\n\n        }\n\n\t*mx_ptr = mx;\n\n\t*my_ptr = my;\n\n\treturn 0;\n\n    } else {\n\n\t*mx_ptr = 0;\n\n\t*my_ptr = 0;\n\n\treturn 1;\n\n    }\n\n}\n", "idx": 22022}
{"project": "FFmpeg", "commit_id": "78987a88a88b28d93d03ed6c228bcb33f178444f", "target": 1, "func": "static int get_std_framerate(int i)\n\n{\n\n    if (i < 60 * 12)\n\n        return i * 1001;\n\n    else\n\n        return ((const int[]) { 24, 30, 60, 12, 15 })[i - 60 * 12] * 1000 * 12;\n\n}\n", "idx": 22023}
{"project": "FFmpeg", "commit_id": "8e87d146d798ca25d8f3a4520a6deb7946b39d73", "target": 1, "func": "static void subband_scale(int *dst, int *src, int scale, int offset, int len)\n\n{\n\n    int ssign = scale < 0 ? -1 : 1;\n\n    int s = FFABS(scale);\n\n    unsigned int round;\n\n    int i, out, c = exp2tab[s & 3];\n\n\n\n    s = offset - (s >> 2);\n\n\n\n    if (s > 31) {\n\n        for (i=0; i<len; i++) {\n\n            dst[i] = 0;\n\n        }\n\n    } else if (s > 0) {\n\n        round = 1 << (s-1);\n\n        for (i=0; i<len; i++) {\n\n            out = (int)(((int64_t)src[i] * c) >> 32);\n\n            dst[i] = ((int)(out+round) >> s) * ssign;\n\n        }\n\n    }\n\n    else {\n\n        s = s + 32;\n\n        round = 1U << (s-1);\n\n        for (i=0; i<len; i++) {\n\n            out = (int)((int64_t)((int64_t)src[i] * c + round) >> s);\n\n            dst[i] = out * ssign;\n\n        }\n\n    }\n\n}\n", "idx": 22026}
{"project": "FFmpeg", "commit_id": "8000d484b83aafa752d84fbdbfb352ffe0dc64f8", "target": 1, "func": "int ff_h264_decode_mb_cabac(const H264Context *h, H264SliceContext *sl)\n\n{\n\n    int mb_xy;\n\n    int mb_type, partition_count, cbp = 0;\n\n    int dct8x8_allowed= h->pps.transform_8x8_mode;\n\n    int decode_chroma = h->sps.chroma_format_idc == 1 || h->sps.chroma_format_idc == 2;\n\n    const int pixel_shift = h->pixel_shift;\n\n\n\n    mb_xy = sl->mb_xy = sl->mb_x + sl->mb_y*h->mb_stride;\n\n\n\n    ff_tlog(h->avctx, \"pic:%d mb:%d/%d\\n\", h->frame_num, sl->mb_x, sl->mb_y);\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n        int skip;\n\n        /* a skipped mb needs the aff flag from the following mb */\n\n        if (FRAME_MBAFF(h) && (sl->mb_y & 1) == 1 && sl->prev_mb_skipped)\n\n            skip = sl->next_mb_skipped;\n\n        else\n\n            skip = decode_cabac_mb_skip(h, sl, sl->mb_x, sl->mb_y );\n\n        /* read skip flags */\n\n        if( skip ) {\n\n            if (FRAME_MBAFF(h) && (sl->mb_y & 1) == 0) {\n\n                h->cur_pic.mb_type[mb_xy] = MB_TYPE_SKIP;\n\n                sl->next_mb_skipped = decode_cabac_mb_skip(h, sl, sl->mb_x, sl->mb_y+1 );\n\n                if(!sl->next_mb_skipped)\n\n                    sl->mb_mbaff = sl->mb_field_decoding_flag = decode_cabac_field_decoding_flag(h, sl);\n\n            }\n\n\n\n            decode_mb_skip(h, sl);\n\n\n\n            h->cbp_table[mb_xy] = 0;\n\n            h->chroma_pred_mode_table[mb_xy] = 0;\n\n            sl->last_qscale_diff = 0;\n\n\n\n            return 0;\n\n\n\n        }\n\n    }\n\n    if (FRAME_MBAFF(h)) {\n\n        if ((sl->mb_y & 1) == 0)\n\n            sl->mb_mbaff =\n\n            sl->mb_field_decoding_flag = decode_cabac_field_decoding_flag(h, sl);\n\n    }\n\n\n\n    sl->prev_mb_skipped = 0;\n\n\n\n    fill_decode_neighbors(h, sl, -(MB_FIELD(sl)));\n\n\n\n    if (sl->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n        int ctx = 0;\n\n        av_assert2(sl->slice_type_nos == AV_PICTURE_TYPE_B);\n\n\n\n        if (!IS_DIRECT(sl->left_type[LTOP] - 1))\n\n            ctx++;\n\n        if (!IS_DIRECT(sl->top_type - 1))\n\n            ctx++;\n\n\n\n        if( !get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+ctx] ) ){\n\n            mb_type= 0; /* B_Direct_16x16 */\n\n        }else if( !get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+3] ) ) {\n\n            mb_type= 1 + get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] ); /* B_L[01]_16x16 */\n\n        }else{\n\n            int bits;\n\n            bits = get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+4] ) << 3;\n\n            bits+= get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] ) << 2;\n\n            bits+= get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] ) << 1;\n\n            bits+= get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] );\n\n            if( bits < 8 ){\n\n                mb_type= bits + 3; /* B_Bi_16x16 through B_L1_L0_16x8 */\n\n            }else if( bits == 13 ){\n\n                mb_type = decode_cabac_intra_mb_type(sl, 32, 0);\n\n                goto decode_intra_mb;\n\n            }else if( bits == 14 ){\n\n                mb_type= 11; /* B_L1_L0_8x16 */\n\n            }else if( bits == 15 ){\n\n                mb_type= 22; /* B_8x8 */\n\n            }else{\n\n                bits= ( bits<<1 ) + get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] );\n\n                mb_type= bits - 4; /* B_L0_Bi_* through B_Bi_Bi_* */\n\n            }\n\n        }\n\n            partition_count= b_mb_type_info[mb_type].partition_count;\n\n            mb_type=         b_mb_type_info[mb_type].type;\n\n    } else if (sl->slice_type_nos == AV_PICTURE_TYPE_P) {\n\n        if( get_cabac_noinline( &sl->cabac, &sl->cabac_state[14] ) == 0 ) {\n\n            /* P-type */\n\n            if( get_cabac_noinline( &sl->cabac, &sl->cabac_state[15] ) == 0 ) {\n\n                /* P_L0_D16x16, P_8x8 */\n\n                mb_type= 3 * get_cabac_noinline( &sl->cabac, &sl->cabac_state[16] );\n\n            } else {\n\n                /* P_L0_D8x16, P_L0_D16x8 */\n\n                mb_type= 2 - get_cabac_noinline( &sl->cabac, &sl->cabac_state[17] );\n\n            }\n\n            partition_count= p_mb_type_info[mb_type].partition_count;\n\n            mb_type=         p_mb_type_info[mb_type].type;\n\n        } else {\n\n            mb_type = decode_cabac_intra_mb_type(sl, 17, 0);\n\n            goto decode_intra_mb;\n\n        }\n\n    } else {\n\n        mb_type = decode_cabac_intra_mb_type(sl, 3, 1);\n\n        if (sl->slice_type == AV_PICTURE_TYPE_SI && mb_type)\n\n            mb_type--;\n\n        av_assert2(sl->slice_type_nos == AV_PICTURE_TYPE_I);\n\ndecode_intra_mb:\n\n        partition_count = 0;\n\n        cbp= i_mb_type_info[mb_type].cbp;\n\n        sl->intra16x16_pred_mode = i_mb_type_info[mb_type].pred_mode;\n\n        mb_type= i_mb_type_info[mb_type].type;\n\n    }\n\n    if (MB_FIELD(sl))\n\n        mb_type |= MB_TYPE_INTERLACED;\n\n\n\n    h->slice_table[mb_xy] = sl->slice_num;\n\n\n\n    if(IS_INTRA_PCM(mb_type)) {\n\n        const int mb_size = ff_h264_mb_sizes[h->sps.chroma_format_idc] *\n\n                            h->sps.bit_depth_luma >> 3;\n\n        const uint8_t *ptr;\n\n\n\n        // We assume these blocks are very rare so we do not optimize it.\n\n        // FIXME The two following lines get the bitstream position in the cabac\n\n        // decode, I think it should be done by a function in cabac.h (or cabac.c).\n\n        ptr= sl->cabac.bytestream;\n\n        if(sl->cabac.low&0x1) ptr--;\n\n        if(CABAC_BITS==16){\n\n            if(sl->cabac.low&0x1FF) ptr--;\n\n        }\n\n\n\n        // The pixels are stored in the same order as levels in h->mb array.\n\n        if ((int) (sl->cabac.bytestream_end - ptr) < mb_size)\n\n            return -1;\n\n        sl->intra_pcm_ptr = ptr;\n\n        ptr += mb_size;\n\n\n\n        ff_init_cabac_decoder(&sl->cabac, ptr, sl->cabac.bytestream_end - ptr);\n\n\n\n        // All blocks are present\n\n        h->cbp_table[mb_xy] = 0xf7ef;\n\n        h->chroma_pred_mode_table[mb_xy] = 0;\n\n        // In deblocking, the quantizer is 0\n\n        h->cur_pic.qscale_table[mb_xy] = 0;\n\n        // All coeffs are present\n\n        memset(h->non_zero_count[mb_xy], 16, 48);\n\n        h->cur_pic.mb_type[mb_xy] = mb_type;\n\n        sl->last_qscale_diff = 0;\n\n        return 0;\n\n    }\n\n\n\n    fill_decode_caches(h, sl, mb_type);\n\n\n\n    if( IS_INTRA( mb_type ) ) {\n\n        int i, pred_mode;\n\n        if( IS_INTRA4x4( mb_type ) ) {\n\n            if (dct8x8_allowed && get_cabac_noinline(&sl->cabac, &sl->cabac_state[399 + sl->neighbor_transform_size])) {\n\n                mb_type |= MB_TYPE_8x8DCT;\n\n                for( i = 0; i < 16; i+=4 ) {\n\n                    int pred = pred_intra_mode(h, sl, i);\n\n                    int mode = decode_cabac_mb_intra4x4_pred_mode(sl, pred);\n\n                    fill_rectangle(&sl->intra4x4_pred_mode_cache[scan8[i]], 2, 2, 8, mode, 1);\n\n                }\n\n            } else {\n\n                for( i = 0; i < 16; i++ ) {\n\n                    int pred = pred_intra_mode(h, sl, i);\n\n                    sl->intra4x4_pred_mode_cache[scan8[i]] = decode_cabac_mb_intra4x4_pred_mode(sl, pred);\n\n\n\n                    ff_tlog(h->avctx, \"i4x4 pred=%d mode=%d\\n\", pred,\n\n                            sl->intra4x4_pred_mode_cache[scan8[i]]);\n\n                }\n\n            }\n\n            write_back_intra_pred_mode(h, sl);\n\n            if (ff_h264_check_intra4x4_pred_mode(h, sl) < 0 ) return -1;\n\n        } else {\n\n            sl->intra16x16_pred_mode = ff_h264_check_intra_pred_mode(h, sl, sl->intra16x16_pred_mode, 0);\n\n            if (sl->intra16x16_pred_mode < 0) return -1;\n\n        }\n\n        if(decode_chroma){\n\n            h->chroma_pred_mode_table[mb_xy] =\n\n            pred_mode                        = decode_cabac_mb_chroma_pre_mode(h, sl);\n\n\n\n            pred_mode= ff_h264_check_intra_pred_mode(h, sl, pred_mode, 1 );\n\n            if( pred_mode < 0 ) return -1;\n\n            sl->chroma_pred_mode = pred_mode;\n\n        } else {\n\n            sl->chroma_pred_mode = DC_128_PRED8x8;\n\n        }\n\n    } else if( partition_count == 4 ) {\n\n        int i, j, sub_partition_count[4], list, ref[2][4];\n\n\n\n        if (sl->slice_type_nos == AV_PICTURE_TYPE_B ) {\n\n            for( i = 0; i < 4; i++ ) {\n\n                sl->sub_mb_type[i] = decode_cabac_b_mb_sub_type(sl);\n\n                sub_partition_count[i] = b_sub_mb_type_info[sl->sub_mb_type[i]].partition_count;\n\n                sl->sub_mb_type[i]     = b_sub_mb_type_info[sl->sub_mb_type[i]].type;\n\n            }\n\n            if (IS_DIRECT(sl->sub_mb_type[0] | sl->sub_mb_type[1] |\n\n                          sl->sub_mb_type[2] | sl->sub_mb_type[3])) {\n\n                ff_h264_pred_direct_motion(h, sl, &mb_type);\n\n                sl->ref_cache[0][scan8[4]] =\n\n                sl->ref_cache[1][scan8[4]] =\n\n                sl->ref_cache[0][scan8[12]] =\n\n                sl->ref_cache[1][scan8[12]] = PART_NOT_AVAILABLE;\n\n                    for( i = 0; i < 4; i++ )\n\n                        fill_rectangle(&sl->direct_cache[scan8[4*i]], 2, 2, 8, (sl->sub_mb_type[i] >> 1) & 0xFF, 1);\n\n            }\n\n        } else {\n\n            for( i = 0; i < 4; i++ ) {\n\n                sl->sub_mb_type[i] = decode_cabac_p_mb_sub_type(sl);\n\n                sub_partition_count[i] = p_sub_mb_type_info[sl->sub_mb_type[i]].partition_count;\n\n                sl->sub_mb_type[i]     = p_sub_mb_type_info[sl->sub_mb_type[i]].type;\n\n            }\n\n        }\n\n\n\n        for( list = 0; list < sl->list_count; list++ ) {\n\n                for( i = 0; i < 4; i++ ) {\n\n                    if(IS_DIRECT(sl->sub_mb_type[i])) continue;\n\n                    if(IS_DIR(sl->sub_mb_type[i], 0, list)){\n\n                        unsigned rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                        if (rc > 1) {\n\n                            ref[list][i] = decode_cabac_mb_ref(sl, list, 4 * i);\n\n                            if (ref[list][i] >= rc) {\n\n                                av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref[list][i], rc);\n\n                                return -1;\n\n                            }\n\n                        }else\n\n                            ref[list][i] = 0;\n\n                    } else {\n\n                        ref[list][i] = -1;\n\n                    }\n\n                    sl->ref_cache[list][scan8[4 * i] + 1] =\n\n                    sl->ref_cache[list][scan8[4 * i] + 8] = sl->ref_cache[list][scan8[4 * i] + 9] = ref[list][i];\n\n                }\n\n        }\n\n\n\n        if(dct8x8_allowed)\n\n            dct8x8_allowed = get_dct8x8_allowed(h, sl);\n\n\n\n        for (list = 0; list < sl->list_count; list++) {\n\n            for(i=0; i<4; i++){\n\n                sl->ref_cache[list][scan8[4 * i]] = sl->ref_cache[list][scan8[4 * i] + 1];\n\n                if(IS_DIRECT(sl->sub_mb_type[i])){\n\n                    fill_rectangle(sl->mvd_cache[list][scan8[4*i]], 2, 2, 8, 0, 2);\n\n                    continue;\n\n                }\n\n\n\n                if(IS_DIR(sl->sub_mb_type[i], 0, list) && !IS_DIRECT(sl->sub_mb_type[i])){\n\n                    const int sub_mb_type= sl->sub_mb_type[i];\n\n                    const int block_width= (sub_mb_type & (MB_TYPE_16x16|MB_TYPE_16x8)) ? 2 : 1;\n\n                    for(j=0; j<sub_partition_count[i]; j++){\n\n                        int mpx, mpy;\n\n                        int mx, my;\n\n                        const int index= 4*i + block_width*j;\n\n                        int16_t (* mv_cache)[2] = &sl->mv_cache[list][ scan8[index] ];\n\n                        uint8_t (* mvd_cache)[2]= &sl->mvd_cache[list][ scan8[index] ];\n\n                        pred_motion(h, sl, index, block_width, list, sl->ref_cache[list][ scan8[index] ], &mx, &my);\n\n                        DECODE_CABAC_MB_MVD(sl, list, index)\n\n                        ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        if(IS_SUB_8X8(sub_mb_type)){\n\n                            mv_cache[ 1 ][0]=\n\n                            mv_cache[ 8 ][0]= mv_cache[ 9 ][0]= mx;\n\n                            mv_cache[ 1 ][1]=\n\n                            mv_cache[ 8 ][1]= mv_cache[ 9 ][1]= my;\n\n\n\n                            mvd_cache[ 1 ][0]=\n\n                            mvd_cache[ 8 ][0]= mvd_cache[ 9 ][0]= mpx;\n\n                            mvd_cache[ 1 ][1]=\n\n                            mvd_cache[ 8 ][1]= mvd_cache[ 9 ][1]= mpy;\n\n                        }else if(IS_SUB_8X4(sub_mb_type)){\n\n                            mv_cache[ 1 ][0]= mx;\n\n                            mv_cache[ 1 ][1]= my;\n\n\n\n                            mvd_cache[ 1 ][0]=  mpx;\n\n                            mvd_cache[ 1 ][1]= mpy;\n\n                        }else if(IS_SUB_4X8(sub_mb_type)){\n\n                            mv_cache[ 8 ][0]= mx;\n\n                            mv_cache[ 8 ][1]= my;\n\n\n\n                            mvd_cache[ 8 ][0]= mpx;\n\n                            mvd_cache[ 8 ][1]= mpy;\n\n                        }\n\n                        mv_cache[ 0 ][0]= mx;\n\n                        mv_cache[ 0 ][1]= my;\n\n\n\n                        mvd_cache[ 0 ][0]= mpx;\n\n                        mvd_cache[ 0 ][1]= mpy;\n\n                    }\n\n                }else{\n\n                    fill_rectangle(sl->mv_cache [list][ scan8[4*i] ], 2, 2, 8, 0, 4);\n\n                    fill_rectangle(sl->mvd_cache[list][ scan8[4*i] ], 2, 2, 8, 0, 2);\n\n                }\n\n            }\n\n        }\n\n    } else if( IS_DIRECT(mb_type) ) {\n\n        ff_h264_pred_direct_motion(h, sl, &mb_type);\n\n        fill_rectangle(sl->mvd_cache[0][scan8[0]], 4, 4, 8, 0, 2);\n\n        fill_rectangle(sl->mvd_cache[1][scan8[0]], 4, 4, 8, 0, 2);\n\n        dct8x8_allowed &= h->sps.direct_8x8_inference_flag;\n\n    } else {\n\n        int list, i;\n\n        if(IS_16X16(mb_type)){\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                if(IS_DIR(mb_type, 0, list)){\n\n                    int ref;\n\n                    unsigned rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                    if (rc > 1) {\n\n                        ref= decode_cabac_mb_ref(sl, list, 0);\n\n                        if (ref >= rc) {\n\n                            av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref, rc);\n\n                            return -1;\n\n                        }\n\n                    }else\n\n                        ref=0;\n\n                    fill_rectangle(&sl->ref_cache[list][ scan8[0] ], 4, 4, 8, ref, 1);\n\n                }\n\n            }\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                if(IS_DIR(mb_type, 0, list)){\n\n                    int mx,my,mpx,mpy;\n\n                    pred_motion(h, sl, 0, 4, list, sl->ref_cache[list][ scan8[0] ], &mx, &my);\n\n                    DECODE_CABAC_MB_MVD(sl, list, 0)\n\n                    ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                    fill_rectangle(sl->mvd_cache[list][ scan8[0] ], 4, 4, 8, pack8to16(mpx,mpy), 2);\n\n                    fill_rectangle(sl->mv_cache[list][ scan8[0] ], 4, 4, 8, pack16to32(mx,my), 4);\n\n                }\n\n            }\n\n        }\n\n        else if(IS_16X8(mb_type)){\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                    for(i=0; i<2; i++){\n\n                        if(IS_DIR(mb_type, i, list)){\n\n                            int ref;\n\n                            unsigned rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                            if (rc > 1) {\n\n                                ref= decode_cabac_mb_ref(sl, list, 8 * i);\n\n                                if (ref >= rc) {\n\n                                    av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref, rc);\n\n                                    return -1;\n\n                                }\n\n                            }else\n\n                                ref=0;\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 16*i ], 4, 2, 8, ref, 1);\n\n                        }else\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 16*i ], 4, 2, 8, (LIST_NOT_USED&0xFF), 1);\n\n                    }\n\n            }\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                for(i=0; i<2; i++){\n\n                    if(IS_DIR(mb_type, i, list)){\n\n                        int mx,my,mpx,mpy;\n\n                        pred_16x8_motion(h, sl, 8*i, list, sl->ref_cache[list][scan8[0] + 16*i], &mx, &my);\n\n                        DECODE_CABAC_MB_MVD(sl, list, 8*i)\n\n                        ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 16*i ], 4, 2, 8, pack8to16(mpx,mpy), 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 16*i ], 4, 2, 8, pack16to32(mx,my), 4);\n\n                    }else{\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 16*i ], 4, 2, 8, 0, 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 16*i ], 4, 2, 8, 0, 4);\n\n                    }\n\n                }\n\n            }\n\n        }else{\n\n            av_assert2(IS_8X16(mb_type));\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                    for(i=0; i<2; i++){\n\n                        if(IS_DIR(mb_type, i, list)){ //FIXME optimize\n\n                            int ref;\n\n                            unsigned rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                            if (rc > 1) {\n\n                                ref = decode_cabac_mb_ref(sl, list, 4 * i);\n\n                                if (ref >= rc) {\n\n                                    av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref, rc);\n\n                                    return -1;\n\n                                }\n\n                            }else\n\n                                ref=0;\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 2*i ], 2, 4, 8, ref, 1);\n\n                        }else\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 2*i ], 2, 4, 8, (LIST_NOT_USED&0xFF), 1);\n\n                    }\n\n            }\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                for(i=0; i<2; i++){\n\n                    if(IS_DIR(mb_type, i, list)){\n\n                        int mx,my,mpx,mpy;\n\n                        pred_8x16_motion(h, sl, i*4, list, sl->ref_cache[list][ scan8[0] + 2*i ], &mx, &my);\n\n                        DECODE_CABAC_MB_MVD(sl, list, 4*i)\n\n\n\n                        ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 2*i ], 2, 4, 8, pack8to16(mpx,mpy), 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 2*i ], 2, 4, 8, pack16to32(mx,my), 4);\n\n                    }else{\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 2*i ], 2, 4, 8, 0, 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 2*i ], 2, 4, 8, 0, 4);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n   if( IS_INTER( mb_type ) ) {\n\n        h->chroma_pred_mode_table[mb_xy] = 0;\n\n        write_back_motion(h, sl, mb_type);\n\n   }\n\n\n\n    if( !IS_INTRA16x16( mb_type ) ) {\n\n        cbp  = decode_cabac_mb_cbp_luma(sl);\n\n        if(decode_chroma)\n\n            cbp |= decode_cabac_mb_cbp_chroma(sl) << 4;\n\n    } else {\n\n        if (!decode_chroma && cbp>15) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"gray chroma\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    h->cbp_table[mb_xy] = sl->cbp = cbp;\n\n\n\n    if( dct8x8_allowed && (cbp&15) && !IS_INTRA( mb_type ) ) {\n\n        mb_type |= MB_TYPE_8x8DCT * get_cabac_noinline(&sl->cabac, &sl->cabac_state[399 + sl->neighbor_transform_size]);\n\n    }\n\n\n\n    /* It would be better to do this in fill_decode_caches, but we don't know\n\n     * the transform mode of the current macroblock there. */\n\n    if (CHROMA444(h) && IS_8x8DCT(mb_type)){\n\n        int i;\n\n        uint8_t *nnz_cache = sl->non_zero_count_cache;\n\n        for (i = 0; i < 2; i++){\n\n            if (sl->left_type[LEFT(i)] && !IS_8x8DCT(sl->left_type[LEFT(i)])) {\n\n                nnz_cache[3+8* 1 + 2*8*i]=\n\n                nnz_cache[3+8* 2 + 2*8*i]=\n\n                nnz_cache[3+8* 6 + 2*8*i]=\n\n                nnz_cache[3+8* 7 + 2*8*i]=\n\n                nnz_cache[3+8*11 + 2*8*i]=\n\n                nnz_cache[3+8*12 + 2*8*i]= IS_INTRA(mb_type) ? 64 : 0;\n\n            }\n\n        }\n\n        if (sl->top_type && !IS_8x8DCT(sl->top_type)){\n\n            uint32_t top_empty = CABAC(h) && !IS_INTRA(mb_type) ? 0 : 0x40404040;\n\n            AV_WN32A(&nnz_cache[4+8* 0], top_empty);\n\n            AV_WN32A(&nnz_cache[4+8* 5], top_empty);\n\n            AV_WN32A(&nnz_cache[4+8*10], top_empty);\n\n        }\n\n    }\n\n    h->cur_pic.mb_type[mb_xy] = mb_type;\n\n\n\n    if( cbp || IS_INTRA16x16( mb_type ) ) {\n\n        const uint8_t *scan, *scan8x8;\n\n        const uint32_t *qmul;\n\n\n\n        if(IS_INTERLACED(mb_type)){\n\n            scan8x8 = sl->qscale ? h->field_scan8x8 : h->field_scan8x8_q0;\n\n            scan    = sl->qscale ? h->field_scan : h->field_scan_q0;\n\n        }else{\n\n            scan8x8 = sl->qscale ? h->zigzag_scan8x8 : h->zigzag_scan8x8_q0;\n\n            scan    = sl->qscale ? h->zigzag_scan : h->zigzag_scan_q0;\n\n        }\n\n\n\n        // decode_cabac_mb_dqp\n\n        if(get_cabac_noinline( &sl->cabac, &sl->cabac_state[60 + (sl->last_qscale_diff != 0)])){\n\n            int val = 1;\n\n            int ctx= 2;\n\n            const int max_qp = 51 + 6*(h->sps.bit_depth_luma-8);\n\n\n\n            while( get_cabac_noinline( &sl->cabac, &sl->cabac_state[60 + ctx] ) ) {\n\n                ctx= 3;\n\n                val++;\n\n                if(val > 2*max_qp){ //prevent infinite loop\n\n                    av_log(h->avctx, AV_LOG_ERROR, \"cabac decode of qscale diff failed at %d %d\\n\", sl->mb_x, sl->mb_y);\n\n                    return -1;\n\n                }\n\n            }\n\n\n\n            if( val&0x01 )\n\n                val=   (val + 1)>>1 ;\n\n            else\n\n                val= -((val + 1)>>1);\n\n            sl->last_qscale_diff = val;\n\n            sl->qscale += val;\n\n            if (((unsigned)sl->qscale) > max_qp){\n\n                if (sl->qscale < 0) sl->qscale += max_qp + 1;\n\n                else                sl->qscale -= max_qp + 1;\n\n            }\n\n            sl->chroma_qp[0] = get_chroma_qp(h, 0, sl->qscale);\n\n            sl->chroma_qp[1] = get_chroma_qp(h, 1, sl->qscale);\n\n        }else\n\n            sl->last_qscale_diff=0;\n\n\n\n        decode_cabac_luma_residual(h, sl, scan, scan8x8, pixel_shift, mb_type, cbp, 0);\n\n        if (CHROMA444(h)) {\n\n            decode_cabac_luma_residual(h, sl, scan, scan8x8, pixel_shift, mb_type, cbp, 1);\n\n            decode_cabac_luma_residual(h, sl, scan, scan8x8, pixel_shift, mb_type, cbp, 2);\n\n        } else if (CHROMA422(h)) {\n\n            if( cbp&0x30 ){\n\n                int c;\n\n                for (c = 0; c < 2; c++)\n\n                    decode_cabac_residual_dc_422(h, sl, sl->mb + ((256 + 16*16*c) << pixel_shift), 3,\n\n                                                 CHROMA_DC_BLOCK_INDEX + c,\n\n                                                 chroma422_dc_scan, 8);\n\n            }\n\n\n\n            if( cbp&0x20 ) {\n\n                int c, i, i8x8;\n\n                for( c = 0; c < 2; c++ ) {\n\n                    int16_t *mb = sl->mb + (16*(16 + 16*c) << pixel_shift);\n\n                    qmul = h->dequant4_coeff[c+1+(IS_INTRA( mb_type ) ? 0:3)][sl->chroma_qp[c]];\n\n                    for (i8x8 = 0; i8x8 < 2; i8x8++) {\n\n                        for (i = 0; i < 4; i++) {\n\n                            const int index = 16 + 16 * c + 8*i8x8 + i;\n\n                            decode_cabac_residual_nondc(h, sl, mb, 4, index, scan + 1, qmul, 15);\n\n                            mb += 16<<pixel_shift;\n\n                        }\n\n                    }\n\n                }\n\n            } else {\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n            }\n\n        } else /* yuv420 */ {\n\n            if( cbp&0x30 ){\n\n                int c;\n\n                for (c = 0; c < 2; c++)\n\n                    decode_cabac_residual_dc(h, sl, sl->mb + ((256 + 16*16*c) << pixel_shift), 3, CHROMA_DC_BLOCK_INDEX+c, chroma_dc_scan, 4);\n\n            }\n\n\n\n            if( cbp&0x20 ) {\n\n                int c, i;\n\n                for( c = 0; c < 2; c++ ) {\n\n                    qmul = h->dequant4_coeff[c+1+(IS_INTRA( mb_type ) ? 0:3)][sl->chroma_qp[c]];\n\n                    for( i = 0; i < 4; i++ ) {\n\n                        const int index = 16 + 16 * c + i;\n\n                        decode_cabac_residual_nondc(h, sl, sl->mb + (16*index << pixel_shift), 4, index, scan + 1, qmul, 15);\n\n                    }\n\n                }\n\n            } else {\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n            }\n\n        }\n\n    } else {\n\n        fill_rectangle(&sl->non_zero_count_cache[scan8[ 0]], 4, 4, 8, 0, 1);\n\n        fill_rectangle(&sl->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n        fill_rectangle(&sl->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n        sl->last_qscale_diff = 0;\n\n    }\n\n\n\n    h->cur_pic.qscale_table[mb_xy] = sl->qscale;\n\n    write_back_non_zero_count(h, sl);\n\n\n\n    return 0;\n\n}\n", "idx": 22028}
{"project": "FFmpeg", "commit_id": "6ea7dd25c773145b50eed55c2059647bb086aaca", "target": 1, "func": "static int swf_write_header(AVFormatContext *s)\n\n{\n\n    SWFContext *swf = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    PutBitContext p;\n\n    uint8_t buf1[256];\n\n    int i, width, height, rate, rate_base;\n\n    int version;\n\n\n\n    swf->sound_samples = 0;\n\n    swf->swf_frame_number = 0;\n\n    swf->video_frame_number = 0;\n\n\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        AVCodecContext *enc = s->streams[i]->codec;\n\n        if (enc->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            if (swf->audio_enc) {\n\n                av_log(s, AV_LOG_ERROR, \"SWF muxer only supports 1 audio stream\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n\n            if (enc->codec_id == AV_CODEC_ID_MP3) {\n\n                if (!enc->frame_size) {\n\n                    av_log(s, AV_LOG_ERROR, \"audio frame size not set\\n\");\n\n                    return -1;\n\n\n                swf->audio_enc = enc;\n\n                swf->audio_fifo= av_fifo_alloc(AUDIO_FIFO_SIZE);\n\n                if (!swf->audio_fifo)\n\n                    return AVERROR(ENOMEM);\n\n            } else {\n\n                av_log(s, AV_LOG_ERROR, \"SWF muxer only supports MP3\\n\");\n\n                return -1;\n\n\n        } else {\n\n            if (swf->video_enc) {\n\n                av_log(s, AV_LOG_ERROR, \"SWF muxer only supports 1 video stream\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n\n            if (enc->codec_id == AV_CODEC_ID_VP6F ||\n\n                enc->codec_id == AV_CODEC_ID_FLV1 ||\n\n                enc->codec_id == AV_CODEC_ID_MJPEG) {\n\n                swf->video_st  = s->streams[i];\n\n                swf->video_enc = enc;\n\n            } else {\n\n                av_log(s, AV_LOG_ERROR, \"SWF muxer only supports VP6, FLV1 and MJPEG\\n\");\n\n                return -1;\n\n\n\n\n\n\n    if (!swf->video_enc) {\n\n        /* currently, cannot work correctly if audio only */\n\n        width = 320;\n\n        height = 200;\n\n        rate = 10;\n\n        rate_base= 1;\n\n    } else {\n\n        width = swf->video_enc->width;\n\n        height = swf->video_enc->height;\n\n        // TODO: should be avg_frame_rate\n\n        rate = swf->video_st->time_base.den;\n\n        rate_base = swf->video_st->time_base.num;\n\n\n\n\n    if (!swf->audio_enc)\n\n        swf->samples_per_frame = (44100LL * rate_base) / rate;\n\n    else\n\n        swf->samples_per_frame = (swf->audio_enc->sample_rate * rate_base) / rate;\n\n\n\n    avio_write(pb, \"FWS\", 3);\n\n\n\n    if (!strcmp(\"avm2\", s->oformat->name))\n\n        version = 9;\n\n    else if (swf->video_enc && swf->video_enc->codec_id == AV_CODEC_ID_VP6F)\n\n        version = 8; /* version 8 and above support VP6 codec */\n\n    else if (swf->video_enc && swf->video_enc->codec_id == AV_CODEC_ID_FLV1)\n\n        version = 6; /* version 6 and above support FLV1 codec */\n\n    else\n\n        version = 4; /* version 4 for mpeg audio support */\n\n    avio_w8(pb, version);\n\n\n\n    avio_wl32(pb, DUMMY_FILE_SIZE); /* dummy size\n\n                                      (will be patched if not streamed) */\n\n\n\n    put_swf_rect(pb, 0, width * 20, 0, height * 20);\n\n\n\n\n\n    avio_wl16(pb, (rate * 256) / rate_base); /* frame rate */\n\n    swf->duration_pos = avio_tell(pb);\n\n    avio_wl16(pb, (uint16_t)(DUMMY_DURATION * (int64_t)rate / rate_base)); /* frame count */\n\n\n\n    /* avm2/swf v9 (also v8?) files require a file attribute tag */\n\n    if (version == 9) {\n\n        put_swf_tag(s, TAG_FILEATTRIBUTES);\n\n        avio_wl32(pb, 1<<3); /* set ActionScript v3/AVM2 flag */\n\n        put_swf_end_tag(s);\n\n\n\n\n    /* define a shape with the jpeg inside */\n\n    if (swf->video_enc && swf->video_enc->codec_id == AV_CODEC_ID_MJPEG) {\n\n        put_swf_tag(s, TAG_DEFINESHAPE);\n\n\n\n        avio_wl16(pb, SHAPE_ID); /* ID of shape */\n\n        /* bounding rectangle */\n\n        put_swf_rect(pb, 0, width, 0, height);\n\n        /* style info */\n\n        avio_w8(pb, 1); /* one fill style */\n\n        avio_w8(pb, 0x41); /* clipped bitmap fill */\n\n        avio_wl16(pb, BITMAP_ID); /* bitmap ID */\n\n        /* position of the bitmap */\n\n        put_swf_matrix(pb, 1 << FRAC_BITS, 0,\n\n                       0,  1 << FRAC_BITS, 0, 0);\n\n        avio_w8(pb, 0); /* no line style */\n\n\n\n        /* shape drawing */\n\n        init_put_bits(&p, buf1, sizeof(buf1));\n\n        put_bits(&p, 4, 1); /* one fill bit */\n\n        put_bits(&p, 4, 0); /* zero line bit */\n\n\n\n        put_bits(&p, 1, 0); /* not an edge */\n\n        put_bits(&p, 5, FLAG_MOVETO | FLAG_SETFILL0);\n\n        put_bits(&p, 5, 1); /* nbits */\n\n        put_bits(&p, 1, 0); /* X */\n\n        put_bits(&p, 1, 0); /* Y */\n\n        put_bits(&p, 1, 1); /* set fill style 1 */\n\n\n\n        /* draw the rectangle ! */\n\n        put_swf_line_edge(&p, width, 0);\n\n        put_swf_line_edge(&p, 0, height);\n\n        put_swf_line_edge(&p, -width, 0);\n\n        put_swf_line_edge(&p, 0, -height);\n\n\n\n        /* end of shape */\n\n        put_bits(&p, 1, 0); /* not an edge */\n\n        put_bits(&p, 5, 0);\n\n\n\n        flush_put_bits(&p);\n\n        avio_write(pb, buf1, put_bits_ptr(&p) - p.buf);\n\n\n\n        put_swf_end_tag(s);\n\n\n\n\n    if (swf->audio_enc && swf->audio_enc->codec_id == AV_CODEC_ID_MP3) {\n\n        int v = 0;\n\n\n\n        /* start sound */\n\n        put_swf_tag(s, TAG_STREAMHEAD2);\n\n        switch(swf->audio_enc->sample_rate) {\n\n        case 11025: v |= 1 << 2; break;\n\n        case 22050: v |= 2 << 2; break;\n\n        case 44100: v |= 3 << 2; break;\n\n        default:\n\n            /* not supported */\n\n            av_log(s, AV_LOG_ERROR, \"swf does not support that sample rate, choose from (44100, 22050, 11025).\\n\");\n\n            return -1;\n\n\n        v |= 0x02; /* 16 bit playback */\n\n        if (swf->audio_enc->channels == 2)\n\n            v |= 0x01; /* stereo playback */\n\n        avio_w8(s->pb, v);\n\n        v |= 0x20; /* mp3 compressed */\n\n        avio_w8(s->pb, v);\n\n        avio_wl16(s->pb, swf->samples_per_frame);  /* avg samples per frame */\n\n        avio_wl16(s->pb, 0);\n\n\n\n        put_swf_end_tag(s);\n\n\n\n\n    avio_flush(s->pb);\n\n    return 0;\n", "idx": 22031}
{"project": "FFmpeg", "commit_id": "7e4881a2d074a7dfba7ee1990b3e17c9276f985d", "target": 0, "func": "static int atrac3_decode_frame(AVCodecContext *avctx,\n\n            void *data, int *data_size,\n\n            AVPacket *avpkt) {\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    ATRAC3Context *q = avctx->priv_data;\n\n    int result = 0;\n\n    const uint8_t* databuf;\n\n    float *samples = data;\n\n\n\n    if (buf_size < avctx->block_align) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Frame too small (%d bytes). Truncated file?\\n\", buf_size);\n\n        *data_size = 0;\n\n        return buf_size;\n\n    }\n\n\n\n    /* Check if we need to descramble and what buffer to pass on. */\n\n    if (q->scrambled_stream) {\n\n        decode_bytes(buf, q->decoded_bytes_buffer, avctx->block_align);\n\n        databuf = q->decoded_bytes_buffer;\n\n    } else {\n\n        databuf = buf;\n\n    }\n\n\n\n    result = decodeFrame(q, databuf, q->channels == 2 ? q->outSamples : &samples);\n\n\n\n    if (result != 0) {\n\n        av_log(NULL,AV_LOG_ERROR,\"Frame decoding error!\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* interleave */\n\n    if (q->channels == 2) {\n\n        q->fmt_conv.float_interleave(samples, (const float **)q->outSamples,\n\n                                     1024, 2);\n\n    }\n\n    *data_size = 1024 * q->channels * av_get_bytes_per_sample(avctx->sample_fmt);\n\n\n\n    return avctx->block_align;\n\n}\n", "idx": 22032}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int flic_probe(AVProbeData *p)\n\n{\n\n    int magic_number;\n\n\n\n    if (p->buf_size < 6)\n\n        return 0;\n\n\n\n    magic_number = AV_RL16(&p->buf[4]);\n\n    if ((magic_number != FLIC_FILE_MAGIC_1) &&\n\n        (magic_number != FLIC_FILE_MAGIC_2) &&\n\n        (magic_number != FLIC_FILE_MAGIC_3))\n\n        return 0;\n\n\n\n    return AVPROBE_SCORE_MAX;\n\n}\n", "idx": 22033}
{"project": "FFmpeg", "commit_id": "1c495b0bf690995c45f79f4f19500921e14ec78a", "target": 1, "func": "static void dwt_encode97_int(DWTContext *s, int *t)\n\n{\n\n    int lev,\n\n        w = s->linelen[s->ndeclevels-1][0];\n\n    int *line = s->i_linebuf;\n\n    line += 5;\n\n\n\n    for (lev = s->ndeclevels-1; lev >= 0; lev--){\n\n        int lh = s->linelen[lev][0],\n\n            lv = s->linelen[lev][1],\n\n            mh = s->mod[lev][0],\n\n            mv = s->mod[lev][1],\n\n            lp;\n\n        int *l;\n\n\n\n        // VER_SD\n\n        l = line + mv;\n\n        for (lp = 0; lp < lh; lp++) {\n\n            int i, j = 0;\n\n\n\n            for (i = 0; i < lv; i++)\n\n                l[i] = t[w*i + lp];\n\n\n\n            sd_1d97_int(line, mv, mv + lv);\n\n\n\n            // copy back and deinterleave\n\n            for (i =   mv; i < lv; i+=2, j++)\n\n                t[w*j + lp] = ((l[i] * I_LFTG_X) + (1 << 16)) >> 17;\n\n            for (i = 1-mv; i < lv; i+=2, j++)\n\n                t[w*j + lp] = ((l[i] * I_LFTG_K) + (1 << 16)) >> 17;\n\n        }\n\n\n\n        // HOR_SD\n\n        l = line + mh;\n\n        for (lp = 0; lp < lv; lp++){\n\n            int i, j = 0;\n\n\n\n            for (i = 0; i < lh; i++)\n\n                l[i] = t[w*lp + i];\n\n\n\n            sd_1d97_int(line, mh, mh + lh);\n\n\n\n            // copy back and deinterleave\n\n            for (i =   mh; i < lh; i+=2, j++)\n\n                t[w*lp + j] = ((l[i] * I_LFTG_X) + (1 << 16)) >> 17;\n\n            for (i = 1-mh; i < lh; i+=2, j++)\n\n                t[w*lp + j] = ((l[i] * I_LFTG_K) + (1 << 16)) >> 17;\n\n        }\n\n\n\n    }\n\n}\n", "idx": 22034}
{"project": "FFmpeg", "commit_id": "ddfa3751c092feaf1e080f66587024689dfe603c", "target": 1, "func": "static int jp2_find_codestream(J2kDecoderContext *s)\n\n{\n\n    uint32_t atom_size;\n\n    int found_codestream = 0, search_range = 10;\n\n\n\n    // skip jpeg2k signature atom\n\n    s->buf += 12;\n\n\n\n    while(!found_codestream && search_range && s->buf_end - s->buf >= 8) {\n\n        atom_size = AV_RB32(s->buf);\n\n        if(AV_RB32(s->buf + 4) == JP2_CODESTREAM) {\n\n            found_codestream = 1;\n\n            s->buf += 8;\n\n        } else {\n\n            if (s->buf_end - s->buf < atom_size)\n\n                return 0;\n\n            s->buf += atom_size;\n\n            search_range--;\n\n        }\n\n    }\n\n\n\n    if(found_codestream)\n\n        return 1;\n\n    return 0;\n\n}\n", "idx": 22035}
{"project": "FFmpeg", "commit_id": "0424e052f83adc422d8a746e3cdc5ab6bc28679e", "target": 1, "func": "static void decode_postinit(H264Context *h){\n\n    MpegEncContext * const s = &h->s;\n\n    Picture *out = s->current_picture_ptr;\n\n    Picture *cur = s->current_picture_ptr;\n\n    int i, pics, out_of_order, out_idx;\n\n\n\n    s->current_picture_ptr->qscale_type= FF_QSCALE_TYPE_H264;\n\n    s->current_picture_ptr->pict_type= s->pict_type;\n\n\n\n    if (h->next_output_pic) return;\n\n\n\n    if (cur->field_poc[0]==INT_MAX || cur->field_poc[1]==INT_MAX) {\n\n        //FIXME this allows the next thread to start once we encounter the first field of a PAFF packet\n\n        //This works if the next packet contains the second field. It does not work if both fields are\n\n        //in the same packet.\n\n        //ff_thread_finish_setup(s->avctx);\n\n        return;\n\n    }\n\n\n\n    cur->interlaced_frame = 0;\n\n    cur->repeat_pict = 0;\n\n\n\n    /* Signal interlacing information externally. */\n\n    /* Prioritize picture timing SEI information over used decoding process if it exists. */\n\n\n\n    if(h->sps.pic_struct_present_flag){\n\n        switch (h->sei_pic_struct)\n\n        {\n\n        case SEI_PIC_STRUCT_FRAME:\n\n            break;\n\n        case SEI_PIC_STRUCT_TOP_FIELD:\n\n        case SEI_PIC_STRUCT_BOTTOM_FIELD:\n\n            cur->interlaced_frame = 1;\n\n            break;\n\n        case SEI_PIC_STRUCT_TOP_BOTTOM:\n\n        case SEI_PIC_STRUCT_BOTTOM_TOP:\n\n            if (FIELD_OR_MBAFF_PICTURE)\n\n                cur->interlaced_frame = 1;\n\n            else\n\n                // try to flag soft telecine progressive\n\n                cur->interlaced_frame = h->prev_interlaced_frame;\n\n            break;\n\n        case SEI_PIC_STRUCT_TOP_BOTTOM_TOP:\n\n        case SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM:\n\n            // Signal the possibility of telecined film externally (pic_struct 5,6)\n\n            // From these hints, let the applications decide if they apply deinterlacing.\n\n            cur->repeat_pict = 1;\n\n            break;\n\n        case SEI_PIC_STRUCT_FRAME_DOUBLING:\n\n            // Force progressive here, as doubling interlaced frame is a bad idea.\n\n            cur->repeat_pict = 2;\n\n            break;\n\n        case SEI_PIC_STRUCT_FRAME_TRIPLING:\n\n            cur->repeat_pict = 4;\n\n            break;\n\n        }\n\n\n\n        if ((h->sei_ct_type & 3) && h->sei_pic_struct <= SEI_PIC_STRUCT_BOTTOM_TOP)\n\n            cur->interlaced_frame = (h->sei_ct_type & (1<<1)) != 0;\n\n    }else{\n\n        /* Derive interlacing flag from used decoding process. */\n\n        cur->interlaced_frame = FIELD_OR_MBAFF_PICTURE;\n\n    }\n\n    h->prev_interlaced_frame = cur->interlaced_frame;\n\n\n\n    if (cur->field_poc[0] != cur->field_poc[1]){\n\n        /* Derive top_field_first from field pocs. */\n\n        cur->top_field_first = cur->field_poc[0] < cur->field_poc[1];\n\n    }else{\n\n        if(cur->interlaced_frame || h->sps.pic_struct_present_flag){\n\n            /* Use picture timing SEI information. Even if it is a information of a past frame, better than nothing. */\n\n            if(h->sei_pic_struct == SEI_PIC_STRUCT_TOP_BOTTOM\n\n              || h->sei_pic_struct == SEI_PIC_STRUCT_TOP_BOTTOM_TOP)\n\n                cur->top_field_first = 1;\n\n            else\n\n                cur->top_field_first = 0;\n\n        }else{\n\n            /* Most likely progressive */\n\n            cur->top_field_first = 0;\n\n        }\n\n    }\n\n\n\n    //FIXME do something with unavailable reference frames\n\n\n\n    /* Sort B-frames into display order */\n\n\n\n    if(h->sps.bitstream_restriction_flag\n\n       && s->avctx->has_b_frames < h->sps.num_reorder_frames){\n\n        s->avctx->has_b_frames = h->sps.num_reorder_frames;\n\n        s->low_delay = 0;\n\n    }\n\n\n\n    if(   s->avctx->strict_std_compliance >= FF_COMPLIANCE_STRICT\n\n       && !h->sps.bitstream_restriction_flag){\n\n        s->avctx->has_b_frames= MAX_DELAYED_PIC_COUNT;\n\n        s->low_delay= 0;\n\n    }\n\n\n\n    pics = 0;\n\n    while(h->delayed_pic[pics]) pics++;\n\n\n\n    assert(pics <= MAX_DELAYED_PIC_COUNT);\n\n\n\n    h->delayed_pic[pics++] = cur;\n\n    if(cur->reference == 0)\n\n        cur->reference = DELAYED_PIC_REF;\n\n\n\n    out = h->delayed_pic[0];\n\n    out_idx = 0;\n\n    for(i=1; h->delayed_pic[i] && !h->delayed_pic[i]->key_frame && !h->delayed_pic[i]->mmco_reset; i++)\n\n        if(h->delayed_pic[i]->poc < out->poc){\n\n            out = h->delayed_pic[i];\n\n            out_idx = i;\n\n        }\n\n    if(s->avctx->has_b_frames == 0 && (h->delayed_pic[0]->key_frame || h->delayed_pic[0]->mmco_reset))\n\n        h->next_outputed_poc= INT_MIN;\n\n    out_of_order = out->poc < h->next_outputed_poc;\n\n\n\n    if(h->sps.bitstream_restriction_flag && s->avctx->has_b_frames >= h->sps.num_reorder_frames)\n\n        { }\n\n    else if((out_of_order && pics-1 == s->avctx->has_b_frames && s->avctx->has_b_frames < MAX_DELAYED_PIC_COUNT)\n\n       || (s->low_delay &&\n\n        ((h->next_outputed_poc != INT_MIN && out->poc > h->next_outputed_poc + 2)\n\n         || cur->pict_type == AV_PICTURE_TYPE_B)))\n\n    {\n\n        s->low_delay = 0;\n\n        s->avctx->has_b_frames++;\n\n    }\n\n\n\n    if(out_of_order || pics > s->avctx->has_b_frames){\n\n        out->reference &= ~DELAYED_PIC_REF;\n\n        out->owner2 = s; // for frame threading, the owner must be the second field's thread\n\n                         // or else the first thread can release the picture and reuse it unsafely\n\n        for(i=out_idx; h->delayed_pic[i]; i++)\n\n            h->delayed_pic[i] = h->delayed_pic[i+1];\n\n    }\n\n    if(!out_of_order && pics > s->avctx->has_b_frames){\n\n        h->next_output_pic = out;\n\n        if(out_idx==0 && h->delayed_pic[0] && (h->delayed_pic[0]->key_frame || h->delayed_pic[0]->mmco_reset)) {\n\n            h->next_outputed_poc = INT_MIN;\n\n        } else\n\n            h->next_outputed_poc = out->poc;\n\n    }else{\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"no picture\\n\");\n\n    }\n\n\n\n    ff_thread_finish_setup(s->avctx);\n\n}\n", "idx": 22037}
{"project": "FFmpeg", "commit_id": "8a701ef7ddbb2d80ef77b14287d286fc9760f131", "target": 1, "func": "static int decode_pic_timing(HEVCContext *s)\n\n{\n\n    GetBitContext *gb = &s->HEVClc->gb;\n\n    HEVCSPS *sps = (HEVCSPS*)s->sps_list[s->active_seq_parameter_set_id]->data;\n\n\n\n    if (!sps)\n\n        return(AVERROR(ENOMEM));\n\n\n\n    if (sps->vui.frame_field_info_present_flag) {\n\n        int pic_struct = get_bits(gb, 4);\n\n        s->picture_struct = AV_PICTURE_STRUCTURE_UNKNOWN;\n\n        if (pic_struct == 2) {\n\n            av_log(s->avctx, AV_LOG_DEBUG, \"BOTTOM Field\\n\");\n\n            s->picture_struct = AV_PICTURE_STRUCTURE_BOTTOM_FIELD;\n\n        } else if (pic_struct == 1) {\n\n            av_log(s->avctx, AV_LOG_DEBUG, \"TOP Field\\n\");\n\n            s->picture_struct = AV_PICTURE_STRUCTURE_TOP_FIELD;\n\n        }\n\n        get_bits(gb, 2);                   // source_scan_type\n\n        get_bits(gb, 1);                   // duplicate_flag\n\n    }\n\n    return 1;\n\n}\n", "idx": 22039}
{"project": "FFmpeg", "commit_id": "3069e70f62fa506c6b86bd7dac4fcb139c886f37", "target": 1, "func": "static void *circular_buffer_task( void *_URLContext)\n\n{\n\n    URLContext *h = _URLContext;\n\n    UDPContext *s = h->priv_data;\n\n    fd_set rfds;\n\n    struct timeval tv;\n\n\n\n    while(!s->exit_thread) {\n\n        int left;\n\n        int ret;\n\n        int len;\n\n\n\n        if (ff_check_interrupt(&h->interrupt_callback)) {\n\n            s->circular_buffer_error = AVERROR(EINTR);\n\n            goto end;\n\n        }\n\n\n\n        FD_ZERO(&rfds);\n\n        FD_SET(s->udp_fd, &rfds);\n\n        tv.tv_sec = 1;\n\n        tv.tv_usec = 0;\n\n        ret = select(s->udp_fd + 1, &rfds, NULL, NULL, &tv);\n\n        if (ret < 0) {\n\n            if (ff_neterrno() == AVERROR(EINTR))\n\n                continue;\n\n            s->circular_buffer_error = AVERROR(EIO);\n\n            goto end;\n\n        }\n\n\n\n        if (!(ret > 0 && FD_ISSET(s->udp_fd, &rfds)))\n\n            continue;\n\n\n\n        /* How much do we have left to the end of the buffer */\n\n        /* Whats the minimum we can read so that we dont comletely fill the buffer */\n\n        left = av_fifo_space(s->fifo);\n\n\n\n        /* No Space left, error, what do we do now */\n\n        if(left < UDP_MAX_PKT_SIZE + 4) {\n\n            av_log(h, AV_LOG_ERROR, \"circular_buffer: OVERRUN\\n\");\n\n            s->circular_buffer_error = AVERROR(EIO);\n\n            goto end;\n\n        }\n\n        len = recv(s->udp_fd, s->tmp+4, sizeof(s->tmp)-4, 0);\n\n        if (len < 0) {\n\n            if (ff_neterrno() != AVERROR(EAGAIN) && ff_neterrno() != AVERROR(EINTR)) {\n\n                s->circular_buffer_error = AVERROR(EIO);\n\n                goto end;\n\n            }\n\n            continue;\n\n        }\n\n        AV_WL32(s->tmp, len);\n\n        pthread_mutex_lock(&s->mutex);\n\n        av_fifo_generic_write(s->fifo, s->tmp, len+4, NULL);\n\n        pthread_cond_signal(&s->cond);\n\n        pthread_mutex_unlock(&s->mutex);\n\n    }\n\n\n\nend:\n\n    pthread_mutex_lock(&s->mutex);\n\n    pthread_cond_signal(&s->cond);\n\n    pthread_mutex_unlock(&s->mutex);\n\n    return NULL;\n\n}\n", "idx": 22040}
{"project": "FFmpeg", "commit_id": "bcaa9099b3648b47060e1724a97dc98b63c83702", "target": 1, "func": "static int decode_rle(uint8_t *bitmap, int linesize, int w, int h,\n                      const uint8_t *buf, int start, int buf_size, int is_8bit)\n{\n    GetBitContext gb;\n    int bit_len;\n    int x, y, len, color;\n    uint8_t *d;\n    if (start >= buf_size)\n    bit_len = (buf_size - start) * 8;\n    init_get_bits(&gb, buf + start, bit_len);\n    x = 0;\n    y = 0;\n    d = bitmap;\n    for(;;) {\n        if (get_bits_count(&gb) > bit_len)\n        if (is_8bit)\n            len = decode_run_8bit(&gb, &color);\n        else\n            len = decode_run_2bit(&gb, &color);\n        len = FFMIN(len, w - x);\n        memset(d + x, color, len);\n        x += len;\n        if (x >= w) {\n            y++;\n            if (y >= h)\n                break;\n            d += linesize;\n            x = 0;\n            /* byte align */\n            align_get_bits(&gb);\n        }\n    }\n    return 0;\n}", "idx": 22041}
{"project": "FFmpeg", "commit_id": "23edd41a0d6994cb5d9983d8f035e8eef78960ad", "target": 1, "func": "static void decode(AVCodecContext *dec_ctx, AVFrame *frame, AVPacket *pkt,\n\n                   const char *filename)\n\n{\n\n    char buf[1024];\n\n    int ret;\n\n\n\n    ret = avcodec_send_packet(dec_ctx, pkt);\n\n    if (ret < 0) {\n\n        fprintf(stderr, \"Error sending a packet for decoding\\n\");\n\n        exit(1);\n\n    }\n\n\n\n    while (ret >= 0) {\n\n        ret = avcodec_receive_frame(dec_ctx, frame);\n\n        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)\n\n            return;\n\n        else if (ret < 0) {\n\n            fprintf(stderr, \"Error during decoding\\n\");\n\n            exit(1);\n\n        }\n\n\n\n        printf(\"saving frame %3d\\n\", dec_ctx->frame_number);\n\n        fflush(stdout);\n\n\n\n        /* the picture is allocated by the decoder. no need to\n\n           free it */\n\n        snprintf(buf, sizeof(buf), filename, dec_ctx->frame_number);\n\n        pgm_save(frame->data[0], frame->linesize[0],\n\n                 frame->width, frame->height, buf);\n\n    }\n\n}\n", "idx": 22043}
{"project": "FFmpeg", "commit_id": "452ac2aaecf7210a2912d9156869c6314142a794", "target": 0, "func": "static void ripemd128_transform(uint32_t *state, const uint8_t buffer[64], int ext)\n\n{\n\n    uint32_t a, b, c, d, e, f, g, h;\n\n    uint32_t block[16];\n\n    int n;\n\n\n\n    if (ext) {\n\n        a = state[0]; b = state[1]; c = state[2]; d = state[3];\n\n        e = state[4]; f = state[5]; g = state[6]; h = state[7];\n\n    } else {\n\n        a = e = state[0];\n\n        b = f = state[1];\n\n        c = g = state[2];\n\n        d = h = state[3];\n\n    }\n\n\n\n    for (n = 0; n < 16; n++)\n\n        block[n] = AV_RL32(buffer + 4 * n);\n\n\n\n    for (n = 0; n < 16;) {\n\n        ROUND128_0_TO_15(a,b,c,d,e,f,g,h);\n\n        ROUND128_0_TO_15(d,a,b,c,h,e,f,g);\n\n        ROUND128_0_TO_15(c,d,a,b,g,h,e,f);\n\n        ROUND128_0_TO_15(b,c,d,a,f,g,h,e);\n\n    }\n\n    SWAP(a,e)\n\n\n\n    for (; n < 32;) {\n\n        ROUND128_16_TO_31(a,b,c,d,e,f,g,h);\n\n        ROUND128_16_TO_31(d,a,b,c,h,e,f,g);\n\n        ROUND128_16_TO_31(c,d,a,b,g,h,e,f);\n\n        ROUND128_16_TO_31(b,c,d,a,f,g,h,e);\n\n    }\n\n    SWAP(b,f)\n\n\n\n    for (; n < 48;) {\n\n        ROUND128_32_TO_47(a,b,c,d,e,f,g,h);\n\n        ROUND128_32_TO_47(d,a,b,c,h,e,f,g);\n\n        ROUND128_32_TO_47(c,d,a,b,g,h,e,f);\n\n        ROUND128_32_TO_47(b,c,d,a,f,g,h,e);\n\n    }\n\n    SWAP(c,g)\n\n\n\n    for (; n < 64;) {\n\n        ROUND128_48_TO_63(a,b,c,d,e,f,g,h);\n\n        ROUND128_48_TO_63(d,a,b,c,h,e,f,g);\n\n        ROUND128_48_TO_63(c,d,a,b,g,h,e,f);\n\n        ROUND128_48_TO_63(b,c,d,a,f,g,h,e);\n\n    }\n\n    SWAP(d,h)\n\n\n\n    if (ext) {\n\n        state[0] += a; state[1] += b; state[2] += c; state[3] += d;\n\n        state[4] += e; state[5] += f; state[6] += g; state[7] += h;\n\n    } else {\n\n        h += c + state[1];\n\n        state[1] = state[2] + d + e;\n\n        state[2] = state[3] + a + f;\n\n        state[3] = state[0] + b + g;\n\n        state[0] = h;\n\n    }\n\n}\n", "idx": 22049}
{"project": "FFmpeg", "commit_id": "3359246d9a47c3f4418d994853efe17324a0159b", "target": 1, "func": "static int mxf_read_seek(AVFormatContext *s, int stream_index, int64_t sample_time, int flags)\n\n{\n\n    AVStream *st = s->streams[stream_index];\n\n    int64_t seconds;\n\n\n\n    if (!s->bit_rate)\n\n        return AVERROR_INVALIDDATA;\n\n    if (sample_time < 0)\n\n        sample_time = 0;\n\n    seconds = av_rescale(sample_time, st->time_base.num, st->time_base.den);\n\n    avio_seek(s->pb, (s->bit_rate * seconds) >> 3, SEEK_SET);\n\n    ff_update_cur_dts(s, st, sample_time);\n\n    return 0;\n\n}\n", "idx": 22054}
{"project": "FFmpeg", "commit_id": "e96ecaf053d8d606e38ae2e56ba6cf58875021b0", "target": 1, "func": "static int encode_apng(AVCodecContext *avctx, AVPacket *pkt,\n\n                       const AVFrame *pict, int *got_packet)\n\n{\n\n    PNGEncContext *s = avctx->priv_data;\n\n    int ret;\n\n    int enc_row_size;\n\n    size_t max_packet_size;\n\n    APNGFctlChunk fctl_chunk;\n\n\n\n    if (pict && avctx->codec_id == AV_CODEC_ID_APNG && s->color_type == PNG_COLOR_TYPE_PALETTE) {\n\n        uint32_t checksum = ~av_crc(av_crc_get_table(AV_CRC_32_IEEE_LE), ~0U, pict->data[1], 256 * sizeof(uint32_t));\n\n\n\n        if (avctx->frame_number == 0) {\n\n            s->palette_checksum = checksum;\n\n        } else if (checksum != s->palette_checksum) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Input contains more than one unique palette. APNG does not support multiple palettes.\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    enc_row_size    = deflateBound(&s->zstream, (avctx->width * s->bits_per_pixel + 7) >> 3);\n\n    max_packet_size =\n\n        AV_INPUT_BUFFER_MIN_SIZE + // headers\n\n        avctx->height * (\n\n            enc_row_size +\n\n            (4 + 12) * (((int64_t)enc_row_size + IOBUF_SIZE - 1) / IOBUF_SIZE) // fdAT * ceil(enc_row_size / IOBUF_SIZE)\n\n        );\n\n    if (max_packet_size > INT_MAX)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if (avctx->frame_number == 0) {\n\n        s->bytestream = avctx->extradata = av_malloc(FF_MIN_BUFFER_SIZE);\n\n        if (!avctx->extradata)\n\n            return AVERROR(ENOMEM);\n\n\n\n        ret = encode_headers(avctx, pict);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        avctx->extradata_size = s->bytestream - avctx->extradata;\n\n\n\n        s->last_frame_packet = av_malloc(max_packet_size);\n\n        if (!s->last_frame_packet)\n\n            return AVERROR(ENOMEM);\n\n    } else if (s->last_frame) {\n\n        ret = ff_alloc_packet2(avctx, pkt, max_packet_size, 0);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        memcpy(pkt->data, s->last_frame_packet, s->last_frame_packet_size);\n\n        pkt->size = s->last_frame_packet_size;\n\n        pkt->pts = pkt->dts = s->last_frame->pts;\n\n    }\n\n\n\n    if (pict) {\n\n        s->bytestream_start =\n\n        s->bytestream       = s->last_frame_packet;\n\n        s->bytestream_end   = s->bytestream + max_packet_size;\n\n\n\n        // We're encoding the frame first, so we have to do a bit of shuffling around\n\n        // to have the image data write to the correct place in the buffer\n\n        fctl_chunk.sequence_number = s->sequence_number;\n\n        ++s->sequence_number;\n\n        s->bytestream += 26 + 12;\n\n\n\n        ret = apng_encode_frame(avctx, pict, &fctl_chunk, &s->last_frame_fctl);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        fctl_chunk.delay_num = 0; // delay filled in during muxing\n\n        fctl_chunk.delay_den = 0;\n\n    } else {\n\n        s->last_frame_fctl.dispose_op = APNG_DISPOSE_OP_NONE;\n\n    }\n\n\n\n    if (s->last_frame) {\n\n        uint8_t* last_fctl_chunk_start = pkt->data;\n\n        uint8_t buf[26];\n\n\n\n        AV_WB32(buf + 0, s->last_frame_fctl.sequence_number);\n\n        AV_WB32(buf + 4, s->last_frame_fctl.width);\n\n        AV_WB32(buf + 8, s->last_frame_fctl.height);\n\n        AV_WB32(buf + 12, s->last_frame_fctl.x_offset);\n\n        AV_WB32(buf + 16, s->last_frame_fctl.y_offset);\n\n        AV_WB16(buf + 20, s->last_frame_fctl.delay_num);\n\n        AV_WB16(buf + 22, s->last_frame_fctl.delay_den);\n\n        buf[24] = s->last_frame_fctl.dispose_op;\n\n        buf[25] = s->last_frame_fctl.blend_op;\n\n        png_write_chunk(&last_fctl_chunk_start, MKTAG('f', 'c', 'T', 'L'), buf, 26);\n\n\n\n        *got_packet = 1;\n\n    }\n\n\n\n    if (pict) {\n\n        if (!s->last_frame) {\n\n            s->last_frame = av_frame_alloc();\n\n            if (!s->last_frame)\n\n                return AVERROR(ENOMEM);\n\n        } else if (s->last_frame_fctl.dispose_op != APNG_DISPOSE_OP_PREVIOUS) {\n\n            if (!s->prev_frame) {\n\n                s->prev_frame = av_frame_alloc();\n\n                if (!s->prev_frame)\n\n                    return AVERROR(ENOMEM);\n\n\n\n                s->prev_frame->format = pict->format;\n\n                s->prev_frame->width = pict->width;\n\n                s->prev_frame->height = pict->height;\n\n                if ((ret = av_frame_get_buffer(s->prev_frame, 32)) < 0)\n\n                    return ret;\n\n            }\n\n\n\n            // Do disposal, but not blending\n\n            memcpy(s->prev_frame->data[0], s->last_frame->data[0],\n\n                   s->last_frame->linesize[0] * s->last_frame->height);\n\n            if (s->last_frame_fctl.dispose_op == APNG_DISPOSE_OP_BACKGROUND) {\n\n                uint32_t y;\n\n                uint8_t bpp = (s->bits_per_pixel + 7) >> 3;\n\n                for (y = s->last_frame_fctl.y_offset; y < s->last_frame_fctl.y_offset + s->last_frame_fctl.height; ++y) {\n\n                    size_t row_start = s->last_frame->linesize[0] * y + bpp * s->last_frame_fctl.x_offset;\n\n                    memset(s->prev_frame->data[0] + row_start, 0, bpp * s->last_frame_fctl.width);\n\n                }\n\n            }\n\n        }\n\n\n\n        av_frame_unref(s->last_frame);\n\n        ret = av_frame_ref(s->last_frame, (AVFrame*)pict);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        s->last_frame_fctl = fctl_chunk;\n\n        s->last_frame_packet_size = s->bytestream - s->bytestream_start;\n\n    } else {\n\n        av_frame_free(&s->last_frame);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22057}
{"project": "FFmpeg", "commit_id": "6a697b42d0c8469c05e2a1a0920d8539ba7b068d", "target": 1, "func": "int ff_combine_frame(ParseContext *pc, int next, const uint8_t **buf, int *buf_size)\n\n{\n\n    if(pc->overread){\n\n        av_dlog(NULL, \"overread %d, state:%X next:%d index:%d o_index:%d\\n\",\n\n                pc->overread, pc->state, next, pc->index, pc->overread_index);\n\n        av_dlog(NULL, \"%X %X %X %X\\n\", (*buf)[0], (*buf)[1], (*buf)[2], (*buf)[3]);\n\n    }\n\n\n\n    /* Copy overread bytes from last frame into buffer. */\n\n    for(; pc->overread>0; pc->overread--){\n\n        pc->buffer[pc->index++]= pc->buffer[pc->overread_index++];\n\n    }\n\n\n\n    /* flush remaining if EOF */\n\n    if(!*buf_size && next == END_NOT_FOUND){\n\n        next= 0;\n\n    }\n\n\n\n    pc->last_index= pc->index;\n\n\n\n    /* copy into buffer end return */\n\n    if(next == END_NOT_FOUND){\n\n        void* new_buffer = av_fast_realloc(pc->buffer, &pc->buffer_size, (*buf_size) + pc->index + FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n        if(!new_buffer)\n\n            return AVERROR(ENOMEM);\n\n        pc->buffer = new_buffer;\n\n        memcpy(&pc->buffer[pc->index], *buf, *buf_size);\n\n        pc->index += *buf_size;\n\n        return -1;\n\n    }\n\n\n\n    *buf_size=\n\n    pc->overread_index= pc->index + next;\n\n\n\n    /* append to buffer */\n\n    if(pc->index){\n\n        void* new_buffer = av_fast_realloc(pc->buffer, &pc->buffer_size, next + pc->index + FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n        if(!new_buffer)\n\n            return AVERROR(ENOMEM);\n\n        pc->buffer = new_buffer;\n\n\n        memcpy(&pc->buffer[pc->index], *buf, next + FF_INPUT_BUFFER_PADDING_SIZE );\n\n        pc->index = 0;\n\n        *buf= pc->buffer;\n\n    }\n\n\n\n    /* store overread bytes */\n\n    for(;next < 0; next++){\n\n        pc->state = (pc->state<<8) | pc->buffer[pc->last_index + next];\n\n        pc->state64 = (pc->state64<<8) | pc->buffer[pc->last_index + next];\n\n        pc->overread++;\n\n    }\n\n\n\n    if(pc->overread){\n\n        av_dlog(NULL, \"overread %d, state:%X next:%d index:%d o_index:%d\\n\",\n\n                pc->overread, pc->state, next, pc->index, pc->overread_index);\n\n        av_dlog(NULL, \"%X %X %X %X\\n\", (*buf)[0], (*buf)[1],(*buf)[2],(*buf)[3]);\n\n    }\n\n\n\n    return 0;\n\n}", "idx": 22061}
{"project": "FFmpeg", "commit_id": "de64d8cf171c6ecdca22d57f0bdd7efec95d0c0e", "target": 1, "func": "static void qtrle_decode_1bpp(QtrleContext *s, int stream_ptr, int row_ptr, int lines_to_change)\n\n{\n\n    int rle_code;\n\n    int pixel_ptr = 0;\n\n    int row_inc = s->frame.linesize[0];\n\n    unsigned char pi0, pi1;  /* 2 8-pixel values */\n\n    unsigned char *rgb = s->frame.data[0];\n\n    int pixel_limit = s->frame.linesize[0] * s->avctx->height;\n\n    int skip;\n\n\n\n    while (lines_to_change) {\n\n        CHECK_STREAM_PTR(2);\n\n        skip = s->buf[stream_ptr++];\n\n        rle_code = (signed char)s->buf[stream_ptr++];\n\n        if (rle_code == 0)\n\n            break;\n\n        if(skip & 0x80) {\n\n            lines_to_change--;\n\n            row_ptr += row_inc;\n\n            pixel_ptr = row_ptr + 2 * (skip & 0x7f);\n\n        } else\n\n            pixel_ptr += 2 * skip;\n\n        CHECK_PIXEL_PTR(0);  /* make sure pixel_ptr is positive */\n\n\n\n        if (rle_code < 0) {\n\n            /* decode the run length code */\n\n            rle_code = -rle_code;\n\n            /* get the next 2 bytes from the stream, treat them as groups\n\n             * of 8 pixels, and output them rle_code times */\n\n            CHECK_STREAM_PTR(2);\n\n            pi0 = s->buf[stream_ptr++];\n\n            pi1 = s->buf[stream_ptr++];\n\n            CHECK_PIXEL_PTR(rle_code * 2);\n\n\n\n            while (rle_code--) {\n\n                rgb[pixel_ptr++] = pi0;\n\n                rgb[pixel_ptr++] = pi1;\n\n            }\n\n        } else {\n\n            /* copy the same pixel directly to output 2 times */\n\n            rle_code *= 2;\n\n            CHECK_STREAM_PTR(rle_code);\n\n            CHECK_PIXEL_PTR(rle_code);\n\n\n\n            while (rle_code--)\n\n                rgb[pixel_ptr++] = s->buf[stream_ptr++];\n\n        }\n\n    }\n\n}\n", "idx": 22062}
{"project": "FFmpeg", "commit_id": "52d2bcc78632f868cc4045c8f1cd03533418f0b6", "target": 0, "func": "static int libopenjpeg_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n\n                                    const AVFrame *frame, int *got_packet)\n\n{\n\n    LibOpenJPEGContext *ctx = avctx->priv_data;\n\n    opj_cinfo_t *compress = ctx->compress;\n\n    opj_image_t *image    = ctx->image;\n\n    opj_cio_t *stream     = ctx->stream;\n\n    int cpyresult = 0;\n\n    int ret, len;\n\n    AVFrame *gbrframe;\n\n\n\n    switch (avctx->pix_fmt) {\n\n    case AV_PIX_FMT_RGB24:\n\n    case AV_PIX_FMT_RGBA:\n\n    case AV_PIX_FMT_GRAY8A:\n\n        cpyresult = libopenjpeg_copy_packed8(avctx, frame, image);\n\n        break;\n\n    case AV_PIX_FMT_XYZ12:\n\n        cpyresult = libopenjpeg_copy_packed12(avctx, frame, image);\n\n        break;\n\n    case AV_PIX_FMT_RGB48:\n\n    case AV_PIX_FMT_RGBA64:\n\n        cpyresult = libopenjpeg_copy_packed16(avctx, frame, image);\n\n        break;\n\n    case AV_PIX_FMT_GBR24P:\n\n    case AV_PIX_FMT_GBRP9:\n\n    case AV_PIX_FMT_GBRP10:\n\n    case AV_PIX_FMT_GBRP12:\n\n    case AV_PIX_FMT_GBRP14:\n\n    case AV_PIX_FMT_GBRP16:\n\n        gbrframe = av_frame_alloc();\n\n        if (!gbrframe)\n\n            return AVERROR(ENOMEM);\n\n        av_frame_ref(gbrframe, frame);\n\n        gbrframe->data[0] = frame->data[2]; // swap to be rgb\n\n        gbrframe->data[1] = frame->data[0];\n\n        gbrframe->data[2] = frame->data[1];\n\n        gbrframe->linesize[0] = frame->linesize[2];\n\n        gbrframe->linesize[1] = frame->linesize[0];\n\n        gbrframe->linesize[2] = frame->linesize[1];\n\n        if (avctx->pix_fmt == AV_PIX_FMT_GBR24P) {\n\n            cpyresult = libopenjpeg_copy_unpacked8(avctx, gbrframe, image);\n\n        } else {\n\n            cpyresult = libopenjpeg_copy_unpacked16(avctx, gbrframe, image);\n\n        }\n\n        av_frame_free(&gbrframe);\n\n        break;\n\n    case AV_PIX_FMT_GRAY8:\n\n    case AV_PIX_FMT_YUV410P:\n\n    case AV_PIX_FMT_YUV411P:\n\n    case AV_PIX_FMT_YUV420P:\n\n    case AV_PIX_FMT_YUV422P:\n\n    case AV_PIX_FMT_YUV440P:\n\n    case AV_PIX_FMT_YUV444P:\n\n    case AV_PIX_FMT_YUVA420P:\n\n    case AV_PIX_FMT_YUVA422P:\n\n    case AV_PIX_FMT_YUVA444P:\n\n        cpyresult = libopenjpeg_copy_unpacked8(avctx, frame, image);\n\n        break;\n\n    case AV_PIX_FMT_GRAY16:\n\n    case AV_PIX_FMT_YUV420P9:\n\n    case AV_PIX_FMT_YUV422P9:\n\n    case AV_PIX_FMT_YUV444P9:\n\n    case AV_PIX_FMT_YUVA420P9:\n\n    case AV_PIX_FMT_YUVA422P9:\n\n    case AV_PIX_FMT_YUVA444P9:\n\n    case AV_PIX_FMT_YUV444P10:\n\n    case AV_PIX_FMT_YUV422P10:\n\n    case AV_PIX_FMT_YUV420P10:\n\n    case AV_PIX_FMT_YUVA444P10:\n\n    case AV_PIX_FMT_YUVA422P10:\n\n    case AV_PIX_FMT_YUVA420P10:\n\n    case AV_PIX_FMT_YUV420P12:\n\n    case AV_PIX_FMT_YUV422P12:\n\n    case AV_PIX_FMT_YUV444P12:\n\n    case AV_PIX_FMT_YUV420P14:\n\n    case AV_PIX_FMT_YUV422P14:\n\n    case AV_PIX_FMT_YUV444P14:\n\n    case AV_PIX_FMT_YUV444P16:\n\n    case AV_PIX_FMT_YUV422P16:\n\n    case AV_PIX_FMT_YUV420P16:\n\n    case AV_PIX_FMT_YUVA444P16:\n\n    case AV_PIX_FMT_YUVA422P16:\n\n    case AV_PIX_FMT_YUVA420P16:\n\n        cpyresult = libopenjpeg_copy_unpacked16(avctx, frame, image);\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"The frame's pixel format '%s' is not supported\\n\",\n\n               av_get_pix_fmt_name(avctx->pix_fmt));\n\n        return AVERROR(EINVAL);\n\n        break;\n\n    }\n\n\n\n    if (!cpyresult) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Could not copy the frame data to the internal image buffer\\n\");\n\n        return -1;\n\n    }\n\n\n\n    cio_seek(stream, 0);\n\n    if (!opj_encode(compress, stream, image, NULL)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error during the opj encode\\n\");\n\n        return -1;\n\n    }\n\n\n\n    len = cio_tell(stream);\n\n    if ((ret = ff_alloc_packet2(avctx, pkt, len)) < 0) {\n\n        return ret;\n\n    }\n\n\n\n    memcpy(pkt->data, stream->buffer, len);\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n\n    *got_packet = 1;\n\n    return 0;\n\n}\n", "idx": 22075}
{"project": "FFmpeg", "commit_id": "808c10e728db2d92ccbb0f8b3bcd4a2f4305a2cf", "target": 0, "func": "static void format_line(void *ptr, int level, const char *fmt, va_list vl,\n\n                        AVBPrint part[3], int *print_prefix, int type[2])\n\n{\n\n    AVClass* avc = ptr ? *(AVClass **) ptr : NULL;\n\n    av_bprint_init(part+0, 0, 1);\n\n    av_bprint_init(part+1, 0, 1);\n\n    av_bprint_init(part+2, 0, 65536);\n\n\n\n    if(type) type[0] = type[1] = AV_CLASS_CATEGORY_NA + 16;\n\n    if (*print_prefix && avc) {\n\n        if (avc->parent_log_context_offset) {\n\n            AVClass** parent = *(AVClass ***) (((uint8_t *) ptr) +\n\n                                   avc->parent_log_context_offset);\n\n            if (parent && *parent) {\n\n                av_bprintf(part+0, \"[%s @ %p] \",\n\n                         (*parent)->item_name(parent), parent);\n\n                if(type) type[0] = get_category(parent);\n\n            }\n\n        }\n\n        av_bprintf(part+1, \"[%s @ %p] \",\n\n                 avc->item_name(ptr), ptr);\n\n        if(type) type[1] = get_category(ptr);\n\n    }\n\n\n\n    av_vbprintf(part+2, fmt, vl);\n\n\n\n    if(*part[0].str || *part[1].str || *part[2].str) {\n\n        char lastc = part[2].len ? part[2].str[part[2].len - 1] : 0;\n\n        *print_prefix = lastc == '\\n' || lastc == '\\r';\n\n    }\n\n}\n", "idx": 22086}
{"project": "FFmpeg", "commit_id": "80a5d05108cb218e8cd2e25c6621a3bfef0a832e", "target": 0, "func": "static av_cold int vaapi_encode_mjpeg_init(AVCodecContext *avctx)\n\n{\n\n    return ff_vaapi_encode_init(avctx, &vaapi_encode_type_mjpeg);\n\n}\n", "idx": 22087}
{"project": "FFmpeg", "commit_id": "d7e14c0d103a2c9cca6c50568e09b40d6f48ea19", "target": 0, "func": "static inline int is_yuv_planar(const PixFmtInfo *ps)\n\n{\n\n    return (ps->color_type == FF_COLOR_YUV ||\n\n            ps->color_type == FF_COLOR_YUV_JPEG) &&\n\n        ps->pixel_type == FF_PIXEL_PLANAR;\n\n}\n", "idx": 22088}
{"project": "FFmpeg", "commit_id": "1f4ff53aea7c5090f31cd1323d95f7c407c9b2bb", "target": 0, "func": "static int dnxhd_init_vlc(DNXHDContext *ctx, uint32_t cid)\n\n{\n\n    if (cid != ctx->cid) {\n\n        int index;\n\n\n\n        if ((index = ff_dnxhd_get_cid_table(cid)) < 0) {\n\n            av_log(ctx->avctx, AV_LOG_ERROR, \"unsupported cid %d\\n\", cid);\n\n            return AVERROR(ENOSYS);\n\n        }\n\n        if (ff_dnxhd_cid_table[index].bit_depth != ctx->bit_depth) {\n\n            av_log(ctx->avctx, AV_LOG_ERROR, \"bit depth mismatches %d %d\\n\", ff_dnxhd_cid_table[index].bit_depth, ctx->bit_depth);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        ctx->cid_table = &ff_dnxhd_cid_table[index];\n\n        av_log(ctx->avctx, AV_LOG_VERBOSE, \"Profile cid %d.\\n\", cid);\n\n\n\n        ff_free_vlc(&ctx->ac_vlc);\n\n        ff_free_vlc(&ctx->dc_vlc);\n\n        ff_free_vlc(&ctx->run_vlc);\n\n\n\n        init_vlc(&ctx->ac_vlc, DNXHD_VLC_BITS, 257,\n\n                 ctx->cid_table->ac_bits, 1, 1,\n\n                 ctx->cid_table->ac_codes, 2, 2, 0);\n\n        init_vlc(&ctx->dc_vlc, DNXHD_DC_VLC_BITS, ctx->bit_depth + 4,\n\n                 ctx->cid_table->dc_bits, 1, 1,\n\n                 ctx->cid_table->dc_codes, 1, 1, 0);\n\n        init_vlc(&ctx->run_vlc, DNXHD_VLC_BITS, 62,\n\n                 ctx->cid_table->run_bits, 1, 1,\n\n                 ctx->cid_table->run_codes, 2, 2, 0);\n\n\n\n        ctx->cid = cid;\n\n    }\n\n    return 0;\n\n}\n", "idx": 22089}
{"project": "FFmpeg", "commit_id": "57d77b3963ce1023eaf5ada8cba58b9379405cc8", "target": 0, "func": "int av_opencl_create_kernel(AVOpenCLKernelEnv *env, const char *kernel_name)\n\n{\n\n    cl_int status;\n\n    int i, ret = 0;\n\n    LOCK_OPENCL;\n\n    if (strlen(kernel_name) + 1 > AV_OPENCL_MAX_KERNEL_NAME_SIZE) {\n\n        av_log(&openclutils, AV_LOG_ERROR, \"Created kernel name %s is too long\\n\", kernel_name);\n\n        ret = AVERROR(EINVAL);\n\n        goto end;\n\n    }\n\n    if (!env->kernel) {\n\n        if (gpu_env.kernel_count >= MAX_KERNEL_NUM) {\n\n            av_log(&openclutils, AV_LOG_ERROR,\n\n            \"Could not create kernel with name '%s', maximum number of kernels %d already reached\\n\",\n\n                kernel_name, MAX_KERNEL_NUM);\n\n            ret = AVERROR(EINVAL);\n\n            goto end;\n\n        }\n\n        for (i = 0; i < gpu_env.program_count; i++) {\n\n            env->kernel = clCreateKernel(gpu_env.programs[i], kernel_name, &status);\n\n            if (status == CL_SUCCESS)\n\n                break;\n\n        }\n\n        if (status != CL_SUCCESS) {\n\n            av_log(&openclutils, AV_LOG_ERROR, \"Could not create OpenCL kernel: %s\\n\", opencl_errstr(status));\n\n            ret = AVERROR_EXTERNAL;\n\n            goto end;\n\n        }\n\n        gpu_env.kernel_count++;\n\n        env->command_queue = gpu_env.command_queue;\n\n        av_strlcpy(env->kernel_name, kernel_name, sizeof(env->kernel_name));\n\n    }\n\nend:\n\n    UNLOCK_OPENCL;\n\n    return ret;\n\n}\n", "idx": 22090}
{"project": "FFmpeg", "commit_id": "d1cacdb8dda4eb2a5532267b0aeb1d2afdf95f05", "target": 0, "func": "static av_cold int a64multi_init_encoder(AVCodecContext *avctx)\n\n{\n\n    A64Context *c = avctx->priv_data;\n\n    int a;\n\n    av_lfg_init(&c->randctx, 1);\n\n\n\n    if (avctx->global_quality < 1) {\n\n        c->mc_lifetime = 4;\n\n    } else {\n\n        c->mc_lifetime = avctx->global_quality /= FF_QP2LAMBDA;\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_INFO, \"charset lifetime set to %d frame(s)\\n\", c->mc_lifetime);\n\n\n\n    /* precalc luma values for later use */\n\n    for (a = 0; a < 5; a++) {\n\n        c->mc_luma_vals[a]=a64_palette[mc_colors[a]][0] * 0.30 +\n\n                           a64_palette[mc_colors[a]][1] * 0.59 +\n\n                           a64_palette[mc_colors[a]][2] * 0.11;\n\n    }\n\n\n\n    c->mc_frame_counter = 0;\n\n    c->mc_use_5col      = avctx->codec->id == CODEC_ID_A64_MULTI5;\n\n    c->mc_meta_charset  = av_malloc (32000 * c->mc_lifetime * sizeof(int));\n\n    c->mc_best_cb       = av_malloc (CHARSET_CHARS * 32 * sizeof(int));\n\n    c->mc_charmap       = av_mallocz(1000 * c->mc_lifetime * sizeof(int));\n\n    c->mc_colram        = av_mallocz(CHARSET_CHARS * sizeof(uint8_t));\n\n    c->mc_charset       = av_malloc (0x800 * (INTERLACED+1) * sizeof(uint8_t));\n\n\n\n    /* set up extradata */\n\n    avctx->extradata      = av_mallocz(8 * 4 + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    avctx->extradata_size = 8 * 4;\n\n    AV_WB32(avctx->extradata, c->mc_lifetime);\n\n    AV_WB32(avctx->extradata+16, INTERLACED);\n\n\n\n    avcodec_get_frame_defaults(&c->picture);\n\n    avctx->coded_frame            = &c->picture;\n\n    avctx->coded_frame->pict_type = FF_I_TYPE;\n\n    avctx->coded_frame->key_frame = 1;\n\n    if (!avctx->codec_tag)\n\n         avctx->codec_tag = AV_RL32(\"a64m\");\n\n\n\n    return 0;\n\n}\n", "idx": 22091}
{"project": "FFmpeg", "commit_id": "f5695926235c9b2a60af07b21c2d6f1db990cc2a", "target": 0, "func": "static int pulse_write_packet(AVFormatContext *h, AVPacket *pkt)\n\n{\n\n    PulseData *s = h->priv_data;\n\n    int size     = pkt->size;\n\n    uint8_t *buf = pkt->data;\n\n    int error;\n\n\n\n    if (s->stream_index != pkt->stream_index)\n\n        return 0;\n\n\n\n    if ((error = pa_simple_write(s->pa, buf, size, &error))) {\n\n        av_log(s, AV_LOG_ERROR, \"pa_simple_write failed: %s\\n\", pa_strerror(error));\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22092}
{"project": "FFmpeg", "commit_id": "e89f58810d0d508552089495781e2a70e95edb99", "target": 0, "func": "static void check_default_settings(AVCodecContext *avctx)\n\n{\n\n    X264Context *x4 = avctx->priv_data;\n\n\n\n    int score = 0;\n\n    score += x4->params.analyse.i_me_range == 0;\n\n    score += x4->params.rc.i_qp_step == 3;\n\n    score += x4->params.i_keyint_max == 12;\n\n    score += x4->params.rc.i_qp_min == 2;\n\n    score += x4->params.rc.i_qp_max == 31;\n\n    score += x4->params.rc.f_qcompress == 0.5;\n\n    score += fabs(x4->params.rc.f_ip_factor - 1.25) < 0.01;\n\n    score += fabs(x4->params.rc.f_pb_factor - 1.25) < 0.01;\n\n    score += x4->params.analyse.inter == 0 && x4->params.analyse.i_subpel_refine == 8;\n\n    if (score >= 5) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Default settings detected, using medium profile\\n\");\n\n        x4->preset = av_strdup(\"medium\");\n\n        if (avctx->bit_rate == 200*1000)\n\n            avctx->crf = 23;\n\n    }\n\n}\n", "idx": 22093}
{"project": "FFmpeg", "commit_id": "255d4e717faa98ab783401acd68a278af32f6360", "target": 0, "func": "static inline int decode_picture_parameter_set(H264Context *h, int bit_length){\n\n    MpegEncContext * const s = &h->s;\n\n    unsigned int tmp, pps_id= get_ue_golomb(&s->gb);\n\n    PPS *pps;\n\n\n\n    pps = alloc_parameter_set(h, (void **)h->pps_buffers, pps_id, MAX_PPS_COUNT, sizeof(PPS), \"pps\");\n\n    if(pps == NULL)\n\n        return -1;\n\n\n\n    tmp= get_ue_golomb(&s->gb);\n\n    if(tmp>=MAX_SPS_COUNT || h->sps_buffers[tmp] == NULL){\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"sps_id out of range\\n\");\n\n        return -1;\n\n    }\n\n    pps->sps_id= tmp;\n\n\n\n    pps->cabac= get_bits1(&s->gb);\n\n    pps->pic_order_present= get_bits1(&s->gb);\n\n    pps->slice_group_count= get_ue_golomb(&s->gb) + 1;\n\n    if(pps->slice_group_count > 1 ){\n\n        pps->mb_slice_group_map_type= get_ue_golomb(&s->gb);\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"FMO not supported\\n\");\n\n        switch(pps->mb_slice_group_map_type){\n\n        case 0:\n\n#if 0\n\n|   for( i = 0; i <= num_slice_groups_minus1; i++ ) |   |        |\n\n|    run_length[ i ]                                |1  |ue(v)   |\n\n#endif\n\n            break;\n\n        case 2:\n\n#if 0\n\n|   for( i = 0; i < num_slice_groups_minus1; i++ )  |   |        |\n\n|{                                                  |   |        |\n\n|    top_left_mb[ i ]                               |1  |ue(v)   |\n\n|    bottom_right_mb[ i ]                           |1  |ue(v)   |\n\n|   }                                               |   |        |\n\n#endif\n\n            break;\n\n        case 3:\n\n        case 4:\n\n        case 5:\n\n#if 0\n\n|   slice_group_change_direction_flag               |1  |u(1)    |\n\n|   slice_group_change_rate_minus1                  |1  |ue(v)   |\n\n#endif\n\n            break;\n\n        case 6:\n\n#if 0\n\n|   slice_group_id_cnt_minus1                       |1  |ue(v)   |\n\n|   for( i = 0; i <= slice_group_id_cnt_minus1; i++ |   |        |\n\n|)                                                  |   |        |\n\n|    slice_group_id[ i ]                            |1  |u(v)    |\n\n#endif\n\n            break;\n\n        }\n\n    }\n\n    pps->ref_count[0]= get_ue_golomb(&s->gb) + 1;\n\n    pps->ref_count[1]= get_ue_golomb(&s->gb) + 1;\n\n    if(pps->ref_count[0]-1 > 32-1 || pps->ref_count[1]-1 > 32-1){\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"reference overflow (pps)\\n\");\n\n        pps->ref_count[0]= pps->ref_count[1]= 1;\n\n        return -1;\n\n    }\n\n\n\n    pps->weighted_pred= get_bits1(&s->gb);\n\n    pps->weighted_bipred_idc= get_bits(&s->gb, 2);\n\n    pps->init_qp= get_se_golomb(&s->gb) + 26;\n\n    pps->init_qs= get_se_golomb(&s->gb) + 26;\n\n    pps->chroma_qp_index_offset[0]= get_se_golomb(&s->gb);\n\n    pps->deblocking_filter_parameters_present= get_bits1(&s->gb);\n\n    pps->constrained_intra_pred= get_bits1(&s->gb);\n\n    pps->redundant_pic_cnt_present = get_bits1(&s->gb);\n\n\n\n    pps->transform_8x8_mode= 0;\n\n    h->dequant_coeff_pps= -1; //contents of sps/pps can change even if id doesn't, so reinit\n\n    memcpy(pps->scaling_matrix4, h->sps_buffers[pps->sps_id]->scaling_matrix4, sizeof(pps->scaling_matrix4));\n\n    memcpy(pps->scaling_matrix8, h->sps_buffers[pps->sps_id]->scaling_matrix8, sizeof(pps->scaling_matrix8));\n\n\n\n    if(get_bits_count(&s->gb) < bit_length){\n\n        pps->transform_8x8_mode= get_bits1(&s->gb);\n\n        decode_scaling_matrices(h, h->sps_buffers[pps->sps_id], pps, 0, pps->scaling_matrix4, pps->scaling_matrix8);\n\n        pps->chroma_qp_index_offset[1]= get_se_golomb(&s->gb); //second_chroma_qp_index_offset\n\n    } else {\n\n        pps->chroma_qp_index_offset[1]= pps->chroma_qp_index_offset[0];\n\n    }\n\n\n\n    build_qp_table(pps, 0, pps->chroma_qp_index_offset[0]);\n\n    build_qp_table(pps, 1, pps->chroma_qp_index_offset[1]);\n\n    if(pps->chroma_qp_index_offset[0] != pps->chroma_qp_index_offset[1])\n\n        h->pps.chroma_qp_diff= 1;\n\n\n\n    if(s->avctx->debug&FF_DEBUG_PICT_INFO){\n\n        av_log(h->s.avctx, AV_LOG_DEBUG, \"pps:%u sps:%u %s slice_groups:%d ref:%d/%d %s qp:%d/%d/%d/%d %s %s %s %s\\n\",\n\n               pps_id, pps->sps_id,\n\n               pps->cabac ? \"CABAC\" : \"CAVLC\",\n\n               pps->slice_group_count,\n\n               pps->ref_count[0], pps->ref_count[1],\n\n               pps->weighted_pred ? \"weighted\" : \"\",\n\n               pps->init_qp, pps->init_qs, pps->chroma_qp_index_offset[0], pps->chroma_qp_index_offset[1],\n\n               pps->deblocking_filter_parameters_present ? \"LPAR\" : \"\",\n\n               pps->constrained_intra_pred ? \"CONSTR\" : \"\",\n\n               pps->redundant_pic_cnt_present ? \"REDU\" : \"\",\n\n               pps->transform_8x8_mode ? \"8x8DCT\" : \"\"\n\n               );\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22095}
{"project": "FFmpeg", "commit_id": "aa48446c9a42fc29ae46ea98717f29edc7fec27d", "target": 0, "func": "static int xface_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n\n                              const AVFrame *frame, int *got_packet)\n\n{\n\n    XFaceContext *xface = avctx->priv_data;\n\n    ProbRangesQueue pq = {{ 0 }, 0};\n\n    uint8_t bitmap_copy[XFACE_PIXELS];\n\n    BigInt b = {0};\n\n    int i, j, k, ret = 0;\n\n    const uint8_t *buf;\n\n    uint8_t *p;\n\n    char intbuf[XFACE_MAX_DIGITS];\n\n\n\n    if (avctx->width || avctx->height) {\n\n        if (avctx->width != XFACE_WIDTH || avctx->height != XFACE_HEIGHT) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Size value %dx%d not supported, only accepts a size of %dx%d\\n\",\n\n                   avctx->width, avctx->height, XFACE_WIDTH, XFACE_HEIGHT);\n\n            return AVERROR(EINVAL);\n\n        }\n\n    }\n\n    avctx->width  = XFACE_WIDTH;\n\n    avctx->height = XFACE_HEIGHT;\n\n\n\n    /* convert image from MONOWHITE to 1=black 0=white bitmap */\n\n    buf = frame->data[0];\n\n    for (i = 0, j = 0; i < XFACE_PIXELS; ) {\n\n        for (k = 0; k < 8; k++)\n\n            xface->bitmap[i++] = (buf[j]>>(7-k))&1;\n\n        if (++j == XFACE_WIDTH/8) {\n\n            buf += frame->linesize[0];\n\n            j = 0;\n\n        }\n\n    }\n\n\n\n    /* create a copy of bitmap */\n\n    memcpy(bitmap_copy, xface->bitmap, XFACE_PIXELS);\n\n    ff_xface_generate_face(xface->bitmap, bitmap_copy);\n\n\n\n    encode_block(xface->bitmap,                         16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + 16,                    16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + 32,                    16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + XFACE_WIDTH * 16,      16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + XFACE_WIDTH * 16 + 16, 16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + XFACE_WIDTH * 16 + 32, 16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + XFACE_WIDTH * 32,      16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + XFACE_WIDTH * 32 + 16, 16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + XFACE_WIDTH * 32 + 32, 16, 16, 0, &pq);\n\n\n\n    while (pq.prob_ranges_idx > 0)\n\n        push_integer(&b, pq.prob_ranges[--pq.prob_ranges_idx]);\n\n\n\n    /* write the inverted big integer in b to intbuf */\n\n    i = 0;\n\n    while (b.nb_words) {\n\n        uint8_t r;\n\n        ff_big_div(&b, XFACE_PRINTS, &r);\n\n        intbuf[i++] = r + XFACE_FIRST_PRINT;\n\n    }\n\n\n\n    if ((ret = ff_alloc_packet2(avctx, pkt, i+2)) < 0)\n\n        return ret;\n\n\n\n    /* revert the number, and close the buffer */\n\n    p = pkt->data;\n\n    while (--i >= 0)\n\n        *(p++) = intbuf[i];\n\n    *(p++) = '\\n';\n\n    *(p++) = 0;\n\n\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n\n    *got_packet = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 22106}
{"project": "FFmpeg", "commit_id": "13a099799e89a76eb921ca452e1b04a7a28a9855", "target": 0, "func": "yuv2422_1_c_template(SwsContext *c, const uint16_t *buf0,\n\n                     const uint16_t *ubuf0, const uint16_t *ubuf1,\n\n                     const uint16_t *vbuf0, const uint16_t *vbuf1,\n\n                     const uint16_t *abuf0, uint8_t *dest, int dstW,\n\n                     int uvalpha, enum PixelFormat dstFormat,\n\n                     int flags, int y, enum PixelFormat target)\n\n{\n\n    int i;\n\n\n\n    if (uvalpha < 2048) {\n\n        for (i = 0; i < (dstW >> 1); i++) {\n\n            int Y1 = buf0[i * 2]     >> 7;\n\n            int Y2 = buf0[i * 2 + 1] >> 7;\n\n            int U  = ubuf1[i]        >> 7;\n\n            int V  = vbuf1[i]        >> 7;\n\n\n\n            output_pixels(i * 4, Y1, U, Y2, V);\n\n        }\n\n    } else {\n\n        for (i = 0; i < (dstW >> 1); i++) {\n\n            int Y1 =  buf0[i * 2]          >> 7;\n\n            int Y2 =  buf0[i * 2 + 1]      >> 7;\n\n            int U  = (ubuf0[i] + ubuf1[i]) >> 8;\n\n            int V  = (vbuf0[i] + vbuf1[i]) >> 8;\n\n\n\n            output_pixels(i * 4, Y1, U, Y2, V);\n\n        }\n\n    }\n\n}\n", "idx": 22117}
{"project": "FFmpeg", "commit_id": "b88be742fac7a77a8095e8155ba8790db4b77568", "target": 1, "func": "static void encode_signal_range(VC2EncContext *s)\n\n{\n\n    int idx;\n\n    AVCodecContext *avctx = s->avctx;\n\n    const AVPixFmtDescriptor *fmt = av_pix_fmt_desc_get(avctx->pix_fmt);\n\n    const int depth = fmt->comp[0].depth;\n\n    if (depth == 8 && avctx->color_range == AVCOL_RANGE_JPEG) {\n\n        idx = 1;\n\n        s->bpp = 1;\n\n        s->diff_offset = 128;\n\n    } else if (depth == 8 && (avctx->color_range == AVCOL_RANGE_MPEG ||\n\n               avctx->color_range == AVCOL_RANGE_UNSPECIFIED)) {\n\n        idx = 2;\n\n        s->bpp = 1;\n\n        s->diff_offset = 128;\n\n    } else if (depth == 10) {\n\n        idx = 3;\n\n        s->bpp = 2;\n\n        s->diff_offset = 512;\n\n    } else {\n\n        idx = 4;\n\n        s->bpp = 2;\n\n        s->diff_offset = 2048;\n\n    }\n\n    put_bits(&s->pb, 1, !s->strict_compliance);\n\n    if (!s->strict_compliance)\n\n        put_vc2_ue_uint(&s->pb, idx);\n\n}\n", "idx": 22123}
{"project": "FFmpeg", "commit_id": "1c37848f9029985d1271da9a0d161c2ebf0aca81", "target": 1, "func": "static int webm_dash_manifest_write_header(AVFormatContext *s)\n\n{\n\n    int i;\n\n    double start = 0.0;\n\n    WebMDashMuxContext *w = s->priv_data;\n\n    parse_adaptation_sets(s);\n\n    write_header(s);\n\n    avio_printf(s->pb, \"<Period id=\\\"0\\\"\");\n\n    avio_printf(s->pb, \" start=\\\"PT%gS\\\"\", start);\n\n    if (!w->is_live) {\n\n        avio_printf(s->pb, \" duration=\\\"PT%gS\\\"\", get_duration(s));\n\n    }\n\n    avio_printf(s->pb, \" >\\n\");\n\n\n\n    for (i = 0; i < w->nb_as; i++) {\n\n        if (write_adaptation_set(s, i) < 0) return -1;\n\n    }\n\n\n\n    avio_printf(s->pb, \"</Period>\\n\");\n\n    write_footer(s);\n\n    return 0;\n\n}\n", "idx": 22124}
{"project": "FFmpeg", "commit_id": "8bd1f1a4c8e591e92e7f4933a89fe5de72e5563f", "target": 1, "func": "static av_cold int tta_decode_init(AVCodecContext * avctx)\n{\n    TTAContext *s = avctx->priv_data;\n    int i;\n    s->avctx = avctx;\n    // 30bytes includes a seektable with one frame\n    if (avctx->extradata_size < 30)\n        return -1;\n    init_get_bits(&s->gb, avctx->extradata, avctx->extradata_size * 8);\n    if (show_bits_long(&s->gb, 32) == AV_RL32(\"TTA1\"))\n    {\n        /* signature */\n        skip_bits(&s->gb, 32);\n        s->format = get_bits(&s->gb, 16);\n        if (s->format > 2) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Invalid format\\n\");\n            return -1;\n        if (s->format == FORMAT_ENCRYPTED) {\n            av_log_missing_feature(s->avctx, \"Encrypted TTA\", 0);\n            return AVERROR(EINVAL);\n        avctx->channels = s->channels = get_bits(&s->gb, 16);\n        avctx->bits_per_coded_sample = get_bits(&s->gb, 16);\n        s->bps = (avctx->bits_per_coded_sample + 7) / 8;\n        avctx->sample_rate = get_bits_long(&s->gb, 32);\n        s->data_length = get_bits_long(&s->gb, 32);\n        skip_bits(&s->gb, 32); // CRC32 of header\n        switch(s->bps) {\n        case 2:\n            avctx->sample_fmt = AV_SAMPLE_FMT_S16;\n            avctx->bits_per_raw_sample = 16;\n            break;\n        case 3:\n            avctx->sample_fmt = AV_SAMPLE_FMT_S32;\n            avctx->bits_per_raw_sample = 24;\n            break;\n        default:\n            av_log(avctx, AV_LOG_ERROR, \"Invalid/unsupported sample format.\\n\");\n        // prevent overflow\n        if (avctx->sample_rate > 0x7FFFFF) {\n            av_log(avctx, AV_LOG_ERROR, \"sample_rate too large\\n\");\n            return AVERROR(EINVAL);\n        s->frame_length = 256 * avctx->sample_rate / 245;\n        s->last_frame_length = s->data_length % s->frame_length;\n        s->total_frames = s->data_length / s->frame_length +\n                        (s->last_frame_length ? 1 : 0);\n        av_log(s->avctx, AV_LOG_DEBUG, \"format: %d chans: %d bps: %d rate: %d block: %d\\n\",\n            s->format, avctx->channels, avctx->bits_per_coded_sample, avctx->sample_rate,\n            avctx->block_align);\n        av_log(s->avctx, AV_LOG_DEBUG, \"data_length: %d frame_length: %d last: %d total: %d\\n\",\n            s->data_length, s->frame_length, s->last_frame_length, s->total_frames);\n        // FIXME: seek table\n        for (i = 0; i < s->total_frames; i++)\n            skip_bits(&s->gb, 32);\n        skip_bits(&s->gb, 32); // CRC32 of seektable\n        if(s->frame_length >= UINT_MAX / (s->channels * sizeof(int32_t))){\n            av_log(avctx, AV_LOG_ERROR, \"frame_length too large\\n\");\n            return -1;\n        if (s->bps == 2) {\n            s->decode_buffer = av_mallocz(sizeof(int32_t)*s->frame_length*s->channels);\n            if (!s->decode_buffer)\n                return AVERROR(ENOMEM);\n        s->ch_ctx = av_malloc(avctx->channels * sizeof(*s->ch_ctx));\n        if (!s->ch_ctx) {\n            av_freep(&s->decode_buffer);\n            return AVERROR(ENOMEM);\n    } else {\n        av_log(avctx, AV_LOG_ERROR, \"Wrong extradata present\\n\");\n        return -1;\n    avcodec_get_frame_defaults(&s->frame);\n    avctx->coded_frame = &s->frame;\n    return 0;", "idx": 22125}
{"project": "FFmpeg", "commit_id": "7cbbc4f7e7ffdb874a25e269ac92f7bb161c5b83", "target": 1, "func": "static int parse_ffconfig(const char *filename)\n\n{\n\n    FILE *f;\n\n    char line[1024];\n\n    char cmd[64];\n\n    char arg[1024];\n\n    const char *p;\n\n    int val, errors, line_num;\n\n    FFStream **last_stream, *stream, *redirect;\n\n    FFStream **last_feed, *feed, *s;\n\n    AVCodecContext audio_enc, video_enc;\n\n    enum AVCodecID audio_id, video_id;\n\n\n\n    f = fopen(filename, \"r\");\n\n    if (!f) {\n\n        perror(filename);\n\n        return -1;\n\n    }\n\n\n\n    errors = 0;\n\n    line_num = 0;\n\n    first_stream = NULL;\n\n    last_stream = &first_stream;\n\n    first_feed = NULL;\n\n    last_feed = &first_feed;\n\n    stream = NULL;\n\n    feed = NULL;\n\n    redirect = NULL;\n\n    audio_id = AV_CODEC_ID_NONE;\n\n    video_id = AV_CODEC_ID_NONE;\n\n\n\n#define ERROR(...) report_config_error(filename, line_num, &errors, __VA_ARGS__)\n\n    for(;;) {\n\n        if (fgets(line, sizeof(line), f) == NULL)\n\n            break;\n\n        line_num++;\n\n        p = line;\n\n        while (av_isspace(*p))\n\n            p++;\n\n        if (*p == '\\0' || *p == '#')\n\n            continue;\n\n\n\n        get_arg(cmd, sizeof(cmd), &p);\n\n\n\n        if (!av_strcasecmp(cmd, \"Port\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            val = atoi(arg);\n\n            if (val < 1 || val > 65536) {\n\n                ERROR(\"Invalid_port: %s\\n\", arg);\n\n            }\n\n            my_http_addr.sin_port = htons(val);\n\n        } else if (!av_strcasecmp(cmd, \"BindAddress\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (resolve_host(&my_http_addr.sin_addr, arg) != 0) {\n\n                ERROR(\"%s:%d: Invalid host/IP address: %s\\n\", arg);\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"NoDaemon\")) {\n\n            // do nothing here, its the default now\n\n        } else if (!av_strcasecmp(cmd, \"RTSPPort\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            val = atoi(arg);\n\n            if (val < 1 || val > 65536) {\n\n                ERROR(\"%s:%d: Invalid port: %s\\n\", arg);\n\n            }\n\n            my_rtsp_addr.sin_port = htons(atoi(arg));\n\n        } else if (!av_strcasecmp(cmd, \"RTSPBindAddress\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (resolve_host(&my_rtsp_addr.sin_addr, arg) != 0) {\n\n                ERROR(\"Invalid host/IP address: %s\\n\", arg);\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"MaxHTTPConnections\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            val = atoi(arg);\n\n            if (val < 1 || val > 65536) {\n\n                ERROR(\"Invalid MaxHTTPConnections: %s\\n\", arg);\n\n            }\n\n            nb_max_http_connections = val;\n\n        } else if (!av_strcasecmp(cmd, \"MaxClients\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            val = atoi(arg);\n\n            if (val < 1 || val > nb_max_http_connections) {\n\n                ERROR(\"Invalid MaxClients: %s\\n\", arg);\n\n            } else {\n\n                nb_max_connections = val;\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"MaxBandwidth\")) {\n\n            int64_t llval;\n\n            get_arg(arg, sizeof(arg), &p);\n\n            llval = strtoll(arg, NULL, 10);\n\n            if (llval < 10 || llval > 10000000) {\n\n                ERROR(\"Invalid MaxBandwidth: %s\\n\", arg);\n\n            } else\n\n                max_bandwidth = llval;\n\n        } else if (!av_strcasecmp(cmd, \"CustomLog\")) {\n\n            if (!ffserver_debug)\n\n                get_arg(logfilename, sizeof(logfilename), &p);\n\n        } else if (!av_strcasecmp(cmd, \"<Feed\")) {\n\n            /*********************************************/\n\n            /* Feed related options */\n\n            char *q;\n\n            if (stream || feed) {\n\n                ERROR(\"Already in a tag\\n\");\n\n            } else {\n\n                feed = av_mallocz(sizeof(FFStream));\n\n                get_arg(feed->filename, sizeof(feed->filename), &p);\n\n                q = strrchr(feed->filename, '>');\n\n                if (*q)\n\n                    *q = '\\0';\n\n\n\n                for (s = first_feed; s; s = s->next) {\n\n                    if (!strcmp(feed->filename, s->filename)) {\n\n                        ERROR(\"Feed '%s' already registered\\n\", s->filename);\n\n                    }\n\n                }\n\n\n\n                feed->fmt = av_guess_format(\"ffm\", NULL, NULL);\n\n                /* defaut feed file */\n\n                snprintf(feed->feed_filename, sizeof(feed->feed_filename),\n\n                         \"/tmp/%s.ffm\", feed->filename);\n\n                feed->feed_max_size = 5 * 1024 * 1024;\n\n                feed->is_feed = 1;\n\n                feed->feed = feed; /* self feeding :-) */\n\n\n\n                /* add in stream list */\n\n                *last_stream = feed;\n\n                last_stream = &feed->next;\n\n                /* add in feed list */\n\n                *last_feed = feed;\n\n                last_feed = &feed->next_feed;\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"Launch\")) {\n\n            if (feed) {\n\n                int i;\n\n\n\n                feed->child_argv = av_mallocz(64 * sizeof(char *));\n\n\n\n                for (i = 0; i < 62; i++) {\n\n                    get_arg(arg, sizeof(arg), &p);\n\n                    if (!arg[0])\n\n                        break;\n\n\n\n                    feed->child_argv[i] = av_strdup(arg);\n\n                }\n\n\n\n                feed->child_argv[i] = av_asprintf(\"http://%s:%d/%s\",\n\n                        (my_http_addr.sin_addr.s_addr == INADDR_ANY) ? \"127.0.0.1\" :\n\n                    inet_ntoa(my_http_addr.sin_addr),\n\n                    ntohs(my_http_addr.sin_port), feed->filename);\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"ReadOnlyFile\")) {\n\n            if (feed) {\n\n                get_arg(feed->feed_filename, sizeof(feed->feed_filename), &p);\n\n                feed->readonly = 1;\n\n            } else if (stream) {\n\n                get_arg(stream->feed_filename, sizeof(stream->feed_filename), &p);\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"File\")) {\n\n            if (feed) {\n\n                get_arg(feed->feed_filename, sizeof(feed->feed_filename), &p);\n\n            } else if (stream)\n\n                get_arg(stream->feed_filename, sizeof(stream->feed_filename), &p);\n\n        } else if (!av_strcasecmp(cmd, \"Truncate\")) {\n\n            if (feed) {\n\n                get_arg(arg, sizeof(arg), &p);\n\n                feed->truncate = strtod(arg, NULL);\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"FileMaxSize\")) {\n\n            if (feed) {\n\n                char *p1;\n\n                double fsize;\n\n\n\n                get_arg(arg, sizeof(arg), &p);\n\n                p1 = arg;\n\n                fsize = strtod(p1, &p1);\n\n                switch(av_toupper(*p1)) {\n\n                case 'K':\n\n                    fsize *= 1024;\n\n                    break;\n\n                case 'M':\n\n                    fsize *= 1024 * 1024;\n\n                    break;\n\n                case 'G':\n\n                    fsize *= 1024 * 1024 * 1024;\n\n                    break;\n\n                }\n\n                feed->feed_max_size = (int64_t)fsize;\n\n                if (feed->feed_max_size < FFM_PACKET_SIZE*4) {\n\n                    ERROR(\"Feed max file size is too small, must be at least %d\\n\", FFM_PACKET_SIZE*4);\n\n                }\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"</Feed>\")) {\n\n            if (!feed) {\n\n                ERROR(\"No corresponding <Feed> for </Feed>\\n\");\n\n            }\n\n            feed = NULL;\n\n        } else if (!av_strcasecmp(cmd, \"<Stream\")) {\n\n            /*********************************************/\n\n            /* Stream related options */\n\n            char *q;\n\n            if (stream || feed) {\n\n                ERROR(\"Already in a tag\\n\");\n\n            } else {\n\n                FFStream *s;\n\n                stream = av_mallocz(sizeof(FFStream));\n\n                get_arg(stream->filename, sizeof(stream->filename), &p);\n\n                q = strrchr(stream->filename, '>');\n\n                if (q)\n\n                    *q = '\\0';\n\n\n\n                for (s = first_stream; s; s = s->next) {\n\n                    if (!strcmp(stream->filename, s->filename)) {\n\n                        ERROR(\"Stream '%s' already registered\\n\", s->filename);\n\n                    }\n\n                }\n\n\n\n                stream->fmt = ffserver_guess_format(NULL, stream->filename, NULL);\n\n                avcodec_get_context_defaults3(&video_enc, NULL);\n\n                avcodec_get_context_defaults3(&audio_enc, NULL);\n\n\n\n                audio_id = AV_CODEC_ID_NONE;\n\n                video_id = AV_CODEC_ID_NONE;\n\n                if (stream->fmt) {\n\n                    audio_id = stream->fmt->audio_codec;\n\n                    video_id = stream->fmt->video_codec;\n\n                }\n\n\n\n                *last_stream = stream;\n\n                last_stream = &stream->next;\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"Feed\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream) {\n\n                FFStream *sfeed;\n\n\n\n                sfeed = first_feed;\n\n                while (sfeed != NULL) {\n\n                    if (!strcmp(sfeed->filename, arg))\n\n                        break;\n\n                    sfeed = sfeed->next_feed;\n\n                }\n\n                if (!sfeed)\n\n                    ERROR(\"feed '%s' not defined\\n\", arg);\n\n                else\n\n                    stream->feed = sfeed;\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"Format\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream) {\n\n                if (!strcmp(arg, \"status\")) {\n\n                    stream->stream_type = STREAM_TYPE_STATUS;\n\n                    stream->fmt = NULL;\n\n                } else {\n\n                    stream->stream_type = STREAM_TYPE_LIVE;\n\n                    /* jpeg cannot be used here, so use single frame jpeg */\n\n                    if (!strcmp(arg, \"jpeg\"))\n\n                        strcpy(arg, \"mjpeg\");\n\n                    stream->fmt = ffserver_guess_format(arg, NULL, NULL);\n\n                    if (!stream->fmt) {\n\n                        ERROR(\"Unknown Format: %s\\n\", arg);\n\n                    }\n\n                }\n\n                if (stream->fmt) {\n\n                    audio_id = stream->fmt->audio_codec;\n\n                    video_id = stream->fmt->video_codec;\n\n                }\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"InputFormat\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream) {\n\n                stream->ifmt = av_find_input_format(arg);\n\n                if (!stream->ifmt) {\n\n                    ERROR(\"Unknown input format: %s\\n\", arg);\n\n                }\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"FaviconURL\")) {\n\n            if (stream && stream->stream_type == STREAM_TYPE_STATUS) {\n\n                get_arg(stream->feed_filename, sizeof(stream->feed_filename), &p);\n\n            } else {\n\n                ERROR(\"FaviconURL only permitted for status streams\\n\");\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"Author\")) {\n\n            if (stream)\n\n                get_arg(stream->author, sizeof(stream->author), &p);\n\n        } else if (!av_strcasecmp(cmd, \"Comment\")) {\n\n            if (stream)\n\n                get_arg(stream->comment, sizeof(stream->comment), &p);\n\n        } else if (!av_strcasecmp(cmd, \"Copyright\")) {\n\n            if (stream)\n\n                get_arg(stream->copyright, sizeof(stream->copyright), &p);\n\n        } else if (!av_strcasecmp(cmd, \"Title\")) {\n\n            if (stream)\n\n                get_arg(stream->title, sizeof(stream->title), &p);\n\n        } else if (!av_strcasecmp(cmd, \"Preroll\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream)\n\n                stream->prebuffer = atof(arg) * 1000;\n\n        } else if (!av_strcasecmp(cmd, \"StartSendOnKey\")) {\n\n            if (stream)\n\n                stream->send_on_key = 1;\n\n        } else if (!av_strcasecmp(cmd, \"AudioCodec\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            audio_id = opt_codec(arg, AVMEDIA_TYPE_AUDIO);\n\n            if (audio_id == AV_CODEC_ID_NONE) {\n\n                ERROR(\"Unknown AudioCodec: %s\\n\", arg);\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"VideoCodec\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            video_id = opt_codec(arg, AVMEDIA_TYPE_VIDEO);\n\n            if (video_id == AV_CODEC_ID_NONE) {\n\n                ERROR(\"Unknown VideoCodec: %s\\n\", arg);\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"MaxTime\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream)\n\n                stream->max_time = atof(arg) * 1000;\n\n        } else if (!av_strcasecmp(cmd, \"AudioBitRate\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream)\n\n                audio_enc.bit_rate = lrintf(atof(arg) * 1000);\n\n        } else if (!av_strcasecmp(cmd, \"AudioChannels\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream)\n\n                audio_enc.channels = atoi(arg);\n\n        } else if (!av_strcasecmp(cmd, \"AudioSampleRate\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream)\n\n                audio_enc.sample_rate = atoi(arg);\n\n        } else if (!av_strcasecmp(cmd, \"AudioQuality\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream) {\n\n//                audio_enc.quality = atof(arg) * 1000;\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"VideoBitRateRange\")) {\n\n            if (stream) {\n\n                int minrate, maxrate;\n\n\n\n                get_arg(arg, sizeof(arg), &p);\n\n\n\n                if (sscanf(arg, \"%d-%d\", &minrate, &maxrate) == 2) {\n\n                    video_enc.rc_min_rate = minrate * 1000;\n\n                    video_enc.rc_max_rate = maxrate * 1000;\n\n                } else {\n\n                    ERROR(\"Incorrect format for VideoBitRateRange -- should be <min>-<max>: %s\\n\", arg);\n\n                }\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"Debug\")) {\n\n            if (stream) {\n\n                get_arg(arg, sizeof(arg), &p);\n\n                video_enc.debug = strtol(arg,0,0);\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"Strict\")) {\n\n            if (stream) {\n\n                get_arg(arg, sizeof(arg), &p);\n\n                video_enc.strict_std_compliance = atoi(arg);\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"VideoBufferSize\")) {\n\n            if (stream) {\n\n                get_arg(arg, sizeof(arg), &p);\n\n                video_enc.rc_buffer_size = atoi(arg) * 8*1024;\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"VideoBitRateTolerance\")) {\n\n            if (stream) {\n\n                get_arg(arg, sizeof(arg), &p);\n\n                video_enc.bit_rate_tolerance = atoi(arg) * 1000;\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"VideoBitRate\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream) {\n\n                video_enc.bit_rate = atoi(arg) * 1000;\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"VideoSize\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream) {\n\n                av_parse_video_size(&video_enc.width, &video_enc.height, arg);\n\n                if ((video_enc.width % 16) != 0 ||\n\n                    (video_enc.height % 16) != 0) {\n\n                    ERROR(\"Image size must be a multiple of 16\\n\");\n\n                }\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"VideoFrameRate\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream) {\n\n                AVRational frame_rate;\n\n                if (av_parse_video_rate(&frame_rate, arg) < 0) {\n\n                    ERROR(\"Incorrect frame rate: %s\\n\", arg);\n\n                } else {\n\n                    video_enc.time_base.num = frame_rate.den;\n\n                    video_enc.time_base.den = frame_rate.num;\n\n                }\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"PixelFormat\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream) {\n\n                video_enc.pix_fmt = av_get_pix_fmt(arg);\n\n                if (video_enc.pix_fmt == AV_PIX_FMT_NONE) {\n\n                    ERROR(\"Unknown pixel format: %s\\n\", arg);\n\n                }\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"VideoGopSize\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream)\n\n                video_enc.gop_size = atoi(arg);\n\n        } else if (!av_strcasecmp(cmd, \"VideoIntraOnly\")) {\n\n            if (stream)\n\n                video_enc.gop_size = 1;\n\n        } else if (!av_strcasecmp(cmd, \"VideoHighQuality\")) {\n\n            if (stream)\n\n                video_enc.mb_decision = FF_MB_DECISION_BITS;\n\n        } else if (!av_strcasecmp(cmd, \"Video4MotionVector\")) {\n\n            if (stream) {\n\n                video_enc.mb_decision = FF_MB_DECISION_BITS; //FIXME remove\n\n                video_enc.flags |= CODEC_FLAG_4MV;\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"AVOptionVideo\") ||\n\n                   !av_strcasecmp(cmd, \"AVOptionAudio\")) {\n\n            char arg2[1024];\n\n            AVCodecContext *avctx;\n\n            int type;\n\n            get_arg(arg, sizeof(arg), &p);\n\n            get_arg(arg2, sizeof(arg2), &p);\n\n            if (!av_strcasecmp(cmd, \"AVOptionVideo\")) {\n\n                avctx = &video_enc;\n\n                type = AV_OPT_FLAG_VIDEO_PARAM;\n\n            } else {\n\n                avctx = &audio_enc;\n\n                type = AV_OPT_FLAG_AUDIO_PARAM;\n\n            }\n\n            if (ffserver_opt_default(arg, arg2, avctx, type|AV_OPT_FLAG_ENCODING_PARAM)) {\n\n                ERROR(\"Error setting %s option to %s %s\\n\", cmd, arg, arg2);\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"AVPresetVideo\") ||\n\n                   !av_strcasecmp(cmd, \"AVPresetAudio\")) {\n\n            AVCodecContext *avctx;\n\n            int type;\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (!av_strcasecmp(cmd, \"AVPresetVideo\")) {\n\n                avctx = &video_enc;\n\n                video_enc.codec_id = video_id;\n\n                type = AV_OPT_FLAG_VIDEO_PARAM;\n\n            } else {\n\n                avctx = &audio_enc;\n\n                audio_enc.codec_id = audio_id;\n\n                type = AV_OPT_FLAG_AUDIO_PARAM;\n\n            }\n\n            if (ffserver_opt_preset(arg, avctx, type|AV_OPT_FLAG_ENCODING_PARAM, &audio_id, &video_id)) {\n\n                ERROR(\"AVPreset error: %s\\n\", arg);\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"VideoTag\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if ((strlen(arg) == 4) && stream)\n\n                video_enc.codec_tag = MKTAG(arg[0], arg[1], arg[2], arg[3]);\n\n        } else if (!av_strcasecmp(cmd, \"BitExact\")) {\n\n            if (stream)\n\n                video_enc.flags |= CODEC_FLAG_BITEXACT;\n\n        } else if (!av_strcasecmp(cmd, \"DctFastint\")) {\n\n            if (stream)\n\n                video_enc.dct_algo  = FF_DCT_FASTINT;\n\n        } else if (!av_strcasecmp(cmd, \"IdctSimple\")) {\n\n            if (stream)\n\n                video_enc.idct_algo = FF_IDCT_SIMPLE;\n\n        } else if (!av_strcasecmp(cmd, \"Qscale\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream) {\n\n                video_enc.flags |= CODEC_FLAG_QSCALE;\n\n                video_enc.global_quality = FF_QP2LAMBDA * atoi(arg);\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"VideoQDiff\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream) {\n\n                video_enc.max_qdiff = atoi(arg);\n\n                if (video_enc.max_qdiff < 1 || video_enc.max_qdiff > 31) {\n\n                    ERROR(\"VideoQDiff out of range\\n\");\n\n                }\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"VideoQMax\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream) {\n\n                video_enc.qmax = atoi(arg);\n\n                if (video_enc.qmax < 1 || video_enc.qmax > 31) {\n\n                    ERROR(\"VideoQMax out of range\\n\");\n\n                }\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"VideoQMin\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream) {\n\n                video_enc.qmin = atoi(arg);\n\n                if (video_enc.qmin < 1 || video_enc.qmin > 31) {\n\n                    ERROR(\"VideoQMin out of range\\n\");\n\n                }\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"LumiMask\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream)\n\n                video_enc.lumi_masking = atof(arg);\n\n        } else if (!av_strcasecmp(cmd, \"DarkMask\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream)\n\n                video_enc.dark_masking = atof(arg);\n\n        } else if (!av_strcasecmp(cmd, \"NoVideo\")) {\n\n            video_id = AV_CODEC_ID_NONE;\n\n        } else if (!av_strcasecmp(cmd, \"NoAudio\")) {\n\n            audio_id = AV_CODEC_ID_NONE;\n\n        } else if (!av_strcasecmp(cmd, \"ACL\")) {\n\n            parse_acl_row(stream, feed, NULL, p, filename, line_num);\n\n        } else if (!av_strcasecmp(cmd, \"DynamicACL\")) {\n\n            if (stream) {\n\n                get_arg(stream->dynamic_acl, sizeof(stream->dynamic_acl), &p);\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"RTSPOption\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream) {\n\n                av_freep(&stream->rtsp_option);\n\n                stream->rtsp_option = av_strdup(arg);\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"MulticastAddress\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream) {\n\n                if (resolve_host(&stream->multicast_ip, arg) != 0) {\n\n                    ERROR(\"Invalid host/IP address: %s\\n\", arg);\n\n                }\n\n                stream->is_multicast = 1;\n\n                stream->loop = 1; /* default is looping */\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"MulticastPort\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream)\n\n                stream->multicast_port = atoi(arg);\n\n        } else if (!av_strcasecmp(cmd, \"MulticastTTL\")) {\n\n            get_arg(arg, sizeof(arg), &p);\n\n            if (stream)\n\n                stream->multicast_ttl = atoi(arg);\n\n        } else if (!av_strcasecmp(cmd, \"NoLoop\")) {\n\n            if (stream)\n\n                stream->loop = 0;\n\n        } else if (!av_strcasecmp(cmd, \"</Stream>\")) {\n\n            if (!stream) {\n\n                ERROR(\"No corresponding <Stream> for </Stream>\\n\");\n\n            } else {\n\n                if (stream->feed && stream->fmt && strcmp(stream->fmt->name, \"ffm\") != 0) {\n\n                    if (audio_id != AV_CODEC_ID_NONE) {\n\n                        audio_enc.codec_type = AVMEDIA_TYPE_AUDIO;\n\n                        audio_enc.codec_id = audio_id;\n\n                        add_codec(stream, &audio_enc);\n\n                    }\n\n                    if (video_id != AV_CODEC_ID_NONE) {\n\n                        video_enc.codec_type = AVMEDIA_TYPE_VIDEO;\n\n                        video_enc.codec_id = video_id;\n\n                        add_codec(stream, &video_enc);\n\n                    }\n\n                }\n\n                stream = NULL;\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"<Redirect\")) {\n\n            /*********************************************/\n\n            char *q;\n\n            if (stream || feed || redirect) {\n\n                ERROR(\"Already in a tag\\n\");\n\n            } else {\n\n                redirect = av_mallocz(sizeof(FFStream));\n\n                *last_stream = redirect;\n\n                last_stream = &redirect->next;\n\n\n\n                get_arg(redirect->filename, sizeof(redirect->filename), &p);\n\n                q = strrchr(redirect->filename, '>');\n\n                if (*q)\n\n                    *q = '\\0';\n\n                redirect->stream_type = STREAM_TYPE_REDIRECT;\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"URL\")) {\n\n            if (redirect)\n\n                get_arg(redirect->feed_filename, sizeof(redirect->feed_filename), &p);\n\n        } else if (!av_strcasecmp(cmd, \"</Redirect>\")) {\n\n            if (!redirect) {\n\n                ERROR(\"No corresponding <Redirect> for </Redirect>\\n\");\n\n            } else {\n\n                if (!redirect->feed_filename[0]) {\n\n                    ERROR(\"No URL found for <Redirect>\\n\");\n\n                }\n\n                redirect = NULL;\n\n            }\n\n        } else if (!av_strcasecmp(cmd, \"LoadModule\")) {\n\n            ERROR(\"Loadable modules no longer supported\\n\");\n\n        } else {\n\n            ERROR(\"Incorrect keyword: '%s'\\n\", cmd);\n\n        }\n\n    }\n\n#undef ERROR\n\n\n\n    fclose(f);\n\n    if (errors)\n\n        return -1;\n\n    else\n\n        return 0;\n\n}\n", "idx": 22129}
{"project": "FFmpeg", "commit_id": "39d607e5bbc25ad9629683702b510e865434ef21", "target": 1, "func": "static void updateMMXDitherTables(SwsContext *c, int dstY, int lumBufIndex, int chrBufIndex,\n\n                                  int lastInLumBuf, int lastInChrBuf)\n\n{\n\n    const int dstH= c->dstH;\n\n    const int flags= c->flags;\n\n    int16_t **lumPixBuf= c->lumPixBuf;\n\n    int16_t **chrUPixBuf= c->chrUPixBuf;\n\n    int16_t **chrVPixBuf= c->chrVPixBuf;\n\n    int16_t **alpPixBuf= c->alpPixBuf;\n\n    const int vLumBufSize= c->vLumBufSize;\n\n    const int vChrBufSize= c->vChrBufSize;\n\n    int16_t *vLumFilterPos= c->vLumFilterPos;\n\n    int16_t *vChrFilterPos= c->vChrFilterPos;\n\n    int16_t *vLumFilter= c->vLumFilter;\n\n    int16_t *vChrFilter= c->vChrFilter;\n\n    int32_t *lumMmxFilter= c->lumMmxFilter;\n\n    int32_t *chrMmxFilter= c->chrMmxFilter;\n\n    int32_t av_unused *alpMmxFilter= c->alpMmxFilter;\n\n    const int vLumFilterSize= c->vLumFilterSize;\n\n    const int vChrFilterSize= c->vChrFilterSize;\n\n    const int chrDstY= dstY>>c->chrDstVSubSample;\n\n    const int firstLumSrcY= vLumFilterPos[dstY]; //First line needed as input\n\n    const int firstChrSrcY= vChrFilterPos[chrDstY]; //First line needed as input\n\n\n\n    c->blueDither= ff_dither8[dstY&1];\n\n    if (c->dstFormat == PIX_FMT_RGB555 || c->dstFormat == PIX_FMT_BGR555)\n\n        c->greenDither= ff_dither8[dstY&1];\n\n    else\n\n        c->greenDither= ff_dither4[dstY&1];\n\n    c->redDither= ff_dither8[(dstY+1)&1];\n\n    if (dstY < dstH - 2) {\n\n        const int16_t **lumSrcPtr= (const int16_t **) lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n        const int16_t **chrUSrcPtr= (const int16_t **) chrUPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n        const int16_t **chrVSrcPtr= (const int16_t **) chrVPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n        const int16_t **alpSrcPtr= (CONFIG_SWSCALE_ALPHA && alpPixBuf) ? (const int16_t **) alpPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize : NULL;\n\n        int i;\n\n        if (flags & SWS_ACCURATE_RND) {\n\n            int s= APCK_SIZE / 8;\n\n            for (i=0; i<vLumFilterSize; i+=2) {\n\n                *(const void**)&lumMmxFilter[s*i              ]= lumSrcPtr[i  ];\n\n                *(const void**)&lumMmxFilter[s*i+APCK_PTR2/4  ]= lumSrcPtr[i+(vLumFilterSize>1)];\n\n                lumMmxFilter[s*i+APCK_COEF/4  ]=\n\n                lumMmxFilter[s*i+APCK_COEF/4+1]= vLumFilter[dstY*vLumFilterSize + i    ]\n\n                           + (vLumFilterSize>1 ? vLumFilter[dstY*vLumFilterSize + i + 1]<<16 : 0);\n\n                if (CONFIG_SWSCALE_ALPHA && alpPixBuf) {\n\n                    *(const void**)&alpMmxFilter[s*i              ]= alpSrcPtr[i  ];\n\n                    *(const void**)&alpMmxFilter[s*i+APCK_PTR2/4  ]= alpSrcPtr[i+(vLumFilterSize>1)];\n\n                    alpMmxFilter[s*i+APCK_COEF/4  ]=\n\n                    alpMmxFilter[s*i+APCK_COEF/4+1]= lumMmxFilter[s*i+APCK_COEF/4  ];\n\n                }\n\n            }\n\n            for (i=0; i<vChrFilterSize; i+=2) {\n\n                *(const void**)&chrMmxFilter[s*i              ]= chrUSrcPtr[i  ];\n\n                *(const void**)&chrMmxFilter[s*i+APCK_PTR2/4  ]= chrUSrcPtr[i+(vChrFilterSize>1)];\n\n                chrMmxFilter[s*i+APCK_COEF/4  ]=\n\n                chrMmxFilter[s*i+APCK_COEF/4+1]= vChrFilter[chrDstY*vChrFilterSize + i    ]\n\n                           + (vChrFilterSize>1 ? vChrFilter[chrDstY*vChrFilterSize + i + 1]<<16 : 0);\n\n            }\n\n        } else {\n\n            for (i=0; i<vLumFilterSize; i++) {\n\n                *(const void**)&lumMmxFilter[4*i+0]= lumSrcPtr[i];\n\n                lumMmxFilter[4*i+2]=\n\n                lumMmxFilter[4*i+3]=\n\n                    ((uint16_t)vLumFilter[dstY*vLumFilterSize + i])*0x10001;\n\n                if (CONFIG_SWSCALE_ALPHA && alpPixBuf) {\n\n                    *(const void**)&alpMmxFilter[4*i+0]= alpSrcPtr[i];\n\n                    alpMmxFilter[4*i+2]=\n\n                    alpMmxFilter[4*i+3]= lumMmxFilter[4*i+2];\n\n                }\n\n            }\n\n            for (i=0; i<vChrFilterSize; i++) {\n\n                *(const void**)&chrMmxFilter[4*i+0]= chrUSrcPtr[i];\n\n                chrMmxFilter[4*i+2]=\n\n                chrMmxFilter[4*i+3]=\n\n                    ((uint16_t)vChrFilter[chrDstY*vChrFilterSize + i])*0x10001;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 22130}
{"project": "FFmpeg", "commit_id": "08b098169be079c4f124a351fda6764fbcd10e79", "target": 1, "func": "static inline int decode_alpha_block(const SHQContext *s, GetBitContext *gb, uint8_t last_alpha[16], uint8_t *dest, int linesize)\n\n{\n\n    uint8_t block[128];\n\n    int i = 0, x, y;\n\n\n\n    memset(block, 0, sizeof(block));\n\n\n\n    {\n\n        OPEN_READER(re, gb);\n\n\n\n        for ( ;; ) {\n\n            int run, level;\n\n\n\n            UPDATE_CACHE_LE(re, gb);\n\n            GET_VLC(run, re, gb, ff_dc_alpha_run_vlc_le.table, ALPHA_VLC_BITS, 2);\n\n\n\n            if (run == 128) break;\n\n            i += run;\n\n            if (i >= 128)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            UPDATE_CACHE_LE(re, gb);\n\n            GET_VLC(level, re, gb, ff_dc_alpha_level_vlc_le.table, ALPHA_VLC_BITS, 2);\n\n            block[i++] = level;\n\n        }\n\n\n\n        CLOSE_READER(re, gb);\n\n    }\n\n\n\n    for (y = 0; y < 8; y++) {\n\n        for (x = 0; x < 16; x++) {\n\n            last_alpha[x] -= block[y * 16 + x];\n\n        }\n\n        memcpy(dest, last_alpha, 16);\n\n        dest += linesize;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22131}
{"project": "FFmpeg", "commit_id": "eea064aea610ea41b5bda0b62dac56be536af9aa", "target": 0, "func": "static int dvbsub_read_4bit_string(uint8_t *destbuf, int dbuf_len,\n\n                                   const uint8_t **srcbuf, int buf_size,\n\n                                   int non_mod, uint8_t *map_table)\n\n{\n\n    GetBitContext gb;\n\n\n\n    int bits;\n\n    int run_length;\n\n    int pixels_read = 0;\n\n\n\n    init_get_bits(&gb, *srcbuf, buf_size << 3);\n\n\n\n    while (get_bits_count(&gb) < buf_size << 3 && pixels_read < dbuf_len) {\n\n        bits = get_bits(&gb, 4);\n\n\n\n        if (bits) {\n\n            if (non_mod != 1 || bits != 1) {\n\n                if (map_table)\n\n                    *destbuf++ = map_table[bits];\n\n                else\n\n                    *destbuf++ = bits;\n\n            }\n\n            pixels_read++;\n\n        } else {\n\n            bits = get_bits1(&gb);\n\n            if (bits == 0) {\n\n                run_length = get_bits(&gb, 3);\n\n\n\n                if (run_length == 0) {\n\n                    (*srcbuf) += (get_bits_count(&gb) + 7) >> 3;\n\n                    return pixels_read;\n\n                }\n\n\n\n                run_length += 2;\n\n\n\n                if (map_table)\n\n                    bits = map_table[0];\n\n                else\n\n                    bits = 0;\n\n\n\n                while (run_length-- > 0 && pixels_read < dbuf_len) {\n\n                    *destbuf++ = bits;\n\n                    pixels_read++;\n\n                }\n\n            } else {\n\n                bits = get_bits1(&gb);\n\n                if (bits == 0) {\n\n                    run_length = get_bits(&gb, 2) + 4;\n\n                    bits = get_bits(&gb, 4);\n\n\n\n                    if (non_mod == 1 && bits == 1)\n\n                        pixels_read += run_length;\n\n                    else {\n\n                        if (map_table)\n\n                            bits = map_table[bits];\n\n                        while (run_length-- > 0 && pixels_read < dbuf_len) {\n\n                            *destbuf++ = bits;\n\n                            pixels_read++;\n\n                        }\n\n                    }\n\n                } else {\n\n                    bits = get_bits(&gb, 2);\n\n                    if (bits == 2) {\n\n                        run_length = get_bits(&gb, 4) + 9;\n\n                        bits = get_bits(&gb, 4);\n\n\n\n                        if (non_mod == 1 && bits == 1)\n\n                            pixels_read += run_length;\n\n                        else {\n\n                            if (map_table)\n\n                                bits = map_table[bits];\n\n                            while (run_length-- > 0 && pixels_read < dbuf_len) {\n\n                                *destbuf++ = bits;\n\n                                pixels_read++;\n\n                            }\n\n                        }\n\n                    } else if (bits == 3) {\n\n                        run_length = get_bits(&gb, 8) + 25;\n\n                        bits = get_bits(&gb, 4);\n\n\n\n                        if (non_mod == 1 && bits == 1)\n\n                            pixels_read += run_length;\n\n                        else {\n\n                            if (map_table)\n\n                                bits = map_table[bits];\n\n                            while (run_length-- > 0 && pixels_read < dbuf_len) {\n\n                                *destbuf++ = bits;\n\n                                pixels_read++;\n\n                            }\n\n                        }\n\n                    } else if (bits == 1) {\n\n                        pixels_read += 2;\n\n                        if (map_table)\n\n                            bits = map_table[0];\n\n                        else\n\n                            bits = 0;\n\n                        if (pixels_read <= dbuf_len) {\n\n                            *destbuf++ = bits;\n\n                            *destbuf++ = bits;\n\n                        }\n\n                    } else {\n\n                        if (map_table)\n\n                            bits = map_table[0];\n\n                        else\n\n                            bits = 0;\n\n                        *destbuf++ = bits;\n\n                        pixels_read ++;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    if (get_bits(&gb, 8))\n\n        av_log(0, AV_LOG_ERROR, \"DVBSub error: line overflow\\n\");\n\n\n\n    (*srcbuf) += (get_bits_count(&gb) + 7) >> 3;\n\n\n\n    return pixels_read;\n\n}\n", "idx": 22133}
{"project": "FFmpeg", "commit_id": "3b9dd906d18f4cd801ceedd20d800a7e53074be9", "target": 0, "func": "static void copy_block(uint16_t *pdest, uint16_t *psrc, int block_size, int pitch)\n\n{\n\n    int y;\n\n\n\n    for (y = 0; y != block_size; y++, pdest += pitch, psrc += pitch)\n\n        memcpy(pdest, psrc, block_size * sizeof(pdest[0]));\n\n}\n", "idx": 22134}
{"project": "FFmpeg", "commit_id": "e706e2e775730db5dfa9103628cd70704dd13cef", "target": 0, "func": "static int ffm2_read_header(AVFormatContext *s)\n\n{\n\n    FFMContext *ffm = s->priv_data;\n\n    AVStream *st;\n\n    AVIOContext *pb = s->pb;\n\n    AVCodecContext *codec, *dummy_codec = NULL;\n\n    AVCodecParameters *codecpar;\n\n    const AVCodecDescriptor *codec_desc;\n\n    int ret;\n\n    int f_main = 0, f_cprv = -1, f_stvi = -1, f_stau = -1;\n\n    AVCodec *enc;\n\n    char *buffer;\n\n\n\n    ffm->packet_size = avio_rb32(pb);\n\n    if (ffm->packet_size != FFM_PACKET_SIZE) {\n\n        av_log(s, AV_LOG_ERROR, \"Invalid packet size %d, expected size was %d\\n\",\n\n               ffm->packet_size, FFM_PACKET_SIZE);\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto fail;\n\n    }\n\n\n\n    ffm->write_index = avio_rb64(pb);\n\n    /* get also filesize */\n\n    if (pb->seekable) {\n\n        ffm->file_size = avio_size(pb);\n\n        if (ffm->write_index && 0)\n\n            adjust_write_index(s);\n\n    } else {\n\n        ffm->file_size = (UINT64_C(1) << 63) - 1;\n\n    }\n\n    dummy_codec = avcodec_alloc_context3(NULL);\n\n\n\n    while(!avio_feof(pb)) {\n\n        unsigned id = avio_rb32(pb);\n\n        unsigned size = avio_rb32(pb);\n\n        int64_t next = avio_tell(pb) + size;\n\n        char rc_eq_buf[128];\n\n\n\n        if(!id)\n\n            break;\n\n\n\n        switch(id) {\n\n        case MKBETAG('M', 'A', 'I', 'N'):\n\n            if (f_main++) {\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            avio_rb32(pb); /* nb_streams */\n\n            avio_rb32(pb); /* total bitrate */\n\n            break;\n\n        case MKBETAG('C', 'O', 'M', 'M'):\n\n            f_cprv = f_stvi = f_stau = 0;\n\n            st = avformat_new_stream(s, NULL);\n\n            if (!st) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto fail;\n\n            }\n\n\n\n            avpriv_set_pts_info(st, 64, 1, 1000000);\n\n\n\n            codec = st->codec;\n\n            codecpar = st->codecpar;\n\n            /* generic info */\n\n            codecpar->codec_id = avio_rb32(pb);\n\n            codec_desc = avcodec_descriptor_get(codecpar->codec_id);\n\n            if (!codec_desc) {\n\n                av_log(s, AV_LOG_ERROR, \"Invalid codec id: %d\\n\", codecpar->codec_id);\n\n                codecpar->codec_id = AV_CODEC_ID_NONE;\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            codecpar->codec_type = avio_r8(pb);\n\n            if (codecpar->codec_type != codec_desc->type) {\n\n                av_log(s, AV_LOG_ERROR, \"Codec type mismatch: expected %d, found %d\\n\",\n\n                       codec_desc->type, codecpar->codec_type);\n\n                codecpar->codec_id = AV_CODEC_ID_NONE;\n\n                codecpar->codec_type = AVMEDIA_TYPE_UNKNOWN;\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            codecpar->bit_rate = avio_rb32(pb);\n\n            if (codecpar->bit_rate < 0) {\n\n                av_log(codec, AV_LOG_ERROR, \"Invalid bit rate %\"PRId64\"\\n\", codecpar->bit_rate);\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            codec->flags = avio_rb32(pb);\n\n            codec->flags2 = avio_rb32(pb);\n\n            codec->debug = avio_rb32(pb);\n\n            if (codec->flags & AV_CODEC_FLAG_GLOBAL_HEADER) {\n\n                int size = avio_rb32(pb);\n\n                if (size < 0 || size >= FF_MAX_EXTRADATA_SIZE) {\n\n                    av_log(s, AV_LOG_ERROR, \"Invalid extradata size %d\\n\", size);\n\n                    ret = AVERROR_INVALIDDATA;\n\n                    goto fail;\n\n                }\n\n                codecpar->extradata = av_mallocz(size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n                if (!codecpar->extradata)\n\n                    return AVERROR(ENOMEM);\n\n                codecpar->extradata_size = size;\n\n                avio_read(pb, codecpar->extradata, size);\n\n            }\n\n            break;\n\n        case MKBETAG('S', 'T', 'V', 'I'):\n\n            if (f_stvi++) {\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            codec->time_base.num = avio_rb32(pb);\n\n            codec->time_base.den = avio_rb32(pb);\n\n            if (codec->time_base.num <= 0 || codec->time_base.den <= 0) {\n\n                av_log(s, AV_LOG_ERROR, \"Invalid time base %d/%d\\n\",\n\n                       codec->time_base.num, codec->time_base.den);\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            codecpar->width = avio_rb16(pb);\n\n            codecpar->height = avio_rb16(pb);\n\n            ret = av_image_check_size(codecpar->width, codecpar->height, 0, s);\n\n            if (ret < 0)\n\n                goto fail;\n\n            avio_rb16(pb); // gop_size\n\n            codecpar->format = avio_rb32(pb);\n\n            if (!av_pix_fmt_desc_get(codecpar->format)) {\n\n                av_log(s, AV_LOG_ERROR, \"Invalid pix fmt id: %d\\n\", codecpar->format);\n\n                codecpar->format = AV_PIX_FMT_NONE;\n\n                goto fail;\n\n            }\n\n            avio_r8(pb);   // qmin\n\n            avio_r8(pb);   // qmax\n\n            avio_r8(pb);   // max_qdiff\n\n            avio_rb16(pb); // qcompress / 10000.0\n\n            avio_rb16(pb); // qblur / 10000.0\n\n            avio_rb32(pb); // bit_rate_tolerance\n\n            avio_get_str(pb, INT_MAX, rc_eq_buf, sizeof(rc_eq_buf));\n\n\n\n            avio_rb32(pb); // rc_max_rate\n\n            avio_rb32(pb); // rc_min_rate\n\n            avio_rb32(pb); // rc_buffer_size\n\n            avio_rb64(pb); // i_quant_factor\n\n            avio_rb64(pb); // b_quant_factor\n\n            avio_rb64(pb); // i_quant_offset\n\n            avio_rb64(pb); // b_quant_offset\n\n            avio_rb32(pb); // dct_algo\n\n            avio_rb32(pb); // strict_std_compliance\n\n            avio_rb32(pb); // max_b_frames\n\n            avio_rb32(pb); // mpeg_quant\n\n            avio_rb32(pb); // intra_dc_precision\n\n            avio_rb32(pb); // me_method\n\n            avio_rb32(pb); // mb_decision\n\n            avio_rb32(pb); // nsse_weight\n\n            avio_rb32(pb); // frame_skip_cmp\n\n            avio_rb64(pb); // rc_buffer_aggressivity\n\n            codecpar->codec_tag = avio_rb32(pb);\n\n            avio_r8(pb);   // thread_count\n\n            avio_rb32(pb); // coder_type\n\n            avio_rb32(pb); // me_cmp\n\n            avio_rb32(pb); // me_subpel_quality\n\n            avio_rb32(pb); // me_range\n\n            avio_rb32(pb); // keyint_min\n\n            avio_rb32(pb); // scenechange_threshold\n\n            avio_rb32(pb); // b_frame_strategy\n\n            avio_rb64(pb); // qcompress\n\n            avio_rb64(pb); // qblur\n\n            avio_rb32(pb); // max_qdiff\n\n            avio_rb32(pb); // refs\n\n            break;\n\n        case MKBETAG('S', 'T', 'A', 'U'):\n\n            if (f_stau++) {\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            codecpar->sample_rate = avio_rb32(pb);\n\n            VALIDATE_PARAMETER(sample_rate, \"sample rate\",        codecpar->sample_rate < 0)\n\n            codecpar->channels = avio_rl16(pb);\n\n            VALIDATE_PARAMETER(channels,    \"number of channels\", codecpar->channels < 0)\n\n            codecpar->frame_size = avio_rl16(pb);\n\n            VALIDATE_PARAMETER(frame_size,  \"frame size\",         codecpar->frame_size < 0)\n\n            break;\n\n        case MKBETAG('C', 'P', 'R', 'V'):\n\n            if (f_cprv++) {\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            enc = avcodec_find_encoder(codecpar->codec_id);\n\n            if (enc && enc->priv_data_size && enc->priv_class) {\n\n                buffer = av_malloc(size + 1);\n\n                if (!buffer) {\n\n                    ret = AVERROR(ENOMEM);\n\n                    goto fail;\n\n                }\n\n                avio_get_str(pb, size, buffer, size + 1);\n\n                if ((ret = ffm_append_recommended_configuration(st, &buffer)) < 0)\n\n                    goto fail;\n\n            }\n\n            break;\n\n        case MKBETAG('S', '2', 'V', 'I'):\n\n            if (f_stvi++ || !size) {\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            buffer = av_malloc(size);\n\n            if (!buffer) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto fail;\n\n            }\n\n            avio_get_str(pb, INT_MAX, buffer, size);\n\n            // The lack of AVOptions support in AVCodecParameters makes this back and forth copying needed\n\n            avcodec_parameters_to_context(dummy_codec, codecpar);\n\n            av_set_options_string(dummy_codec, buffer, \"=\", \",\");\n\n            avcodec_parameters_from_context(codecpar, dummy_codec);\n\n            if ((ret = ffm_append_recommended_configuration(st, &buffer)) < 0)\n\n                goto fail;\n\n            break;\n\n        case MKBETAG('S', '2', 'A', 'U'):\n\n            if (f_stau++ || !size) {\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            buffer = av_malloc(size);\n\n            if (!buffer) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto fail;\n\n            }\n\n            avio_get_str(pb, INT_MAX, buffer, size);\n\n            // The lack of AVOptions support in AVCodecParameters makes this back and forth copying needed\n\n            avcodec_parameters_to_context(dummy_codec, codecpar);\n\n            av_set_options_string(dummy_codec, buffer, \"=\", \",\");\n\n            avcodec_parameters_from_context(codecpar, dummy_codec);\n\n            if ((ret = ffm_append_recommended_configuration(st, &buffer)) < 0)\n\n                goto fail;\n\n            break;\n\n        }\n\n        avio_seek(pb, next, SEEK_SET);\n\n    }\n\n\n\n    /* get until end of block reached */\n\n    while ((avio_tell(pb) % ffm->packet_size) != 0 && !pb->eof_reached)\n\n        avio_r8(pb);\n\n\n\n    /* init packet demux */\n\n    ffm->packet_ptr = ffm->packet;\n\n    ffm->packet_end = ffm->packet;\n\n    ffm->frame_offset = 0;\n\n    ffm->dts = 0;\n\n    ffm->read_state = READ_HEADER;\n\n    ffm->first_packet = 1;\n\n    avcodec_free_context(&dummy_codec);\n\n    return 0;\n\n fail:\n\n    avcodec_free_context(&dummy_codec);\n\n    return ret;\n\n}\n", "idx": 22135}
{"project": "FFmpeg", "commit_id": "f1ffb01ee9fd3a15c395c3cf6ff362ac5cd668d0", "target": 0, "func": "static double get_audio_clock(VideoState *is)\n\n{\n\n    double pts;\n\n    int hw_buf_size, bytes_per_sec;\n\n    pts = is->audio_clock;\n\n    hw_buf_size = audio_write_get_buf_size(is);\n\n    bytes_per_sec = 0;\n\n    if (is->audio_st) {\n\n        bytes_per_sec = is->audio_st->codec->sample_rate *\n\n                        2 * is->audio_st->codec->channels;\n\n    }\n\n    if (bytes_per_sec)\n\n        pts -= (double)hw_buf_size / bytes_per_sec;\n\n    return pts;\n\n}\n", "idx": 22136}
{"project": "FFmpeg", "commit_id": "de1824e970d448a84bedce4936c301c322baa714", "target": 0, "func": "static int mpeg_decode_frame(AVCodecContext *avctx,\n\n                             void *data, int *data_size,\n\n                             AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    Mpeg1Context *s = avctx->priv_data;\n\n    AVFrame *picture = data;\n\n    MpegEncContext *s2 = &s->mpeg_enc_ctx;\n\n    av_dlog(avctx, \"fill_buffer\\n\");\n\n\n\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == SEQ_END_CODE)) {\n\n        /* special case for last picture */\n\n        if (s2->low_delay == 0 && s2->next_picture_ptr) {\n\n            *picture = s2->next_picture_ptr->f;\n\n            s2->next_picture_ptr = NULL;\n\n\n\n            *data_size = sizeof(AVFrame);\n\n        }\n\n        return buf_size;\n\n    }\n\n\n\n    if (s2->flags & CODEC_FLAG_TRUNCATED) {\n\n        int next = ff_mpeg1_find_frame_end(&s2->parse_context, buf, buf_size, NULL);\n\n\n\n        if (ff_combine_frame(&s2->parse_context, next, (const uint8_t **)&buf, &buf_size) < 0)\n\n            return buf_size;\n\n    }\n\n\n\n    s2->codec_tag = avpriv_toupper4(avctx->codec_tag);\n\n    if (s->mpeg_enc_ctx_allocated == 0 && (   s2->codec_tag == AV_RL32(\"VCR2\")\n\n                                           || s2->codec_tag == AV_RL32(\"BW10\")\n\n                                          ))\n\n        vcr2_init_sequence(avctx);\n\n\n\n    s->slice_count = 0;\n\n\n\n    if (avctx->extradata && !avctx->frame_number) {\n\n        int ret = decode_chunks(avctx, picture, data_size, avctx->extradata, avctx->extradata_size);\n\n        if(*data_size) {\n\n            av_log(avctx, AV_LOG_ERROR, \"picture in extradata\\n\");\n\n            *data_size = 0;\n\n        }\n\n        if (ret < 0 && (avctx->err_recognition & AV_EF_EXPLODE))\n\n            return ret;\n\n    }\n\n\n\n    return decode_chunks(avctx, picture, data_size, buf, buf_size);\n\n}\n", "idx": 22137}
{"project": "FFmpeg", "commit_id": "7f4ec4364bc4a73036660c1c6a3c4801db524e9e", "target": 0, "func": "uint8_t *ff_stream_new_side_data(AVStream *st, enum AVPacketSideDataType type,\n\n                                 int size)\n\n{\n\n    AVPacketSideData *sd, *tmp;\n\n    int i;\n\n    uint8_t *data = av_malloc(size);\n\n\n\n    if (!data)\n\n        return NULL;\n\n\n\n    for (i = 0; i < st->nb_side_data; i++) {\n\n        sd = &st->side_data[i];\n\n\n\n        if (sd->type == type) {\n\n            av_freep(&sd->data);\n\n            sd->data = data;\n\n            sd->size = size;\n\n            return sd->data;\n\n        }\n\n    }\n\n\n\n    tmp = av_realloc_array(st->side_data, st->nb_side_data + 1, sizeof(*tmp));\n\n    if (!tmp) {\n\n        av_freep(&data);\n\n        return NULL;\n\n    }\n\n\n\n    st->side_data = tmp;\n\n    st->nb_side_data++;\n\n\n\n    sd = &st->side_data[st->nb_side_data - 1];\n\n    sd->type = type;\n\n    sd->data = data;\n\n    sd->size = size;\n\n    return data;\n\n}\n", "idx": 22138}
{"project": "FFmpeg", "commit_id": "ac47e014bbaf5163871a8beb7522015e0bc27615", "target": 0, "func": "static int adts_write_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    ADTSContext *adts = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    uint8_t buf[ADTS_HEADER_SIZE];\n\n\n\n    if (!pkt->size)\n\n        return 0;\n\n    if (adts->write_adts) {\n\n        ff_adts_write_frame_header(adts, buf, pkt->size, adts->pce_size);\n\n        avio_write(pb, buf, ADTS_HEADER_SIZE);\n\n        if (adts->pce_size) {\n\n            avio_write(pb, adts->pce_data, adts->pce_size);\n\n            adts->pce_size = 0;\n\n        }\n\n    }\n\n    avio_write(pb, pkt->data, pkt->size);\n\n    avio_flush(pb);\n\n\n\n    return 0;\n\n}\n", "idx": 22148}
{"project": "FFmpeg", "commit_id": "ce2f9fdb0a92956aedfa2c564d1374a2f1eebfbd", "target": 0, "func": "static int parse_optional_info(DCACoreDecoder *s)\n\n{\n\n    DCAContext *dca = s->avctx->priv_data;\n\n    int ret = -1;\n\n\n\n    // Time code stamp\n\n    if (s->ts_present)\n\n        skip_bits_long(&s->gb, 32);\n\n\n\n    // Auxiliary data\n\n    if (s->aux_present && (ret = parse_aux_data(s)) < 0\n\n        && (s->avctx->err_recognition & AV_EF_EXPLODE))\n\n        return ret;\n\n\n\n    if (ret < 0)\n\n        s->prim_dmix_embedded = 0;\n\n\n\n    // Core extensions\n\n    if (s->ext_audio_present && !dca->core_only) {\n\n        int sync_pos = FFMIN(s->frame_size / 4, s->gb.size_in_bits / 32) - 1;\n\n        int last_pos = get_bits_count(&s->gb) / 32;\n\n        int size, dist;\n\n\n\n        // Search for extension sync words aligned on 4-byte boundary. Search\n\n        // must be done backwards from the end of core frame to work around\n\n        // sync word aliasing issues.\n\n        switch (s->ext_audio_type) {\n\n        case EXT_AUDIO_XCH:\n\n            if (dca->request_channel_layout)\n\n                break;\n\n\n\n            // The distance between XCH sync word and end of the core frame\n\n            // must be equal to XCH frame size. Off by one error is allowed for\n\n            // compatibility with legacy bitstreams. Minimum XCH frame size is\n\n            // 96 bytes. AMODE and PCHS are further checked to reduce\n\n            // probability of alias sync detection.\n\n            for (; sync_pos >= last_pos; sync_pos--) {\n\n                if (AV_RB32(s->gb.buffer + sync_pos * 4) == DCA_SYNCWORD_XCH) {\n\n                    s->gb.index = (sync_pos + 1) * 32;\n\n                    size = get_bits(&s->gb, 10) + 1;\n\n                    dist = s->frame_size - sync_pos * 4;\n\n                    if (size >= 96\n\n                        && (size == dist || size - 1 == dist)\n\n                        && get_bits(&s->gb, 7) == 0x08) {\n\n                        s->xch_pos = get_bits_count(&s->gb);\n\n                        break;\n\n                    }\n\n                }\n\n            }\n\n\n\n            if (s->avctx->err_recognition & AV_EF_EXPLODE) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"XCH sync word not found\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            break;\n\n\n\n        case EXT_AUDIO_X96:\n\n            // The distance between X96 sync word and end of the core frame\n\n            // must be equal to X96 frame size. Minimum X96 frame size is 96\n\n            // bytes.\n\n            for (; sync_pos >= last_pos; sync_pos--) {\n\n                if (AV_RB32(s->gb.buffer + sync_pos * 4) == DCA_SYNCWORD_X96) {\n\n                    s->gb.index = (sync_pos + 1) * 32;\n\n                    size = get_bits(&s->gb, 12) + 1;\n\n                    dist = s->frame_size - sync_pos * 4;\n\n                    if (size >= 96 && size == dist) {\n\n                        s->x96_pos = get_bits_count(&s->gb);\n\n                        break;\n\n                    }\n\n                }\n\n            }\n\n\n\n            if (s->avctx->err_recognition & AV_EF_EXPLODE) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"X96 sync word not found\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            break;\n\n\n\n        case EXT_AUDIO_XXCH:\n\n            if (dca->request_channel_layout)\n\n                break;\n\n\n\n            // XXCH frame header CRC must be valid. Minimum XXCH frame header\n\n            // size is 11 bytes.\n\n            for (; sync_pos >= last_pos; sync_pos--) {\n\n                if (AV_RB32(s->gb.buffer + sync_pos * 4) == DCA_SYNCWORD_XXCH) {\n\n                    s->gb.index = (sync_pos + 1) * 32;\n\n                    size = get_bits(&s->gb, 6) + 1;\n\n                    if (size >= 11 &&\n\n                        !ff_dca_check_crc(&s->gb, (sync_pos + 1) * 32,\n\n                                          sync_pos * 32 + size * 8)) {\n\n                        s->xxch_pos = sync_pos * 32;\n\n                        break;\n\n                    }\n\n                }\n\n            }\n\n\n\n            if (s->avctx->err_recognition & AV_EF_EXPLODE) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"XXCH sync word not found\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            break;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22159}
{"project": "FFmpeg", "commit_id": "369cb092ecbbaff20bb0a2a1d60536c3bc04a8f0", "target": 1, "func": "static void generate_silence(uint8_t* buf, enum AVSampleFormat sample_fmt, size_t size)\n\n{\n\n    int fill_char = 0x00;\n\n    if (sample_fmt == AV_SAMPLE_FMT_U8)\n\n        fill_char = 0x80;\n\n    memset(buf, fill_char, size);\n\n}\n", "idx": 22164}
{"project": "FFmpeg", "commit_id": "a7e7417c41c2c85495b74074b96989c5d68bae22", "target": 0, "func": "void ff_ac3_bit_alloc_calc_psd(int8_t *exp, int start, int end, int16_t *psd,\n\n                               int16_t *band_psd)\n\n{\n\n    int bin, j, k, end1, v;\n\n\n\n    /* exponent mapping to PSD */\n\n    for(bin=start;bin<end;bin++) {\n\n        psd[bin]=(3072 - (exp[bin] << 7));\n\n    }\n\n\n\n    /* PSD integration */\n\n    j=start;\n\n    k=bin_to_band_tab[start];\n\n    do {\n\n        v = psd[j++];\n\n        end1 = FFMIN(band_start_tab[k+1], end);\n\n        for (; j < end1; j++) {\n\n            /* logadd */\n\n            int adr = FFMIN(FFABS(v - psd[j]) >> 1, 255);\n\n            v = FFMAX(v, psd[j]) + ff_ac3_log_add_tab[adr];\n\n        }\n\n        band_psd[k]=v;\n\n        k++;\n\n    } while (end > band_start_tab[k]);\n\n}\n", "idx": 22171}
{"project": "FFmpeg", "commit_id": "d8edf1b515ae9fbcea2103305241d130c16e1003", "target": 0, "func": "static void rv40_h_loop_filter(uint8_t *src, int stride, int dmode,\n\n                               int lim_q1, int lim_p1,\n\n                               int alpha, int beta, int beta2, int chroma, int edge){\n\n    rv40_adaptive_loop_filter(src, stride, 1, dmode, lim_q1, lim_p1,\n\n                              alpha, beta, beta2, chroma, edge);\n\n}\n", "idx": 22182}
{"project": "FFmpeg", "commit_id": "d629f3edaa39b48ac92ac5e5ae8440e35805b792", "target": 0, "func": "static int mono_decode(COOKContext *q, COOKSubpacket *p, float *mlt_buffer)\n\n{\n\n    int category_index[128];\n\n    int quant_index_table[102];\n\n    int category[128];\n\n    int ret;\n\n\n\n    memset(&category,       0, sizeof(category));\n\n    memset(&category_index, 0, sizeof(category_index));\n\n\n\n    if ((ret = decode_envelope(q, p, quant_index_table)) < 0)\n\n        return ret;\n\n    q->num_vectors = get_bits(&q->gb, p->log2_numvector_size);\n\n    categorize(q, p, quant_index_table, category, category_index);\n\n    expand_category(q, category, category_index);\n\n    decode_vectors(q, p, category, quant_index_table, mlt_buffer);\n\n\n\n    return 0;\n\n}\n", "idx": 22193}
{"project": "FFmpeg", "commit_id": "fea471347218be0b8d1313b8f14ea9512e555d76", "target": 0, "func": "static int cuvid_test_dummy_decoder(AVCodecContext *avctx,\n\n                                    const CUVIDPARSERPARAMS *cuparseinfo,\n\n                                    int probed_width,\n\n                                    int probed_height)\n\n{\n\n    CuvidContext *ctx = avctx->priv_data;\n\n    CUVIDDECODECREATEINFO cuinfo;\n\n    CUvideodecoder cudec = 0;\n\n    int ret = 0;\n\n\n\n    memset(&cuinfo, 0, sizeof(cuinfo));\n\n\n\n    cuinfo.CodecType = cuparseinfo->CodecType;\n\n    cuinfo.ChromaFormat = cudaVideoChromaFormat_420;\n\n    cuinfo.OutputFormat = cudaVideoSurfaceFormat_NV12;\n\n\n\n    cuinfo.ulWidth = probed_width;\n\n    cuinfo.ulHeight = probed_height;\n\n    cuinfo.ulTargetWidth = cuinfo.ulWidth;\n\n    cuinfo.ulTargetHeight = cuinfo.ulHeight;\n\n\n\n    cuinfo.target_rect.left = 0;\n\n    cuinfo.target_rect.top = 0;\n\n    cuinfo.target_rect.right = cuinfo.ulWidth;\n\n    cuinfo.target_rect.bottom = cuinfo.ulHeight;\n\n\n\n    cuinfo.ulNumDecodeSurfaces = ctx->nb_surfaces;\n\n    cuinfo.ulNumOutputSurfaces = 1;\n\n    cuinfo.ulCreationFlags = cudaVideoCreate_PreferCUVID;\n\n    cuinfo.bitDepthMinus8 = 0;\n\n\n\n    cuinfo.DeinterlaceMode = cudaVideoDeinterlaceMode_Weave;\n\n\n\n    ret = CHECK_CU(ctx->cvdl->cuvidCreateDecoder(&cudec, &cuinfo));\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    ret = CHECK_CU(ctx->cvdl->cuvidDestroyDecoder(cudec));\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    return 0;\n\n}\n", "idx": 22195}
{"project": "FFmpeg", "commit_id": "091bc6ca8c643bfece2c70ff2404c7b31574e1f1", "target": 0, "func": "static void mm_decode_inter(MmContext * s, int half_horiz, int half_vert, const uint8_t *buf, int buf_size)\n\n{\n\n    const int data_ptr = 2 + AV_RL16(&buf[0]);\n\n    int d, r, y;\n\n    d = data_ptr; r = 2; y = 0;\n\n\n\n    while(r < data_ptr) {\n\n        int i, j;\n\n        int length = buf[r] & 0x7f;\n\n        int x = buf[r+1] + ((buf[r] & 0x80) << 1);\n\n        r += 2;\n\n\n\n        if (length==0) {\n\n            y += x;\n\n            continue;\n\n        }\n\n\n\n        for(i=0; i<length; i++) {\n\n            for(j=0; j<8; j++) {\n\n                int replace = (buf[r+i] >> (7-j)) & 1;\n\n                if (replace) {\n\n                    int color = buf[d];\n\n                    s->frame.data[0][y*s->frame.linesize[0] + x] = color;\n\n                    if (half_horiz)\n\n                        s->frame.data[0][y*s->frame.linesize[0] + x + 1] = color;\n\n                    if (half_vert) {\n\n                        s->frame.data[0][(y+1)*s->frame.linesize[0] + x] = color;\n\n                        if (half_horiz)\n\n                            s->frame.data[0][(y+1)*s->frame.linesize[0] + x + 1] = color;\n\n                    }\n\n                    d++;\n\n                }\n\n                x += half_horiz ? 2 : 1;\n\n            }\n\n        }\n\n\n\n        r += length;\n\n        y += half_vert ? 2 : 1;\n\n    }\n\n}\n", "idx": 22206}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(vu9_to_vu12)(const uint8_t *src1, const uint8_t *src2,\n\n                                       uint8_t *dst1, uint8_t *dst2,\n\n                                       long width, long height,\n\n                                       long srcStride1, long srcStride2,\n\n                                       long dstStride1, long dstStride2)\n\n{\n\n    x86_reg y;\n\n    long x,w,h;\n\n    w=width/2; h=height/2;\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__ volatile(\n\n        PREFETCH\" %0    \\n\\t\"\n\n        PREFETCH\" %1    \\n\\t\"\n\n        ::\"m\"(*(src1+srcStride1)),\"m\"(*(src2+srcStride2)):\"memory\");\n\n#endif\n\n    for (y=0;y<h;y++) {\n\n        const uint8_t* s1=src1+srcStride1*(y>>1);\n\n        uint8_t* d=dst1+dstStride1*y;\n\n        x=0;\n\n#if COMPILE_TEMPLATE_MMX\n\n        for (;x<w-31;x+=32) {\n\n            __asm__ volatile(\n\n                PREFETCH\"   32%1        \\n\\t\"\n\n                \"movq         %1, %%mm0 \\n\\t\"\n\n                \"movq        8%1, %%mm2 \\n\\t\"\n\n                \"movq       16%1, %%mm4 \\n\\t\"\n\n                \"movq       24%1, %%mm6 \\n\\t\"\n\n                \"movq      %%mm0, %%mm1 \\n\\t\"\n\n                \"movq      %%mm2, %%mm3 \\n\\t\"\n\n                \"movq      %%mm4, %%mm5 \\n\\t\"\n\n                \"movq      %%mm6, %%mm7 \\n\\t\"\n\n                \"punpcklbw %%mm0, %%mm0 \\n\\t\"\n\n                \"punpckhbw %%mm1, %%mm1 \\n\\t\"\n\n                \"punpcklbw %%mm2, %%mm2 \\n\\t\"\n\n                \"punpckhbw %%mm3, %%mm3 \\n\\t\"\n\n                \"punpcklbw %%mm4, %%mm4 \\n\\t\"\n\n                \"punpckhbw %%mm5, %%mm5 \\n\\t\"\n\n                \"punpcklbw %%mm6, %%mm6 \\n\\t\"\n\n                \"punpckhbw %%mm7, %%mm7 \\n\\t\"\n\n                MOVNTQ\"    %%mm0,   %0  \\n\\t\"\n\n                MOVNTQ\"    %%mm1,  8%0  \\n\\t\"\n\n                MOVNTQ\"    %%mm2, 16%0  \\n\\t\"\n\n                MOVNTQ\"    %%mm3, 24%0  \\n\\t\"\n\n                MOVNTQ\"    %%mm4, 32%0  \\n\\t\"\n\n                MOVNTQ\"    %%mm5, 40%0  \\n\\t\"\n\n                MOVNTQ\"    %%mm6, 48%0  \\n\\t\"\n\n                MOVNTQ\"    %%mm7, 56%0\"\n\n                :\"=m\"(d[2*x])\n\n                :\"m\"(s1[x])\n\n                :\"memory\");\n\n        }\n\n#endif\n\n        for (;x<w;x++) d[2*x]=d[2*x+1]=s1[x];\n\n    }\n\n    for (y=0;y<h;y++) {\n\n        const uint8_t* s2=src2+srcStride2*(y>>1);\n\n        uint8_t* d=dst2+dstStride2*y;\n\n        x=0;\n\n#if COMPILE_TEMPLATE_MMX\n\n        for (;x<w-31;x+=32) {\n\n            __asm__ volatile(\n\n                PREFETCH\"   32%1        \\n\\t\"\n\n                \"movq         %1, %%mm0 \\n\\t\"\n\n                \"movq        8%1, %%mm2 \\n\\t\"\n\n                \"movq       16%1, %%mm4 \\n\\t\"\n\n                \"movq       24%1, %%mm6 \\n\\t\"\n\n                \"movq      %%mm0, %%mm1 \\n\\t\"\n\n                \"movq      %%mm2, %%mm3 \\n\\t\"\n\n                \"movq      %%mm4, %%mm5 \\n\\t\"\n\n                \"movq      %%mm6, %%mm7 \\n\\t\"\n\n                \"punpcklbw %%mm0, %%mm0 \\n\\t\"\n\n                \"punpckhbw %%mm1, %%mm1 \\n\\t\"\n\n                \"punpcklbw %%mm2, %%mm2 \\n\\t\"\n\n                \"punpckhbw %%mm3, %%mm3 \\n\\t\"\n\n                \"punpcklbw %%mm4, %%mm4 \\n\\t\"\n\n                \"punpckhbw %%mm5, %%mm5 \\n\\t\"\n\n                \"punpcklbw %%mm6, %%mm6 \\n\\t\"\n\n                \"punpckhbw %%mm7, %%mm7 \\n\\t\"\n\n                MOVNTQ\"    %%mm0,   %0  \\n\\t\"\n\n                MOVNTQ\"    %%mm1,  8%0  \\n\\t\"\n\n                MOVNTQ\"    %%mm2, 16%0  \\n\\t\"\n\n                MOVNTQ\"    %%mm3, 24%0  \\n\\t\"\n\n                MOVNTQ\"    %%mm4, 32%0  \\n\\t\"\n\n                MOVNTQ\"    %%mm5, 40%0  \\n\\t\"\n\n                MOVNTQ\"    %%mm6, 48%0  \\n\\t\"\n\n                MOVNTQ\"    %%mm7, 56%0\"\n\n                :\"=m\"(d[2*x])\n\n                :\"m\"(s2[x])\n\n                :\"memory\");\n\n        }\n\n#endif\n\n        for (;x<w;x++) d[2*x]=d[2*x+1]=s2[x];\n\n    }\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__(\n\n            EMMS\"       \\n\\t\"\n\n            SFENCE\"     \\n\\t\"\n\n            ::: \"memory\"\n\n        );\n\n#endif\n\n}\n", "idx": 22217}
{"project": "FFmpeg", "commit_id": "a29a0aba79dad35a80cfcdf6db6b506afb48dcaa", "target": 1, "func": "static int analyze_chunk(AVFormatContext *s, const uint8_t *chunk)\n{\n    TYDemuxContext *ty = s->priv_data;\n    int num_recs, i;\n    TyRecHdr *hdrs;\n    int num_6e0, num_be0, num_9c0, num_3c0;\n    /* skip if it's a Part header */\n    if (AV_RB32(&chunk[0]) == TIVO_PES_FILEID)\n        return 0;\n    /* number of records in chunk (we ignore high order byte;\n     * rarely are there > 256 chunks & we don't need that many anyway) */\n    num_recs = chunk[0];\n    if (num_recs < 5) {\n        /* try again with the next chunk.  Sometimes there are dead ones */\n        return 0;\n    }\n    chunk += 4;       /* skip past rec count & SEQ bytes */\n    ff_dlog(s, \"probe: chunk has %d recs\\n\", num_recs);\n    hdrs = parse_chunk_headers(chunk, num_recs);\n    if (!hdrs)\n        return AVERROR(ENOMEM);\n    /* scan headers.\n     * 1. check video packets.  Presence of 0x6e0 means S1.\n     *    No 6e0 but have be0 means S2.\n     * 2. probe for audio 0x9c0 vs 0x3c0 (AC3 vs Mpeg)\n     *    If AC-3, then we have DTivo.\n     *    If MPEG, search for PTS offset.  This will determine SA vs. DTivo.\n     */\n    num_6e0 = num_be0 = num_9c0 = num_3c0 = 0;\n    for (i = 0; i < num_recs; i++) {\n        switch (hdrs[i].subrec_type << 8 | hdrs[i].rec_type) {\n        case 0x6e0:\n            num_6e0++;\n        case 0xbe0:\n            num_be0++;\n        case 0x3c0:\n            num_3c0++;\n        case 0x9c0:\n            num_9c0++;\n        }\n    }\n    ff_dlog(s, \"probe: chunk has %d 0x6e0 recs, %d 0xbe0 recs.\\n\",\n            num_6e0, num_be0);\n    /* set up our variables */\n    if (num_6e0 > 0) {\n        ff_dlog(s, \"detected Series 1 Tivo\\n\");\n        ty->tivo_series = TIVO_SERIES1;\n        ty->pes_length = SERIES1_PES_LENGTH;\n    } else if (num_be0 > 0) {\n        ff_dlog(s, \"detected Series 2 Tivo\\n\");\n        ty->tivo_series = TIVO_SERIES2;\n        ty->pes_length = SERIES2_PES_LENGTH;\n    }\n    if (num_9c0 > 0) {\n        ff_dlog(s, \"detected AC-3 Audio (DTivo)\\n\");\n        ty->audio_type = TIVO_AUDIO_AC3;\n        ty->tivo_type = TIVO_TYPE_DTIVO;\n        ty->pts_offset = AC3_PTS_OFFSET;\n        ty->pes_length = AC3_PES_LENGTH;\n    } else if (num_3c0 > 0) {\n        ty->audio_type = TIVO_AUDIO_MPEG;\n        ff_dlog(s, \"detected MPEG Audio\\n\");\n    }\n    /* if tivo_type still unknown, we can check PTS location\n     * in MPEG packets to determine tivo_type */\n    if (ty->tivo_type == TIVO_TYPE_UNKNOWN) {\n        uint32_t data_offset = 16 * num_recs;\n        for (i = 0; i < num_recs; i++) {\n            if ((hdrs[i].subrec_type << 0x08 | hdrs[i].rec_type) == 0x3c0 && hdrs[i].rec_size > 15) {\n                /* first make sure we're aligned */\n                int pes_offset = find_es_header(ty_MPEGAudioPacket,\n                        &chunk[data_offset], 5);\n                if (pes_offset >= 0) {\n                    /* pes found. on SA, PES has hdr data at offset 6, not PTS. */\n                    if ((chunk[data_offset + 6 + pes_offset] & 0x80) == 0x80) {\n                        /* S1SA or S2(any) Mpeg Audio (PES hdr, not a PTS start) */\n                        if (ty->tivo_series == TIVO_SERIES1)\n                            ff_dlog(s, \"detected Stand-Alone Tivo\\n\");\n                        ty->tivo_type = TIVO_TYPE_SA;\n                        ty->pts_offset = SA_PTS_OFFSET;\n                    } else {\n                        if (ty->tivo_series == TIVO_SERIES1)\n                            ff_dlog(s, \"detected DirecTV Tivo\\n\");\n                        ty->tivo_type = TIVO_TYPE_DTIVO;\n                        ty->pts_offset = DTIVO_PTS_OFFSET;\n                    }\n                }\n            }\n            data_offset += hdrs[i].rec_size;\n        }\n    }\n    av_free(hdrs);\n    return 0;\n}", "idx": 22222}
{"project": "FFmpeg", "commit_id": "159ab4625bd3641e79b564335be8069dca881978", "target": 1, "func": "static int hevc_decode_nal_units(const uint8_t *buf, int buf_size, HEVCParamSets *ps,\n\n                                 int is_nalff, int nal_length_size, void *logctx)\n\n{\n\n    int i;\n\n    int ret = 0;\n\n    H2645Packet pkt = { 0 };\n\n\n\n    ret = ff_h2645_packet_split(&pkt, buf, buf_size, logctx, is_nalff, nal_length_size, AV_CODEC_ID_HEVC, 1);\n\n    if (ret < 0) {\n\n        goto done;\n\n    }\n\n\n\n    for (i = 0; i < pkt.nb_nals; i++) {\n\n        H2645NAL *nal = &pkt.nals[i];\n\n\n\n        /* ignore everything except parameter sets and VCL NALUs */\n\n        switch (nal->type) {\n\n        case HEVC_NAL_VPS: ff_hevc_decode_nal_vps(&nal->gb, logctx, ps);    break;\n\n        case HEVC_NAL_SPS: ff_hevc_decode_nal_sps(&nal->gb, logctx, ps, 1); break;\n\n        case HEVC_NAL_PPS: ff_hevc_decode_nal_pps(&nal->gb, logctx, ps);    break;\n\n        default:\n\n            av_log(logctx, AV_LOG_VERBOSE, \"Ignoring NAL type %d in extradata\\n\", nal->type);\n\n            break;\n\n        }\n\n    }\n\n\n\ndone:\n\n    ff_h2645_packet_uninit(&pkt);\n\n    return ret;\n\n}\n", "idx": 22225}
{"project": "FFmpeg", "commit_id": "21234c835d2d003d390d462b6e1b2622e7b02c39", "target": 1, "func": "static int load_sofa(AVFilterContext *ctx, char *filename, int *samplingrate)\n\n{\n\n    struct SOFAlizerContext *s = ctx->priv;\n\n    /* variables associated with content of SOFA file: */\n\n    int ncid, n_dims, n_vars, n_gatts, n_unlim_dim_id, status;\n\n    char data_delay_dim_name[NC_MAX_NAME];\n\n    float *sp_a, *sp_e, *sp_r, *data_ir;\n\n    char *sofa_conventions;\n\n    char dim_name[NC_MAX_NAME];   /* names of netCDF dimensions */\n\n    size_t *dim_length;           /* lengths of netCDF dimensions */\n\n    char *text;\n\n    unsigned int sample_rate;\n\n    int data_delay_dim_id[2];\n\n    int samplingrate_id;\n\n    int data_delay_id;\n\n    int n_samples;\n\n    int m_dim_id = -1;\n\n    int n_dim_id = -1;\n\n    int data_ir_id;\n\n    size_t att_len;\n\n    int m_dim;\n\n    int *data_delay;\n\n    int sp_id;\n\n    int i, ret;\n\n\n\n    s->sofa.ncid = 0;\n\n    status = nc_open(filename, NC_NOWRITE, &ncid); /* open SOFA file read-only */\n\n    if (status != NC_NOERR) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Can't find SOFA-file '%s'\\n\", filename);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    /* get number of dimensions, vars, global attributes and Id of unlimited dimensions: */\n\n    nc_inq(ncid, &n_dims, &n_vars, &n_gatts, &n_unlim_dim_id);\n\n\n\n    /* -- get number of measurements (\"M\") and length of one IR (\"N\") -- */\n\n    dim_length = av_malloc_array(n_dims, sizeof(*dim_length));\n\n    if (!dim_length) {\n\n        nc_close(ncid);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    for (i = 0; i < n_dims; i++) { /* go through all dimensions of file */\n\n        nc_inq_dim(ncid, i, (char *)&dim_name, &dim_length[i]); /* get dimensions */\n\n        if (!strncmp(\"M\", (const char *)&dim_name, 1)) /* get ID of dimension \"M\" */\n\n            m_dim_id = i;\n\n        if (!strncmp(\"N\", (const char *)&dim_name, 1)) /* get ID of dimension \"N\" */\n\n            n_dim_id = i;\n\n    }\n\n\n\n    if ((m_dim_id == -1) || (n_dim_id == -1)) { /* dimension \"M\" or \"N\" couldn't be found */\n\n        av_log(ctx, AV_LOG_ERROR, \"Can't find required dimensions in SOFA file.\\n\");\n\n        av_freep(&dim_length);\n\n        nc_close(ncid);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    n_samples = dim_length[n_dim_id]; /* get length of one IR */\n\n    m_dim     = dim_length[m_dim_id]; /* get number of measurements */\n\n\n\n    av_freep(&dim_length);\n\n\n\n    /* -- check file type -- */\n\n    /* get length of attritube \"Conventions\" */\n\n    status = nc_inq_attlen(ncid, NC_GLOBAL, \"Conventions\", &att_len);\n\n    if (status != NC_NOERR) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Can't get length of attribute \\\"Conventions\\\".\\n\");\n\n        nc_close(ncid);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* check whether file is SOFA file */\n\n    text = av_malloc(att_len + 1);\n\n    if (!text) {\n\n        nc_close(ncid);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    nc_get_att_text(ncid, NC_GLOBAL, \"Conventions\", text);\n\n    *(text + att_len) = 0;\n\n    if (strncmp(\"SOFA\", text, 4)) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Not a SOFA file!\\n\");\n\n        av_freep(&text);\n\n        nc_close(ncid);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    av_freep(&text);\n\n\n\n    status = nc_inq_attlen(ncid, NC_GLOBAL, \"License\", &att_len);\n\n    if (status == NC_NOERR) {\n\n        text = av_malloc(att_len + 1);\n\n        if (text) {\n\n            nc_get_att_text(ncid, NC_GLOBAL, \"License\", text);\n\n            *(text + att_len) = 0;\n\n            av_log(ctx, AV_LOG_INFO, \"SOFA file License: %s\\n\", text);\n\n            av_freep(&text);\n\n        }\n\n    }\n\n\n\n    status = nc_inq_attlen(ncid, NC_GLOBAL, \"SourceDescription\", &att_len);\n\n    if (status == NC_NOERR) {\n\n        text = av_malloc(att_len + 1);\n\n        if (text) {\n\n            nc_get_att_text(ncid, NC_GLOBAL, \"SourceDescription\", text);\n\n            *(text + att_len) = 0;\n\n            av_log(ctx, AV_LOG_INFO, \"SOFA file SourceDescription: %s\\n\", text);\n\n            av_freep(&text);\n\n        }\n\n    }\n\n\n\n    status = nc_inq_attlen(ncid, NC_GLOBAL, \"Comment\", &att_len);\n\n    if (status == NC_NOERR) {\n\n        text = av_malloc(att_len + 1);\n\n        if (text) {\n\n            nc_get_att_text(ncid, NC_GLOBAL, \"Comment\", text);\n\n            *(text + att_len) = 0;\n\n            av_log(ctx, AV_LOG_INFO, \"SOFA file Comment: %s\\n\", text);\n\n            av_freep(&text);\n\n        }\n\n    }\n\n\n\n    status = nc_inq_attlen(ncid, NC_GLOBAL, \"SOFAConventions\", &att_len);\n\n    if (status != NC_NOERR) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Can't get length of attribute \\\"SOFAConventions\\\".\\n\");\n\n        nc_close(ncid);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    sofa_conventions = av_malloc(att_len + 1);\n\n    if (!sofa_conventions) {\n\n        nc_close(ncid);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    nc_get_att_text(ncid, NC_GLOBAL, \"SOFAConventions\", sofa_conventions);\n\n    *(sofa_conventions + att_len) = 0;\n\n    if (strncmp(\"SimpleFreeFieldHRIR\", sofa_conventions, att_len)) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Not a SimpleFreeFieldHRIR file!\\n\");\n\n        av_freep(&sofa_conventions);\n\n        nc_close(ncid);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    av_freep(&sofa_conventions);\n\n\n\n    /* -- get sampling rate of HRTFs -- */\n\n    /* read ID, then value */\n\n    status  = nc_inq_varid(ncid, \"Data.SamplingRate\", &samplingrate_id);\n\n    status += nc_get_var_uint(ncid, samplingrate_id, &sample_rate);\n\n    if (status != NC_NOERR) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Couldn't read Data.SamplingRate.\\n\");\n\n        nc_close(ncid);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    *samplingrate = sample_rate; /* remember sampling rate */\n\n\n\n    /* -- allocate memory for one value for each measurement position: -- */\n\n    sp_a = s->sofa.sp_a = av_malloc_array(m_dim, sizeof(float));\n\n    sp_e = s->sofa.sp_e = av_malloc_array(m_dim, sizeof(float));\n\n    sp_r = s->sofa.sp_r = av_malloc_array(m_dim, sizeof(float));\n\n    /* delay and IR values required for each ear and measurement position: */\n\n    data_delay = s->sofa.data_delay = av_calloc(m_dim, 2 * sizeof(int));\n\n    data_ir = s->sofa.data_ir = av_malloc_array(m_dim * n_samples, sizeof(float) * 2);\n\n\n\n    if (!data_delay || !sp_a || !sp_e || !sp_r || !data_ir) {\n\n        /* if memory could not be allocated */\n\n        close_sofa(&s->sofa);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    /* get impulse responses (HRTFs): */\n\n    /* get corresponding ID */\n\n    status = nc_inq_varid(ncid, \"Data.IR\", &data_ir_id);\n\n    status += nc_get_var_float(ncid, data_ir_id, data_ir); /* read and store IRs */\n\n    if (status != NC_NOERR) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Couldn't read Data.IR!\\n\");\n\n        ret = AVERROR(EINVAL);\n\n        goto error;\n\n    }\n\n\n\n    /* get source positions of the HRTFs in the SOFA file: */\n\n    status  = nc_inq_varid(ncid, \"SourcePosition\", &sp_id); /* get corresponding ID */\n\n    status += nc_get_vara_float(ncid, sp_id, (size_t[2]){ 0, 0 } ,\n\n                (size_t[2]){ m_dim, 1}, sp_a); /* read & store azimuth angles */\n\n    status += nc_get_vara_float(ncid, sp_id, (size_t[2]){ 0, 1 } ,\n\n                (size_t[2]){ m_dim, 1}, sp_e); /* read & store elevation angles */\n\n    status += nc_get_vara_float(ncid, sp_id, (size_t[2]){ 0, 2 } ,\n\n                (size_t[2]){ m_dim, 1}, sp_r); /* read & store radii */\n\n    if (status != NC_NOERR) { /* if any source position variable coudn't be read */\n\n        av_log(ctx, AV_LOG_ERROR, \"Couldn't read SourcePosition.\\n\");\n\n        ret = AVERROR(EINVAL);\n\n        goto error;\n\n    }\n\n\n\n    /* read Data.Delay, check for errors and fit it to data_delay */\n\n    status  = nc_inq_varid(ncid, \"Data.Delay\", &data_delay_id);\n\n    status += nc_inq_vardimid(ncid, data_delay_id, &data_delay_dim_id[0]);\n\n    status += nc_inq_dimname(ncid, data_delay_dim_id[0], data_delay_dim_name);\n\n    if (status != NC_NOERR) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Couldn't read Data.Delay.\\n\");\n\n        ret = AVERROR(EINVAL);\n\n        goto error;\n\n    }\n\n\n\n    /* Data.Delay dimension check */\n\n    /* dimension of Data.Delay is [I R]: */\n\n    if (!strncmp(data_delay_dim_name, \"I\", 2)) {\n\n        /* check 2 characters to assure string is 0-terminated after \"I\" */\n\n        int delay[2]; /* delays get from SOFA file: */\n\n\n\n        av_log(ctx, AV_LOG_DEBUG, \"Data.Delay has dimension [I R]\\n\");\n\n        status = nc_get_var_int(ncid, data_delay_id, &delay[0]);\n\n        if (status != NC_NOERR) {\n\n            av_log(ctx, AV_LOG_ERROR, \"Couldn't read Data.Delay\\n\");\n\n            ret = AVERROR(EINVAL);\n\n            goto error;\n\n        }\n\n        int *data_delay_r = data_delay + m_dim;\n\n        for (i = 0; i < m_dim; i++) { /* extend given dimension [I R] to [M R] */\n\n            /* assign constant delay value for all measurements to data_delay fields */\n\n            data_delay[i]   = delay[0];\n\n            data_delay_r[i] = delay[1];\n\n        }\n\n        /* dimension of Data.Delay is [M R] */\n\n    } else if (!strncmp(data_delay_dim_name, \"M\", 2)) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Data.Delay in dimension [M R]\\n\");\n\n        /* get delays from SOFA file: */\n\n        status = nc_get_var_int(ncid, data_delay_id, data_delay);\n\n        if (status != NC_NOERR) {\n\n            av_log(ctx, AV_LOG_ERROR, \"Couldn't read Data.Delay\\n\");\n\n            ret = AVERROR(EINVAL);\n\n            goto error;\n\n        }\n\n    } else { /* dimension of Data.Delay is neither [I R] nor [M R] */\n\n        av_log(ctx, AV_LOG_ERROR, \"Data.Delay does not have the required dimensions [I R] or [M R].\\n\");\n\n        ret = AVERROR(EINVAL);\n\n        goto error;\n\n    }\n\n\n\n    /* save information in SOFA struct: */\n\n    s->sofa.m_dim = m_dim; /* no. measurement positions */\n\n    s->sofa.n_samples = n_samples; /* length on one IR */\n\n    s->sofa.ncid = ncid; /* netCDF ID of SOFA file */\n\n    nc_close(ncid); /* close SOFA file */\n\n\n\n    return 0;\n\n\n\nerror:\n\n    close_sofa(&s->sofa);\n\n    return ret;\n\n}\n", "idx": 22231}
{"project": "FFmpeg", "commit_id": "3ab9a2a5577d445252724af4067d2a7c8a378efa", "target": 1, "func": "static int rv40_h_loop_filter_strength(uint8_t *src, int stride,\n\n                                       int beta, int beta2, int edge,\n\n                                       int *p1, int *q1)\n\n{\n\n    return rv40_loop_filter_strength(src, stride, 1, beta, beta2, edge, p1, q1);\n\n}\n", "idx": 22239}
{"project": "FFmpeg", "commit_id": "88db5551cf1ced4ea3e5e8bd5b684d2dc74b1ed2", "target": 0, "func": "static int decode_pic(AVSContext *h) {\n\n    MpegEncContext *s = &h->s;\n\n    int skip_count;\n\n    enum cavs_mb mb_type;\n\n\n\n    if (!s->context_initialized) {\n\n        s->avctx->idct_algo = FF_IDCT_CAVS;\n\n        if (MPV_common_init(s) < 0)\n\n            return -1;\n\n        ff_init_scantable(s->dsp.idct_permutation,&h->scantable,ff_zigzag_direct);\n\n    }\n\n    skip_bits(&s->gb,16);//bbv_dwlay\n\n    if(h->stc == PIC_PB_START_CODE) {\n\n        h->pic_type = get_bits(&s->gb,2) + FF_I_TYPE;\n\n        if(h->pic_type > FF_B_TYPE) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"illegal picture type\\n\");\n\n            return -1;\n\n        }\n\n        /* make sure we have the reference frames we need */\n\n        if(!h->DPB[0].data[0] ||\n\n          (!h->DPB[1].data[0] && h->pic_type == FF_B_TYPE))\n\n            return -1;\n\n    } else {\n\n        h->pic_type = FF_I_TYPE;\n\n        if(get_bits1(&s->gb))\n\n            skip_bits(&s->gb,24);//time_code\n\n    }\n\n    /* release last B frame */\n\n    if(h->picture.data[0])\n\n        s->avctx->release_buffer(s->avctx, (AVFrame *)&h->picture);\n\n\n\n    s->avctx->get_buffer(s->avctx, (AVFrame *)&h->picture);\n\n    ff_cavs_init_pic(h);\n\n    h->picture.poc = get_bits(&s->gb,8)*2;\n\n\n\n    /* get temporal distances and MV scaling factors */\n\n    if(h->pic_type != FF_B_TYPE) {\n\n        h->dist[0] = (h->picture.poc - h->DPB[0].poc  + 512) % 512;\n\n    } else {\n\n        h->dist[0] = (h->DPB[0].poc  - h->picture.poc + 512) % 512;\n\n    }\n\n    h->dist[1] = (h->picture.poc - h->DPB[1].poc  + 512) % 512;\n\n    h->scale_den[0] = h->dist[0] ? 512/h->dist[0] : 0;\n\n    h->scale_den[1] = h->dist[1] ? 512/h->dist[1] : 0;\n\n    if(h->pic_type == FF_B_TYPE) {\n\n        h->sym_factor = h->dist[0]*h->scale_den[1];\n\n    } else {\n\n        h->direct_den[0] = h->dist[0] ? 16384/h->dist[0] : 0;\n\n        h->direct_den[1] = h->dist[1] ? 16384/h->dist[1] : 0;\n\n    }\n\n\n\n    if(s->low_delay)\n\n        get_ue_golomb(&s->gb); //bbv_check_times\n\n    h->progressive             = get_bits1(&s->gb);\n\n    h->pic_structure = 1;\n\n    if(!h->progressive)\n\n        h->pic_structure = get_bits1(&s->gb);\n\n    if(!h->pic_structure && h->stc == PIC_PB_START_CODE)\n\n        skip_bits1(&s->gb);     //advanced_pred_mode_disable\n\n    skip_bits1(&s->gb);        //top_field_first\n\n    skip_bits1(&s->gb);        //repeat_first_field\n\n    h->qp_fixed                = get_bits1(&s->gb);\n\n    h->qp                      = get_bits(&s->gb,6);\n\n    if(h->pic_type == FF_I_TYPE) {\n\n        if(!h->progressive && !h->pic_structure)\n\n            skip_bits1(&s->gb);//what is this?\n\n        skip_bits(&s->gb,4);   //reserved bits\n\n    } else {\n\n        if(!(h->pic_type == FF_B_TYPE && h->pic_structure == 1))\n\n            h->ref_flag        = get_bits1(&s->gb);\n\n        skip_bits(&s->gb,4);   //reserved bits\n\n        h->skip_mode_flag      = get_bits1(&s->gb);\n\n    }\n\n    h->loop_filter_disable     = get_bits1(&s->gb);\n\n    if(!h->loop_filter_disable && get_bits1(&s->gb)) {\n\n        h->alpha_offset        = get_se_golomb(&s->gb);\n\n        h->beta_offset         = get_se_golomb(&s->gb);\n\n    } else {\n\n        h->alpha_offset = h->beta_offset  = 0;\n\n    }\n\n    if(h->pic_type == FF_I_TYPE) {\n\n        do {\n\n            check_for_slice(h);\n\n            decode_mb_i(h, 0);\n\n        } while(ff_cavs_next_mb(h));\n\n    } else if(h->pic_type == FF_P_TYPE) {\n\n        do {\n\n            check_for_slice(h);\n\n            if(h->skip_mode_flag) {\n\n                skip_count = get_ue_golomb(&s->gb);\n\n                while(skip_count--) {\n\n                    decode_mb_p(h,P_SKIP);\n\n                    if(!ff_cavs_next_mb(h))\n\n                        goto done;\n\n                }\n\n                check_for_slice(h);\n\n                mb_type = get_ue_golomb(&s->gb) + P_16X16;\n\n            } else\n\n                mb_type = get_ue_golomb(&s->gb) + P_SKIP;\n\n            if(mb_type > P_8X8) {\n\n                decode_mb_i(h, mb_type - P_8X8 - 1);\n\n            } else\n\n                decode_mb_p(h,mb_type);\n\n        } while(ff_cavs_next_mb(h));\n\n    } else { /* FF_B_TYPE */\n\n        do {\n\n            check_for_slice(h);\n\n            if(h->skip_mode_flag) {\n\n                skip_count = get_ue_golomb(&s->gb);\n\n                while(skip_count--) {\n\n                    decode_mb_b(h,B_SKIP);\n\n                    if(!ff_cavs_next_mb(h))\n\n                        goto done;\n\n                }\n\n                check_for_slice(h);\n\n                mb_type = get_ue_golomb(&s->gb) + B_DIRECT;\n\n            } else\n\n                mb_type = get_ue_golomb(&s->gb) + B_SKIP;\n\n            if(mb_type > B_8X8) {\n\n                decode_mb_i(h, mb_type - B_8X8 - 1);\n\n            } else\n\n                decode_mb_b(h,mb_type);\n\n        } while(ff_cavs_next_mb(h));\n\n    }\n\n done:\n\n    if(h->pic_type != FF_B_TYPE) {\n\n        if(h->DPB[1].data[0])\n\n            s->avctx->release_buffer(s->avctx, (AVFrame *)&h->DPB[1]);\n\n        h->DPB[1] = h->DPB[0];\n\n        h->DPB[0] = h->picture;\n\n        memset(&h->picture,0,sizeof(Picture));\n\n    }\n\n    return 0;\n\n}\n", "idx": 22240}
{"project": "FFmpeg", "commit_id": "6a287fd7ce5ea69f4eeadda6a049d669eb8efb46", "target": 0, "func": "static int gxf_interleave_packet(AVFormatContext *s, AVPacket *out, AVPacket *pkt, int flush)\n\n{\n\n    GXFContext *gxf = s->priv_data;\n\n    AVPacket new_pkt;\n\n    int i;\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        if (s->streams[i]->codec->codec_type == CODEC_TYPE_AUDIO) {\n\n            GXFStreamContext *sc = &gxf->streams[i];\n\n            if (pkt && pkt->stream_index == i) {\n\n                av_fifo_write(&sc->audio_buffer, pkt->data, pkt->size);\n\n                pkt = NULL;\n\n            }\n\n            if (flush || av_fifo_size(&sc->audio_buffer) >= GXF_AUDIO_PACKET_SIZE) {\n\n                if (!pkt && gxf_new_audio_packet(gxf, sc, &new_pkt, flush) > 0) {\n\n                    pkt = &new_pkt;\n\n                    break; /* add pkt right now into list */\n\n                }\n\n            }\n\n        }\n\n    }\n\n    return av_interleave_packet_per_dts(s, out, pkt, flush);\n\n}\n", "idx": 22241}
{"project": "FFmpeg", "commit_id": "538de4354dcd6c57154c5a5dec0744dcaa06b874", "target": 0, "func": "int ff_nvdec_decode_init(AVCodecContext *avctx)\n\n{\n\n    NVDECContext *ctx = avctx->internal->hwaccel_priv_data;\n\n\n\n    NVDECFramePool      *pool;\n\n    AVHWFramesContext   *frames_ctx;\n\n    const AVPixFmtDescriptor *sw_desc;\n\n\n\n    CUVIDDECODECREATEINFO params = { 0 };\n\n\n\n    int cuvid_codec_type, cuvid_chroma_format;\n\n    int ret = 0;\n\n\n\n    sw_desc = av_pix_fmt_desc_get(avctx->sw_pix_fmt);\n\n    if (!sw_desc)\n\n        return AVERROR_BUG;\n\n\n\n    cuvid_codec_type = map_avcodec_id(avctx->codec_id);\n\n    if (cuvid_codec_type < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported codec ID\\n\");\n\n        return AVERROR_BUG;\n\n    }\n\n\n\n    cuvid_chroma_format = map_chroma_format(avctx->sw_pix_fmt);\n\n    if (cuvid_chroma_format < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported chroma format\\n\");\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    if (!avctx->hw_frames_ctx) {\n\n        ret = ff_decode_get_hw_frames_ctx(avctx, AV_HWDEVICE_TYPE_CUDA);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n\n\n\n    params.ulWidth             = avctx->coded_width;\n\n    params.ulHeight            = avctx->coded_height;\n\n    params.ulTargetWidth       = avctx->coded_width;\n\n    params.ulTargetHeight      = avctx->coded_height;\n\n    params.bitDepthMinus8      = sw_desc->comp[0].depth - 8;\n\n    params.OutputFormat        = params.bitDepthMinus8 ?\n\n                                 cudaVideoSurfaceFormat_P016 : cudaVideoSurfaceFormat_NV12;\n\n    params.CodecType           = cuvid_codec_type;\n\n    params.ChromaFormat        = cuvid_chroma_format;\n\n    params.ulNumDecodeSurfaces = frames_ctx->initial_pool_size;\n\n    params.ulNumOutputSurfaces = 1;\n\n\n\n    ret = nvdec_decoder_create(&ctx->decoder_ref, frames_ctx->device_ref, &params, avctx);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    pool = av_mallocz(sizeof(*pool));\n\n    if (!pool) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    pool->dpb_size = frames_ctx->initial_pool_size;\n\n\n\n    ctx->decoder_pool = av_buffer_pool_init2(sizeof(int), pool,\n\n                                             nvdec_decoder_frame_alloc, av_free);\n\n    if (!ctx->decoder_pool) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    return 0;\n\nfail:\n\n    ff_nvdec_decode_uninit(avctx);\n\n    return ret;\n\n}\n", "idx": 22242}
{"project": "FFmpeg", "commit_id": "dc3c3758ce6368aa2f0a9a9b544bce2e130cc4e1", "target": 1, "func": "static int thp_read_packet(AVFormatContext *s,\n\n                            AVPacket *pkt)\n\n{\n\n    ThpDemuxContext *thp = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    unsigned int size;\n\n    int ret;\n\n\n\n    if (thp->audiosize == 0) {\n\n        /* Terminate when last frame is reached.  */\n\n        if (thp->frame >= thp->framecnt)\n\n            return AVERROR_EOF;\n\n\n\n        avio_seek(pb, thp->next_frame, SEEK_SET);\n\n\n\n        /* Locate the next frame and read out its size.  */\n\n        thp->next_frame += FFMAX(thp->next_framesz, 1);\n\n        thp->next_framesz = avio_rb32(pb);\n\n\n\n                        avio_rb32(pb); /* Previous total size.  */\n\n        size          = avio_rb32(pb); /* Total size of this frame.  */\n\n\n\n        /* Store the audiosize so the next time this function is called,\n\n           the audio can be read.  */\n\n        if (thp->has_audio)\n\n            thp->audiosize = avio_rb32(pb); /* Audio size.  */\n\n        else\n\n            thp->frame++;\n\n\n\n        ret = av_get_packet(pb, pkt, size);\n\n\n\n        if (ret != size) {\n\n            av_free_packet(pkt);\n\n            return AVERROR(EIO);\n\n        }\n\n\n\n        pkt->stream_index = thp->video_stream_index;\n\n    } else {\n\n        ret = av_get_packet(pb, pkt, thp->audiosize);\n\n\n\n        if (ret != thp->audiosize) {\n\n            av_free_packet(pkt);\n\n            return AVERROR(EIO);\n\n        }\n\n\n\n        pkt->stream_index = thp->audio_stream_index;\n\n        if (thp->audiosize >= 8)\n\n            pkt->duration = AV_RB32(&pkt->data[4]);\n\n\n\n        thp->audiosize = 0;\n\n        thp->frame++;\n\n    }\n\n\n\n    return 0;\n\n}", "idx": 22249}
{"project": "FFmpeg", "commit_id": "857cd1f33bcf86005529af2a77f861f884327be5", "target": 0, "func": "static int RENAME(resample_common)(ResampleContext *c,\n\n                                   DELEM *dst, const DELEM *src,\n\n                                   int n, int update_ctx)\n\n{\n\n    int dst_index;\n\n    int index= c->index;\n\n    int frac= c->frac;\n\n    int sample_index = index >> c->phase_shift;\n\n\n\n    index &= c->phase_mask;\n\n    for (dst_index = 0; dst_index < n; dst_index++) {\n\n        FELEM *filter = ((FELEM *) c->filter_bank) + c->filter_alloc * index;\n\n\n\n        FELEM2 val=0;\n\n        int i;\n\n        for (i = 0; i < c->filter_length; i++) {\n\n            val += src[sample_index + i] * (FELEM2)filter[i];\n\n        }\n\n        OUT(dst[dst_index], val);\n\n\n\n        frac  += c->dst_incr_mod;\n\n        index += c->dst_incr_div;\n\n        if (frac >= c->src_incr) {\n\n            frac -= c->src_incr;\n\n            index++;\n\n        }\n\n        sample_index += index >> c->phase_shift;\n\n        index &= c->phase_mask;\n\n    }\n\n\n\n    if(update_ctx){\n\n        c->frac= frac;\n\n        c->index= index;\n\n    }\n\n\n\n    return sample_index;\n\n}\n", "idx": 22251}
{"project": "FFmpeg", "commit_id": "38d553322891c8e47182f05199d19888422167dc", "target": 1, "func": "int av_image_fill_pointers(uint8_t *data[4], enum PixelFormat pix_fmt, int height,\n\n                           uint8_t *ptr, const int linesizes[4])\n\n{\n\n    int i, total_size, size[4], has_plane[4];\n\n\n\n    const AVPixFmtDescriptor *desc = &av_pix_fmt_descriptors[pix_fmt];\n\n    memset(data     , 0, sizeof(data[0])*4);\n\n    memset(size     , 0, sizeof(size));\n\n    memset(has_plane, 0, sizeof(has_plane));\n\n\n\n    if ((unsigned)pix_fmt >= PIX_FMT_NB || desc->flags & PIX_FMT_HWACCEL)\n\n        return AVERROR(EINVAL);\n\n\n\n    data[0] = ptr;\n\n    if (linesizes[0] > (INT_MAX - 1024) / height)\n\n        return AVERROR(EINVAL);\n\n    size[0] = linesizes[0] * height;\n\n\n\n    if (desc->flags & PIX_FMT_PAL) {\n\n        size[0] = (size[0] + 3) & ~3;\n\n        data[1] = ptr + size[0]; /* palette is stored here as 256 32 bits words */\n\n        return size[0] + 256 * 4;\n\n    }\n\n\n\n    for (i = 0; i < 4; i++)\n\n        has_plane[desc->comp[i].plane] = 1;\n\n\n\n    total_size = size[0];\n\n    for (i = 1; i < 4 && has_plane[i]; i++) {\n\n        int h, s = (i == 1 || i == 2) ? desc->log2_chroma_h : 0;\n\n        data[i] = data[i-1] + size[i-1];\n\n        h = (height + (1 << s) - 1) >> s;\n\n        if (linesizes[i] > INT_MAX / h)\n\n            return AVERROR(EINVAL);\n\n        size[i] = h * linesizes[i];\n\n        if (total_size > INT_MAX - size[i])\n\n            return AVERROR(EINVAL);\n\n        total_size += size[i];\n\n    }\n\n\n\n    return total_size;\n\n}\n", "idx": 22253}
{"project": "FFmpeg", "commit_id": "79042a6eb150e5d80a0e7bf242d9945d1246703b", "target": 1, "func": "av_cold int MPV_common_init(MpegEncContext *s)\n\n{\n\n    int y_size, c_size, yc_size, i, mb_array_size, mv_table_size, x, y, threads;\n\n\n\n    if(s->codec_id == CODEC_ID_MPEG2VIDEO && !s->progressive_sequence)\n\n        s->mb_height = (s->height + 31) / 32 * 2;\n\n    else\n\n        s->mb_height = (s->height + 15) / 16;\n\n\n\n    if(s->avctx->pix_fmt == PIX_FMT_NONE){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"decoding to PIX_FMT_NONE is not supported.\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(s->avctx->thread_count > MAX_THREADS || (s->avctx->thread_count > s->mb_height && s->mb_height)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"too many threads\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if((s->width || s->height) && avcodec_check_dimensions(s->avctx, s->width, s->height))\n\n        return -1;\n\n\n\n    dsputil_init(&s->dsp, s->avctx);\n\n    ff_dct_common_init(s);\n\n\n\n    s->flags= s->avctx->flags;\n\n    s->flags2= s->avctx->flags2;\n\n\n\n    s->mb_width  = (s->width  + 15) / 16;\n\n    s->mb_stride = s->mb_width + 1;\n\n    s->b8_stride = s->mb_width*2 + 1;\n\n    s->b4_stride = s->mb_width*4 + 1;\n\n    mb_array_size= s->mb_height * s->mb_stride;\n\n    mv_table_size= (s->mb_height+2) * s->mb_stride + 1;\n\n\n\n    /* set chroma shifts */\n\n    avcodec_get_chroma_sub_sample(s->avctx->pix_fmt,&(s->chroma_x_shift),\n\n                                                    &(s->chroma_y_shift) );\n\n\n\n    /* set default edge pos, will be overriden in decode_header if needed */\n\n    s->h_edge_pos= s->mb_width*16;\n\n    s->v_edge_pos= s->mb_height*16;\n\n\n\n    s->mb_num = s->mb_width * s->mb_height;\n\n\n\n    s->block_wrap[0]=\n\n    s->block_wrap[1]=\n\n    s->block_wrap[2]=\n\n    s->block_wrap[3]= s->b8_stride;\n\n    s->block_wrap[4]=\n\n    s->block_wrap[5]= s->mb_stride;\n\n\n\n    y_size = s->b8_stride * (2 * s->mb_height + 1);\n\n    c_size = s->mb_stride * (s->mb_height + 1);\n\n    yc_size = y_size + 2 * c_size;\n\n\n\n    /* convert fourcc to upper case */\n\n    s->codec_tag = ff_toupper4(s->avctx->codec_tag);\n\n\n\n    s->stream_codec_tag = ff_toupper4(s->avctx->stream_codec_tag);\n\n\n\n    s->avctx->coded_frame= (AVFrame*)&s->current_picture;\n\n\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->mb_index2xy, (s->mb_num+1)*sizeof(int), fail) //error ressilience code looks cleaner with this\n\n    for(y=0; y<s->mb_height; y++){\n\n        for(x=0; x<s->mb_width; x++){\n\n            s->mb_index2xy[ x + y*s->mb_width ] = x + y*s->mb_stride;\n\n        }\n\n    }\n\n    s->mb_index2xy[ s->mb_height*s->mb_width ] = (s->mb_height-1)*s->mb_stride + s->mb_width; //FIXME really needed?\n\n\n\n    if (s->encoding) {\n\n        /* Allocate MV tables */\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->p_mv_table_base            , mv_table_size * 2 * sizeof(int16_t), fail)\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->b_forw_mv_table_base       , mv_table_size * 2 * sizeof(int16_t), fail)\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->b_back_mv_table_base       , mv_table_size * 2 * sizeof(int16_t), fail)\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->b_bidir_forw_mv_table_base , mv_table_size * 2 * sizeof(int16_t), fail)\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->b_bidir_back_mv_table_base , mv_table_size * 2 * sizeof(int16_t), fail)\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->b_direct_mv_table_base     , mv_table_size * 2 * sizeof(int16_t), fail)\n\n        s->p_mv_table           = s->p_mv_table_base            + s->mb_stride + 1;\n\n        s->b_forw_mv_table      = s->b_forw_mv_table_base       + s->mb_stride + 1;\n\n        s->b_back_mv_table      = s->b_back_mv_table_base       + s->mb_stride + 1;\n\n        s->b_bidir_forw_mv_table= s->b_bidir_forw_mv_table_base + s->mb_stride + 1;\n\n        s->b_bidir_back_mv_table= s->b_bidir_back_mv_table_base + s->mb_stride + 1;\n\n        s->b_direct_mv_table    = s->b_direct_mv_table_base     + s->mb_stride + 1;\n\n\n\n        if(s->msmpeg4_version){\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->ac_stats, 2*2*(MAX_LEVEL+1)*(MAX_RUN+1)*2*sizeof(int), fail);\n\n        }\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->avctx->stats_out, 256, fail);\n\n\n\n        /* Allocate MB type table */\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->mb_type  , mb_array_size * sizeof(uint16_t), fail) //needed for encoding\n\n\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->lambda_table, mb_array_size * sizeof(int), fail)\n\n\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->q_intra_matrix  , 64*32   * sizeof(int), fail)\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->q_inter_matrix  , 64*32   * sizeof(int), fail)\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->q_intra_matrix16, 64*32*2 * sizeof(uint16_t), fail)\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->q_inter_matrix16, 64*32*2 * sizeof(uint16_t), fail)\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->input_picture, MAX_PICTURE_COUNT * sizeof(Picture*), fail)\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->reordered_input_picture, MAX_PICTURE_COUNT * sizeof(Picture*), fail)\n\n\n\n        if(s->avctx->noise_reduction){\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->dct_offset, 2 * 64 * sizeof(uint16_t), fail)\n\n        }\n\n    }\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->picture, MAX_PICTURE_COUNT * sizeof(Picture), fail)\n\n    for(i = 0; i < MAX_PICTURE_COUNT; i++) {\n\n        avcodec_get_frame_defaults((AVFrame *)&s->picture[i]);\n\n    }\n\n\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->error_status_table, mb_array_size*sizeof(uint8_t), fail)\n\n\n\n    if(s->codec_id==CODEC_ID_MPEG4 || (s->flags & CODEC_FLAG_INTERLACED_ME)){\n\n        /* interlaced direct mode decoding tables */\n\n            for(i=0; i<2; i++){\n\n                int j, k;\n\n                for(j=0; j<2; j++){\n\n                    for(k=0; k<2; k++){\n\n                        FF_ALLOCZ_OR_GOTO(s->avctx,    s->b_field_mv_table_base[i][j][k], mv_table_size * 2 * sizeof(int16_t), fail)\n\n                        s->b_field_mv_table[i][j][k] = s->b_field_mv_table_base[i][j][k] + s->mb_stride + 1;\n\n                    }\n\n                    FF_ALLOCZ_OR_GOTO(s->avctx, s->b_field_select_table [i][j], mb_array_size * 2 * sizeof(uint8_t), fail)\n\n                    FF_ALLOCZ_OR_GOTO(s->avctx, s->p_field_mv_table_base[i][j], mv_table_size * 2 * sizeof(int16_t), fail)\n\n                    s->p_field_mv_table[i][j] = s->p_field_mv_table_base[i][j]+ s->mb_stride + 1;\n\n                }\n\n                FF_ALLOCZ_OR_GOTO(s->avctx, s->p_field_select_table[i], mb_array_size * 2 * sizeof(uint8_t), fail)\n\n            }\n\n    }\n\n    if (s->out_format == FMT_H263) {\n\n        /* ac values */\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->ac_val_base, yc_size * sizeof(int16_t) * 16, fail);\n\n        s->ac_val[0] = s->ac_val_base + s->b8_stride + 1;\n\n        s->ac_val[1] = s->ac_val_base + y_size + s->mb_stride + 1;\n\n        s->ac_val[2] = s->ac_val[1] + c_size;\n\n\n\n        /* cbp values */\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->coded_block_base, y_size, fail);\n\n        s->coded_block= s->coded_block_base + s->b8_stride + 1;\n\n\n\n        /* cbp, ac_pred, pred_dir */\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->cbp_table     , mb_array_size * sizeof(uint8_t), fail)\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->pred_dir_table, mb_array_size * sizeof(uint8_t), fail)\n\n    }\n\n\n\n    if (s->h263_pred || s->h263_plus || !s->encoding) {\n\n        /* dc values */\n\n        //MN: we need these for error resilience of intra-frames\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->dc_val_base, yc_size * sizeof(int16_t), fail);\n\n        s->dc_val[0] = s->dc_val_base + s->b8_stride + 1;\n\n        s->dc_val[1] = s->dc_val_base + y_size + s->mb_stride + 1;\n\n        s->dc_val[2] = s->dc_val[1] + c_size;\n\n        for(i=0;i<yc_size;i++)\n\n            s->dc_val_base[i] = 1024;\n\n    }\n\n\n\n    /* which mb is a intra block */\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->mbintra_table, mb_array_size, fail);\n\n    memset(s->mbintra_table, 1, mb_array_size);\n\n\n\n    /* init macroblock skip table */\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->mbskip_table, mb_array_size+2, fail);\n\n    //Note the +1 is for a quicker mpeg4 slice_end detection\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->prev_pict_types, PREV_PICT_TYPES_BUFFER_SIZE, fail);\n\n\n\n    s->parse_context.state= -1;\n\n    if((s->avctx->debug&(FF_DEBUG_VIS_QP|FF_DEBUG_VIS_MB_TYPE)) || (s->avctx->debug_mv)){\n\n       s->visualization_buffer[0] = av_malloc((s->mb_width*16 + 2*EDGE_WIDTH) * s->mb_height*16 + 2*EDGE_WIDTH);\n\n       s->visualization_buffer[1] = av_malloc((s->mb_width*16 + 2*EDGE_WIDTH) * s->mb_height*16 + 2*EDGE_WIDTH);\n\n       s->visualization_buffer[2] = av_malloc((s->mb_width*16 + 2*EDGE_WIDTH) * s->mb_height*16 + 2*EDGE_WIDTH);\n\n    }\n\n\n\n    s->context_initialized = 1;\n\n\n\n    s->thread_context[0]= s;\n\n    threads = s->avctx->thread_count;\n\n\n\n    for(i=1; i<threads; i++){\n\n        s->thread_context[i]= av_malloc(sizeof(MpegEncContext));\n\n        memcpy(s->thread_context[i], s, sizeof(MpegEncContext));\n\n    }\n\n\n\n    for(i=0; i<threads; i++){\n\n        if(init_duplicate_context(s->thread_context[i], s) < 0)\n\n           goto fail;\n\n        s->thread_context[i]->start_mb_y= (s->mb_height*(i  ) + s->avctx->thread_count/2) / s->avctx->thread_count;\n\n        s->thread_context[i]->end_mb_y  = (s->mb_height*(i+1) + s->avctx->thread_count/2) / s->avctx->thread_count;\n\n    }\n\n\n\n    return 0;\n\n fail:\n\n    MPV_common_end(s);\n\n    return -1;\n\n}\n", "idx": 22255}
{"project": "FFmpeg", "commit_id": "7f46a641bf2540b8cf1293d5e50c0c0e34264254", "target": 1, "func": "static av_cold int aac_decode_init(AVCodecContext *avctx)\n\n{\n\n    AACContext *ac = avctx->priv_data;\n\n    int ret;\n\n\n\n    ac->avctx = avctx;\n\n    ac->oc[1].m4ac.sample_rate = avctx->sample_rate;\n\n\n\n    aacdec_init(ac);\n\n#if USE_FIXED\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_S32P;\n\n#else\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_FLTP;\n\n#endif /* USE_FIXED */\n\n\n\n    if (avctx->extradata_size > 0) {\n\n        if ((ret = decode_audio_specific_config(ac, ac->avctx, &ac->oc[1].m4ac,\n\n                                                avctx->extradata,\n\n                                                avctx->extradata_size * 8,\n\n                                                1)) < 0)\n\n            return ret;\n\n    } else {\n\n        int sr, i;\n\n        uint8_t layout_map[MAX_ELEM_ID*4][3];\n\n        int layout_map_tags;\n\n\n\n        sr = sample_rate_idx(avctx->sample_rate);\n\n        ac->oc[1].m4ac.sampling_index = sr;\n\n        ac->oc[1].m4ac.channels = avctx->channels;\n\n        ac->oc[1].m4ac.sbr = -1;\n\n        ac->oc[1].m4ac.ps = -1;\n\n\n\n        for (i = 0; i < FF_ARRAY_ELEMS(ff_mpeg4audio_channels); i++)\n\n            if (ff_mpeg4audio_channels[i] == avctx->channels)\n\n                break;\n\n        if (i == FF_ARRAY_ELEMS(ff_mpeg4audio_channels)) {\n\n            i = 0;\n\n        }\n\n        ac->oc[1].m4ac.chan_config = i;\n\n\n\n        if (ac->oc[1].m4ac.chan_config) {\n\n            int ret = set_default_channel_config(avctx, layout_map,\n\n                &layout_map_tags, ac->oc[1].m4ac.chan_config);\n\n            if (!ret)\n\n                output_configure(ac, layout_map, layout_map_tags,\n\n                                 OC_GLOBAL_HDR, 0);\n\n            else if (avctx->err_recognition & AV_EF_EXPLODE)\n\n                return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    if (avctx->channels > MAX_CHANNELS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Too many channels\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    AAC_INIT_VLC_STATIC( 0, 304);\n\n    AAC_INIT_VLC_STATIC( 1, 270);\n\n    AAC_INIT_VLC_STATIC( 2, 550);\n\n    AAC_INIT_VLC_STATIC( 3, 300);\n\n    AAC_INIT_VLC_STATIC( 4, 328);\n\n    AAC_INIT_VLC_STATIC( 5, 294);\n\n    AAC_INIT_VLC_STATIC( 6, 306);\n\n    AAC_INIT_VLC_STATIC( 7, 268);\n\n    AAC_INIT_VLC_STATIC( 8, 510);\n\n    AAC_INIT_VLC_STATIC( 9, 366);\n\n    AAC_INIT_VLC_STATIC(10, 462);\n\n\n\n    AAC_RENAME(ff_aac_sbr_init)();\n\n\n\n#if USE_FIXED\n\n    ac->fdsp = avpriv_alloc_fixed_dsp(avctx->flags & AV_CODEC_FLAG_BITEXACT);\n\n#else\n\n    ac->fdsp = avpriv_float_dsp_alloc(avctx->flags & AV_CODEC_FLAG_BITEXACT);\n\n#endif /* USE_FIXED */\n\n    if (!ac->fdsp) {\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    ac->random_state = 0x1f2e3d4c;\n\n\n\n    ff_aac_tableinit();\n\n\n\n    INIT_VLC_STATIC(&vlc_scalefactors, 7,\n\n                    FF_ARRAY_ELEMS(ff_aac_scalefactor_code),\n\n                    ff_aac_scalefactor_bits,\n\n                    sizeof(ff_aac_scalefactor_bits[0]),\n\n                    sizeof(ff_aac_scalefactor_bits[0]),\n\n                    ff_aac_scalefactor_code,\n\n                    sizeof(ff_aac_scalefactor_code[0]),\n\n                    sizeof(ff_aac_scalefactor_code[0]),\n\n                    352);\n\n\n\n    AAC_RENAME_32(ff_mdct_init)(&ac->mdct,       11, 1, 1.0 / RANGE15(1024.0));\n\n    AAC_RENAME_32(ff_mdct_init)(&ac->mdct_ld,    10, 1, 1.0 / RANGE15(512.0));\n\n    AAC_RENAME_32(ff_mdct_init)(&ac->mdct_small,  8, 1, 1.0 / RANGE15(128.0));\n\n    AAC_RENAME_32(ff_mdct_init)(&ac->mdct_ltp,   11, 0, RANGE15(-2.0));\n\n#if !USE_FIXED\n\n    ret = ff_imdct15_init(&ac->mdct480, 5);\n\n    if (ret < 0)\n\n        return ret;\n\n#endif\n\n    // window initialization\n\n    AAC_RENAME(ff_kbd_window_init)(AAC_RENAME(ff_aac_kbd_long_1024), 4.0, 1024);\n\n    AAC_RENAME(ff_kbd_window_init)(AAC_RENAME(ff_aac_kbd_short_128), 6.0, 128);\n\n    AAC_RENAME(ff_init_ff_sine_windows)(10);\n\n    AAC_RENAME(ff_init_ff_sine_windows)( 9);\n\n    AAC_RENAME(ff_init_ff_sine_windows)( 7);\n\n\n\n    AAC_RENAME(cbrt_tableinit)();\n\n\n\n    return 0;\n\n}\n", "idx": 22256}
{"project": "FFmpeg", "commit_id": "a6cd817a544e4e526f18391bd2c7112dc12d2f94", "target": 1, "func": "static int msf_probe(AVProbeData *p)\n{\n    if (memcmp(p->buf, \"MSF\", 3))\n        return 0;\n    if (AV_RB32(p->buf+8) <= 0)\n        return 0;\n    if (AV_RB32(p->buf+16) <= 0)\n        return 0;\n    return AVPROBE_SCORE_MAX / 3 * 2;\n}", "idx": 22266}
{"project": "FFmpeg", "commit_id": "cbba331aa02f29870581ff0b7ded7477b279ae2c", "target": 0, "func": "static inline int writer_print_string(WriterContext *wctx,\n\n                                      const char *key, const char *val, int opt)\n\n{\n\n    const struct section *section = wctx->section[wctx->level];\n\n    int ret = 0;\n\n\n\n    if (opt && !(wctx->writer->flags & WRITER_FLAG_DISPLAY_OPTIONAL_FIELDS))\n\n        return 0;\n\n\n\n    if (section->show_all_entries || av_dict_get(section->entries_to_show, key, NULL, 0)) {\n\n        wctx->writer->print_string(wctx, key, val);\n\n        wctx->nb_item[wctx->level]++;\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 22273}
{"project": "FFmpeg", "commit_id": "259c71c199e9b4ea89bf4cb90ed0e207ddc9dff7", "target": 0, "func": "static int mpjpeg_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    int size;\n\n    int ret;\n\n\n\n    MPJPEGDemuxContext *mpjpeg = s->priv_data;\n\n    if (mpjpeg->boundary == NULL) {\n\n        mpjpeg->boundary = av_strdup(\"--\");\n\n        mpjpeg->searchstr = av_strdup(\"\\r\\n--\");\n\n        if (!mpjpeg->boundary || !mpjpeg->searchstr) {\n\n            av_freep(&mpjpeg->boundary);\n\n            av_freep(&mpjpeg->searchstr);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        mpjpeg->searchstr_len = strlen(mpjpeg->searchstr);\n\n    }\n\n\n\n    ret = parse_multipart_header(s->pb, &size, mpjpeg->boundary, s);\n\n\n\n\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (size > 0) {\n\n        /* size has been provided to us in MIME header */\n\n        ret = av_get_packet(s->pb, pkt, size);\n\n    } else {\n\n        /* no size was given -- we read until the next boundary or end-of-file */\n\n        int remaining = 0, len;\n\n\n\n        const int read_chunk = 2048;\n\n        av_init_packet(pkt);\n\n        pkt->data = NULL;\n\n        pkt->size = 0;\n\n        pkt->pos  = avio_tell(s->pb);\n\n\n\n        /* we may need to return as much as all we've read back to the buffer */\n\n        ffio_ensure_seekback(s->pb, read_chunk);\n\n\n\n        while ((ret = av_append_packet(s->pb, pkt, read_chunk - remaining)) >= 0) {\n\n            /* scan the new data */\n\n            len = ret + remaining;\n\n            char *start = pkt->data + pkt->size - len;\n\n            do {\n\n                if (!memcmp(start, mpjpeg->searchstr, mpjpeg->searchstr_len)) {\n\n                    // got the boundary! rewind the stream\n\n                    avio_seek(s->pb, -(len-2), SEEK_CUR);\n\n                    pkt->size -= (len-2);\n\n                    return pkt->size;\n\n                }\n\n                len--;\n\n                start++;\n\n            } while (len >= mpjpeg->searchstr_len);\n\n            remaining = len;\n\n        }\n\n\n\n        /* error or EOF occurred */\n\n        if (ret == AVERROR_EOF) {\n\n            ret = pkt->size > 0 ? pkt->size : AVERROR_EOF;\n\n        } else {\n\n            av_packet_unref(pkt);\n\n        }\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 22284}
{"project": "FFmpeg", "commit_id": "6a63ff19b6a7fe3bc32c7fb4a62fca8f65786432", "target": 0, "func": "static int mov_read_enda(MOVContext *c, ByteIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st = c->fc->streams[c->fc->nb_streams-1];\n\n    int little_endian = get_be16(pb);\n\n\n\n    dprintf(c->fc, \"enda %d\\n\", little_endian);\n\n    if (little_endian == 1) {\n\n        switch (st->codec->codec_id) {\n\n        case CODEC_ID_PCM_S24BE:\n\n            st->codec->codec_id = CODEC_ID_PCM_S24LE;\n\n            break;\n\n        case CODEC_ID_PCM_S32BE:\n\n            st->codec->codec_id = CODEC_ID_PCM_S32LE;\n\n            break;\n\n        case CODEC_ID_PCM_F32BE:\n\n            st->codec->codec_id = CODEC_ID_PCM_F32LE;\n\n            break;\n\n        case CODEC_ID_PCM_F64BE:\n\n            st->codec->codec_id = CODEC_ID_PCM_F64LE;\n\n            break;\n\n        default:\n\n            break;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 22295}
{"project": "FFmpeg", "commit_id": "d9837434a91dbb3632df335414aad538e5b0a6e9", "target": 0, "func": "static inline int decode_scalar(GetBitContext *gb, int k, int limit, int readsamplesize){\n\n    int x = get_unary_0_9(gb);\n\n\n\n    if (x > 8) { /* RICE THRESHOLD */\n\n        /* use alternative encoding */\n\n        x = get_bits(gb, readsamplesize);\n\n    } else {\n\n        if (k >= limit)\n\n            k = limit;\n\n\n\n        if (k != 1) {\n\n            int extrabits = show_bits(gb, k);\n\n\n\n            /* multiply x by 2^k - 1, as part of their strange algorithm */\n\n            x = (x << k) - x;\n\n\n\n            if (extrabits > 1) {\n\n                x += extrabits - 1;\n\n                skip_bits(gb, k);\n\n            } else\n\n                skip_bits(gb, k - 1);\n\n        }\n\n    }\n\n    return x;\n\n}\n", "idx": 22296}
{"project": "FFmpeg", "commit_id": "315b0f974252120cfacb0346954a2d817dff279a", "target": 0, "func": "static void opt_b_frames(const char *arg)\n\n{\n\n    b_frames = atoi(arg);\n\n    if (b_frames > FF_MAX_B_FRAMES) {\n\n        fprintf(stderr, \"\\nCannot have more than %d B frames, increase FF_MAX_B_FRAMES.\\n\", FF_MAX_B_FRAMES);\n\n        exit(1);\n\n    } else if (b_frames < 1) {\n\n        fprintf(stderr, \"\\nNumber of B frames must be higher than 0\\n\");\n\n        exit(1);\n\n    }\n\n}\n", "idx": 22297}
{"project": "FFmpeg", "commit_id": "870ee6f71579f2f3f20dee93d6246d12871c280d", "target": 1, "func": "static av_cold int encode_init(AVCodecContext* avc_context)\n\n{\n\n    theora_info t_info;\n\n    theora_comment t_comment;\n\n    ogg_packet o_packet;\n\n    unsigned int offset;\n\n    TheoraContext *h = avc_context->priv_data;\n\n\n\n    /* Set up the theora_info struct */\n\n    theora_info_init( &t_info );\n\n    t_info.width = FFALIGN(avc_context->width, 16);\n\n    t_info.height = FFALIGN(avc_context->height, 16);\n\n    t_info.frame_width = avc_context->width;\n\n    t_info.frame_height = avc_context->height;\n\n    t_info.offset_x = 0;\n\n    t_info.offset_y = avc_context->height & 0xf;\n\n    /* Swap numerator and denominator as time_base in AVCodecContext gives the\n\n     * time period between frames, but theora_info needs the framerate.  */\n\n    t_info.fps_numerator = avc_context->time_base.den;\n\n    t_info.fps_denominator = avc_context->time_base.num;\n\n    if (avc_context->sample_aspect_ratio.num != 0) {\n\n        t_info.aspect_numerator = avc_context->sample_aspect_ratio.num;\n\n        t_info.aspect_denominator = avc_context->sample_aspect_ratio.den;\n\n    } else {\n\n        t_info.aspect_numerator = 1;\n\n        t_info.aspect_denominator = 1;\n\n    }\n\n    t_info.colorspace = OC_CS_UNSPECIFIED;\n\n    t_info.pixelformat = OC_PF_420;\n\n    t_info.target_bitrate = avc_context->bit_rate;\n\n    t_info.keyframe_frequency = avc_context->gop_size;\n\n    t_info.keyframe_frequency_force = avc_context->gop_size;\n\n    t_info.keyframe_mindistance = avc_context->keyint_min;\n\n    t_info.quality = 0;\n\n\n\n    t_info.quick_p = 1;\n\n    t_info.dropframes_p = 0;\n\n    t_info.keyframe_auto_p = 1;\n\n    t_info.keyframe_data_target_bitrate = t_info.target_bitrate * 1.5;\n\n    t_info.keyframe_auto_threshold = 80;\n\n    t_info.noise_sensitivity = 1;\n\n    t_info.sharpness = 0;\n\n\n\n    /* Now initialise libtheora */\n\n    if (theora_encode_init( &(h->t_state), &t_info ) != 0) {\n\n        av_log(avc_context, AV_LOG_ERROR, \"theora_encode_init failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* Clear up theora_info struct */\n\n    theora_info_clear( &t_info );\n\n\n\n    /*\n\n        Output first header packet consisting of theora\n\n        header, comment, and tables.\n\n\n\n        Each one is prefixed with a 16bit size, then they\n\n        are concatenated together into ffmpeg's extradata.\n\n    */\n\n    offset = 0;\n\n\n\n    /* Header */\n\n    theora_encode_header( &(h->t_state), &o_packet );\n\n    if (concatenate_packet( &offset, avc_context, &o_packet ) != 0) {\n\n        return -1;\n\n    }\n\n\n\n    /* Comment */\n\n    theora_comment_init( &t_comment );\n\n    theora_encode_comment( &t_comment, &o_packet );\n\n    if (concatenate_packet( &offset, avc_context, &o_packet ) != 0) {\n\n        return -1;\n\n    }\n\n\n\n    /* Tables */\n\n    theora_encode_tables( &(h->t_state), &o_packet );\n\n    if (concatenate_packet( &offset, avc_context, &o_packet ) != 0) {\n\n        return -1;\n\n    }\n\n\n\n    /* Clear up theora_comment struct */\n\n    theora_comment_clear( &t_comment );\n\n\n\n    /* Set up the output AVFrame */\n\n    avc_context->coded_frame= avcodec_alloc_frame();\n\n\n\n    return 0;\n\n}\n", "idx": 22298}
{"project": "FFmpeg", "commit_id": "2bb79b23fe106a45eab6ff80d7ef7519d542d1f7", "target": 1, "func": "static int frame_thread_init(AVCodecContext *avctx)\n\n{\n\n    int thread_count = avctx->thread_count;\n\n    AVCodec *codec = avctx->codec;\n\n    AVCodecContext *src = avctx;\n\n    FrameThreadContext *fctx;\n\n    int i, err = 0;\n\n\n\n    if (thread_count <= 1) {\n\n        avctx->active_thread_type = 0;\n\n        return 0;\n\n    }\n\n\n\n    avctx->thread_opaque = fctx = av_mallocz(sizeof(FrameThreadContext));\n\n\n\n    fctx->threads = av_mallocz(sizeof(PerThreadContext) * thread_count);\n\n    pthread_mutex_init(&fctx->buffer_mutex, NULL);\n\n    fctx->delaying = 1;\n\n\n\n    for (i = 0; i < thread_count; i++) {\n\n        AVCodecContext *copy = av_malloc(sizeof(AVCodecContext));\n\n        PerThreadContext *p  = &fctx->threads[i];\n\n\n\n        pthread_mutex_init(&p->mutex, NULL);\n\n        pthread_mutex_init(&p->progress_mutex, NULL);\n\n        pthread_cond_init(&p->input_cond, NULL);\n\n        pthread_cond_init(&p->progress_cond, NULL);\n\n        pthread_cond_init(&p->output_cond, NULL);\n\n\n\n        p->parent = fctx;\n\n        p->avctx  = copy;\n\n\n\n        if (!copy) {\n\n            err = AVERROR(ENOMEM);\n\n            goto error;\n\n        }\n\n\n\n        *copy = *src;\n\n        copy->thread_opaque = p;\n\n        copy->pkt = &p->avpkt;\n\n\n\n        if (!i) {\n\n            src = copy;\n\n\n\n            if (codec->init)\n\n                err = codec->init(copy);\n\n\n\n            update_context_from_thread(avctx, copy, 1);\n\n        } else {\n\n            copy->priv_data = av_malloc(codec->priv_data_size);\n\n            if (!copy->priv_data) {\n\n                err = AVERROR(ENOMEM);\n\n                goto error;\n\n            }\n\n            memcpy(copy->priv_data, src->priv_data, codec->priv_data_size);\n\n            copy->internal = av_malloc(sizeof(AVCodecInternal));\n\n            if (!copy->internal) {\n\n                err = AVERROR(ENOMEM);\n\n                goto error;\n\n            }\n\n            *(copy->internal) = *(src->internal);\n\n            copy->internal->is_copy = 1;\n\n\n\n            if (codec->init_thread_copy)\n\n                err = codec->init_thread_copy(copy);\n\n        }\n\n\n\n        if (err) goto error;\n\n\n\n        pthread_create(&p->thread, NULL, frame_worker_thread, p);\n\n    }\n\n\n\n    return 0;\n\n\n\nerror:\n\n    frame_thread_free(avctx, i+1);\n\n\n\n    return err;\n\n}\n", "idx": 22299}
{"project": "FFmpeg", "commit_id": "e1219cdaf9fb4bc8cea410e1caf802373c1bfe51", "target": 0, "func": "static char *shorts2str(int16_t *sp, int count, const char *sep)\n\n{\n\n    int i;\n\n    char *ap, *ap0;\n\n    if (!sep) sep = \", \";\n\n    ap = av_malloc((5 + strlen(sep)) * count);\n\n    if (!ap)\n\n        return NULL;\n\n    ap0   = ap;\n\n    ap[0] = '\\0';\n\n    for (i = 0; i < count; i++) {\n\n        int l = snprintf(ap, 5 + strlen(sep), \"%d%s\", sp[i], sep);\n\n        ap += l;\n\n    }\n\n    ap0[strlen(ap0) - strlen(sep)] = '\\0';\n\n    return ap0;\n\n}\n", "idx": 22301}
{"project": "FFmpeg", "commit_id": "4987faee78b9869f8f4646b8dd971d459df218a5", "target": 1, "func": "static int h264_set_parameter_from_sps(H264Context *h)\n{\n    if (h->flags & CODEC_FLAG_LOW_DELAY ||\n        (h->sps.bitstream_restriction_flag &&\n         !h->sps.num_reorder_frames)) {\n        if (h->avctx->has_b_frames > 1 || h->delayed_pic[0])\n            av_log(h->avctx, AV_LOG_WARNING, \"Delayed frames seen. \"\n                   \"Reenabling low delay requires a codec flush.\\n\");\n        else\n            h->low_delay = 1;\n    if (h->avctx->has_b_frames < 2)\n        h->avctx->has_b_frames = !h->low_delay;\n    if (h->avctx->bits_per_raw_sample != h->sps.bit_depth_luma ||\n        h->cur_chroma_format_idc      != h->sps.chroma_format_idc) {\n        if (h->avctx->codec &&\n            h->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU &&\n            (h->sps.bit_depth_luma != 8 || h->sps.chroma_format_idc > 1)) {\n            av_log(h->avctx, AV_LOG_ERROR,\n                   \"VDPAU decoding does not support video colorspace.\\n\");\n            return AVERROR_INVALIDDATA;\n        if (h->sps.bit_depth_luma >= 8 && h->sps.bit_depth_luma <= 10) {\n            h->avctx->bits_per_raw_sample = h->sps.bit_depth_luma;\n            h->cur_chroma_format_idc      = h->sps.chroma_format_idc;\n            h->pixel_shift                = h->sps.bit_depth_luma > 8;\n            ff_h264dsp_init(&h->h264dsp, h->sps.bit_depth_luma,\n                            h->sps.chroma_format_idc);\n            ff_h264chroma_init(&h->h264chroma, h->sps.bit_depth_chroma);\n            ff_h264qpel_init(&h->h264qpel, h->sps.bit_depth_luma);\n            ff_h264_pred_init(&h->hpc, h->avctx->codec_id, h->sps.bit_depth_luma,\n                              h->sps.chroma_format_idc);\n            h->dsp.dct_bits = h->sps.bit_depth_luma > 8 ? 32 : 16;\n            ff_dsputil_init(&h->dsp, h->avctx);\n            ff_videodsp_init(&h->vdsp, h->sps.bit_depth_luma);\n        } else {\n            av_log(h->avctx, AV_LOG_ERROR, \"Unsupported bit depth: %d\\n\",\n                   h->sps.bit_depth_luma);\n            return AVERROR_INVALIDDATA;\n    return 0;", "idx": 22302}
{"project": "FFmpeg", "commit_id": "aba232cfa9b193604ed98f3fa505378d006b1b3b", "target": 1, "func": "int ff_raw_video_read_header(AVFormatContext *s)\n\n{\n\n    AVStream *st;\n\n    FFRawVideoDemuxerContext *s1 = s->priv_data;\n\n    AVRational framerate;\n\n    int ret = 0;\n\n\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id = s->iformat->raw_codec_id;\n\n    st->need_parsing = AVSTREAM_PARSE_FULL;\n\n\n\n    if ((ret = av_parse_video_rate(&framerate, s1->framerate)) < 0) {\n\n        av_log(s, AV_LOG_ERROR, \"Could not parse framerate: %s.\\n\", s1->framerate);\n\n        goto fail;\n\n    }\n\n\n\n    st->r_frame_rate = st->avg_frame_rate = framerate;\n\n    avpriv_set_pts_info(st, 64, framerate.den, framerate.num);\n\n\n\nfail:\n\n    return ret;\n\n}\n", "idx": 22304}
{"project": "FFmpeg", "commit_id": "b1d61eb7aaaef84391130b6f5e83942cc829a8c8", "target": 1, "func": "static int mov_read_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    MOVContext *mov = s->priv_data;\n    MOVStreamContext *sc;\n    AVIndexEntry *sample;\n    AVStream *st = NULL;\n    int ret;\n    mov->fc = s;\n retry:\n    sample = mov_find_next_sample(s, &st);\n    if (!sample) {\n        mov->found_mdat = 0;\n        if (!mov->next_root_atom)\n            return AVERROR_EOF;\n        avio_seek(s->pb, mov->next_root_atom, SEEK_SET);\n        mov->next_root_atom = 0;\n        if (mov_read_default(mov, s->pb, (MOVAtom){ AV_RL32(\"root\"), INT64_MAX }) < 0 ||\n            url_feof(s->pb))\n            return AVERROR_EOF;\n        av_dlog(s, \"read fragments, offset 0x%\"PRIx64\"\\n\", avio_tell(s->pb));\n        goto retry;\n    sc = st->priv_data;\n    /* must be done just before reading, to avoid infinite loop on sample */\n    sc->current_sample++;\n    if (st->discard != AVDISCARD_ALL) {\n        if (avio_seek(sc->pb, sample->pos, SEEK_SET) != sample->pos) {\n            av_log(mov->fc, AV_LOG_ERROR, \"stream %d, offset 0x%\"PRIx64\": partial file\\n\",\n                   sc->ffindex, sample->pos);\n            return AVERROR_INVALIDDATA;\n        ret = av_get_packet(sc->pb, pkt, sample->size);\n        if (ret < 0)\n            return ret;\n        if (sc->has_palette) {\n            uint8_t *pal;\n            pal = av_packet_new_side_data(pkt, AV_PKT_DATA_PALETTE, AVPALETTE_SIZE);\n            if (!pal) {\n                av_log(mov->fc, AV_LOG_ERROR, \"Cannot append palette to packet\\n\");\n            } else {\n                memcpy(pal, sc->palette, AVPALETTE_SIZE);\n                sc->has_palette = 0;\n#if CONFIG_DV_DEMUXER\n        if (mov->dv_demux && sc->dv_audio_container) {\n            avpriv_dv_produce_packet(mov->dv_demux, pkt, pkt->data, pkt->size, pkt->pos);\n            av_free(pkt->data);\n            pkt->size = 0;\n            ret = avpriv_dv_get_packet(mov->dv_demux, pkt);\n            if (ret < 0)\n                return ret;\n#endif\n    pkt->stream_index = sc->ffindex;\n    pkt->dts = sample->timestamp;\n    if (sc->ctts_data && sc->ctts_index < sc->ctts_count) {\n        pkt->pts = pkt->dts + sc->dts_shift + sc->ctts_data[sc->ctts_index].duration;\n        /* update ctts context */\n        sc->ctts_sample++;\n        if (sc->ctts_index < sc->ctts_count &&\n            sc->ctts_data[sc->ctts_index].count == sc->ctts_sample) {\n            sc->ctts_index++;\n            sc->ctts_sample = 0;\n        if (sc->wrong_dts)\n            pkt->dts = AV_NOPTS_VALUE;\n    } else {\n        int64_t next_dts = (sc->current_sample < st->nb_index_entries) ?\n            st->index_entries[sc->current_sample].timestamp : st->duration;\n        pkt->duration = next_dts - pkt->dts;\n        pkt->pts = pkt->dts;\n    if (st->discard == AVDISCARD_ALL)\n        goto retry;\n    pkt->flags |= sample->flags & AVINDEX_KEYFRAME ? AV_PKT_FLAG_KEY : 0;\n    pkt->pos = sample->pos;\n    av_dlog(s, \"stream %d, pts %\"PRId64\", dts %\"PRId64\", pos 0x%\"PRIx64\", duration %d\\n\",\n            pkt->stream_index, pkt->pts, pkt->dts, pkt->pos, pkt->duration);\n    return 0;", "idx": 22305}
{"project": "FFmpeg", "commit_id": "ecff5acb5a738fcb4f9e206a12070dac4bf259b3", "target": 1, "func": "static int svq1_motion_inter_4v_block(DSPContext *dsp, GetBitContext *bitbuf,\n\n                                      uint8_t *current, uint8_t *previous,\n\n                                      int pitch, svq1_pmv *motion, int x, int y)\n\n{\n\n    uint8_t *src;\n\n    uint8_t *dst;\n\n    svq1_pmv mv;\n\n    svq1_pmv *pmv[4];\n\n    int i, result;\n\n\n\n    /* predict and decode motion vector (0) */\n\n    pmv[0] = &motion[0];\n\n    if (y == 0) {\n\n        pmv[1] =\n\n        pmv[2] = pmv[0];\n\n    } else {\n\n        pmv[1] = &motion[(x / 8) + 2];\n\n        pmv[2] = &motion[(x / 8) + 4];\n\n    }\n\n\n\n    result = svq1_decode_motion_vector(bitbuf, &mv, pmv);\n\n\n\n    if (result != 0)\n\n        return result;\n\n\n\n    /* predict and decode motion vector (1) */\n\n    pmv[0] = &mv;\n\n    if (y == 0) {\n\n        pmv[1] =\n\n        pmv[2] = pmv[0];\n\n    } else {\n\n        pmv[1] = &motion[(x / 8) + 3];\n\n    }\n\n    result = svq1_decode_motion_vector(bitbuf, &motion[0], pmv);\n\n\n\n    if (result != 0)\n\n        return result;\n\n\n\n    /* predict and decode motion vector (2) */\n\n    pmv[1] = &motion[0];\n\n    pmv[2] = &motion[(x / 8) + 1];\n\n\n\n    result = svq1_decode_motion_vector(bitbuf, &motion[(x / 8) + 2], pmv);\n\n\n\n    if (result != 0)\n\n        return result;\n\n\n\n    /* predict and decode motion vector (3) */\n\n    pmv[2] = &motion[(x / 8) + 2];\n\n    pmv[3] = &motion[(x / 8) + 3];\n\n\n\n    result = svq1_decode_motion_vector(bitbuf, pmv[3], pmv);\n\n\n\n    if (result != 0)\n\n        return result;\n\n\n\n    /* form predictions */\n\n    for (i = 0; i < 4; i++) {\n\n        int mvx = pmv[i]->x + (i  & 1) * 16;\n\n        int mvy = pmv[i]->y + (i >> 1) * 16;\n\n\n\n        // FIXME: clipping or padding?\n\n        if (y + (mvy >> 1) < 0)\n\n            mvy = 0;\n\n        if (x + (mvx >> 1) < 0)\n\n            mvx = 0;\n\n\n\n        src = &previous[(x + (mvx >> 1)) + (y + (mvy >> 1)) * pitch];\n\n        dst = current;\n\n\n\n        dsp->put_pixels_tab[1][((mvy & 1) << 1) | (mvx & 1)](dst, src, pitch, 8);\n\n\n\n        /* select next block */\n\n        if (i & 1)\n\n            current += 8 * (pitch - 1);\n\n        else\n\n            current += 8;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22308}
{"project": "FFmpeg", "commit_id": "628b48db85dae7ad212a63dafcd6a3bf8d8e93f3", "target": 0, "func": "static av_always_inline void idct_mb(VP8Context *s, uint8_t *dst[3], VP8Macroblock *mb)\n\n{\n\n    int x, y, ch;\n\n\n\n    if (mb->mode != MODE_I4x4) {\n\n        uint8_t *y_dst = dst[0];\n\n        for (y = 0; y < 4; y++) {\n\n            uint32_t nnz4 = AV_RL32(s->non_zero_count_cache[y]);\n\n            if (nnz4) {\n\n                if (nnz4&~0x01010101) {\n\n                    for (x = 0; x < 4; x++) {\n\n                        if ((uint8_t)nnz4 == 1)\n\n                            s->vp8dsp.vp8_idct_dc_add(y_dst+4*x, s->block[y][x], s->linesize);\n\n                        else if((uint8_t)nnz4 > 1)\n\n                            s->vp8dsp.vp8_idct_add(y_dst+4*x, s->block[y][x], s->linesize);\n\n                        nnz4 >>= 8;\n\n                        if (!nnz4)\n\n                            break;\n\n                    }\n\n                } else {\n\n                    s->vp8dsp.vp8_idct_dc_add4y(y_dst, s->block[y], s->linesize);\n\n                }\n\n            }\n\n            y_dst += 4*s->linesize;\n\n        }\n\n    }\n\n\n\n    for (ch = 0; ch < 2; ch++) {\n\n        uint32_t nnz4 = AV_RL32(s->non_zero_count_cache[4+ch]);\n\n        if (nnz4) {\n\n            uint8_t *ch_dst = dst[1+ch];\n\n            if (nnz4&~0x01010101) {\n\n                for (y = 0; y < 2; y++) {\n\n                    for (x = 0; x < 2; x++) {\n\n                        if ((uint8_t)nnz4 == 1)\n\n                            s->vp8dsp.vp8_idct_dc_add(ch_dst+4*x, s->block[4+ch][(y<<1)+x], s->uvlinesize);\n\n                        else if((uint8_t)nnz4 > 1)\n\n                            s->vp8dsp.vp8_idct_add(ch_dst+4*x, s->block[4+ch][(y<<1)+x], s->uvlinesize);\n\n                        nnz4 >>= 8;\n\n                        if (!nnz4)\n\n                            break;\n\n                    }\n\n                    ch_dst += 4*s->uvlinesize;\n\n                }\n\n            } else {\n\n                s->vp8dsp.vp8_idct_dc_add4uv(ch_dst, s->block[4+ch], s->uvlinesize);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 22312}
{"project": "FFmpeg", "commit_id": "c5d4f87e81111427c0952278ec247fa8ab1e6e52", "target": 1, "func": "static av_always_inline float quantize_and_encode_band_cost_template(\n\n                                struct AACEncContext *s,\n\n                                PutBitContext *pb, const float *in,\n\n                                const float *scaled, int size, int scale_idx,\n\n                                int cb, const float lambda, const float uplim,\n\n                                int *bits, int BT_ZERO, int BT_UNSIGNED,\n\n                                int BT_PAIR, int BT_ESC)\n\n{\n\n    const int q_idx = POW_SF2_ZERO - scale_idx + SCALE_ONE_POS - SCALE_DIV_512;\n\n    const float Q   = ff_aac_pow2sf_tab [q_idx];\n\n    const float Q34 = ff_aac_pow34sf_tab[q_idx];\n\n    const float IQ  = ff_aac_pow2sf_tab [POW_SF2_ZERO + scale_idx - SCALE_ONE_POS + SCALE_DIV_512];\n\n    const float CLIPPED_ESCAPE = 165140.0f*IQ;\n\n    int i, j;\n\n    float cost = 0;\n\n    const int dim = BT_PAIR ? 2 : 4;\n\n    int resbits = 0;\n\n    const int range  = aac_cb_range[cb];\n\n    const int maxval = aac_cb_maxval[cb];\n\n    int off;\n\n\n\n    if (BT_ZERO) {\n\n        for (i = 0; i < size; i++)\n\n            cost += in[i]*in[i];\n\n        if (bits)\n\n            *bits = 0;\n\n        return cost * lambda;\n\n    }\n\n    if (!scaled) {\n\n        abs_pow34_v(s->scoefs, in, size);\n\n        scaled = s->scoefs;\n\n    }\n\n    quantize_bands(s->qcoefs, in, scaled, size, Q34, !BT_UNSIGNED, maxval);\n\n    if (BT_UNSIGNED) {\n\n        off = 0;\n\n    } else {\n\n        off = maxval;\n\n    }\n\n    for (i = 0; i < size; i += dim) {\n\n        const float *vec;\n\n        int *quants = s->qcoefs + i;\n\n        int curidx = 0;\n\n        int curbits;\n\n        float rd = 0.0f;\n\n        for (j = 0; j < dim; j++) {\n\n            curidx *= range;\n\n            curidx += quants[j] + off;\n\n        }\n\n        curbits =  ff_aac_spectral_bits[cb-1][curidx];\n\n        vec     = &ff_aac_codebook_vectors[cb-1][curidx*dim];\n\n        if (BT_UNSIGNED) {\n\n            for (j = 0; j < dim; j++) {\n\n                float t = fabsf(in[i+j]);\n\n                float di;\n\n                if (BT_ESC && vec[j] == 64.0f) { //FIXME: slow\n\n                    if (t >= CLIPPED_ESCAPE) {\n\n                        di = t - CLIPPED_ESCAPE;\n\n                        curbits += 21;\n\n                    } else {\n\n                        int c = av_clip_uintp2(quant(t, Q), 13);\n\n                        di = t - c*cbrtf(c)*IQ;\n\n                        curbits += av_log2(c)*2 - 4 + 1;\n\n                    }\n\n                } else {\n\n                    di = t - vec[j]*IQ;\n\n                }\n\n                if (vec[j] != 0.0f)\n\n                    curbits++;\n\n                rd += di*di;\n\n            }\n\n        } else {\n\n            for (j = 0; j < dim; j++) {\n\n                float di = in[i+j] - vec[j]*IQ;\n\n                rd += di*di;\n\n            }\n\n        }\n\n        cost    += rd * lambda + curbits;\n\n        resbits += curbits;\n\n        if (cost >= uplim)\n\n            return uplim;\n\n        if (pb) {\n\n            put_bits(pb, ff_aac_spectral_bits[cb-1][curidx], ff_aac_spectral_codes[cb-1][curidx]);\n\n            if (BT_UNSIGNED)\n\n                for (j = 0; j < dim; j++)\n\n                    if (ff_aac_codebook_vectors[cb-1][curidx*dim+j] != 0.0f)\n\n                        put_bits(pb, 1, in[i+j] < 0.0f);\n\n            if (BT_ESC) {\n\n                for (j = 0; j < 2; j++) {\n\n                    if (ff_aac_codebook_vectors[cb-1][curidx*2+j] == 64.0f) {\n\n                        int coef = av_clip_uintp2(quant(fabsf(in[i+j]), Q), 13);\n\n                        int len = av_log2(coef);\n\n\n\n                        put_bits(pb, len - 4 + 1, (1 << (len - 4 + 1)) - 2);\n\n                        put_bits(pb, len, coef & ((1 << len) - 1));\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    if (bits)\n\n        *bits = resbits;\n\n    return cost;\n\n}\n", "idx": 22313}
{"project": "FFmpeg", "commit_id": "5952b8da0b7f65dfa23991e71737e0abdaeb339c", "target": 1, "func": "static int seek_test(const char *input_filename, const char *start, const char *end)\n\n{\n\n    AVCodec *codec = NULL;\n\n    AVCodecContext *ctx= NULL;\n\n    AVCodecParameters *origin_par = NULL;\n\n    AVFrame *fr = NULL;\n\n    AVFormatContext *fmt_ctx = NULL;\n\n    int video_stream;\n\n    int result;\n\n    int i, j;\n\n    long int start_ts, end_ts;\n\n\n\n    size_of_array = 0;\n\n    number_of_elements = 0;\n\n    crc_array = pts_array = NULL;\n\n\n\n    result = avformat_open_input(&fmt_ctx, input_filename, NULL, NULL);\n\n    if (result < 0) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Can't open file\\n\");\n\n        return result;\n\n    }\n\n\n\n    result = avformat_find_stream_info(fmt_ctx, NULL);\n\n    if (result < 0) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Can't get stream info\\n\");\n\n        return result;\n\n    }\n\n\n\n    start_ts = read_seek_range(start);\n\n    end_ts = read_seek_range(end);\n\n    if ((start_ts < 0) || (end_ts < 0))\n\n        return -1;\n\n\n\n    //TODO: add ability to work with audio format\n\n    video_stream = av_find_best_stream(fmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0);\n\n    if (video_stream < 0) {\n\n      av_log(NULL, AV_LOG_ERROR, \"Can't find video stream in input file\\n\");\n\n      return -1;\n\n    }\n\n\n\n    origin_par = fmt_ctx->streams[video_stream]->codecpar;\n\n\n\n    codec = avcodec_find_decoder(origin_par->codec_id);\n\n    if (!codec) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Can't find decoder\\n\");\n\n        return -1;\n\n    }\n\n\n\n    ctx = avcodec_alloc_context3(codec);\n\n    if (!ctx) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Can't allocate decoder context\\n\");\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    result = avcodec_parameters_to_context(ctx, origin_par);\n\n    if (result) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Can't copy decoder context\\n\");\n\n        return result;\n\n    }\n\n\n\n    result = avcodec_open2(ctx, codec, NULL);\n\n    if (result < 0) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Can't open decoder\\n\");\n\n        return result;\n\n    }\n\n\n\n    fr = av_frame_alloc();\n\n    if (!fr) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Can't allocate frame\\n\");\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    result = compute_crc_of_packets(fmt_ctx, video_stream, ctx, fr, i, j, 1);\n\n    if (result != 0)\n\n        return -1;\n\n\n\n    for (i = start_ts; i < end_ts; i += 100) {\n\n        for (j = i + 100; j < end_ts; j += 100)\n\n        result = compute_crc_of_packets(fmt_ctx, video_stream, ctx, fr, i, j, 0);\n\n        if (result != 0)\n\n            return -1;\n\n    }\n\n\n\n    av_freep(&crc_array);\n\n    av_freep(&pts_array);\n\n    av_frame_free(&fr);\n\n    avcodec_close(ctx);\n\n    avformat_close_input(&fmt_ctx);\n\n    avcodec_free_context(&ctx);\n\n    return 0;\n\n}\n", "idx": 22316}
{"project": "FFmpeg", "commit_id": "90540c2d5ace46a1e9789c75fde0b1f7dbb12a9b", "target": 1, "func": "static inline void RENAME(rgb15to16)(const uint8_t *src, uint8_t *dst, int src_size)\n\n{\n\n    register const uint8_t* s=src;\n\n    register uint8_t* d=dst;\n\n    register const uint8_t *end;\n\n    const uint8_t *mm_end;\n\n    end = s + src_size;\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*s));\n\n    __asm__ volatile(\"movq        %0, %%mm4\"::\"m\"(mask15s));\n\n    mm_end = end - 15;\n\n    while (s<mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"  32%1         \\n\\t\"\n\n            \"movq        %1, %%mm0  \\n\\t\"\n\n            \"movq       8%1, %%mm2  \\n\\t\"\n\n            \"movq     %%mm0, %%mm1  \\n\\t\"\n\n            \"movq     %%mm2, %%mm3  \\n\\t\"\n\n            \"pand     %%mm4, %%mm0  \\n\\t\"\n\n            \"pand     %%mm4, %%mm2  \\n\\t\"\n\n            \"paddw    %%mm1, %%mm0  \\n\\t\"\n\n            \"paddw    %%mm3, %%mm2  \\n\\t\"\n\n            MOVNTQ\"   %%mm0,  %0    \\n\\t\"\n\n            MOVNTQ\"   %%mm2, 8%0\"\n\n            :\"=m\"(*d)\n\n            :\"m\"(*s)\n\n        );\n\n        d+=16;\n\n        s+=16;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n    mm_end = end - 3;\n\n    while (s < mm_end) {\n\n        register unsigned x= *((const uint32_t *)s);\n\n        *((uint32_t *)d) = (x&0x7FFF7FFF) + (x&0x7FE07FE0);\n\n        d+=4;\n\n        s+=4;\n\n    }\n\n    if (s < end) {\n\n        register unsigned short x= *((const uint16_t *)s);\n\n        *((uint16_t *)d) = (x&0x7FFF) + (x&0x7FE0);\n\n    }\n\n}\n", "idx": 22317}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "static inline void RENAME(rgb15to32)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n\tconst uint16_t *end;\n\n#ifdef HAVE_MMX\n\n\tconst uint16_t *mm_end;\n\n#endif\n\n\tuint8_t *d = (uint8_t *)dst;\n\n\tconst uint16_t *s = (const uint16_t *)src;\n\n\tend = s + src_size/2;\n\n#ifdef HAVE_MMX\n\n\t__asm __volatile(PREFETCH\"\t%0\"::\"m\"(*s):\"memory\");\n\n\t__asm __volatile(\"pxor\t%%mm7,%%mm7\\n\\t\":::\"memory\");\n\n\tmm_end = end - 3;\n\n\twhile(s < mm_end)\n\n\t{\n\n\t    __asm __volatile(\n\n\t\tPREFETCH\" 32%1\\n\\t\"\n\n\t\t\"movq\t%1, %%mm0\\n\\t\"\n\n\t\t\"movq\t%1, %%mm1\\n\\t\"\n\n\t\t\"movq\t%1, %%mm2\\n\\t\"\n\n\t\t\"pand\t%2, %%mm0\\n\\t\"\n\n\t\t\"pand\t%3, %%mm1\\n\\t\"\n\n\t\t\"pand\t%4, %%mm2\\n\\t\"\n\n\t\t\"psllq\t$3, %%mm0\\n\\t\"\n\n\t\t\"psrlq\t$2, %%mm1\\n\\t\"\n\n\t\t\"psrlq\t$7, %%mm2\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm3\\n\\t\"\n\n\t\t\"movq\t%%mm1, %%mm4\\n\\t\"\n\n\t\t\"movq\t%%mm2, %%mm5\\n\\t\"\n\n\t\t\"punpcklwd %%mm7, %%mm0\\n\\t\"\n\n\t\t\"punpcklwd %%mm7, %%mm1\\n\\t\"\n\n\t\t\"punpcklwd %%mm7, %%mm2\\n\\t\"\n\n\t\t\"punpckhwd %%mm7, %%mm3\\n\\t\"\n\n\t\t\"punpckhwd %%mm7, %%mm4\\n\\t\"\n\n\t\t\"punpckhwd %%mm7, %%mm5\\n\\t\"\n\n\t\t\"psllq\t$8, %%mm1\\n\\t\"\n\n\t\t\"psllq\t$16, %%mm2\\n\\t\"\n\n\t\t\"por\t%%mm1, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm2, %%mm0\\n\\t\"\n\n\t\t\"psllq\t$8, %%mm4\\n\\t\"\n\n\t\t\"psllq\t$16, %%mm5\\n\\t\"\n\n\t\t\"por\t%%mm4, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm5, %%mm3\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm3, 8%0\\n\\t\"\n\n\t\t:\"=m\"(*d)\n\n\t\t:\"m\"(*s),\"m\"(mask15b),\"m\"(mask15g),\"m\"(mask15r)\n\n\t\t:\"memory\");\n\n\t\td += 16;\n\n\t\ts += 4;\n\n\t}\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\twhile(s < end)\n\n\t{\n\n#if 0 //slightly slower on athlon\n\n\t\tint bgr= *s++;\n\n\t\t*((uint32_t*)d)++ = ((bgr&0x1F)<<3) + ((bgr&0x3E0)<<6) + ((bgr&0x7C00)<<9);\n\n#else\n\n\t\tregister uint16_t bgr;\n\n\t\tbgr = *s++;\n\n#ifdef WORDS_BIGENDIAN\n\n\t\t*d++ = 0;\n\n\t\t*d++ = (bgr&0x7C00)>>7;\n\n\t\t*d++ = (bgr&0x3E0)>>2;\n\n\t\t*d++ = (bgr&0x1F)<<3;\n\n#else\n\n\t\t*d++ = (bgr&0x1F)<<3;\n\n\t\t*d++ = (bgr&0x3E0)>>2;\n\n\t\t*d++ = (bgr&0x7C00)>>7;\n\n\t\t*d++ = 0;\n\n#endif\n\n\n\n#endif\n\n\t}\n\n}\n", "idx": 22318}
{"project": "FFmpeg", "commit_id": "ac4b32df71bd932838043a4838b86d11e169707f", "target": 1, "func": "int decode_splitmvs(VP8Context *s, VP56RangeCoder *c, VP8Macroblock *mb, int layout)\n\n{\n\n    int part_idx;\n\n    int n, num;\n\n    VP8Macroblock *top_mb;\n\n    VP8Macroblock *left_mb = &mb[-1];\n\n    const uint8_t *mbsplits_left = vp8_mbsplits[left_mb->partitioning];\n\n    const uint8_t *mbsplits_top, *mbsplits_cur, *firstidx;\n\n    VP56mv *top_mv;\n\n    VP56mv *left_mv = left_mb->bmv;\n\n    VP56mv *cur_mv  = mb->bmv;\n\n\n\n    if (!layout) // layout is inlined, s->mb_layout is not\n\n        top_mb = &mb[2];\n\n    else\n\n        top_mb = &mb[-s->mb_width - 1];\n\n    mbsplits_top = vp8_mbsplits[top_mb->partitioning];\n\n    top_mv       = top_mb->bmv;\n\n\n\n    if (vp56_rac_get_prob_branchy(c, vp8_mbsplit_prob[0])) {\n\n        if (vp56_rac_get_prob_branchy(c, vp8_mbsplit_prob[1]))\n\n            part_idx = VP8_SPLITMVMODE_16x8 + vp56_rac_get_prob(c, vp8_mbsplit_prob[2]);\n\n        else\n\n            part_idx = VP8_SPLITMVMODE_8x8;\n\n    } else {\n\n        part_idx = VP8_SPLITMVMODE_4x4;\n\n    }\n\n\n\n    num              = vp8_mbsplit_count[part_idx];\n\n    mbsplits_cur     = vp8_mbsplits[part_idx],\n\n    firstidx         = vp8_mbfirstidx[part_idx];\n\n    mb->partitioning = part_idx;\n\n\n\n    for (n = 0; n < num; n++) {\n\n        int k = firstidx[n];\n\n        uint32_t left, above;\n\n        const uint8_t *submv_prob;\n\n\n\n        if (!(k & 3))\n\n            left = AV_RN32A(&left_mv[mbsplits_left[k + 3]]);\n\n        else\n\n            left = AV_RN32A(&cur_mv[mbsplits_cur[k - 1]]);\n\n        if (k <= 3)\n\n            above = AV_RN32A(&top_mv[mbsplits_top[k + 12]]);\n\n        else\n\n            above = AV_RN32A(&cur_mv[mbsplits_cur[k - 4]]);\n\n\n\n        submv_prob = get_submv_prob(left, above);\n\n\n\n        if (vp56_rac_get_prob_branchy(c, submv_prob[0])) {\n\n            if (vp56_rac_get_prob_branchy(c, submv_prob[1])) {\n\n                if (vp56_rac_get_prob_branchy(c, submv_prob[2])) {\n\n                    mb->bmv[n].y = mb->mv.y + read_mv_component(c, s->prob->mvc[0]);\n\n                    mb->bmv[n].x = mb->mv.x + read_mv_component(c, s->prob->mvc[1]);\n\n                } else {\n\n                    AV_ZERO32(&mb->bmv[n]);\n\n                }\n\n            } else {\n\n                AV_WN32A(&mb->bmv[n], above);\n\n            }\n\n        } else {\n\n            AV_WN32A(&mb->bmv[n], left);\n\n        }\n\n    }\n\n\n\n    return num;\n\n}\n", "idx": 22320}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "static inline void FUNC(idctSparseColPut)(pixel *dest, int line_size,\n\n                                          DCTELEM *col)\n\n{\n\n    int a0, a1, a2, a3, b0, b1, b2, b3;\n\n    INIT_CLIP;\n\n\n\n    IDCT_COLS;\n\n\n\n    dest[0] = CLIP((a0 + b0) >> COL_SHIFT);\n\n    dest += line_size;\n\n    dest[0] = CLIP((a1 + b1) >> COL_SHIFT);\n\n    dest += line_size;\n\n    dest[0] = CLIP((a2 + b2) >> COL_SHIFT);\n\n    dest += line_size;\n\n    dest[0] = CLIP((a3 + b3) >> COL_SHIFT);\n\n    dest += line_size;\n\n    dest[0] = CLIP((a3 - b3) >> COL_SHIFT);\n\n    dest += line_size;\n\n    dest[0] = CLIP((a2 - b2) >> COL_SHIFT);\n\n    dest += line_size;\n\n    dest[0] = CLIP((a1 - b1) >> COL_SHIFT);\n\n    dest += line_size;\n\n    dest[0] = CLIP((a0 - b0) >> COL_SHIFT);\n\n}\n", "idx": 22321}
{"project": "FFmpeg", "commit_id": "62b1e3b1031e901105d78e831120de8e4c3e0013", "target": 1, "func": "static int aasc_decode_frame(AVCodecContext *avctx,\n\n                              void *data, int *got_frame,\n\n                              AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    AascContext *s     = avctx->priv_data;\n\n    int compr, i, stride, ret;\n\n\n\n    if (buf_size < 4)\n\n\n\n\n    if ((ret = ff_reget_buffer(avctx, s->frame)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n\n\n    compr     = AV_RL32(buf);\n\n    buf      += 4;\n\n    buf_size -= 4;\n\n    switch (compr) {\n\n    case 0:\n\n        stride = (avctx->width * 3 + 3) & ~3;\n\n\n\n        for (i = avctx->height - 1; i >= 0; i--) {\n\n            memcpy(s->frame->data[0] + i * s->frame->linesize[0], buf, avctx->width * 3);\n\n            buf += stride;\n\n        }\n\n        break;\n\n    case 1:\n\n        bytestream2_init(&s->gb, buf, buf_size);\n\n        ff_msrle_decode(avctx, (AVPicture*)s->frame, 8, &s->gb);\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown compression type %d\\n\", compr);\n\n\n    }\n\n\n\n    *got_frame = 1;\n\n    if ((ret = av_frame_ref(data, s->frame)) < 0)\n\n        return ret;\n\n\n\n    /* report that the buffer was completely consumed */\n\n    return buf_size;\n\n}", "idx": 22324}
{"project": "FFmpeg", "commit_id": "311107a65d0105044d1691b5e85d6f30879b0eb4", "target": 0, "func": "int check_codec_match(AVCodecContext *ccf, AVCodecContext *ccs, int stream)\n\n{\n\n    int matches = 1;\n\n\n\n#define CHECK_CODEC(x)  (ccf->x != ccs->x)\n\n    if (CHECK_CODEC(codec_id) || CHECK_CODEC(codec_type)) {\n\n        http_log(\"Codecs do not match for stream %d\\n\", stream);\n\n        matches = 0;\n\n    } else if (CHECK_CODEC(bit_rate) || CHECK_CODEC(flags)) {\n\n        http_log(\"Codec bitrates do not match for stream %d\\n\", stream);\n\n        matches = 0;\n\n    } else if (ccf->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n        if (CHECK_CODEC(time_base.den) ||\n\n            CHECK_CODEC(time_base.num) ||\n\n            CHECK_CODEC(width) ||\n\n            CHECK_CODEC(height)) {\n\n            http_log(\"Codec width, height or framerate do not match for stream %d\\n\", stream);\n\n            matches = 0;\n\n        }\n\n    } else if (ccf->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n        if (CHECK_CODEC(sample_rate) ||\n\n            CHECK_CODEC(channels) ||\n\n            CHECK_CODEC(frame_size)) {\n\n            http_log(\"Codec sample_rate, channels, frame_size do not match for stream %d\\n\", stream);\n\n            matches = 0;\n\n        }\n\n    } else {\n\n        http_log(\"Unknown codec type for stream %d\\n\", stream);\n\n        matches = 0;\n\n    }\n\n\n\n    return matches;\n\n}\n", "idx": 22332}
{"project": "FFmpeg", "commit_id": "fbdb2059684ff27be61cfe40446e68cb2f9a12f8", "target": 0, "func": "static int encode_init(AVCodecContext * avctx){\n\n    WMACodecContext *s = avctx->priv_data;\n\n    int i, flags1, flags2;\n\n    uint8_t *extradata;\n\n\n\n    s->avctx = avctx;\n\n\n\n    if(avctx->channels > MAX_CHANNELS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"too many channels: got %i, need %i or fewer\",\n\n               avctx->channels, MAX_CHANNELS);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (avctx->sample_rate > 48000) {\n\n        av_log(avctx, AV_LOG_ERROR, \"sample rate is too high: %d > 48kHz\",\n\n               avctx->sample_rate);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if(avctx->bit_rate < 24*1000) {\n\n        av_log(avctx, AV_LOG_ERROR, \"bitrate too low: got %i, need 24000 or higher\\n\",\n\n               avctx->bit_rate);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    /* extract flag infos */\n\n    flags1 = 0;\n\n    flags2 = 1;\n\n    if (avctx->codec->id == CODEC_ID_WMAV1) {\n\n        extradata= av_malloc(4);\n\n        avctx->extradata_size= 4;\n\n        AV_WL16(extradata, flags1);\n\n        AV_WL16(extradata+2, flags2);\n\n    } else if (avctx->codec->id == CODEC_ID_WMAV2) {\n\n        extradata= av_mallocz(10);\n\n        avctx->extradata_size= 10;\n\n        AV_WL32(extradata, flags1);\n\n        AV_WL16(extradata+4, flags2);\n\n    }else\n\n        av_assert0(0);\n\n    avctx->extradata= extradata;\n\n    s->use_exp_vlc = flags2 & 0x0001;\n\n    s->use_bit_reservoir = flags2 & 0x0002;\n\n    s->use_variable_block_len = flags2 & 0x0004;\n\n    if (avctx->channels == 2)\n\n        s->ms_stereo = 1;\n\n\n\n    ff_wma_init(avctx, flags2);\n\n\n\n    /* init MDCT */\n\n    for(i = 0; i < s->nb_block_sizes; i++)\n\n        ff_mdct_init(&s->mdct_ctx[i], s->frame_len_bits - i + 1, 0, 1.0);\n\n\n\n    s->block_align     = avctx->bit_rate * (int64_t)s->frame_len /\n\n                         (avctx->sample_rate * 8);\n\n    s->block_align     = FFMIN(s->block_align, MAX_CODED_SUPERFRAME_SIZE);\n\n    avctx->block_align = s->block_align;\n\n    avctx->bit_rate    = avctx->block_align * 8LL * avctx->sample_rate /\n\n                         s->frame_len;\n\n//av_log(NULL, AV_LOG_ERROR, \"%d %d %d %d\\n\", s->block_align, avctx->bit_rate, s->frame_len, avctx->sample_rate);\n\n    avctx->frame_size = avctx->delay = s->frame_len;\n\n\n\n#if FF_API_OLD_ENCODE_AUDIO\n\n    avctx->coded_frame = &s->frame;\n\n    avcodec_get_frame_defaults(avctx->coded_frame);\n\n#endif\n\n\n\n    return 0;\n\n}\n", "idx": 22333}
{"project": "FFmpeg", "commit_id": "fa2a34cd40d124161c748bb0f430dc63c94dd0da", "target": 0, "func": "AVFilter **av_filter_next(AVFilter **filter)\n\n{\n\n    return filter ? ++filter : &registered_avfilters[0];\n\n}\n", "idx": 22344}
{"project": "FFmpeg", "commit_id": "d9293648147013403de729958ea4c19a5b6c40e4", "target": 1, "func": "static void get_tag(AVFormatContext *s, const char *key, int type, int len, int type2_size)\n\n{\n\n    char *value;\n\n    int64_t off = avio_tell(s->pb);\n\n\n\n    if ((unsigned)len >= (UINT_MAX - 1) / 2)\n\n        return;\n\n\n\n    value = av_malloc(2 * len + 1);\n\n    if (!value)\n\n        goto finish;\n\n\n\n    if (type == 0) {         // UTF16-LE\n\n        avio_get_str16le(s->pb, len, value, 2 * len + 1);\n\n    } else if (type == -1) { // ASCII\n\n        avio_read(s->pb, value, len);\n\n        value[len]=0;\n\n    } else if (type == 1) {  // byte array\n\n        if (!strcmp(key, \"WM/Picture\")) { // handle cover art\n\n            asf_read_picture(s, len);\n\n        } else if (!strcmp(key, \"ID3\")) { // handle ID3 tag\n\n            get_id3_tag(s, len);\n\n        } else {\n\n            av_log(s, AV_LOG_VERBOSE, \"Unsupported byte array in tag %s.\\n\", key);\n\n        }\n\n        goto finish;\n\n    } else if (type > 1 && type <= 5) {  // boolean or DWORD or QWORD or WORD\n\n        uint64_t num = get_value(s->pb, type, type2_size);\n\n        snprintf(value, len, \"%\"PRIu64, num);\n\n    } else if (type == 6) { // (don't) handle GUID\n\n        av_log(s, AV_LOG_DEBUG, \"Unsupported GUID value in tag %s.\\n\", key);\n\n        goto finish;\n\n    } else {\n\n        av_log(s, AV_LOG_DEBUG,\n\n               \"Unsupported value type %d in tag %s.\\n\", type, key);\n\n        goto finish;\n\n    }\n\n    if (*value)\n\n        av_dict_set(&s->metadata, key, value, 0);\n\n\n\nfinish:\n\n    av_freep(&value);\n\n    avio_seek(s->pb, off + len, SEEK_SET);\n\n}\n", "idx": 22351}
{"project": "FFmpeg", "commit_id": "6ed000c8e6e8a5f55433b2d67e21bcba2ebc4b5d", "target": 1, "func": "av_cold int ff_yuv2rgb_c_init_tables(SwsContext *c, const int inv_table[4], int fullRange,\n\n                                     int brightness, int contrast, int saturation)\n\n{\n\n    const int isRgb =      c->dstFormat==PIX_FMT_RGB32\n\n                        || c->dstFormat==PIX_FMT_RGB32_1\n\n                        || c->dstFormat==PIX_FMT_BGR24\n\n                        || c->dstFormat==PIX_FMT_RGB565BE\n\n                        || c->dstFormat==PIX_FMT_RGB565LE\n\n                        || c->dstFormat==PIX_FMT_RGB555BE\n\n                        || c->dstFormat==PIX_FMT_RGB555LE\n\n                        || c->dstFormat==PIX_FMT_RGB444BE\n\n                        || c->dstFormat==PIX_FMT_RGB444LE\n\n                        || c->dstFormat==PIX_FMT_RGB8\n\n                        || c->dstFormat==PIX_FMT_RGB4\n\n                        || c->dstFormat==PIX_FMT_RGB4_BYTE\n\n                        || c->dstFormat==PIX_FMT_MONOBLACK;\n\n    const int isNotNe =    c->dstFormat==PIX_FMT_NE(RGB565LE,RGB565BE)\n\n                        || c->dstFormat==PIX_FMT_NE(RGB555LE,RGB555BE)\n\n                        || c->dstFormat==PIX_FMT_NE(RGB444LE,RGB444BE)\n\n                        || c->dstFormat==PIX_FMT_NE(BGR565LE,BGR565BE)\n\n                        || c->dstFormat==PIX_FMT_NE(BGR555LE,BGR555BE)\n\n                        || c->dstFormat==PIX_FMT_NE(BGR444LE,BGR444BE);\n\n    const int bpp = c->dstFormatBpp;\n\n    uint8_t *y_table;\n\n    uint16_t *y_table16;\n\n    uint32_t *y_table32;\n\n    int i, base, rbase, gbase, bbase, abase, needAlpha;\n\n    const int yoffs = fullRange ? 384 : 326;\n\n\n\n    int64_t crv =  inv_table[0];\n\n    int64_t cbu =  inv_table[1];\n\n    int64_t cgu = -inv_table[2];\n\n    int64_t cgv = -inv_table[3];\n\n    int64_t cy  = 1<<16;\n\n    int64_t oy  = 0;\n\n\n\n    int64_t yb = 0;\n\n\n\n    if (!fullRange) {\n\n        cy = (cy*255) / 219;\n\n        oy = 16<<16;\n\n    } else {\n\n        crv = (crv*224) / 255;\n\n        cbu = (cbu*224) / 255;\n\n        cgu = (cgu*224) / 255;\n\n        cgv = (cgv*224) / 255;\n\n    }\n\n\n\n    cy  = (cy *contrast             ) >> 16;\n\n    crv = (crv*contrast * saturation) >> 32;\n\n    cbu = (cbu*contrast * saturation) >> 32;\n\n    cgu = (cgu*contrast * saturation) >> 32;\n\n    cgv = (cgv*contrast * saturation) >> 32;\n\n    oy -= 256*brightness;\n\n\n\n    c->uOffset=   0x0400040004000400LL;\n\n    c->vOffset=   0x0400040004000400LL;\n\n    c->yCoeff=    roundToInt16(cy *8192) * 0x0001000100010001ULL;\n\n    c->vrCoeff=   roundToInt16(crv*8192) * 0x0001000100010001ULL;\n\n    c->ubCoeff=   roundToInt16(cbu*8192) * 0x0001000100010001ULL;\n\n    c->vgCoeff=   roundToInt16(cgv*8192) * 0x0001000100010001ULL;\n\n    c->ugCoeff=   roundToInt16(cgu*8192) * 0x0001000100010001ULL;\n\n    c->yOffset=   roundToInt16(oy *   8) * 0x0001000100010001ULL;\n\n\n\n    c->yuv2rgb_y_coeff  = (int16_t)roundToInt16(cy <<13);\n\n    c->yuv2rgb_y_offset = (int16_t)roundToInt16(oy << 9);\n\n    c->yuv2rgb_v2r_coeff= (int16_t)roundToInt16(crv<<13);\n\n    c->yuv2rgb_v2g_coeff= (int16_t)roundToInt16(cgv<<13);\n\n    c->yuv2rgb_u2g_coeff= (int16_t)roundToInt16(cgu<<13);\n\n    c->yuv2rgb_u2b_coeff= (int16_t)roundToInt16(cbu<<13);\n\n\n\n    //scale coefficients by cy\n\n    crv = ((crv << 16) + 0x8000) / cy;\n\n    cbu = ((cbu << 16) + 0x8000) / cy;\n\n    cgu = ((cgu << 16) + 0x8000) / cy;\n\n    cgv = ((cgv << 16) + 0x8000) / cy;\n\n\n\n    av_free(c->yuvTable);\n\n\n\n    switch (bpp) {\n\n    case 1:\n\n        c->yuvTable = av_malloc(1024);\n\n        y_table = c->yuvTable;\n\n        yb = -(384<<16) - oy;\n\n        for (i = 0; i < 1024-110; i++) {\n\n            y_table[i+110] = av_clip_uint8((yb + 0x8000) >> 16) >> 7;\n\n            yb += cy;\n\n        }\n\n        fill_table(c->table_gU, 1, cgu, y_table + yoffs);\n\n        fill_gv_table(c->table_gV, 1, cgv);\n\n        break;\n\n    case 4:\n\n    case 4|128:\n\n        rbase = isRgb ? 3 : 0;\n\n        gbase = 1;\n\n        bbase = isRgb ? 0 : 3;\n\n        c->yuvTable = av_malloc(1024*3);\n\n        y_table = c->yuvTable;\n\n        yb = -(384<<16) - oy;\n\n        for (i = 0; i < 1024-110; i++) {\n\n            int yval = av_clip_uint8((yb + 0x8000) >> 16);\n\n            y_table[i+110     ] =  (yval >> 7)       << rbase;\n\n            y_table[i+ 37+1024] = ((yval + 43) / 85) << gbase;\n\n            y_table[i+110+2048] =  (yval >> 7)       << bbase;\n\n            yb += cy;\n\n        }\n\n        fill_table(c->table_rV, 1, crv, y_table + yoffs);\n\n        fill_table(c->table_gU, 1, cgu, y_table + yoffs + 1024);\n\n        fill_table(c->table_bU, 1, cbu, y_table + yoffs + 2048);\n\n        fill_gv_table(c->table_gV, 1, cgv);\n\n        break;\n\n    case 8:\n\n        rbase = isRgb ? 5 : 0;\n\n        gbase = isRgb ? 2 : 3;\n\n        bbase = isRgb ? 0 : 6;\n\n        c->yuvTable = av_malloc(1024*3);\n\n        y_table = c->yuvTable;\n\n        yb = -(384<<16) - oy;\n\n        for (i = 0; i < 1024-38; i++) {\n\n            int yval = av_clip_uint8((yb + 0x8000) >> 16);\n\n            y_table[i+16     ] = ((yval + 18) / 36) << rbase;\n\n            y_table[i+16+1024] = ((yval + 18) / 36) << gbase;\n\n            y_table[i+37+2048] = ((yval + 43) / 85) << bbase;\n\n            yb += cy;\n\n        }\n\n        fill_table(c->table_rV, 1, crv, y_table + yoffs);\n\n        fill_table(c->table_gU, 1, cgu, y_table + yoffs + 1024);\n\n        fill_table(c->table_bU, 1, cbu, y_table + yoffs + 2048);\n\n        fill_gv_table(c->table_gV, 1, cgv);\n\n        break;\n\n    case 12:\n\n        rbase = isRgb ? 8 : 0;\n\n        gbase = 4;\n\n        bbase = isRgb ? 0 : 8;\n\n        c->yuvTable = av_malloc(1024*3*2);\n\n        y_table16 = c->yuvTable;\n\n        yb = -(384<<16) - oy;\n\n        for (i = 0; i < 1024; i++) {\n\n            uint8_t yval = av_clip_uint8((yb + 0x8000) >> 16);\n\n            y_table16[i     ] = (yval >> 4) << rbase;\n\n            y_table16[i+1024] = (yval >> 4) << gbase;\n\n            y_table16[i+2048] = (yval >> 4) << bbase;\n\n            yb += cy;\n\n        }\n\n        if (isNotNe)\n\n            for (i = 0; i < 1024*3; i++)\n\n                y_table16[i] = av_bswap16(y_table16[i]);\n\n        fill_table(c->table_rV, 2, crv, y_table16 + yoffs);\n\n        fill_table(c->table_gU, 2, cgu, y_table16 + yoffs + 1024);\n\n        fill_table(c->table_bU, 2, cbu, y_table16 + yoffs + 2048);\n\n        fill_gv_table(c->table_gV, 2, cgv);\n\n        break;\n\n    case 15:\n\n    case 16:\n\n        rbase = isRgb ? bpp - 5 : 0;\n\n        gbase = 5;\n\n        bbase = isRgb ? 0 : (bpp - 5);\n\n        c->yuvTable = av_malloc(1024*3*2);\n\n        y_table16 = c->yuvTable;\n\n        yb = -(384<<16) - oy;\n\n        for (i = 0; i < 1024; i++) {\n\n            uint8_t yval = av_clip_uint8((yb + 0x8000) >> 16);\n\n            y_table16[i     ] = (yval >> 3)          << rbase;\n\n            y_table16[i+1024] = (yval >> (18 - bpp)) << gbase;\n\n            y_table16[i+2048] = (yval >> 3)          << bbase;\n\n            yb += cy;\n\n        }\n\n        if(isNotNe)\n\n            for (i = 0; i < 1024*3; i++)\n\n                y_table16[i] = av_bswap16(y_table16[i]);\n\n        fill_table(c->table_rV, 2, crv, y_table16 + yoffs);\n\n        fill_table(c->table_gU, 2, cgu, y_table16 + yoffs + 1024);\n\n        fill_table(c->table_bU, 2, cbu, y_table16 + yoffs + 2048);\n\n        fill_gv_table(c->table_gV, 2, cgv);\n\n        break;\n\n    case 24:\n\n    case 48:\n\n        c->yuvTable = av_malloc(1024);\n\n        y_table = c->yuvTable;\n\n        yb = -(384<<16) - oy;\n\n        for (i = 0; i < 1024; i++) {\n\n            y_table[i] = av_clip_uint8((yb + 0x8000) >> 16);\n\n            yb += cy;\n\n        }\n\n        fill_table(c->table_rV, 1, crv, y_table + yoffs);\n\n        fill_table(c->table_gU, 1, cgu, y_table + yoffs);\n\n        fill_table(c->table_bU, 1, cbu, y_table + yoffs);\n\n        fill_gv_table(c->table_gV, 1, cgv);\n\n        break;\n\n    case 32:\n\n        base = (c->dstFormat == PIX_FMT_RGB32_1 || c->dstFormat == PIX_FMT_BGR32_1) ? 8 : 0;\n\n        rbase = base + (isRgb ? 16 : 0);\n\n        gbase = base + 8;\n\n        bbase = base + (isRgb ? 0 : 16);\n\n        needAlpha = CONFIG_SWSCALE_ALPHA && isALPHA(c->srcFormat);\n\n        if (!needAlpha)\n\n            abase = (base + 24) & 31;\n\n        c->yuvTable = av_malloc(1024*3*4);\n\n        y_table32 = c->yuvTable;\n\n        yb = -(384<<16) - oy;\n\n        for (i = 0; i < 1024; i++) {\n\n            unsigned yval = av_clip_uint8((yb + 0x8000) >> 16);\n\n            y_table32[i     ] = (yval << rbase) + (needAlpha ? 0 : (255u << abase));\n\n            y_table32[i+1024] = yval << gbase;\n\n            y_table32[i+2048] = yval << bbase;\n\n            yb += cy;\n\n        }\n\n        fill_table(c->table_rV, 4, crv, y_table32 + yoffs);\n\n        fill_table(c->table_gU, 4, cgu, y_table32 + yoffs + 1024);\n\n        fill_table(c->table_bU, 4, cbu, y_table32 + yoffs + 2048);\n\n        fill_gv_table(c->table_gV, 4, cgv);\n\n        break;\n\n    default:\n\n        c->yuvTable = NULL;\n\n        av_log(c, AV_LOG_ERROR, \"%ibpp not supported by yuv2rgb\\n\", bpp);\n\n        return -1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 22353}
{"project": "FFmpeg", "commit_id": "ae4c9ddebc32eaacbd62681d776881e59ca6e6f7", "target": 1, "func": "static int config_input_ref(AVFilterLink *inlink)\n\n{\n\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(inlink->format);\n\n    AVFilterContext *ctx  = inlink->dst;\n\n    PSNRContext *s = ctx->priv;\n\n    unsigned sum;\n\n    int j;\n\n\n\n    s->nb_components = desc->nb_components;\n\n    if (ctx->inputs[0]->w != ctx->inputs[1]->w ||\n\n        ctx->inputs[0]->h != ctx->inputs[1]->h) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Width and height of input videos must be same.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    if (ctx->inputs[0]->format != ctx->inputs[1]->format) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Inputs must be of same pixel format.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    s->max[0] = (1 << (desc->comp[0].depth_minus1 + 1)) - 1;\n\n    s->max[1] = (1 << (desc->comp[1].depth_minus1 + 1)) - 1;\n\n    s->max[2] = (1 << (desc->comp[2].depth_minus1 + 1)) - 1;\n\n    s->max[3] = (1 << (desc->comp[3].depth_minus1 + 1)) - 1;\n\n\n\n    s->is_rgb = ff_fill_rgba_map(s->rgba_map, inlink->format) >= 0;\n\n    s->comps[0] = s->is_rgb ? 'r' : 'y' ;\n\n    s->comps[1] = s->is_rgb ? 'g' : 'u' ;\n\n    s->comps[2] = s->is_rgb ? 'b' : 'v' ;\n\n    s->comps[3] = 'a';\n\n\n\n    s->planeheight[1] = s->planeheight[2] = FF_CEIL_RSHIFT(inlink->h, desc->log2_chroma_h);\n\n    s->planeheight[0] = s->planeheight[3] = inlink->h;\n\n    s->planewidth[1]  = s->planewidth[2]  = FF_CEIL_RSHIFT(inlink->w, desc->log2_chroma_w);\n\n    s->planewidth[0]  = s->planewidth[3]  = inlink->w;\n\n    sum = 0;\n\n    for (j = 0; j < s->nb_components; j++)\n\n        sum += s->planeheight[j] * s->planewidth[j];\n\n    for (j = 0; j < s->nb_components; j++) {\n\n        s->planeweight[j] = (double) s->planeheight[j] * s->planewidth[j] / sum;\n\n        s->average_max += s->max[j] * s->planeweight[j];\n\n    }\n\n\n\n    s->compute_mse = desc->comp[0].depth_minus1 > 7 ? compute_images_mse_16bit : compute_images_mse;\n\n\n\n    return 0;\n\n}\n", "idx": 22355}
{"project": "FFmpeg", "commit_id": "d509c743b78da198af385fea362b632292cd00ad", "target": 1, "func": "int dv_produce_packet(DVDemuxContext *c, AVPacket *pkt,\n\n                      uint8_t* buf, int buf_size)\n\n{\n\n    int size, i;\n\n    uint8_t *ppcm[4] = {0};\n\n\n\n    if (buf_size < DV_PROFILE_BYTES ||\n\n        !(c->sys = dv_frame_profile(buf)) ||\n\n        buf_size < c->sys->frame_size) {\n\n          return -1;   /* Broken frame, or not enough data */\n\n    }\n\n\n\n    /* Queueing audio packet */\n\n    /* FIXME: in case of no audio/bad audio we have to do something */\n\n    size = dv_extract_audio_info(c, buf);\n\n    for (i = 0; i < c->ach; i++) {\n\n       c->audio_pkt[i].size = size;\n\n       c->audio_pkt[i].pts  = c->abytes * 30000*8 / c->ast[i]->codec->bit_rate;\n\n       ppcm[i] = c->audio_buf[i];\n\n    }\n\n    dv_extract_audio(buf, ppcm, c->sys);\n\n    c->abytes += size;\n\n\n\n    /* We work with 720p frames split in half, thus even frames have\n\n     * channels 0,1 and odd 2,3. */\n\n    if (c->sys->height == 720) {\n\n        if (buf[1] & 0x0C)\n\n            c->audio_pkt[2].size = c->audio_pkt[3].size = 0;\n\n        else\n\n            c->audio_pkt[0].size = c->audio_pkt[1].size = 0;\n\n    }\n\n\n\n    /* Now it's time to return video packet */\n\n    size = dv_extract_video_info(c, buf);\n\n    av_init_packet(pkt);\n\n    pkt->data         = buf;\n\n    pkt->size         = size;\n\n    pkt->flags       |= PKT_FLAG_KEY;\n\n    pkt->stream_index = c->vst->id;\n\n    pkt->pts          = c->frames;\n\n\n\n    c->frames++;\n\n\n\n    return size;\n\n}\n", "idx": 22356}
{"project": "FFmpeg", "commit_id": "271c869cc3285dac2b6f2663a87c70bf3ba2b04f", "target": 1, "func": "int ff_rtmp_packet_create(RTMPPacket *pkt, int channel_id, RTMPPacketType type,\n\n                          int timestamp, int size)\n\n{\n\n\n    pkt->data = av_malloc(size);\n\n    if (!pkt->data)\n\n        return AVERROR(ENOMEM);\n\n\n    pkt->data_size  = size;\n\n    pkt->channel_id = channel_id;\n\n    pkt->type       = type;\n\n    pkt->timestamp  = timestamp;\n\n    pkt->extra      = 0;\n\n    pkt->ts_delta   = 0;\n\n\n\n    return 0;\n", "idx": 22357}
{"project": "FFmpeg", "commit_id": "008f872f614e6646c5b1fc8888e40bea4796eb5f", "target": 0, "func": "static int ac3_decode_frame(AVCodecContext * avctx, void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    AC3DecodeContext *s = avctx->priv_data;\n\n    int16_t *out_samples = (int16_t *)data;\n\n    int blk, ch, err;\n\n    const uint8_t *channel_map;\n\n    const float *output[AC3_MAX_CHANNELS];\n\n\n\n    /* initialize the GetBitContext with the start of valid AC-3 Frame */\n\n    if (s->input_buffer) {\n\n        /* copy input buffer to decoder context to avoid reading past the end\n\n           of the buffer, which can be caused by a damaged input stream. */\n\n        memcpy(s->input_buffer, buf, FFMIN(buf_size, AC3_FRAME_BUFFER_SIZE));\n\n        init_get_bits(&s->gbc, s->input_buffer, buf_size * 8);\n\n    } else {\n\n        init_get_bits(&s->gbc, buf, buf_size * 8);\n\n    }\n\n\n\n    /* parse the syncinfo */\n\n    *data_size = 0;\n\n    err = parse_frame_header(s);\n\n\n\n    /* check that reported frame size fits in input buffer */\n\n    if(s->frame_size > buf_size) {\n\n        av_log(avctx, AV_LOG_ERROR, \"incomplete frame\\n\");\n\n        err = AAC_AC3_PARSE_ERROR_FRAME_SIZE;\n\n    }\n\n\n\n    /* check for crc mismatch */\n\n    if(err != AAC_AC3_PARSE_ERROR_FRAME_SIZE && avctx->error_recognition >= FF_ER_CAREFUL) {\n\n        if(av_crc(av_crc_get_table(AV_CRC_16_ANSI), 0, &buf[2], s->frame_size-2)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"frame CRC mismatch\\n\");\n\n            err = AAC_AC3_PARSE_ERROR_CRC;\n\n        }\n\n    }\n\n\n\n    if(err && err != AAC_AC3_PARSE_ERROR_CRC) {\n\n        switch(err) {\n\n            case AAC_AC3_PARSE_ERROR_SYNC:\n\n                av_log(avctx, AV_LOG_ERROR, \"frame sync error\\n\");\n\n                return -1;\n\n            case AAC_AC3_PARSE_ERROR_BSID:\n\n                av_log(avctx, AV_LOG_ERROR, \"invalid bitstream id\\n\");\n\n                break;\n\n            case AAC_AC3_PARSE_ERROR_SAMPLE_RATE:\n\n                av_log(avctx, AV_LOG_ERROR, \"invalid sample rate\\n\");\n\n                break;\n\n            case AAC_AC3_PARSE_ERROR_FRAME_SIZE:\n\n                av_log(avctx, AV_LOG_ERROR, \"invalid frame size\\n\");\n\n                break;\n\n            case AAC_AC3_PARSE_ERROR_FRAME_TYPE:\n\n                /* skip frame if CRC is ok. otherwise use error concealment. */\n\n                /* TODO: add support for substreams and dependent frames */\n\n                if(s->frame_type == EAC3_FRAME_TYPE_DEPENDENT || s->substreamid) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"unsupported frame type : skipping frame\\n\");\n\n                    return s->frame_size;\n\n                } else {\n\n                    av_log(avctx, AV_LOG_ERROR, \"invalid frame type\\n\");\n\n                }\n\n                break;\n\n            default:\n\n                av_log(avctx, AV_LOG_ERROR, \"invalid header\\n\");\n\n                break;\n\n        }\n\n    }\n\n\n\n    /* if frame is ok, set audio parameters */\n\n    if (!err) {\n\n        avctx->sample_rate = s->sample_rate;\n\n        avctx->bit_rate = s->bit_rate;\n\n\n\n        /* channel config */\n\n        s->out_channels = s->channels;\n\n        s->output_mode = s->channel_mode;\n\n        if(s->lfe_on)\n\n            s->output_mode |= AC3_OUTPUT_LFEON;\n\n        if (avctx->request_channels > 0 && avctx->request_channels <= 2 &&\n\n                avctx->request_channels < s->channels) {\n\n            s->out_channels = avctx->request_channels;\n\n            s->output_mode  = avctx->request_channels == 1 ? AC3_CHMODE_MONO : AC3_CHMODE_STEREO;\n\n            s->channel_layout = ff_ac3_channel_layout_tab[s->output_mode];\n\n        }\n\n        avctx->channels = s->out_channels;\n\n        avctx->channel_layout = s->channel_layout;\n\n\n\n        /* set downmixing coefficients if needed */\n\n        if(s->channels != s->out_channels && !((s->output_mode & AC3_OUTPUT_LFEON) &&\n\n                s->fbw_channels == s->out_channels)) {\n\n            set_downmix_coeffs(s);\n\n        }\n\n    } else if (!s->out_channels) {\n\n        s->out_channels = avctx->channels;\n\n        if(s->out_channels < s->channels)\n\n            s->output_mode  = s->out_channels == 1 ? AC3_CHMODE_MONO : AC3_CHMODE_STEREO;\n\n    }\n\n\n\n    /* decode the audio blocks */\n\n    channel_map = ff_ac3_dec_channel_map[s->output_mode & ~AC3_OUTPUT_LFEON][s->lfe_on];\n\n    for (ch = 0; ch < s->out_channels; ch++)\n\n        output[ch] = s->output[channel_map[ch]];\n\n    for (blk = 0; blk < s->num_blocks; blk++) {\n\n        if (!err && decode_audio_block(s, blk)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"error decoding the audio block\\n\");\n\n            err = 1;\n\n        }\n\n        s->dsp.float_to_int16_interleave(out_samples, output, 256, s->out_channels);\n\n        out_samples += 256 * s->out_channels;\n\n    }\n\n    *data_size = s->num_blocks * 256 * avctx->channels * sizeof (int16_t);\n\n    return s->frame_size;\n\n}\n", "idx": 22358}
{"project": "FFmpeg", "commit_id": "39d607e5bbc25ad9629683702b510e865434ef21", "target": 1, "func": "static inline void RENAME(yuv2yuvX_ar)(SwsContext *c, const int16_t *lumFilter,\n\n                                       const int16_t **lumSrc, int lumFilterSize,\n\n                                       const int16_t *chrFilter, const int16_t **chrUSrc,\n\n                                       const int16_t **chrVSrc,\n\n                                       int chrFilterSize, const int16_t **alpSrc,\n\n                                       uint8_t *dest, uint8_t *uDest, uint8_t *vDest,\n\n                                       uint8_t *aDest, long dstW, long chrDstW)\n\n{\n\n    if (uDest) {\n\n        YSCALEYUV2YV12X_ACCURATE(CHR_MMX_FILTER_OFFSET, uDest, chrDstW, 0)\n\n        YSCALEYUV2YV12X_ACCURATE(CHR_MMX_FILTER_OFFSET, vDest, chrDstW + c->uv_off, c->uv_off)\n\n    }\n\n    if (CONFIG_SWSCALE_ALPHA && aDest) {\n\n        YSCALEYUV2YV12X_ACCURATE(ALP_MMX_FILTER_OFFSET, aDest, dstW, 0)\n\n    }\n\n\n\n    YSCALEYUV2YV12X_ACCURATE(LUM_MMX_FILTER_OFFSET, dest, dstW, 0)\n\n}\n", "idx": 22361}
{"project": "FFmpeg", "commit_id": "2caf19e90f270abe1e80a3e85acaf0eb5c9d0aac", "target": 1, "func": "static void FUNCC(pred8x8l_vertical)(uint8_t *_src, int has_topleft, int has_topright, int _stride)\n\n{\n\n    int y;\n\n    pixel *src = (pixel*)_src;\n\n    int stride = _stride/sizeof(pixel);\n\n\n\n    PREDICT_8x8_LOAD_TOP;\n\n    src[0] = t0;\n\n    src[1] = t1;\n\n    src[2] = t2;\n\n    src[3] = t3;\n\n    src[4] = t4;\n\n    src[5] = t5;\n\n    src[6] = t6;\n\n    src[7] = t7;\n\n    for( y = 1; y < 8; y++ ) {\n\n        ((pixel4*)(src+y*stride))[0] = ((pixel4*)src)[0];\n\n        ((pixel4*)(src+y*stride))[1] = ((pixel4*)src)[1];\n\n    }\n\n}\n", "idx": 22362}
{"project": "FFmpeg", "commit_id": "a71abb714e350b017e1e0c1607e343e1e2f2f8a9", "target": 0, "func": "static int check_intra_pred_mode(int mode, int mb_x, int mb_y)\n\n{\n\n    if (mode == DC_PRED8x8) {\n\n        if (!(mb_x|mb_y))\n\n            mode = DC_128_PRED8x8;\n\n        else if (!mb_y)\n\n            mode = LEFT_DC_PRED8x8;\n\n        else if (!mb_x)\n\n            mode = TOP_DC_PRED8x8;\n\n    }\n\n    return mode;\n\n}\n", "idx": 22363}
{"project": "FFmpeg", "commit_id": "abe20c59b93426958624e16e89b24e0c0b43f370", "target": 1, "func": "static int http_open_cnx(URLContext *h)\n\n{\n\n    const char *path, *proxy_path, *lower_proto = \"tcp\", *local_path;\n\n    char hostname[1024], hoststr[1024], proto[10];\n\n    char auth[1024], proxyauth[1024];\n\n    char path1[1024];\n\n    char buf[1024], urlbuf[1024];\n\n    int port, use_proxy, err, location_changed = 0, redirects = 0;\n\n    HTTPAuthType cur_auth_type, cur_proxy_auth_type;\n\n    HTTPContext *s = h->priv_data;\n\n    URLContext *hd = NULL;\n\n\n\n    proxy_path = getenv(\"http_proxy\");\n\n    use_proxy = (proxy_path != NULL) && !getenv(\"no_proxy\") &&\n\n        av_strstart(proxy_path, \"http://\", NULL);\n\n\n\n    /* fill the dest addr */\n\n redo:\n\n    /* needed in any case to build the host string */\n\n    av_url_split(proto, sizeof(proto), auth, sizeof(auth),\n\n                 hostname, sizeof(hostname), &port,\n\n                 path1, sizeof(path1), s->location);\n\n    ff_url_join(hoststr, sizeof(hoststr), NULL, NULL, hostname, port, NULL);\n\n\n\n    if (!strcmp(proto, \"https\")) {\n\n        lower_proto = \"tls\";\n\n        use_proxy = 0;\n\n        if (port < 0)\n\n            port = 443;\n\n    }\n\n    if (port < 0)\n\n        port = 80;\n\n\n\n    if (path1[0] == '\\0')\n\n        path = \"/\";\n\n    else\n\n        path = path1;\n\n    local_path = path;\n\n    if (use_proxy) {\n\n        /* Reassemble the request URL without auth string - we don't\n\n         * want to leak the auth to the proxy. */\n\n        ff_url_join(urlbuf, sizeof(urlbuf), proto, NULL, hostname, port, \"%s\",\n\n                    path1);\n\n        path = urlbuf;\n\n        av_url_split(NULL, 0, proxyauth, sizeof(proxyauth),\n\n                     hostname, sizeof(hostname), &port, NULL, 0, proxy_path);\n\n    }\n\n\n\n    ff_url_join(buf, sizeof(buf), lower_proto, NULL, hostname, port, NULL);\n\n    err = ffurl_open(&hd, buf, AVIO_FLAG_READ_WRITE,\n\n                     &h->interrupt_callback, NULL);\n\n    if (err < 0)\n\n        goto fail;\n\n\n\n    s->hd = hd;\n\n    cur_auth_type = s->auth_state.auth_type;\n\n    cur_proxy_auth_type = s->auth_state.auth_type;\n\n    if (http_connect(h, path, local_path, hoststr, auth, proxyauth, &location_changed) < 0)\n\n        goto fail;\n\n    if (s->http_code == 401) {\n\n        if (cur_auth_type == HTTP_AUTH_NONE && s->auth_state.auth_type != HTTP_AUTH_NONE) {\n\n            ffurl_close(hd);\n\n            goto redo;\n\n        } else\n\n            goto fail;\n\n    }\n\n    if (s->http_code == 407) {\n\n        if (cur_proxy_auth_type == HTTP_AUTH_NONE &&\n\n            s->proxy_auth_state.auth_type != HTTP_AUTH_NONE) {\n\n            ffurl_close(hd);\n\n            goto redo;\n\n        } else\n\n            goto fail;\n\n    }\n\n    if ((s->http_code == 301 || s->http_code == 302 || s->http_code == 303 || s->http_code == 307)\n\n        && location_changed == 1) {\n\n        /* url moved, get next */\n\n        ffurl_close(hd);\n\n        if (redirects++ >= MAX_REDIRECTS)\n\n            return AVERROR(EIO);\n\n        location_changed = 0;\n\n        goto redo;\n\n    }\n\n    return 0;\n\n fail:\n\n    if (hd)\n\n        ffurl_close(hd);\n\n    s->hd = NULL;\n\n    return AVERROR(EIO);\n\n}\n", "idx": 22370}
{"project": "FFmpeg", "commit_id": "23fe14bb20888038b91e62b16d50fe0b75043a10", "target": 1, "func": "static void vmdaudio_loadsound(VmdAudioContext *s, unsigned char *data,\n\n    uint8_t *buf, int silence)\n\n{\n\n    if (s->channels == 2) {\n\n        if ((s->block_align & 0x01) == 0) {\n\n            if (silence)\n\n                memset(data, 0, s->block_align * 2);\n\n            else\n\n                vmdaudio_decode_audio(s, data, buf, 1);\n\n        } else {\n\n            if (silence)\n\n                memset(data, 0, s->block_align * 2);\n\n//            else\n\n//                vmdaudio_decode_audio(s, data, buf, 1);\n\n        }\n\n    } else {\n\n    }\n\n}\n", "idx": 22371}
{"project": "FFmpeg", "commit_id": "441026fcb13ac23aa10edc312bdacb6445a0ad06", "target": 1, "func": "static int xwd_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame, AVPacket *avpkt)\n\n{\n\n    AVFrame *p = data;\n\n    const uint8_t *buf = avpkt->data;\n\n    int i, ret, buf_size = avpkt->size;\n\n    uint32_t version, header_size, vclass, ncolors;\n\n    uint32_t xoffset, be, bpp, lsize, rsize;\n\n    uint32_t pixformat, pixdepth, bunit, bitorder, bpad;\n\n    uint32_t rgb[3];\n\n    uint8_t *ptr;\n\n    GetByteContext gb;\n\n\n\n    if (buf_size < XWD_HEADER_SIZE)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    bytestream2_init(&gb, buf, buf_size);\n\n    header_size = bytestream2_get_be32u(&gb);\n\n\n\n    version = bytestream2_get_be32u(&gb);\n\n    if (version != XWD_VERSION) {\n\n        av_log(avctx, AV_LOG_ERROR, \"unsupported version\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (buf_size < header_size || header_size < XWD_HEADER_SIZE) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid header size\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    pixformat     = bytestream2_get_be32u(&gb);\n\n    pixdepth      = bytestream2_get_be32u(&gb);\n\n    avctx->width  = bytestream2_get_be32u(&gb);\n\n    avctx->height = bytestream2_get_be32u(&gb);\n\n    xoffset       = bytestream2_get_be32u(&gb);\n\n    be            = bytestream2_get_be32u(&gb);\n\n    bunit         = bytestream2_get_be32u(&gb);\n\n    bitorder      = bytestream2_get_be32u(&gb);\n\n    bpad          = bytestream2_get_be32u(&gb);\n\n    bpp           = bytestream2_get_be32u(&gb);\n\n    lsize         = bytestream2_get_be32u(&gb);\n\n    vclass        = bytestream2_get_be32u(&gb);\n\n    rgb[0]        = bytestream2_get_be32u(&gb);\n\n    rgb[1]        = bytestream2_get_be32u(&gb);\n\n    rgb[2]        = bytestream2_get_be32u(&gb);\n\n    bytestream2_skipu(&gb, 8);\n\n    ncolors       = bytestream2_get_be32u(&gb);\n\n    bytestream2_skipu(&gb, header_size - (XWD_HEADER_SIZE - 20));\n\n\n\n    av_log(avctx, AV_LOG_DEBUG,\n\n           \"pixformat %\"PRIu32\", pixdepth %\"PRIu32\", bunit %\"PRIu32\", bitorder %\"PRIu32\", bpad %\"PRIu32\"\\n\",\n\n           pixformat, pixdepth, bunit, bitorder, bpad);\n\n    av_log(avctx, AV_LOG_DEBUG,\n\n           \"vclass %\"PRIu32\", ncolors %\"PRIu32\", bpp %\"PRIu32\", be %\"PRIu32\", lsize %\"PRIu32\", xoffset %\"PRIu32\"\\n\",\n\n           vclass, ncolors, bpp, be, lsize, xoffset);\n\n    av_log(avctx, AV_LOG_DEBUG,\n\n           \"red %0\"PRIx32\", green %0\"PRIx32\", blue %0\"PRIx32\"\\n\",\n\n           rgb[0], rgb[1], rgb[2]);\n\n\n\n    if (pixformat > XWD_Z_PIXMAP) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid pixmap format\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (pixdepth == 0 || pixdepth > 32) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid pixmap depth\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (xoffset) {\n\n        avpriv_request_sample(avctx, \"xoffset %\"PRIu32\"\", xoffset);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if (be > 1) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid byte order\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (bitorder > 1) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid bitmap bit order\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (bunit != 8 && bunit != 16 && bunit != 32) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid bitmap unit\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (bpad != 8 && bpad != 16 && bpad != 32) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid bitmap scan-line pad\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (bpp == 0 || bpp > 32) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid bits per pixel\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (ncolors > 256) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid number of entries in colormap\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if ((ret = av_image_check_size(avctx->width, avctx->height, 0, NULL)) < 0)\n\n        return ret;\n\n\n\n    rsize = FFALIGN(avctx->width * bpp, bpad) / 8;\n\n    if (lsize < rsize) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid bytes per scan-line\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (bytestream2_get_bytes_left(&gb) < ncolors * XWD_CMAP_SIZE + (uint64_t)avctx->height * lsize) {\n\n        av_log(avctx, AV_LOG_ERROR, \"input buffer too small\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (pixformat != XWD_Z_PIXMAP) {\n\n        avpriv_report_missing_feature(avctx, \"Pixmap format %\"PRIu32, pixformat);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    avctx->pix_fmt = AV_PIX_FMT_NONE;\n\n    switch (vclass) {\n\n    case XWD_STATIC_GRAY:\n\n    case XWD_GRAY_SCALE:\n\n        if (bpp != 1 && bpp != 8)\n\n            return AVERROR_INVALIDDATA;\n\n        if (pixdepth == 1) {\n\n            avctx->pix_fmt = AV_PIX_FMT_MONOWHITE;\n\n        } else if (pixdepth == 8) {\n\n            avctx->pix_fmt = AV_PIX_FMT_GRAY8;\n\n        }\n\n        break;\n\n    case XWD_STATIC_COLOR:\n\n    case XWD_PSEUDO_COLOR:\n\n        if (bpp == 8)\n\n            avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n        break;\n\n    case XWD_TRUE_COLOR:\n\n    case XWD_DIRECT_COLOR:\n\n        if (bpp != 16 && bpp != 24 && bpp != 32)\n\n            return AVERROR_INVALIDDATA;\n\n        if (bpp == 16 && pixdepth == 15) {\n\n            if (rgb[0] == 0x7C00 && rgb[1] == 0x3E0 && rgb[2] == 0x1F)\n\n                avctx->pix_fmt = be ? AV_PIX_FMT_RGB555BE : AV_PIX_FMT_RGB555LE;\n\n            else if (rgb[0] == 0x1F && rgb[1] == 0x3E0 && rgb[2] == 0x7C00)\n\n                avctx->pix_fmt = be ? AV_PIX_FMT_BGR555BE : AV_PIX_FMT_BGR555LE;\n\n        } else if (bpp == 16 && pixdepth == 16) {\n\n            if (rgb[0] == 0xF800 && rgb[1] == 0x7E0 && rgb[2] == 0x1F)\n\n                avctx->pix_fmt = be ? AV_PIX_FMT_RGB565BE : AV_PIX_FMT_RGB565LE;\n\n            else if (rgb[0] == 0x1F && rgb[1] == 0x7E0 && rgb[2] == 0xF800)\n\n                avctx->pix_fmt = be ? AV_PIX_FMT_BGR565BE : AV_PIX_FMT_BGR565LE;\n\n        } else if (bpp == 24) {\n\n            if (rgb[0] == 0xFF0000 && rgb[1] == 0xFF00 && rgb[2] == 0xFF)\n\n                avctx->pix_fmt = be ? AV_PIX_FMT_RGB24 : AV_PIX_FMT_BGR24;\n\n            else if (rgb[0] == 0xFF && rgb[1] == 0xFF00 && rgb[2] == 0xFF0000)\n\n                avctx->pix_fmt = be ? AV_PIX_FMT_BGR24 : AV_PIX_FMT_RGB24;\n\n        } else if (bpp == 32) {\n\n            if (rgb[0] == 0xFF0000 && rgb[1] == 0xFF00 && rgb[2] == 0xFF)\n\n                avctx->pix_fmt = be ? AV_PIX_FMT_ARGB : AV_PIX_FMT_BGRA;\n\n            else if (rgb[0] == 0xFF && rgb[1] == 0xFF00 && rgb[2] == 0xFF0000)\n\n                avctx->pix_fmt = be ? AV_PIX_FMT_ABGR : AV_PIX_FMT_RGBA;\n\n        }\n\n        bytestream2_skipu(&gb, ncolors * XWD_CMAP_SIZE);\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid visual class\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (avctx->pix_fmt == AV_PIX_FMT_NONE) {\n\n        avpriv_request_sample(avctx,\n\n                              \"Unknown file: bpp %\"PRIu32\", pixdepth %\"PRIu32\", vclass %\"PRIu32\"\",\n\n                              bpp, pixdepth, vclass);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if ((ret = ff_get_buffer(avctx, p, 0)) < 0)\n\n        return ret;\n\n\n\n    p->key_frame = 1;\n\n    p->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    if (avctx->pix_fmt == AV_PIX_FMT_PAL8) {\n\n        uint32_t *dst = (uint32_t *)p->data[1];\n\n        uint8_t red, green, blue;\n\n\n\n        for (i = 0; i < ncolors; i++) {\n\n\n\n            bytestream2_skipu(&gb, 4); // skip colormap entry number\n\n            red    = bytestream2_get_byteu(&gb);\n\n            bytestream2_skipu(&gb, 1);\n\n            green  = bytestream2_get_byteu(&gb);\n\n            bytestream2_skipu(&gb, 1);\n\n            blue   = bytestream2_get_byteu(&gb);\n\n            bytestream2_skipu(&gb, 3); // skip bitmask flag and padding\n\n\n\n            dst[i] = red << 16 | green << 8 | blue;\n\n        }\n\n    }\n\n\n\n    ptr = p->data[0];\n\n    for (i = 0; i < avctx->height; i++) {\n\n        bytestream2_get_bufferu(&gb, ptr, rsize);\n\n        bytestream2_skipu(&gb, lsize - rsize);\n\n        ptr += p->linesize[0];\n\n    }\n\n\n\n    *got_frame       = 1;\n\n\n\n    return buf_size;\n\n}\n", "idx": 22373}
{"project": "FFmpeg", "commit_id": "8088d6f5f11b9f9188555f4642c940ddc92271a6", "target": 1, "func": "static int decode_frame(AVCodecContext *avctx,\n\n                        void *data, int *got_frame,\n\n                        AVPacket *avpkt)\n\n{\n\n    PicContext *s = avctx->priv_data;\n\n    AVFrame *frame = data;\n\n    uint32_t *palette;\n\n    int bits_per_plane, bpp, etype, esize, npal, pos_after_pal;\n\n    int i, x, y, plane, tmp, ret, val;\n\n\n\n    bytestream2_init(&s->g, avpkt->data, avpkt->size);\n\n\n\n    if (bytestream2_get_bytes_left(&s->g) < 11)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (bytestream2_get_le16u(&s->g) != 0x1234)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    s->width       = bytestream2_get_le16u(&s->g);\n\n    s->height      = bytestream2_get_le16u(&s->g);\n\n    bytestream2_skip(&s->g, 4);\n\n    tmp            = bytestream2_get_byteu(&s->g);\n\n    bits_per_plane = tmp & 0xF;\n\n    s->nb_planes   = (tmp >> 4) + 1;\n\n    bpp            = bits_per_plane * s->nb_planes;\n\n    if (bits_per_plane > 8 || bpp < 1 || bpp > 32) {\n\n        avpriv_request_sample(avctx, \"Unsupported bit depth\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if (bytestream2_peek_byte(&s->g) == 0xFF || bpp == 1 || bpp == 4 || bpp == 8) {\n\n        bytestream2_skip(&s->g, 2);\n\n        etype = bytestream2_get_le16(&s->g);\n\n        esize = bytestream2_get_le16(&s->g);\n\n        if (bytestream2_get_bytes_left(&s->g) < esize)\n\n            return AVERROR_INVALIDDATA;\n\n    } else {\n\n        etype = -1;\n\n        esize = 0;\n\n    }\n\n\n\n    avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n\n\n    if (s->width != avctx->width && s->height != avctx->height) {\n\n        if (av_image_check_size(s->width, s->height, 0, avctx) < 0)\n\n            return -1;\n\n        avcodec_set_dimensions(avctx, s->width, s->height);\n\n    }\n\n\n\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n\n        return ret;\n\n    memset(frame->data[0], 0, s->height * frame->linesize[0]);\n\n    frame->pict_type           = AV_PICTURE_TYPE_I;\n\n    frame->palette_has_changed = 1;\n\n\n\n    pos_after_pal = bytestream2_tell(&s->g) + esize;\n\n    palette = (uint32_t*)frame->data[1];\n\n    if (etype == 1 && esize > 1 && bytestream2_peek_byte(&s->g) < 6) {\n\n        int idx = bytestream2_get_byte(&s->g);\n\n        npal = 4;\n\n        for (i = 0; i < npal; i++)\n\n            palette[i] = ff_cga_palette[ cga_mode45_index[idx][i] ];\n\n    } else if (etype == 2) {\n\n        npal = FFMIN(esize, 16);\n\n        for (i = 0; i < npal; i++) {\n\n            int pal_idx = bytestream2_get_byte(&s->g);\n\n            palette[i]  = ff_cga_palette[FFMIN(pal_idx, 15)];\n\n        }\n\n    } else if (etype == 3) {\n\n        npal = FFMIN(esize, 16);\n\n        for (i = 0; i < npal; i++) {\n\n            int pal_idx = bytestream2_get_byte(&s->g);\n\n            palette[i]  = ff_ega_palette[FFMIN(pal_idx, 63)];\n\n        }\n\n    } else if (etype == 4 || etype == 5) {\n\n        npal = FFMIN(esize / 3, 256);\n\n        for (i = 0; i < npal; i++) {\n\n            palette[i] = bytestream2_get_be24(&s->g) << 2;\n\n            palette[i] |= 0xFFU << 24 | palette[i] >> 6 & 0x30303;\n\n        }\n\n    } else {\n\n        if (bpp == 1) {\n\n            npal = 2;\n\n            palette[0] = 0xFF000000;\n\n            palette[1] = 0xFFFFFFFF;\n\n        } else if (bpp == 2) {\n\n            npal = 4;\n\n            for (i = 0; i < npal; i++)\n\n                palette[i] = ff_cga_palette[ cga_mode45_index[0][i] ];\n\n        } else {\n\n            npal = 16;\n\n            memcpy(palette, ff_cga_palette, npal * 4);\n\n        }\n\n    }\n\n    // fill remaining palette entries\n\n    memset(palette + npal, 0, AVPALETTE_SIZE - npal * 4);\n\n    // skip remaining palette bytes\n\n    bytestream2_seek(&s->g, pos_after_pal, SEEK_SET);\n\n\n\n    val = 0;\n\n    y = s->height - 1;\n\n    if (bytestream2_get_le16(&s->g)) {\n\n        x = 0;\n\n        plane = 0;\n\n        while (y >= 0 && bytestream2_get_bytes_left(&s->g) >= 6) {\n\n            int stop_size, marker, t1, t2;\n\n\n\n            t1        = bytestream2_get_bytes_left(&s->g);\n\n            t2        = bytestream2_get_le16(&s->g);\n\n            stop_size = t1 - FFMIN(t1, t2);\n\n            // ignore uncompressed block size\n\n            bytestream2_skip(&s->g, 2);\n\n            marker    = bytestream2_get_byte(&s->g);\n\n\n\n            while (plane < s->nb_planes && y >= 0 &&\n\n                   bytestream2_get_bytes_left(&s->g) > stop_size) {\n\n                int run = 1;\n\n                val = bytestream2_get_byte(&s->g);\n\n                if (val == marker) {\n\n                    run = bytestream2_get_byte(&s->g);\n\n                    if (run == 0)\n\n                        run = bytestream2_get_le16(&s->g);\n\n                    val = bytestream2_get_byte(&s->g);\n\n                }\n\n                if (!bytestream2_get_bytes_left(&s->g))\n\n                    break;\n\n\n\n                if (bits_per_plane == 8) {\n\n                    picmemset_8bpp(s, frame, val, run, &x, &y);\n\n                    if (y < 0)\n\n                        goto finish;\n\n                } else {\n\n                    picmemset(s, frame, val, run, &x, &y, &plane, bits_per_plane);\n\n                }\n\n            }\n\n        }\n\n\n\n        if (x < avctx->width && y >= 0) {\n\n            int run = (y + 1) * avctx->width - x;\n\n            if (bits_per_plane == 8)\n\n                picmemset_8bpp(s, frame, val, run, &x, &y);\n\n            else\n\n                picmemset(s, frame, val, run / (8 / bits_per_plane), &x, &y, &plane, bits_per_plane);\n\n        }\n\n    } else {\n\n        while (y >= 0 && bytestream2_get_bytes_left(&s->g) > 0) {\n\n            memcpy(frame->data[0] + y * frame->linesize[0], s->g.buffer, FFMIN(avctx->width, bytestream2_get_bytes_left(&s->g)));\n\n            bytestream2_skip(&s->g, avctx->width);\n\n            y--;\n\n        }\n\n    }\n\nfinish:\n\n\n\n    *got_frame      = 1;\n\n    return avpkt->size;\n\n}\n", "idx": 22375}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int voc_probe(AVProbeData *p)\n\n{\n\n    int version, check;\n\n\n\n    if (p->buf_size < 26)\n\n        return 0;\n\n    if (memcmp(p->buf, voc_magic, sizeof(voc_magic) - 1))\n\n        return 0;\n\n    version = p->buf[22] | (p->buf[23] << 8);\n\n    check = p->buf[24] | (p->buf[25] << 8);\n\n    if (~version + 0x1234 != check)\n\n        return 10;\n\n\n\n    return AVPROBE_SCORE_MAX;\n\n}\n", "idx": 22379}
{"project": "FFmpeg", "commit_id": "130c6497d2e511d1363cb51ddf68dc9cc2c2f987", "target": 1, "func": "static int filter_frame(AVFilterLink *inlink, AVFilterBufferRef *cur_buf)\n\n{\n\n    AlphaExtractContext *extract = inlink->dst->priv;\n\n    AVFilterLink *outlink = inlink->dst->outputs[0];\n\n    AVFilterBufferRef *out_buf =\n\n        ff_get_video_buffer(outlink, AV_PERM_WRITE, outlink->w, outlink->h);\n\n    int ret;\n\n\n\n    if (!out_buf) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto end;\n\n    }\n\n    avfilter_copy_buffer_ref_props(out_buf, cur_buf);\n\n\n\n    if (extract->is_packed_rgb) {\n\n        int x, y;\n\n        uint8_t *pin, *pout;\n\n        for (y = 0; y < out_buf->video->h; y++) {\n\n            pin = cur_buf->data[0] + y * cur_buf->linesize[0] + extract->rgba_map[A];\n\n            pout = out_buf->data[0] + y * out_buf->linesize[0];\n\n            for (x = 0; x < out_buf->video->w; x++) {\n\n                *pout = *pin;\n\n                pout += 1;\n\n                pin += 4;\n\n            }\n\n        }\n\n    } else {\n\n        const int linesize = FFMIN(out_buf->linesize[Y], cur_buf->linesize[A]);\n\n        int y;\n\n        for (y = 0; y < out_buf->video->h; y++) {\n\n            memcpy(out_buf->data[Y] + y * out_buf->linesize[Y],\n\n                   cur_buf->data[A] + y * cur_buf->linesize[A],\n\n                   linesize);\n\n        }\n\n    }\n\n\n\n    ret = ff_filter_frame(outlink, out_buf);\n\n\n\nend:\n\n    avfilter_unref_buffer(cur_buf);\n\n    return ret;\n\n}\n", "idx": 22380}
{"project": "FFmpeg", "commit_id": "313b52fbfff47ed934cdeccaebda9b3406466575", "target": 1, "func": "static av_cold int alac_decode_init(AVCodecContext * avctx)\n\n{\n\n    ALACContext *alac = avctx->priv_data;\n\n    alac->avctx = avctx;\n\n    alac->context_initialized = 0;\n\n\n\n    alac->numchannels = alac->avctx->channels;\n\n\n\n    return 0;\n\n}\n", "idx": 22382}
{"project": "FFmpeg", "commit_id": "e7e5114c506957f40aafd794e06de1a7e341e9d5", "target": 1, "func": "static int cinepak_decode_vectors (CinepakContext *s, cvid_strip *strip,\n\n                                   int chunk_id, int size, const uint8_t *data)\n\n{\n\n    const uint8_t   *eod = (data + size);\n\n    uint32_t         flag, mask;\n\n    uint8_t         *cb0, *cb1, *cb2, *cb3;\n\n    unsigned int     x, y;\n\n    char            *ip0, *ip1, *ip2, *ip3;\n\n\n\n    flag = 0;\n\n    mask = 0;\n\n\n\n    for (y=strip->y1; y < strip->y2; y+=4) {\n\n\n\n/* take care of y dimension not being multiple of 4, such streams exist */\n\n        ip0 = ip1 = ip2 = ip3 = s->frame->data[0] +\n\n          (s->palette_video?strip->x1:strip->x1*3) + (y * s->frame->linesize[0]);\n\n        if(s->avctx->height - y > 1) {\n\n            ip1 = ip0 + s->frame->linesize[0];\n\n            if(s->avctx->height - y > 2) {\n\n                ip2 = ip1 + s->frame->linesize[0];\n\n                if(s->avctx->height - y > 3) {\n\n                    ip3 = ip2 + s->frame->linesize[0];\n\n                }\n\n            }\n\n        }\n\n/* to get the correct picture for not-multiple-of-4 cases let us fill\n\n * each block from the bottom up, thus possibly overwriting the top line\n\n * more than once but ending with the correct data in place\n\n * (instead of in-loop checking) */\n\n\n\n        for (x=strip->x1; x < strip->x2; x+=4) {\n\n            if ((chunk_id & 0x01) && !(mask >>= 1)) {\n\n                if ((data + 4) > eod)\n\n                    return AVERROR_INVALIDDATA;\n\n\n\n                flag  = AV_RB32 (data);\n\n                data += 4;\n\n                mask  = 0x80000000;\n\n            }\n\n\n\n            if (!(chunk_id & 0x01) || (flag & mask)) {\n\n                if (!(chunk_id & 0x02) && !(mask >>= 1)) {\n\n                    if ((data + 4) > eod)\n\n                        return AVERROR_INVALIDDATA;\n\n\n\n                    flag  = AV_RB32 (data);\n\n                    data += 4;\n\n                    mask  = 0x80000000;\n\n                }\n\n\n\n                if ((chunk_id & 0x02) || (~flag & mask)) {\n\n                    uint8_t *p;\n\n                    if (data >= eod)\n\n                        return AVERROR_INVALIDDATA;\n\n\n\n                    p = strip->v1_codebook[*data++];\n\n                    if (s->palette_video) {\n\n                        ip3[0] = ip3[1] = ip2[0] = ip2[1] = p[6];\n\n                        ip3[2] = ip3[3] = ip2[2] = ip2[3] = p[9];\n\n                        ip1[0] = ip1[1] = ip0[0] = ip0[1] = p[0];\n\n                        ip1[2] = ip1[3] = ip0[2] = ip0[3] = p[3];\n\n                    } else {\n\n                        p += 6;\n\n                        memcpy(ip3 + 0, p, 3); memcpy(ip3 + 3, p, 3);\n\n                        memcpy(ip2 + 0, p, 3); memcpy(ip2 + 3, p, 3);\n\n                        p += 3; /* ... + 9 */\n\n                        memcpy(ip3 + 6, p, 3); memcpy(ip3 + 9, p, 3);\n\n                        memcpy(ip2 + 6, p, 3); memcpy(ip2 + 9, p, 3);\n\n                        p -= 9; /* ... + 0 */\n\n                        memcpy(ip1 + 0, p, 3); memcpy(ip1 + 3, p, 3);\n\n                        memcpy(ip0 + 0, p, 3); memcpy(ip0 + 3, p, 3);\n\n                        p += 3; /* ... + 3 */\n\n                        memcpy(ip1 + 6, p, 3); memcpy(ip1 + 9, p, 3);\n\n                        memcpy(ip0 + 6, p, 3); memcpy(ip0 + 9, p, 3);\n\n                    }\n\n\n\n                } else if (flag & mask) {\n\n                    if ((data + 4) > eod)\n\n                        return AVERROR_INVALIDDATA;\n\n\n\n                    cb0 = strip->v4_codebook[*data++];\n\n                    cb1 = strip->v4_codebook[*data++];\n\n                    cb2 = strip->v4_codebook[*data++];\n\n                    cb3 = strip->v4_codebook[*data++];\n\n                    if (s->palette_video) {\n\n                        uint8_t *p;\n\n                        p = ip3;\n\n                        *p++ = cb2[6];\n\n                        *p++ = cb2[9];\n\n                        *p++ = cb3[6];\n\n                        *p   = cb3[9];\n\n                        p = ip2;\n\n                        *p++ = cb2[0];\n\n                        *p++ = cb2[3];\n\n                        *p++ = cb3[0];\n\n                        *p   = cb3[3];\n\n                        p = ip1;\n\n                        *p++ = cb0[6];\n\n                        *p++ = cb0[9];\n\n                        *p++ = cb1[6];\n\n                        *p   = cb1[9];\n\n                        p = ip0;\n\n                        *p++ = cb0[0];\n\n                        *p++ = cb0[3];\n\n                        *p++ = cb1[0];\n\n                        *p   = cb1[3];\n\n                    } else {\n\n                        memcpy(ip3 + 0, cb2 + 6, 6);\n\n                        memcpy(ip3 + 6, cb3 + 6, 6);\n\n                        memcpy(ip2 + 0, cb2 + 0, 6);\n\n                        memcpy(ip2 + 6, cb3 + 0, 6);\n\n                        memcpy(ip1 + 0, cb0 + 6, 6);\n\n                        memcpy(ip1 + 6, cb1 + 6, 6);\n\n                        memcpy(ip0 + 0, cb0 + 0, 6);\n\n                        memcpy(ip0 + 6, cb1 + 0, 6);\n\n                    }\n\n\n\n                }\n\n            }\n\n\n\n            if (s->palette_video) {\n\n                ip0 += 4;  ip1 += 4;\n\n                ip2 += 4;  ip3 += 4;\n\n            } else {\n\n                ip0 += 12;  ip1 += 12;\n\n                ip2 += 12;  ip3 += 12;\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22385}
{"project": "FFmpeg", "commit_id": "de7d29063133b240a9fe2c26049b35a6a028c8a1", "target": 1, "func": "AVRational av_d2q(double d, int max)\n\n{\n\n    AVRational a;\n\n#define LOG2  0.69314718055994530941723212145817656807550013436025\n\n    int exponent;\n\n    int64_t den;\n\n    if (isnan(d))\n\n        return (AVRational) { 0,0 };\n\n    if (isinf(d))\n\n        return (AVRational) { d < 0 ? -1 : 1, 0 };\n\n    exponent = FFMAX( (int)(log(fabs(d) + 1e-20)/LOG2), 0);\n\n    den = 1LL << (61 - exponent);\n\n    av_reduce(&a.num, &a.den, (int64_t)(d * den + 0.5), den, max);\n\n\n\n    return a;\n\n}\n", "idx": 22386}
{"project": "FFmpeg", "commit_id": "221b804f3491638ecf2eec1302c669ad2d9ec799", "target": 1, "func": "static void selfTest(uint8_t *src[3], int stride[3], int w, int h){\n\n\tenum PixelFormat srcFormat, dstFormat;\n\n\tint srcW, srcH, dstW, dstH;\n\n\tint flags;\n\n\n\n\tfor(srcFormat = 0; srcFormat < PIX_FMT_NB; srcFormat++) {\n\n\t\tfor(dstFormat = 0; dstFormat < PIX_FMT_NB; dstFormat++) {\n\n\t\t\tprintf(\"%s -> %s\\n\",\n\n\t\t\t\t\tsws_format_name(srcFormat),\n\n\t\t\t\t\tsws_format_name(dstFormat));\n\n\n\n\t\t\tsrcW= w;\n\n\t\t\tsrcH= h;\n\n\t\t\tfor(dstW=w - w/3; dstW<= 4*w/3; dstW+= w/3){\n\n\t\t\t\tfor(dstH=h - h/3; dstH<= 4*h/3; dstH+= h/3){\n\n\t\t\t\t\tfor(flags=1; flags<33; flags*=2) {\n\n\t\t\t\t\t\tint res;\n\n\n\n\t\t\t\t\t\tres = doTest(src, stride, w, h, srcFormat, dstFormat,\n\n\t\t\t\t\t\t\tsrcW, srcH, dstW, dstH, flags);\n\n\t\t\t\t\t\tif (res < 0) {\n\n\t\t\t\t\t\t\tdstW = 4 * w / 3;\n\n\t\t\t\t\t\t\tdstH = 4 * h / 3;\n\n\t\t\t\t\t\t\tflags = 33;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n}\n", "idx": 22388}
{"project": "FFmpeg", "commit_id": "bc488ec28aec4bc91ba47283c49c9f7f25696eaa", "target": 1, "func": "static int dct_max8x8_c(MpegEncContext *s, uint8_t *src1,\n\n                        uint8_t *src2, ptrdiff_t stride, int h)\n\n{\n\n    LOCAL_ALIGNED_16(int16_t, temp, [64]);\n\n    int sum = 0, i;\n\n\n\n    av_assert2(h == 8);\n\n\n\n    s->pdsp.diff_pixels(temp, src1, src2, stride);\n\n    s->fdsp.fdct(temp);\n\n\n\n    for (i = 0; i < 64; i++)\n\n        sum = FFMAX(sum, FFABS(temp[i]));\n\n\n\n    return sum;\n\n}\n", "idx": 22390}
{"project": "FFmpeg", "commit_id": "d6737539e77e78fca9a04914d51996cfd1ccc55c", "target": 0, "func": "static void intra_predict_mad_cow_dc_l00_8x8_msa(uint8_t *src, int32_t stride)\n\n{\n\n    uint8_t lp_cnt;\n\n    uint32_t src0 = 0;\n\n    uint64_t out0, out1;\n\n\n\n    for (lp_cnt = 0; lp_cnt < 4; lp_cnt++) {\n\n        src0 += src[lp_cnt * stride - 1];\n\n    }\n\n\n\n    src0 = (src0 + 2) >> 2;\n\n    out0 = src0 * 0x0101010101010101;\n\n    out1 = 0x8080808080808080;\n\n\n\n    for (lp_cnt = 4; lp_cnt--;) {\n\n        SD(out0, src);\n\n        SD(out1, src + stride * 4);\n\n        src += stride;\n\n    }\n\n}\n", "idx": 22391}
{"project": "FFmpeg", "commit_id": "e16e49ac90f6da9e019fdf23084cbb256d14bd9c", "target": 0, "func": "static void term_exit(void)\n\n{\n\n#ifndef __MINGW32__\n\n    tcsetattr (0, TCSANOW, &oldtty);\n\n#endif\n\n}\n", "idx": 22392}
{"project": "FFmpeg", "commit_id": "a483aae7d8bcd37b50bb86345606bbcd2301110b", "target": 0, "func": "static void copy_parameter_set(void **to, void **from, int count, int size)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < count; i++) {\n\n        if (to[i] && !from[i])\n\n            av_freep(&to[i]);\n\n        else if (from[i] && !to[i])\n\n            to[i] = av_malloc(size);\n\n\n\n        if (from[i])\n\n            memcpy(to[i], from[i], size);\n\n    }\n\n}\n", "idx": 22393}
{"project": "FFmpeg", "commit_id": "c16e99e3b3c02edcf33245468731d414eab97dac", "target": 0, "func": "av_cold void swri_resample_dsp_x86_init(ResampleContext *c)\n\n{\n\n    int av_unused mm_flags = av_get_cpu_flags();\n\n\n\n    switch(c->format){\n\n    case AV_SAMPLE_FMT_S16P:\n\n        if (ARCH_X86_32 && EXTERNAL_MMXEXT(mm_flags)) {\n\n            c->dsp.resample = c->linear ? ff_resample_linear_int16_mmxext\n\n                                        : ff_resample_common_int16_mmxext;\n\n        }\n\n        if (EXTERNAL_SSE2(mm_flags)) {\n\n            c->dsp.resample = c->linear ? ff_resample_linear_int16_sse2\n\n                                        : ff_resample_common_int16_sse2;\n\n        }\n\n        if (EXTERNAL_XOP(mm_flags)) {\n\n            c->dsp.resample = c->linear ? ff_resample_linear_int16_xop\n\n                                        : ff_resample_common_int16_xop;\n\n        }\n\n        break;\n\n    case AV_SAMPLE_FMT_FLTP:\n\n        if (EXTERNAL_SSE(mm_flags)) {\n\n            c->dsp.resample = c->linear ? ff_resample_linear_float_sse\n\n                                        : ff_resample_common_float_sse;\n\n        }\n\n        if (EXTERNAL_AVX(mm_flags)) {\n\n            c->dsp.resample = c->linear ? ff_resample_linear_float_avx\n\n                                        : ff_resample_common_float_avx;\n\n        }\n\n        if (EXTERNAL_FMA3(mm_flags)) {\n\n            c->dsp.resample = c->linear ? ff_resample_linear_float_fma3\n\n                                        : ff_resample_common_float_fma3;\n\n        }\n\n        if (EXTERNAL_FMA4(mm_flags)) {\n\n            c->dsp.resample = c->linear ? ff_resample_linear_float_fma4\n\n                                        : ff_resample_common_float_fma4;\n\n        }\n\n        break;\n\n    case AV_SAMPLE_FMT_DBLP:\n\n        if (EXTERNAL_SSE2(mm_flags)) {\n\n            c->dsp.resample = c->linear ? ff_resample_linear_double_sse2\n\n                                        : ff_resample_common_double_sse2;\n\n        }\n\n        break;\n\n    }\n\n}\n", "idx": 22394}
{"project": "FFmpeg", "commit_id": "255d4e717faa98ab783401acd68a278af32f6360", "target": 0, "func": "alloc_parameter_set(H264Context *h, void **vec, const unsigned int id, const unsigned int max,\n\n                    const size_t size, const char *name)\n\n{\n\n    if(id>=max) {\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"%s_id (%d) out of range\\n\", name, id);\n\n        return NULL;\n\n    }\n\n\n\n    if(!vec[id]) {\n\n        vec[id] = av_mallocz(size);\n\n        if(vec[id] == NULL)\n\n            av_log(h->s.avctx, AV_LOG_ERROR, \"cannot allocate memory for %s\\n\", name);\n\n    }\n\n    return vec[id];\n\n}\n", "idx": 22395}
{"project": "FFmpeg", "commit_id": "7c79ec66b6cc25a150d33d7397c8f4310b77e70f", "target": 0, "func": "static int filter_frame(AVFilterLink *inlink, AVFrame *ref)\n\n{\n\n    FrameStepContext *framestep = inlink->dst->priv;\n\n\n\n    if (!(framestep->frame_count++ % framestep->frame_step)) {\n\n        framestep->frame_selected = 1;\n\n        return ff_filter_frame(inlink->dst->outputs[0], ref);\n\n    } else {\n\n        framestep->frame_selected = 0;\n\n        av_frame_free(&ref);\n\n        return 0;\n\n    }\n\n}\n", "idx": 22396}
{"project": "FFmpeg", "commit_id": "4dcb69cc12d00d46f93a07178e2087a8d27c8f64", "target": 0, "func": "void ff_aac_search_for_is(AACEncContext *s, AVCodecContext *avctx, ChannelElement *cpe)\n\n{\n\n    SingleChannelElement *sce0 = &cpe->ch[0];\n\n    SingleChannelElement *sce1 = &cpe->ch[1];\n\n    int start = 0, count = 0, w, w2, g, i, prev_sf1 = -1;\n\n    const float freq_mult = avctx->sample_rate/(1024.0f/sce0->ics.num_windows)/2.0f;\n\n    uint8_t nextband1[128];\n\n\n\n    if (!cpe->common_window)\n\n        return;\n\n\n\n    /** Scout out next nonzero bands */\n\n    ff_init_nextband_map(sce1, nextband1);\n\n\n\n    for (w = 0; w < sce0->ics.num_windows; w += sce0->ics.group_len[w]) {\n\n        start = 0;\n\n        for (g = 0;  g < sce0->ics.num_swb; g++) {\n\n            if (start*freq_mult > INT_STEREO_LOW_LIMIT*(s->lambda/170.0f) &&\n\n                cpe->ch[0].band_type[w*16+g] != NOISE_BT && !cpe->ch[0].zeroes[w*16+g] &&\n\n                cpe->ch[1].band_type[w*16+g] != NOISE_BT && !cpe->ch[1].zeroes[w*16+g] &&\n\n                ff_sfdelta_can_remove_band(sce1, nextband1, prev_sf1, w*16+g)) {\n\n                float ener0 = 0.0f, ener1 = 0.0f, ener01 = 0.0f, ener01p = 0.0f;\n\n                struct AACISError ph_err1, ph_err2, *best;\n\n                if (sce0->band_type[w*16+g] == NOISE_BT ||\n\n                    sce1->band_type[w*16+g] == NOISE_BT) {\n\n                    start += sce0->ics.swb_sizes[g];\n\n                    continue;\n\n                }\n\n                for (w2 = 0; w2 < sce0->ics.group_len[w]; w2++) {\n\n                    for (i = 0; i < sce0->ics.swb_sizes[g]; i++) {\n\n                        float coef0 = fabsf(sce0->coeffs[start+(w+w2)*128+i]);\n\n                        float coef1 = fabsf(sce1->coeffs[start+(w+w2)*128+i]);\n\n                        ener0  += coef0*coef0;\n\n                        ener1  += coef1*coef1;\n\n                        ener01 += (coef0 + coef1)*(coef0 + coef1);\n\n                        ener01p += (coef0 - coef1)*(coef0 - coef1);\n\n                    }\n\n                }\n\n                ph_err1 = ff_aac_is_encoding_err(s, cpe, start, w, g,\n\n                                                 ener0, ener1, ener01p, 0, -1);\n\n                ph_err2 = ff_aac_is_encoding_err(s, cpe, start, w, g,\n\n                                                 ener0, ener1, ener01, 0, +1);\n\n                best = (ph_err1.pass && ph_err1.error < ph_err2.error) ? &ph_err1 : &ph_err2;\n\n                if (best->pass) {\n\n                    cpe->is_mask[w*16+g] = 1;\n\n                    cpe->ms_mask[w*16+g] = 0;\n\n                    cpe->ch[0].is_ener[w*16+g] = sqrt(ener0 / best->ener01);\n\n                    cpe->ch[1].is_ener[w*16+g] = ener0/ener1;\n\n                    cpe->ch[1].band_type[w*16+g] = (best->phase > 0) ? INTENSITY_BT : INTENSITY_BT2;\n\n                    count++;\n\n                }\n\n            }\n\n            if (!sce1->zeroes[w*16+g] && sce1->band_type[w*16+g] < RESERVED_BT)\n\n                prev_sf1 = sce1->sf_idx[w*16+g];\n\n            start += sce0->ics.swb_sizes[g];\n\n        }\n\n    }\n\n    cpe->is_mode = !!count;\n\n}\n", "idx": 22405}
{"project": "FFmpeg", "commit_id": "6cd325c1064c80f47b596f3b2bea24f227b198f2", "target": 0, "func": "int ff_aac_ac3_parse(AVCodecParserContext *s1,\n\n                     AVCodecContext *avctx,\n\n                     const uint8_t **poutbuf, int *poutbuf_size,\n\n                     const uint8_t *buf, int buf_size)\n\n{\n\n    AACAC3ParseContext *s = s1->priv_data;\n\n    const uint8_t *buf_ptr;\n\n    int len, sample_rate, bit_rate, channels, samples;\n\n\n\n    *poutbuf = NULL;\n\n    *poutbuf_size = 0;\n\n\n\n    buf_ptr = buf;\n\n    while (buf_size > 0) {\n\n        int size_needed= s->frame_size ? s->frame_size : s->header_size;\n\n        len = s->inbuf_ptr - s->inbuf;\n\n\n\n        if(len<size_needed){\n\n            len = FFMIN(size_needed - len, buf_size);\n\n            memcpy(s->inbuf_ptr, buf_ptr, len);\n\n            buf_ptr      += len;\n\n            s->inbuf_ptr += len;\n\n            buf_size     -= len;\n\n        }\n\n\n\n        if (s->frame_size == 0) {\n\n            if ((s->inbuf_ptr - s->inbuf) == s->header_size) {\n\n                len = s->sync(s->inbuf, &channels, &sample_rate, &bit_rate,\n\n                              &samples);\n\n                if (len == 0) {\n\n                    /* no sync found : move by one byte (inefficient, but simple!) */\n\n                    memmove(s->inbuf, s->inbuf + 1, s->header_size - 1);\n\n                    s->inbuf_ptr--;\n\n                } else {\n\n                    s->frame_size = len;\n\n                    /* update codec info */\n\n                    avctx->sample_rate = sample_rate;\n\n                    avctx->channels = channels;\n\n                    /* allow downmixing to mono or stereo for AC3 */\n\n                    if(avctx->request_channels > 0 &&\n\n                            avctx->request_channels < channels &&\n\n                            avctx->request_channels <= 2 &&\n\n                            avctx->codec_id == CODEC_ID_AC3) {\n\n                        avctx->channels = avctx->request_channels;\n\n                    }\n\n                    avctx->bit_rate = bit_rate;\n\n                    avctx->frame_size = samples;\n\n                }\n\n            }\n\n        } else {\n\n            if(s->inbuf_ptr - s->inbuf == s->frame_size){\n\n                *poutbuf = s->inbuf;\n\n                *poutbuf_size = s->frame_size;\n\n                s->inbuf_ptr = s->inbuf;\n\n                s->frame_size = 0;\n\n                break;\n\n            }\n\n        }\n\n    }\n\n    return buf_ptr - buf;\n\n}\n", "idx": 22416}
{"project": "FFmpeg", "commit_id": "298c4e3c522a1bc43cb557efe2e443be2ee80bb5", "target": 0, "func": "static int mpegts_read_header(AVFormatContext *s,\n\n                              AVFormatParameters *ap)\n\n{\n\n    MpegTSContext *ts = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    uint8_t buf[5*1024];\n\n    int len;\n\n    int64_t pos;\n\n\n\n#if FF_API_FORMAT_PARAMETERS\n\n    if (ap) {\n\n        if (ap->mpeg2ts_compute_pcr)\n\n            ts->mpeg2ts_compute_pcr = ap->mpeg2ts_compute_pcr;\n\n        if(ap->mpeg2ts_raw){\n\n            av_log(s, AV_LOG_ERROR, \"use mpegtsraw_demuxer!\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n#endif\n\n\n\n    /* read the first 1024 bytes to get packet size */\n\n    pos = avio_tell(pb);\n\n    len = avio_read(pb, buf, sizeof(buf));\n\n    if (len != sizeof(buf))\n\n        goto fail;\n\n    ts->raw_packet_size = get_packet_size(buf, sizeof(buf));\n\n    if (ts->raw_packet_size <= 0)\n\n        goto fail;\n\n    ts->stream = s;\n\n    ts->auto_guess = 0;\n\n\n\n    if (s->iformat == &ff_mpegts_demuxer) {\n\n        /* normal demux */\n\n\n\n        /* first do a scaning to get all the services */\n\n        if (avio_seek(pb, pos, SEEK_SET) < 0)\n\n            av_log(s, AV_LOG_ERROR, \"Unable to seek back to the start\\n\");\n\n\n\n        mpegts_open_section_filter(ts, SDT_PID, sdt_cb, ts, 1);\n\n\n\n        mpegts_open_section_filter(ts, PAT_PID, pat_cb, ts, 1);\n\n\n\n        handle_packets(ts, s->probesize / ts->raw_packet_size);\n\n        /* if could not find service, enable auto_guess */\n\n\n\n        ts->auto_guess = 1;\n\n\n\n        av_dlog(ts->stream, \"tuning done\\n\");\n\n\n\n        s->ctx_flags |= AVFMTCTX_NOHEADER;\n\n    } else {\n\n        AVStream *st;\n\n        int pcr_pid, pid, nb_packets, nb_pcrs, ret, pcr_l;\n\n        int64_t pcrs[2], pcr_h;\n\n        int packet_count[2];\n\n        uint8_t packet[TS_PACKET_SIZE];\n\n\n\n        /* only read packets */\n\n\n\n        st = av_new_stream(s, 0);\n\n        if (!st)\n\n            goto fail;\n\n        av_set_pts_info(st, 60, 1, 27000000);\n\n        st->codec->codec_type = AVMEDIA_TYPE_DATA;\n\n        st->codec->codec_id = CODEC_ID_MPEG2TS;\n\n\n\n        /* we iterate until we find two PCRs to estimate the bitrate */\n\n        pcr_pid = -1;\n\n        nb_pcrs = 0;\n\n        nb_packets = 0;\n\n        for(;;) {\n\n            ret = read_packet(s, packet, ts->raw_packet_size);\n\n            if (ret < 0)\n\n                return -1;\n\n            pid = AV_RB16(packet + 1) & 0x1fff;\n\n            if ((pcr_pid == -1 || pcr_pid == pid) &&\n\n                parse_pcr(&pcr_h, &pcr_l, packet) == 0) {\n\n                pcr_pid = pid;\n\n                packet_count[nb_pcrs] = nb_packets;\n\n                pcrs[nb_pcrs] = pcr_h * 300 + pcr_l;\n\n                nb_pcrs++;\n\n                if (nb_pcrs >= 2)\n\n                    break;\n\n            }\n\n            nb_packets++;\n\n        }\n\n\n\n        /* NOTE1: the bitrate is computed without the FEC */\n\n        /* NOTE2: it is only the bitrate of the start of the stream */\n\n        ts->pcr_incr = (pcrs[1] - pcrs[0]) / (packet_count[1] - packet_count[0]);\n\n        ts->cur_pcr = pcrs[0] - ts->pcr_incr * packet_count[0];\n\n        s->bit_rate = (TS_PACKET_SIZE * 8) * 27e6 / ts->pcr_incr;\n\n        st->codec->bit_rate = s->bit_rate;\n\n        st->start_time = ts->cur_pcr;\n\n        av_dlog(ts->stream, \"start=%0.3f pcr=%0.3f incr=%d\\n\",\n\n                st->start_time / 1000000.0, pcrs[0] / 27e6, ts->pcr_incr);\n\n    }\n\n\n\n    avio_seek(pb, pos, SEEK_SET);\n\n    return 0;\n\n fail:\n\n    return -1;\n\n}\n", "idx": 22424}
{"project": "FFmpeg", "commit_id": "043800a96888f1a04732f12316ba477d8f098d3f", "target": 0, "func": "static int end_frame(AVFilterLink *inlink)\n\n{\n\n    AVFilterContext    *ctx = inlink->dst;\n\n    FPSContext           *s = ctx->priv;\n\n    AVFilterLink   *outlink = ctx->outputs[0];\n\n    AVFilterBufferRef  *buf = inlink->cur_buf;\n\n    int64_t delta;\n\n    int i, ret;\n\n\n\n    inlink->cur_buf = NULL;\n\n    s->frames_in++;\n\n    /* discard frames until we get the first timestamp */\n\n    if (s->pts == AV_NOPTS_VALUE) {\n\n        if (buf->pts != AV_NOPTS_VALUE) {\n\n            write_to_fifo(s->fifo, buf);\n\n            s->first_pts = s->pts = buf->pts;\n\n        } else {\n\n            av_log(ctx, AV_LOG_WARNING, \"Discarding initial frame(s) with no \"\n\n                   \"timestamp.\\n\");\n\n            avfilter_unref_buffer(buf);\n\n            s->drop++;\n\n        }\n\n        return 0;\n\n    }\n\n\n\n    /* now wait for the next timestamp */\n\n    if (buf->pts == AV_NOPTS_VALUE) {\n\n        return write_to_fifo(s->fifo, buf);\n\n    }\n\n\n\n    /* number of output frames */\n\n    delta = av_rescale_q(buf->pts - s->pts, inlink->time_base,\n\n                         outlink->time_base);\n\n\n\n    if (delta < 1) {\n\n        /* drop the frame and everything buffered except the first */\n\n        AVFilterBufferRef *tmp;\n\n        int drop = av_fifo_size(s->fifo)/sizeof(AVFilterBufferRef*);\n\n\n\n        av_log(ctx, AV_LOG_DEBUG, \"Dropping %d frame(s).\\n\", drop);\n\n        s->drop += drop;\n\n\n\n        av_fifo_generic_read(s->fifo, &tmp, sizeof(tmp), NULL);\n\n        flush_fifo(s->fifo);\n\n        ret = write_to_fifo(s->fifo, tmp);\n\n\n\n        avfilter_unref_buffer(buf);\n\n        return ret;\n\n    }\n\n\n\n    /* can output >= 1 frames */\n\n    for (i = 0; i < delta; i++) {\n\n        AVFilterBufferRef *buf_out;\n\n        av_fifo_generic_read(s->fifo, &buf_out, sizeof(buf_out), NULL);\n\n\n\n        /* duplicate the frame if needed */\n\n        if (!av_fifo_size(s->fifo) && i < delta - 1) {\n\n            av_log(ctx, AV_LOG_DEBUG, \"Duplicating frame.\\n\");\n\n            write_to_fifo(s->fifo, avfilter_ref_buffer(buf_out, AV_PERM_READ));\n\n            s->dup++;\n\n        }\n\n\n\n        buf_out->pts = av_rescale_q(s->first_pts, inlink->time_base,\n\n                                    outlink->time_base) + s->frames_out;\n\n\n\n        if ((ret = ff_start_frame(outlink, buf_out)) < 0 ||\n\n            (ret = ff_draw_slice(outlink, 0, outlink->h, 1)) < 0 ||\n\n            (ret = ff_end_frame(outlink)) < 0) {\n\n            avfilter_unref_bufferp(&buf);\n\n            return ret;\n\n        }\n\n\n\n        s->frames_out++;\n\n    }\n\n    flush_fifo(s->fifo);\n\n\n\n    ret = write_to_fifo(s->fifo, buf);\n\n    s->pts = s->first_pts + av_rescale_q(s->frames_out, outlink->time_base, inlink->time_base);\n\n\n\n    return ret;\n\n}\n", "idx": 22425}
{"project": "FFmpeg", "commit_id": "c0175fa92b7edd45a06e4ab16c8e83da0c94a9f6", "target": 1, "func": "static int roq_read_packet(AVFormatContext *s,\n\n                           AVPacket *pkt)\n\n{\n\n    RoqDemuxContext *roq = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int ret = 0;\n\n    unsigned int chunk_size;\n\n    unsigned int chunk_type;\n\n    unsigned int codebook_size;\n\n    unsigned char preamble[RoQ_CHUNK_PREAMBLE_SIZE];\n\n    int packet_read = 0;\n\n    int64_t codebook_offset;\n\n\n\n    while (!packet_read) {\n\n\n\n        if (avio_feof(s->pb))\n\n            return AVERROR(EIO);\n\n\n\n        /* get the next chunk preamble */\n\n        if ((ret = avio_read(pb, preamble, RoQ_CHUNK_PREAMBLE_SIZE)) !=\n\n            RoQ_CHUNK_PREAMBLE_SIZE)\n\n            return AVERROR(EIO);\n\n\n\n        chunk_type = AV_RL16(&preamble[0]);\n\n        chunk_size = AV_RL32(&preamble[2]);\n\n        if(chunk_size > INT_MAX)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        chunk_size = ffio_limit(pb, chunk_size);\n\n\n\n        switch (chunk_type) {\n\n\n\n        case RoQ_INFO:\n\n            if (roq->video_stream_index == -1) {\n\n                AVStream *st = avformat_new_stream(s, NULL);\n\n                if (!st)\n\n                    return AVERROR(ENOMEM);\n\n                avpriv_set_pts_info(st, 63, 1, roq->frame_rate);\n\n                roq->video_stream_index = st->index;\n\n                st->codecpar->codec_type   = AVMEDIA_TYPE_VIDEO;\n\n                st->codecpar->codec_id     = AV_CODEC_ID_ROQ;\n\n                st->codecpar->codec_tag    = 0;  /* no fourcc */\n\n\n\n                if (avio_read(pb, preamble, RoQ_CHUNK_PREAMBLE_SIZE) != RoQ_CHUNK_PREAMBLE_SIZE)\n\n                    return AVERROR(EIO);\n\n                st->codecpar->width  = roq->width  = AV_RL16(preamble);\n\n                st->codecpar->height = roq->height = AV_RL16(preamble + 2);\n\n                break;\n\n            }\n\n            /* don't care about this chunk anymore */\n\n            avio_skip(pb, RoQ_CHUNK_PREAMBLE_SIZE);\n\n            break;\n\n\n\n        case RoQ_QUAD_CODEBOOK:\n\n            if (roq->video_stream_index < 0)\n\n                return AVERROR_INVALIDDATA;\n\n            /* packet needs to contain both this codebook and next VQ chunk */\n\n            codebook_offset = avio_tell(pb) - RoQ_CHUNK_PREAMBLE_SIZE;\n\n            codebook_size = chunk_size;\n\n            avio_skip(pb, codebook_size);\n\n            if (avio_read(pb, preamble, RoQ_CHUNK_PREAMBLE_SIZE) !=\n\n                RoQ_CHUNK_PREAMBLE_SIZE)\n\n                return AVERROR(EIO);\n\n            chunk_size = AV_RL32(&preamble[2]) + RoQ_CHUNK_PREAMBLE_SIZE * 2 +\n\n                codebook_size;\n\n\n\n            if (chunk_size > INT_MAX)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            /* rewind */\n\n            avio_seek(pb, codebook_offset, SEEK_SET);\n\n\n\n            /* load up the packet */\n\n            ret= av_get_packet(pb, pkt, chunk_size);\n\n            if (ret != chunk_size)\n\n                return AVERROR(EIO);\n\n            pkt->stream_index = roq->video_stream_index;\n\n            pkt->pts = roq->video_pts++;\n\n\n\n            packet_read = 1;\n\n            break;\n\n\n\n        case RoQ_SOUND_MONO:\n\n        case RoQ_SOUND_STEREO:\n\n            if (roq->audio_stream_index == -1) {\n\n                AVStream *st = avformat_new_stream(s, NULL);\n\n                if (!st)\n\n                    return AVERROR(ENOMEM);\n\n                avpriv_set_pts_info(st, 32, 1, RoQ_AUDIO_SAMPLE_RATE);\n\n                roq->audio_stream_index = st->index;\n\n                st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n\n                st->codecpar->codec_id = AV_CODEC_ID_ROQ_DPCM;\n\n                st->codecpar->codec_tag = 0;  /* no tag */\n\n                if (chunk_type == RoQ_SOUND_STEREO) {\n\n                    st->codecpar->channels       = 2;\n\n                    st->codecpar->channel_layout = AV_CH_LAYOUT_STEREO;\n\n                } else {\n\n                    st->codecpar->channels       = 1;\n\n                    st->codecpar->channel_layout = AV_CH_LAYOUT_MONO;\n\n                }\n\n                roq->audio_channels    = st->codecpar->channels;\n\n                st->codecpar->sample_rate = RoQ_AUDIO_SAMPLE_RATE;\n\n                st->codecpar->bits_per_coded_sample = 16;\n\n                st->codecpar->bit_rate = st->codecpar->channels * st->codecpar->sample_rate *\n\n                    st->codecpar->bits_per_coded_sample;\n\n                st->codecpar->block_align = st->codecpar->channels * st->codecpar->bits_per_coded_sample;\n\n            }\n\n        case RoQ_QUAD_VQ:\n\n            if (chunk_type == RoQ_QUAD_VQ) {\n\n                if (roq->video_stream_index < 0)\n\n                    return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            /* load up the packet */\n\n            if (av_new_packet(pkt, chunk_size + RoQ_CHUNK_PREAMBLE_SIZE))\n\n                return AVERROR(EIO);\n\n            /* copy over preamble */\n\n            memcpy(pkt->data, preamble, RoQ_CHUNK_PREAMBLE_SIZE);\n\n\n\n            if (chunk_type == RoQ_QUAD_VQ) {\n\n                pkt->stream_index = roq->video_stream_index;\n\n                pkt->pts = roq->video_pts++;\n\n            } else {\n\n                pkt->stream_index = roq->audio_stream_index;\n\n                pkt->pts = roq->audio_frame_count;\n\n                roq->audio_frame_count += (chunk_size / roq->audio_channels);\n\n            }\n\n\n\n            pkt->pos= avio_tell(pb);\n\n            ret = avio_read(pb, pkt->data + RoQ_CHUNK_PREAMBLE_SIZE,\n\n                chunk_size);\n\n            if (ret != chunk_size)\n\n                ret = AVERROR(EIO);\n\n\n\n            packet_read = 1;\n\n            break;\n\n\n\n        default:\n\n            av_log(s, AV_LOG_ERROR, \"  unknown RoQ chunk (%04X)\\n\", chunk_type);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 22426}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(hScale)(int16_t *dst, int dstW, uint8_t *src, int srcW, int xInc,\n\n\t\t\t\t  int16_t *filter, int16_t *filterPos, int filterSize)\n\n{\n\n#ifdef HAVE_MMX\n\n\tassert(filterSize % 4 == 0 && filterSize>0);\n\n\tif(filterSize==4) // allways true for upscaling, sometimes for down too\n\n\t{\n\n\t\tlong counter= -2*dstW;\n\n\t\tfilter-= counter*2;\n\n\t\tfilterPos-= counter/2;\n\n\t\tdst-= counter/2;\n\n\t\tasm volatile(\n\n\t\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"movq \"MANGLE(w02)\", %%mm6\t\\n\\t\"\n\n\t\t\t\"push %%\"REG_BP\"\t\t\\n\\t\" // we use 7 regs here ...\n\n\t\t\t\"mov %%\"REG_a\", %%\"REG_BP\"\t\\n\\t\"\n\n\t\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\t\"movzwl (%2, %%\"REG_BP\"), %%eax\t\\n\\t\"\n\n\t\t\t\"movzwl 2(%2, %%\"REG_BP\"), %%ebx\\n\\t\"\n\n\t\t\t\"movq (%1, %%\"REG_BP\", 4), %%mm1\\n\\t\"\n\n\t\t\t\"movq 8(%1, %%\"REG_BP\", 4), %%mm3\\n\\t\"\n\n\t\t\t\"movd (%3, %%\"REG_a\"), %%mm0\t\\n\\t\"\n\n\t\t\t\"movd (%3, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm2, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm3, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm6, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm0, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"movd %%mm0, (%4, %%\"REG_BP\")\t\\n\\t\"\n\n\t\t\t\"add $4, %%\"REG_BP\"\t\t\\n\\t\"\n\n\t\t\t\" jnc 1b\t\t\t\\n\\t\"\n\n\n\n\t\t\t\"pop %%\"REG_BP\"\t\t\t\\n\\t\"\n\n\t\t\t: \"+a\" (counter)\n\n\t\t\t: \"c\" (filter), \"d\" (filterPos), \"S\" (src), \"D\" (dst)\n\n\t\t\t: \"%\"REG_b\n\n\t\t);\n\n\t}\n\n\telse if(filterSize==8)\n\n\t{\n\n\t\tlong counter= -2*dstW;\n\n\t\tfilter-= counter*4;\n\n\t\tfilterPos-= counter/2;\n\n\t\tdst-= counter/2;\n\n\t\tasm volatile(\n\n\t\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"movq \"MANGLE(w02)\", %%mm6\t\\n\\t\"\n\n\t\t\t\"push %%\"REG_BP\"\t\t\\n\\t\" // we use 7 regs here ...\n\n\t\t\t\"mov %%\"REG_a\", %%\"REG_BP\"\t\\n\\t\"\n\n\t\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\t\"movzwl (%2, %%\"REG_BP\"), %%eax\t\\n\\t\"\n\n\t\t\t\"movzwl 2(%2, %%\"REG_BP\"), %%ebx\\n\\t\"\n\n\t\t\t\"movq (%1, %%\"REG_BP\", 8), %%mm1\\n\\t\"\n\n\t\t\t\"movq 16(%1, %%\"REG_BP\", 8), %%mm3\\n\\t\"\n\n\t\t\t\"movd (%3, %%\"REG_a\"), %%mm0\t\\n\\t\"\n\n\t\t\t\"movd (%3, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm2, %%mm3\t\t\\n\\t\"\n\n\n\n\t\t\t\"movq 8(%1, %%\"REG_BP\", 8), %%mm1\\n\\t\"\n\n\t\t\t\"movq 24(%1, %%\"REG_BP\", 8), %%mm5\\n\\t\"\n\n\t\t\t\"movd 4(%3, %%\"REG_a\"), %%mm4\t\\n\\t\"\n\n\t\t\t\"movd 4(%3, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm1, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm2, %%mm5\t\t\\n\\t\"\n\n\t\t\t\"paddd %%mm4, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"paddd %%mm5, %%mm3\t\t\\n\\t\"\n\n\t\t\t\t\t\t\n\n\t\t\t\"psrad $8, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm3, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm6, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm0, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"movd %%mm0, (%4, %%\"REG_BP\")\t\\n\\t\"\n\n\t\t\t\"add $4, %%\"REG_BP\"\t\t\\n\\t\"\n\n\t\t\t\" jnc 1b\t\t\t\\n\\t\"\n\n\n\n\t\t\t\"pop %%\"REG_BP\"\t\t\t\\n\\t\"\n\n\t\t\t: \"+a\" (counter)\n\n\t\t\t: \"c\" (filter), \"d\" (filterPos), \"S\" (src), \"D\" (dst)\n\n\t\t\t: \"%\"REG_b\n\n\t\t);\n\n\t}\n\n\telse\n\n\t{\n\n\t\tuint8_t *offset = src+filterSize;\n\n\t\tlong counter= -2*dstW;\n\n//\t\tfilter-= counter*filterSize/2;\n\n\t\tfilterPos-= counter/2;\n\n\t\tdst-= counter/2;\n\n\t\tasm volatile(\n\n\t\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"movq \"MANGLE(w02)\", %%mm6\t\\n\\t\"\n\n\t\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\t\"mov %2, %%\"REG_c\"\t\t\\n\\t\"\n\n\t\t\t\"movzwl (%%\"REG_c\", %0), %%eax\t\\n\\t\"\n\n\t\t\t\"movzwl 2(%%\"REG_c\", %0), %%ebx\t\\n\\t\"\n\n\t\t\t\"mov %5, %%\"REG_c\"\t\t\\n\\t\"\n\n\t\t\t\"pxor %%mm4, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"pxor %%mm5, %%mm5\t\t\\n\\t\"\n\n\t\t\t\"2:\t\t\t\t\\n\\t\"\n\n\t\t\t\"movq (%1), %%mm1\t\t\\n\\t\"\n\n\t\t\t\"movq (%1, %6), %%mm3\t\t\\n\\t\"\n\n\t\t\t\"movd (%%\"REG_c\", %%\"REG_a\"), %%mm0\\n\\t\"\n\n\t\t\t\"movd (%%\"REG_c\", %%\"REG_b\"), %%mm2\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm2, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"paddd %%mm3, %%mm5\t\t\\n\\t\"\n\n\t\t\t\"paddd %%mm0, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"add $8, %1\t\t\t\\n\\t\"\n\n\t\t\t\"add $4, %%\"REG_c\"\t\t\\n\\t\"\n\n\t\t\t\"cmp %4, %%\"REG_c\"\t\t\\n\\t\"\n\n\t\t\t\" jb 2b\t\t\t\t\\n\\t\"\n\n\t\t\t\"add %6, %1\t\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm5\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm5, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm6, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm4, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"mov %3, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\"movd %%mm4, (%%\"REG_a\", %0)\t\\n\\t\"\n\n\t\t\t\"add $4, %0\t\t\t\\n\\t\"\n\n\t\t\t\" jnc 1b\t\t\t\\n\\t\"\n\n\n\n\t\t\t: \"+r\" (counter), \"+r\" (filter)\n\n\t\t\t: \"m\" (filterPos), \"m\" (dst), \"m\"(offset),\n\n\t\t\t  \"m\" (src), \"r\" ((long)filterSize*2)\n\n\t\t\t: \"%\"REG_b, \"%\"REG_a, \"%\"REG_c\n\n\t\t);\n\n\t}\n\n#else\n\n#ifdef HAVE_ALTIVEC\n\n\thScale_altivec_real(dst, dstW, src, srcW, xInc, filter, filterPos, filterSize);\n\n#else\n\n\tint i;\n\n\tfor(i=0; i<dstW; i++)\n\n\t{\n\n\t\tint j;\n\n\t\tint srcPos= filterPos[i];\n\n\t\tint val=0;\n\n//\t\tprintf(\"filterPos: %d\\n\", filterPos[i]);\n\n\t\tfor(j=0; j<filterSize; j++)\n\n\t\t{\n\n//\t\t\tprintf(\"filter: %d, src: %d\\n\", filter[i], src[srcPos + j]);\n\n\t\t\tval += ((int)src[srcPos + j])*filter[filterSize*i + j];\n\n\t\t}\n\n//\t\tfilter += hFilterSize;\n\n\t\tdst[i] = MIN(MAX(0, val>>7), (1<<15)-1); // the cubic equation does overflow ...\n\n//\t\tdst[i] = val>>7;\n\n\t}\n\n#endif\n\n#endif\n\n}\n", "idx": 22429}
{"project": "FFmpeg", "commit_id": "4156df59f59626f60186a4effed80f60c9c4e8cc", "target": 1, "func": "static int mov_read_dref(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st;\n\n    MOVStreamContext *sc;\n\n    int entries, i, j;\n\n\n\n    if (c->fc->nb_streams < 1)\n\n        return 0;\n\n    st = c->fc->streams[c->fc->nb_streams-1];\n\n    sc = st->priv_data;\n\n\n\n    avio_rb32(pb); // version + flags\n\n    entries = avio_rb32(pb);\n\n    if (entries >  (atom.size - 1) / MIN_DATA_ENTRY_BOX_SIZE + 1 ||\n\n        entries >= UINT_MAX / sizeof(*sc->drefs))\n\n        return AVERROR_INVALIDDATA;\n\n    av_free(sc->drefs);\n\n    sc->drefs_count = 0;\n\n    sc->drefs = av_mallocz(entries * sizeof(*sc->drefs));\n\n    if (!sc->drefs)\n\n        return AVERROR(ENOMEM);\n\n    sc->drefs_count = entries;\n\n\n\n    for (i = 0; i < sc->drefs_count; i++) {\n\n        MOVDref *dref = &sc->drefs[i];\n\n        uint32_t size = avio_rb32(pb);\n\n        int64_t next = avio_tell(pb) + size - 4;\n\n\n\n        if (size < 12)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        dref->type = avio_rl32(pb);\n\n        avio_rb32(pb); // version + flags\n\n        av_dlog(c->fc, \"type %.4s size %d\\n\", (char*)&dref->type, size);\n\n\n\n        if (dref->type == MKTAG('a','l','i','s') && size > 150) {\n\n            /* macintosh alias record */\n\n            uint16_t volume_len, len;\n\n            int16_t type;\n\n\n\n            avio_skip(pb, 10);\n\n\n\n            volume_len = avio_r8(pb);\n\n            volume_len = FFMIN(volume_len, 27);\n\n            avio_read(pb, dref->volume, 27);\n\n            dref->volume[volume_len] = 0;\n\n            av_log(c->fc, AV_LOG_DEBUG, \"volume %s, len %d\\n\", dref->volume, volume_len);\n\n\n\n            avio_skip(pb, 12);\n\n\n\n            len = avio_r8(pb);\n\n            len = FFMIN(len, 63);\n\n            avio_read(pb, dref->filename, 63);\n\n            dref->filename[len] = 0;\n\n            av_log(c->fc, AV_LOG_DEBUG, \"filename %s, len %d\\n\", dref->filename, len);\n\n\n\n            avio_skip(pb, 16);\n\n\n\n            /* read next level up_from_alias/down_to_target */\n\n            dref->nlvl_from = avio_rb16(pb);\n\n            dref->nlvl_to   = avio_rb16(pb);\n\n            av_log(c->fc, AV_LOG_DEBUG, \"nlvl from %d, nlvl to %d\\n\",\n\n                   dref->nlvl_from, dref->nlvl_to);\n\n\n\n            avio_skip(pb, 16);\n\n\n\n            for (type = 0; type != -1 && avio_tell(pb) < next; ) {\n\n                if(url_feof(pb))\n\n                    return AVERROR_EOF;\n\n                type = avio_rb16(pb);\n\n                len = avio_rb16(pb);\n\n                av_log(c->fc, AV_LOG_DEBUG, \"type %d, len %d\\n\", type, len);\n\n                if (len&1)\n\n                    len += 1;\n\n                if (type == 2) { // absolute path\n\n                    av_free(dref->path);\n\n                    dref->path = av_mallocz(len+1);\n\n                    if (!dref->path)\n\n                        return AVERROR(ENOMEM);\n\n                    avio_read(pb, dref->path, len);\n\n                    if (len > volume_len && !strncmp(dref->path, dref->volume, volume_len)) {\n\n                        len -= volume_len;\n\n                        memmove(dref->path, dref->path+volume_len, len);\n\n                        dref->path[len] = 0;\n\n                    }\n\n                    for (j = 0; j < len; j++)\n\n                        if (dref->path[j] == ':')\n\n                            dref->path[j] = '/';\n\n                    av_log(c->fc, AV_LOG_DEBUG, \"path %s\\n\", dref->path);\n\n                } else if (type == 0) { // directory name\n\n                    av_free(dref->dir);\n\n                    dref->dir = av_malloc(len+1);\n\n                    if (!dref->dir)\n\n                        return AVERROR(ENOMEM);\n\n                    avio_read(pb, dref->dir, len);\n\n                    dref->dir[len] = 0;\n\n                    for (j = 0; j < len; j++)\n\n                        if (dref->dir[j] == ':')\n\n                            dref->dir[j] = '/';\n\n                    av_log(c->fc, AV_LOG_DEBUG, \"dir %s\\n\", dref->dir);\n\n                } else\n\n                    avio_skip(pb, len);\n\n            }\n\n        }\n\n        avio_seek(pb, next, SEEK_SET);\n\n    }\n\n    return 0;\n\n}\n", "idx": 22433}
{"project": "FFmpeg", "commit_id": "176046d2b59c2042cd35a58848d4964563287f63", "target": 0, "func": "int ff_pulse_audio_get_devices(AVDeviceInfoList *devices, const char *server, int output)\n\n{\n\n    pa_mainloop *pa_ml = NULL;\n\n    pa_mainloop_api *pa_mlapi = NULL;\n\n    pa_operation *pa_op = NULL;\n\n    pa_context *pa_ctx = NULL;\n\n    enum pa_operation_state op_state;\n\n    enum PulseAudioContextState loop_state = PULSE_CONTEXT_INITIALIZING;\n\n    PulseAudioDeviceList dev_list = { 0 };\n\n    int i;\n\n\n\n    dev_list.output = output;\n\n    dev_list.devices = devices;\n\n    if (!devices)\n\n        return AVERROR(EINVAL);\n\n    devices->nb_devices = 0;\n\n    devices->devices = NULL;\n\n    if (!(pa_ml = pa_mainloop_new()))\n\n        return AVERROR(ENOMEM);\n\n    if (!(pa_mlapi = pa_mainloop_get_api(pa_ml))) {\n\n        dev_list.error_code = AVERROR_EXTERNAL;\n\n        goto fail;\n\n    }\n\n    if (!(pa_ctx = pa_context_new(pa_mlapi, \"Query devices\"))) {\n\n        dev_list.error_code = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    pa_context_set_state_callback(pa_ctx, pa_state_cb, &loop_state);\n\n    if (pa_context_connect(pa_ctx, server, 0, NULL) < 0) {\n\n        dev_list.error_code = AVERROR_EXTERNAL;\n\n        goto fail;\n\n    }\n\n\n\n    while (loop_state == PULSE_CONTEXT_INITIALIZING)\n\n        pa_mainloop_iterate(pa_ml, 1, NULL);\n\n    if (loop_state == PULSE_CONTEXT_FINISHED) {\n\n        dev_list.error_code = AVERROR_EXTERNAL;\n\n        goto fail;\n\n    }\n\n\n\n    if (output)\n\n        pa_op = pa_context_get_sink_info_list(pa_ctx, pulse_audio_sink_device_cb, &dev_list);\n\n    else\n\n        pa_op = pa_context_get_source_info_list(pa_ctx, pulse_audio_source_device_cb, &dev_list);\n\n    while ((op_state = pa_operation_get_state(pa_op)) == PA_OPERATION_RUNNING)\n\n        pa_mainloop_iterate(pa_ml, 1, NULL);\n\n    if (op_state != PA_OPERATION_DONE)\n\n        dev_list.error_code = AVERROR_EXTERNAL;\n\n    pa_operation_unref(pa_op);\n\n    if (dev_list.error_code < 0)\n\n        goto fail;\n\n\n\n    pa_op = pa_context_get_server_info(pa_ctx, pulse_server_info_cb, &dev_list);\n\n    while ((op_state = pa_operation_get_state(pa_op)) == PA_OPERATION_RUNNING)\n\n        pa_mainloop_iterate(pa_ml, 1, NULL);\n\n    if (op_state != PA_OPERATION_DONE)\n\n        dev_list.error_code = AVERROR_EXTERNAL;\n\n    pa_operation_unref(pa_op);\n\n    if (dev_list.error_code < 0)\n\n        goto fail;\n\n\n\n    devices->default_device = -1;\n\n    for (i = 0; i < devices->nb_devices; i++) {\n\n        if (!strcmp(devices->devices[i]->device_name, dev_list.default_device)) {\n\n            devices->default_device = i;\n\n            break;\n\n        }\n\n    }\n\n\n\n  fail:\n\n    av_free(dev_list.default_device);\n\n    if(pa_ctx)\n\n        pa_context_disconnect(pa_ctx);\n\n    if (pa_ctx)\n\n        pa_context_unref(pa_ctx);\n\n    if (pa_ml)\n\n        pa_mainloop_free(pa_ml);\n\n    return dev_list.error_code;\n\n}\n", "idx": 22435}
{"project": "FFmpeg", "commit_id": "d3b4b74c32cf302d36a4c4d2cce08027f0a22560", "target": 0, "func": "static int encode_picture_lossless(AVCodecContext *avctx, unsigned char *buf, int buf_size, void *data){\n\n    MpegEncContext * const s = avctx->priv_data;\n\n    MJpegContext * const m = s->mjpeg_ctx;\n\n    AVFrame *pict = data;\n\n    const int width= s->width;\n\n    const int height= s->height;\n\n    AVFrame * const p= (AVFrame*)&s->current_picture;\n\n    const int predictor= avctx->prediction_method+1;\n\n\n\n    init_put_bits(&s->pb, buf, buf_size);\n\n\n\n    *p = *pict;\n\n    p->pict_type= FF_I_TYPE;\n\n    p->key_frame= 1;\n\n\n\n    ff_mjpeg_encode_picture_header(s);\n\n\n\n    s->header_bits= put_bits_count(&s->pb);\n\n\n\n    if(avctx->pix_fmt == PIX_FMT_RGB32){\n\n        int x, y, i;\n\n        const int linesize= p->linesize[0];\n\n        uint16_t (*buffer)[4]= (void *) s->rd_scratchpad;\n\n        int left[3], top[3], topleft[3];\n\n\n\n        for(i=0; i<3; i++){\n\n            buffer[0][i]= 1 << (9 - 1);\n\n        }\n\n\n\n        for(y = 0; y < height; y++) {\n\n            const int modified_predictor= y ? predictor : 1;\n\n            uint8_t *ptr = p->data[0] + (linesize * y);\n\n\n\n            if(s->pb.buf_end - s->pb.buf - (put_bits_count(&s->pb)>>3) < width*3*4){\n\n                av_log(s->avctx, AV_LOG_ERROR, \"encoded frame too large\\n\");\n\n                return -1;\n\n            }\n\n\n\n            for(i=0; i<3; i++){\n\n                top[i]= left[i]= topleft[i]= buffer[0][i];\n\n            }\n\n            for(x = 0; x < width; x++) {\n\n                buffer[x][1] = ptr[4*x+0] - ptr[4*x+1] + 0x100;\n\n                buffer[x][2] = ptr[4*x+2] - ptr[4*x+1] + 0x100;\n\n                buffer[x][0] = (ptr[4*x+0] + 2*ptr[4*x+1] + ptr[4*x+2])>>2;\n\n\n\n                for(i=0;i<3;i++) {\n\n                    int pred, diff;\n\n\n\n                    PREDICT(pred, topleft[i], top[i], left[i], modified_predictor);\n\n\n\n                    topleft[i]= top[i];\n\n                    top[i]= buffer[x+1][i];\n\n\n\n                    left[i]= buffer[x][i];\n\n\n\n                    diff= ((left[i] - pred + 0x100)&0x1FF) - 0x100;\n\n\n\n                    if(i==0)\n\n                        ff_mjpeg_encode_dc(s, diff, m->huff_size_dc_luminance, m->huff_code_dc_luminance); //FIXME ugly\n\n                    else\n\n                        ff_mjpeg_encode_dc(s, diff, m->huff_size_dc_chrominance, m->huff_code_dc_chrominance);\n\n                }\n\n            }\n\n        }\n\n    }else{\n\n        int mb_x, mb_y, i;\n\n        const int mb_width  = (width  + s->mjpeg_hsample[0] - 1) / s->mjpeg_hsample[0];\n\n        const int mb_height = (height + s->mjpeg_vsample[0] - 1) / s->mjpeg_vsample[0];\n\n\n\n        for(mb_y = 0; mb_y < mb_height; mb_y++) {\n\n            if(s->pb.buf_end - s->pb.buf - (put_bits_count(&s->pb)>>3) < mb_width * 4 * 3 * s->mjpeg_hsample[0] * s->mjpeg_vsample[0]){\n\n                av_log(s->avctx, AV_LOG_ERROR, \"encoded frame too large\\n\");\n\n                return -1;\n\n            }\n\n            for(mb_x = 0; mb_x < mb_width; mb_x++) {\n\n                if(mb_x==0 || mb_y==0){\n\n                    for(i=0;i<3;i++) {\n\n                        uint8_t *ptr;\n\n                        int x, y, h, v, linesize;\n\n                        h = s->mjpeg_hsample[i];\n\n                        v = s->mjpeg_vsample[i];\n\n                        linesize= p->linesize[i];\n\n\n\n                        for(y=0; y<v; y++){\n\n                            for(x=0; x<h; x++){\n\n                                int pred;\n\n\n\n                                ptr = p->data[i] + (linesize * (v * mb_y + y)) + (h * mb_x + x); //FIXME optimize this crap\n\n                                if(y==0 && mb_y==0){\n\n                                    if(x==0 && mb_x==0){\n\n                                        pred= 128;\n\n                                    }else{\n\n                                        pred= ptr[-1];\n\n                                    }\n\n                                }else{\n\n                                    if(x==0 && mb_x==0){\n\n                                        pred= ptr[-linesize];\n\n                                    }else{\n\n                                        PREDICT(pred, ptr[-linesize-1], ptr[-linesize], ptr[-1], predictor);\n\n                                    }\n\n                                }\n\n\n\n                                if(i==0)\n\n                                    ff_mjpeg_encode_dc(s, (int8_t)(*ptr - pred), m->huff_size_dc_luminance, m->huff_code_dc_luminance); //FIXME ugly\n\n                                else\n\n                                    ff_mjpeg_encode_dc(s, (int8_t)(*ptr - pred), m->huff_size_dc_chrominance, m->huff_code_dc_chrominance);\n\n                            }\n\n                        }\n\n                    }\n\n                }else{\n\n                    for(i=0;i<3;i++) {\n\n                        uint8_t *ptr;\n\n                        int x, y, h, v, linesize;\n\n                        h = s->mjpeg_hsample[i];\n\n                        v = s->mjpeg_vsample[i];\n\n                        linesize= p->linesize[i];\n\n\n\n                        for(y=0; y<v; y++){\n\n                            for(x=0; x<h; x++){\n\n                                int pred;\n\n\n\n                                ptr = p->data[i] + (linesize * (v * mb_y + y)) + (h * mb_x + x); //FIXME optimize this crap\n\n//printf(\"%d %d %d %d %8X\\n\", mb_x, mb_y, x, y, ptr);\n\n                                PREDICT(pred, ptr[-linesize-1], ptr[-linesize], ptr[-1], predictor);\n\n\n\n                                if(i==0)\n\n                                    ff_mjpeg_encode_dc(s, (int8_t)(*ptr - pred), m->huff_size_dc_luminance, m->huff_code_dc_luminance); //FIXME ugly\n\n                                else\n\n                                    ff_mjpeg_encode_dc(s, (int8_t)(*ptr - pred), m->huff_size_dc_chrominance, m->huff_code_dc_chrominance);\n\n                            }\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    emms_c();\n\n\n\n    ff_mjpeg_encode_picture_trailer(s);\n\n    s->picture_number++;\n\n\n\n    flush_put_bits(&s->pb);\n\n    return pbBufPtr(&s->pb) - s->pb.buf;\n\n//    return (put_bits_count(&f->pb)+7)/8;\n\n}\n", "idx": 22436}
{"project": "FFmpeg", "commit_id": "deabb52ab4c1fdb3dd319f3980b1489a182011f1", "target": 1, "func": "static int ivi_decode_blocks(GetBitContext *gb, IVIBandDesc *band, IVITile *tile,\n                             AVCodecContext *avctx)\n{\n    int         mbn, blk, num_blocks, num_coeffs, blk_size, scan_pos, run, val,\n                pos, is_intra, mc_type = 0, mv_x, mv_y, col_mask;\n    uint8_t     col_flags[8];\n    int32_t     prev_dc, trvec[64];\n    uint32_t    cbp, sym, lo, hi, quant, buf_offs, q;\n    IVIMbInfo   *mb;\n    RVMapDesc   *rvmap = band->rv_map;\n    void (*mc_with_delta_func)(int16_t *buf, const int16_t *ref_buf, uint32_t pitch, int mc_type);\n    void (*mc_no_delta_func)  (int16_t *buf, const int16_t *ref_buf, uint32_t pitch, int mc_type);\n    const uint16_t  *base_tab;\n    const uint8_t   *scale_tab;\n    prev_dc = 0; /* init intra prediction for the DC coefficient */\n    blk_size   = band->blk_size;\n    col_mask   = blk_size - 1; /* column mask for tracking non-zero coeffs */\n    num_blocks = (band->mb_size != blk_size) ? 4 : 1; /* number of blocks per mb */\n    num_coeffs = blk_size * blk_size;\n    if (blk_size == 8) {\n        mc_with_delta_func = ff_ivi_mc_8x8_delta;\n        mc_no_delta_func   = ff_ivi_mc_8x8_no_delta;\n    } else {\n        mc_with_delta_func = ff_ivi_mc_4x4_delta;\n        mc_no_delta_func   = ff_ivi_mc_4x4_no_delta;\n    for (mbn = 0, mb = tile->mbs; mbn < tile->num_MBs; mb++, mbn++) {\n        is_intra = !mb->type;\n        cbp      = mb->cbp;\n        buf_offs = mb->buf_offs;\n        quant = av_clip(band->glob_quant + mb->q_delta, 0, 23);\n        base_tab  = is_intra ? band->intra_base  : band->inter_base;\n        scale_tab = is_intra ? band->intra_scale : band->inter_scale;\n        if (scale_tab)\n            quant = scale_tab[quant];\n        if (!is_intra) {\n            mv_x = mb->mv_x;\n            mv_y = mb->mv_y;\n            if (band->is_halfpel) {\n                mc_type = ((mv_y & 1) << 1) | (mv_x & 1);\n                mv_x >>= 1;\n                mv_y >>= 1; /* convert halfpel vectors into fullpel ones */\n            if (mb->type) {\n                int dmv_x, dmv_y, cx, cy;\n                dmv_x = mb->mv_x >> band->is_halfpel;\n                dmv_y = mb->mv_y >> band->is_halfpel;\n                cx    = mb->mv_x &  band->is_halfpel;\n                cy    = mb->mv_y &  band->is_halfpel;\n                if (   mb->xpos + dmv_x < 0\n                    || mb->xpos + dmv_x + band->mb_size + cx > band->pitch\n                    || mb->ypos + dmv_y < 0\n                    || mb->ypos + dmv_y + band->mb_size + cy > band->aheight) {\n        for (blk = 0; blk < num_blocks; blk++) {\n            /* adjust block position in the buffer according to its number */\n            if (blk & 1) {\n                buf_offs += blk_size;\n            } else if (blk == 2) {\n                buf_offs -= blk_size;\n                buf_offs += blk_size * band->pitch;\n            if (cbp & 1) { /* block coded ? */\n                scan_pos = -1;\n                memset(trvec, 0, num_coeffs*sizeof(trvec[0])); /* zero transform vector */\n                memset(col_flags, 0, sizeof(col_flags));      /* zero column flags */\n                while (scan_pos <= num_coeffs) {\n                    sym = get_vlc2(gb, band->blk_vlc.tab->table, IVI_VLC_BITS, 1);\n                    if (sym == rvmap->eob_sym)\n                        break; /* End of block */\n                    if (sym == rvmap->esc_sym) { /* Escape - run/val explicitly coded using 3 vlc codes */\n                        run = get_vlc2(gb, band->blk_vlc.tab->table, IVI_VLC_BITS, 1) + 1;\n                        lo  = get_vlc2(gb, band->blk_vlc.tab->table, IVI_VLC_BITS, 1);\n                        hi  = get_vlc2(gb, band->blk_vlc.tab->table, IVI_VLC_BITS, 1);\n                        val = IVI_TOSIGNED((hi << 6) | lo); /* merge them and convert into signed val */\n                    } else {\n                        if (sym >= 256U) {\n                            av_log(avctx, AV_LOG_ERROR, \"Invalid sym encountered: %d.\\n\", sym);\n                            return -1;\n                        run = rvmap->runtab[sym];\n                        val = rvmap->valtab[sym];\n                    /* de-zigzag and dequantize */\n                    scan_pos += run;\n                    if (scan_pos >= num_coeffs)\n                        break;\n                    pos = band->scan[scan_pos];\n                    if (!val)\n                        av_dlog(avctx, \"Val = 0 encountered!\\n\");\n                    q = (base_tab[pos] * quant) >> 9;\n                    if (q > 1)\n                        val = val * q + FFSIGN(val) * (((q ^ 1) - 1) >> 1);\n                    trvec[pos] = val;\n                    col_flags[pos & col_mask] |= !!val; /* track columns containing non-zero coeffs */\n                }// while\n                if (scan_pos >= num_coeffs && sym != rvmap->eob_sym)\n                    return -1; /* corrupt block data */\n                /* undoing DC coeff prediction for intra-blocks */\n                if (is_intra && band->is_2d_trans) {\n                    prev_dc      += trvec[0];\n                    trvec[0]      = prev_dc;\n                    col_flags[0] |= !!prev_dc;\n                /* apply inverse transform */\n                band->inv_transform(trvec, band->buf + buf_offs,\n                                    band->pitch, col_flags);\n                /* apply motion compensation */\n                if (!is_intra)\n                    mc_with_delta_func(band->buf + buf_offs,\n                                       band->ref_buf + buf_offs + mv_y * band->pitch + mv_x,\n                                       band->pitch, mc_type);\n            } else {\n                /* block not coded */\n                /* for intra blocks apply the dc slant transform */\n                /* for inter - perform the motion compensation without delta */\n                if (is_intra && band->dc_transform) {\n                    band->dc_transform(&prev_dc, band->buf + buf_offs,\n                                       band->pitch, blk_size);\n                } else\n                    mc_no_delta_func(band->buf + buf_offs,\n                                     band->ref_buf + buf_offs + mv_y * band->pitch + mv_x,\n                                     band->pitch, mc_type);\n            cbp >>= 1;\n        }// for blk\n    }// for mbn\n    align_get_bits(gb);\n    return 0;", "idx": 22437}
{"project": "FFmpeg", "commit_id": "dbe29db8cb09fb39bd8dc5b25934e92279d0aa8d", "target": 1, "func": "static int skip_data_stream_element(AACContext *ac, GetBitContext *gb)\n\n{\n\n    int byte_align = get_bits1(gb);\n\n    int count = get_bits(gb, 8);\n\n    if (count == 255)\n\n        count += get_bits(gb, 8);\n\n    if (byte_align)\n\n        align_get_bits(gb);\n\n\n\n    if (get_bits_left(gb) < 8 * count) {\n\n        av_log(ac->avctx, AV_LOG_ERROR, overread_err);\n\n        return -1;\n\n    }\n\n    skip_bits_long(gb, 8 * count);\n\n    return 0;\n\n}\n", "idx": 22442}
{"project": "FFmpeg", "commit_id": "c90b88090c260a0af018b6c1e955266e24ebf6f4", "target": 1, "func": "static int filter_frame(AVFilterLink *inlink, AVFrame *inbuf)\n\n{\n\n    AudioPhaserContext *s = inlink->dst->priv;\n\n    AVFilterLink *outlink = inlink->dst->outputs[0];\n\n    AVFrame *outbuf;\n\n\n\n    if (av_frame_is_writable(inbuf)) {\n\n        outbuf = inbuf;\n\n    } else {\n\n        outbuf = ff_get_audio_buffer(inlink, inbuf->nb_samples);\n\n        if (!outbuf)\n\n            return AVERROR(ENOMEM);\n\n        av_frame_copy_props(outbuf, inbuf);\n\n    }\n\n\n\n    s->phaser(s, inbuf->extended_data, outbuf->extended_data,\n\n              outbuf->nb_samples, outbuf->channels);\n\n\n\n    if (inbuf != outbuf)\n\n        av_frame_free(&inbuf);\n\n\n\n    return ff_filter_frame(outlink, outbuf);\n\n}\n", "idx": 22445}
{"project": "FFmpeg", "commit_id": "53df079a730043cd0aa330c9aba7950034b1424f", "target": 1, "func": "static void allocate_buffers(ALACContext *alac)\n\n{\n\n    int chan;\n\n    for (chan = 0; chan < alac->numchannels; chan++) {\n\n        alac->predicterror_buffer[chan] =\n\n            av_malloc(alac->setinfo_max_samples_per_frame * 4);\n\n\n\n        alac->outputsamples_buffer[chan] =\n\n            av_malloc(alac->setinfo_max_samples_per_frame * 4);\n\n\n\n        alac->wasted_bits_buffer[chan] = av_malloc(alac->setinfo_max_samples_per_frame * 4);\n\n    }\n\n}\n", "idx": 22447}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(planar2x)(const uint8_t *src, uint8_t *dst, int srcWidth, int srcHeight, int srcStride, int dstStride)\n\n{\n\n\tint x,y;\n\n\t\n\n\tdst[0]= src[0];\n\n        \n\n\t// first line\n\n\tfor(x=0; x<srcWidth-1; x++){\n\n\t\tdst[2*x+1]= (3*src[x] +   src[x+1])>>2;\n\n\t\tdst[2*x+2]= (  src[x] + 3*src[x+1])>>2;\n\n\t}\n\n\tdst[2*srcWidth-1]= src[srcWidth-1];\n\n\t\n\n        dst+= dstStride;\n\n\n\n\tfor(y=1; y<srcHeight; y++){\n\n#if defined (HAVE_MMX2) || defined (HAVE_3DNOW)\n\n\t\tconst long mmxSize= srcWidth&~15;\n\n\t\tasm volatile(\n\n\t\t\t\"mov %4, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\t\"movq (%0, %%\"REG_a\"), %%mm0\t\\n\\t\"\n\n\t\t\t\"movq (%1, %%\"REG_a\"), %%mm1\t\\n\\t\"\n\n\t\t\t\"movq 1(%0, %%\"REG_a\"), %%mm2\t\\n\\t\"\n\n\t\t\t\"movq 1(%1, %%\"REG_a\"), %%mm3\t\\n\\t\"\n\n\t\t\t\"movq -1(%0, %%\"REG_a\"), %%mm4\t\\n\\t\"\n\n\t\t\t\"movq -1(%1, %%\"REG_a\"), %%mm5\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm0, %%mm5\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm0, %%mm3\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm0, %%mm5\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm0, %%mm3\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm1, %%mm4\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm1, %%mm2\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm1, %%mm4\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm1, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"movq %%mm5, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"movq %%mm4, %%mm6\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm3, %%mm5\t\t\\n\\t\"\n\n\t\t\t\"punpckhbw %%mm3, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm2, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"punpckhbw %%mm2, %%mm6\t\t\\n\\t\"\n\n#if 1\n\n\t\t\tMOVNTQ\" %%mm5, (%2, %%\"REG_a\", 2)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm7, 8(%2, %%\"REG_a\", 2)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm4, (%3, %%\"REG_a\", 2)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm6, 8(%3, %%\"REG_a\", 2)\\n\\t\"\n\n#else\n\n\t\t\t\"movq %%mm5, (%2, %%\"REG_a\", 2)\t\\n\\t\"\n\n\t\t\t\"movq %%mm7, 8(%2, %%\"REG_a\", 2)\\n\\t\"\n\n\t\t\t\"movq %%mm4, (%3, %%\"REG_a\", 2)\t\\n\\t\"\n\n\t\t\t\"movq %%mm6, 8(%3, %%\"REG_a\", 2)\\n\\t\"\n\n#endif\n\n\t\t\t\"add $8, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\" js 1b\t\t\t\t\\n\\t\"\n\n\t\t\t:: \"r\" (src + mmxSize  ), \"r\" (src + srcStride + mmxSize  ),\n\n\t\t\t   \"r\" (dst + mmxSize*2), \"r\" (dst + dstStride + mmxSize*2),\n\n\t\t\t   \"g\" (-mmxSize)\n\n\t\t\t: \"%\"REG_a\n\n\n\n\t\t);\n\n#else\n\n\t\tconst int mmxSize=1;\n\n#endif\n\n\t\tdst[0        ]= (3*src[0] +   src[srcStride])>>2;\n\n\t\tdst[dstStride]= (  src[0] + 3*src[srcStride])>>2;\n\n\n\n\t\tfor(x=mmxSize-1; x<srcWidth-1; x++){\n\n\t\t\tdst[2*x          +1]= (3*src[x+0] +   src[x+srcStride+1])>>2;\n\n\t\t\tdst[2*x+dstStride+2]= (  src[x+0] + 3*src[x+srcStride+1])>>2;\n\n\t\t\tdst[2*x+dstStride+1]= (  src[x+1] + 3*src[x+srcStride  ])>>2;\n\n\t\t\tdst[2*x          +2]= (3*src[x+1] +   src[x+srcStride  ])>>2;\n\n\t\t}\n\n\t\tdst[srcWidth*2 -1            ]= (3*src[srcWidth-1] +   src[srcWidth-1 + srcStride])>>2;\n\n\t\tdst[srcWidth*2 -1 + dstStride]= (  src[srcWidth-1] + 3*src[srcWidth-1 + srcStride])>>2;\n\n\n\n\t\tdst+=dstStride*2;\n\n\t\tsrc+=srcStride;\n\n\t}\n\n\t\n\n\t// last line\n\n#if 1\n\n\tdst[0]= src[0];\n\n        \n\n\tfor(x=0; x<srcWidth-1; x++){\n\n\t\tdst[2*x+1]= (3*src[x] +   src[x+1])>>2;\n\n\t\tdst[2*x+2]= (  src[x] + 3*src[x+1])>>2;\n\n\t}\n\n\tdst[2*srcWidth-1]= src[srcWidth-1];\n\n#else\n\n\tfor(x=0; x<srcWidth; x++){\n\n\t\tdst[2*x+0]=\n\n\t\tdst[2*x+1]= src[x];\n\n\t}\n\n#endif\n\n\n\n#ifdef HAVE_MMX\n\nasm volatile(   EMMS\" \\n\\t\"\n\n        \tSFENCE\" \\n\\t\"\n\n        \t:::\"memory\");\n\n#endif\n\n}\n", "idx": 22448}
{"project": "FFmpeg", "commit_id": "c1e035ea89c16b8da91fae6983973a7186e138f6", "target": 1, "func": "static int mxf_parse_physical_source_package(MXFContext *mxf, MXFTrack *source_track, AVStream *st)\n\n{\n\n    MXFPackage *temp_package = NULL;\n\n    MXFPackage *physical_package = NULL;\n\n    MXFTrack *physical_track = NULL;\n\n    MXFStructuralComponent *component = NULL;\n\n    MXFStructuralComponent *sourceclip = NULL;\n\n    MXFTimecodeComponent *mxf_tc = NULL;\n\n    MXFPulldownComponent *mxf_pulldown = NULL;\n\n    int i, j, k;\n\n    AVTimecode tc;\n\n    int flags;\n\n    int64_t start_position;\n\n\n\n    for (i = 0; i < source_track->sequence->structural_components_count; i++) {\n\n        component = mxf_resolve_strong_ref(mxf, &source_track->sequence->structural_components_refs[i], SourceClip);\n\n        if (!component)\n\n            continue;\n\n\n\n        for (j = 0; j < mxf->packages_count; j++) {\n\n            temp_package = mxf_resolve_strong_ref(mxf, &mxf->packages_refs[j], SourcePackage);\n\n            if (!temp_package)\n\n                continue;\n\n            if (!memcmp(temp_package->package_uid, component->source_package_uid, 16)){\n\n                physical_package = temp_package;\n\n                sourceclip = component;\n\n                break;\n\n            }\n\n        }\n\n        if (!physical_package)\n\n            break;\n\n\n\n        /* the name of physical source package is name of the reel or tape */\n\n        if (physical_package->name[0])\n\n            av_dict_set(&st->metadata, \"reel_name\", physical_package->name, 0);\n\n\n\n        /* the source timecode is calculated by adding the start_position of the sourceclip from the file source package track\n\n         * to the start_frame of the timecode component located on one of the tracks of the physical source package.\n\n         */\n\n        for (j = 0; j < physical_package->tracks_count; j++) {\n\n            if (!(physical_track = mxf_resolve_strong_ref(mxf, &physical_package->tracks_refs[j], Track))) {\n\n                av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve source track strong ref\\n\");\n\n                continue;\n\n            }\n\n\n\n            if (!(physical_track->sequence = mxf_resolve_strong_ref(mxf, &physical_track->sequence_ref, Sequence))) {\n\n                av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve source track sequence strong ref\\n\");\n\n                continue;\n\n            }\n\n\n\n            for (k = 0; k < physical_track->sequence->structural_components_count; k++) {\n\n                component = mxf_resolve_strong_ref(mxf, &physical_track->sequence->structural_components_refs[k], TimecodeComponent);\n\n                if (!component){\n\n                    /* timcode component may be located on a pulldown component */\n\n                    component = mxf_resolve_strong_ref(mxf, &physical_track->sequence->structural_components_refs[k], PulldownComponent);\n\n                    if (!component)\n\n                        continue;\n\n                    mxf_pulldown = (MXFPulldownComponent*)component;\n\n                    component = mxf_resolve_strong_ref(mxf, &mxf_pulldown->input_segment_ref, TimecodeComponent);\n\n                    if (!component)\n\n                        continue;\n\n                }\n\n\n\n                mxf_tc = (MXFTimecodeComponent*)component;\n\n                flags = mxf_tc->drop_frame == 1 ? AV_TIMECODE_FLAG_DROPFRAME : 0;\n\n                /* scale sourceclip start_position to match physical track edit rate */\n\n                start_position = av_rescale_q(sourceclip->start_position,\n\n                                              physical_track->edit_rate,\n\n                                              source_track->edit_rate);\n\n\n\n                if (av_timecode_init(&tc, mxf_tc->rate, flags, start_position + mxf_tc->start_frame, mxf->fc) == 0) {\n\n                    mxf_add_timecode_metadata(&st->metadata, \"timecode\", &tc);\n\n                    return 0;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22451}
{"project": "FFmpeg", "commit_id": "adaa7743f5fdca0c0aca0b7ffdebf61c7d868571", "target": 0, "func": "static AVStream *find_stream(void *log, AVFormatContext *avf, const char *spec)\n\n{\n\n    int i, ret, already = 0, stream_id = -1;\n\n    char type_char, dummy;\n\n    AVStream *found = NULL;\n\n    enum AVMediaType type;\n\n\n\n    ret = sscanf(spec, \"d%[av]%d%c\", &type_char, &stream_id, &dummy);\n\n    if (ret >= 1 && ret <= 2) {\n\n        type = type_char == 'v' ? AVMEDIA_TYPE_VIDEO : AVMEDIA_TYPE_AUDIO;\n\n        ret = av_find_best_stream(avf, type, stream_id, -1, NULL, 0);\n\n        if (ret < 0) {\n\n            av_log(log, AV_LOG_ERROR, \"No %s stream with index '%d' found\\n\",\n\n                   av_get_media_type_string(type), stream_id);\n\n            return NULL;\n\n        }\n\n        return avf->streams[ret];\n\n    }\n\n    for (i = 0; i < avf->nb_streams; i++) {\n\n        ret = avformat_match_stream_specifier(avf, avf->streams[i], spec);\n\n        if (ret < 0) {\n\n            av_log(log, AV_LOG_ERROR,\n\n                   \"Invalid stream specifier \\\"%s\\\"\\n\", spec);\n\n            return NULL;\n\n        }\n\n        if (!ret)\n\n            continue;\n\n        if (avf->streams[i]->discard != AVDISCARD_ALL) {\n\n            already++;\n\n            continue;\n\n        }\n\n        if (found) {\n\n            av_log(log, AV_LOG_WARNING,\n\n                   \"Ambiguous stream specifier \\\"%s\\\", using #%d\\n\", spec, i);\n\n            break;\n\n        }\n\n        found = avf->streams[i];\n\n    }\n\n    if (!found) {\n\n        av_log(log, AV_LOG_WARNING, \"Stream specifier \\\"%s\\\" %s\\n\", spec,\n\n               already ? \"matched only already used streams\" :\n\n                         \"did not match any stream\");\n\n        return NULL;\n\n    }\n\n    if (found->codec->codec_type != AVMEDIA_TYPE_VIDEO &&\n\n        found->codec->codec_type != AVMEDIA_TYPE_AUDIO) {\n\n        av_log(log, AV_LOG_ERROR, \"Stream specifier \\\"%s\\\" matched a %s stream,\"\n\n               \"currently unsupported by libavfilter\\n\", spec,\n\n               av_get_media_type_string(found->codec->codec_type));\n\n        return NULL;\n\n    }\n\n    return found;\n\n}\n", "idx": 22453}
{"project": "FFmpeg", "commit_id": "9d5c62ba5b586c80af508b5914934b1c439f6652", "target": 0, "func": "static int set_string_number(void *obj, const AVOption *o, const char *val, void *dst)\n\n{\n\n    int ret = 0, notfirst = 0;\n\n    for (;;) {\n\n        int i, den = 1;\n\n        char buf[256];\n\n        int cmd = 0;\n\n        double d, num = 1;\n\n        int64_t intnum = 1;\n\n\n\n        if (*val == '+' || *val == '-')\n\n            cmd = *(val++);\n\n\n\n        for (i = 0; i < sizeof(buf) - 1 && val[i] && val[i] != '+' && val[i] != '-'; i++)\n\n            buf[i] = val[i];\n\n        buf[i] = 0;\n\n\n\n        {\n\n            const AVOption *o_named = av_opt_find(obj, buf, o->unit, 0, 0);\n\n            if (o_named && o_named->type == AV_OPT_TYPE_CONST)\n\n                d = DEFAULT_NUMVAL(o_named);\n\n            else if (!strcmp(buf, \"default\")) d = DEFAULT_NUMVAL(o);\n\n            else if (!strcmp(buf, \"max\"    )) d = o->max;\n\n            else if (!strcmp(buf, \"min\"    )) d = o->min;\n\n            else if (!strcmp(buf, \"none\"   )) d = 0;\n\n            else if (!strcmp(buf, \"all\"    )) d = ~0;\n\n            else {\n\n                int res = av_expr_parse_and_eval(&d, buf, const_names, const_values, NULL, NULL, NULL, NULL, NULL, 0, obj);\n\n                if (res < 0) {\n\n                    av_log(obj, AV_LOG_ERROR, \"Unable to parse option value \\\"%s\\\"\\n\", val);\n\n                    return res;\n\n                }\n\n            }\n\n        }\n\n        if (o->type == AV_OPT_TYPE_FLAGS) {\n\n            read_number(o, dst, NULL, NULL, &intnum);\n\n            if      (cmd == '+') d = intnum | (int64_t)d;\n\n            else if (cmd == '-') d = intnum &~(int64_t)d;\n\n        } else {\n\n            read_number(o, dst, &num, &den, &intnum);\n\n            if      (cmd == '+') d = notfirst*num*intnum/den + d;\n\n            else if (cmd == '-') d = notfirst*num*intnum/den - d;\n\n        }\n\n\n\n        if ((ret = write_number(obj, o, dst, d, 1, 1)) < 0)\n\n            return ret;\n\n        val += i;\n\n        if (!*val)\n\n            return 0;\n\n        notfirst = 1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22454}
{"project": "FFmpeg", "commit_id": "e7a5854d23e139f5352b59e094387823dbf82522", "target": 0, "func": "static int amr_wb_encode_frame(AVCodecContext *avctx,\n\n                            unsigned char *frame/*out*/, int buf_size, void *data/*in*/)\n\n{\n\n    AMRWBContext *s;\n\n    int size;\n\n    s = (AMRWBContext*) avctx->priv_data;\n\n    s->mode=getWBBitrateMode(avctx->bit_rate);\n\n    size = E_IF_encode(s->state, s->mode, data, frame, s->allow_dtx);\n\n    return size;\n\n}\n", "idx": 22455}
{"project": "FFmpeg", "commit_id": "4d59d075a96c7bc9fc7a118f96015fbf5156708a", "target": 0, "func": "static void check_rgb2yuv(void)\n\n{\n\n    declare_func(void, uint8_t *dst[3], ptrdiff_t dst_stride[3],\n\n                 int16_t *src[3], ptrdiff_t src_stride,\n\n                 int w, int h, const int16_t coeff[3][3][8],\n\n                 const int16_t off[8]);\n\n    ColorSpaceDSPContext dsp;\n\n    int odepth, fmt, n;\n\n    LOCAL_ALIGNED_32(int16_t, src_y, [W * H * 2]);\n\n    LOCAL_ALIGNED_32(int16_t, src_u, [W * H * 2]);\n\n    LOCAL_ALIGNED_32(int16_t, src_v, [W * H * 2]);\n\n    int16_t *src[3] = { src_y, src_u, src_v };\n\n    LOCAL_ALIGNED_32(uint8_t, dst0_y, [W * H]);\n\n    LOCAL_ALIGNED_32(uint8_t, dst0_u, [W * H]);\n\n    LOCAL_ALIGNED_32(uint8_t, dst0_v, [W * H]);\n\n    LOCAL_ALIGNED_32(uint8_t, dst1_y, [W * H]);\n\n    LOCAL_ALIGNED_32(uint8_t, dst1_u, [W * H]);\n\n    LOCAL_ALIGNED_32(uint8_t, dst1_v, [W * H]);\n\n    uint8_t *dst0[3] = { dst0_y, dst0_u, dst0_v }, *dst1[3] = { dst1_y, dst1_u, dst1_v };\n\n    LOCAL_ALIGNED_32(int16_t, offset, [8]);\n\n    LOCAL_ALIGNED_32(int16_t, coeff_buf, [3 * 3 * 8]);\n\n    int16_t (*coeff)[3][8] = (int16_t(*)[3][8]) coeff_buf;\n\n\n\n    ff_colorspacedsp_init(&dsp);\n\n    for (n = 0; n < 8; n++) {\n\n        offset[n] = 16;\n\n\n\n        // these somewhat resemble bt601/smpte170m coefficients\n\n        coeff[0][0][n] = lrint(0.3 * (1 << 14));\n\n        coeff[0][1][n] = lrint(0.6 * (1 << 14));\n\n        coeff[0][2][n] = lrint(0.1 * (1 << 14));\n\n        coeff[1][0][n] = lrint(-0.15 * (1 << 14));\n\n        coeff[1][1][n] = lrint(-0.35 * (1 << 14));\n\n        coeff[1][2][n] = lrint(0.5 * (1 << 14));\n\n        coeff[2][0][n] = lrint(0.5 * (1 << 14));\n\n        coeff[2][1][n] = lrint(-0.42 * (1 << 14));\n\n        coeff[2][2][n] = lrint(-0.08 * (1 << 14));\n\n    }\n\n    for (odepth = 0; odepth < 3; odepth++) {\n\n        for (fmt = 0; fmt < 3; fmt++) {\n\n            if (check_func(dsp.rgb2yuv[odepth][fmt],\n\n                           \"ff_colorspacedsp_rgb2yuv_%sp%d\",\n\n                           format_string[fmt], odepth * 2 + 8)) {\n\n                int ss_w = !!fmt, ss_h = fmt == 2;\n\n                int y_dst_stride = W << !!odepth;\n\n                int uv_dst_stride = y_dst_stride >> ss_w;\n\n\n\n                randomize_buffers();\n\n                call_ref(dst0, (ptrdiff_t[3]) { y_dst_stride, uv_dst_stride, uv_dst_stride },\n\n                         src, W, W, H, coeff, offset);\n\n                call_new(dst1, (ptrdiff_t[3]) { y_dst_stride, uv_dst_stride, uv_dst_stride },\n\n                         src, W, W, H, coeff, offset);\n\n                if (memcmp(dst0[0], dst1[0], H * y_dst_stride) ||\n\n                    memcmp(dst0[1], dst1[1], H * uv_dst_stride >> ss_h) ||\n\n                    memcmp(dst0[2], dst1[2], H * uv_dst_stride >> ss_h)) {\n\n                    fail();\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    report(\"rgb2yuv\");\n\n}\n", "idx": 22456}
{"project": "FFmpeg", "commit_id": "69494fd5c50742cb7d9ad9ca45b154ab9c33fa19", "target": 0, "func": "static void lag_pred_line(LagarithContext *l, uint8_t *buf,\n\n                          int width, int stride, int line)\n\n{\n\n    int L, TL;\n\n\n\n    /* Left pixel is actually prev_row[width] */\n\n    L = buf[width - stride - 1];\n\n    if (!line) {\n\n        /* Left prediction only for first line */\n\n        L = l->dsp.add_hfyu_left_prediction(buf + 1, buf + 1,\n\n                                            width - 1, buf[0]);\n\n        return;\n\n    } else if (line == 1) {\n\n        /* Second line, left predict first pixel, the rest of the line is median predicted\n\n         * NOTE: In the case of RGB this pixel is top predicted */\n\n        TL = l->avctx->pix_fmt == PIX_FMT_YUV420P ? buf[-stride] : L;\n\n    } else {\n\n        /* Top left is 2 rows back, last pixel */\n\n        TL = buf[width - (2 * stride) - 1];\n\n    }\n\n\n\n    add_lag_median_prediction(buf, buf - stride, buf,\n\n                              width, &L, &TL);\n\n}\n", "idx": 22457}
{"project": "FFmpeg", "commit_id": "2c1e075308e14810149f53be87959a62cb83a730", "target": 0, "func": "flac_header (AVFormatContext * s, int idx)\n\n{\n\n    struct ogg *ogg = s->priv_data;\n\n    struct ogg_stream *os = ogg->streams + idx;\n\n    AVStream *st = s->streams[idx];\n\n    GetBitContext gb;\n\n    FLACStreaminfo si;\n\n    int mdt;\n\n\n\n    if (os->buf[os->pstart] == 0xff)\n\n        return 0;\n\n\n\n    init_get_bits(&gb, os->buf + os->pstart, os->psize*8);\n\n    skip_bits1(&gb); /* metadata_last */\n\n    mdt = get_bits(&gb, 7);\n\n\n\n    if (mdt == OGG_FLAC_METADATA_TYPE_STREAMINFO) {\n\n        uint8_t *streaminfo_start = os->buf + os->pstart + 5 + 4 + 4 + 4;\n\n        skip_bits_long(&gb, 4*8); /* \"FLAC\" */\n\n        if(get_bits(&gb, 8) != 1) /* unsupported major version */\n\n            return -1;\n\n        skip_bits_long(&gb, 8 + 16); /* minor version + header count */\n\n        skip_bits_long(&gb, 4*8); /* \"fLaC\" */\n\n\n\n        /* METADATA_BLOCK_HEADER */\n\n        if (get_bits_long(&gb, 32) != FLAC_STREAMINFO_SIZE)\n\n            return -1;\n\n\n\n        avpriv_flac_parse_streaminfo(st->codec, &si, streaminfo_start);\n\n\n\n        st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n        st->codec->codec_id = AV_CODEC_ID_FLAC;\n\n        st->need_parsing = AVSTREAM_PARSE_HEADERS;\n\n\n\n        ff_alloc_extradata(st->codec, FLAC_STREAMINFO_SIZE);\n\n        memcpy(st->codec->extradata, streaminfo_start, st->codec->extradata_size);\n\n\n\n        avpriv_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n    } else if (mdt == FLAC_METADATA_TYPE_VORBIS_COMMENT) {\n\n        ff_vorbis_comment (s, &st->metadata, os->buf + os->pstart + 4, os->psize - 4);\n\n    }\n\n\n\n    return 1;\n\n}\n", "idx": 22458}
{"project": "FFmpeg", "commit_id": "934fe00680a1139cbc0950641655af5923dd7763", "target": 0, "func": "static int opt_input_file(OptionsContext *o, const char *opt, const char *filename)\n\n{\n\n    AVFormatContext *ic;\n\n    AVInputFormat *file_iformat = NULL;\n\n    int err, i, ret;\n\n    int64_t timestamp;\n\n    uint8_t buf[128];\n\n    AVDictionary **opts;\n\n    int orig_nb_streams;                     // number of streams before avformat_find_stream_info\n\n\n\n    if (o->format) {\n\n        if (!(file_iformat = av_find_input_format(o->format))) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Unknown input format: '%s'\\n\", o->format);\n\n            exit_program(1);\n\n        }\n\n    }\n\n\n\n    if (!strcmp(filename, \"-\"))\n\n        filename = \"pipe:\";\n\n\n\n    using_stdin |= !strncmp(filename, \"pipe:\", 5) ||\n\n                    !strcmp(filename, \"/dev/stdin\");\n\n\n\n    /* get default parameters from command line */\n\n    ic = avformat_alloc_context();\n\n    if (!ic) {\n\n        print_error(filename, AVERROR(ENOMEM));\n\n        exit_program(1);\n\n    }\n\n    if (o->nb_audio_sample_rate) {\n\n        snprintf(buf, sizeof(buf), \"%d\", o->audio_sample_rate[o->nb_audio_sample_rate - 1].u.i);\n\n        av_dict_set(&format_opts, \"sample_rate\", buf, 0);\n\n    }\n\n    if (o->nb_audio_channels) {\n\n        snprintf(buf, sizeof(buf), \"%d\", o->audio_channels[o->nb_audio_channels - 1].u.i);\n\n        av_dict_set(&format_opts, \"channels\", buf, 0);\n\n    }\n\n    if (o->nb_frame_rates) {\n\n        av_dict_set(&format_opts, \"framerate\", o->frame_rates[o->nb_frame_rates - 1].u.str, 0);\n\n    }\n\n    if (o->nb_frame_sizes) {\n\n        av_dict_set(&format_opts, \"video_size\", o->frame_sizes[o->nb_frame_sizes - 1].u.str, 0);\n\n    }\n\n    if (o->nb_frame_pix_fmts)\n\n        av_dict_set(&format_opts, \"pixel_format\", o->frame_pix_fmts[o->nb_frame_pix_fmts - 1].u.str, 0);\n\n\n\n    ic->video_codec_id   = video_codec_name ?\n\n        find_codec_or_die(video_codec_name   , AVMEDIA_TYPE_VIDEO   , 0)->id : CODEC_ID_NONE;\n\n    ic->audio_codec_id   = audio_codec_name ?\n\n        find_codec_or_die(audio_codec_name   , AVMEDIA_TYPE_AUDIO   , 0)->id : CODEC_ID_NONE;\n\n    ic->subtitle_codec_id= subtitle_codec_name ?\n\n        find_codec_or_die(subtitle_codec_name, AVMEDIA_TYPE_SUBTITLE, 0)->id : CODEC_ID_NONE;\n\n    ic->flags |= AVFMT_FLAG_NONBLOCK;\n\n    ic->interrupt_callback = int_cb;\n\n\n\n    if (loop_input) {\n\n        av_log(NULL, AV_LOG_WARNING, \"-loop_input is deprecated, use -loop 1\\n\");\n\n        ic->loop_input = loop_input;\n\n    }\n\n\n\n    /* open the input file with generic avformat function */\n\n    err = avformat_open_input(&ic, filename, file_iformat, &format_opts);\n\n    if (err < 0) {\n\n        print_error(filename, err);\n\n        exit_program(1);\n\n    }\n\n    assert_avoptions(format_opts);\n\n\n\n    /* apply forced codec ids */\n\n    for (i = 0; i < ic->nb_streams; i++)\n\n        choose_decoder(o, ic, ic->streams[i]);\n\n\n\n    /* Set AVCodecContext options for avformat_find_stream_info */\n\n    opts = setup_find_stream_info_opts(ic, codec_opts);\n\n    orig_nb_streams = ic->nb_streams;\n\n\n\n    /* If not enough info to get the stream parameters, we decode the\n\n       first frames to get it. (used in mpeg case for example) */\n\n    ret = avformat_find_stream_info(ic, opts);\n\n    if (ret < 0) {\n\n        av_log(NULL, AV_LOG_FATAL, \"%s: could not find codec parameters\\n\", filename);\n\n        av_close_input_file(ic);\n\n        exit_program(1);\n\n    }\n\n\n\n    timestamp = o->start_time;\n\n    /* add the stream start time */\n\n    if (ic->start_time != AV_NOPTS_VALUE)\n\n        timestamp += ic->start_time;\n\n\n\n    /* if seeking requested, we execute it */\n\n    if (o->start_time != 0) {\n\n        ret = av_seek_frame(ic, -1, timestamp, AVSEEK_FLAG_BACKWARD);\n\n        if (ret < 0) {\n\n            av_log(NULL, AV_LOG_WARNING, \"%s: could not seek to position %0.3f\\n\",\n\n                   filename, (double)timestamp / AV_TIME_BASE);\n\n        }\n\n    }\n\n\n\n    /* update the current parameters so that they match the one of the input stream */\n\n    add_input_streams(o, ic);\n\n\n\n    /* dump the file content */\n\n    av_dump_format(ic, nb_input_files, filename, 0);\n\n\n\n    input_files = grow_array(input_files, sizeof(*input_files), &nb_input_files, nb_input_files + 1);\n\n    input_files[nb_input_files - 1].ctx        = ic;\n\n    input_files[nb_input_files - 1].ist_index  = nb_input_streams - ic->nb_streams;\n\n    input_files[nb_input_files - 1].ts_offset  = o->input_ts_offset - (copy_ts ? 0 : timestamp);\n\n    input_files[nb_input_files - 1].nb_streams = ic->nb_streams;\n\n    input_files[nb_input_files - 1].rate_emu   = o->rate_emu;\n\n\n\n    for (i = 0; i < o->nb_dump_attachment; i++) {\n\n        int j;\n\n\n\n        for (j = 0; j < ic->nb_streams; j++) {\n\n            AVStream *st = ic->streams[j];\n\n\n\n            if (check_stream_specifier(ic, st, o->dump_attachment[i].specifier) == 1)\n\n                dump_attachment(st, o->dump_attachment[i].u.str);\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < orig_nb_streams; i++)\n\n        av_dict_free(&opts[i]);\n\n    av_freep(&opts);\n\n\n\n    reset_options(o, 1);\n\n    return 0;\n\n}\n", "idx": 22459}
{"project": "FFmpeg", "commit_id": "eb38d8fe926bdce8110fa4be4fddf6598a079a20", "target": 0, "func": "static void fill_tone_level_array (QDM2Context *q, int flag)\n\n{\n\n    int i, sb, ch, sb_used;\n\n    int tmp, tab;\n\n\n\n    // This should never happen\n\n    if (q->nb_channels <= 0)\n\n        return;\n\n\n\n    for (ch = 0; ch < q->nb_channels; ch++)\n\n        for (sb = 0; sb < 30; sb++)\n\n            for (i = 0; i < 8; i++) {\n\n                if ((tab=coeff_per_sb_for_dequant[q->coeff_per_sb_select][sb]) < (last_coeff[q->coeff_per_sb_select] - 1))\n\n                    tmp = q->quantized_coeffs[ch][tab + 1][i] * dequant_table[q->coeff_per_sb_select][tab + 1][sb]+\n\n                          q->quantized_coeffs[ch][tab][i] * dequant_table[q->coeff_per_sb_select][tab][sb];\n\n                else\n\n                    tmp = q->quantized_coeffs[ch][tab][i] * dequant_table[q->coeff_per_sb_select][tab][sb];\n\n                if(tmp < 0)\n\n                    tmp += 0xff;\n\n                q->tone_level_idx_base[ch][sb][i] = (tmp / 256) & 0xff;\n\n            }\n\n\n\n    sb_used = QDM2_SB_USED(q->sub_sampling);\n\n\n\n    if ((q->superblocktype_2_3 != 0) && !flag) {\n\n        for (sb = 0; sb < sb_used; sb++)\n\n            for (ch = 0; ch < q->nb_channels; ch++)\n\n                for (i = 0; i < 64; i++) {\n\n                    q->tone_level_idx[ch][sb][i] = q->tone_level_idx_base[ch][sb][i / 8];\n\n                    if (q->tone_level_idx[ch][sb][i] < 0)\n\n                        q->tone_level[ch][sb][i] = 0;\n\n                    else\n\n                        q->tone_level[ch][sb][i] = fft_tone_level_table[0][q->tone_level_idx[ch][sb][i] & 0x3f];\n\n                }\n\n    } else {\n\n        tab = q->superblocktype_2_3 ? 0 : 1;\n\n        for (sb = 0; sb < sb_used; sb++) {\n\n            if ((sb >= 4) && (sb <= 23)) {\n\n                for (ch = 0; ch < q->nb_channels; ch++)\n\n                    for (i = 0; i < 64; i++) {\n\n                        tmp = q->tone_level_idx_base[ch][sb][i / 8] -\n\n                              q->tone_level_idx_hi1[ch][sb / 8][i / 8][i % 8] -\n\n                              q->tone_level_idx_mid[ch][sb - 4][i / 8] -\n\n                              q->tone_level_idx_hi2[ch][sb - 4];\n\n                        q->tone_level_idx[ch][sb][i] = tmp & 0xff;\n\n                        if ((tmp < 0) || (!q->superblocktype_2_3 && !tmp))\n\n                            q->tone_level[ch][sb][i] = 0;\n\n                        else\n\n                            q->tone_level[ch][sb][i] = fft_tone_level_table[tab][tmp & 0x3f];\n\n                }\n\n            } else {\n\n                if (sb > 4) {\n\n                    for (ch = 0; ch < q->nb_channels; ch++)\n\n                        for (i = 0; i < 64; i++) {\n\n                            tmp = q->tone_level_idx_base[ch][sb][i / 8] -\n\n                                  q->tone_level_idx_hi1[ch][2][i / 8][i % 8] -\n\n                                  q->tone_level_idx_hi2[ch][sb - 4];\n\n                            q->tone_level_idx[ch][sb][i] = tmp & 0xff;\n\n                            if ((tmp < 0) || (!q->superblocktype_2_3 && !tmp))\n\n                                q->tone_level[ch][sb][i] = 0;\n\n                            else\n\n                                q->tone_level[ch][sb][i] = fft_tone_level_table[tab][tmp & 0x3f];\n\n                    }\n\n                } else {\n\n                    for (ch = 0; ch < q->nb_channels; ch++)\n\n                        for (i = 0; i < 64; i++) {\n\n                            tmp = q->tone_level_idx[ch][sb][i] = q->tone_level_idx_base[ch][sb][i / 8];\n\n                            if ((tmp < 0) || (!q->superblocktype_2_3 && !tmp))\n\n                                q->tone_level[ch][sb][i] = 0;\n\n                            else\n\n                                q->tone_level[ch][sb][i] = fft_tone_level_table[tab][tmp & 0x3f];\n\n                        }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    return;\n\n}\n", "idx": 22460}
{"project": "FFmpeg", "commit_id": "d38c173dfb4bbee19ec341202c6c79bb0aa2cdad", "target": 0, "func": "static int filter_frame(AVFilterLink *inlink, AVFrame *src_buffer)\n\n{\n\n    AVFilterContext  *ctx = inlink->dst;\n\n    ATempoContext *atempo = ctx->priv;\n\n    AVFilterLink *outlink = ctx->outputs[0];\n\n\n\n    int ret = 0;\n\n    int n_in = src_buffer->nb_samples;\n\n    int n_out = (int)(0.5 + ((double)n_in) / atempo->tempo);\n\n\n\n    const uint8_t *src = src_buffer->data[0];\n\n    const uint8_t *src_end = src + n_in * atempo->stride;\n\n\n\n    while (src < src_end) {\n\n        if (!atempo->dst_buffer) {\n\n            atempo->dst_buffer = ff_get_audio_buffer(outlink, n_out);\n\n            av_frame_copy_props(atempo->dst_buffer, src_buffer);\n\n\n\n            atempo->dst = atempo->dst_buffer->data[0];\n\n            atempo->dst_end = atempo->dst + n_out * atempo->stride;\n\n        }\n\n\n\n        yae_apply(atempo, &src, src_end, &atempo->dst, atempo->dst_end);\n\n\n\n        if (atempo->dst == atempo->dst_end) {\n\n            ret = push_samples(atempo, outlink, n_out);\n\n            if (ret < 0)\n\n                goto end;\n\n            atempo->request_fulfilled = 1;\n\n        }\n\n    }\n\n\n\n    atempo->nsamples_in += n_in;\n\nend:\n\n    av_frame_free(&src_buffer);\n\n    return ret;\n\n}\n", "idx": 22461}
{"project": "FFmpeg", "commit_id": "4bb1070c154e49d35805fbcdac9c9e92f702ef96", "target": 0, "func": "static av_always_inline void decode_line(FFV1Context *s, int w,\n\n                                         int16_t *sample[2],\n\n                                         int plane_index, int bits)\n\n{\n\n    PlaneContext *const p = &s->plane[plane_index];\n\n    RangeCoder *const c   = &s->c;\n\n    int x;\n\n    int run_count = 0;\n\n    int run_mode  = 0;\n\n    int run_index = s->run_index;\n\n\n\n    for (x = 0; x < w; x++) {\n\n        int diff, context, sign;\n\n\n\n        context = get_context(p, sample[1] + x, sample[0] + x, sample[1] + x);\n\n        if (context < 0) {\n\n            context = -context;\n\n            sign    = 1;\n\n        } else\n\n            sign = 0;\n\n\n\n        av_assert2(context < p->context_count);\n\n\n\n        if (s->ac) {\n\n            diff = get_symbol_inline(c, p->state[context], 1);\n\n        } else {\n\n            if (context == 0 && run_mode == 0)\n\n                run_mode = 1;\n\n\n\n            if (run_mode) {\n\n                if (run_count == 0 && run_mode == 1) {\n\n                    if (get_bits1(&s->gb)) {\n\n                        run_count = 1 << ff_log2_run[run_index];\n\n                        if (x + run_count <= w)\n\n                            run_index++;\n\n                    } else {\n\n                        if (ff_log2_run[run_index])\n\n                            run_count = get_bits(&s->gb, ff_log2_run[run_index]);\n\n                        else\n\n                            run_count = 0;\n\n                        if (run_index)\n\n                            run_index--;\n\n                        run_mode = 2;\n\n                    }\n\n                }\n\n                run_count--;\n\n                if (run_count < 0) {\n\n                    run_mode  = 0;\n\n                    run_count = 0;\n\n                    diff      = get_vlc_symbol(&s->gb, &p->vlc_state[context],\n\n                                               bits);\n\n                    if (diff >= 0)\n\n                        diff++;\n\n                } else\n\n                    diff = 0;\n\n            } else\n\n                diff = get_vlc_symbol(&s->gb, &p->vlc_state[context], bits);\n\n\n\n            ff_dlog(s->avctx, \"count:%d index:%d, mode:%d, x:%d pos:%d\\n\",\n\n                    run_count, run_index, run_mode, x, get_bits_count(&s->gb));\n\n        }\n\n\n\n        if (sign)\n\n            diff = -diff;\n\n\n\n        sample[1][x] = (predict(sample[1] + x, sample[0] + x) + diff) &\n\n                       ((1 << bits) - 1);\n\n    }\n\n    s->run_index = run_index;\n\n}\n", "idx": 22468}
{"project": "FFmpeg", "commit_id": "e5540b3fd30367ce3cc33b2f34a04b660dbc4b38", "target": 0, "func": "static int decode_i_picture_header(VC9Context *v)\n\n{\n\n  int pqindex, status = 0, ac_pred, condover;\n\n\n\n    /* Prolog common to all frametypes should be done in caller */\n\n    //BF = Buffer Fullness\n\n    if (v->profile <= PROFILE_MAIN && get_bits(&v->gb, 7))\n\n    {\n\n        av_log(v, AV_LOG_DEBUG, \"I BufferFullness not 0\\n\");\n\n    }\n\n\n\n    /* Quantizer stuff */\n\n    pqindex = get_bits(&v->gb, 5);\n\n    if (v->quantizer_mode == QUANT_FRAME_IMPLICIT)\n\n        v->pq = pquant_table[0][pqindex];\n\n    else\n\n    {\n\n        v->pq = pquant_table[v->quantizer_mode-1][pqindex];\n\n    }\n\n    if (pqindex < 9) v->halfpq = get_bits(&v->gb, 1);\n\n    if (v->quantizer_mode == QUANT_FRAME_EXPLICIT)\n\n        v->pquantizer = get_bits(&v->gb, 1);\n\n    av_log(v->avctx, AV_LOG_DEBUG, \"I frame: QP=%i (+%i/2)\\n\",\n\n           v->pq, v->halfpq);\n\n#if HAS_ADVANCED_PROFILE\n\n    if (v->profile <= PROFILE_MAIN)\n\n#endif\n\n    {\n\n        if (v->extended_mv) v->mvrange = get_prefix(&v->gb, 0, 3);\n\n        if (v->multires) v->respic = get_bits(&v->gb, 2);\n\n    }\n\n#if HAS_ADVANCED_PROFILE\n\n    else\n\n    {\n\n        ac_pred = get_bits(&v->gb, 1);\n\n        if (v->postprocflag) v->postproc = get_bits(&v->gb, 1);\n\n        /* 7.1.1.34 + 8.5.2 */\n\n        if (v->overlap && v->pq<9)\n\n        {\n\n            condover = get_bits(&v->gb, 1);\n\n            if (condover)\n\n            {\n\n                condover = 2+get_bits(&v->gb, 1);\n\n                if (condover == 3)\n\n                    status = bitplane_decoding(v->over_flags_plane,\n\n                                                   v->width_mb, v->height_mb, v);\n\n            }\n\n        }\n\n    }\n\n#endif\n\n\n\n    /* Epilog should be done in caller */\n\n    return status;\n\n}\n", "idx": 22479}
{"project": "FFmpeg", "commit_id": "fbd6c97f9ca858140df16dd07200ea0d4bdc1a83", "target": 1, "func": "static void add_to_pool(BufferPoolEntry *buf)\n\n{\n\n    AVBufferPool *pool;\n\n    BufferPoolEntry *cur, *end = buf;\n\n\n\n    if (!buf)\n\n        return;\n\n    pool = buf->pool;\n\n\n\n    while (end->next)\n\n        end = end->next;\n\n\n\n    while ((cur = avpriv_atomic_ptr_cas((void * volatile *)&pool->pool, NULL, buf))) {\n\n        /* pool is not empty, retrieve it and append it to our list */\n\n        cur = get_pool(pool);\n\n        end->next = cur;\n\n        while (end->next)\n\n            end = end->next;\n\n    }\n\n}\n", "idx": 22488}
{"project": "FFmpeg", "commit_id": "2d40a09b6e73230b160a505f01ed1acf169e1d9f", "target": 1, "func": "static int libquvi_read_seek(AVFormatContext *s, int stream_index, int64_t timestamp, int flags)\n\n{\n\n    LibQuviContext *qc = s->priv_data;\n\n    return av_seek_frame(qc->fmtctx, stream_index, timestamp, flags);\n\n}\n", "idx": 22493}
{"project": "FFmpeg", "commit_id": "b6eaae39b4913db81d9e3d0ad6a2f6261757d83d", "target": 1, "func": "static int asf_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    ASFContext *asf = s->priv_data;\n\n    ASFStream *asf_st = 0;\n\n    ByteIOContext *pb = &s->pb;\n\n    //static int pc = 0;\n\n    for (;;) {\n\n        int rsize = 0;\n\n        if (asf->packet_size_left < FRAME_HEADER_SIZE\n\n            || asf->packet_segments < 1) {\n\n            //asf->packet_size_left <= asf->packet_padsize) {\n\n            int ret = asf->packet_size_left + asf->packet_padsize;\n\n            //printf(\"PacketLeftSize:%d  Pad:%d Pos:%Ld\\n\", asf->packet_size_left, asf->packet_padsize, url_ftell(pb));\n\n            if((url_ftell(&s->pb) + ret - s->data_offset) % asf->packet_size)\n\n                ret += asf->packet_size - ((url_ftell(&s->pb) + ret - s->data_offset) % asf->packet_size);\n\n            /* fail safe */\n\n            url_fskip(pb, ret);\n\n            asf->packet_pos= url_ftell(&s->pb);\n\n\n\n\n            ret = asf_get_packet(s);\n\n            //printf(\"READ ASF PACKET  %d   r:%d   c:%d\\n\", ret, asf->packet_size_left, pc++);\n\n            if (ret < 0 || url_feof(pb))\n\n                return AVERROR_IO;\n\n            asf->packet_time_start = 0;\n\n            continue;\n\n        }\n\n        if (asf->packet_time_start == 0) {\n\n            /* read frame header */\n\n            int num = get_byte(pb);\n\n            asf->packet_segments--;\n\n            rsize++;\n\n            asf->packet_key_frame = (num & 0x80) >> 7;\n\n            asf->stream_index = asf->asfid2avid[num & 0x7f];\n\n            // sequence should be ignored!\n\n            DO_2BITS(asf->packet_property >> 4, asf->packet_seq, 0);\n\n            DO_2BITS(asf->packet_property >> 2, asf->packet_frag_offset, 0);\n\n            DO_2BITS(asf->packet_property, asf->packet_replic_size, 0);\n\n//printf(\"key:%d stream:%d seq:%d offset:%d replic_size:%d\\n\", asf->packet_key_frame, asf->stream_index, asf->packet_seq, //asf->packet_frag_offset, asf->packet_replic_size);\n\n            if (asf->packet_replic_size > 1) {\n\n                assert(asf->packet_replic_size >= 8);\n\n                // it should be always at least 8 bytes - FIXME validate\n\n                asf->packet_obj_size = get_le32(pb);\n\n                asf->packet_frag_timestamp = get_le32(pb); // timestamp\n\n                if (asf->packet_replic_size > 8)\n\n                    url_fskip(pb, asf->packet_replic_size - 8);\n\n                rsize += asf->packet_replic_size; // FIXME - check validity\n\n            } else if (asf->packet_replic_size==1){\n\n                // multipacket - frag_offset is begining timestamp\n\n                asf->packet_time_start = asf->packet_frag_offset;\n\n                asf->packet_frag_offset = 0;\n\n                asf->packet_frag_timestamp = asf->packet_timestamp;\n\n\n\n                asf->packet_time_delta = get_byte(pb);\n\n                rsize++;\n\n            }else{\n\n                assert(asf->packet_replic_size==0);\n\n            }\n\n            if (asf->packet_flags & 0x01) {\n\n                DO_2BITS(asf->packet_segsizetype >> 6, asf->packet_frag_size, 0); // 0 is illegal\n\n#undef DO_2BITS\n\n                //printf(\"Fragsize %d\\n\", asf->packet_frag_size);\n\n            } else {\n\n                asf->packet_frag_size = asf->packet_size_left - rsize;\n\n                //printf(\"Using rest  %d %d %d\\n\", asf->packet_frag_size, asf->packet_size_left, rsize);\n\n            }\n\n            if (asf->packet_replic_size == 1) {\n\n                asf->packet_multi_size = asf->packet_frag_size;\n\n                if (asf->packet_multi_size > asf->packet_size_left) {\n\n                    asf->packet_segments = 0;\n\n                    continue;\n\n                }\n\n            }\n\n            asf->packet_size_left -= rsize;\n\n            //printf(\"___objsize____  %d   %d    rs:%d\\n\", asf->packet_obj_size, asf->packet_frag_offset, rsize);\n\n\n\n            if (asf->stream_index < 0\n\n                || s->streams[asf->stream_index]->discard >= AVDISCARD_ALL\n\n                || (!asf->packet_key_frame && s->streams[asf->stream_index]->discard >= AVDISCARD_NONKEY)\n\n                ) {\n\n                asf->packet_time_start = 0;\n\n                /* unhandled packet (should not happen) */\n\n                url_fskip(pb, asf->packet_frag_size);\n\n                asf->packet_size_left -= asf->packet_frag_size;\n\n                if(asf->stream_index < 0)\n\n                    av_log(s, AV_LOG_ERROR, \"ff asf skip %d  %d\\n\", asf->packet_frag_size, num & 0x7f);\n\n                continue;\n\n            }\n\n            asf->asf_st = s->streams[asf->stream_index]->priv_data;\n\n        }\n\n        asf_st = asf->asf_st;\n\n\n\n        if ((asf->packet_frag_offset != asf_st->frag_offset\n\n             || (asf->packet_frag_offset\n\n                 && asf->packet_seq != asf_st->seq)) // seq should be ignored\n\n           ) {\n\n            /* cannot continue current packet: free it */\n\n            // FIXME better check if packet was already allocated\n\n            av_log(s, AV_LOG_INFO, \"ff asf parser skips: %d - %d     o:%d - %d    %d %d   fl:%d\\n\",\n\n                   asf_st->pkt.size,\n\n                   asf->packet_obj_size,\n\n                   asf->packet_frag_offset, asf_st->frag_offset,\n\n                   asf->packet_seq, asf_st->seq, asf->packet_frag_size);\n\n            if (asf_st->pkt.size)\n\n                av_free_packet(&asf_st->pkt);\n\n            asf_st->frag_offset = 0;\n\n            if (asf->packet_frag_offset != 0) {\n\n                url_fskip(pb, asf->packet_frag_size);\n\n                av_log(s, AV_LOG_INFO, \"ff asf parser skipping %db\\n\", asf->packet_frag_size);\n\n                asf->packet_size_left -= asf->packet_frag_size;\n\n                continue;\n\n            }\n\n        }\n\n        if (asf->packet_replic_size == 1) {\n\n            // frag_offset is here used as the begining timestamp\n\n            asf->packet_frag_timestamp = asf->packet_time_start;\n\n            asf->packet_time_start += asf->packet_time_delta;\n\n            asf->packet_obj_size = asf->packet_frag_size = get_byte(pb);\n\n            asf->packet_size_left--;\n\n            asf->packet_multi_size--;\n\n            if (asf->packet_multi_size < asf->packet_obj_size)\n\n            {\n\n                asf->packet_time_start = 0;\n\n                url_fskip(pb, asf->packet_multi_size);\n\n                asf->packet_size_left -= asf->packet_multi_size;\n\n                continue;\n\n            }\n\n            asf->packet_multi_size -= asf->packet_obj_size;\n\n            //printf(\"COMPRESS size  %d  %d  %d   ms:%d\\n\", asf->packet_obj_size, asf->packet_frag_timestamp, asf->packet_size_left, asf->packet_multi_size);\n\n        }\n\n        if (asf_st->frag_offset == 0) {\n\n            /* new packet */\n\n            av_new_packet(&asf_st->pkt, asf->packet_obj_size);\n\n            asf_st->seq = asf->packet_seq;\n\n            asf_st->pkt.pts = asf->packet_frag_timestamp;\n\n            asf_st->pkt.stream_index = asf->stream_index;\n\n            asf_st->pkt.pos =\n\n            asf_st->packet_pos= asf->packet_pos;\n\n//printf(\"new packet: stream:%d key:%d packet_key:%d audio:%d size:%d\\n\",\n\n//asf->stream_index, asf->packet_key_frame, asf_st->pkt.flags & PKT_FLAG_KEY,\n\n//s->streams[asf->stream_index]->codec->codec_type == CODEC_TYPE_AUDIO, asf->packet_obj_size);\n\n            if (s->streams[asf->stream_index]->codec->codec_type == CODEC_TYPE_AUDIO)\n\n                asf->packet_key_frame = 1;\n\n            if (asf->packet_key_frame)\n\n                asf_st->pkt.flags |= PKT_FLAG_KEY;\n\n        }\n\n\n\n        /* read data */\n\n        //printf(\"READ PACKET s:%d  os:%d  o:%d,%d  l:%d   DATA:%p\\n\",\n\n        //       asf->packet_size, asf_st->pkt.size, asf->packet_frag_offset,\n\n        //       asf_st->frag_offset, asf->packet_frag_size, asf_st->pkt.data);\n\n        asf->packet_size_left -= asf->packet_frag_size;\n\n        if (asf->packet_size_left < 0)\n\n            continue;\n\n        get_buffer(pb, asf_st->pkt.data + asf->packet_frag_offset,\n\n                   asf->packet_frag_size);\n\n        asf_st->frag_offset += asf->packet_frag_size;\n\n        /* test if whole packet is read */\n\n        if (asf_st->frag_offset == asf_st->pkt.size) {\n\n            /* return packet */\n\n            if (asf_st->ds_span > 1) {\n\n                /* packet descrambling */\n\n                char* newdata = av_malloc(asf_st->pkt.size);\n\n                if (newdata) {\n\n                    int offset = 0;\n\n                    while (offset < asf_st->pkt.size) {\n\n                        int off = offset / asf_st->ds_chunk_size;\n\n                        int row = off / asf_st->ds_span;\n\n                        int col = off % asf_st->ds_span;\n\n                        int idx = row + col * asf_st->ds_packet_size / asf_st->ds_chunk_size;\n\n                        //printf(\"off:%d  row:%d  col:%d  idx:%d\\n\", off, row, col, idx);\n\n                        memcpy(newdata + offset,\n\n                               asf_st->pkt.data + idx * asf_st->ds_chunk_size,\n\n                               asf_st->ds_chunk_size);\n\n                        offset += asf_st->ds_chunk_size;\n\n                    }\n\n                    av_free(asf_st->pkt.data);\n\n                    asf_st->pkt.data = newdata;\n\n                }\n\n            }\n\n            asf_st->frag_offset = 0;\n\n            memcpy(pkt, &asf_st->pkt, sizeof(AVPacket));\n\n            //printf(\"packet %d %d\\n\", asf_st->pkt.size, asf->packet_frag_size);\n\n            asf_st->pkt.size = 0;\n\n            asf_st->pkt.data = 0;\n\n            break; // packet completed\n\n        }\n\n    }\n\n    return 0;\n\n}", "idx": 22499}
{"project": "FFmpeg", "commit_id": "1ec83d9a9e472f485897ac92bad9631d551a8c5b", "target": 0, "func": "static int decode_frame(AVCodecContext *avctx,\n\n                        void *data, int *data_size, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    TiffContext *const s = avctx->priv_data;\n\n    AVFrame *picture = data;\n\n    AVFrame *const p = &s->picture;\n\n    const uint8_t *orig_buf = buf, *end_buf = buf + buf_size;\n\n    unsigned off;\n\n    int id, le, ret;\n\n    int i, j, entries;\n\n    int stride;\n\n    unsigned soff, ssize;\n\n    uint8_t *dst;\n\n\n\n    //parse image header\n\n    if (end_buf - buf < 8)\n\n        return AVERROR_INVALIDDATA;\n\n    id = AV_RL16(buf);\n\n    buf += 2;\n\n    if (id == 0x4949)\n\n        le = 1;\n\n    else if (id == 0x4D4D)\n\n        le = 0;\n\n    else {\n\n        av_log(avctx, AV_LOG_ERROR, \"TIFF header not found\\n\");\n\n        return -1;\n\n    }\n\n    s->le = le;\n\n    s->invert = 0;\n\n    s->compr = TIFF_RAW;\n\n    s->fill_order = 0;\n\n    free_geotags(s);\n\n    /* free existing metadata */\n\n    av_dict_free(&s->picture.metadata);\n\n\n\n    // As TIFF 6.0 specification puts it \"An arbitrary but carefully chosen number\n\n    // that further identifies the file as a TIFF file\"\n\n    if (tget_short(&buf, le) != 42) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"The answer to life, universe and everything is not correct!\\n\");\n\n        return -1;\n\n    }\n\n    // Reset these pointers so we can tell if they were set this frame\n\n    s->stripsizes = s->stripdata = NULL;\n\n    /* parse image file directory */\n\n    off = tget_long(&buf, le);\n\n    if (off >= UINT_MAX - 14 || end_buf - orig_buf < off + 14) {\n\n        av_log(avctx, AV_LOG_ERROR, \"IFD offset is greater than image size\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    buf = orig_buf + off;\n\n    entries = tget_short(&buf, le);\n\n    for (i = 0; i < entries; i++) {\n\n        if (tiff_decode_tag(s, orig_buf, buf, end_buf) < 0)\n\n            return -1;\n\n        buf += 12;\n\n    }\n\n\n\n    for (i = 0; i<s->geotag_count; i++) {\n\n        const char *keyname = get_geokey_name(s->geotags[i].key);\n\n        if (!keyname) {\n\n            av_log(avctx, AV_LOG_WARNING, \"Unknown or unsupported GeoTIFF key %d\\n\", s->geotags[i].key);\n\n            continue;\n\n        }\n\n        if (get_geokey_type(s->geotags[i].key) != s->geotags[i].type) {\n\n            av_log(avctx, AV_LOG_WARNING, \"Type of GeoTIFF key %d is wrong\\n\", s->geotags[i].key);\n\n            continue;\n\n        }\n\n        ret = av_dict_set(&s->picture.metadata, keyname, s->geotags[i].val, 0);\n\n        if (ret<0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Writing metadata with key '%s' failed\\n\", keyname);\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    if (!s->stripdata && !s->stripoff) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Image data is missing\\n\");\n\n        return -1;\n\n    }\n\n    /* now we have the data and may start decoding */\n\n    if ((ret = init_image(s)) < 0)\n\n        return ret;\n\n\n\n    if (s->strips == 1 && !s->stripsize) {\n\n        av_log(avctx, AV_LOG_WARNING, \"Image data size missing\\n\");\n\n        s->stripsize = buf_size - s->stripoff;\n\n    }\n\n    stride = p->linesize[0];\n\n    dst = p->data[0];\n\n    for (i = 0; i < s->height; i += s->rps) {\n\n        if (s->stripsizes) {\n\n            if (s->stripsizes >= end_buf)\n\n                return AVERROR_INVALIDDATA;\n\n            ssize = tget(&s->stripsizes, s->sstype, s->le);\n\n        } else\n\n            ssize = s->stripsize;\n\n\n\n        if (s->stripdata) {\n\n            if (s->stripdata >= end_buf)\n\n                return AVERROR_INVALIDDATA;\n\n            soff = tget(&s->stripdata, s->sot, s->le);\n\n        } else\n\n            soff = s->stripoff;\n\n\n\n        if (soff > buf_size || ssize > buf_size - soff) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Invalid strip size/offset\\n\");\n\n            return -1;\n\n        }\n\n        if (tiff_unpack_strip(s, dst, stride, orig_buf + soff, ssize,\n\n                              FFMIN(s->rps, s->height - i)) < 0)\n\n            break;\n\n        dst += s->rps * stride;\n\n    }\n\n    if (s->predictor == 2) {\n\n        dst = p->data[0];\n\n        soff = s->bpp >> 3;\n\n        ssize = s->width * soff;\n\n        if (s->avctx->pix_fmt == PIX_FMT_RGB48LE ||\n\n            s->avctx->pix_fmt == PIX_FMT_RGBA64LE) {\n\n            for (i = 0; i < s->height; i++) {\n\n                for (j = soff; j < ssize; j += 2)\n\n                    AV_WL16(dst + j, AV_RL16(dst + j) + AV_RL16(dst + j - soff));\n\n                dst += stride;\n\n            }\n\n        } else if (s->avctx->pix_fmt == PIX_FMT_RGB48BE ||\n\n                   s->avctx->pix_fmt == PIX_FMT_RGBA64BE) {\n\n            for (i = 0; i < s->height; i++) {\n\n                for (j = soff; j < ssize; j += 2)\n\n                    AV_WB16(dst + j, AV_RB16(dst + j) + AV_RB16(dst + j - soff));\n\n                dst += stride;\n\n            }\n\n        } else {\n\n            for (i = 0; i < s->height; i++) {\n\n                for (j = soff; j < ssize; j++)\n\n                    dst[j] += dst[j - soff];\n\n                dst += stride;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (s->invert) {\n\n        dst = s->picture.data[0];\n\n        for (i = 0; i < s->height; i++) {\n\n            for (j = 0; j < s->picture.linesize[0]; j++)\n\n                dst[j] = (s->avctx->pix_fmt == PIX_FMT_PAL8 ? (1<<s->bpp) - 1 : 255) - dst[j];\n\n            dst += s->picture.linesize[0];\n\n        }\n\n    }\n\n    *picture   = s->picture;\n\n    *data_size = sizeof(AVPicture);\n\n\n\n    return buf_size;\n\n}\n", "idx": 22500}
{"project": "FFmpeg", "commit_id": "5688fd77b57f1dd454990dc6fe48c6a3a1729eca", "target": 0, "func": "void ff_limiter_init_x86(LimiterDSPContext *dsp, int bpp)\n\n{\n\n    int cpu_flags = av_get_cpu_flags();\n\n\n\n    if (ARCH_X86_64 && EXTERNAL_SSE2(cpu_flags)) {\n\n        if (bpp <= 8) {\n\n            dsp->limiter = ff_limiter_8bit_sse2;\n\n        }\n\n    }\n\n    if (ARCH_X86_64 && EXTERNAL_SSE4(cpu_flags)) {\n\n        if (bpp > 8) {\n\n            dsp->limiter = ff_limiter_16bit_sse4;\n\n        }\n\n    }\n\n}\n", "idx": 22501}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "void ff_thread_release_buffer(AVCodecContext *avctx, ThreadFrame *f)\n\n{\n\n    PerThreadContext *p = avctx->internal->thread_ctx;\n\n    FrameThreadContext *fctx;\n\n    AVFrame *dst, *tmp;\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    int can_direct_free = !(avctx->active_thread_type & FF_THREAD_FRAME) ||\n\n                          avctx->thread_safe_callbacks                   ||\n\n                          (\n\n#if FF_API_GET_BUFFER\n\n                           !avctx->get_buffer &&\n\n#endif\n\n                           avctx->get_buffer2 == avcodec_default_get_buffer2);\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n\n\n    if (!f->f->buf[0])\n\n        return;\n\n\n\n    if (avctx->debug & FF_DEBUG_BUFFERS)\n\n        av_log(avctx, AV_LOG_DEBUG, \"thread_release_buffer called on pic %p\\n\", f);\n\n\n\n    av_buffer_unref(&f->progress);\n\n    f->owner    = NULL;\n\n\n\n    if (can_direct_free) {\n\n        av_frame_unref(f->f);\n\n        return;\n\n    }\n\n\n\n    fctx = p->parent;\n\n    pthread_mutex_lock(&fctx->buffer_mutex);\n\n\n\n    if (p->num_released_buffers + 1 >= INT_MAX / sizeof(*p->released_buffers))\n\n        goto fail;\n\n    tmp = av_fast_realloc(p->released_buffers, &p->released_buffers_allocated,\n\n                          (p->num_released_buffers + 1) *\n\n                          sizeof(*p->released_buffers));\n\n    if (!tmp)\n\n        goto fail;\n\n    p->released_buffers = tmp;\n\n\n\n    dst = &p->released_buffers[p->num_released_buffers];\n\n    av_frame_move_ref(dst, f->f);\n\n\n\n    p->num_released_buffers++;\n\n\n\nfail:\n\n    pthread_mutex_unlock(&fctx->buffer_mutex);\n\n}\n", "idx": 22503}
{"project": "FFmpeg", "commit_id": "f19af812a32c1398d48c3550d11dbc6aafbb2bfc", "target": 1, "func": "static void dump(unsigned char *buf,size_t len)\n\n{\n\n\tint i;\n\n\tfor(i=0;i<len;i++) {\n\n\t\tif ((i&15)==0) printf(\"%04x  \",i);\n\n\t\tprintf(\"%02x \",buf[i]);\n\n\t\tif ((i&15)==15) printf(\"\\n\");\n\n\t}\n\n\tprintf(\"\\n\");\n\n}\n", "idx": 22505}
{"project": "FFmpeg", "commit_id": "74e4948235bc8f8946eeca20525258bbf383f75d", "target": 1, "func": "static int hls_decode_entry_wpp(AVCodecContext *avctxt, void *input_ctb_row, int job, int self_id)\n\n{\n\n    HEVCContext *s1  = avctxt->priv_data, *s;\n\n    HEVCLocalContext *lc;\n\n    int ctb_size    = 1<< s1->ps.sps->log2_ctb_size;\n\n    int more_data   = 1;\n\n    int *ctb_row_p    = input_ctb_row;\n\n    int ctb_row = ctb_row_p[job];\n\n    int ctb_addr_rs = s1->sh.slice_ctb_addr_rs + ctb_row * ((s1->ps.sps->width + ctb_size - 1) >> s1->ps.sps->log2_ctb_size);\n\n    int ctb_addr_ts = s1->ps.pps->ctb_addr_rs_to_ts[ctb_addr_rs];\n\n    int thread = ctb_row % s1->threads_number;\n\n    int ret;\n\n\n\n    s = s1->sList[self_id];\n\n    lc = s->HEVClc;\n\n\n\n    if(ctb_row) {\n\n        ret = init_get_bits8(&lc->gb, s->data + s->sh.offset[ctb_row - 1], s->sh.size[ctb_row - 1]);\n\n\n\n        if (ret < 0)\n\n            return ret;\n\n        ff_init_cabac_decoder(&lc->cc, s->data + s->sh.offset[(ctb_row)-1], s->sh.size[ctb_row - 1]);\n\n    }\n\n\n\n    while(more_data && ctb_addr_ts < s->ps.sps->ctb_size) {\n\n        int x_ctb = (ctb_addr_rs % s->ps.sps->ctb_width) << s->ps.sps->log2_ctb_size;\n\n        int y_ctb = (ctb_addr_rs / s->ps.sps->ctb_width) << s->ps.sps->log2_ctb_size;\n\n\n\n        hls_decode_neighbour(s, x_ctb, y_ctb, ctb_addr_ts);\n\n\n\n        ff_thread_await_progress2(s->avctx, ctb_row, thread, SHIFT_CTB_WPP);\n\n\n\n        if (avpriv_atomic_int_get(&s1->wpp_err)){\n\n            ff_thread_report_progress2(s->avctx, ctb_row , thread, SHIFT_CTB_WPP);\n\n            return 0;\n\n        }\n\n\n\n        ff_hevc_cabac_init(s, ctb_addr_ts);\n\n        hls_sao_param(s, x_ctb >> s->ps.sps->log2_ctb_size, y_ctb >> s->ps.sps->log2_ctb_size);\n\n        more_data = hls_coding_quadtree(s, x_ctb, y_ctb, s->ps.sps->log2_ctb_size, 0);\n\n\n\n        if (more_data < 0) {\n\n            s->tab_slice_address[ctb_addr_rs] = -1;\n\n\n\n            return more_data;\n\n        }\n\n\n\n        ctb_addr_ts++;\n\n\n\n        ff_hevc_save_states(s, ctb_addr_ts);\n\n        ff_thread_report_progress2(s->avctx, ctb_row, thread, 1);\n\n        ff_hevc_hls_filters(s, x_ctb, y_ctb, ctb_size);\n\n\n\n        if (!more_data && (x_ctb+ctb_size) < s->ps.sps->width && ctb_row != s->sh.num_entry_point_offsets) {\n\n\n\n            return 0;\n\n        }\n\n\n\n        if ((x_ctb+ctb_size) >= s->ps.sps->width && (y_ctb+ctb_size) >= s->ps.sps->height ) {\n\n            ff_hevc_hls_filter(s, x_ctb, y_ctb, ctb_size);\n\n            ff_thread_report_progress2(s->avctx, ctb_row , thread, SHIFT_CTB_WPP);\n\n            return ctb_addr_ts;\n\n        }\n\n        ctb_addr_rs       = s->ps.pps->ctb_addr_ts_to_rs[ctb_addr_ts];\n\n        x_ctb+=ctb_size;\n\n\n\n        if(x_ctb >= s->ps.sps->width) {\n\n            break;\n\n        }\n\n    }\n\n\n\n\n    return 0;\n\n}", "idx": 22506}
{"project": "FFmpeg", "commit_id": "5afe1d27912be9b643ffb4ddc21f6d920260dbb0", "target": 1, "func": "static int mpegts_raw_read_packet(AVFormatContext *s,\n\n                                  AVPacket *pkt)\n\n{\n\n    MpegTSContext *ts = s->priv_data;\n\n    int ret, i;\n\n    int64_t pcr_h, next_pcr_h, pos;\n\n    int pcr_l, next_pcr_l;\n\n    uint8_t pcr_buf[12];\n\n    uint8_t *data;\n\n\n\n    if (av_new_packet(pkt, TS_PACKET_SIZE) < 0)\n\n        return AVERROR(ENOMEM);\n\n    pkt->pos= avio_tell(s->pb);\n\n    ret = read_packet(s, pkt->data, ts->raw_packet_size, &data);\n\n    if (ret < 0) {\n\n        av_free_packet(pkt);\n\n        return ret;\n\n    }\n\n    if (data != pkt->data)\n\n        memcpy(pkt->data, data, ts->raw_packet_size);\n\n    finished_reading_packet(s, ts->raw_packet_size);\n\n    if (ts->mpeg2ts_compute_pcr) {\n\n        /* compute exact PCR for each packet */\n\n        if (parse_pcr(&pcr_h, &pcr_l, pkt->data) == 0) {\n\n            /* we read the next PCR (XXX: optimize it by using a bigger buffer */\n\n            pos = avio_tell(s->pb);\n\n            for(i = 0; i < MAX_PACKET_READAHEAD; i++) {\n\n                avio_seek(s->pb, pos + i * ts->raw_packet_size, SEEK_SET);\n\n                avio_read(s->pb, pcr_buf, 12);\n\n                if (parse_pcr(&next_pcr_h, &next_pcr_l, pcr_buf) == 0) {\n\n                    /* XXX: not precise enough */\n\n                    ts->pcr_incr = ((next_pcr_h - pcr_h) * 300 + (next_pcr_l - pcr_l)) /\n\n                        (i + 1);\n\n                    break;\n\n                }\n\n            }\n\n            avio_seek(s->pb, pos, SEEK_SET);\n\n            /* no next PCR found: we use previous increment */\n\n            ts->cur_pcr = pcr_h * 300 + pcr_l;\n\n        }\n\n        pkt->pts = ts->cur_pcr;\n\n        pkt->duration = ts->pcr_incr;\n\n        ts->cur_pcr += ts->pcr_incr;\n\n    }\n\n    pkt->stream_index = 0;\n\n    return 0;\n\n}\n", "idx": 22508}
{"project": "FFmpeg", "commit_id": "90540c2d5ace46a1e9789c75fde0b1f7dbb12a9b", "target": 1, "func": "static inline void RENAME(rgb24tobgr16)(const uint8_t *src, uint8_t *dst, int src_size)\n\n{\n\n    const uint8_t *s = src;\n\n    const uint8_t *end;\n\n    const uint8_t *mm_end;\n\n    uint16_t *d = (uint16_t *)dst;\n\n    end = s + src_size;\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*src):\"memory\");\n\n    __asm__ volatile(\n\n        \"movq         %0, %%mm7     \\n\\t\"\n\n        \"movq         %1, %%mm6     \\n\\t\"\n\n        ::\"m\"(red_16mask),\"m\"(green_16mask));\n\n    mm_end = end - 11;\n\n    while (s < mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"    32%1           \\n\\t\"\n\n            \"movd          %1, %%mm0    \\n\\t\"\n\n            \"movd         3%1, %%mm3    \\n\\t\"\n\n            \"punpckldq    6%1, %%mm0    \\n\\t\"\n\n            \"punpckldq    9%1, %%mm3    \\n\\t\"\n\n            \"movq       %%mm0, %%mm1    \\n\\t\"\n\n            \"movq       %%mm0, %%mm2    \\n\\t\"\n\n            \"movq       %%mm3, %%mm4    \\n\\t\"\n\n            \"movq       %%mm3, %%mm5    \\n\\t\"\n\n            \"psrlq         $3, %%mm0    \\n\\t\"\n\n            \"psrlq         $3, %%mm3    \\n\\t\"\n\n            \"pand          %2, %%mm0    \\n\\t\"\n\n            \"pand          %2, %%mm3    \\n\\t\"\n\n            \"psrlq         $5, %%mm1    \\n\\t\"\n\n            \"psrlq         $5, %%mm4    \\n\\t\"\n\n            \"pand       %%mm6, %%mm1    \\n\\t\"\n\n            \"pand       %%mm6, %%mm4    \\n\\t\"\n\n            \"psrlq         $8, %%mm2    \\n\\t\"\n\n            \"psrlq         $8, %%mm5    \\n\\t\"\n\n            \"pand       %%mm7, %%mm2    \\n\\t\"\n\n            \"pand       %%mm7, %%mm5    \\n\\t\"\n\n            \"por        %%mm1, %%mm0    \\n\\t\"\n\n            \"por        %%mm4, %%mm3    \\n\\t\"\n\n            \"por        %%mm2, %%mm0    \\n\\t\"\n\n            \"por        %%mm5, %%mm3    \\n\\t\"\n\n            \"psllq        $16, %%mm3    \\n\\t\"\n\n            \"por        %%mm3, %%mm0    \\n\\t\"\n\n            MOVNTQ\"     %%mm0, %0       \\n\\t\"\n\n            :\"=m\"(*d):\"m\"(*s),\"m\"(blue_16mask):\"memory\");\n\n        d += 4;\n\n        s += 12;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n    while (s < end) {\n\n        const int b = *s++;\n\n        const int g = *s++;\n\n        const int r = *s++;\n\n        *d++ = (b>>3) | ((g&0xFC)<<3) | ((r&0xF8)<<8);\n\n    }\n\n}\n", "idx": 22509}
{"project": "FFmpeg", "commit_id": "0491a2a07a44f6e5e6f34081835e402c07025fd2", "target": 0, "func": "static char *time_value_string(char *buf, int buf_size, int64_t val, const AVRational *time_base)\n\n{\n\n    if (val == AV_NOPTS_VALUE) {\n\n        snprintf(buf, buf_size, \"N/A\");\n\n    } else {\n\n        double d = val * av_q2d(*time_base);\n\n        value_string(buf, buf_size, (struct unit_value){.val.d=d, .unit=unit_second_str});\n\n    }\n\n\n\n    return buf;\n\n}\n", "idx": 22511}
{"project": "FFmpeg", "commit_id": "e1c48b7aaedc5deb6f22ced02dfe4f356bf3f421", "target": 0, "func": "static void png_save2(const char *filename, uint32_t *bitmap, int w, int h)\n\n{\n\n    int x, y, v;\n\n    FILE *f;\n\n    char fname[40], fname2[40];\n\n    char command[1024];\n\n\n\n    snprintf(fname, 40, \"%s.ppm\", filename);\n\n\n\n    f = fopen(fname, \"w\");\n\n    if (!f) {\n\n        perror(fname);\n\n        exit(1);\n\n    }\n\n    fprintf(f, \"P6\\n\"\n\n            \"%d %d\\n\"\n\n            \"%d\\n\",\n\n            w, h, 255);\n\n    for(y = 0; y < h; y++) {\n\n        for(x = 0; x < w; x++) {\n\n            v = bitmap[y * w + x];\n\n            putc((v >> 16) & 0xff, f);\n\n            putc((v >> 8) & 0xff, f);\n\n            putc((v >> 0) & 0xff, f);\n\n        }\n\n    }\n\n    fclose(f);\n\n\n\n\n\n    snprintf(fname2, 40, \"%s-a.pgm\", filename);\n\n\n\n    f = fopen(fname2, \"w\");\n\n    if (!f) {\n\n        perror(fname2);\n\n        exit(1);\n\n    }\n\n    fprintf(f, \"P5\\n\"\n\n            \"%d %d\\n\"\n\n            \"%d\\n\",\n\n            w, h, 255);\n\n    for(y = 0; y < h; y++) {\n\n        for(x = 0; x < w; x++) {\n\n            v = bitmap[y * w + x];\n\n            putc((v >> 24) & 0xff, f);\n\n        }\n\n    }\n\n    fclose(f);\n\n\n\n    snprintf(command, 1024, \"pnmtopng -alpha %s %s > %s.png 2> /dev/null\", fname2, fname, filename);\n\n    system(command);\n\n\n\n    snprintf(command, 1024, \"rm %s %s\", fname, fname2);\n\n    system(command);\n\n}\n", "idx": 22512}
{"project": "FFmpeg", "commit_id": "af1e8ffdad4ae0a6d73e8d26d5893739e3c7a389", "target": 0, "func": "static int spdif_write_packet(struct AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    IEC61937Context *ctx = s->priv_data;\n\n    int ret, padding;\n\n\n\n    ctx->out_buf = pkt->data;\n\n    ctx->out_bytes = pkt->size;\n\n    ctx->length_code = FFALIGN(pkt->size, 2) << 3;\n\n    ctx->use_preamble = 1;\n\n    ctx->extra_bswap = 0;\n\n\n\n    ret = ctx->header_info(s, pkt);\n\n    if (ret < 0)\n\n        return ret;\n\n    if (!ctx->pkt_offset)\n\n        return 0;\n\n\n\n    padding = (ctx->pkt_offset - ctx->use_preamble * BURST_HEADER_SIZE - ctx->out_bytes) & ~1;\n\n    if (padding < 0) {\n\n        av_log(s, AV_LOG_ERROR, \"bitrate is too high\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (ctx->use_preamble) {\n\n        put_le16(s->pb, SYNCWORD1);       //Pa\n\n        put_le16(s->pb, SYNCWORD2);       //Pb\n\n        put_le16(s->pb, ctx->data_type);  //Pc\n\n        put_le16(s->pb, ctx->length_code);//Pd\n\n    }\n\n\n\n    if (HAVE_BIGENDIAN ^ ctx->extra_bswap) {\n\n    put_buffer(s->pb, ctx->out_buf, ctx->out_bytes & ~1);\n\n    } else {\n\n    av_fast_malloc(&ctx->buffer, &ctx->buffer_size, ctx->out_bytes + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    if (!ctx->buffer)\n\n        return AVERROR(ENOMEM);\n\n    ff_spdif_bswap_buf16((uint16_t *)ctx->buffer, (uint16_t *)ctx->out_buf, ctx->out_bytes >> 1);\n\n    put_buffer(s->pb, ctx->buffer, ctx->out_bytes & ~1);\n\n    }\n\n\n\n    if (ctx->out_bytes & 1)\n\n        put_be16(s->pb, ctx->out_buf[ctx->out_bytes - 1]);\n\n\n\n    put_nbyte(s->pb, 0, padding);\n\n\n\n    av_log(s, AV_LOG_DEBUG, \"type=%x len=%i pkt_offset=%i\\n\",\n\n           ctx->data_type, ctx->out_bytes, ctx->pkt_offset);\n\n\n\n    put_flush_packet(s->pb);\n\n    return 0;\n\n}\n", "idx": 22513}
{"project": "FFmpeg", "commit_id": "1b1bb2c4efc126d74d44d8c421860c85f932ecb1", "target": 0, "func": "av_cold void ff_rl_init(RLTable *rl,\n\n                        uint8_t static_store[2][2 * MAX_RUN + MAX_LEVEL + 3])\n\n{\n\n    int8_t  max_level[MAX_RUN + 1], max_run[MAX_LEVEL + 1];\n\n    uint8_t index_run[MAX_RUN + 1];\n\n    int last, run, level, start, end, i;\n\n\n\n    /* If table is static, we can quit if rl->max_level[0] is not NULL */\n\n    if (static_store && rl->max_level[0])\n\n        return;\n\n\n\n    /* compute max_level[], max_run[] and index_run[] */\n\n    for (last = 0; last < 2; last++) {\n\n        if (last == 0) {\n\n            start = 0;\n\n            end = rl->last;\n\n        } else {\n\n            start = rl->last;\n\n            end = rl->n;\n\n        }\n\n\n\n        memset(max_level, 0, MAX_RUN + 1);\n\n        memset(max_run, 0, MAX_LEVEL + 1);\n\n        memset(index_run, rl->n, MAX_RUN + 1);\n\n        for (i = start; i < end; i++) {\n\n            run   = rl->table_run[i];\n\n            level = rl->table_level[i];\n\n            if (index_run[run] == rl->n)\n\n                index_run[run] = i;\n\n            if (level > max_level[run])\n\n                max_level[run] = level;\n\n            if (run > max_run[level])\n\n                max_run[level] = run;\n\n        }\n\n        if (static_store)\n\n            rl->max_level[last] = static_store[last];\n\n        else\n\n            rl->max_level[last] = av_malloc(MAX_RUN + 1);\n\n        memcpy(rl->max_level[last], max_level, MAX_RUN + 1);\n\n        if (static_store)\n\n            rl->max_run[last]   = static_store[last] + MAX_RUN + 1;\n\n        else\n\n            rl->max_run[last]   = av_malloc(MAX_LEVEL + 1);\n\n        memcpy(rl->max_run[last], max_run, MAX_LEVEL + 1);\n\n        if (static_store)\n\n            rl->index_run[last] = static_store[last] + MAX_RUN + MAX_LEVEL + 2;\n\n        else\n\n            rl->index_run[last] = av_malloc(MAX_RUN + 1);\n\n        memcpy(rl->index_run[last], index_run, MAX_RUN + 1);\n\n    }\n\n}\n", "idx": 22514}
{"project": "FFmpeg", "commit_id": "322428c851980396485d4c6bb4cfe79db43467f8", "target": 1, "func": "int av_opencl_init(AVDictionary *options, AVOpenCLExternalEnv *ext_opencl_env)\n\n{\n\n    int ret = 0;\n\n    AVDictionaryEntry *opt_build_entry;\n\n    AVDictionaryEntry *opt_platform_entry;\n\n    AVDictionaryEntry *opt_device_entry;\n\n    LOCK_OPENCL\n\n    if (!gpu_env.init_count) {\n\n        opt_platform_entry = av_dict_get(options, \"platform_idx\", NULL, 0);\n\n        opt_device_entry   = av_dict_get(options, \"device_idx\", NULL, 0);\n\n        /* initialize devices, context, command_queue */\n\n        gpu_env.usr_spec_dev_info.platform_idx = -1;\n\n        gpu_env.usr_spec_dev_info.dev_idx = -1;\n\n        if (opt_platform_entry) {\n\n            gpu_env.usr_spec_dev_info.platform_idx = strtol(opt_platform_entry->value, NULL, 10);\n\n        }\n\n        if (opt_device_entry) {\n\n            gpu_env.usr_spec_dev_info.dev_idx = strtol(opt_device_entry->value, NULL, 10);\n\n        }\n\n        ret = init_opencl_env(&gpu_env, ext_opencl_env);\n\n        if (ret < 0)\n\n            goto end;\n\n    }\n\n    /*initialize program, kernel_name, kernel_count*/\n\n    opt_build_entry = av_dict_get(options, \"build_options\", NULL, 0);\n\n    if (opt_build_entry)\n\n        ret = compile_kernel_file(&gpu_env, opt_build_entry->value);\n\n    else\n\n        ret = compile_kernel_file(&gpu_env, NULL);\n\n    if (ret < 0)\n\n        goto end;\n\n    av_assert1(gpu_env.kernel_code_count > 0);\n\n    gpu_env.init_count++;\n\n\n\nend:\n\n    UNLOCK_OPENCL\n\n    return ret;\n\n}\n", "idx": 22517}
{"project": "FFmpeg", "commit_id": "689a8674131c3852fc78eff1d7c044850d263e22", "target": 1, "func": "static int msf_read_header(AVFormatContext *s)\n\n{\n\n    unsigned codec, align, size;\n\n    AVStream *st;\n\n\n\n    avio_skip(s->pb, 4);\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    st->codec->codec_type  = AVMEDIA_TYPE_AUDIO;\n\n    codec                  = avio_rb32(s->pb);\n\n    st->codec->channels    = avio_rb32(s->pb);\n\n    if (st->codec->channels <= 0)\n\n        return AVERROR_INVALIDDATA;\n\n    size = avio_rb32(s->pb);\n\n    st->codec->sample_rate = avio_rb32(s->pb);\n\n    if (st->codec->sample_rate <= 0)\n\n        return AVERROR_INVALIDDATA;\n\n    align = avio_rb32(s->pb) ;\n\n    if (align > INT_MAX / st->codec->channels)\n\n        return AVERROR_INVALIDDATA;\n\n    st->codec->block_align = align;\n\n    switch (codec) {\n\n    case 0: st->codec->codec_id = AV_CODEC_ID_PCM_S16BE; break;\n\n    case 3: st->codec->block_align = 16 * st->codec->channels;\n\n            st->codec->codec_id = AV_CODEC_ID_ADPCM_PSX; break;\n\n    case 7: st->need_parsing = AVSTREAM_PARSE_FULL_RAW;\n\n            st->codec->codec_id = AV_CODEC_ID_MP3;       break;\n\n    default:\n\n            avpriv_request_sample(s, \"Codec %d\", codec);\n\n            return AVERROR_PATCHWELCOME;\n\n    }\n\n    st->duration = av_get_audio_frame_duration(st->codec, size);\n\n    avio_skip(s->pb, 0x40 - avio_tell(s->pb));\n\n    avpriv_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n\n\n    return 0;\n\n}\n", "idx": 22518}
{"project": "FFmpeg", "commit_id": "84a6bc23570c17ce91071e41431103f709c0d595", "target": 0, "func": "static int32_t tag_tree_size(uint16_t w, uint16_t h)\n\n{\n\n    uint32_t res = 0;\n\n    while (w > 1 || h > 1) {\n\n        res += w * h;\n\n        if (res + 1 >= INT32_MAX)\n\n            return -1;\n\n        w = (w + 1) >> 1;\n\n        h = (h + 1) >> 1;\n\n    }\n\n    return (int32_t)(res + 1);\n\n}\n", "idx": 22521}
{"project": "FFmpeg", "commit_id": "e95580e70a8c0102cc2a399dff25307211a9b7ca", "target": 0, "func": "static int mov_write_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    MOVContext *mov = s->priv_data;\n\n    ByteIOContext *pb = s->pb;\n\n    MOVTrack *trk = &mov->tracks[pkt->stream_index];\n\n    AVCodecContext *enc = trk->enc;\n\n    unsigned int samplesInChunk = 0;\n\n    int size= pkt->size;\n\n\n\n    if (url_is_streamed(s->pb)) return 0; /* Can't handle that */\n\n    if (!size) return 0; /* Discard 0 sized packets */\n\n\n\n    if (enc->codec_id == CODEC_ID_AMR_NB) {\n\n        /* We must find out how many AMR blocks there are in one packet */\n\n        static uint16_t packed_size[16] =\n\n            {13, 14, 16, 18, 20, 21, 27, 32, 6, 0, 0, 0, 0, 0, 0, 0};\n\n        int len = 0;\n\n\n\n        while (len < size && samplesInChunk < 100) {\n\n            len += packed_size[(pkt->data[len] >> 3) & 0x0F];\n\n            samplesInChunk++;\n\n        }\n\n        if(samplesInChunk > 1){\n\n            av_log(s, AV_LOG_ERROR, \"fatal error, input is not a single packet, implement a AVParser for it\\n\");\n\n            return -1;\n\n        }\n\n    } else if (trk->sampleSize)\n\n        samplesInChunk = size/trk->sampleSize;\n\n    else\n\n        samplesInChunk = 1;\n\n\n\n    /* copy extradata if it exists */\n\n    if (trk->vosLen == 0 && enc->extradata_size > 0) {\n\n        trk->vosLen = enc->extradata_size;\n\n        trk->vosData = av_malloc(trk->vosLen);\n\n        memcpy(trk->vosData, enc->extradata, trk->vosLen);\n\n    }\n\n\n\n    if (enc->codec_id == CODEC_ID_H264 && trk->vosLen > 0 && *(uint8_t *)trk->vosData != 1) {\n\n        /* from x264 or from bytestream h264 */\n\n        /* nal reformating needed */\n\n        int ret = ff_avc_parse_nal_units(pkt->data, &pkt->data, &pkt->size);\n\n        if (ret < 0)\n\n            return ret;\n\n        assert(pkt->size);\n\n        size = pkt->size;\n\n    } else if (enc->codec_id == CODEC_ID_DNXHD && !trk->vosLen) {\n\n        /* copy frame header to create needed atoms */\n\n        if (size < 640)\n\n            return -1;\n\n        trk->vosLen = 640;\n\n        trk->vosData = av_malloc(trk->vosLen);\n\n        memcpy(trk->vosData, pkt->data, 640);\n\n    }\n\n\n\n    if (!(trk->entry % MOV_INDEX_CLUSTER_SIZE)) {\n\n        trk->cluster = av_realloc(trk->cluster, (trk->entry + MOV_INDEX_CLUSTER_SIZE) * sizeof(*trk->cluster));\n\n        if (!trk->cluster)\n\n            return -1;\n\n    }\n\n\n\n    trk->cluster[trk->entry].pos = url_ftell(pb);\n\n    trk->cluster[trk->entry].samplesInChunk = samplesInChunk;\n\n    trk->cluster[trk->entry].size = size;\n\n    trk->cluster[trk->entry].entries = samplesInChunk;\n\n    trk->cluster[trk->entry].dts = pkt->dts;\n\n    trk->trackDuration = pkt->dts - trk->cluster[0].dts + pkt->duration;\n\n\n\n    if(enc->codec_type == CODEC_TYPE_VIDEO) {\n\n        if (pkt->dts != pkt->pts)\n\n            trk->hasBframes = 1;\n\n        trk->cluster[trk->entry].cts = pkt->pts - pkt->dts;\n\n        trk->cluster[trk->entry].key_frame = !!(pkt->flags & PKT_FLAG_KEY);\n\n        if(trk->cluster[trk->entry].key_frame)\n\n            trk->hasKeyframes++;\n\n    }\n\n    trk->entry++;\n\n    trk->sampleCount += samplesInChunk;\n\n    mov->mdat_size += size;\n\n\n\n    put_buffer(pb, pkt->data, size);\n\n\n\n    put_flush_packet(pb);\n\n    return 0;\n\n}\n", "idx": 22522}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(rgb24tobgr24)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n    unsigned i;\n\n#if COMPILE_TEMPLATE_MMX\n\n    x86_reg mmx_size= 23 - src_size;\n\n    __asm__ volatile (\n\n        \"test             %%\"REG_a\", %%\"REG_a\"          \\n\\t\"\n\n        \"jns                     2f                     \\n\\t\"\n\n        \"movq     \"MANGLE(mask24r)\", %%mm5              \\n\\t\"\n\n        \"movq     \"MANGLE(mask24g)\", %%mm6              \\n\\t\"\n\n        \"movq     \"MANGLE(mask24b)\", %%mm7              \\n\\t\"\n\n        \".p2align                 4                     \\n\\t\"\n\n        \"1:                                             \\n\\t\"\n\n        PREFETCH\" 32(%1, %%\"REG_a\")                     \\n\\t\"\n\n        \"movq       (%1, %%\"REG_a\"), %%mm0              \\n\\t\" // BGR BGR BG\n\n        \"movq       (%1, %%\"REG_a\"), %%mm1              \\n\\t\" // BGR BGR BG\n\n        \"movq      2(%1, %%\"REG_a\"), %%mm2              \\n\\t\" // R BGR BGR B\n\n        \"psllq                  $16, %%mm0              \\n\\t\" // 00 BGR BGR\n\n        \"pand                 %%mm5, %%mm0              \\n\\t\"\n\n        \"pand                 %%mm6, %%mm1              \\n\\t\"\n\n        \"pand                 %%mm7, %%mm2              \\n\\t\"\n\n        \"por                  %%mm0, %%mm1              \\n\\t\"\n\n        \"por                  %%mm2, %%mm1              \\n\\t\"\n\n        \"movq      6(%1, %%\"REG_a\"), %%mm0              \\n\\t\" // BGR BGR BG\n\n        MOVNTQ\"               %%mm1,   (%2, %%\"REG_a\")  \\n\\t\" // RGB RGB RG\n\n        \"movq      8(%1, %%\"REG_a\"), %%mm1              \\n\\t\" // R BGR BGR B\n\n        \"movq     10(%1, %%\"REG_a\"), %%mm2              \\n\\t\" // GR BGR BGR\n\n        \"pand                 %%mm7, %%mm0              \\n\\t\"\n\n        \"pand                 %%mm5, %%mm1              \\n\\t\"\n\n        \"pand                 %%mm6, %%mm2              \\n\\t\"\n\n        \"por                  %%mm0, %%mm1              \\n\\t\"\n\n        \"por                  %%mm2, %%mm1              \\n\\t\"\n\n        \"movq     14(%1, %%\"REG_a\"), %%mm0              \\n\\t\" // R BGR BGR B\n\n        MOVNTQ\"               %%mm1,  8(%2, %%\"REG_a\")  \\n\\t\" // B RGB RGB R\n\n        \"movq     16(%1, %%\"REG_a\"), %%mm1              \\n\\t\" // GR BGR BGR\n\n        \"movq     18(%1, %%\"REG_a\"), %%mm2              \\n\\t\" // BGR BGR BG\n\n        \"pand                 %%mm6, %%mm0              \\n\\t\"\n\n        \"pand                 %%mm7, %%mm1              \\n\\t\"\n\n        \"pand                 %%mm5, %%mm2              \\n\\t\"\n\n        \"por                  %%mm0, %%mm1              \\n\\t\"\n\n        \"por                  %%mm2, %%mm1              \\n\\t\"\n\n        MOVNTQ\"               %%mm1, 16(%2, %%\"REG_a\")  \\n\\t\"\n\n        \"add                    $24, %%\"REG_a\"          \\n\\t\"\n\n        \" js                     1b                     \\n\\t\"\n\n        \"2:                                             \\n\\t\"\n\n        : \"+a\" (mmx_size)\n\n        : \"r\" (src-mmx_size), \"r\"(dst-mmx_size)\n\n    );\n\n\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n\n\n    if (mmx_size==23) return; //finished, was multiple of 8\n\n\n\n    src+= src_size;\n\n    dst+= src_size;\n\n    src_size= 23-mmx_size;\n\n    src-= src_size;\n\n    dst-= src_size;\n\n#endif\n\n    for (i=0; i<src_size; i+=3) {\n\n        register uint8_t x;\n\n        x          = src[i + 2];\n\n        dst[i + 1] = src[i + 1];\n\n        dst[i + 2] = src[i + 0];\n\n        dst[i + 0] = x;\n\n    }\n\n}\n", "idx": 22523}
{"project": "FFmpeg", "commit_id": "486637af8ef29ec215e0e0b7ecd3b5470f0e04e5", "target": 0, "func": "static inline void mix_2f_2r_to_mono(AC3DecodeContext *ctx)\n\n{\n\n    int i;\n\n    float (*output)[256] = ctx->audio_block.block_output;\n\n\n\n    for (i = 0; i < 256; i++)\n\n        output[1][i] = (output[2][i] + output[3][i] + output[4][i]);\n\n    memset(output[2], 0, sizeof(output[2]));\n\n    memset(output[3], 0, sizeof(output[3]));\n\n    memset(output[4], 0, sizeof(output[4]));\n\n}\n", "idx": 22524}
{"project": "FFmpeg", "commit_id": "18b94669372d3d4b6c51e347587ea64acef9dbb8", "target": 1, "func": "static void ebml_free(EbmlSyntax *syntax, void *data)\n\n{\n\n    int i, j;\n\n    for (i = 0; syntax[i].id; i++) {\n\n        void *data_off = (char *) data + syntax[i].data_offset;\n\n        switch (syntax[i].type) {\n\n        case EBML_STR:\n\n        case EBML_UTF8:\n\n            av_freep(data_off);\n\n            break;\n\n        case EBML_BIN:\n\n            av_freep(&((EbmlBin *) data_off)->data);\n\n            break;\n\n        case EBML_LEVEL1:\n\n        case EBML_NEST:\n\n            if (syntax[i].list_elem_size) {\n\n                EbmlList *list = data_off;\n\n                char *ptr = list->elem;\n\n                for (j = 0; j < list->nb_elem;\n\n                     j++, ptr += syntax[i].list_elem_size)\n\n                    ebml_free(syntax[i].def.n, ptr);\n\n                av_freep(&list->elem);\n\n\n            } else\n\n                ebml_free(syntax[i].def.n, data_off);\n\n        default:\n\n            break;\n\n        }\n\n    }\n\n}", "idx": 22528}
{"project": "FFmpeg", "commit_id": "bd5c860fdbc33d19d2ff0f6d1f06de07c17560dd", "target": 1, "func": "int av_thread_message_queue_alloc(AVThreadMessageQueue **mq,\n\n                                  unsigned nelem,\n\n                                  unsigned elsize)\n\n{\n\n#if HAVE_THREADS\n\n    AVThreadMessageQueue *rmq;\n\n    int ret = 0;\n\n\n\n    if (nelem > INT_MAX / elsize)\n\n        return AVERROR(EINVAL);\n\n    if (!(rmq = av_mallocz(sizeof(*rmq))))\n\n        return AVERROR(ENOMEM);\n\n    if ((ret = pthread_mutex_init(&rmq->lock, NULL))) {\n\n        av_free(rmq);\n\n        return AVERROR(ret);\n\n    }\n\n    if ((ret = pthread_cond_init(&rmq->cond, NULL))) {\n\n        pthread_mutex_destroy(&rmq->lock);\n\n        av_free(rmq);\n\n        return AVERROR(ret);\n\n    }\n\n    if (!(rmq->fifo = av_fifo_alloc(elsize * nelem))) {\n\n        pthread_cond_destroy(&rmq->cond);\n\n        pthread_mutex_destroy(&rmq->lock);\n\n        av_free(rmq);\n\n        return AVERROR(ret);\n\n    }\n\n    rmq->elsize = elsize;\n\n    *mq = rmq;\n\n    return 0;\n\n#else\n\n    *mq = NULL;\n\n    return AVERROR(ENOSYS);\n\n#endif /* HAVE_THREADS */\n\n}\n", "idx": 22530}
{"project": "FFmpeg", "commit_id": "220b24c7c97dc033ceab1510549f66d0e7b52ef1", "target": 1, "func": "void ff_schro_queue_free(FFSchroQueue *queue, void (*free_func)(void *))\n\n{\n\n    while (queue->p_head)\n\n        free_func(ff_schro_queue_pop(queue));\n\n}\n", "idx": 22531}
{"project": "FFmpeg", "commit_id": "32baeafeee4f8446c2c3720b9223ad2166ca9d30", "target": 1, "func": "static void xvid_idct_put(uint8_t *dest, ptrdiff_t line_size, int16_t *block)\n\n{\n\n    ff_xvid_idct(block);\n\n    ff_put_pixels_clamped(block, dest, line_size);\n\n}\n", "idx": 22532}
{"project": "FFmpeg", "commit_id": "3c6607eb6f946ed3e108db3f0694cab7e5a5df7e", "target": 1, "func": "int attribute_align_arg avcodec_encode_video2(AVCodecContext *avctx,\n\n                                              AVPacket *avpkt,\n\n                                              const AVFrame *frame,\n\n                                              int *got_packet_ptr)\n\n{\n\n    int ret;\n\n    int user_packet = !!avpkt->data;\n\n\n\n    *got_packet_ptr = 0;\n\n\n\n    if (!(avctx->codec->capabilities & CODEC_CAP_DELAY) && !frame) {\n\n        av_free_packet(avpkt);\n\n        av_init_packet(avpkt);\n\n        avpkt->size     = 0;\n\n        return 0;\n\n    }\n\n\n\n    if (av_image_check_size(avctx->width, avctx->height, 0, avctx))\n\n        return AVERROR(EINVAL);\n\n\n\n    av_assert0(avctx->codec->encode2);\n\n\n\n    ret = avctx->codec->encode2(avctx, avpkt, frame, got_packet_ptr);\n\n    if (!ret) {\n\n        if (!*got_packet_ptr)\n\n            avpkt->size = 0;\n\n        else if (!(avctx->codec->capabilities & CODEC_CAP_DELAY))\n\n            avpkt->pts = avpkt->dts = frame->pts;\n\n\n\n        if (!user_packet && avpkt->data) {\n\n            uint8_t *new_data = av_realloc(avpkt->data, avpkt->size);\n\n            if (new_data)\n\n                avpkt->data = new_data;\n\n        }\n\n\n\n        avctx->frame_number++;\n\n    }\n\n\n\n    if (ret < 0 || !*got_packet_ptr)\n\n        av_free_packet(avpkt);\n\n\n\n    emms_c();\n\n    return ret;\n\n}\n", "idx": 22533}
{"project": "FFmpeg", "commit_id": "568e18b15e2ddf494fd8926707d34ca08c8edce5", "target": 1, "func": "static int get_str(ByteIOContext *bc, char *string, int maxlen){\n\n    int len= get_v(bc);\n\n    \n\n    if(len && maxlen)\n\n        get_buffer(bc, string, FFMIN(len, maxlen));\n\n    while(len > maxlen){\n\n        get_byte(bc);\n\n        len--;\n\n    }\n\n\n\n    if(maxlen)\n\n        string[FFMIN(len, maxlen-1)]= 0;\n\n    \n\n    if(maxlen == len)\n\n        return -1;\n\n    else\n\n        return 0;\n\n}\n", "idx": 22535}
{"project": "FFmpeg", "commit_id": "493aa30adf88baf5bc734072592a22db586f0cfb", "target": 1, "func": "static int dvbsub_decode(AVCodecContext *avctx,\n\n                         void *data, int *data_size,\n\n                         AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    DVBSubContext *ctx = avctx->priv_data;\n\n    AVSubtitle *sub = data;\n\n    const uint8_t *p, *p_end;\n\n    int segment_type;\n\n    int page_id;\n\n    int segment_length;\n\n\n\n#ifdef DEBUG_PACKET_CONTENTS\n\n    int i;\n\n\n\n    av_log(avctx, AV_LOG_INFO, \"DVB sub packet:\\n\");\n\n\n\n    for (i=0; i < buf_size; i++) {\n\n        av_log(avctx, AV_LOG_INFO, \"%02x \", buf[i]);\n\n        if (i % 16 == 15)\n\n            av_log(avctx, AV_LOG_INFO, \"\\n\");\n\n    }\n\n\n\n    if (i % 16)\n\n        av_log(avctx, AV_LOG_INFO, \"\\n\");\n\n\n\n#endif\n\n\n\n    if (buf_size <= 2 || *buf != 0x0f)\n\n        return -1;\n\n\n\n    p = buf;\n\n    p_end = buf + buf_size;\n\n\n\n    while (p < p_end && *p == 0x0f) {\n\n        p += 1;\n\n        segment_type = *p++;\n\n        page_id = AV_RB16(p);\n\n        p += 2;\n\n        segment_length = AV_RB16(p);\n\n        p += 2;\n\n\n\n        if (page_id == ctx->composition_id || page_id == ctx->ancillary_id ||\n\n            ctx->composition_id == -1 || ctx->ancillary_id == -1) {\n\n            switch (segment_type) {\n\n            case DVBSUB_PAGE_SEGMENT:\n\n                dvbsub_parse_page_segment(avctx, p, segment_length);\n\n                break;\n\n            case DVBSUB_REGION_SEGMENT:\n\n                dvbsub_parse_region_segment(avctx, p, segment_length);\n\n                break;\n\n            case DVBSUB_CLUT_SEGMENT:\n\n                dvbsub_parse_clut_segment(avctx, p, segment_length);\n\n                break;\n\n            case DVBSUB_OBJECT_SEGMENT:\n\n                dvbsub_parse_object_segment(avctx, p, segment_length);\n\n                break;\n\n            case DVBSUB_DISPLAYDEFINITION_SEGMENT:\n\n                dvbsub_parse_display_definition_segment(avctx, p, segment_length);\n\n            case DVBSUB_DISPLAY_SEGMENT:\n\n                *data_size = dvbsub_display_end_segment(avctx, p, segment_length, sub);\n\n                break;\n\n            default:\n\n                av_dlog(avctx, \"Subtitling segment type 0x%x, page id %d, length %d\\n\",\n\n                        segment_type, page_id, segment_length);\n\n                break;\n\n            }\n\n        }\n\n\n\n        p += segment_length;\n\n    }\n\n\n\n    return p - buf;\n\n}\n", "idx": 22536}
{"project": "FFmpeg", "commit_id": "09d5929f3721613fbb9ac9e74265c89c70df2ce0", "target": 1, "func": "static int tag_tree_decode(Jpeg2000DecoderContext *s, Jpeg2000TgtNode *node,\n                           int threshold)\n{\n    Jpeg2000TgtNode *stack[30];\n    int sp = -1, curval = 0;\n    while (node && !node->vis) {\n        stack[++sp] = node;\n        node        = node->parent;\n    }\n    if (node)\n        curval = node->val;\n    else\n        curval = stack[sp]->val;\n    while (curval < threshold && sp >= 0) {\n        if (curval < stack[sp]->val)\n            curval = stack[sp]->val;\n        while (curval < threshold) {\n            int ret;\n            if ((ret = get_bits(s, 1)) > 0) {\n                stack[sp]->vis++;\n                break;\n            } else if (!ret)\n                curval++;\n            else\n                return ret;\n        }\n        stack[sp]->val = curval;\n        sp--;\n    }\n    return curval;\n}", "idx": 22537}
{"project": "FFmpeg", "commit_id": "590863876d1478547640304a31c15809c3618090", "target": 1, "func": "static int output_configure(AACContext *ac,\n\n                            uint8_t layout_map[MAX_ELEM_ID * 4][3], int tags,\n\n                            enum OCStatus oc_type, int get_new_frame)\n\n{\n\n    AVCodecContext *avctx = ac->avctx;\n\n    int i, channels = 0, ret;\n\n    uint64_t layout = 0;\n\n    uint8_t id_map[TYPE_END][MAX_ELEM_ID] = {{ 0 }};\n\n    uint8_t type_counts[TYPE_END] = { 0 };\n\n\n\n    if (ac->oc[1].layout_map != layout_map) {\n\n        memcpy(ac->oc[1].layout_map, layout_map, tags * sizeof(layout_map[0]));\n\n        ac->oc[1].layout_map_tags = tags;\n\n\n    for (i = 0; i < tags; i++) {\n\n        int type =         layout_map[i][0];\n\n        int id =           layout_map[i][1];\n\n        id_map[type][id] = type_counts[type]++;\n\n\n\n\n\n\n    // Try to sniff a reasonable channel order, otherwise output the\n\n    // channels in the order the PCE declared them.\n\n    if (avctx->request_channel_layout != AV_CH_LAYOUT_NATIVE)\n\n        layout = sniff_channel_order(layout_map, tags);\n\n    for (i = 0; i < tags; i++) {\n\n        int type =     layout_map[i][0];\n\n        int id =       layout_map[i][1];\n\n        int iid =      id_map[type][id];\n\n        int position = layout_map[i][2];\n\n        // Allocate or free elements depending on if they are in the\n\n        // current program configuration.\n\n        ret = che_configure(ac, position, type, iid, &channels);\n\n        if (ret < 0)\n\n            return ret;\n\n        ac->tag_che_map[type][id] = ac->che[type][iid];\n\n\n    if (ac->oc[1].m4ac.ps == 1 && channels == 2) {\n\n        if (layout == AV_CH_FRONT_CENTER) {\n\n            layout = AV_CH_FRONT_LEFT|AV_CH_FRONT_RIGHT;\n\n        } else {\n\n            layout = 0;\n\n\n\n\n\n    if (layout) avctx->channel_layout = layout;\n\n                            ac->oc[1].channel_layout = layout;\n\n    avctx->channels       = ac->oc[1].channels       = channels;\n\n    ac->oc[1].status = oc_type;\n\n\n\n    if (get_new_frame) {\n\n        if ((ret = frame_configure_elements(ac->avctx)) < 0)\n\n            return ret;\n\n\n\n\n    return 0;\n", "idx": 22538}
{"project": "FFmpeg", "commit_id": "fd7af82c53ea8a2577ea8952d35fb158db594592", "target": 0, "func": "static int decompress_i(AVCodecContext *avctx, uint32_t *dst, int linesize)\n\n{\n\n    SCPRContext *s = avctx->priv_data;\n\n    GetByteContext *gb = &s->gb;\n\n    int cx = 0, cx1 = 0, k = 0, clr = 0;\n\n    int run, r, g, b, off, y = 0, x = 0, ret;\n\n    const int cxshift = s->cxshift;\n\n    unsigned lx, ly, ptype;\n\n\n\n    reinit_tables(s);\n\n    bytestream2_skip(gb, 2);\n\n    init_rangecoder(&s->rc, gb);\n\n\n\n    while (k < avctx->width + 1) {\n\n        ret = decode_unit(s, &s->pixel_model[0][cx + cx1], 400, &r);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        cx1 = (cx << 6) & 0xFC0;\n\n        cx = r >> cxshift;\n\n        ret = decode_unit(s, &s->pixel_model[1][cx + cx1], 400, &g);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        cx1 = (cx << 6) & 0xFC0;\n\n        cx = g >> cxshift;\n\n        ret = decode_unit(s, &s->pixel_model[2][cx + cx1], 400, &b);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        cx1 = (cx << 6) & 0xFC0;\n\n        cx = b >> cxshift;\n\n\n\n        ret = decode_value(s, s->run_model[0], 256, 400, &run);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        clr = (b << 16) + (g << 8) + r;\n\n        k += run;\n\n        while (run-- > 0) {\n\n            dst[y * linesize + x] = clr;\n\n            lx = x;\n\n            ly = y;\n\n            x++;\n\n            if (x >= avctx->width) {\n\n                x = 0;\n\n                y++;\n\n            }\n\n        }\n\n    }\n\n    off = -linesize - 1;\n\n    ptype = 0;\n\n\n\n    while (x < avctx->width && y < avctx->height) {\n\n        ret = decode_value(s, s->op_model[ptype], 6, 1000, &ptype);\n\n        if (ret < 0)\n\n            return ret;\n\n        if (ptype == 0) {\n\n            ret = decode_unit(s, &s->pixel_model[0][cx + cx1], 400, &r);\n\n            if (ret < 0)\n\n                return ret;\n\n\n\n            cx1 = (cx << 6) & 0xFC0;\n\n            cx = r >> cxshift;\n\n            ret = decode_unit(s, &s->pixel_model[1][cx + cx1], 400, &g);\n\n            if (ret < 0)\n\n                return ret;\n\n\n\n            cx1 = (cx << 6) & 0xFC0;\n\n            cx = g >> cxshift;\n\n            ret = decode_unit(s, &s->pixel_model[2][cx + cx1], 400, &b);\n\n            if (ret < 0)\n\n                return ret;\n\n\n\n            cx1 = (cx << 6) & 0xFC0;\n\n            cx = b >> cxshift;\n\n            clr = (b << 16) + (g << 8) + r;\n\n        }\n\n        if (ptype > 5)\n\n            return AVERROR_INVALIDDATA;\n\n        ret = decode_value(s, s->run_model[ptype], 256, 400, &run);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        switch (ptype) {\n\n        case 0:\n\n            while (run-- > 0) {\n\n                dst[y * linesize + x] = clr;\n\n                lx = x;\n\n                ly = y;\n\n                x++;\n\n                if (x >= avctx->width) {\n\n                    x = 0;\n\n                    y++;\n\n                }\n\n            }\n\n            break;\n\n        case 1:\n\n            while (run-- > 0) {\n\n                dst[y * linesize + x] = dst[ly * linesize + lx];\n\n                lx = x;\n\n                ly = y;\n\n                x++;\n\n                if (x >= avctx->width) {\n\n                    x = 0;\n\n                    y++;\n\n                }\n\n            }\n\n            clr = dst[ly * linesize + lx];\n\n            break;\n\n        case 2:\n\n            while (run-- > 0) {\n\n                clr = dst[y * linesize + x + off + 1];\n\n                dst[y * linesize + x] = clr;\n\n                lx = x;\n\n                ly = y;\n\n                x++;\n\n                if (x >= avctx->width) {\n\n                    x = 0;\n\n                    y++;\n\n                }\n\n            }\n\n            break;\n\n        case 4:\n\n            while (run-- > 0) {\n\n                uint8_t *odst = (uint8_t *)dst;\n\n                r = odst[(ly * linesize + lx) * 4] +\n\n                    odst[((y * linesize + x) + off) * 4 + 4] -\n\n                    odst[((y * linesize + x) + off) * 4];\n\n                g = odst[(ly * linesize + lx) * 4 + 1] +\n\n                    odst[((y * linesize + x) + off) * 4 + 5] -\n\n                    odst[((y * linesize + x) + off) * 4 + 1];\n\n                b = odst[(ly * linesize + lx) * 4 + 2] +\n\n                    odst[((y * linesize + x) + off) * 4 + 6] -\n\n                    odst[((y * linesize + x) + off) * 4 + 2];\n\n                clr = ((b & 0xFF) << 16) + ((g & 0xFF) << 8) + (r & 0xFF);\n\n                dst[y * linesize + x] = clr;\n\n                lx = x;\n\n                ly = y;\n\n                x++;\n\n                if (x >= avctx->width) {\n\n                    x = 0;\n\n                    y++;\n\n                }\n\n            }\n\n            break;\n\n        case 5:\n\n            while (run-- > 0) {\n\n                clr = dst[y * linesize + x + off];\n\n                dst[y * linesize + x] = clr;\n\n                lx = x;\n\n                ly = y;\n\n                x++;\n\n                if (x >= avctx->width) {\n\n                    x = 0;\n\n                    y++;\n\n                }\n\n            }\n\n            break;\n\n        }\n\n\n\n        if (avctx->bits_per_coded_sample == 16) {\n\n            cx1 = (clr & 0xFF00) >> 2;\n\n            cx = (clr & 0xFFFFFF) >> 16;\n\n        } else {\n\n            cx1 = (clr & 0xFC00) >> 4;\n\n            cx = (clr & 0xFFFFFF) >> 18;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22548}
{"project": "FFmpeg", "commit_id": "69e7336b8e16ee65226fc20381baf537f4b125e6", "target": 0, "func": "AVInputFormat *av_find_input_format(const char *short_name)\n\n{\n\n    AVInputFormat *fmt = NULL;\n\n    while ((fmt = av_iformat_next(fmt)))\n\n        if (match_format(short_name, fmt->name))\n\n            return fmt;\n\n    return NULL;\n\n}\n", "idx": 22559}
{"project": "FFmpeg", "commit_id": "1c088632e98af96f9cbe8129c5d7eb7274f8d4ed", "target": 0, "func": "static inline int parse_nal_units(AVCodecParserContext *s, const uint8_t *buf,\n\n                           int buf_size, AVCodecContext *avctx)\n\n{\n\n    HEVCParserContext *ctx = s->priv_data;\n\n    HEVCContext       *h   = &ctx->h;\n\n    GetBitContext      *gb;\n\n    SliceHeader        *sh = &h->sh;\n\n    HEVCParamSets *ps = &h->ps;\n\n    HEVCSEIContext *sei = &h->sei;\n\n    int is_global = buf == avctx->extradata;\n\n    int i, ret;\n\n\n\n    if (!h->HEVClc)\n\n        h->HEVClc = av_mallocz(sizeof(HEVCLocalContext));\n\n    if (!h->HEVClc)\n\n        return AVERROR(ENOMEM);\n\n\n\n    gb = &h->HEVClc->gb;\n\n\n\n    /* set some sane default values */\n\n    s->pict_type         = AV_PICTURE_TYPE_I;\n\n    s->key_frame         = 0;\n\n    s->picture_structure = AV_PICTURE_STRUCTURE_UNKNOWN;\n\n\n\n    h->avctx = avctx;\n\n\n\n    ff_hevc_reset_sei(sei);\n\n\n\n    ret = ff_h2645_packet_split(&ctx->pkt, buf, buf_size, avctx, 0, 0,\n\n                                AV_CODEC_ID_HEVC, 1);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    for (i = 0; i < ctx->pkt.nb_nals; i++) {\n\n        H2645NAL *nal = &ctx->pkt.nals[i];\n\n        int num = 0, den = 0;\n\n\n\n        h->nal_unit_type = nal->type;\n\n        h->temporal_id   = nal->temporal_id;\n\n        *gb = nal->gb;\n\n\n\n        switch (h->nal_unit_type) {\n\n        case HEVC_NAL_VPS:\n\n            ff_hevc_decode_nal_vps(gb, avctx, ps);\n\n            break;\n\n        case HEVC_NAL_SPS:\n\n            ff_hevc_decode_nal_sps(gb, avctx, ps, 1);\n\n            break;\n\n        case HEVC_NAL_PPS:\n\n            ff_hevc_decode_nal_pps(gb, avctx, ps);\n\n            break;\n\n        case HEVC_NAL_SEI_PREFIX:\n\n        case HEVC_NAL_SEI_SUFFIX:\n\n            ff_hevc_decode_nal_sei(gb, avctx, sei, ps, h->nal_unit_type);\n\n            break;\n\n        case HEVC_NAL_TRAIL_N:\n\n        case HEVC_NAL_TRAIL_R:\n\n        case HEVC_NAL_TSA_N:\n\n        case HEVC_NAL_TSA_R:\n\n        case HEVC_NAL_STSA_N:\n\n        case HEVC_NAL_STSA_R:\n\n        case HEVC_NAL_RADL_N:\n\n        case HEVC_NAL_RADL_R:\n\n        case HEVC_NAL_RASL_N:\n\n        case HEVC_NAL_RASL_R:\n\n        case HEVC_NAL_BLA_W_LP:\n\n        case HEVC_NAL_BLA_W_RADL:\n\n        case HEVC_NAL_BLA_N_LP:\n\n        case HEVC_NAL_IDR_W_RADL:\n\n        case HEVC_NAL_IDR_N_LP:\n\n        case HEVC_NAL_CRA_NUT:\n\n\n\n            if (is_global) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Invalid NAL unit: %d\\n\", h->nal_unit_type);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            sh->first_slice_in_pic_flag = get_bits1(gb);\n\n            s->picture_structure = h->sei.picture_timing.picture_struct;\n\n            s->field_order = h->sei.picture_timing.picture_struct;\n\n\n\n            if (IS_IRAP(h)) {\n\n                s->key_frame = 1;\n\n                sh->no_output_of_prior_pics_flag = get_bits1(gb);\n\n            }\n\n\n\n            sh->pps_id = get_ue_golomb(gb);\n\n            if (sh->pps_id >= HEVC_MAX_PPS_COUNT || !ps->pps_list[sh->pps_id]) {\n\n                av_log(avctx, AV_LOG_ERROR, \"PPS id out of range: %d\\n\", sh->pps_id);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            ps->pps = (HEVCPPS*)ps->pps_list[sh->pps_id]->data;\n\n\n\n            if (ps->pps->sps_id >= HEVC_MAX_SPS_COUNT || !ps->sps_list[ps->pps->sps_id]) {\n\n                av_log(avctx, AV_LOG_ERROR, \"SPS id out of range: %d\\n\", ps->pps->sps_id);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if (ps->sps != (HEVCSPS*)ps->sps_list[ps->pps->sps_id]->data) {\n\n                ps->sps = (HEVCSPS*)ps->sps_list[ps->pps->sps_id]->data;\n\n                ps->vps = (HEVCVPS*)ps->vps_list[ps->sps->vps_id]->data;\n\n            }\n\n\n\n            s->coded_width  = ps->sps->width;\n\n            s->coded_height = ps->sps->height;\n\n            s->width        = ps->sps->output_width;\n\n            s->height       = ps->sps->output_height;\n\n            s->format       = ps->sps->pix_fmt;\n\n            avctx->profile  = ps->sps->ptl.general_ptl.profile_idc;\n\n            avctx->level    = ps->sps->ptl.general_ptl.level_idc;\n\n\n\n            if (ps->vps->vps_timing_info_present_flag) {\n\n                num = ps->vps->vps_num_units_in_tick;\n\n                den = ps->vps->vps_time_scale;\n\n            } else if (ps->sps->vui.vui_timing_info_present_flag) {\n\n                num = ps->sps->vui.vui_num_units_in_tick;\n\n                den = ps->sps->vui.vui_time_scale;\n\n            }\n\n\n\n            if (num != 0 && den != 0)\n\n                av_reduce(&avctx->framerate.den, &avctx->framerate.num,\n\n                          num, den, 1 << 30);\n\n\n\n            if (!sh->first_slice_in_pic_flag) {\n\n                int slice_address_length;\n\n\n\n                if (ps->pps->dependent_slice_segments_enabled_flag)\n\n                    sh->dependent_slice_segment_flag = get_bits1(gb);\n\n                else\n\n                    sh->dependent_slice_segment_flag = 0;\n\n\n\n                slice_address_length = av_ceil_log2_c(ps->sps->ctb_width *\n\n                                                      ps->sps->ctb_height);\n\n                sh->slice_segment_addr = get_bitsz(gb, slice_address_length);\n\n                if (sh->slice_segment_addr >= ps->sps->ctb_width * ps->sps->ctb_height) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"Invalid slice segment address: %u.\\n\",\n\n                           sh->slice_segment_addr);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n            } else\n\n                sh->dependent_slice_segment_flag = 0;\n\n\n\n            if (sh->dependent_slice_segment_flag)\n\n                break;\n\n\n\n            for (i = 0; i < ps->pps->num_extra_slice_header_bits; i++)\n\n                skip_bits(gb, 1); // slice_reserved_undetermined_flag[]\n\n\n\n            sh->slice_type = get_ue_golomb(gb);\n\n            if (!(sh->slice_type == HEVC_SLICE_I || sh->slice_type == HEVC_SLICE_P ||\n\n                  sh->slice_type == HEVC_SLICE_B)) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Unknown slice type: %d.\\n\",\n\n                       sh->slice_type);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            s->pict_type = sh->slice_type == HEVC_SLICE_B ? AV_PICTURE_TYPE_B :\n\n                           sh->slice_type == HEVC_SLICE_P ? AV_PICTURE_TYPE_P :\n\n                                                       AV_PICTURE_TYPE_I;\n\n\n\n            if (ps->pps->output_flag_present_flag)\n\n                sh->pic_output_flag = get_bits1(gb);\n\n\n\n            if (ps->sps->separate_colour_plane_flag)\n\n                sh->colour_plane_id = get_bits(gb, 2);\n\n\n\n            if (!IS_IDR(h)) {\n\n                sh->pic_order_cnt_lsb = get_bits(gb, ps->sps->log2_max_poc_lsb);\n\n                s->output_picture_number = h->poc = ff_hevc_compute_poc(h->ps.sps, h->pocTid0, sh->pic_order_cnt_lsb, h->nal_unit_type);\n\n            } else\n\n                s->output_picture_number = h->poc = 0;\n\n\n\n            if (h->temporal_id == 0 &&\n\n                h->nal_unit_type != HEVC_NAL_TRAIL_N &&\n\n                h->nal_unit_type != HEVC_NAL_TSA_N &&\n\n                h->nal_unit_type != HEVC_NAL_STSA_N &&\n\n                h->nal_unit_type != HEVC_NAL_RADL_N &&\n\n                h->nal_unit_type != HEVC_NAL_RASL_N &&\n\n                h->nal_unit_type != HEVC_NAL_RADL_R &&\n\n                h->nal_unit_type != HEVC_NAL_RASL_R)\n\n                h->pocTid0 = h->poc;\n\n\n\n            return 0; /* no need to evaluate the rest */\n\n        }\n\n    }\n\n    /* didn't find a picture! */\n\n    if (!is_global)\n\n        av_log(h->avctx, AV_LOG_ERROR, \"missing picture in access unit\\n\");\n\n    return -1;\n\n}\n", "idx": 22563}
{"project": "FFmpeg", "commit_id": "e549933a270dd2cfc36f2cf9bb6b29acf3dc6d08", "target": 0, "func": "void ff_put_h264_qpel4_mc22_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_mid_4w_msa(src - (2 * stride) - 2, stride, dst, stride, 4);\n\n}\n", "idx": 22564}
{"project": "FFmpeg", "commit_id": "625b582d5a9196c582e7702b542b3e0face30ccf", "target": 0, "func": "static int read_sbr_single_channel_element(AACContext *ac,\n\n                                            SpectralBandReplication *sbr,\n\n                                            GetBitContext *gb)\n\n{\n\n    int ret;\n\n\n\n    if (get_bits1(gb)) // bs_data_extra\n\n        skip_bits(gb, 4); // bs_reserved\n\n\n\n    if (read_sbr_grid(ac, sbr, gb, &sbr->data[0]))\n\n        return -1;\n\n    read_sbr_dtdf(sbr, gb, &sbr->data[0]);\n\n    read_sbr_invf(sbr, gb, &sbr->data[0]);\n\n    read_sbr_envelope(sbr, gb, &sbr->data[0], 0);\n\n    if((ret = read_sbr_noise(ac, sbr, gb, &sbr->data[0], 0)) < 0)\n\n        return ret;\n\n\n\n    if ((sbr->data[0].bs_add_harmonic_flag = get_bits1(gb)))\n\n        get_bits1_vector(gb, sbr->data[0].bs_add_harmonic, sbr->n[1]);\n\n\n\n    return 0;\n\n}\n", "idx": 22565}
{"project": "FFmpeg", "commit_id": "61bd0ed781b56eea1e8e851aab34a2ee3b59fbac", "target": 0, "func": "int ff_h2645_packet_split(H2645Packet *pkt, const uint8_t *buf, int length,\n\n                          void *logctx, int is_nalff, int nal_length_size,\n\n                          enum AVCodecID codec_id)\n\n{\n\n    int consumed, ret = 0;\n\n    const uint8_t *next_avc = buf + (is_nalff ? 0 : length);\n\n\n\n    pkt->nb_nals = 0;\n\n    while (length >= 4) {\n\n        H2645NAL *nal;\n\n        int extract_length = 0;\n\n        int skip_trailing_zeros = 1;\n\n\n\n        /*\n\n         * Only parse an AVC1 length field if one is expected at the current\n\n         * buffer position. There are unfortunately streams with multiple\n\n         * NAL units covered by the length field. Those NAL units are delimited\n\n         * by Annex B start code prefixes. ff_h2645_extract_rbsp() detects it\n\n         * correctly and consumes only the first NAL unit. The additional NAL\n\n         * units are handled here in the Annex B parsing code.\n\n         */\n\n        if (buf == next_avc) {\n\n            int i;\n\n            for (i = 0; i < nal_length_size; i++)\n\n                extract_length = (extract_length << 8) | buf[i];\n\n\n\n            if (extract_length > length) {\n\n                av_log(logctx, AV_LOG_ERROR, \"Invalid NAL unit size.\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            buf     += nal_length_size;\n\n            length  -= nal_length_size;\n\n            // keep track of the next AVC1 length field\n\n            next_avc = buf + extract_length;\n\n        } else {\n\n            /*\n\n             * expected to return immediately except for streams with mixed\n\n             * NAL unit coding\n\n             */\n\n            int buf_index = find_next_start_code(buf, next_avc);\n\n\n\n            buf    += buf_index;\n\n            length -= buf_index;\n\n\n\n            /*\n\n             * break if an AVC1 length field is expected at the current buffer\n\n             * position\n\n             */\n\n            if (buf == next_avc)\n\n                continue;\n\n\n\n            if (length > 0) {\n\n                extract_length = length;\n\n            } else if (pkt->nb_nals == 0) {\n\n                av_log(logctx, AV_LOG_ERROR, \"No NAL unit found\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            } else {\n\n                break;\n\n            }\n\n        }\n\n\n\n        if (pkt->nals_allocated < pkt->nb_nals + 1) {\n\n            int new_size = pkt->nals_allocated + 1;\n\n            H2645NAL *tmp = av_realloc_array(pkt->nals, new_size, sizeof(*tmp));\n\n            if (!tmp)\n\n                return AVERROR(ENOMEM);\n\n\n\n            pkt->nals = tmp;\n\n            memset(pkt->nals + pkt->nals_allocated, 0,\n\n                   (new_size - pkt->nals_allocated) * sizeof(*tmp));\n\n            pkt->nals_allocated = new_size;\n\n        }\n\n        nal = &pkt->nals[pkt->nb_nals++];\n\n\n\n        consumed = ff_h2645_extract_rbsp(buf, extract_length, nal);\n\n        if (consumed < 0)\n\n            return consumed;\n\n\n\n        /* see commit 3566042a0 */\n\n        if (consumed < length - 3 &&\n\n            buf[consumed]     == 0x00 && buf[consumed + 1] == 0x00 &&\n\n            buf[consumed + 2] == 0x01 && buf[consumed + 3] == 0xE0)\n\n            skip_trailing_zeros = 0;\n\n\n\n        nal->size_bits = get_bit_length(nal, skip_trailing_zeros);\n\n\n\n        ret = init_get_bits(&nal->gb, nal->data, nal->size_bits);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        if (codec_id == AV_CODEC_ID_HEVC)\n\n            ret = hevc_parse_nal_header(nal, logctx);\n\n        else\n\n            ret = h264_parse_nal_header(nal, logctx);\n\n        if (ret <= 0) {\n\n            if (ret < 0) {\n\n                av_log(logctx, AV_LOG_ERROR, \"Invalid NAL unit %d, skipping.\\n\",\n\n                       nal->type);\n\n            }\n\n            pkt->nb_nals--;\n\n        }\n\n\n\n        buf    += consumed;\n\n        length -= consumed;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22566}
{"project": "FFmpeg", "commit_id": "3c895fc098f7637f6d5ec3a9d6766e724a8b9e41", "target": 0, "func": "static int output_packet(AVInputStream *ist, int ist_index,\n\n                         AVOutputStream **ost_table, int nb_ostreams,\n\n                         const AVPacket *pkt)\n\n{\n\n    AVFormatContext *os;\n\n    AVOutputStream *ost;\n\n    uint8_t *ptr;\n\n    int len, ret, i;\n\n    uint8_t *data_buf;\n\n    int data_size, got_picture;\n\n    AVFrame picture;\n\n    short samples[AVCODEC_MAX_AUDIO_FRAME_SIZE / 2];\n\n    void *buffer_to_free;\n\n    \n\n    if (pkt && pkt->pts != AV_NOPTS_VALUE) { //FIXME seems redundant, as libavformat does this too\n\n        ist->next_pts = ist->pts = pkt->dts;\n\n    } else {\n\n        ist->pts = ist->next_pts;\n\n    }\n\n    \n\n    if (pkt == NULL) {\n\n        /* EOF handling */\n\n        ptr = NULL;\n\n        len = 0;\n\n        goto handle_eof;\n\n    }\n\n\n\n    len = pkt->size;\n\n    ptr = pkt->data;\n\n    while (len > 0) {\n\n    handle_eof:\n\n        /* decode the packet if needed */\n\n        data_buf = NULL; /* fail safe */\n\n        data_size = 0;\n\n        if (ist->decoding_needed) {\n\n            switch(ist->st->codec.codec_type) {\n\n            case CODEC_TYPE_AUDIO:\n\n                    /* XXX: could avoid copy if PCM 16 bits with same\n\n                       endianness as CPU */\n\n                ret = avcodec_decode_audio(&ist->st->codec, samples, &data_size,\n\n                                           ptr, len);\n\n                if (ret < 0)\n\n                    goto fail_decode;\n\n                ptr += ret;\n\n                len -= ret;\n\n                /* Some bug in mpeg audio decoder gives */\n\n                /* data_size < 0, it seems they are overflows */\n\n                if (data_size <= 0) {\n\n                    /* no audio frame */\n\n                    continue;\n\n                }\n\n                data_buf = (uint8_t *)samples;\n\n                ist->next_pts += ((int64_t)AV_TIME_BASE/2 * data_size) / \n\n                    (ist->st->codec.sample_rate * ist->st->codec.channels);\n\n                break;\n\n            case CODEC_TYPE_VIDEO:\n\n                    data_size = (ist->st->codec.width * ist->st->codec.height * 3) / 2;\n\n                    /* XXX: allocate picture correctly */\n\n                    avcodec_get_frame_defaults(&picture);\n\n\n\n                    ret = avcodec_decode_video(&ist->st->codec, \n\n                                               &picture, &got_picture, ptr, len);\n\n                    ist->st->quality= picture.quality;\n\n                    if (ret < 0) \n\n                        goto fail_decode;\n\n                    if (!got_picture) {\n\n                        /* no picture yet */\n\n                        goto discard_packet;\n\n                    }\n\n                    if (ist->st->codec.frame_rate_base != 0) {\n\n                        ist->next_pts += ((int64_t)AV_TIME_BASE * \n\n                                          ist->st->codec.frame_rate_base) /\n\n                            ist->st->codec.frame_rate;\n\n                    }\n\n                    len = 0;\n\n                    break;\n\n                default:\n\n                    goto fail_decode;\n\n                }\n\n            } else {\n\n                data_buf = ptr;\n\n                data_size = len;\n\n                ret = len;\n\n                len = 0;\n\n            }\n\n\n\n            buffer_to_free = NULL;\n\n            if (ist->st->codec.codec_type == CODEC_TYPE_VIDEO) {\n\n                pre_process_video_frame(ist, (AVPicture *)&picture, \n\n                                        &buffer_to_free);\n\n            }\n\n\n\n            /* frame rate emulation */\n\n            if (ist->st->codec.rate_emu) {\n\n                int64_t pts = av_rescale((int64_t) ist->frame * ist->st->codec.frame_rate_base, 1000000, ist->st->codec.frame_rate);\n\n                int64_t now = av_gettime() - ist->start;\n\n                if (pts > now)\n\n                    usleep(pts - now);\n\n\n\n                ist->frame++;\n\n            }\n\n\n\n#if 0\n\n            /* mpeg PTS deordering : if it is a P or I frame, the PTS\n\n               is the one of the next displayed one */\n\n            /* XXX: add mpeg4 too ? */\n\n            if (ist->st->codec.codec_id == CODEC_ID_MPEG1VIDEO) {\n\n                if (ist->st->codec.pict_type != B_TYPE) {\n\n                    int64_t tmp;\n\n                    tmp = ist->last_ip_pts;\n\n                    ist->last_ip_pts  = ist->frac_pts.val;\n\n                    ist->frac_pts.val = tmp;\n\n                }\n\n            }\n\n#endif\n\n            /* if output time reached then transcode raw format, \n\n\t       encode packets and output them */\n\n            if (start_time == 0 || ist->pts >= start_time)\n\n                for(i=0;i<nb_ostreams;i++) {\n\n                    int frame_size;\n\n\n\n                    ost = ost_table[i];\n\n                    if (ost->source_index == ist_index) {\n\n                        os = output_files[ost->file_index];\n\n\n\n#if 0\n\n                        printf(\"%d: got pts=%0.3f %0.3f\\n\", i, \n\n                               (double)pkt->pts / AV_TIME_BASE, \n\n                               ((double)ist->pts / AV_TIME_BASE) - \n\n                               ((double)ost->st->pts.val * ost->time_base.num / ost->time_base.den));\n\n#endif\n\n                        /* set the input output pts pairs */\n\n                        ost->sync_ipts = (double)ist->pts / AV_TIME_BASE;\n\n\n\n                        if (ost->encoding_needed) {\n\n                            switch(ost->st->codec.codec_type) {\n\n                            case CODEC_TYPE_AUDIO:\n\n                                do_audio_out(os, ost, ist, data_buf, data_size);\n\n                                break;\n\n                            case CODEC_TYPE_VIDEO:\n\n                                /* find an audio stream for synchro */\n\n                                {\n\n                                    int i;\n\n                                    AVOutputStream *audio_sync, *ost1;\n\n                                    audio_sync = NULL;\n\n                                    for(i=0;i<nb_ostreams;i++) {\n\n                                        ost1 = ost_table[i];\n\n                                        if (ost1->file_index == ost->file_index &&\n\n                                            ost1->st->codec.codec_type == CODEC_TYPE_AUDIO) {\n\n                                            audio_sync = ost1;\n\n                                            break;\n\n                                        }\n\n                                    }\n\n\n\n                                    do_video_out(os, ost, ist, &picture, &frame_size, audio_sync);\n\n                                    video_size += frame_size;\n\n                                    if (do_vstats && frame_size)\n\n                                        do_video_stats(os, ost, frame_size);\n\n                                }\n\n                                break;\n\n                            default:\n\n                                av_abort();\n\n                            }\n\n                        } else {\n\n                            AVFrame avframe; //FIXME/XXX remove this\n\n                            AVPacket opkt;\n\n                            av_init_packet(&opkt);\n\n\n\n                            /* no reencoding needed : output the packet directly */\n\n                            /* force the input stream PTS */\n\n                        \n\n                            avcodec_get_frame_defaults(&avframe);\n\n                            ost->st->codec.coded_frame= &avframe;\n\n                            avframe.key_frame = pkt->flags & PKT_FLAG_KEY; \n\n\n\n                            if(ost->st->codec.codec_type == CODEC_TYPE_AUDIO)\n\n                                audio_size += data_size;\n\n                            else if (ost->st->codec.codec_type == CODEC_TYPE_VIDEO)\n\n                                video_size += data_size;\n\n\n\n                            opkt.stream_index= ost->index;\n\n                            opkt.data= data_buf;\n\n                            opkt.size= data_size;\n\n                            opkt.pts= ist->pts; //FIXME dts vs. pts\n\n                            opkt.flags= pkt->flags;\n\n                            \n\n                            av_write_frame(os, &opkt);\n\n                            ost->st->codec.frame_number++;\n\n                            ost->frame_number++;\n\n                        }\n\n                    }\n\n                }\n\n            av_free(buffer_to_free);\n\n        }\n\n discard_packet:\n\n    return 0;\n\n fail_decode:\n\n    return -1;\n\n}\n", "idx": 22567}
{"project": "FFmpeg", "commit_id": "08a747afb98c11da48b89339c2f1c5fdc56ced7e", "target": 0, "func": "static void count_frame_bits(AC3EncodeContext *s)\n\n{\n\n    AC3EncOptions *opt = &s->options;\n\n    int blk, ch;\n\n    int frame_bits = 0;\n\n\n\n    /* header */\n\n    if (s->eac3) {\n\n        /* coupling */\n\n        if (s->channel_mode > AC3_CHMODE_MONO) {\n\n            frame_bits++;\n\n            for (blk = 1; blk < AC3_MAX_BLOCKS; blk++) {\n\n                AC3Block *block = &s->blocks[blk];\n\n                frame_bits++;\n\n                if (block->new_cpl_strategy)\n\n                    frame_bits++;\n\n            }\n\n        }\n\n        /* coupling exponent strategy */\n\n        for (blk = 0; blk < AC3_MAX_BLOCKS; blk++)\n\n            frame_bits += 2 * s->blocks[blk].cpl_in_use;\n\n    } else {\n\n        if (opt->audio_production_info)\n\n            frame_bits += 7;\n\n        if (s->bitstream_id == 6) {\n\n            if (opt->extended_bsi_1)\n\n                frame_bits += 14;\n\n            if (opt->extended_bsi_2)\n\n                frame_bits += 14;\n\n        }\n\n    }\n\n\n\n    /* audio blocks */\n\n    for (blk = 0; blk < AC3_MAX_BLOCKS; blk++) {\n\n        AC3Block *block = &s->blocks[blk];\n\n\n\n        /* coupling strategy */\n\n        if (!s->eac3)\n\n            frame_bits++;\n\n        if (block->new_cpl_strategy) {\n\n            if (!s->eac3)\n\n                frame_bits++;\n\n            if (block->cpl_in_use) {\n\n                if (s->eac3)\n\n                    frame_bits++;\n\n                if (!s->eac3 || s->channel_mode != AC3_CHMODE_STEREO)\n\n                    frame_bits += s->fbw_channels;\n\n                if (s->channel_mode == AC3_CHMODE_STEREO)\n\n                    frame_bits++;\n\n                frame_bits += 4 + 4;\n\n                if (s->eac3)\n\n                    frame_bits++;\n\n                else\n\n                    frame_bits += s->num_cpl_subbands - 1;\n\n            }\n\n        }\n\n\n\n        /* coupling coordinates */\n\n        if (block->cpl_in_use) {\n\n            for (ch = 1; ch <= s->fbw_channels; ch++) {\n\n                if (block->channel_in_cpl[ch]) {\n\n                    if (!s->eac3 || block->new_cpl_coords != 2)\n\n                        frame_bits++;\n\n                    if (block->new_cpl_coords) {\n\n                        frame_bits += 2;\n\n                        frame_bits += (4 + 4) * s->num_cpl_bands;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n\n\n        /* stereo rematrixing */\n\n        if (s->channel_mode == AC3_CHMODE_STEREO) {\n\n            if (!s->eac3 || blk > 0)\n\n                frame_bits++;\n\n            if (s->blocks[blk].new_rematrixing_strategy)\n\n                frame_bits += block->num_rematrixing_bands;\n\n        }\n\n\n\n        /* bandwidth codes & gain range */\n\n        for (ch = 1; ch <= s->fbw_channels; ch++) {\n\n            if (s->exp_strategy[ch][blk] != EXP_REUSE) {\n\n                if (!block->channel_in_cpl[ch])\n\n                    frame_bits += 6;\n\n                frame_bits += 2;\n\n            }\n\n        }\n\n\n\n        /* coupling exponent strategy */\n\n        if (!s->eac3 && block->cpl_in_use)\n\n            frame_bits += 2;\n\n\n\n        /* snr offsets and fast gain codes */\n\n        if (!s->eac3) {\n\n            frame_bits++;\n\n            if (block->new_snr_offsets)\n\n                frame_bits += 6 + (s->channels + block->cpl_in_use) * (4 + 3);\n\n        }\n\n\n\n        /* coupling leak info */\n\n        if (block->cpl_in_use) {\n\n            if (!s->eac3 || block->new_cpl_leak != 2)\n\n                frame_bits++;\n\n            if (block->new_cpl_leak)\n\n                frame_bits += 3 + 3;\n\n        }\n\n    }\n\n\n\n    s->frame_bits = s->frame_bits_fixed + frame_bits;\n\n}\n", "idx": 22568}
{"project": "FFmpeg", "commit_id": "29ba091136a5e04574f7bfc1b17536c923958f6f", "target": 0, "func": "const char *swscale_configuration(void)\n\n{\n\n    return FFMPEG_CONFIGURATION;\n\n}\n", "idx": 22573}
{"project": "FFmpeg", "commit_id": "2192f89368d837a4d960a1cabf5475fdeff697e7", "target": 1, "func": "static void load_module(const char *filename)\n\n{\n\n    void *dll;\n\n    void (*init_func)(void);\n\n    dll = dlopen(filename, RTLD_NOW);\n\n    if (!dll) {\n\n        fprintf(stderr, \"Could not load module '%s' - %s\\n\",\n\n                filename, dlerror());\n\n\n    }\n\n\n\n    init_func = dlsym(dll, \"ffserver_module_init\");\n\n    if (!init_func) {\n\n        fprintf(stderr,\n\n                \"%s: init function 'ffserver_module_init()' not found\\n\",\n\n                filename);\n\n        dlclose(dll);\n\n\n    }\n\n\n\n    init_func();\n\n}", "idx": 22576}
{"project": "FFmpeg", "commit_id": "0a41f47dc17b49acaff6fe469a6ab358986cc449", "target": 0, "func": "DVDemuxContext* avpriv_dv_init_demux(AVFormatContext *s)\n\n{\n\n    DVDemuxContext *c;\n\n\n\n    c = av_mallocz(sizeof(DVDemuxContext));\n\n    if (!c)\n\n        return NULL;\n\n\n\n    c->vst = avformat_new_stream(s, NULL);\n\n    if (!c->vst) {\n\n        av_free(c);\n\n        return NULL;\n\n    }\n\n\n\n    c->sys  = NULL;\n\n    c->fctx = s;\n\n    memset(c->ast, 0, sizeof(c->ast));\n\n    c->ach    = 0;\n\n    c->frames = 0;\n\n    c->abytes = 0;\n\n\n\n    c->vst->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n    c->vst->codec->codec_id   = CODEC_ID_DVVIDEO;\n\n    c->vst->codec->bit_rate   = 25000000;\n\n    c->vst->start_time        = 0;\n\n\n\n    return c;\n\n}\n", "idx": 22577}
{"project": "FFmpeg", "commit_id": "15cea3695daf3f6363794594982e3816ddc8d90b", "target": 1, "func": "int ff_read_riff_info(AVFormatContext *s, int64_t size)\n\n{\n\n    int64_t start, end, cur;\n\n    AVIOContext *pb = s->pb;\n\n\n\n    start = avio_tell(pb);\n\n    end = start + size;\n\n\n\n    while ((cur = avio_tell(pb)) >= 0 && cur <= end - 8 /* = tag + size */) {\n\n        uint32_t chunk_code;\n\n        int64_t chunk_size;\n\n        char key[5] = {0};\n\n        char *value;\n\n\n\n        chunk_code = avio_rl32(pb);\n\n        chunk_size = avio_rl32(pb);\n\n        if (chunk_size > end || end - chunk_size < cur || chunk_size == UINT_MAX) {\n\n            av_log(s, AV_LOG_ERROR, \"too big INFO subchunk\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        chunk_size += (chunk_size & 1);\n\n\n\n        value = av_malloc(chunk_size + 1);\n\n        if (!value) {\n\n            av_log(s, AV_LOG_ERROR, \"out of memory, unable to read INFO tag\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n\n\n        AV_WL32(key, chunk_code);\n\n\n\n        if (avio_read(pb, value, chunk_size) != chunk_size) {\n\n            av_freep(key);\n\n            av_freep(value);\n\n            av_log(s, AV_LOG_ERROR, \"premature end of file while reading INFO tag\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        value[chunk_size] = 0;\n\n\n\n        av_dict_set(&s->metadata, key, value, AV_DICT_DONT_STRDUP_VAL);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22578}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int h261_decode_frame(AVCodecContext *avctx, void *data,\n\n                             int *got_frame, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    H261Context *h     = avctx->priv_data;\n\n    MpegEncContext *s  = &h->s;\n\n    int ret;\n\n    AVFrame *pict = data;\n\n\n\n    av_dlog(avctx, \"*****frame %d size=%d\\n\", avctx->frame_number, buf_size);\n\n    av_dlog(avctx, \"bytes=%x %x %x %x\\n\", buf[0], buf[1], buf[2], buf[3]);\n\n    s->flags  = avctx->flags;\n\n    s->flags2 = avctx->flags2;\n\n\n\n    h->gob_start_code_skipped = 0;\n\n\n\nretry:\n\n    init_get_bits(&s->gb, buf, buf_size * 8);\n\n\n\n    if (!s->context_initialized)\n\n        // we need the IDCT permutaton for reading a custom matrix\n\n        if (ff_MPV_common_init(s) < 0)\n\n            return -1;\n\n\n\n    ret = h261_decode_picture_header(h);\n\n\n\n    /* skip if the header was thrashed */\n\n    if (ret < 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"header damaged\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (s->width != avctx->coded_width || s->height != avctx->coded_height) {\n\n        ParseContext pc = s->parse_context; // FIXME move this demuxing hack to libavformat\n\n        s->parse_context.buffer = 0;\n\n        ff_MPV_common_end(s);\n\n        s->parse_context = pc;\n\n    }\n\n    if (!s->context_initialized) {\n\n        ret = ff_set_dimensions(avctx, s->width, s->height);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        goto retry;\n\n    }\n\n\n\n    // for skipping the frame\n\n    s->current_picture.f.pict_type = s->pict_type;\n\n    s->current_picture.f.key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n\n\n    if ((avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type == AV_PICTURE_TYPE_B) ||\n\n        (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type != AV_PICTURE_TYPE_I) ||\n\n         avctx->skip_frame >= AVDISCARD_ALL)\n\n        return get_consumed_bytes(s, buf_size);\n\n\n\n    if (ff_MPV_frame_start(s, avctx) < 0)\n\n        return -1;\n\n\n\n    ff_mpeg_er_frame_start(s);\n\n\n\n    /* decode each macroblock */\n\n    s->mb_x = 0;\n\n    s->mb_y = 0;\n\n\n\n    while (h->gob_number < (s->mb_height == 18 ? 12 : 5)) {\n\n        if (h261_resync(h) < 0)\n\n            break;\n\n        h261_decode_gob(h);\n\n    }\n\n    ff_MPV_frame_end(s);\n\n\n\n    assert(s->current_picture.f.pict_type == s->current_picture_ptr->f.pict_type);\n\n    assert(s->current_picture.f.pict_type == s->pict_type);\n\n\n\n    if ((ret = av_frame_ref(pict, &s->current_picture_ptr->f)) < 0)\n\n        return ret;\n\n    ff_print_debug_info(s, s->current_picture_ptr);\n\n\n\n    *got_frame = 1;\n\n\n\n    return get_consumed_bytes(s, buf_size);\n\n}\n", "idx": 22579}
{"project": "FFmpeg", "commit_id": "62b1e3b1031e901105d78e831120de8e4c3e0013", "target": 1, "func": "static int aasc_decode_frame(AVCodecContext *avctx,\n                              void *data, int *got_frame,\n                              AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size       = avpkt->size;\n    AascContext *s     = avctx->priv_data;\n    int compr, i, stride, ret;\n    if ((ret = ff_reget_buffer(avctx, s->frame)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n        return ret;\n    }\n    compr     = AV_RL32(buf);\n    buf      += 4;\n    buf_size -= 4;\n    switch (compr) {\n    case 0:\n        stride = (avctx->width * 3 + 3) & ~3;\n        if (buf_size < stride * avctx->height)\n        for (i = avctx->height - 1; i >= 0; i--) {\n            memcpy(s->frame->data[0] + i * s->frame->linesize[0], buf, avctx->width * 3);\n            buf += stride;\n        }\n        break;\n    case 1:\n        bytestream2_init(&s->gb, buf, buf_size);\n        ff_msrle_decode(avctx, (AVPicture*)s->frame, 8, &s->gb);\n        break;\n    default:\n        av_log(avctx, AV_LOG_ERROR, \"Unknown compression type %d\\n\", compr);\n    }\n    *got_frame = 1;\n    if ((ret = av_frame_ref(data, s->frame)) < 0)\n        return ret;\n    /* report that the buffer was completely consumed */\n    return buf_size;\n}", "idx": 22585}
{"project": "FFmpeg", "commit_id": "ac4b32df71bd932838043a4838b86d11e169707f", "target": 1, "func": "static av_always_inline void filter_common(uint8_t *p, ptrdiff_t stride,\n\n                                           int is4tap)\n\n{\n\n    LOAD_PIXELS\n\n    int a, f1, f2;\n\n    const uint8_t *cm = ff_crop_tab + MAX_NEG_CROP;\n\n\n\n    a = 3 * (q0 - p0);\n\n\n\n    if (is4tap)\n\n        a += clip_int8(p1 - q1);\n\n\n\n    a = clip_int8(a);\n\n\n\n    // We deviate from the spec here with c(a+3) >> 3\n\n    // since that's what libvpx does.\n\n    f1 = FFMIN(a + 4, 127) >> 3;\n\n    f2 = FFMIN(a + 3, 127) >> 3;\n\n\n\n    // Despite what the spec says, we do need to clamp here to\n\n    // be bitexact with libvpx.\n\n    p[-1 * stride] = cm[p0 + f2];\n\n    p[ 0 * stride] = cm[q0 - f1];\n\n\n\n    // only used for _inner on blocks without high edge variance\n\n    if (!is4tap) {\n\n        a = (f1 + 1) >> 1;\n\n        p[-2 * stride] = cm[p1 + a];\n\n        p[ 1 * stride] = cm[q1 - a];\n\n    }\n\n}\n", "idx": 22586}
{"project": "FFmpeg", "commit_id": "c2c4cee866926cb95b2b1a4b28fff9caa4177c7e", "target": 0, "func": "static int mkv_write_track(AVFormatContext *s, MatroskaMuxContext *mkv,\n\n                           int i, AVIOContext *pb, int default_stream_exists)\n\n{\n\n    AVStream *st = s->streams[i];\n\n    AVCodecContext *codec = st->codec;\n\n    ebml_master subinfo, track;\n\n    int native_id = 0;\n\n    int qt_id = 0;\n\n    int bit_depth = av_get_bits_per_sample(codec->codec_id);\n\n    int sample_rate = codec->sample_rate;\n\n    int output_sample_rate = 0;\n\n    int display_width_div = 1;\n\n    int display_height_div = 1;\n\n    int j, ret;\n\n    AVDictionaryEntry *tag;\n\n\n\n    // ms precision is the de-facto standard timescale for mkv files\n\n    avpriv_set_pts_info(st, 64, 1, 1000);\n\n\n\n    if (codec->codec_type == AVMEDIA_TYPE_ATTACHMENT) {\n\n        mkv->have_attachments = 1;\n\n        return 0;\n\n    }\n\n\n\n    if (!bit_depth && codec->codec_id != AV_CODEC_ID_ADPCM_G726)\n\n        bit_depth = av_get_bytes_per_sample(codec->sample_fmt) << 3;\n\n    if (!bit_depth)\n\n        bit_depth = codec->bits_per_coded_sample;\n\n\n\n    if (codec->codec_id == AV_CODEC_ID_AAC)\n\n        get_aac_sample_rates(s, codec, &sample_rate, &output_sample_rate);\n\n\n\n    track = start_ebml_master(pb, MATROSKA_ID_TRACKENTRY, 0);\n\n    put_ebml_uint (pb, MATROSKA_ID_TRACKNUMBER,\n\n                   mkv->is_dash ? mkv->dash_track_number : i + 1);\n\n    put_ebml_uint (pb, MATROSKA_ID_TRACKUID,\n\n                   mkv->is_dash ? mkv->dash_track_number : i + 1);\n\n    put_ebml_uint (pb, MATROSKA_ID_TRACKFLAGLACING , 0);    // no lacing (yet)\n\n\n\n    if ((tag = av_dict_get(st->metadata, \"title\", NULL, 0)))\n\n        put_ebml_string(pb, MATROSKA_ID_TRACKNAME, tag->value);\n\n    tag = av_dict_get(st->metadata, \"language\", NULL, 0);\n\n    if (mkv->mode != MODE_WEBM || codec->codec_id != AV_CODEC_ID_WEBVTT) {\n\n        put_ebml_string(pb, MATROSKA_ID_TRACKLANGUAGE, tag && tag->value ? tag->value:\"und\");\n\n    } else if (tag && tag->value) {\n\n        put_ebml_string(pb, MATROSKA_ID_TRACKLANGUAGE, tag->value);\n\n    }\n\n\n\n    // The default value for TRACKFLAGDEFAULT is 1, so add element\n\n    // if we need to clear it.\n\n    if (default_stream_exists && !(st->disposition & AV_DISPOSITION_DEFAULT))\n\n        put_ebml_uint(pb, MATROSKA_ID_TRACKFLAGDEFAULT, !!(st->disposition & AV_DISPOSITION_DEFAULT));\n\n\n\n    if (st->disposition & AV_DISPOSITION_FORCED)\n\n        put_ebml_uint(pb, MATROSKA_ID_TRACKFLAGFORCED, 1);\n\n\n\n    if (mkv->mode == MODE_WEBM && codec->codec_id == AV_CODEC_ID_WEBVTT) {\n\n        const char *codec_id;\n\n        if (st->disposition & AV_DISPOSITION_CAPTIONS) {\n\n            codec_id = \"D_WEBVTT/CAPTIONS\";\n\n            native_id = MATROSKA_TRACK_TYPE_SUBTITLE;\n\n        } else if (st->disposition & AV_DISPOSITION_DESCRIPTIONS) {\n\n            codec_id = \"D_WEBVTT/DESCRIPTIONS\";\n\n            native_id = MATROSKA_TRACK_TYPE_METADATA;\n\n        } else if (st->disposition & AV_DISPOSITION_METADATA) {\n\n            codec_id = \"D_WEBVTT/METADATA\";\n\n            native_id = MATROSKA_TRACK_TYPE_METADATA;\n\n        } else {\n\n            codec_id = \"D_WEBVTT/SUBTITLES\";\n\n            native_id = MATROSKA_TRACK_TYPE_SUBTITLE;\n\n        }\n\n        put_ebml_string(pb, MATROSKA_ID_CODECID, codec_id);\n\n    } else {\n\n        // look for a codec ID string specific to mkv to use,\n\n        // if none are found, use AVI codes\n\n        for (j = 0; ff_mkv_codec_tags[j].id != AV_CODEC_ID_NONE; j++) {\n\n            if (ff_mkv_codec_tags[j].id == codec->codec_id) {\n\n                put_ebml_string(pb, MATROSKA_ID_CODECID, ff_mkv_codec_tags[j].str);\n\n                native_id = 1;\n\n                break;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (codec->codec_type == AVMEDIA_TYPE_AUDIO && codec->delay && codec->codec_id == AV_CODEC_ID_OPUS) {\n\n//         mkv->tracks[i].ts_offset = av_rescale_q(codec->delay,\n\n//                                                 (AVRational){ 1, codec->sample_rate },\n\n//                                                 st->time_base);\n\n\n\n        put_ebml_uint(pb, MATROSKA_ID_CODECDELAY,\n\n                      av_rescale_q(codec->delay, (AVRational){ 1, codec->sample_rate },\n\n                                   (AVRational){ 1, 1000000000 }));\n\n    }\n\n    if (codec->codec_id == AV_CODEC_ID_OPUS) {\n\n        put_ebml_uint(pb, MATROSKA_ID_SEEKPREROLL, OPUS_SEEK_PREROLL);\n\n    }\n\n\n\n    if (mkv->mode == MODE_WEBM && !(codec->codec_id == AV_CODEC_ID_VP8 ||\n\n                                    codec->codec_id == AV_CODEC_ID_VP9 ||\n\n                                    codec->codec_id == AV_CODEC_ID_OPUS ||\n\n                                    codec->codec_id == AV_CODEC_ID_VORBIS ||\n\n                                    codec->codec_id == AV_CODEC_ID_WEBVTT)) {\n\n        av_log(s, AV_LOG_ERROR,\n\n               \"Only VP8 or VP9 video and Vorbis or Opus audio and WebVTT subtitles are supported for WebM.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    switch (codec->codec_type) {\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        put_ebml_uint(pb, MATROSKA_ID_TRACKTYPE, MATROSKA_TRACK_TYPE_VIDEO);\n\n\n\n        if(   st->avg_frame_rate.num > 0 && st->avg_frame_rate.den > 0\n\n           && 1.0/av_q2d(st->avg_frame_rate) > av_q2d(codec->time_base))\n\n            put_ebml_uint(pb, MATROSKA_ID_TRACKDEFAULTDURATION, 1E9 / av_q2d(st->avg_frame_rate));\n\n        else\n\n            put_ebml_uint(pb, MATROSKA_ID_TRACKDEFAULTDURATION, av_q2d(codec->time_base)*1E9);\n\n\n\n        if (!native_id &&\n\n            ff_codec_get_tag(ff_codec_movvideo_tags, codec->codec_id) &&\n\n            (!ff_codec_get_tag(ff_codec_bmp_tags,   codec->codec_id) ||\n\n             codec->codec_id == AV_CODEC_ID_SVQ1 ||\n\n             codec->codec_id == AV_CODEC_ID_SVQ3 ||\n\n             codec->codec_id == AV_CODEC_ID_CINEPAK))\n\n            qt_id = 1;\n\n\n\n        if (qt_id)\n\n            put_ebml_string(pb, MATROSKA_ID_CODECID, \"V_QUICKTIME\");\n\n        else if (!native_id) {\n\n            // if there is no mkv-specific codec ID, use VFW mode\n\n            put_ebml_string(pb, MATROSKA_ID_CODECID, \"V_MS/VFW/FOURCC\");\n\n            mkv->tracks[i].write_dts = 1;\n\n        }\n\n\n\n        subinfo = start_ebml_master(pb, MATROSKA_ID_TRACKVIDEO, 0);\n\n        // XXX: interlace flag?\n\n        put_ebml_uint (pb, MATROSKA_ID_VIDEOPIXELWIDTH , codec->width);\n\n        put_ebml_uint (pb, MATROSKA_ID_VIDEOPIXELHEIGHT, codec->height);\n\n\n\n        if ((tag = av_dict_get(st->metadata, \"stereo_mode\", NULL, 0)) ||\n\n            (tag = av_dict_get( s->metadata, \"stereo_mode\", NULL, 0))) {\n\n            int st_mode = MATROSKA_VIDEO_STEREO_MODE_COUNT;\n\n\n\n            for (j=0; j<MATROSKA_VIDEO_STEREO_MODE_COUNT; j++)\n\n                if (!strcmp(tag->value, ff_matroska_video_stereo_mode[j])){\n\n                    st_mode = j;\n\n                    break;\n\n                }\n\n\n\n            if (mkv_write_stereo_mode(s, pb, st_mode, mkv->mode) < 0)\n\n                return AVERROR(EINVAL);\n\n\n\n            switch (st_mode) {\n\n            case 1:\n\n            case 8:\n\n            case 9:\n\n            case 11:\n\n                display_width_div = 2;\n\n                break;\n\n            case 2:\n\n            case 3:\n\n            case 6:\n\n            case 7:\n\n                display_height_div = 2;\n\n                break;\n\n            }\n\n        }\n\n\n\n        if ((tag = av_dict_get(st->metadata, \"alpha_mode\", NULL, 0)) ||\n\n            (tag = av_dict_get( s->metadata, \"alpha_mode\", NULL, 0)) ||\n\n            (codec->pix_fmt == AV_PIX_FMT_YUVA420P)) {\n\n            put_ebml_uint(pb, MATROSKA_ID_VIDEOALPHAMODE, 1);\n\n        }\n\n\n\n        if (st->sample_aspect_ratio.num) {\n\n            int64_t d_width = av_rescale(codec->width, st->sample_aspect_ratio.num, st->sample_aspect_ratio.den);\n\n            if (d_width > INT_MAX) {\n\n                av_log(s, AV_LOG_ERROR, \"Overflow in display width\\n\");\n\n                return AVERROR(EINVAL);\n\n            }\n\n            put_ebml_uint(pb, MATROSKA_ID_VIDEODISPLAYWIDTH , d_width / display_width_div);\n\n            put_ebml_uint(pb, MATROSKA_ID_VIDEODISPLAYHEIGHT, codec->height / display_height_div);\n\n        } else if (display_width_div != 1 || display_height_div != 1) {\n\n            put_ebml_uint(pb, MATROSKA_ID_VIDEODISPLAYWIDTH , codec->width / display_width_div);\n\n            put_ebml_uint(pb, MATROSKA_ID_VIDEODISPLAYHEIGHT, codec->height / display_height_div);\n\n        }\n\n\n\n        if (codec->codec_id == AV_CODEC_ID_RAWVIDEO) {\n\n            uint32_t color_space = av_le2ne32(codec->codec_tag);\n\n            put_ebml_binary(pb, MATROSKA_ID_VIDEOCOLORSPACE, &color_space, sizeof(color_space));\n\n        }\n\n        end_ebml_master(pb, subinfo);\n\n        break;\n\n\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        put_ebml_uint(pb, MATROSKA_ID_TRACKTYPE, MATROSKA_TRACK_TYPE_AUDIO);\n\n\n\n        if (!native_id)\n\n            // no mkv-specific ID, use ACM mode\n\n            put_ebml_string(pb, MATROSKA_ID_CODECID, \"A_MS/ACM\");\n\n\n\n        subinfo = start_ebml_master(pb, MATROSKA_ID_TRACKAUDIO, 0);\n\n        put_ebml_uint  (pb, MATROSKA_ID_AUDIOCHANNELS    , codec->channels);\n\n        put_ebml_float (pb, MATROSKA_ID_AUDIOSAMPLINGFREQ, sample_rate);\n\n        if (output_sample_rate)\n\n            put_ebml_float(pb, MATROSKA_ID_AUDIOOUTSAMPLINGFREQ, output_sample_rate);\n\n        if (bit_depth)\n\n            put_ebml_uint(pb, MATROSKA_ID_AUDIOBITDEPTH, bit_depth);\n\n        end_ebml_master(pb, subinfo);\n\n        break;\n\n\n\n    case AVMEDIA_TYPE_SUBTITLE:\n\n        if (!native_id) {\n\n            av_log(s, AV_LOG_ERROR, \"Subtitle codec %d is not supported.\\n\", codec->codec_id);\n\n            return AVERROR(ENOSYS);\n\n        }\n\n\n\n        if (mkv->mode != MODE_WEBM || codec->codec_id != AV_CODEC_ID_WEBVTT)\n\n            native_id = MATROSKA_TRACK_TYPE_SUBTITLE;\n\n\n\n        put_ebml_uint(pb, MATROSKA_ID_TRACKTYPE, native_id);\n\n        break;\n\n    default:\n\n        av_log(s, AV_LOG_ERROR, \"Only audio, video, and subtitles are supported for Matroska.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (mkv->mode != MODE_WEBM || codec->codec_id != AV_CODEC_ID_WEBVTT) {\n\n        ret = mkv_write_codecprivate(s, pb, codec, native_id, qt_id);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    end_ebml_master(pb, track);\n\n\n\n    return 0;\n\n}\n", "idx": 22589}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int ffm_probe(AVProbeData *p)\n\n{\n\n    if (p->buf_size >= 4 &&\n\n        p->buf[0] == 'F' && p->buf[1] == 'F' && p->buf[2] == 'M' &&\n\n        p->buf[3] == '1')\n\n        return AVPROBE_SCORE_MAX + 1;\n\n    return 0;\n\n}\n", "idx": 22590}
{"project": "FFmpeg", "commit_id": "a2f7314ba231cde459c4f33f1a7602ae9d9d2d28", "target": 1, "func": "static inline void RENAME(duplicate)(uint8_t src[], int stride)\n\n{\n\n#if TEMPLATE_PP_MMX\n\n    __asm__ volatile(\n\n        \"movq (%0), %%mm0               \\n\\t\"\n\n        \"add %1, %0                     \\n\\t\"\n\n        \"movq %%mm0, (%0)               \\n\\t\"\n\n        \"movq %%mm0, (%0, %1)           \\n\\t\"\n\n        \"movq %%mm0, (%0, %1, 2)        \\n\\t\"\n\n        : \"+r\" (src)\n\n        : \"r\" ((x86_reg)-stride)\n\n    );\n\n#else\n\n    int i;\n\n    uint8_t *p=src;\n\n    for(i=0; i<3; i++){\n\n        p-= stride;\n\n        memcpy(p, src, 8);\n\n    }\n\n#endif\n\n}\n", "idx": 22591}
{"project": "FFmpeg", "commit_id": "a5e5959d52860678d028df07ad1351a11aaf47f7", "target": 1, "func": "static void compute_pkt_fields(AVFormatContext *s, AVStream *st,\n\n                               AVCodecParserContext *pc, AVPacket *pkt,\n\n                               int64_t next_dts, int64_t next_pts)\n\n{\n\n    int num, den, presentation_delayed, delay, i;\n\n    int64_t offset;\n\n    AVRational duration;\n\n    int onein_oneout = st->codec->codec_id != AV_CODEC_ID_H264 &&\n\n                       st->codec->codec_id != AV_CODEC_ID_HEVC;\n\n\n\n    if (s->flags & AVFMT_FLAG_NOFILLIN)\n\n        return;\n\n\n\n    if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO && pkt->dts != AV_NOPTS_VALUE) {\n\n        if (pkt->dts == pkt->pts && st->last_dts_for_order_check != AV_NOPTS_VALUE) {\n\n            if (st->last_dts_for_order_check <= pkt->dts) {\n\n                st->dts_ordered++;\n\n            } else {\n\n                av_log(s, st->dts_misordered ? AV_LOG_DEBUG : AV_LOG_WARNING,\n\n                       \"DTS %\"PRIi64\" < %\"PRIi64\" out of order\\n\",\n\n                       pkt->dts,\n\n                       st->last_dts_for_order_check);\n\n                st->dts_misordered++;\n\n            }\n\n            if (st->dts_ordered + st->dts_misordered > 250) {\n\n                st->dts_ordered    >>= 1;\n\n                st->dts_misordered >>= 1;\n\n            }\n\n        }\n\n\n\n        st->last_dts_for_order_check = pkt->dts;\n\n        if (st->dts_ordered < 8*st->dts_misordered && pkt->dts == pkt->pts)\n\n            pkt->dts = AV_NOPTS_VALUE;\n\n    }\n\n\n\n    if ((s->flags & AVFMT_FLAG_IGNDTS) && pkt->pts != AV_NOPTS_VALUE)\n\n        pkt->dts = AV_NOPTS_VALUE;\n\n\n\n    if (pc && pc->pict_type == AV_PICTURE_TYPE_B\n\n        && !st->codec->has_b_frames)\n\n        //FIXME Set low_delay = 0 when has_b_frames = 1\n\n        st->codec->has_b_frames = 1;\n\n\n\n    /* do we have a video B-frame ? */\n\n    delay = st->codec->has_b_frames;\n\n    presentation_delayed = 0;\n\n\n\n    /* XXX: need has_b_frame, but cannot get it if the codec is\n\n     *  not initialized */\n\n    if (delay &&\n\n        pc && pc->pict_type != AV_PICTURE_TYPE_B)\n\n        presentation_delayed = 1;\n\n\n\n    if (pkt->pts != AV_NOPTS_VALUE && pkt->dts != AV_NOPTS_VALUE &&\n\n        st->pts_wrap_bits < 63 &&\n\n        pkt->dts - (1LL << (st->pts_wrap_bits - 1)) > pkt->pts) {\n\n        if (is_relative(st->cur_dts) || pkt->dts - (1LL<<(st->pts_wrap_bits - 1)) > st->cur_dts) {\n\n            pkt->dts -= 1LL << st->pts_wrap_bits;\n\n        } else\n\n            pkt->pts += 1LL << st->pts_wrap_bits;\n\n    }\n\n\n\n    /* Some MPEG-2 in MPEG-PS lack dts (issue #171 / input_file.mpg).\n\n     * We take the conservative approach and discard both.\n\n     * Note: If this is misbehaving for an H.264 file, then possibly\n\n     * presentation_delayed is not set correctly. */\n\n    if (delay == 1 && pkt->dts == pkt->pts &&\n\n        pkt->dts != AV_NOPTS_VALUE && presentation_delayed) {\n\n        av_log(s, AV_LOG_DEBUG, \"invalid dts/pts combination %\"PRIi64\"\\n\", pkt->dts);\n\n        if (    strcmp(s->iformat->name, \"mov,mp4,m4a,3gp,3g2,mj2\")\n\n             && strcmp(s->iformat->name, \"flv\")) // otherwise we discard correct timestamps for vc1-wmapro.ism\n\n            pkt->dts = AV_NOPTS_VALUE;\n\n    }\n\n\n\n    duration = av_mul_q((AVRational) {pkt->duration, 1}, st->time_base);\n\n    if (pkt->duration == 0) {\n\n        ff_compute_frame_duration(s, &num, &den, st, pc, pkt);\n\n        if (den && num) {\n\n            duration = (AVRational) {num, den};\n\n            pkt->duration = av_rescale_rnd(1,\n\n                                           num * (int64_t) st->time_base.den,\n\n                                           den * (int64_t) st->time_base.num,\n\n                                           AV_ROUND_DOWN);\n\n        }\n\n    }\n\n\n\n    if (pkt->duration != 0 && (s->packet_buffer || s->parse_queue))\n\n        update_initial_durations(s, st, pkt->stream_index, pkt->duration);\n\n\n\n    /* Correct timestamps with byte offset if demuxers only have timestamps\n\n     * on packet boundaries */\n\n    if (pc && st->need_parsing == AVSTREAM_PARSE_TIMESTAMPS && pkt->size) {\n\n        /* this will estimate bitrate based on this frame's duration and size */\n\n        offset = av_rescale(pc->offset, pkt->duration, pkt->size);\n\n        if (pkt->pts != AV_NOPTS_VALUE)\n\n            pkt->pts += offset;\n\n        if (pkt->dts != AV_NOPTS_VALUE)\n\n            pkt->dts += offset;\n\n    }\n\n\n\n    /* This may be redundant, but it should not hurt. */\n\n    if (pkt->dts != AV_NOPTS_VALUE &&\n\n        pkt->pts != AV_NOPTS_VALUE &&\n\n        pkt->pts > pkt->dts)\n\n        presentation_delayed = 1;\n\n\n\n    av_dlog(NULL,\n\n            \"IN delayed:%d pts:%s, dts:%s cur_dts:%s st:%d pc:%p duration:%d delay:%d onein_oneout:%d\\n\",\n\n            presentation_delayed, av_ts2str(pkt->pts), av_ts2str(pkt->dts), av_ts2str(st->cur_dts),\n\n            pkt->stream_index, pc, pkt->duration, delay, onein_oneout);\n\n    /* Interpolate PTS and DTS if they are not present. We skip H264\n\n     * currently because delay and has_b_frames are not reliably set. */\n\n    if ((delay == 0 || (delay == 1 && pc)) &&\n\n        onein_oneout) {\n\n        if (presentation_delayed) {\n\n            /* DTS = decompression timestamp */\n\n            /* PTS = presentation timestamp */\n\n            if (pkt->dts == AV_NOPTS_VALUE)\n\n                pkt->dts = st->last_IP_pts;\n\n            update_initial_timestamps(s, pkt->stream_index, pkt->dts, pkt->pts, pkt);\n\n            if (pkt->dts == AV_NOPTS_VALUE)\n\n                pkt->dts = st->cur_dts;\n\n\n\n            /* This is tricky: the dts must be incremented by the duration\n\n             * of the frame we are displaying, i.e. the last I- or P-frame. */\n\n            if (st->last_IP_duration == 0)\n\n                st->last_IP_duration = pkt->duration;\n\n            if (pkt->dts != AV_NOPTS_VALUE)\n\n                st->cur_dts = pkt->dts + st->last_IP_duration;\n\n            if (pkt->dts != AV_NOPTS_VALUE &&\n\n                pkt->pts == AV_NOPTS_VALUE &&\n\n                st->last_IP_duration > 0 &&\n\n                (st->cur_dts - next_dts) <= 1 &&\n\n                next_dts != next_pts &&\n\n                next_pts != AV_NOPTS_VALUE)\n\n                pkt->pts = next_dts;\n\n\n\n            st->last_IP_duration = pkt->duration;\n\n            st->last_IP_pts      = pkt->pts;\n\n            /* Cannot compute PTS if not present (we can compute it only\n\n             * by knowing the future. */\n\n        } else if (pkt->pts != AV_NOPTS_VALUE ||\n\n                   pkt->dts != AV_NOPTS_VALUE ||\n\n                   pkt->duration                ) {\n\n\n\n            /* presentation is not delayed : PTS and DTS are the same */\n\n            if (pkt->pts == AV_NOPTS_VALUE)\n\n                pkt->pts = pkt->dts;\n\n            update_initial_timestamps(s, pkt->stream_index, pkt->pts,\n\n                                      pkt->pts, pkt);\n\n            if (pkt->pts == AV_NOPTS_VALUE)\n\n                pkt->pts = st->cur_dts;\n\n            pkt->dts = pkt->pts;\n\n            if (pkt->pts != AV_NOPTS_VALUE)\n\n                st->cur_dts = av_add_stable(st->time_base, pkt->pts, duration, 1);\n\n        }\n\n    }\n\n\n\n    if (pkt->pts != AV_NOPTS_VALUE && delay <= MAX_REORDER_DELAY && has_decode_delay_been_guessed(st)) {\n\n        st->pts_buffer[0] = pkt->pts;\n\n        for (i = 0; i<delay && st->pts_buffer[i] > st->pts_buffer[i + 1]; i++)\n\n            FFSWAP(int64_t, st->pts_buffer[i], st->pts_buffer[i + 1]);\n\n\n\n        pkt->dts = select_from_pts_buffer(st, st->pts_buffer, pkt->dts);\n\n    }\n\n    // We skipped it above so we try here.\n\n    if (!onein_oneout)\n\n        // This should happen on the first packet\n\n        update_initial_timestamps(s, pkt->stream_index, pkt->dts, pkt->pts, pkt);\n\n    if (pkt->dts > st->cur_dts)\n\n        st->cur_dts = pkt->dts;\n\n\n\n    av_dlog(NULL, \"OUTdelayed:%d/%d pts:%s, dts:%s cur_dts:%s\\n\",\n\n            presentation_delayed, delay, av_ts2str(pkt->pts), av_ts2str(pkt->dts), av_ts2str(st->cur_dts));\n\n\n\n    /* update flags */\n\n    if (is_intra_only(st->codec))\n\n        pkt->flags |= AV_PKT_FLAG_KEY;\n\n    if (pc)\n\n        pkt->convergence_duration = pc->convergence_duration;\n\n}\n", "idx": 22593}
{"project": "FFmpeg", "commit_id": "a2a17d3f879436182bcc52c2986a56acd81e7e92", "target": 1, "func": "static inline int vertClassify_altivec(uint8_t src[], int stride, PPContext *c) {\n\n    /*\n\n    this code makes no assumption on src or stride.\n\n    One could remove the recomputation of the perm\n\n    vector by assuming (stride % 16) == 0, unfortunately\n\n    this is not always true.\n\n    */\n\n    DECLARE_ALIGNED(16, short, data)[8] =\n\n                    {\n\n                        ((c->nonBQP*c->ppMode.baseDcDiff)>>8) + 1,\n\n                        data[0] * 2 + 1,\n\n                        c->QP * 2,\n\n                        c->QP * 4\n\n                    };\n\n    int numEq;\n\n    uint8_t *src2 = src;\n\n    vector signed short v_dcOffset;\n\n    vector signed short v2QP;\n\n    vector unsigned short v4QP;\n\n    vector unsigned short v_dcThreshold;\n\n    const int properStride = (stride % 16);\n\n    const int srcAlign = ((unsigned long)src2 % 16);\n\n    const int two_vectors = ((srcAlign > 8) || properStride) ? 1 : 0;\n\n    const vector signed int zero = vec_splat_s32(0);\n\n    const vector signed short mask = vec_splat_s16(1);\n\n    vector signed int v_numEq = vec_splat_s32(0);\n\n    vector signed short v_data = vec_ld(0, data);\n\n    vector signed short v_srcAss0, v_srcAss1, v_srcAss2, v_srcAss3,\n\n                        v_srcAss4, v_srcAss5, v_srcAss6, v_srcAss7;\n\n//FIXME avoid this mess if possible\n\n    register int j0 = 0,\n\n                 j1 = stride,\n\n                 j2 = 2 * stride,\n\n                 j3 = 3 * stride,\n\n                 j4 = 4 * stride,\n\n                 j5 = 5 * stride,\n\n                 j6 = 6 * stride,\n\n                 j7 = 7 * stride;\n\n    vector unsigned char v_srcA0, v_srcA1, v_srcA2, v_srcA3,\n\n                         v_srcA4, v_srcA5, v_srcA6, v_srcA7;\n\n\n\n    v_dcOffset = vec_splat(v_data, 0);\n\n    v_dcThreshold = (vector unsigned short)vec_splat(v_data, 1);\n\n    v2QP = vec_splat(v_data, 2);\n\n    v4QP = (vector unsigned short)vec_splat(v_data, 3);\n\n\n\n    src2 += stride * 4;\n\n\n\n#define LOAD_LINE(i)                                                    \\\n\n    {                                                                   \\\n\n    vector unsigned char perm##i = vec_lvsl(j##i, src2);                \\\n\n    vector unsigned char v_srcA2##i;                                    \\\n\n    vector unsigned char v_srcA1##i = vec_ld(j##i, src2);               \\\n\n    if (two_vectors)                                                    \\\n\n        v_srcA2##i = vec_ld(j##i + 16, src2);                           \\\n\n    v_srcA##i =                                                         \\\n\n        vec_perm(v_srcA1##i, v_srcA2##i, perm##i);                      \\\n\n    v_srcAss##i =                                                       \\\n\n        (vector signed short)vec_mergeh((vector signed char)zero,       \\\n\n                                        (vector signed char)v_srcA##i); }\n\n\n\n#define LOAD_LINE_ALIGNED(i)                                            \\\n\n    v_srcA##i = vec_ld(j##i, src2);                                     \\\n\n    v_srcAss##i =                                                       \\\n\n        (vector signed short)vec_mergeh((vector signed char)zero,       \\\n\n                                        (vector signed char)v_srcA##i)\n\n\n\n    /* Special-casing the aligned case is worthwhile, as all calls from\n\n     * the (transposed) horizontable deblocks will be aligned, in addition\n\n     * to the naturally aligned vertical deblocks. */\n\n    if (properStride && srcAlign) {\n\n        LOAD_LINE_ALIGNED(0);\n\n        LOAD_LINE_ALIGNED(1);\n\n        LOAD_LINE_ALIGNED(2);\n\n        LOAD_LINE_ALIGNED(3);\n\n        LOAD_LINE_ALIGNED(4);\n\n        LOAD_LINE_ALIGNED(5);\n\n        LOAD_LINE_ALIGNED(6);\n\n        LOAD_LINE_ALIGNED(7);\n\n    } else {\n\n        LOAD_LINE(0);\n\n        LOAD_LINE(1);\n\n        LOAD_LINE(2);\n\n        LOAD_LINE(3);\n\n        LOAD_LINE(4);\n\n        LOAD_LINE(5);\n\n        LOAD_LINE(6);\n\n        LOAD_LINE(7);\n\n    }\n\n#undef LOAD_LINE\n\n#undef LOAD_LINE_ALIGNED\n\n\n\n#define ITER(i, j)                                                      \\\n\n    const vector signed short v_diff##i =                               \\\n\n        vec_sub(v_srcAss##i, v_srcAss##j);                              \\\n\n    const vector signed short v_sum##i =                                \\\n\n        vec_add(v_diff##i, v_dcOffset);                                 \\\n\n    const vector signed short v_comp##i =                               \\\n\n        (vector signed short)vec_cmplt((vector unsigned short)v_sum##i, \\\n\n                                       v_dcThreshold);                  \\\n\n    const vector signed short v_part##i = vec_and(mask, v_comp##i);\n\n\n\n    {\n\n        ITER(0, 1)\n\n        ITER(1, 2)\n\n        ITER(2, 3)\n\n        ITER(3, 4)\n\n        ITER(4, 5)\n\n        ITER(5, 6)\n\n        ITER(6, 7)\n\n\n\n        v_numEq = vec_sum4s(v_part0, v_numEq);\n\n        v_numEq = vec_sum4s(v_part1, v_numEq);\n\n        v_numEq = vec_sum4s(v_part2, v_numEq);\n\n        v_numEq = vec_sum4s(v_part3, v_numEq);\n\n        v_numEq = vec_sum4s(v_part4, v_numEq);\n\n        v_numEq = vec_sum4s(v_part5, v_numEq);\n\n        v_numEq = vec_sum4s(v_part6, v_numEq);\n\n    }\n\n\n\n#undef ITER\n\n\n\n    v_numEq = vec_sums(v_numEq, zero);\n\n\n\n    v_numEq = vec_splat(v_numEq, 3);\n\n    vec_ste(v_numEq, 0, &numEq);\n\n\n\n    if (numEq > c->ppMode.flatnessThreshold){\n\n        const vector unsigned char mmoP1 = (const vector unsigned char)\n\n            {0x1f, 0x1f, 0x1f, 0x1f, 0x1f, 0x1f, 0x1f, 0x1f,\n\n             0x00, 0x01, 0x12, 0x13, 0x08, 0x09, 0x1A, 0x1B};\n\n        const vector unsigned char mmoP2 = (const vector unsigned char)\n\n            {0x04, 0x05, 0x16, 0x17, 0x0C, 0x0D, 0x1E, 0x1F,\n\n             0x1f, 0x1f, 0x1f, 0x1f, 0x1f, 0x1f, 0x1f, 0x1f};\n\n        const vector unsigned char mmoP = (const vector unsigned char)\n\n            vec_lvsl(8, (unsigned char*)0);\n\n\n\n        vector signed short mmoL1 = vec_perm(v_srcAss0, v_srcAss2, mmoP1);\n\n        vector signed short mmoL2 = vec_perm(v_srcAss4, v_srcAss6, mmoP2);\n\n        vector signed short mmoL = vec_perm(mmoL1, mmoL2, mmoP);\n\n        vector signed short mmoR1 = vec_perm(v_srcAss5, v_srcAss7, mmoP1);\n\n        vector signed short mmoR2 = vec_perm(v_srcAss1, v_srcAss3, mmoP2);\n\n        vector signed short mmoR = vec_perm(mmoR1, mmoR2, mmoP);\n\n        vector signed short mmoDiff = vec_sub(mmoL, mmoR);\n\n        vector unsigned short mmoSum = (vector unsigned short)vec_add(mmoDiff, v2QP);\n\n\n\n        if (vec_any_gt(mmoSum, v4QP))\n\n            return 0;\n\n        else\n\n            return 1;\n\n    }\n\n    else return 2;\n\n}\n", "idx": 22594}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int vaapi_vc1_start_frame(AVCodecContext *avctx, av_unused const uint8_t *buffer, av_unused uint32_t size)\n\n{\n\n    VC1Context * const v = avctx->priv_data;\n\n    MpegEncContext * const s = &v->s;\n\n    struct vaapi_context * const vactx = avctx->hwaccel_context;\n\n    VAPictureParameterBufferVC1 *pic_param;\n\n\n\n    av_dlog(avctx, \"vaapi_vc1_start_frame()\\n\");\n\n\n\n    vactx->slice_param_size = sizeof(VASliceParameterBufferVC1);\n\n\n\n    /* Fill in VAPictureParameterBufferVC1 */\n\n    pic_param = ff_vaapi_alloc_pic_param(vactx, sizeof(VAPictureParameterBufferVC1));\n\n    if (!pic_param)\n\n        return -1;\n\n    pic_param->forward_reference_picture                            = VA_INVALID_ID;\n\n    pic_param->backward_reference_picture                           = VA_INVALID_ID;\n\n    pic_param->inloop_decoded_picture                               = VA_INVALID_ID;\n\n    pic_param->sequence_fields.value                                = 0; /* reset all bits */\n\n    pic_param->sequence_fields.bits.pulldown                        = v->broadcast;\n\n    pic_param->sequence_fields.bits.interlace                       = v->interlace;\n\n    pic_param->sequence_fields.bits.tfcntrflag                      = v->tfcntrflag;\n\n    pic_param->sequence_fields.bits.finterpflag                     = v->finterpflag;\n\n    pic_param->sequence_fields.bits.psf                             = v->psf;\n\n    pic_param->sequence_fields.bits.multires                        = v->multires;\n\n    pic_param->sequence_fields.bits.overlap                         = v->overlap;\n\n    pic_param->sequence_fields.bits.syncmarker                      = v->resync_marker;\n\n    pic_param->sequence_fields.bits.rangered                        = v->rangered;\n\n    pic_param->sequence_fields.bits.max_b_frames                    = s->avctx->max_b_frames;\n\n#if VA_CHECK_VERSION(0,32,0)\n\n    pic_param->sequence_fields.bits.profile                         = v->profile;\n\n#endif\n\n    pic_param->coded_width                                          = s->avctx->coded_width;\n\n    pic_param->coded_height                                         = s->avctx->coded_height;\n\n    pic_param->entrypoint_fields.value                              = 0; /* reset all bits */\n\n    pic_param->entrypoint_fields.bits.broken_link                   = v->broken_link;\n\n    pic_param->entrypoint_fields.bits.closed_entry                  = v->closed_entry;\n\n    pic_param->entrypoint_fields.bits.panscan_flag                  = v->panscanflag;\n\n    pic_param->entrypoint_fields.bits.loopfilter                    = s->loop_filter;\n\n    pic_param->conditional_overlap_flag                             = v->condover;\n\n    pic_param->fast_uvmc_flag                                       = v->fastuvmc;\n\n    pic_param->range_mapping_fields.value                           = 0; /* reset all bits */\n\n    pic_param->range_mapping_fields.bits.luma_flag                  = v->range_mapy_flag;\n\n    pic_param->range_mapping_fields.bits.luma                       = v->range_mapy;\n\n    pic_param->range_mapping_fields.bits.chroma_flag                = v->range_mapuv_flag;\n\n    pic_param->range_mapping_fields.bits.chroma                     = v->range_mapuv;\n\n    pic_param->b_picture_fraction                                   = v->bfraction_lut_index;\n\n    pic_param->cbp_table                                            = v->cbpcy_vlc ? v->cbpcy_vlc - ff_vc1_cbpcy_p_vlc : 0;\n\n    pic_param->mb_mode_table                                        = 0; /* XXX: interlaced frame */\n\n    pic_param->range_reduction_frame                                = v->rangeredfrm;\n\n    pic_param->rounding_control                                     = v->rnd;\n\n    pic_param->post_processing                                      = v->postproc;\n\n    pic_param->picture_resolution_index                             = v->respic;\n\n    pic_param->luma_scale                                           = v->lumscale;\n\n    pic_param->luma_shift                                           = v->lumshift;\n\n    pic_param->picture_fields.value                                 = 0; /* reset all bits */\n\n    pic_param->picture_fields.bits.picture_type                     = vc1_get_PTYPE(v);\n\n    pic_param->picture_fields.bits.frame_coding_mode                = v->fcm;\n\n    pic_param->picture_fields.bits.top_field_first                  = v->tff;\n\n    pic_param->picture_fields.bits.is_first_field                   = v->fcm == 0; /* XXX: interlaced frame */\n\n    pic_param->picture_fields.bits.intensity_compensation           = v->mv_mode == MV_PMODE_INTENSITY_COMP;\n\n    pic_param->raw_coding.value                                     = 0; /* reset all bits */\n\n    pic_param->raw_coding.flags.mv_type_mb                          = v->mv_type_is_raw;\n\n    pic_param->raw_coding.flags.direct_mb                           = v->dmb_is_raw;\n\n    pic_param->raw_coding.flags.skip_mb                             = v->skip_is_raw;\n\n    pic_param->raw_coding.flags.field_tx                            = 0; /* XXX: interlaced frame */\n\n    pic_param->raw_coding.flags.forward_mb                          = 0; /* XXX: interlaced frame */\n\n    pic_param->raw_coding.flags.ac_pred                             = v->acpred_is_raw;\n\n    pic_param->raw_coding.flags.overflags                           = v->overflg_is_raw;\n\n    pic_param->bitplane_present.value                               = 0; /* reset all bits */\n\n    pic_param->bitplane_present.flags.bp_mv_type_mb                 = vc1_has_MVTYPEMB_bitplane(v);\n\n    pic_param->bitplane_present.flags.bp_direct_mb                  = vc1_has_DIRECTMB_bitplane(v);\n\n    pic_param->bitplane_present.flags.bp_skip_mb                    = vc1_has_SKIPMB_bitplane(v);\n\n    pic_param->bitplane_present.flags.bp_field_tx                   = 0; /* XXX: interlaced frame */\n\n    pic_param->bitplane_present.flags.bp_forward_mb                 = 0; /* XXX: interlaced frame */\n\n    pic_param->bitplane_present.flags.bp_ac_pred                    = vc1_has_ACPRED_bitplane(v);\n\n    pic_param->bitplane_present.flags.bp_overflags                  = vc1_has_OVERFLAGS_bitplane(v);\n\n    pic_param->reference_fields.value                               = 0; /* reset all bits */\n\n    pic_param->reference_fields.bits.reference_distance_flag        = v->refdist_flag;\n\n    pic_param->reference_fields.bits.reference_distance             = 0; /* XXX: interlaced frame */\n\n    pic_param->reference_fields.bits.num_reference_pictures         = 0; /* XXX: interlaced frame */\n\n    pic_param->reference_fields.bits.reference_field_pic_indicator  = 0; /* XXX: interlaced frame */\n\n    pic_param->mv_fields.value                                      = 0; /* reset all bits */\n\n    pic_param->mv_fields.bits.mv_mode                               = vc1_get_MVMODE(v);\n\n    pic_param->mv_fields.bits.mv_mode2                              = vc1_get_MVMODE2(v);\n\n    pic_param->mv_fields.bits.mv_table                              = s->mv_table_index;\n\n    pic_param->mv_fields.bits.two_mv_block_pattern_table            = 0; /* XXX: interlaced frame */\n\n    pic_param->mv_fields.bits.four_mv_switch                        = 0; /* XXX: interlaced frame */\n\n    pic_param->mv_fields.bits.four_mv_block_pattern_table           = 0; /* XXX: interlaced frame */\n\n    pic_param->mv_fields.bits.extended_mv_flag                      = v->extended_mv;\n\n    pic_param->mv_fields.bits.extended_mv_range                     = v->mvrange;\n\n    pic_param->mv_fields.bits.extended_dmv_flag                     = v->extended_dmv;\n\n    pic_param->mv_fields.bits.extended_dmv_range                    = 0; /* XXX: interlaced frame */\n\n    pic_param->pic_quantizer_fields.value                           = 0; /* reset all bits */\n\n    pic_param->pic_quantizer_fields.bits.dquant                     = v->dquant;\n\n    pic_param->pic_quantizer_fields.bits.quantizer                  = v->quantizer_mode;\n\n    pic_param->pic_quantizer_fields.bits.half_qp                    = v->halfpq;\n\n    pic_param->pic_quantizer_fields.bits.pic_quantizer_scale        = v->pq;\n\n    pic_param->pic_quantizer_fields.bits.pic_quantizer_type         = v->pquantizer;\n\n    pic_param->pic_quantizer_fields.bits.dq_frame                   = v->dquantfrm;\n\n    pic_param->pic_quantizer_fields.bits.dq_profile                 = v->dqprofile;\n\n    pic_param->pic_quantizer_fields.bits.dq_sb_edge                 = v->dqprofile == DQPROFILE_SINGLE_EDGE  ? v->dqsbedge : 0;\n\n    pic_param->pic_quantizer_fields.bits.dq_db_edge                 = v->dqprofile == DQPROFILE_DOUBLE_EDGES ? v->dqsbedge : 0;\n\n    pic_param->pic_quantizer_fields.bits.dq_binary_level            = v->dqbilevel;\n\n    pic_param->pic_quantizer_fields.bits.alt_pic_quantizer          = v->altpq;\n\n    pic_param->transform_fields.value                               = 0; /* reset all bits */\n\n    pic_param->transform_fields.bits.variable_sized_transform_flag  = v->vstransform;\n\n    pic_param->transform_fields.bits.mb_level_transform_type_flag   = v->ttmbf;\n\n    pic_param->transform_fields.bits.frame_level_transform_type     = vc1_get_TTFRM(v);\n\n    pic_param->transform_fields.bits.transform_ac_codingset_idx1    = v->c_ac_table_index;\n\n    pic_param->transform_fields.bits.transform_ac_codingset_idx2    = v->y_ac_table_index;\n\n    pic_param->transform_fields.bits.intra_transform_dc_table       = v->s.dc_table_index;\n\n\n\n    switch (s->pict_type) {\n\n    case AV_PICTURE_TYPE_B:\n\n        pic_param->backward_reference_picture = ff_vaapi_get_surface_id(&s->next_picture.f);\n\n        // fall-through\n\n    case AV_PICTURE_TYPE_P:\n\n        pic_param->forward_reference_picture = ff_vaapi_get_surface_id(&s->last_picture.f);\n\n        break;\n\n    }\n\n\n\n    if (pic_param->bitplane_present.value) {\n\n        uint8_t *bitplane;\n\n        const uint8_t *ff_bp[3];\n\n        int x, y, n;\n\n\n\n        switch (s->pict_type) {\n\n        case AV_PICTURE_TYPE_P:\n\n            ff_bp[0] = pic_param->bitplane_present.flags.bp_direct_mb  ? v->direct_mb_plane    : NULL;\n\n            ff_bp[1] = pic_param->bitplane_present.flags.bp_skip_mb    ? s->mbskip_table       : NULL;\n\n            ff_bp[2] = pic_param->bitplane_present.flags.bp_mv_type_mb ? v->mv_type_mb_plane   : NULL;\n\n            break;\n\n        case AV_PICTURE_TYPE_B:\n\n            if (!v->bi_type) {\n\n                ff_bp[0] = pic_param->bitplane_present.flags.bp_direct_mb ? v->direct_mb_plane : NULL;\n\n                ff_bp[1] = pic_param->bitplane_present.flags.bp_skip_mb   ? s->mbskip_table    : NULL;\n\n                ff_bp[2] = NULL; /* XXX: interlaced frame (FORWARD plane) */\n\n                break;\n\n            }\n\n            /* fall-through (BI-type) */\n\n        case AV_PICTURE_TYPE_I:\n\n            ff_bp[0] = NULL; /* XXX: interlaced frame (FIELDTX plane) */\n\n            ff_bp[1] = pic_param->bitplane_present.flags.bp_ac_pred    ? v->acpred_plane       : NULL;\n\n            ff_bp[2] = pic_param->bitplane_present.flags.bp_overflags  ? v->over_flags_plane   : NULL;\n\n            break;\n\n        default:\n\n            ff_bp[0] = NULL;\n\n            ff_bp[1] = NULL;\n\n            ff_bp[2] = NULL;\n\n            break;\n\n        }\n\n\n\n        bitplane = ff_vaapi_alloc_bitplane(vactx, (s->mb_width * s->mb_height + 1) / 2);\n\n        if (!bitplane)\n\n            return -1;\n\n\n\n        n = 0;\n\n        for (y = 0; y < s->mb_height; y++)\n\n            for (x = 0; x < s->mb_width; x++, n++)\n\n                vc1_pack_bitplanes(bitplane, n, ff_bp, x, y, s->mb_stride);\n\n        if (n & 1) /* move last nibble to the high order */\n\n            bitplane[n/2] <<= 4;\n\n    }\n\n    return 0;\n\n}\n", "idx": 22595}
{"project": "FFmpeg", "commit_id": "eb5049227033d946add93c0714bb8a28d94166f1", "target": 1, "func": "static int dxv_decompress_raw(AVCodecContext *avctx)\n{\n    DXVContext *ctx = avctx->priv_data;\n    GetByteContext *gbc = &ctx->gbc;\n    bytestream2_get_buffer(gbc, ctx->tex_data, ctx->tex_size);\n    return 0;\n}", "idx": 22596}
{"project": "FFmpeg", "commit_id": "b791a0831b0a027e7ba4eb6961cc0180472ac603", "target": 1, "func": "static av_cold void dsputil_init_sse2(DSPContext *c, AVCodecContext *avctx,\n\n                                      int mm_flags)\n\n{\n\n#if HAVE_SSE2_INLINE\n\n    const int high_bit_depth = avctx->bits_per_raw_sample > 8;\n\n\n\n    if (!high_bit_depth && avctx->idct_algo == FF_IDCT_XVIDMMX) {\n\n        c->idct_put              = ff_idct_xvid_sse2_put;\n\n        c->idct_add              = ff_idct_xvid_sse2_add;\n\n        c->idct                  = ff_idct_xvid_sse2;\n\n        c->idct_permutation_type = FF_SSE2_IDCT_PERM;\n\n    }\n\n#endif /* HAVE_SSE2_INLINE */\n\n\n\n#if HAVE_SSE2_EXTERNAL\n\n    c->scalarproduct_int16          = ff_scalarproduct_int16_sse2;\n\n    c->scalarproduct_and_madd_int16 = ff_scalarproduct_and_madd_int16_sse2;\n\n    if (mm_flags & AV_CPU_FLAG_ATOM) {\n\n        c->vector_clip_int32 = ff_vector_clip_int32_int_sse2;\n\n    } else {\n\n        c->vector_clip_int32 = ff_vector_clip_int32_sse2;\n\n    }\n\n    if (avctx->flags & CODEC_FLAG_BITEXACT) {\n\n        c->apply_window_int16 = ff_apply_window_int16_sse2;\n\n    } else if (!(mm_flags & AV_CPU_FLAG_SSE2SLOW)) {\n\n        c->apply_window_int16 = ff_apply_window_int16_round_sse2;\n\n    }\n\n    c->bswap_buf = ff_bswap32_buf_sse2;\n\n#endif /* HAVE_SSE2_EXTERNAL */\n\n}\n", "idx": 22597}
{"project": "FFmpeg", "commit_id": "6e3ea4461fa9a77964efd2fa7ed1250dd1c8d43d", "target": 0, "func": "static int mxf_read_local_tags(MXFContext *mxf, KLVPacket *klv, int (*read_child)(), int ctx_size, enum MXFMetadataSetType type)\n\n{\n\n    ByteIOContext *pb = mxf->fc->pb;\n\n    MXFMetadataSet *ctx = ctx_size ? av_mallocz(ctx_size) : mxf;\n\n    uint64_t klv_end = url_ftell(pb) + klv->length;\n\n\n\n    if (!ctx)\n\n        return -1;\n\n    while (url_ftell(pb) + 4 < klv_end) {\n\n        int tag = get_be16(pb);\n\n        int size = get_be16(pb); /* KLV specified by 0x53 */\n\n        uint64_t next = url_ftell(pb) + size;\n\n        UID uid;\n\n\n\n        if (!size) { /* ignore empty tag, needed for some files with empty UMID tag */\n\n            av_log(mxf->fc, AV_LOG_ERROR, \"local tag 0x%04X with 0 size\\n\", tag);\n\n            continue;\n\n        }\n\n        if (tag > 0x7FFF) { /* dynamic tag */\n\n            int i;\n\n            for (i = 0; i < mxf->local_tags_count; i++) {\n\n                int local_tag = AV_RB16(mxf->local_tags+i*18);\n\n                if (local_tag == tag) {\n\n                    memcpy(uid, mxf->local_tags+i*18+2, 16);\n\n                    dprintf(mxf->fc, \"local tag 0x%04X\\n\", local_tag);\n\n#ifdef DEBUG\n\n                    PRINT_KEY(mxf->fc, \"uid\", uid);\n\n#endif\n\n                }\n\n            }\n\n        }\n\n        if (ctx_size && tag == 0x3C0A)\n\n            get_buffer(pb, ctx->uid, 16);\n\n        else\n\n            read_child(ctx, pb, tag, size, uid);\n\n\n\n        url_fseek(pb, next, SEEK_SET);\n\n    }\n\n    if (ctx_size) ctx->type = type;\n\n    return ctx_size ? mxf_add_metadata_set(mxf, ctx) : 0;\n\n}\n", "idx": 22599}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static void RENAME(extract_even2)(const uint8_t *src, uint8_t *dst0, uint8_t *dst1, x86_reg count)\n\n{\n\n    dst0+=   count;\n\n    dst1+=   count;\n\n    src += 4*count;\n\n    count= - count;\n\n#if COMPILE_TEMPLATE_MMX\n\n    if(count <= -8) {\n\n        count += 7;\n\n        __asm__ volatile(\n\n            \"pcmpeqw       %%mm7, %%mm7        \\n\\t\"\n\n            \"psrlw            $8, %%mm7        \\n\\t\"\n\n            \"1:                                \\n\\t\"\n\n            \"movq -28(%1, %0, 4), %%mm0        \\n\\t\"\n\n            \"movq -20(%1, %0, 4), %%mm1        \\n\\t\"\n\n            \"movq -12(%1, %0, 4), %%mm2        \\n\\t\"\n\n            \"movq  -4(%1, %0, 4), %%mm3        \\n\\t\"\n\n            \"pand          %%mm7, %%mm0        \\n\\t\"\n\n            \"pand          %%mm7, %%mm1        \\n\\t\"\n\n            \"pand          %%mm7, %%mm2        \\n\\t\"\n\n            \"pand          %%mm7, %%mm3        \\n\\t\"\n\n            \"packuswb      %%mm1, %%mm0        \\n\\t\"\n\n            \"packuswb      %%mm3, %%mm2        \\n\\t\"\n\n            \"movq          %%mm0, %%mm1        \\n\\t\"\n\n            \"movq          %%mm2, %%mm3        \\n\\t\"\n\n            \"psrlw            $8, %%mm0        \\n\\t\"\n\n            \"psrlw            $8, %%mm2        \\n\\t\"\n\n            \"pand          %%mm7, %%mm1        \\n\\t\"\n\n            \"pand          %%mm7, %%mm3        \\n\\t\"\n\n            \"packuswb      %%mm2, %%mm0        \\n\\t\"\n\n            \"packuswb      %%mm3, %%mm1        \\n\\t\"\n\n            MOVNTQ\"        %%mm0,- 7(%3, %0)   \\n\\t\"\n\n            MOVNTQ\"        %%mm1,- 7(%2, %0)   \\n\\t\"\n\n            \"add              $8, %0           \\n\\t\"\n\n            \" js 1b                            \\n\\t\"\n\n            : \"+r\"(count)\n\n            : \"r\"(src), \"r\"(dst0), \"r\"(dst1)\n\n        );\n\n        count -= 7;\n\n    }\n\n#endif\n\n    while(count<0) {\n\n        dst0[count]= src[4*count+0];\n\n        dst1[count]= src[4*count+2];\n\n        count++;\n\n    }\n\n}\n", "idx": 22600}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int au_probe(AVProbeData *p)\n\n{\n\n    /* check file header */\n\n    if (p->buf_size <= 24)\n\n        return 0;\n\n    if (p->buf[0] == '.' && p->buf[1] == 's' &&\n\n        p->buf[2] == 'n' && p->buf[3] == 'd')\n\n        return AVPROBE_SCORE_MAX;\n\n    else\n\n        return 0;\n\n}\n", "idx": 22601}
{"project": "FFmpeg", "commit_id": "89f704cabab446afc8ba6ecea76714a51b1df32b", "target": 0, "func": "static int X264_frame(AVCodecContext *ctx, AVPacket *pkt, const AVFrame *frame,\n\n                      int *got_packet)\n\n{\n\n    X264Context *x4 = ctx->priv_data;\n\n    x264_nal_t *nal;\n\n    int nnal, i, ret;\n\n    x264_picture_t pic_out = {0};\n\n    int pict_type;\n\n\n\n    x264_picture_init( &x4->pic );\n\n    x4->pic.img.i_csp   = x4->params.i_csp;\n\n    if (x264_bit_depth > 8)\n\n        x4->pic.img.i_csp |= X264_CSP_HIGH_DEPTH;\n\n    x4->pic.img.i_plane = avfmt2_num_planes(ctx->pix_fmt);\n\n\n\n    if (frame) {\n\n        for (i = 0; i < x4->pic.img.i_plane; i++) {\n\n            x4->pic.img.plane[i]    = frame->data[i];\n\n            x4->pic.img.i_stride[i] = frame->linesize[i];\n\n        }\n\n\n\n        x4->pic.i_pts  = frame->pts;\n\n\n\n        switch (frame->pict_type) {\n\n        case AV_PICTURE_TYPE_I:\n\n            x4->pic.i_type = x4->forced_idr > 0 ? X264_TYPE_IDR\n\n                                                : X264_TYPE_KEYFRAME;\n\n            break;\n\n        case AV_PICTURE_TYPE_P:\n\n            x4->pic.i_type = X264_TYPE_P;\n\n            break;\n\n        case AV_PICTURE_TYPE_B:\n\n            x4->pic.i_type = X264_TYPE_B;\n\n            break;\n\n        default:\n\n            x4->pic.i_type = X264_TYPE_AUTO;\n\n            break;\n\n        }\n\n        reconfig_encoder(ctx, frame);\n\n\n\n        if (x4->a53_cc) {\n\n            void *sei_data;\n\n            size_t sei_size;\n\n\n\n            ret = ff_alloc_a53_sei(frame, 0, &sei_data, &sei_size);\n\n            if (ret < 0) {\n\n                av_log(ctx, AV_LOG_ERROR, \"Not enough memory for closed captions, skipping\\n\");\n\n            } else if (sei_data) {\n\n                x4->pic.extra_sei.payloads = av_mallocz(sizeof(x4->pic.extra_sei.payloads[0]));\n\n                if (x4->pic.extra_sei.payloads == NULL) {\n\n                    av_log(ctx, AV_LOG_ERROR, \"Not enough memory for closed captions, skipping\\n\");\n\n                    av_free(sei_data);\n\n                } else {\n\n                    x4->pic.extra_sei.sei_free = av_free;\n\n\n\n                    x4->pic.extra_sei.payloads[0].payload_size = sei_size;\n\n                    x4->pic.extra_sei.payloads[0].payload = sei_data;\n\n                    x4->pic.extra_sei.num_payloads = 1;\n\n                    x4->pic.extra_sei.payloads[0].payload_type = 4;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    do {\n\n        if (x264_encoder_encode(x4->enc, &nal, &nnal, frame? &x4->pic: NULL, &pic_out) < 0)\n\n            return AVERROR_EXTERNAL;\n\n\n\n        ret = encode_nals(ctx, pkt, nal, nnal);\n\n        if (ret < 0)\n\n            return ret;\n\n    } while (!ret && !frame && x264_encoder_delayed_frames(x4->enc));\n\n\n\n    pkt->pts = pic_out.i_pts;\n\n    pkt->dts = pic_out.i_dts;\n\n\n\n\n\n    switch (pic_out.i_type) {\n\n    case X264_TYPE_IDR:\n\n    case X264_TYPE_I:\n\n        pict_type = AV_PICTURE_TYPE_I;\n\n        break;\n\n    case X264_TYPE_P:\n\n        pict_type = AV_PICTURE_TYPE_P;\n\n        break;\n\n    case X264_TYPE_B:\n\n    case X264_TYPE_BREF:\n\n        pict_type = AV_PICTURE_TYPE_B;\n\n        break;\n\n    default:\n\n        pict_type = AV_PICTURE_TYPE_NONE;\n\n    }\n\n#if FF_API_CODED_FRAME\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    ctx->coded_frame->pict_type = pict_type;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n\n\n    pkt->flags |= AV_PKT_FLAG_KEY*pic_out.b_keyframe;\n\n    if (ret) {\n\n        ff_side_data_set_encoder_stats(pkt, (pic_out.i_qpplus1 - 1) * FF_QP2LAMBDA, NULL, 0, pict_type);\n\n\n\n#if FF_API_CODED_FRAME\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n        ctx->coded_frame->quality = (pic_out.i_qpplus1 - 1) * FF_QP2LAMBDA;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n    }\n\n\n\n    *got_packet = ret;\n\n    return 0;\n\n}\n", "idx": 22602}
{"project": "FFmpeg", "commit_id": "332f9ac4e31ce5e6d0c42ac9e0229d7d1b2b4d60", "target": 0, "func": "int flv_h263_decode_picture_header(MpegEncContext *s)\n\n{\n\n    int format, width, height;\n\n\n\n    /* picture header */\n\n    if (get_bits_long(&s->gb, 17) != 1) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Bad picture start code\\n\");\n\n        return -1;\n\n    }\n\n    format = get_bits(&s->gb, 5);\n\n    if (format != 0 && format != 1) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Bad picture format\\n\");\n\n        return -1;\n\n    }\n\n    s->h263_flv = format+1;\n\n    s->picture_number = get_bits(&s->gb, 8); /* picture timestamp */\n\n    format = get_bits(&s->gb, 3);\n\n    switch (format) {\n\n    case 0:\n\n        width = get_bits(&s->gb, 8);\n\n        height = get_bits(&s->gb, 8);\n\n        break;\n\n    case 1:\n\n        width = get_bits(&s->gb, 16);\n\n        height = get_bits(&s->gb, 16);\n\n        break;\n\n    case 2:\n\n        width = 352;\n\n        height = 288;\n\n        break;\n\n    case 3:\n\n        width = 176;\n\n        height = 144;\n\n        break;\n\n    case 4:\n\n        width = 128;\n\n        height = 96;\n\n        break;\n\n    case 5:\n\n        width = 320;\n\n        height = 240;\n\n        break;\n\n    case 6:\n\n        width = 160;\n\n        height = 120;\n\n        break;\n\n    default:\n\n        width = height = 0;\n\n        break;\n\n    }\n\n    if ((width == 0) || (height == 0))\n\n        return -1;\n\n    s->width = width;\n\n    s->height = height;\n\n\n\n    s->pict_type = I_TYPE + get_bits(&s->gb, 2);\n\n    if (s->pict_type > P_TYPE)\n\n        s->pict_type = P_TYPE;\n\n    skip_bits1(&s->gb);\t/* deblocking flag */\n\n    s->qscale = get_bits(&s->gb, 5);\n\n\n\n    s->h263_plus = 0;\n\n\n\n    s->unrestricted_mv = 1;\n\n    s->h263_long_vectors = 0;\n\n\n\n    /* PEI */\n\n    while (get_bits1(&s->gb) != 0) {\n\n        skip_bits(&s->gb, 8);\n\n    }\n\n    s->f_code = 1;\n\n\n\n    if(s->avctx->debug & FF_DEBUG_PICT_INFO){\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"%c esc_type:%d, qp:%d num:%d\\n\",\n\n               av_get_pict_type_char(s->pict_type), s->h263_flv-1, s->qscale, s->picture_number);\n\n    }\n\n    \n\n    s->y_dc_scale_table=\n\n    s->c_dc_scale_table= ff_mpeg1_dc_scale_table;\n\n\n\n    return 0;\n\n}\n", "idx": 22603}
{"project": "FFmpeg", "commit_id": "56706ac0d5723cb549fec2602e798ab1bf6004cd", "target": 1, "func": "static int libopenjpeg_copy_unpacked8(AVCodecContext *avctx, const AVFrame *frame, opj_image_t *image)\n\n{\n\n    int compno;\n\n    int x;\n\n    int y;\n\n    int width;\n\n    int height;\n\n    int *image_line;\n\n    int frame_index;\n\n    const int numcomps = image->numcomps;\n\n\n\n    for (compno = 0; compno < numcomps; ++compno) {\n\n        if (image->comps[compno].w > frame->linesize[compno]) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Error: frame's linesize is too small for the image\\n\");\n\n            return 0;\n\n        }\n\n    }\n\n\n\n    for (compno = 0; compno < numcomps; ++compno) {\n\n        width  = avctx->width / image->comps[compno].dx;\n\n        height = avctx->height / image->comps[compno].dy;\n\n        for (y = 0; y < height; ++y) {\n\n            image_line = image->comps[compno].data + y * image->comps[compno].w;\n\n            frame_index = y * frame->linesize[compno];\n\n            for (x = 0; x < width; ++x)\n\n                image_line[x] = frame->data[compno][frame_index++];\n\n            for (; x < image->comps[compno].w; ++x) {\n\n                image_line[x] = image_line[x - 1];\n\n            }\n\n        }\n\n        for (; y < image->comps[compno].h; ++y) {\n\n            image_line = image->comps[compno].data + y * image->comps[compno].w;\n\n            for (x = 0; x < image->comps[compno].w; ++x) {\n\n                image_line[x] = image_line[x - image->comps[compno].w];\n\n            }\n\n        }\n\n    }\n\n\n\n    return 1;\n\n}\n", "idx": 22606}
{"project": "FFmpeg", "commit_id": "984d58a3440d513f66344b5332f6b589c0a6bbc6", "target": 1, "func": "static int url_alloc_for_protocol(URLContext **puc, struct URLProtocol *up,\n\n                                  const char *filename, int flags,\n\n                                  const AVIOInterruptCB *int_cb)\n\n{\n\n    URLContext *uc;\n\n    int err;\n\n\n\n#if CONFIG_NETWORK\n\n    if (up->flags & URL_PROTOCOL_FLAG_NETWORK && !ff_network_init())\n\n        return AVERROR(EIO);\n\n#endif\n\n    if ((flags & AVIO_FLAG_READ) && !up->url_read) {\n\n        av_log(NULL, AV_LOG_ERROR,\n\n               \"Impossible to open the '%s' protocol for reading\\n\", up->name);\n\n        return AVERROR(EIO);\n\n    }\n\n    if ((flags & AVIO_FLAG_WRITE) && !up->url_write) {\n\n        av_log(NULL, AV_LOG_ERROR,\n\n               \"Impossible to open the '%s' protocol for writing\\n\", up->name);\n\n        return AVERROR(EIO);\n\n    }\n\n    uc = av_mallocz(sizeof(URLContext) + strlen(filename) + 1);\n\n    if (!uc) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    uc->av_class = &ffurl_context_class;\n\n    uc->filename = (char *)&uc[1];\n\n    strcpy(uc->filename, filename);\n\n    uc->prot            = up;\n\n    uc->flags           = flags;\n\n    uc->is_streamed     = 0; /* default = not streamed */\n\n    uc->max_packet_size = 0; /* default: stream file */\n\n    if (up->priv_data_size) {\n\n        uc->priv_data = av_mallocz(up->priv_data_size);\n\n        if (!uc->priv_data) {\n\n            err = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n        if (up->priv_data_class) {\n\n            int proto_len= strlen(up->name);\n\n            char *start = strchr(uc->filename, ',');\n\n            *(const AVClass **)uc->priv_data = up->priv_data_class;\n\n            av_opt_set_defaults(uc->priv_data);\n\n            if(!strncmp(up->name, uc->filename, proto_len) && uc->filename + proto_len == start){\n\n                int ret= 0;\n\n                char *p= start;\n\n                char sep= *++p;\n\n                char *key, *val;\n\n                p++;\n\n                while(ret >= 0 && (key= strchr(p, sep)) && p<key && (val = strchr(key+1, sep))){\n\n                    *val= *key= 0;\n\n                    ret= av_opt_set(uc->priv_data, p, key+1, 0);\n\n                    if (ret == AVERROR_OPTION_NOT_FOUND)\n\n                        av_log(uc, AV_LOG_ERROR, \"Key '%s' not found.\\n\", p);\n\n                    *val= *key= sep;\n\n                    p= val+1;\n\n                }\n\n                if(ret<0 || p!=key){\n\n                    av_log(uc, AV_LOG_ERROR, \"Error parsing options string %s\\n\", start);\n\n                    av_freep(&uc->priv_data);\n\n                    av_freep(&uc);\n\n                    err = AVERROR(EINVAL);\n\n                    goto fail;\n\n                }\n\n                memmove(start, key+1, strlen(key));\n\n            }\n\n        }\n\n    }\n\n    if (int_cb)\n\n        uc->interrupt_callback = *int_cb;\n\n\n\n    *puc = uc;\n\n    return 0;\n\nfail:\n\n    *puc = NULL;\n\n    if (uc)\n\n        av_freep(&uc->priv_data);\n\n    av_freep(&uc);\n\n#if CONFIG_NETWORK\n\n    if (up->flags & URL_PROTOCOL_FLAG_NETWORK)\n\n        ff_network_close();\n\n#endif\n\n    return err;\n\n}\n", "idx": 22607}
{"project": "FFmpeg", "commit_id": "e92a78a4095d69d876bef189225608a35166dc4a", "target": 1, "func": "void ff_write_pass1_stats(MpegEncContext *s)\n\n{\n\n    snprintf(s->avctx->stats_out, 256,\n\n             \"in:%d out:%d type:%d q:%d itex:%d ptex:%d mv:%d misc:%d \"\n\n             \"fcode:%d bcode:%d mc-var:%d var:%d icount:%d skipcount:%d hbits:%d;\\n\",\n\n             s->current_picture_ptr->f.display_picture_number,\n\n             s->current_picture_ptr->f.coded_picture_number,\n\n             s->pict_type,\n\n             s->current_picture.f.quality,\n\n             s->i_tex_bits,\n\n             s->p_tex_bits,\n\n             s->mv_bits,\n\n             s->misc_bits,\n\n             s->f_code,\n\n             s->b_code,\n\n             s->current_picture.mc_mb_var_sum,\n\n             s->current_picture.mb_var_sum,\n\n             s->i_count, s->skip_count,\n\n             s->header_bits);\n\n}\n", "idx": 22608}
{"project": "FFmpeg", "commit_id": "2ce4f28431623cdde4aa496fd10430f6c7bdef63", "target": 1, "func": "static int ff_vp56_decode_mbs(AVCodecContext *avctx, void *data,\n\n                              int jobnr, int threadnr)\n\n{\n\n    VP56Context *s0 = avctx->priv_data;\n\n    int is_alpha = (jobnr == 1);\n\n    VP56Context *s = is_alpha ? s0->alpha_context : s0;\n\n    AVFrame *const p = s->frames[VP56_FRAME_CURRENT];\n\n    int mb_row, mb_col, mb_row_flip, mb_offset = 0;\n\n    int block, y, uv;\n\n    ptrdiff_t stride_y, stride_uv;\n\n    int res;\n\n    int damaged = 0;\n\n\n\n    if (p->key_frame) {\n\n        p->pict_type = AV_PICTURE_TYPE_I;\n\n        s->default_models_init(s);\n\n        for (block=0; block<s->mb_height*s->mb_width; block++)\n\n            s->macroblocks[block].type = VP56_MB_INTRA;\n\n    } else {\n\n        p->pict_type = AV_PICTURE_TYPE_P;\n\n        vp56_parse_mb_type_models(s);\n\n        s->parse_vector_models(s);\n\n        s->mb_type = VP56_MB_INTER_NOVEC_PF;\n\n    }\n\n\n\n    if (s->parse_coeff_models(s))\n\n        goto next;\n\n\n\n    memset(s->prev_dc, 0, sizeof(s->prev_dc));\n\n    s->prev_dc[1][VP56_FRAME_CURRENT] = 128;\n\n    s->prev_dc[2][VP56_FRAME_CURRENT] = 128;\n\n\n\n    for (block=0; block < 4*s->mb_width+6; block++) {\n\n        s->above_blocks[block].ref_frame = VP56_FRAME_NONE;\n\n        s->above_blocks[block].dc_coeff = 0;\n\n        s->above_blocks[block].not_null_dc = 0;\n\n    }\n\n    s->above_blocks[2*s->mb_width + 2].ref_frame = VP56_FRAME_CURRENT;\n\n    s->above_blocks[3*s->mb_width + 4].ref_frame = VP56_FRAME_CURRENT;\n\n\n\n    stride_y  = p->linesize[0];\n\n    stride_uv = p->linesize[1];\n\n\n\n    if (s->flip < 0)\n\n        mb_offset = 7;\n\n\n\n    /* main macroblocks loop */\n\n    for (mb_row=0; mb_row<s->mb_height; mb_row++) {\n\n        if (s->flip < 0)\n\n            mb_row_flip = s->mb_height - mb_row - 1;\n\n        else\n\n            mb_row_flip = mb_row;\n\n\n\n        for (block=0; block<4; block++) {\n\n            s->left_block[block].ref_frame = VP56_FRAME_NONE;\n\n            s->left_block[block].dc_coeff = 0;\n\n            s->left_block[block].not_null_dc = 0;\n\n        }\n\n        memset(s->coeff_ctx, 0, sizeof(s->coeff_ctx));\n\n        memset(s->coeff_ctx_last, 24, sizeof(s->coeff_ctx_last));\n\n\n\n        s->above_block_idx[0] = 1;\n\n        s->above_block_idx[1] = 2;\n\n        s->above_block_idx[2] = 1;\n\n        s->above_block_idx[3] = 2;\n\n        s->above_block_idx[4] = 2*s->mb_width + 2 + 1;\n\n        s->above_block_idx[5] = 3*s->mb_width + 4 + 1;\n\n\n\n        s->block_offset[s->frbi] = (mb_row_flip*16 + mb_offset) * stride_y;\n\n        s->block_offset[s->srbi] = s->block_offset[s->frbi] + 8*stride_y;\n\n        s->block_offset[1] = s->block_offset[0] + 8;\n\n        s->block_offset[3] = s->block_offset[2] + 8;\n\n        s->block_offset[4] = (mb_row_flip*8 + mb_offset) * stride_uv;\n\n        s->block_offset[5] = s->block_offset[4];\n\n\n\n        for (mb_col=0; mb_col<s->mb_width; mb_col++) {\n\n            if (!damaged) {\n\n                int ret = vp56_decode_mb(s, mb_row, mb_col, is_alpha);\n\n                if (ret < 0)\n\n                    damaged = 1;\n\n            }\n\n            if (damaged)\n\n                vp56_conceal_mb(s, mb_row, mb_col, is_alpha);\n\n\n\n            for (y=0; y<4; y++) {\n\n                s->above_block_idx[y] += 2;\n\n                s->block_offset[y] += 16;\n\n            }\n\n\n\n            for (uv=4; uv<6; uv++) {\n\n                s->above_block_idx[uv] += 1;\n\n                s->block_offset[uv] += 8;\n\n            }\n\n        }\n\n    }\n\n\n\nnext:\n\n    if (p->key_frame || s->golden_frame) {\n\n        av_frame_unref(s->frames[VP56_FRAME_GOLDEN]);\n\n        if ((res = av_frame_ref(s->frames[VP56_FRAME_GOLDEN], p)) < 0)\n\n            return res;\n\n    }\n\n\n\n    av_frame_unref(s->frames[VP56_FRAME_PREVIOUS]);\n\n    FFSWAP(AVFrame *, s->frames[VP56_FRAME_CURRENT],\n\n                      s->frames[VP56_FRAME_PREVIOUS]);\n\n    return 0;\n\n}\n", "idx": 22612}
{"project": "FFmpeg", "commit_id": "1f467220cfd1664782b1fe210bbc9342ad460fd2", "target": 1, "func": "static int draw_slice(AVFilterLink *inlink, int y0, int h, int slice_dir)\n\n{\n\n    AlphaExtractContext *extract = inlink->dst->priv;\n\n    AVFilterBufferRef *cur_buf = inlink->cur_buf;\n\n    AVFilterBufferRef *out_buf = inlink->dst->outputs[0]->out_buf;\n\n\n\n    if (extract->is_packed_rgb) {\n\n        int x, y;\n\n        uint8_t *pin, *pout;\n\n        for (y = y0; y < (y0 + h); y++) {\n\n            pin = cur_buf->data[0] + y * cur_buf->linesize[0] + extract->rgba_map[A];\n\n            pout = out_buf->data[0] + y * out_buf->linesize[0];\n\n            for (x = 0; x < out_buf->video->w; x++) {\n\n                *pout = *pin;\n\n                pout += 1;\n\n                pin += 4;\n\n            }\n\n        }\n\n    } else if (cur_buf->linesize[A] == out_buf->linesize[Y]) {\n\n        const int linesize = cur_buf->linesize[A];\n\n        memcpy(out_buf->data[Y] + y0 * linesize,\n\n               cur_buf->data[A] + y0 * linesize,\n\n               linesize * h);\n\n    } else {\n\n        const int linesize = FFMIN(out_buf->linesize[Y], cur_buf->linesize[A]);\n\n        int y;\n\n        for (y = y0; y < (y0 + h); y++) {\n\n            memcpy(out_buf->data[Y] + y * out_buf->linesize[Y],\n\n                   cur_buf->data[A] + y * cur_buf->linesize[A],\n\n                   linesize);\n\n        }\n\n    }\n\n    return ff_draw_slice(inlink->dst->outputs[0], y0, h, slice_dir);\n\n}\n", "idx": 22614}
{"project": "FFmpeg", "commit_id": "bc0a603c7888c1faf4db580829e103b21442b6e4", "target": 1, "func": "static int sad16_altivec(void *v, uint8_t *pix1, uint8_t *pix2, int line_size, int h)\n\n{\n\n    int i;\n\n    int s;\n\n    const vector unsigned int zero = (const vector unsigned int)vec_splat_u32(0);\n\n    vector unsigned char perm1, perm2, *pix1v, *pix2v;\n\n    vector unsigned char t1, t2, t3,t4, t5;\n\n    vector unsigned int sad;\n\n    vector signed int sumdiffs;\n\n\n\n    sad = (vector unsigned int)vec_splat_u32(0);\n\n\n\n\n\n    for (i = 0; i < h; i++) {\n\n        /* Read potentially unaligned pixels into t1 and t2 */\n\n        perm1 = vec_lvsl(0, pix1);\n\n        pix1v = (vector unsigned char *) pix1;\n\n        perm2 = vec_lvsl(0, pix2);\n\n        pix2v = (vector unsigned char *) pix2;\n\n        t1 = vec_perm(pix1v[0], pix1v[1], perm1);\n\n        t2 = vec_perm(pix2v[0], pix2v[1], perm2);\n\n\n\n        /* Calculate a sum of abs differences vector */\n\n        t3 = vec_max(t1, t2);\n\n        t4 = vec_min(t1, t2);\n\n        t5 = vec_sub(t3, t4);\n\n\n\n        /* Add each 4 pixel group together and put 4 results into sad */\n\n        sad = vec_sum4s(t5, sad);\n\n\n\n        pix1 += line_size;\n\n        pix2 += line_size;\n\n    }\n\n\n\n    /* Sum up the four partial sums, and put the result into s */\n\n    sumdiffs = vec_sums((vector signed int) sad, (vector signed int) zero);\n\n    sumdiffs = vec_splat(sumdiffs, 3);\n\n    vec_ste(sumdiffs, 0, &s);\n\n\n\n    return s;\n\n}\n", "idx": 22616}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "void rgb8tobgr8(const uint8_t *src, uint8_t *dst, unsigned int src_size)\n\n{\n\n\tunsigned i;\n\n\tunsigned num_pixels = src_size;\n\n\tfor(i=0; i<num_pixels; i++)\n\n\t{\n\n\t    unsigned b,g,r;\n\n\t    register uint8_t rgb;\n\n\t    rgb = src[i];\n\n\t    r = (rgb&0x07);\n\n\t    g = (rgb&0x38)>>3;\n\n\t    b = (rgb&0xC0)>>6;\n\n\t    dst[i] = ((b<<1)&0x07) | ((g&0x07)<<3) | ((r&0x03)<<6);\n\n\t}\n\n}\n", "idx": 22617}
{"project": "FFmpeg", "commit_id": "36b7e983a664d20dc3809704b47cf8d59895b4de", "target": 1, "func": "static int vorbis_parse_setup_hdr_residues(vorbis_context *vc){\n    GetBitContext *gb=&vc->gb;\n    uint_fast8_t i, j, k;\n    vc->residue_count=get_bits(gb, 6)+1;\n    vc->residues=av_mallocz(vc->residue_count * sizeof(vorbis_residue));\n    AV_DEBUG(\" There are %d residues. \\n\", vc->residue_count);\n    for(i=0;i<vc->residue_count;++i) {\n        vorbis_residue *res_setup=&vc->residues[i];\n        uint_fast8_t cascade[64];\n        uint_fast8_t high_bits;\n        uint_fast8_t low_bits;\n        res_setup->type=get_bits(gb, 16);\n        AV_DEBUG(\" %d. residue type %d \\n\", i, res_setup->type);\n        res_setup->begin=get_bits(gb, 24);\n        res_setup->end=get_bits(gb, 24);\n        res_setup->partition_size=get_bits(gb, 24)+1;\n        res_setup->classifications=get_bits(gb, 6)+1;\n        res_setup->classbook=get_bits(gb, 8);\n        if (res_setup->classbook>=vc->codebook_count) {\n            av_log(vc->avccontext, AV_LOG_ERROR, \"classbook value %d out of range. \\n\", res_setup->classbook);\n        AV_DEBUG(\"    begin %d end %d part.size %d classif.s %d classbook %d \\n\", res_setup->begin, res_setup->end, res_setup->partition_size,\n          res_setup->classifications, res_setup->classbook);\n        for(j=0;j<res_setup->classifications;++j) {\n            high_bits=0;\n            low_bits=get_bits(gb, 3);\n            if (get_bits1(gb)) {\n                high_bits=get_bits(gb, 5);\n            cascade[j]=(high_bits<<3)+low_bits;\n            AV_DEBUG(\"     %d class casscade depth: %d \\n\", j, ilog(cascade[j]));\n        res_setup->maxpass=0;\n        for(j=0;j<res_setup->classifications;++j) {\n            for(k=0;k<8;++k) {\n                if (cascade[j]&(1<<k)) {\n                    int bits=get_bits(gb, 8);\n                    if (bits>=vc->codebook_count) {\n                        av_log(vc->avccontext, AV_LOG_ERROR, \"book value %d out of range. \\n\", bits);\n                    res_setup->books[j][k]=bits;\n                    AV_DEBUG(\"     %d class casscade depth %d book: %d \\n\", j, k, res_setup->books[j][k]);\n                    if (k>res_setup->maxpass) {\n                        res_setup->maxpass=k;\n                } else {\n                    res_setup->books[j][k]=-1;\n    return 0;", "idx": 22620}
{"project": "FFmpeg", "commit_id": "a33c7dd21362a694692d0dc30fdbffae5a5d837e", "target": 1, "func": "static int flashsv_decode_block(AVCodecContext *avctx, AVPacket *avpkt,\n\n                                GetBitContext *gb, int block_size,\n\n                                int width, int height, int x_pos, int y_pos,\n\n                                int blk_idx)\n\n{\n\n    struct FlashSVContext *s = avctx->priv_data;\n\n    uint8_t *line = s->tmpblock;\n\n    int k;\n\n    int ret = inflateReset(&s->zstream);\n\n    if (ret != Z_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Inflate reset error: %d\\n\", ret);\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n    if (s->zlibprime_curr || s->zlibprime_prev) {\n\n        ret = flashsv2_prime(s,\n\n                             s->blocks[blk_idx].pos,\n\n                             s->blocks[blk_idx].size);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n    s->zstream.next_in   = avpkt->data + get_bits_count(gb) / 8;\n\n    s->zstream.avail_in  = block_size;\n\n    s->zstream.next_out  = s->tmpblock;\n\n    s->zstream.avail_out = s->block_size * 3;\n\n    ret = inflate(&s->zstream, Z_FINISH);\n\n    if (ret == Z_DATA_ERROR) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Zlib resync occurred\\n\");\n\n        inflateSync(&s->zstream);\n\n        ret = inflate(&s->zstream, Z_FINISH);\n\n    }\n\n\n\n    if (ret != Z_OK && ret != Z_STREAM_END) {\n\n        //return -1;\n\n    }\n\n\n\n    if (s->is_keyframe) {\n\n        s->blocks[blk_idx].pos  = s->keyframedata + (get_bits_count(gb) / 8);\n\n        s->blocks[blk_idx].size = block_size;\n\n    }\n\n\n\n    y_pos += s->diff_start;\n\n\n\n    if (!s->color_depth) {\n\n        /* Flash Screen Video stores the image upside down, so copy\n\n         * lines to destination in reverse order. */\n\n        for (k = 1; k <= s->diff_height; k++) {\n\n            memcpy(s->frame->data[0] + x_pos * 3 +\n\n                   (s->image_height - y_pos - k) * s->frame->linesize[0],\n\n                   line, width * 3);\n\n            /* advance source pointer to next line */\n\n            line += width * 3;\n\n        }\n\n    } else {\n\n        /* hybrid 15-bit/palette mode */\n\n        decode_hybrid(s->tmpblock, s->frame->data[0],\n\n                      s->image_height - (y_pos + 1 + s->diff_height),\n\n                      x_pos, s->diff_height, width,\n\n                      s->frame->linesize[0], s->pal);\n\n    }\n\n    skip_bits_long(gb, 8 * block_size); /* skip the consumed bits */\n\n    return 0;\n\n}\n", "idx": 22621}
{"project": "FFmpeg", "commit_id": "87ecefdab0097537c5c30014e57b19113ab05eee", "target": 1, "func": "static void evaluate_utility_inc(elbg_data *elbg)\n\n{\n\n    int i, inc=0;\n\n\n\n    for (i=0; i < elbg->numCB; i++) {\n\n        if (elbg->numCB*elbg->utility[i] > elbg->error)\n\n            inc += elbg->utility[i];\n\n        elbg->utility_inc[i] = inc;\n\n    }\n\n}\n", "idx": 22626}
{"project": "FFmpeg", "commit_id": "a4f6be86d67ae30d494fbe8a470bc32b715d75a9", "target": 0, "func": "static av_always_inline void filter_mb_dir(H264Context *h, int mb_x, int mb_y, uint8_t *img_y, uint8_t *img_cb, uint8_t *img_cr, unsigned int linesize, unsigned int uvlinesize, int mb_xy, int mb_type, int mvy_limit, int first_vertical_edge_done, int chroma, int chroma444, int dir) {\n\n    MpegEncContext * const s = &h->s;\n\n    int edge;\n\n    int chroma_qp_avg[2];\n\n    const int mbm_xy = dir == 0 ? mb_xy -1 : h->top_mb_xy;\n\n    const int mbm_type = dir == 0 ? h->left_type[LTOP] : h->top_type;\n\n\n\n    // how often to recheck mv-based bS when iterating between edges\n\n    static const uint8_t mask_edge_tab[2][8]={{0,3,3,3,1,1,1,1},\n\n                                              {0,3,1,1,3,3,3,3}};\n\n    const int mask_edge = mask_edge_tab[dir][(mb_type>>3)&7];\n\n    const int edges = mask_edge== 3 && !(h->cbp&15) ? 1 : 4;\n\n\n\n    // how often to recheck mv-based bS when iterating along each edge\n\n    const int mask_par0 = mb_type & (MB_TYPE_16x16 | (MB_TYPE_8x16 >> dir));\n\n\n\n    if(mbm_type && !first_vertical_edge_done){\n\n\n\n        if (FRAME_MBAFF && (dir == 1) && ((mb_y&1) == 0)\n\n            && IS_INTERLACED(mbm_type&~mb_type)\n\n            ) {\n\n            // This is a special case in the norm where the filtering must\n\n            // be done twice (one each of the field) even if we are in a\n\n            // frame macroblock.\n\n            //\n\n            unsigned int tmp_linesize   = 2 *   linesize;\n\n            unsigned int tmp_uvlinesize = 2 * uvlinesize;\n\n            int mbn_xy = mb_xy - 2 * s->mb_stride;\n\n            int j;\n\n\n\n            for(j=0; j<2; j++, mbn_xy += s->mb_stride){\n\n                DECLARE_ALIGNED(8, int16_t, bS)[4];\n\n                int qp;\n\n                if (IS_INTRA(mb_type | s->current_picture.f.mb_type[mbn_xy])) {\n\n                    AV_WN64A(bS, 0x0003000300030003ULL);\n\n                } else {\n\n                    if (!CABAC && IS_8x8DCT(s->current_picture.f.mb_type[mbn_xy])) {\n\n                        bS[0]= 1+((h->cbp_table[mbn_xy] & 0x4000)||h->non_zero_count_cache[scan8[0]+0]);\n\n                        bS[1]= 1+((h->cbp_table[mbn_xy] & 0x4000)||h->non_zero_count_cache[scan8[0]+1]);\n\n                        bS[2]= 1+((h->cbp_table[mbn_xy] & 0x8000)||h->non_zero_count_cache[scan8[0]+2]);\n\n                        bS[3]= 1+((h->cbp_table[mbn_xy] & 0x8000)||h->non_zero_count_cache[scan8[0]+3]);\n\n                    }else{\n\n                    const uint8_t *mbn_nnz = h->non_zero_count[mbn_xy] + 3*4;\n\n                    int i;\n\n                    for( i = 0; i < 4; i++ ) {\n\n                        bS[i] = 1 + !!(h->non_zero_count_cache[scan8[0]+i] | mbn_nnz[i]);\n\n                    }\n\n                    }\n\n                }\n\n                // Do not use s->qscale as luma quantizer because it has not the same\n\n                // value in IPCM macroblocks.\n\n                qp = (s->current_picture.f.qscale_table[mb_xy] + s->current_picture.f.qscale_table[mbn_xy] + 1) >> 1;\n\n                tprintf(s->avctx, \"filter mb:%d/%d dir:%d edge:%d, QPy:%d ls:%d uvls:%d\", mb_x, mb_y, dir, edge, qp, tmp_linesize, tmp_uvlinesize);\n\n                { int i; for (i = 0; i < 4; i++) tprintf(s->avctx, \" bS[%d]:%d\", i, bS[i]); tprintf(s->avctx, \"\\n\"); }\n\n                filter_mb_edgeh( &img_y[j*linesize], tmp_linesize, bS, qp, h );\n\n                chroma_qp_avg[0] = (h->chroma_qp[0] + get_chroma_qp(h, 0, s->current_picture.f.qscale_table[mbn_xy]) + 1) >> 1;\n\n                chroma_qp_avg[1] = (h->chroma_qp[1] + get_chroma_qp(h, 1, s->current_picture.f.qscale_table[mbn_xy]) + 1) >> 1;\n\n                if (chroma) {\n\n                    if (chroma444) {\n\n                        filter_mb_edgeh (&img_cb[j*uvlinesize], tmp_uvlinesize, bS, chroma_qp_avg[0], h);\n\n                        filter_mb_edgeh (&img_cr[j*uvlinesize], tmp_uvlinesize, bS, chroma_qp_avg[1], h);\n\n                    } else {\n\n                        filter_mb_edgech(&img_cb[j*uvlinesize], tmp_uvlinesize, bS, chroma_qp_avg[0], h);\n\n                        filter_mb_edgech(&img_cr[j*uvlinesize], tmp_uvlinesize, bS, chroma_qp_avg[1], h);\n\n                    }\n\n                }\n\n            }\n\n        }else{\n\n            DECLARE_ALIGNED(8, int16_t, bS)[4];\n\n            int qp;\n\n\n\n            if( IS_INTRA(mb_type|mbm_type)) {\n\n                AV_WN64A(bS, 0x0003000300030003ULL);\n\n                if (   (!IS_INTERLACED(mb_type|mbm_type))\n\n                    || ((FRAME_MBAFF || (s->picture_structure != PICT_FRAME)) && (dir == 0))\n\n                )\n\n                    AV_WN64A(bS, 0x0004000400040004ULL);\n\n            } else {\n\n                int i;\n\n                int mv_done;\n\n\n\n                if( dir && FRAME_MBAFF && IS_INTERLACED(mb_type ^ mbm_type)) {\n\n                    AV_WN64A(bS, 0x0001000100010001ULL);\n\n                    mv_done = 1;\n\n                }\n\n                else if( mask_par0 && ((mbm_type & (MB_TYPE_16x16 | (MB_TYPE_8x16 >> dir)))) ) {\n\n                    int b_idx= 8 + 4;\n\n                    int bn_idx= b_idx - (dir ? 8:1);\n\n\n\n                    bS[0] = bS[1] = bS[2] = bS[3] = check_mv(h, 8 + 4, bn_idx, mvy_limit);\n\n                    mv_done = 1;\n\n                }\n\n                else\n\n                    mv_done = 0;\n\n\n\n                for( i = 0; i < 4; i++ ) {\n\n                    int x = dir == 0 ? 0 : i;\n\n                    int y = dir == 0 ? i    : 0;\n\n                    int b_idx= 8 + 4 + x + 8*y;\n\n                    int bn_idx= b_idx - (dir ? 8:1);\n\n\n\n                    if( h->non_zero_count_cache[b_idx] |\n\n                        h->non_zero_count_cache[bn_idx] ) {\n\n                        bS[i] = 2;\n\n                    }\n\n                    else if(!mv_done)\n\n                    {\n\n                        bS[i] = check_mv(h, b_idx, bn_idx, mvy_limit);\n\n                    }\n\n                }\n\n            }\n\n\n\n            /* Filter edge */\n\n            // Do not use s->qscale as luma quantizer because it has not the same\n\n            // value in IPCM macroblocks.\n\n            if(bS[0]+bS[1]+bS[2]+bS[3]){\n\n                qp = (s->current_picture.f.qscale_table[mb_xy] + s->current_picture.f.qscale_table[mbm_xy] + 1) >> 1;\n\n                //tprintf(s->avctx, \"filter mb:%d/%d dir:%d edge:%d, QPy:%d, QPc:%d, QPcn:%d\\n\", mb_x, mb_y, dir, edge, qp, h->chroma_qp[0], s->current_picture.qscale_table[mbn_xy]);\n\n                tprintf(s->avctx, \"filter mb:%d/%d dir:%d edge:%d, QPy:%d ls:%d uvls:%d\", mb_x, mb_y, dir, edge, qp, linesize, uvlinesize);\n\n                //{ int i; for (i = 0; i < 4; i++) tprintf(s->avctx, \" bS[%d]:%d\", i, bS[i]); tprintf(s->avctx, \"\\n\"); }\n\n                chroma_qp_avg[0] = (h->chroma_qp[0] + get_chroma_qp(h, 0, s->current_picture.f.qscale_table[mbm_xy]) + 1) >> 1;\n\n                chroma_qp_avg[1] = (h->chroma_qp[1] + get_chroma_qp(h, 1, s->current_picture.f.qscale_table[mbm_xy]) + 1) >> 1;\n\n                if( dir == 0 ) {\n\n                    filter_mb_edgev( &img_y[0], linesize, bS, qp, h );\n\n                    if (chroma) {\n\n                        if (chroma444) {\n\n                            filter_mb_edgev ( &img_cb[0], uvlinesize, bS, chroma_qp_avg[0], h);\n\n                            filter_mb_edgev ( &img_cr[0], uvlinesize, bS, chroma_qp_avg[1], h);\n\n                        } else {\n\n                            filter_mb_edgecv( &img_cb[0], uvlinesize, bS, chroma_qp_avg[0], h);\n\n                            filter_mb_edgecv( &img_cr[0], uvlinesize, bS, chroma_qp_avg[1], h);\n\n                        }\n\n                    }\n\n                } else {\n\n                    filter_mb_edgeh( &img_y[0], linesize, bS, qp, h );\n\n                    if (chroma) {\n\n                        if (chroma444) {\n\n                            filter_mb_edgeh ( &img_cb[0], uvlinesize, bS, chroma_qp_avg[0], h);\n\n                            filter_mb_edgeh ( &img_cr[0], uvlinesize, bS, chroma_qp_avg[1], h);\n\n                        } else {\n\n                            filter_mb_edgech( &img_cb[0], uvlinesize, bS, chroma_qp_avg[0], h);\n\n                            filter_mb_edgech( &img_cr[0], uvlinesize, bS, chroma_qp_avg[1], h);\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    /* Calculate bS */\n\n    for( edge = 1; edge < edges; edge++ ) {\n\n        DECLARE_ALIGNED(8, int16_t, bS)[4];\n\n        int qp;\n\n\n\n        if( IS_8x8DCT(mb_type & (edge<<24)) ) // (edge&1) && IS_8x8DCT(mb_type)\n\n            continue;\n\n\n\n        if( IS_INTRA(mb_type)) {\n\n            AV_WN64A(bS, 0x0003000300030003ULL);\n\n        } else {\n\n            int i;\n\n            int mv_done;\n\n\n\n            if( edge & mask_edge ) {\n\n                AV_ZERO64(bS);\n\n                mv_done = 1;\n\n            }\n\n            else if( mask_par0 ) {\n\n                int b_idx= 8 + 4 + edge * (dir ? 8:1);\n\n                int bn_idx= b_idx - (dir ? 8:1);\n\n\n\n                bS[0] = bS[1] = bS[2] = bS[3] = check_mv(h, b_idx, bn_idx, mvy_limit);\n\n                mv_done = 1;\n\n            }\n\n            else\n\n                mv_done = 0;\n\n\n\n            for( i = 0; i < 4; i++ ) {\n\n                int x = dir == 0 ? edge : i;\n\n                int y = dir == 0 ? i    : edge;\n\n                int b_idx= 8 + 4 + x + 8*y;\n\n                int bn_idx= b_idx - (dir ? 8:1);\n\n\n\n                if( h->non_zero_count_cache[b_idx] |\n\n                    h->non_zero_count_cache[bn_idx] ) {\n\n                    bS[i] = 2;\n\n                }\n\n                else if(!mv_done)\n\n                {\n\n                    bS[i] = check_mv(h, b_idx, bn_idx, mvy_limit);\n\n                }\n\n            }\n\n\n\n            if(bS[0]+bS[1]+bS[2]+bS[3] == 0)\n\n                continue;\n\n        }\n\n\n\n        /* Filter edge */\n\n        // Do not use s->qscale as luma quantizer because it has not the same\n\n        // value in IPCM macroblocks.\n\n        qp = s->current_picture.f.qscale_table[mb_xy];\n\n        //tprintf(s->avctx, \"filter mb:%d/%d dir:%d edge:%d, QPy:%d, QPc:%d, QPcn:%d\\n\", mb_x, mb_y, dir, edge, qp, h->chroma_qp[0], s->current_picture.qscale_table[mbn_xy]);\n\n        tprintf(s->avctx, \"filter mb:%d/%d dir:%d edge:%d, QPy:%d ls:%d uvls:%d\", mb_x, mb_y, dir, edge, qp, linesize, uvlinesize);\n\n        //{ int i; for (i = 0; i < 4; i++) tprintf(s->avctx, \" bS[%d]:%d\", i, bS[i]); tprintf(s->avctx, \"\\n\"); }\n\n        if( dir == 0 ) {\n\n            filter_mb_edgev( &img_y[4*edge << h->pixel_shift], linesize, bS, qp, h );\n\n            if (chroma) {\n\n                if (chroma444) {\n\n                    filter_mb_edgev ( &img_cb[4*edge << h->pixel_shift], uvlinesize, bS, h->chroma_qp[0], h);\n\n                    filter_mb_edgev ( &img_cr[4*edge << h->pixel_shift], uvlinesize, bS, h->chroma_qp[1], h);\n\n                } else if( (edge&1) == 0 ) {\n\n                    filter_mb_edgecv( &img_cb[2*edge << h->pixel_shift], uvlinesize, bS, h->chroma_qp[0], h);\n\n                    filter_mb_edgecv( &img_cr[2*edge << h->pixel_shift], uvlinesize, bS, h->chroma_qp[1], h);\n\n                }\n\n            }\n\n        } else {\n\n            filter_mb_edgeh( &img_y[4*edge*linesize], linesize, bS, qp, h );\n\n            if (chroma) {\n\n                if (chroma444) {\n\n                    filter_mb_edgeh ( &img_cb[4*edge*uvlinesize], uvlinesize, bS, h->chroma_qp[0], h);\n\n                    filter_mb_edgeh ( &img_cr[4*edge*uvlinesize], uvlinesize, bS, h->chroma_qp[1], h);\n\n                } else if( (edge&1) == 0 ) {\n\n                    filter_mb_edgech( &img_cb[2*edge*uvlinesize], uvlinesize, bS, h->chroma_qp[0], h);\n\n                    filter_mb_edgech( &img_cr[2*edge*uvlinesize], uvlinesize, bS, h->chroma_qp[1], h);\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 22628}
{"project": "FFmpeg", "commit_id": "9f61abc8111c7c43f49ca012e957a108b9cc7610", "target": 0, "func": "static int mov_read_close(AVFormatContext *s)\n\n{\n\n    MOVContext *mov = s->priv_data;\n\n    int i, j;\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVStream *st = s->streams[i];\n\n        MOVStreamContext *sc = st->priv_data;\n\n\n\n        av_freep(&sc->ctts_data);\n\n        for (j = 0; j < sc->drefs_count; j++) {\n\n            av_freep(&sc->drefs[j].path);\n\n            av_freep(&sc->drefs[j].dir);\n\n        }\n\n        av_freep(&sc->drefs);\n\n        if (sc->pb && sc->pb != s->pb)\n\n            avio_close(sc->pb);\n\n\n\n        av_freep(&sc->chunk_offsets);\n\n        av_freep(&sc->stsc_data);\n\n        av_freep(&sc->sample_sizes);\n\n        av_freep(&sc->keyframes);\n\n        av_freep(&sc->stts_data);\n\n        av_freep(&sc->stps_data);\n\n        av_freep(&sc->rap_group);\n\n        av_freep(&sc->display_matrix);\n\n    }\n\n\n\n    if (mov->dv_demux) {\n\n        avformat_free_context(mov->dv_fctx);\n\n        mov->dv_fctx = NULL;\n\n    }\n\n\n\n    av_freep(&mov->trex_data);\n\n\n\n    return 0;\n\n}\n", "idx": 22629}
{"project": "FFmpeg", "commit_id": "1dc42050185d63c1de5d16146fbaee92640af187", "target": 0, "func": "static int color_request_frame(AVFilterLink *link)\n\n{\n\n    ColorContext *color = link->src->priv;\n\n    AVFilterBufferRef *picref = ff_get_video_buffer(link, AV_PERM_WRITE, color->w, color->h);\n\n    int ret;\n\n\n\n    picref->video->pixel_aspect = (AVRational) {1, 1};\n\n    picref->pts                 = color->pts++;\n\n    picref->pos                 = -1;\n\n\n\n    ret = ff_start_frame(link, avfilter_ref_buffer(picref, ~0));\n\n    if (ret < 0)\n\n        goto fail;\n\n\n\n    ff_draw_rectangle(picref->data, picref->linesize,\n\n                      color->line, color->line_step, color->hsub, color->vsub,\n\n                      0, 0, color->w, color->h);\n\n    ret = ff_draw_slice(link, 0, color->h, 1);\n\n    if (ret < 0)\n\n        goto fail;\n\n\n\n    ret = ff_end_frame(link);\n\n\n\nfail:\n\n    avfilter_unref_buffer(picref);\n\n\n\n    return ret;\n\n}\n", "idx": 22630}
{"project": "FFmpeg", "commit_id": "26f5e1469f9469ab30e16d6311bdbcbc7e0790cf", "target": 0, "func": "static int mov_read_stsd(MOVContext *c, ByteIOContext *pb, MOV_atom_t atom)\n\n{\n\n    AVStream *st = c->fc->streams[c->fc->nb_streams-1];\n\n    MOVStreamContext *sc = st->priv_data;\n\n    int j, entries, pseudo_stream_id;\n\n\n\n    get_byte(pb); /* version */\n\n    get_be24(pb); /* flags */\n\n\n\n    entries = get_be32(pb);\n\n\n\n    for(pseudo_stream_id=0; pseudo_stream_id<entries; pseudo_stream_id++) {\n\n        //Parsing Sample description table\n\n        enum CodecID id;\n\n        int dref_id;\n\n        MOV_atom_t a = { 0, 0, 0 };\n\n        offset_t start_pos = url_ftell(pb);\n\n        int size = get_be32(pb); /* size */\n\n        uint32_t format = get_le32(pb); /* data format */\n\n\n\n        get_be32(pb); /* reserved */\n\n        get_be16(pb); /* reserved */\n\n        dref_id = get_be16(pb);\n\n\n\n        if (st->codec->codec_tag &&\n\n            st->codec->codec_tag != format &&\n\n            (c->fc->video_codec_id ? codec_get_id(codec_movvideo_tags, format) != c->fc->video_codec_id\n\n                                   : st->codec->codec_tag != MKTAG('j','p','e','g'))\n\n           ){\n\n            /* Multiple fourcc, we skip JPEG. This is not correct, we should\n\n             * export it as a separate AVStream but this needs a few changes\n\n             * in the MOV demuxer, patch welcome. */\n\n            av_log(c->fc, AV_LOG_WARNING, \"multiple fourcc not supported\\n\");\n\n            url_fskip(pb, size - (url_ftell(pb) - start_pos));\n\n            continue;\n\n        }\n\n        sc->pseudo_stream_id = st->codec->codec_tag ? -1 : pseudo_stream_id;\n\n        sc->dref_id= dref_id;\n\n\n\n        st->codec->codec_tag = format;\n\n        id = codec_get_id(codec_movaudio_tags, format);\n\n        if (id<=0 && (format&0xFFFF) == 'm'+('s'<<8))\n\n            id = codec_get_id(codec_wav_tags, bswap_32(format)&0xFFFF);\n\n\n\n        if (st->codec->codec_type != CODEC_TYPE_VIDEO && id > 0) {\n\n            st->codec->codec_type = CODEC_TYPE_AUDIO;\n\n        } else if (st->codec->codec_type != CODEC_TYPE_AUDIO && /* do not overwrite codec type */\n\n                   format && format != MKTAG('m','p','4','s')) { /* skip old asf mpeg4 tag */\n\n            id = codec_get_id(codec_movvideo_tags, format);\n\n            if (id <= 0)\n\n                id = codec_get_id(codec_bmp_tags, format);\n\n            if (id > 0)\n\n                st->codec->codec_type = CODEC_TYPE_VIDEO;\n\n            else if(st->codec->codec_type == CODEC_TYPE_DATA){\n\n                id = codec_get_id(ff_codec_movsubtitle_tags, format);\n\n                if(id > 0)\n\n                    st->codec->codec_type = CODEC_TYPE_SUBTITLE;\n\n            }\n\n        }\n\n\n\n        dprintf(c->fc, \"size=%d 4CC= %c%c%c%c codec_type=%d\\n\", size,\n\n                (format >> 0) & 0xff, (format >> 8) & 0xff, (format >> 16) & 0xff,\n\n                (format >> 24) & 0xff, st->codec->codec_type);\n\n\n\n        if(st->codec->codec_type==CODEC_TYPE_VIDEO) {\n\n            uint8_t codec_name[32];\n\n            unsigned int color_depth;\n\n            int color_greyscale;\n\n\n\n            st->codec->codec_id = id;\n\n            get_be16(pb); /* version */\n\n            get_be16(pb); /* revision level */\n\n            get_be32(pb); /* vendor */\n\n            get_be32(pb); /* temporal quality */\n\n            get_be32(pb); /* spatial quality */\n\n\n\n            st->codec->width = get_be16(pb); /* width */\n\n            st->codec->height = get_be16(pb); /* height */\n\n\n\n            get_be32(pb); /* horiz resolution */\n\n            get_be32(pb); /* vert resolution */\n\n            get_be32(pb); /* data size, always 0 */\n\n            get_be16(pb); /* frames per samples */\n\n\n\n            get_buffer(pb, codec_name, 32); /* codec name, pascal string */\n\n            if (codec_name[0] <= 31) {\n\n                memcpy(st->codec->codec_name, &codec_name[1],codec_name[0]);\n\n                st->codec->codec_name[codec_name[0]] = 0;\n\n            }\n\n\n\n            st->codec->bits_per_coded_sample = get_be16(pb); /* depth */\n\n            st->codec->color_table_id = get_be16(pb); /* colortable id */\n\n            dprintf(c->fc, \"depth %d, ctab id %d\\n\",\n\n                   st->codec->bits_per_coded_sample, st->codec->color_table_id);\n\n            /* figure out the palette situation */\n\n            color_depth = st->codec->bits_per_coded_sample & 0x1F;\n\n            color_greyscale = st->codec->bits_per_coded_sample & 0x20;\n\n\n\n            /* if the depth is 2, 4, or 8 bpp, file is palettized */\n\n            if ((color_depth == 2) || (color_depth == 4) ||\n\n                (color_depth == 8)) {\n\n                /* for palette traversal */\n\n                unsigned int color_start, color_count, color_end;\n\n                unsigned char r, g, b;\n\n\n\n                if (color_greyscale) {\n\n                    int color_index, color_dec;\n\n                    /* compute the greyscale palette */\n\n                    st->codec->bits_per_coded_sample = color_depth;\n\n                    color_count = 1 << color_depth;\n\n                    color_index = 255;\n\n                    color_dec = 256 / (color_count - 1);\n\n                    for (j = 0; j < color_count; j++) {\n\n                        r = g = b = color_index;\n\n                        c->palette_control.palette[j] =\n\n                            (r << 16) | (g << 8) | (b);\n\n                        color_index -= color_dec;\n\n                        if (color_index < 0)\n\n                            color_index = 0;\n\n                    }\n\n                } else if (st->codec->color_table_id) {\n\n                    const uint8_t *color_table;\n\n                    /* if flag bit 3 is set, use the default palette */\n\n                    color_count = 1 << color_depth;\n\n                    if (color_depth == 2)\n\n                        color_table = ff_qt_default_palette_4;\n\n                    else if (color_depth == 4)\n\n                        color_table = ff_qt_default_palette_16;\n\n                    else\n\n                        color_table = ff_qt_default_palette_256;\n\n\n\n                    for (j = 0; j < color_count; j++) {\n\n                        r = color_table[j * 4 + 0];\n\n                        g = color_table[j * 4 + 1];\n\n                        b = color_table[j * 4 + 2];\n\n                        c->palette_control.palette[j] =\n\n                            (r << 16) | (g << 8) | (b);\n\n                    }\n\n                } else {\n\n                    /* load the palette from the file */\n\n                    color_start = get_be32(pb);\n\n                    color_count = get_be16(pb);\n\n                    color_end = get_be16(pb);\n\n                    if ((color_start <= 255) &&\n\n                        (color_end <= 255)) {\n\n                        for (j = color_start; j <= color_end; j++) {\n\n                            /* each R, G, or B component is 16 bits;\n\n                             * only use the top 8 bits; skip alpha bytes\n\n                             * up front */\n\n                            get_byte(pb);\n\n                            get_byte(pb);\n\n                            r = get_byte(pb);\n\n                            get_byte(pb);\n\n                            g = get_byte(pb);\n\n                            get_byte(pb);\n\n                            b = get_byte(pb);\n\n                            get_byte(pb);\n\n                            c->palette_control.palette[j] =\n\n                                (r << 16) | (g << 8) | (b);\n\n                        }\n\n                    }\n\n                }\n\n                st->codec->palctrl = &c->palette_control;\n\n                st->codec->palctrl->palette_changed = 1;\n\n            } else\n\n                st->codec->palctrl = NULL;\n\n        } else if(st->codec->codec_type==CODEC_TYPE_AUDIO) {\n\n            int bits_per_sample, flags;\n\n            uint16_t version = get_be16(pb);\n\n\n\n            st->codec->codec_id = id;\n\n            get_be16(pb); /* revision level */\n\n            get_be32(pb); /* vendor */\n\n\n\n            st->codec->channels = get_be16(pb);             /* channel count */\n\n            dprintf(c->fc, \"audio channels %d\\n\", st->codec->channels);\n\n            st->codec->bits_per_coded_sample = get_be16(pb);      /* sample size */\n\n\n\n            sc->audio_cid = get_be16(pb);\n\n            get_be16(pb); /* packet size = 0 */\n\n\n\n            st->codec->sample_rate = ((get_be32(pb) >> 16));\n\n\n\n            //Read QT version 1 fields. In version 0 these do not exist.\n\n            dprintf(c->fc, \"version =%d, isom =%d\\n\",version,c->isom);\n\n            if(!c->isom) {\n\n                if(version==1) {\n\n                    sc->samples_per_frame = get_be32(pb);\n\n                    get_be32(pb); /* bytes per packet */\n\n                    sc->bytes_per_frame = get_be32(pb);\n\n                    get_be32(pb); /* bytes per sample */\n\n                } else if(version==2) {\n\n                    get_be32(pb); /* sizeof struct only */\n\n                    st->codec->sample_rate = av_int2dbl(get_be64(pb)); /* float 64 */\n\n                    st->codec->channels = get_be32(pb);\n\n                    get_be32(pb); /* always 0x7F000000 */\n\n                    st->codec->bits_per_coded_sample = get_be32(pb); /* bits per channel if sound is uncompressed */\n\n                    flags = get_be32(pb); /* lcpm format specific flag */\n\n                    sc->bytes_per_frame = get_be32(pb); /* bytes per audio packet if constant */\n\n                    sc->samples_per_frame = get_be32(pb); /* lpcm frames per audio packet if constant */\n\n                    if (format == MKTAG('l','p','c','m'))\n\n                        st->codec->codec_id = mov_get_lpcm_codec_id(st->codec->bits_per_coded_sample, flags);\n\n                }\n\n            }\n\n\n\n            switch (st->codec->codec_id) {\n\n            case CODEC_ID_PCM_S8:\n\n            case CODEC_ID_PCM_U8:\n\n                if (st->codec->bits_per_coded_sample == 16)\n\n                    st->codec->codec_id = CODEC_ID_PCM_S16BE;\n\n                break;\n\n            case CODEC_ID_PCM_S16LE:\n\n            case CODEC_ID_PCM_S16BE:\n\n                if (st->codec->bits_per_coded_sample == 8)\n\n                    st->codec->codec_id = CODEC_ID_PCM_S8;\n\n                else if (st->codec->bits_per_coded_sample == 24)\n\n                    st->codec->codec_id =\n\n                        st->codec->codec_id == CODEC_ID_PCM_S16BE ?\n\n                        CODEC_ID_PCM_S24BE : CODEC_ID_PCM_S24LE;\n\n                break;\n\n            /* set values for old format before stsd version 1 appeared */\n\n            case CODEC_ID_MACE3:\n\n                sc->samples_per_frame = 6;\n\n                sc->bytes_per_frame = 2*st->codec->channels;\n\n                break;\n\n            case CODEC_ID_MACE6:\n\n                sc->samples_per_frame = 6;\n\n                sc->bytes_per_frame = 1*st->codec->channels;\n\n                break;\n\n            case CODEC_ID_ADPCM_IMA_QT:\n\n                sc->samples_per_frame = 64;\n\n                sc->bytes_per_frame = 34*st->codec->channels;\n\n                break;\n\n            case CODEC_ID_GSM:\n\n                sc->samples_per_frame = 160;\n\n                sc->bytes_per_frame = 33;\n\n                break;\n\n            default:\n\n                break;\n\n            }\n\n\n\n            bits_per_sample = av_get_bits_per_sample(st->codec->codec_id);\n\n            if (bits_per_sample) {\n\n                st->codec->bits_per_coded_sample = bits_per_sample;\n\n                sc->sample_size = (bits_per_sample >> 3) * st->codec->channels;\n\n            }\n\n        } else if(st->codec->codec_type==CODEC_TYPE_SUBTITLE){\n\n            st->codec->codec_id= id;\n\n        } else {\n\n            /* other codec type, just skip (rtp, mp4s, tmcd ...) */\n\n            url_fskip(pb, size - (url_ftell(pb) - start_pos));\n\n        }\n\n        /* this will read extra atoms at the end (wave, alac, damr, avcC, SMI ...) */\n\n        a.size = size - (url_ftell(pb) - start_pos);\n\n        if (a.size > 8) {\n\n            if (mov_read_default(c, pb, a) < 0)\n\n                return -1;\n\n        } else if (a.size > 0)\n\n            url_fskip(pb, a.size);\n\n    }\n\n\n\n    if(st->codec->codec_type==CODEC_TYPE_AUDIO && st->codec->sample_rate==0 && sc->time_scale>1)\n\n        st->codec->sample_rate= sc->time_scale;\n\n\n\n    /* special codec parameters handling */\n\n    switch (st->codec->codec_id) {\n\n#ifdef CONFIG_DV_DEMUXER\n\n    case CODEC_ID_DVAUDIO:\n\n        c->dv_fctx = av_alloc_format_context();\n\n        c->dv_demux = dv_init_demux(c->dv_fctx);\n\n        if (!c->dv_demux) {\n\n            av_log(c->fc, AV_LOG_ERROR, \"dv demux context init error\\n\");\n\n            return -1;\n\n        }\n\n        sc->dv_audio_container = 1;\n\n        st->codec->codec_id = CODEC_ID_PCM_S16LE;\n\n        break;\n\n#endif\n\n    /* no ifdef since parameters are always those */\n\n    case CODEC_ID_AMR_WB:\n\n        st->codec->sample_rate= 16000;\n\n        st->codec->channels= 1; /* really needed */\n\n        break;\n\n    case CODEC_ID_QCELP:\n\n    case CODEC_ID_AMR_NB:\n\n        st->codec->frame_size= sc->samples_per_frame;\n\n        st->codec->sample_rate= 8000;\n\n        st->codec->channels= 1; /* really needed */\n\n        break;\n\n    case CODEC_ID_MP2:\n\n    case CODEC_ID_MP3:\n\n        st->codec->codec_type = CODEC_TYPE_AUDIO; /* force type after stsd for m1a hdlr */\n\n        st->need_parsing = AVSTREAM_PARSE_FULL;\n\n        break;\n\n    case CODEC_ID_GSM:\n\n    case CODEC_ID_ADPCM_MS:\n\n    case CODEC_ID_ADPCM_IMA_WAV:\n\n        st->codec->block_align = sc->bytes_per_frame;\n\n        break;\n\n    case CODEC_ID_ALAC:\n\n        if (st->codec->extradata_size == 36)\n\n            st->codec->frame_size = AV_RB32((st->codec->extradata+12));\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22631}
{"project": "FFmpeg", "commit_id": "a7a17e3f1915ce69b787dc58c5d8dba0910fc0a4", "target": 0, "func": "void ff_hevc_deblocking_boundary_strengths(HEVCContext *s, int x0, int y0,\n\n                                           int log2_trafo_size)\n\n{\n\n    HEVCLocalContext *lc = &s->HEVClc;\n\n    MvField *tab_mvf     = s->ref->tab_mvf;\n\n    int log2_min_pu_size = s->sps->log2_min_pu_size;\n\n    int log2_min_tu_size = s->sps->log2_min_tb_size;\n\n    int min_pu_width     = s->sps->min_pu_width;\n\n    int min_tu_width     = s->sps->min_tb_width;\n\n    int is_intra = tab_mvf[(y0 >> log2_min_pu_size) * min_pu_width +\n\n                           (x0 >> log2_min_pu_size)].is_intra;\n\n    int i, j, bs;\n\n\n\n    if (y0 > 0 && (y0 & 7) == 0) {\n\n        int yp_pu = (y0 - 1) >> log2_min_pu_size;\n\n        int yq_pu =  y0      >> log2_min_pu_size;\n\n        int yp_tu = (y0 - 1) >> log2_min_tu_size;\n\n        int yq_tu =  y0      >> log2_min_tu_size;\n\n\n\n        for (i = 0; i < (1 << log2_trafo_size); i += 4) {\n\n            int x_pu = (x0 + i) >> log2_min_pu_size;\n\n            int x_tu = (x0 + i) >> log2_min_tu_size;\n\n            MvField *top  = &tab_mvf[yp_pu * min_pu_width + x_pu];\n\n            MvField *curr = &tab_mvf[yq_pu * min_pu_width + x_pu];\n\n            uint8_t top_cbf_luma  = s->cbf_luma[yp_tu * min_tu_width + x_tu];\n\n            uint8_t curr_cbf_luma = s->cbf_luma[yq_tu * min_tu_width + x_tu];\n\n            RefPicList *top_refPicList = ff_hevc_get_ref_list(s, s->ref,\n\n                                                              x0 + i, y0 - 1);\n\n\n\n            bs = boundary_strength(s, curr, curr_cbf_luma,\n\n                                   top, top_cbf_luma, top_refPicList, 1);\n\n            if (!s->sh.slice_loop_filter_across_slices_enabled_flag &&\n\n                lc->boundary_flags & BOUNDARY_UPPER_SLICE &&\n\n                (y0 % (1 << s->sps->log2_ctb_size)) == 0)\n\n                bs = 0;\n\n            else if (!s->pps->loop_filter_across_tiles_enabled_flag &&\n\n                     lc->boundary_flags & BOUNDARY_UPPER_TILE &&\n\n                     (y0 % (1 << s->sps->log2_ctb_size)) == 0)\n\n                bs = 0;\n\n            if (bs)\n\n                s->horizontal_bs[((x0 + i) + y0 * s->bs_width) >> 2] = bs;\n\n        }\n\n    }\n\n\n\n    // bs for TU internal horizontal PU boundaries\n\n    if (log2_trafo_size > s->sps->log2_min_pu_size && !is_intra)\n\n        for (j = 8; j < (1 << log2_trafo_size); j += 8) {\n\n            int yp_pu = (y0 + j - 1) >> log2_min_pu_size;\n\n            int yq_pu = (y0 + j)     >> log2_min_pu_size;\n\n            int yp_tu = (y0 + j - 1) >> log2_min_tu_size;\n\n            int yq_tu = (y0 + j)     >> log2_min_tu_size;\n\n\n\n            for (i = 0; i < (1 << log2_trafo_size); i += 4) {\n\n                int x_pu = (x0 + i) >> log2_min_pu_size;\n\n                int x_tu = (x0 + i) >> log2_min_tu_size;\n\n                MvField *top  = &tab_mvf[yp_pu * min_pu_width + x_pu];\n\n                MvField *curr = &tab_mvf[yq_pu * min_pu_width + x_pu];\n\n                uint8_t top_cbf_luma  = s->cbf_luma[yp_tu * min_tu_width + x_tu];\n\n                uint8_t curr_cbf_luma = s->cbf_luma[yq_tu * min_tu_width + x_tu];\n\n                RefPicList *top_refPicList = ff_hevc_get_ref_list(s, s->ref,\n\n                                                                  x0 + i,\n\n                                                                  y0 + j - 1);\n\n\n\n                bs = boundary_strength(s, curr, curr_cbf_luma,\n\n                                       top, top_cbf_luma, top_refPicList, 0);\n\n                if (bs)\n\n                    s->horizontal_bs[((x0 + i) + (y0 + j) * s->bs_width) >> 2] = bs;\n\n            }\n\n        }\n\n\n\n    // bs for vertical TU boundaries\n\n    if (x0 > 0 && (x0 & 7) == 0) {\n\n        int xp_pu = (x0 - 1) >> log2_min_pu_size;\n\n        int xq_pu =  x0      >> log2_min_pu_size;\n\n        int xp_tu = (x0 - 1) >> log2_min_tu_size;\n\n        int xq_tu =  x0      >> log2_min_tu_size;\n\n\n\n        for (i = 0; i < (1 << log2_trafo_size); i += 4) {\n\n            int y_pu      = (y0 + i) >> log2_min_pu_size;\n\n            int y_tu      = (y0 + i) >> log2_min_tu_size;\n\n            MvField *left = &tab_mvf[y_pu * min_pu_width + xp_pu];\n\n            MvField *curr = &tab_mvf[y_pu * min_pu_width + xq_pu];\n\n\n\n            uint8_t left_cbf_luma = s->cbf_luma[y_tu * min_tu_width + xp_tu];\n\n            uint8_t curr_cbf_luma = s->cbf_luma[y_tu * min_tu_width + xq_tu];\n\n            RefPicList *left_refPicList = ff_hevc_get_ref_list(s, s->ref,\n\n                                                               x0 - 1, y0 + i);\n\n\n\n            bs = boundary_strength(s, curr, curr_cbf_luma,\n\n                                   left, left_cbf_luma, left_refPicList, 1);\n\n            if (!s->sh.slice_loop_filter_across_slices_enabled_flag &&\n\n                lc->boundary_flags & BOUNDARY_LEFT_SLICE &&\n\n                (x0 % (1 << s->sps->log2_ctb_size)) == 0)\n\n                bs = 0;\n\n            else if (!s->pps->loop_filter_across_tiles_enabled_flag &&\n\n                     lc->boundary_flags & BOUNDARY_LEFT_TILE &&\n\n                     (x0 % (1 << s->sps->log2_ctb_size)) == 0)\n\n                bs = 0;\n\n            if (bs)\n\n                s->vertical_bs[(x0 >> 3) + ((y0 + i) >> 2) * s->bs_width] = bs;\n\n        }\n\n    }\n\n\n\n    // bs for TU internal vertical PU boundaries\n\n    if (log2_trafo_size > log2_min_pu_size && !is_intra)\n\n        for (j = 0; j < (1 << log2_trafo_size); j += 4) {\n\n            int y_pu = (y0 + j) >> log2_min_pu_size;\n\n            int y_tu = (y0 + j) >> log2_min_tu_size;\n\n\n\n            for (i = 8; i < (1 << log2_trafo_size); i += 8) {\n\n                int xp_pu = (x0 + i - 1) >> log2_min_pu_size;\n\n                int xq_pu = (x0 + i)     >> log2_min_pu_size;\n\n                int xp_tu = (x0 + i - 1) >> log2_min_tu_size;\n\n                int xq_tu = (x0 + i)     >> log2_min_tu_size;\n\n                MvField *left = &tab_mvf[y_pu * min_pu_width + xp_pu];\n\n                MvField *curr = &tab_mvf[y_pu * min_pu_width + xq_pu];\n\n                uint8_t left_cbf_luma = s->cbf_luma[y_tu * min_tu_width + xp_tu];\n\n                uint8_t curr_cbf_luma = s->cbf_luma[y_tu * min_tu_width + xq_tu];\n\n                RefPicList *left_refPicList = ff_hevc_get_ref_list(s, s->ref,\n\n                                                                   x0 + i - 1,\n\n                                                                   y0 + j);\n\n\n\n                bs = boundary_strength(s, curr, curr_cbf_luma,\n\n                                       left, left_cbf_luma, left_refPicList, 0);\n\n                if (bs)\n\n                    s->vertical_bs[((x0 + i) >> 3) + ((y0 + j) >> 2) * s->bs_width] = bs;\n\n            }\n\n        }\n\n}\n", "idx": 22632}
{"project": "FFmpeg", "commit_id": "4bb1070c154e49d35805fbcdac9c9e92f702ef96", "target": 0, "func": "int ffv1_init_slice_state(FFV1Context *f, FFV1Context *fs)\n\n{\n\n    int j;\n\n\n\n    fs->plane_count  = f->plane_count;\n\n    fs->transparency = f->transparency;\n\n    for (j = 0; j < f->plane_count; j++) {\n\n        PlaneContext *const p = &fs->plane[j];\n\n\n\n        if (fs->ac) {\n\n            if (!p->state)\n\n                p->state = av_malloc(CONTEXT_SIZE * p->context_count *\n\n                                     sizeof(uint8_t));\n\n            if (!p->state)\n\n                return AVERROR(ENOMEM);\n\n        } else {\n\n            if (!p->vlc_state)\n\n                p->vlc_state = av_malloc(p->context_count * sizeof(VlcState));\n\n            if (!p->vlc_state)\n\n                return AVERROR(ENOMEM);\n\n        }\n\n    }\n\n\n\n    if (fs->ac > 1) {\n\n        //FIXME only redo if state_transition changed\n\n        for (j = 1; j < 256; j++) {\n\n            fs->c.one_state[j]        = f->state_transition[j];\n\n            fs->c.zero_state[256 - j] = 256 - fs->c.one_state[j];\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22633}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int vdpau_vc1_start_frame(AVCodecContext *avctx,\n\n                                 const uint8_t *buffer, uint32_t size)\n\n{\n\n    VC1Context * const v  = avctx->priv_data;\n\n    MpegEncContext * const s = &v->s;\n\n    Picture *pic          = s->current_picture_ptr;\n\n    struct vdpau_picture_context *pic_ctx = pic->hwaccel_picture_private;\n\n    VdpPictureInfoVC1 *info = &pic_ctx->info.vc1;\n\n    VdpVideoSurface ref;\n\n\n\n    /*  fill LvPictureInfoVC1 struct */\n\n    info->forward_reference  = VDP_INVALID_HANDLE;\n\n    info->backward_reference = VDP_INVALID_HANDLE;\n\n\n\n    switch (s->pict_type) {\n\n    case AV_PICTURE_TYPE_B:\n\n        ref = ff_vdpau_get_surface_id(&s->next_picture.f);\n\n        assert(ref != VDP_INVALID_HANDLE);\n\n        info->backward_reference = ref;\n\n        /* fall-through */\n\n    case AV_PICTURE_TYPE_P:\n\n        ref = ff_vdpau_get_surface_id(&s->last_picture.f);\n\n        assert(ref != VDP_INVALID_HANDLE);\n\n        info->forward_reference  = ref;\n\n    }\n\n\n\n    info->slice_count       = 0;\n\n    if (v->bi_type)\n\n        info->picture_type  = 4;\n\n    else\n\n        info->picture_type  = s->pict_type - 1 + s->pict_type / 3;\n\n\n\n    info->frame_coding_mode = v->fcm ? (v->fcm + 1) : 0;\n\n    info->postprocflag      = v->postprocflag;\n\n    info->pulldown          = v->broadcast;\n\n    info->interlace         = v->interlace;\n\n    info->tfcntrflag        = v->tfcntrflag;\n\n    info->finterpflag       = v->finterpflag;\n\n    info->psf               = v->psf;\n\n    info->dquant            = v->dquant;\n\n    info->panscan_flag      = v->panscanflag;\n\n    info->refdist_flag      = v->refdist_flag;\n\n    info->quantizer         = v->quantizer_mode;\n\n    info->extended_mv       = v->extended_mv;\n\n    info->extended_dmv      = v->extended_dmv;\n\n    info->overlap           = v->overlap;\n\n    info->vstransform       = v->vstransform;\n\n    info->loopfilter        = v->s.loop_filter;\n\n    info->fastuvmc          = v->fastuvmc;\n\n    info->range_mapy_flag   = v->range_mapy_flag;\n\n    info->range_mapy        = v->range_mapy;\n\n    info->range_mapuv_flag  = v->range_mapuv_flag;\n\n    info->range_mapuv       = v->range_mapuv;\n\n    /* Specific to simple/main profile only */\n\n    info->multires          = v->multires;\n\n    info->syncmarker        = v->resync_marker;\n\n    info->rangered          = v->rangered | (v->rangeredfrm << 1);\n\n    info->maxbframes        = v->s.max_b_frames;\n\n    info->deblockEnable     = v->postprocflag & 1;\n\n    info->pquant            = v->pq;\n\n\n\n    return ff_vdpau_common_start_frame(pic_ctx, buffer, size);\n\n}\n", "idx": 22634}
{"project": "FFmpeg", "commit_id": "8e5f093c2cf13eab3d68d893bf8f30c56ba4e733", "target": 1, "func": "static int cinvideo_decode_frame(AVCodecContext *avctx,\n\n                                 void *data, int *data_size,\n\n                                 AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    CinVideoContext *cin = avctx->priv_data;\n\n    int i, y, palette_type, palette_colors_count, bitmap_frame_type, bitmap_frame_size;\n\n\n\n    cin->frame.buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE;\n\n    if (avctx->reget_buffer(avctx, &cin->frame)) {\n\n        av_log(cin->avctx, AV_LOG_ERROR, \"delphinecinvideo: reget_buffer() failed to allocate a frame\\n\");\n\n        return -1;\n\n    }\n\n\n\n    palette_type = buf[0];\n\n    palette_colors_count = AV_RL16(buf+1);\n\n    bitmap_frame_type = buf[3];\n\n    buf += 4;\n\n\n\n    bitmap_frame_size = buf_size - 4;\n\n\n\n    /* handle palette */\n\n\n\n    if (palette_type == 0) {\n\n        for (i = 0; i < palette_colors_count; ++i) {\n\n            cin->palette[i] = bytestream_get_le24(&buf);\n\n            bitmap_frame_size -= 3;\n\n        }\n\n    } else {\n\n        for (i = 0; i < palette_colors_count; ++i) {\n\n            cin->palette[buf[0]] = AV_RL24(buf+1);\n\n            buf += 4;\n\n            bitmap_frame_size -= 4;\n\n        }\n\n    }\n\n    memcpy(cin->frame.data[1], cin->palette, sizeof(cin->palette));\n\n    cin->frame.palette_has_changed = 1;\n\n\n\n    /* note: the decoding routines below assumes that surface.width = surface.pitch */\n\n    switch (bitmap_frame_type) {\n\n    case 9:\n\n        cin_decode_rle(buf, bitmap_frame_size,\n\n          cin->bitmap_table[CIN_CUR_BMP], cin->bitmap_size);\n\n        break;\n\n    case 34:\n\n        cin_decode_rle(buf, bitmap_frame_size,\n\n          cin->bitmap_table[CIN_CUR_BMP], cin->bitmap_size);\n\n        cin_apply_delta_data(cin->bitmap_table[CIN_PRE_BMP],\n\n          cin->bitmap_table[CIN_CUR_BMP], cin->bitmap_size);\n\n        break;\n\n    case 35:\n\n        cin_decode_huffman(buf, bitmap_frame_size,\n\n          cin->bitmap_table[CIN_INT_BMP], cin->bitmap_size);\n\n        cin_decode_rle(cin->bitmap_table[CIN_INT_BMP], bitmap_frame_size,\n\n          cin->bitmap_table[CIN_CUR_BMP], cin->bitmap_size);\n\n        break;\n\n    case 36:\n\n        bitmap_frame_size = cin_decode_huffman(buf, bitmap_frame_size,\n\n          cin->bitmap_table[CIN_INT_BMP], cin->bitmap_size);\n\n        cin_decode_rle(cin->bitmap_table[CIN_INT_BMP], bitmap_frame_size,\n\n          cin->bitmap_table[CIN_CUR_BMP], cin->bitmap_size);\n\n        cin_apply_delta_data(cin->bitmap_table[CIN_PRE_BMP],\n\n          cin->bitmap_table[CIN_CUR_BMP], cin->bitmap_size);\n\n        break;\n\n    case 37:\n\n        cin_decode_huffman(buf, bitmap_frame_size,\n\n          cin->bitmap_table[CIN_CUR_BMP], cin->bitmap_size);\n\n        break;\n\n    case 38:\n\n        cin_decode_lzss(buf, bitmap_frame_size,\n\n          cin->bitmap_table[CIN_CUR_BMP], cin->bitmap_size);\n\n        break;\n\n    case 39:\n\n        cin_decode_lzss(buf, bitmap_frame_size,\n\n          cin->bitmap_table[CIN_CUR_BMP], cin->bitmap_size);\n\n        cin_apply_delta_data(cin->bitmap_table[CIN_PRE_BMP],\n\n          cin->bitmap_table[CIN_CUR_BMP], cin->bitmap_size);\n\n        break;\n\n    }\n\n\n\n    for (y = 0; y < cin->avctx->height; ++y)\n\n        memcpy(cin->frame.data[0] + (cin->avctx->height - 1 - y) * cin->frame.linesize[0],\n\n          cin->bitmap_table[CIN_CUR_BMP] + y * cin->avctx->width,\n\n          cin->avctx->width);\n\n\n\n    FFSWAP(uint8_t *, cin->bitmap_table[CIN_CUR_BMP], cin->bitmap_table[CIN_PRE_BMP]);\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame *)data = cin->frame;\n\n\n\n    return buf_size;\n\n}", "idx": 22635}
{"project": "FFmpeg", "commit_id": "62702eebded6c6341d214405812a981f80e46ea2", "target": 1, "func": "static void RENAME(decode_rgb_frame)(FFV1Context *s, uint8_t *src[3], int w, int h, int stride[3])\n\n{\n\n    int x, y, p;\n\n    TYPE *sample[4][2];\n\n    int lbd    = s->avctx->bits_per_raw_sample <= 8;\n\n    int bits   = s->avctx->bits_per_raw_sample > 0 ? s->avctx->bits_per_raw_sample : 8;\n\n    int offset = 1 << bits;\n\n\n\n    for (x = 0; x < 4; x++) {\n\n        sample[x][0] = RENAME(s->sample_buffer) +  x * 2      * (w + 6) + 3;\n\n        sample[x][1] = RENAME(s->sample_buffer) + (x * 2 + 1) * (w + 6) + 3;\n\n    }\n\n\n\n    s->run_index = 0;\n\n\n\n    memset(RENAME(s->sample_buffer), 0, 8 * (w + 6) * sizeof(*RENAME(s->sample_buffer)));\n\n\n\n    for (y = 0; y < h; y++) {\n\n        for (p = 0; p < 3 + s->transparency; p++) {\n\n            TYPE *temp = sample[p][0]; // FIXME: try a normal buffer\n\n\n\n            sample[p][0] = sample[p][1];\n\n            sample[p][1] = temp;\n\n\n\n            sample[p][1][-1]= sample[p][0][0  ];\n\n            sample[p][0][ w]= sample[p][0][w-1];\n\n            if (lbd && s->slice_coding_mode == 0)\n\n                RENAME(decode_line)(s, w, sample[p], (p + 1)/2, 9);\n\n            else\n\n                RENAME(decode_line)(s, w, sample[p], (p + 1)/2, bits + (s->slice_coding_mode != 1));\n\n        }\n\n        for (x = 0; x < w; x++) {\n\n            int g = sample[0][1][x];\n\n            int b = sample[1][1][x];\n\n            int r = sample[2][1][x];\n\n            int a = sample[3][1][x];\n\n\n\n            if (s->slice_coding_mode != 1) {\n\n                b -= offset;\n\n                r -= offset;\n\n                g -= (b * s->slice_rct_by_coef + r * s->slice_rct_ry_coef) >> 2;\n\n                b += g;\n\n                r += g;\n\n            }\n\n\n\n            if (lbd)\n\n                *((uint32_t*)(src[0] + x*4 + stride[0]*y)) = b + (g<<8) + (r<<16) + (a<<24);\n\n            else if (sizeof(TYPE) == 4) {\n\n                *((uint16_t*)(src[0] + x*2 + stride[0]*y)) = g;\n\n                *((uint16_t*)(src[1] + x*2 + stride[1]*y)) = b;\n\n                *((uint16_t*)(src[2] + x*2 + stride[2]*y)) = r;\n\n            } else {\n\n                *((uint16_t*)(src[0] + x*2 + stride[0]*y)) = b;\n\n                *((uint16_t*)(src[1] + x*2 + stride[1]*y)) = g;\n\n                *((uint16_t*)(src[2] + x*2 + stride[2]*y)) = r;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 22636}
{"project": "FFmpeg", "commit_id": "36583d23bdbe31e8845d3ca9162bce33fef6e48c", "target": 0, "func": "void ff_af_queue_remove(AudioFrameQueue *afq, int nb_samples, int64_t *pts,\n\n                        int *duration)\n\n{\n\n    int64_t out_pts = AV_NOPTS_VALUE;\n\n    int removed_samples = 0;\n\n\n\n#ifdef DEBUG\n\n    ff_af_queue_log_state(afq);\n\n#endif\n\n\n\n    /* get output pts from the next frame or generated pts */\n\n    if (afq->frame_queue) {\n\n        if (afq->frame_queue->pts != AV_NOPTS_VALUE)\n\n            out_pts = afq->frame_queue->pts - afq->remaining_delay;\n\n    } else {\n\n        if (afq->next_pts != AV_NOPTS_VALUE)\n\n            out_pts = afq->next_pts - afq->remaining_delay;\n\n    }\n\n    if (pts) {\n\n        if (out_pts != AV_NOPTS_VALUE)\n\n            *pts = ff_samples_to_time_base(afq->avctx, out_pts);\n\n        else\n\n            *pts = AV_NOPTS_VALUE;\n\n    }\n\n\n\n    /* if the delay is larger than the packet duration, we use up delay samples\n\n       for the output packet and leave all frames in the queue */\n\n    if (afq->remaining_delay >= nb_samples) {\n\n        removed_samples      += nb_samples;\n\n        afq->remaining_delay -= nb_samples;\n\n    }\n\n    /* remove frames from the queue until we have enough to cover the\n\n       requested number of samples or until the queue is empty */\n\n    while (removed_samples < nb_samples && afq->frame_queue) {\n\n        removed_samples += afq->frame_queue->duration;\n\n        delete_next_frame(afq);\n\n    }\n\n    afq->remaining_samples -= removed_samples;\n\n\n\n    /* if there are no frames left and we have room for more samples, use\n\n       any remaining delay samples */\n\n    if (removed_samples < nb_samples && afq->remaining_samples > 0) {\n\n        int add_samples = FFMIN(afq->remaining_samples,\n\n                                nb_samples - removed_samples);\n\n        removed_samples        += add_samples;\n\n        afq->remaining_samples -= add_samples;\n\n    }\n\n    if (removed_samples > nb_samples)\n\n        av_log(afq->avctx, AV_LOG_WARNING, \"frame_size is too large\\n\");\n\n    if (duration)\n\n        *duration = ff_samples_to_time_base(afq->avctx, removed_samples);\n\n}\n", "idx": 22637}
{"project": "FFmpeg", "commit_id": "c5c2060cf597c8eb5989ca4ba68a1eaeb59f7cdb", "target": 0, "func": "QPEL_H264(put_,        PUT_OP, mmxext)\n\nQPEL_H264(avg_, AVG_MMXEXT_OP, mmxext)\n\nQPEL_H264_V_XMM(put_,       PUT_OP, sse2)\n\nQPEL_H264_V_XMM(avg_,AVG_MMXEXT_OP, sse2)\n\nQPEL_H264_HV_XMM(put_,       PUT_OP, sse2)\n\nQPEL_H264_HV_XMM(avg_,AVG_MMXEXT_OP, sse2)\n\nQPEL_H264_H_XMM(put_,       PUT_OP, ssse3)\n\nQPEL_H264_H_XMM(avg_,AVG_MMXEXT_OP, ssse3)\n\nQPEL_H264_HV_XMM(put_,       PUT_OP, ssse3)\n\nQPEL_H264_HV_XMM(avg_,AVG_MMXEXT_OP, ssse3)\n\n#undef PAVGB\n\n\n\nH264_MC_4816(mmxext)\n\nH264_MC_816(H264_MC_V, sse2)\n\nH264_MC_816(H264_MC_HV, sse2)\n\nH264_MC_816(H264_MC_H, ssse3)\n\nH264_MC_816(H264_MC_HV, ssse3)\n\n\n\n\n\n//10bit\n\n#define LUMA_MC_OP(OP, NUM, DEPTH, TYPE, OPT) \\\n\nvoid ff_ ## OP ## _h264_qpel ## NUM ## _ ## TYPE ## _ ## DEPTH ## _ ## OPT \\\n\n    (uint8_t *dst, uint8_t *src, int stride);\n\n\n\n#define LUMA_MC_ALL(DEPTH, TYPE, OPT) \\\n\n    LUMA_MC_OP(put,  4, DEPTH, TYPE, OPT) \\\n\n    LUMA_MC_OP(avg,  4, DEPTH, TYPE, OPT) \\\n\n    LUMA_MC_OP(put,  8, DEPTH, TYPE, OPT) \\\n\n    LUMA_MC_OP(avg,  8, DEPTH, TYPE, OPT) \\\n\n    LUMA_MC_OP(put, 16, DEPTH, TYPE, OPT) \\\n\n    LUMA_MC_OP(avg, 16, DEPTH, TYPE, OPT)\n\n\n\n#define LUMA_MC_816(DEPTH, TYPE, OPT) \\\n\n    LUMA_MC_OP(put,  8, DEPTH, TYPE, OPT) \\\n\n    LUMA_MC_OP(avg,  8, DEPTH, TYPE, OPT) \\\n\n    LUMA_MC_OP(put, 16, DEPTH, TYPE, OPT) \\\n\n    LUMA_MC_OP(avg, 16, DEPTH, TYPE, OPT)\n\n\n\nLUMA_MC_ALL(10, mc00, mmxext)\n\nLUMA_MC_ALL(10, mc10, mmxext)\n\nLUMA_MC_ALL(10, mc20, mmxext)\n\nLUMA_MC_ALL(10, mc30, mmxext)\n\nLUMA_MC_ALL(10, mc01, mmxext)\n\nLUMA_MC_ALL(10, mc11, mmxext)\n\nLUMA_MC_ALL(10, mc21, mmxext)\n\nLUMA_MC_ALL(10, mc31, mmxext)\n\nLUMA_MC_ALL(10, mc02, mmxext)\n\nLUMA_MC_ALL(10, mc12, mmxext)\n\nLUMA_MC_ALL(10, mc22, mmxext)\n\nLUMA_MC_ALL(10, mc32, mmxext)\n\nLUMA_MC_ALL(10, mc03, mmxext)\n\nLUMA_MC_ALL(10, mc13, mmxext)\n\nLUMA_MC_ALL(10, mc23, mmxext)\n\nLUMA_MC_ALL(10, mc33, mmxext)\n\n\n\nLUMA_MC_816(10, mc00, sse2)\n\nLUMA_MC_816(10, mc10, sse2)\n\nLUMA_MC_816(10, mc10, sse2_cache64)\n\nLUMA_MC_816(10, mc10, ssse3_cache64)\n\nLUMA_MC_816(10, mc20, sse2)\n\nLUMA_MC_816(10, mc20, sse2_cache64)\n\nLUMA_MC_816(10, mc20, ssse3_cache64)\n\nLUMA_MC_816(10, mc30, sse2)\n\nLUMA_MC_816(10, mc30, sse2_cache64)\n\nLUMA_MC_816(10, mc30, ssse3_cache64)\n\nLUMA_MC_816(10, mc01, sse2)\n\nLUMA_MC_816(10, mc11, sse2)\n\nLUMA_MC_816(10, mc21, sse2)\n\nLUMA_MC_816(10, mc31, sse2)\n\nLUMA_MC_816(10, mc02, sse2)\n\nLUMA_MC_816(10, mc12, sse2)\n\nLUMA_MC_816(10, mc22, sse2)\n\nLUMA_MC_816(10, mc32, sse2)\n\nLUMA_MC_816(10, mc03, sse2)\n\nLUMA_MC_816(10, mc13, sse2)\n\nLUMA_MC_816(10, mc23, sse2)\n\nLUMA_MC_816(10, mc33, sse2)\n\n\n\n#define QPEL16_OPMC(OP, MC, MMX)\\\n\nvoid ff_ ## OP ## _h264_qpel16_ ## MC ## _10_ ## MMX(uint8_t *dst, uint8_t *src, int stride){\\\n\n    ff_ ## OP ## _h264_qpel8_ ## MC ## _10_ ## MMX(dst   , src   , stride);\\\n\n    ff_ ## OP ## _h264_qpel8_ ## MC ## _10_ ## MMX(dst+16, src+16, stride);\\\n\n    src += 8*stride;\\\n\n    dst += 8*stride;\\\n\n    ff_ ## OP ## _h264_qpel8_ ## MC ## _10_ ## MMX(dst   , src   , stride);\\\n\n    ff_ ## OP ## _h264_qpel8_ ## MC ## _10_ ## MMX(dst+16, src+16, stride);\\\n\n}\n\n\n\n#define QPEL16_OP(MC, MMX)\\\n\nQPEL16_OPMC(put, MC, MMX)\\\n\nQPEL16_OPMC(avg, MC, MMX)\n\n\n\n#define QPEL16(MMX)\\\n\nQPEL16_OP(mc00, MMX)\\\n\nQPEL16_OP(mc01, MMX)\\\n\nQPEL16_OP(mc02, MMX)\\\n\nQPEL16_OP(mc03, MMX)\\\n\nQPEL16_OP(mc10, MMX)\\\n\nQPEL16_OP(mc11, MMX)\\\n\nQPEL16_OP(mc12, MMX)\\\n\nQPEL16_OP(mc13, MMX)\\\n\nQPEL16_OP(mc20, MMX)\\\n\nQPEL16_OP(mc21, MMX)\\\n\nQPEL16_OP(mc22, MMX)\\\n\nQPEL16_OP(mc23, MMX)\\\n\nQPEL16_OP(mc30, MMX)\\\n\nQPEL16_OP(mc31, MMX)\\\n\nQPEL16_OP(mc32, MMX)\\\n\nQPEL16_OP(mc33, MMX)\n\n\n\n#if ARCH_X86_32 && HAVE_YASM && CONFIG_H264QPEL // ARCH_X86_64 implies SSE2+\n\nQPEL16(mmxext)\n\n#endif\n\n\n\n#endif /* HAVE_YASM */\n\n\n\n#define SET_QPEL_FUNCS(PFX, IDX, SIZE, CPU, PREFIX)                          \\\n\n    do {                                                                     \\\n\n    c->PFX ## _pixels_tab[IDX][ 0] = PREFIX ## PFX ## SIZE ## _mc00_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][ 1] = PREFIX ## PFX ## SIZE ## _mc10_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][ 2] = PREFIX ## PFX ## SIZE ## _mc20_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][ 3] = PREFIX ## PFX ## SIZE ## _mc30_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][ 4] = PREFIX ## PFX ## SIZE ## _mc01_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][ 5] = PREFIX ## PFX ## SIZE ## _mc11_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][ 6] = PREFIX ## PFX ## SIZE ## _mc21_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][ 7] = PREFIX ## PFX ## SIZE ## _mc31_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][ 8] = PREFIX ## PFX ## SIZE ## _mc02_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][ 9] = PREFIX ## PFX ## SIZE ## _mc12_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][10] = PREFIX ## PFX ## SIZE ## _mc22_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][11] = PREFIX ## PFX ## SIZE ## _mc32_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][12] = PREFIX ## PFX ## SIZE ## _mc03_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][13] = PREFIX ## PFX ## SIZE ## _mc13_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][14] = PREFIX ## PFX ## SIZE ## _mc23_ ## CPU; \\\n\n    c->PFX ## _pixels_tab[IDX][15] = PREFIX ## PFX ## SIZE ## _mc33_ ## CPU; \\\n\n    } while (0)\n\n\n\n#define H264_QPEL_FUNCS(x, y, CPU)                                                            \\\n\n    do {                                                                                      \\\n\n        c->put_h264_qpel_pixels_tab[0][x + y * 4] = put_h264_qpel16_mc ## x ## y ## _ ## CPU; \\\n\n        c->put_h264_qpel_pixels_tab[1][x + y * 4] = put_h264_qpel8_mc  ## x ## y ## _ ## CPU; \\\n\n        c->avg_h264_qpel_pixels_tab[0][x + y * 4] = avg_h264_qpel16_mc ## x ## y ## _ ## CPU; \\\n\n        c->avg_h264_qpel_pixels_tab[1][x + y * 4] = avg_h264_qpel8_mc  ## x ## y ## _ ## CPU; \\\n\n    } while (0)\n\n\n\n#define H264_QPEL_FUNCS_10(x, y, CPU)                                                               \\\n\n    do {                                                                                            \\\n\n        c->put_h264_qpel_pixels_tab[0][x + y * 4] = ff_put_h264_qpel16_mc ## x ## y ## _10_ ## CPU; \\\n\n        c->put_h264_qpel_pixels_tab[1][x + y * 4] = ff_put_h264_qpel8_mc  ## x ## y ## _10_ ## CPU; \\\n\n        c->avg_h264_qpel_pixels_tab[0][x + y * 4] = ff_avg_h264_qpel16_mc ## x ## y ## _10_ ## CPU; \\\n\n        c->avg_h264_qpel_pixels_tab[1][x + y * 4] = ff_avg_h264_qpel8_mc  ## x ## y ## _10_ ## CPU; \\\n\n    } while (0)\n\n\n\nvoid ff_h264qpel_init_x86(H264QpelContext *c, int bit_depth)\n\n{\n\n    int high_bit_depth = bit_depth > 8;\n\n    int mm_flags = av_get_cpu_flags();\n\n\n\n#if HAVE_MMXEXT_EXTERNAL\n\n    if (!high_bit_depth) {\n\n        SET_QPEL_FUNCS(put_h264_qpel, 0, 16, mmxext, );\n\n        SET_QPEL_FUNCS(put_h264_qpel, 1,  8, mmxext, );\n\n        SET_QPEL_FUNCS(put_h264_qpel, 2,  4, mmxext, );\n\n        SET_QPEL_FUNCS(avg_h264_qpel, 0, 16, mmxext, );\n\n        SET_QPEL_FUNCS(avg_h264_qpel, 1,  8, mmxext, );\n\n        SET_QPEL_FUNCS(avg_h264_qpel, 2,  4, mmxext, );\n\n    } else if (bit_depth == 10) {\n\n#if !ARCH_X86_64\n\n        SET_QPEL_FUNCS(avg_h264_qpel, 0, 16, 10_mmxext, ff_);\n\n        SET_QPEL_FUNCS(put_h264_qpel, 0, 16, 10_mmxext, ff_);\n\n        SET_QPEL_FUNCS(put_h264_qpel, 1,  8, 10_mmxext, ff_);\n\n        SET_QPEL_FUNCS(avg_h264_qpel, 1,  8, 10_mmxext, ff_);\n\n#endif\n\n        SET_QPEL_FUNCS(put_h264_qpel, 2, 4,  10_mmxext, ff_);\n\n        SET_QPEL_FUNCS(avg_h264_qpel, 2, 4,  10_mmxext, ff_);\n\n    }\n\n#endif\n\n\n\n#if HAVE_SSE2_EXTERNAL\n\n    if (!(mm_flags & AV_CPU_FLAG_SSE2SLOW) && !high_bit_depth) {\n\n        // these functions are slower than mmx on AMD, but faster on Intel\n\n        H264_QPEL_FUNCS(0, 0, sse2);\n\n    }\n\n\n\n    if (!high_bit_depth) {\n\n        H264_QPEL_FUNCS(0, 1, sse2);\n\n        H264_QPEL_FUNCS(0, 2, sse2);\n\n        H264_QPEL_FUNCS(0, 3, sse2);\n\n        H264_QPEL_FUNCS(1, 1, sse2);\n\n        H264_QPEL_FUNCS(1, 2, sse2);\n\n        H264_QPEL_FUNCS(1, 3, sse2);\n\n        H264_QPEL_FUNCS(2, 1, sse2);\n\n        H264_QPEL_FUNCS(2, 2, sse2);\n\n        H264_QPEL_FUNCS(2, 3, sse2);\n\n        H264_QPEL_FUNCS(3, 1, sse2);\n\n        H264_QPEL_FUNCS(3, 2, sse2);\n\n        H264_QPEL_FUNCS(3, 3, sse2);\n\n    }\n\n\n\n    if (bit_depth == 10) {\n\n        SET_QPEL_FUNCS(put_h264_qpel, 0, 16, 10_sse2, ff_);\n\n        SET_QPEL_FUNCS(put_h264_qpel, 1,  8, 10_sse2, ff_);\n\n        SET_QPEL_FUNCS(avg_h264_qpel, 0, 16, 10_sse2, ff_);\n\n        SET_QPEL_FUNCS(avg_h264_qpel, 1,  8, 10_sse2, ff_);\n\n        H264_QPEL_FUNCS_10(1, 0, sse2_cache64);\n\n        H264_QPEL_FUNCS_10(2, 0, sse2_cache64);\n\n        H264_QPEL_FUNCS_10(3, 0, sse2_cache64);\n\n    }\n\n#endif\n\n\n\n#if HAVE_SSSE3_EXTERNAL\n\n    if (!high_bit_depth) {\n\n        H264_QPEL_FUNCS(1, 0, ssse3);\n\n        H264_QPEL_FUNCS(1, 1, ssse3);\n\n        H264_QPEL_FUNCS(1, 2, ssse3);\n\n        H264_QPEL_FUNCS(1, 3, ssse3);\n\n        H264_QPEL_FUNCS(2, 0, ssse3);\n\n        H264_QPEL_FUNCS(2, 1, ssse3);\n\n        H264_QPEL_FUNCS(2, 2, ssse3);\n\n        H264_QPEL_FUNCS(2, 3, ssse3);\n\n        H264_QPEL_FUNCS(3, 0, ssse3);\n\n        H264_QPEL_FUNCS(3, 1, ssse3);\n\n        H264_QPEL_FUNCS(3, 2, ssse3);\n\n        H264_QPEL_FUNCS(3, 3, ssse3);\n\n    }\n\n\n\n    if (bit_depth == 10) {\n\n        H264_QPEL_FUNCS_10(1, 0, ssse3_cache64);\n\n        H264_QPEL_FUNCS_10(2, 0, ssse3_cache64);\n\n        H264_QPEL_FUNCS_10(3, 0, ssse3_cache64);\n\n    }\n\n#endif\n\n\n\n#if HAVE_AVX_EXTERNAL\n\n    if (bit_depth == 10) {\n\n        H264_QPEL_FUNCS_10(1, 0, sse2);\n\n        H264_QPEL_FUNCS_10(2, 0, sse2);\n\n        H264_QPEL_FUNCS_10(3, 0, sse2);\n\n    }\n\n#endif\n\n}\n", "idx": 22638}
{"project": "FFmpeg", "commit_id": "24d20496d2e6e1df6456c5231d892269dd1fcf38", "target": 1, "func": "static int decode_lowdelay(DiracContext *s)\n\n{\n\n    AVCodecContext *avctx = s->avctx;\n\n    int slice_x, slice_y, bufsize;\n\n    int64_t coef_buf_size, bytes = 0;\n\n    const uint8_t *buf;\n\n    DiracSlice *slices;\n\n    SliceCoeffs tmp[MAX_DWT_LEVELS];\n\n    int slice_num = 0;\n\n\n\n    if (s->slice_params_num_buf != (s->num_x * s->num_y)) {\n\n        s->slice_params_buf = av_realloc_f(s->slice_params_buf, s->num_x * s->num_y, sizeof(DiracSlice));\n\n        if (!s->slice_params_buf) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"slice params buffer allocation failure\\n\");\n\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        s->slice_params_num_buf = s->num_x * s->num_y;\n\n    }\n\n    slices = s->slice_params_buf;\n\n\n\n    /* 8 becacuse that's how much the golomb reader could overread junk data\n\n     * from another plane/slice at most, and 512 because SIMD */\n\n    coef_buf_size = subband_coeffs(s, s->num_x - 1, s->num_y - 1, 0, tmp) + 8;\n\n    coef_buf_size = (coef_buf_size << (1 + s->pshift)) + 512;\n\n\n\n    if (s->threads_num_buf != avctx->thread_count ||\n\n        s->thread_buf_size != coef_buf_size) {\n\n        s->threads_num_buf  = avctx->thread_count;\n\n        s->thread_buf_size  = coef_buf_size;\n\n        s->thread_buf       = av_realloc_f(s->thread_buf, avctx->thread_count, s->thread_buf_size);\n\n        if (!s->thread_buf) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"thread buffer allocation failure\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n    }\n\n\n\n    align_get_bits(&s->gb);\n\n    /*[DIRAC_STD] 13.5.2 Slices. slice(sx,sy) */\n\n    buf = s->gb.buffer + get_bits_count(&s->gb)/8;\n\n    bufsize = get_bits_left(&s->gb);\n\n\n\n    if (s->hq_picture) {\n\n        int i;\n\n\n\n        for (slice_y = 0; bufsize > 0 && slice_y < s->num_y; slice_y++) {\n\n            for (slice_x = 0; bufsize > 0 && slice_x < s->num_x; slice_x++) {\n\n                bytes = s->highquality.prefix_bytes + 1;\n\n                for (i = 0; i < 3; i++) {\n\n                    if (bytes <= bufsize/8)\n\n                        bytes += buf[bytes] * s->highquality.size_scaler + 1;\n\n                }\n\n                if (bytes >= INT_MAX || bytes*8 > bufsize) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"too many bytes\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                slices[slice_num].bytes   = bytes;\n\n                slices[slice_num].slice_x = slice_x;\n\n                slices[slice_num].slice_y = slice_y;\n\n                init_get_bits(&slices[slice_num].gb, buf, bufsize);\n\n                slice_num++;\n\n\n\n                buf     += bytes;\n\n                if (bufsize/8 >= bytes)\n\n                    bufsize -= bytes*8;\n\n                else\n\n                    bufsize = 0;\n\n            }\n\n        }\n\n\n\n        if (s->num_x*s->num_y != slice_num) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"too few slices\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        avctx->execute2(avctx, decode_hq_slice_row, slices, NULL, s->num_y);\n\n    } else {\n\n        for (slice_y = 0; bufsize > 0 && slice_y < s->num_y; slice_y++) {\n\n            for (slice_x = 0; bufsize > 0 && slice_x < s->num_x; slice_x++) {\n\n                bytes = (slice_num+1) * (int64_t)s->lowdelay.bytes.num / s->lowdelay.bytes.den\n\n                       - slice_num    * (int64_t)s->lowdelay.bytes.num / s->lowdelay.bytes.den;\n\n                slices[slice_num].bytes   = bytes;\n\n                slices[slice_num].slice_x = slice_x;\n\n                slices[slice_num].slice_y = slice_y;\n\n                init_get_bits(&slices[slice_num].gb, buf, bufsize);\n\n                slice_num++;\n\n\n\n                buf     += bytes;\n\n                if (bufsize/8 >= bytes)\n\n                    bufsize -= bytes*8;\n\n                else\n\n                    bufsize = 0;\n\n            }\n\n        }\n\n        avctx->execute(avctx, decode_lowdelay_slice, slices, NULL, slice_num,\n\n                       sizeof(DiracSlice)); /* [DIRAC_STD] 13.5.2 Slices */\n\n    }\n\n\n\n    if (s->dc_prediction) {\n\n        if (s->pshift) {\n\n            intra_dc_prediction_10(&s->plane[0].band[0][0]); /* [DIRAC_STD] 13.3 intra_dc_prediction() */\n\n            intra_dc_prediction_10(&s->plane[1].band[0][0]); /* [DIRAC_STD] 13.3 intra_dc_prediction() */\n\n            intra_dc_prediction_10(&s->plane[2].band[0][0]); /* [DIRAC_STD] 13.3 intra_dc_prediction() */\n\n        } else {\n\n            intra_dc_prediction_8(&s->plane[0].band[0][0]);\n\n            intra_dc_prediction_8(&s->plane[1].band[0][0]);\n\n            intra_dc_prediction_8(&s->plane[2].band[0][0]);\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}", "idx": 22643}
{"project": "FFmpeg", "commit_id": "6369a7b742bd64e7ded377fe79a5d723379ce08d", "target": 1, "func": "static int xface_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n\n                              const AVFrame *frame, int *got_packet)\n\n{\n\n    XFaceContext *xface = avctx->priv_data;\n\n    ProbRangesQueue pq = {{ 0 }, 0};\n\n    uint8_t bitmap_copy[XFACE_PIXELS];\n\n    BigInt b = {0};\n\n    int i, j, k, ret = 0;\n\n    const uint8_t *buf;\n\n    uint8_t *p;\n\n    char intbuf[XFACE_MAX_DIGITS];\n\n\n\n    if (avctx->width || avctx->height) {\n\n        if (avctx->width != XFACE_WIDTH || avctx->height != XFACE_HEIGHT) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Size value %dx%d not supported, only accepts a size of %dx%d\\n\",\n\n                   avctx->width, avctx->height, XFACE_WIDTH, XFACE_HEIGHT);\n\n            return AVERROR(EINVAL);\n\n        }\n\n    }\n\n    avctx->width  = XFACE_WIDTH;\n\n    avctx->height = XFACE_HEIGHT;\n\n\n\n    /* convert image from MONOWHITE to 1=black 0=white bitmap */\n\n    buf = frame->data[0];\n\n    i = j = 0;\n\n    do {\n\n        for (k = 0; k < 8; k++)\n\n            xface->bitmap[i++] = (buf[j]>>(7-k))&1;\n\n        if (++j == XFACE_WIDTH/8) {\n\n            buf += frame->linesize[0];\n\n            j = 0;\n\n        }\n\n    } while (i < XFACE_PIXELS);\n\n\n\n    /* create a copy of bitmap */\n\n    memcpy(bitmap_copy, xface->bitmap, XFACE_PIXELS);\n\n    ff_xface_generate_face(xface->bitmap, bitmap_copy);\n\n\n\n    encode_block(xface->bitmap,                         16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + 16,                    16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + 32,                    16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + XFACE_WIDTH * 16,      16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + XFACE_WIDTH * 16 + 16, 16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + XFACE_WIDTH * 16 + 32, 16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + XFACE_WIDTH * 32,      16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + XFACE_WIDTH * 32 + 16, 16, 16, 0, &pq);\n\n    encode_block(xface->bitmap + XFACE_WIDTH * 32 + 32, 16, 16, 0, &pq);\n\n\n\n    while (pq.prob_ranges_idx > 0)\n\n        push_integer(&b, pq.prob_ranges[--pq.prob_ranges_idx]);\n\n\n\n    /* write the inverted big integer in b to intbuf */\n\n    i = 0;\n\n\n    while (b.nb_words) {\n\n        uint8_t r;\n\n        ff_big_div(&b, XFACE_PRINTS, &r);\n\n\n        intbuf[i++] = r + XFACE_FIRST_PRINT;\n\n    }\n\n\n\n    if ((ret = ff_alloc_packet2(avctx, pkt, i+2)) < 0)\n\n        return ret;\n\n\n\n    /* revert the number, and close the buffer */\n\n    p = pkt->data;\n\n    while (--i >= 0)\n\n        *(p++) = intbuf[i];\n\n    *(p++) = '\\n';\n\n    *(p++) = 0;\n\n\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n\n    *got_packet = 1;\n\n\n\n    return 0;\n\n}", "idx": 22644}
{"project": "FFmpeg", "commit_id": "b44a55ad2d182dc5dce09609badfb6dcb575e632", "target": 1, "func": "static int mov_text_decode_frame(AVCodecContext *avctx,\n\n                            void *data, int *got_sub_ptr, AVPacket *avpkt)\n\n{\n\n    AVSubtitle *sub = data;\n\n    int ret, ts_start, ts_end;\n\n    AVBPrint buf;\n\n    char *ptr = avpkt->data;\n\n    char *end;\n\n    //char *ptr_temp;\n\n    int text_length, tsmb_type, style_entries, tsmb_size;\n\n    int **style_start = {0,};\n\n    int **style_end = {0,};\n\n    int **style_flags = {0,};\n\n    const uint8_t *tsmb;\n\n    int index, i;\n\n    int *flag;\n\n    int *style_pos;\n\n\n\n    if (!ptr || avpkt->size < 2)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    /*\n\n     * A packet of size two with value zero is an empty subtitle\n\n     * used to mark the end of the previous non-empty subtitle.\n\n     * We can just drop them here as we have duration information\n\n     * already. If the value is non-zero, then it's technically a\n\n     * bad packet.\n\n     */\n\n    if (avpkt->size == 2)\n\n        return AV_RB16(ptr) == 0 ? 0 : AVERROR_INVALIDDATA;\n\n\n\n    /*\n\n     * The first two bytes of the packet are the length of the text string\n\n     * In complex cases, there are style descriptors appended to the string\n\n     * so we can't just assume the packet size is the string size.\n\n     */\n\n    text_length = AV_RB16(ptr);\n\n    end = ptr + FFMIN(2 + text_length, avpkt->size);\n\n    ptr += 2;\n\n\n\n    ts_start = av_rescale_q(avpkt->pts,\n\n                            avctx->time_base,\n\n                            (AVRational){1,100});\n\n    ts_end   = av_rescale_q(avpkt->pts + avpkt->duration,\n\n                            avctx->time_base,\n\n                            (AVRational){1,100});\n\n\n\n    tsmb_size = 0;\n\n    // Note that the spec recommends lines be no longer than 2048 characters.\n\n    av_bprint_init(&buf, 0, AV_BPRINT_SIZE_UNLIMITED);\n\n    if (text_length + 2 != avpkt->size) {\n\n        while (text_length + 2 + tsmb_size < avpkt->size)  {\n\n            tsmb = ptr + text_length + tsmb_size;\n\n            tsmb_size = AV_RB32(tsmb);\n\n            tsmb += 4;\n\n            tsmb_type = AV_RB32(tsmb);\n\n            tsmb += 4;\n\n\n\n            if (tsmb_type == MKBETAG('s','t','y','l')) {\n\n                style_entries = AV_RB16(tsmb);\n\n                tsmb += 2;\n\n\n\n                for(i = 0; i < style_entries; i++) {\n\n                    style_pos = av_malloc(4);\n\n                    *style_pos = AV_RB16(tsmb);\n\n                    index = i;\n\n                    av_dynarray_add(&style_start, &index, style_pos);\n\n                    tsmb += 2;\n\n                    style_pos = av_malloc(4);\n\n                    *style_pos = AV_RB16(tsmb);\n\n                    index = i;\n\n                    av_dynarray_add(&style_end, &index, style_pos);\n\n                    tsmb += 2;\n\n                    // fontID = AV_RB16(tsmb);\n\n                    tsmb += 2;\n\n                    flag = av_malloc(4);\n\n                    *flag = AV_RB8(tsmb);\n\n                    index = i;\n\n                    av_dynarray_add(&style_flags, &index, flag);\n\n                    //fontsize=AV_RB8(tsmb);\n\n                    tsmb += 2;\n\n                    // text-color-rgba\n\n                    tsmb += 4;\n\n                }\n\n                text_to_ass(&buf, ptr, end, style_start, style_end, style_flags, style_entries);\n\n                av_freep(&style_start);\n\n                av_freep(&style_end);\n\n                av_freep(&style_flags);\n\n            }\n\n        }\n\n    } else\n\n        text_to_ass(&buf, ptr, end, NULL, NULL, 0, 0);\n\n\n\n    ret = ff_ass_add_rect_bprint(sub, &buf, ts_start, ts_end - ts_start);\n\n    av_bprint_finalize(&buf, NULL);\n\n    if (ret < 0)\n\n        return ret;\n\n    *got_sub_ptr = sub->num_rects > 0;\n\n    return avpkt->size;\n\n}\n", "idx": 22645}
{"project": "FFmpeg", "commit_id": "9a162146ca6cc12ef7ad4a15164349482885962c", "target": 1, "func": "av_cold void ff_snow_common_end(SnowContext *s)\n\n{\n\n    int plane_index, level, orientation, i;\n\n\n\n    av_freep(&s->spatial_dwt_buffer);\n\n    av_freep(&s->temp_dwt_buffer);\n\n    av_freep(&s->spatial_idwt_buffer);\n\n    av_freep(&s->temp_idwt_buffer);\n\n    av_freep(&s->run_buffer);\n\n\n\n    s->m.me.temp= NULL;\n\n    av_freep(&s->m.me.scratchpad);\n\n    av_freep(&s->m.me.map);\n\n    av_freep(&s->m.me.score_map);\n\n    av_freep(&s->m.obmc_scratchpad);\n\n\n\n    av_freep(&s->block);\n\n    av_freep(&s->scratchbuf);\n\n    av_freep(&s->emu_edge_buffer);\n\n\n\n    for(i=0; i<MAX_REF_FRAMES; i++){\n\n        av_freep(&s->ref_mvs[i]);\n\n        av_freep(&s->ref_scores[i]);\n\n        if(s->last_picture[i]->data[0]) {\n\n            av_assert0(s->last_picture[i]->data[0] != s->current_picture->data[0]);\n\n        }\n\n        av_frame_free(&s->last_picture[i]);\n\n    }\n\n\n\n    for(plane_index=0; plane_index < s->nb_planes; plane_index++){\n\n        for(level=s->spatial_decomposition_count-1; level>=0; level--){\n\n            for(orientation=level ? 1 : 0; orientation<4; orientation++){\n\n                SubBand *b= &s->plane[plane_index].band[level][orientation];\n\n\n\n                av_freep(&b->x_coeff);\n\n            }\n\n        }\n\n    }\n\n    av_frame_free(&s->mconly_picture);\n\n    av_frame_free(&s->current_picture);\n\n}\n", "idx": 22646}
{"project": "FFmpeg", "commit_id": "fad9f495c07be2d990620f5000de075ba2cf1cbd", "target": 0, "func": "static int decode_frame(AVCodecContext * avctx,\n\n\t\t\tvoid *data, int *data_size,\n\n\t\t\tUINT8 * buf, int buf_size)\n\n{\n\n    MPADecodeContext *s = avctx->priv_data;\n\n    UINT32 header;\n\n    UINT8 *buf_ptr;\n\n    int len, out_size;\n\n    short *out_samples = data;\n\n\n\n    *data_size = 0;\n\n    buf_ptr = buf;\n\n    while (buf_size > 0) {\n\n\tlen = s->inbuf_ptr - s->inbuf;\n\n\tif (s->frame_size == 0) {\n\n            /* special case for next header for first frame in free\n\n               format case (XXX: find a simpler method) */\n\n            if (s->free_format_next_header != 0) {\n\n                s->inbuf[0] = s->free_format_next_header >> 24;\n\n                s->inbuf[1] = s->free_format_next_header >> 16;\n\n                s->inbuf[2] = s->free_format_next_header >> 8;\n\n                s->inbuf[3] = s->free_format_next_header;\n\n                s->inbuf_ptr = s->inbuf + 4;\n\n                s->free_format_next_header = 0;\n\n                goto got_header;\n\n            }\n\n\t    /* no header seen : find one. We need at least HEADER_SIZE\n\n               bytes to parse it */\n\n\t    len = HEADER_SIZE - len;\n\n\t    if (len > buf_size)\n\n\t\tlen = buf_size;\n\n\t    if (len > 0) {\n\n\t\tmemcpy(s->inbuf_ptr, buf_ptr, len);\n\n\t\tbuf_ptr += len;\n\n\t\tbuf_size -= len;\n\n\t\ts->inbuf_ptr += len;\n\n\t    }\n\n\t    if ((s->inbuf_ptr - s->inbuf) >= HEADER_SIZE) {\n\n            got_header:\n\n\t\theader = (s->inbuf[0] << 24) | (s->inbuf[1] << 16) |\n\n\t\t    (s->inbuf[2] << 8) | s->inbuf[3];\n\n\n\n\t\tif (check_header(header) < 0) {\n\n\t\t    /* no sync found : move by one byte (inefficient, but simple!) */\n\n\t\t    memcpy(s->inbuf, s->inbuf + 1, s->inbuf_ptr - s->inbuf - 1);\n\n\t\t    s->inbuf_ptr--;\n\n                    dprintf(\"skip %x\\n\", header);\n\n                    /* reset free format frame size to give a chance\n\n                       to get a new bitrate */\n\n                    s->free_format_frame_size = 0;\n\n\t\t} else {\n\n\t\t    if (decode_header(s, header) == 1) {\n\n                        /* free format: compute frame size */\n\n\t\t\ts->frame_size = -1;\n\n\t\t\tmemcpy(s->inbuf, s->inbuf + 1, s->inbuf_ptr - s->inbuf - 1);\n\n\t\t\ts->inbuf_ptr--;\n\n                    } else {\n\n                        /* update codec info */\n\n                        avctx->sample_rate = s->sample_rate;\n\n                        avctx->channels = s->nb_channels;\n\n\t\t\tavctx->bit_rate = s->bit_rate;\n\n\t\t\tavctx->frame_size = s->frame_size;\n\n                    }\n\n\t\t}\n\n\t    }\n\n        } else if (s->frame_size == -1) {\n\n            /* free format : find next sync to compute frame size */\n\n\t    len = MPA_MAX_CODED_FRAME_SIZE - len;\n\n\t    if (len > buf_size)\n\n\t\tlen = buf_size;\n\n            if (len == 0) {\n\n                /* frame too long: resync */\n\n                s->frame_size = 0;\n\n            } else {\n\n                UINT8 *p, *pend;\n\n                UINT32 header1;\n\n                int padding;\n\n\n\n                memcpy(s->inbuf_ptr, buf_ptr, len);\n\n                /* check for header */\n\n                p = s->inbuf_ptr - 3;\n\n                pend = s->inbuf_ptr + len - 4;\n\n                while (p <= pend) {\n\n                    header = (p[0] << 24) | (p[1] << 16) |\n\n                        (p[2] << 8) | p[3];\n\n                    header1 = (s->inbuf[0] << 24) | (s->inbuf[1] << 16) |\n\n                        (s->inbuf[2] << 8) | s->inbuf[3];\n\n                    /* check with high probability that we have a\n\n                       valid header */\n\n                    if ((header & SAME_HEADER_MASK) ==\n\n                        (header1 & SAME_HEADER_MASK)) {\n\n                        /* header found: update pointers */\n\n                        len = (p + 4) - s->inbuf_ptr;\n\n                        buf_ptr += len;\n\n                        buf_size -= len;\n\n                        s->inbuf_ptr = p;\n\n                        /* compute frame size */\n\n                        s->free_format_next_header = header;\n\n                        s->free_format_frame_size = s->inbuf_ptr - s->inbuf;\n\n                        padding = (header1 >> 9) & 1;\n\n                        if (s->layer == 1)\n\n                            s->free_format_frame_size -= padding * 4;\n\n                        else\n\n                            s->free_format_frame_size -= padding;\n\n                        dprintf(\"free frame size=%d padding=%d\\n\", \n\n                                s->free_format_frame_size, padding);\n\n                        decode_header(s, header1);\n\n                        goto next_data;\n\n                    }\n\n                    p++;\n\n                }\n\n                /* not found: simply increase pointers */\n\n                buf_ptr += len;\n\n                s->inbuf_ptr += len;\n\n                buf_size -= len;\n\n            }\n\n\t} else if (len < s->frame_size) {\n\n            if (s->frame_size > MPA_MAX_CODED_FRAME_SIZE)\n\n                s->frame_size = MPA_MAX_CODED_FRAME_SIZE;\n\n\t    len = s->frame_size - len;\n\n\t    if (len > buf_size)\n\n\t\tlen = buf_size;\n\n\t    else if (len < 4)\n\n\t\tlen = buf_size > 4 ? 4 : buf_size;\n\n\t    memcpy(s->inbuf_ptr, buf_ptr, len);\n\n\t    buf_ptr += len;\n\n\t    s->inbuf_ptr += len;\n\n\t    buf_size -= len;\n\n\t} else {\n\n            out_size = mp_decode_frame(s, out_samples);\n\n\t    s->inbuf_ptr = s->inbuf;\n\n\t    s->frame_size = 0;\n\n\t    *data_size = out_size;\n\n\t    break;\n\n\t}\n\n    next_data:\n\n    }\n\n    return buf_ptr - buf;\n\n}\n", "idx": 22648}
{"project": "FFmpeg", "commit_id": "ed2112fb36d7407d960b4f44475a700a7c44344c", "target": 0, "func": "static void mov_write_uuidprof_tag(AVIOContext *pb, AVFormatContext *s)\n\n{\n\n    AVStream       *video_st    = s->streams[0];\n\n    AVCodecParameters *video_par = s->streams[0]->codecpar;\n\n    AVCodecParameters *audio_par = s->streams[1]->codecpar;\n\n    int audio_rate = audio_par->sample_rate;\n\n    int64_t frame_rate = (video_st->avg_frame_rate.num * 0x10000LL) / video_st->avg_frame_rate.den;\n\n    int audio_kbitrate = audio_par->bit_rate / 1000;\n\n    int video_kbitrate = FFMIN(video_par->bit_rate / 1000, 800 - audio_kbitrate);\n\n\n\n    avio_wb32(pb, 0x94); /* size */\n\n    ffio_wfourcc(pb, \"uuid\");\n\n    ffio_wfourcc(pb, \"PROF\");\n\n\n\n    avio_wb32(pb, 0x21d24fce); /* 96 bit UUID */\n\n    avio_wb32(pb, 0xbb88695c);\n\n    avio_wb32(pb, 0xfac9c740);\n\n\n\n    avio_wb32(pb, 0x0);  /* ? */\n\n    avio_wb32(pb, 0x3);  /* 3 sections ? */\n\n\n\n    avio_wb32(pb, 0x14); /* size */\n\n    ffio_wfourcc(pb, \"FPRF\");\n\n    avio_wb32(pb, 0x0);  /* ? */\n\n    avio_wb32(pb, 0x0);  /* ? */\n\n    avio_wb32(pb, 0x0);  /* ? */\n\n\n\n    avio_wb32(pb, 0x2c);  /* size */\n\n    ffio_wfourcc(pb, \"APRF\"); /* audio */\n\n    avio_wb32(pb, 0x0);\n\n    avio_wb32(pb, 0x2);   /* TrackID */\n\n    ffio_wfourcc(pb, \"mp4a\");\n\n    avio_wb32(pb, 0x20f);\n\n    avio_wb32(pb, 0x0);\n\n    avio_wb32(pb, audio_kbitrate);\n\n    avio_wb32(pb, audio_kbitrate);\n\n    avio_wb32(pb, audio_rate);\n\n    avio_wb32(pb, audio_par->channels);\n\n\n\n    avio_wb32(pb, 0x34);  /* size */\n\n    ffio_wfourcc(pb, \"VPRF\");   /* video */\n\n    avio_wb32(pb, 0x0);\n\n    avio_wb32(pb, 0x1);    /* TrackID */\n\n    if (video_par->codec_id == AV_CODEC_ID_H264) {\n\n        ffio_wfourcc(pb, \"avc1\");\n\n        avio_wb16(pb, 0x014D);\n\n        avio_wb16(pb, 0x0015);\n\n    } else {\n\n        ffio_wfourcc(pb, \"mp4v\");\n\n        avio_wb16(pb, 0x0000);\n\n        avio_wb16(pb, 0x0103);\n\n    }\n\n    avio_wb32(pb, 0x0);\n\n    avio_wb32(pb, video_kbitrate);\n\n    avio_wb32(pb, video_kbitrate);\n\n    avio_wb32(pb, frame_rate);\n\n    avio_wb32(pb, frame_rate);\n\n    avio_wb16(pb, video_par->width);\n\n    avio_wb16(pb, video_par->height);\n\n    avio_wb32(pb, 0x010001); /* ? */\n\n}\n", "idx": 22649}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "void rgb32tobgr24(const uint8_t *src, uint8_t *dst, unsigned int src_size)\n\n{\n\n\tunsigned i;\n\n\tunsigned num_pixels = src_size >> 2;\n\n\tfor(i=0; i<num_pixels; i++)\n\n\t{\n\n\t\tdst[3*i + 0] = src[4*i + 2];\n\n\t\tdst[3*i + 1] = src[4*i + 1];\n\n\t\tdst[3*i + 2] = src[4*i + 0];\n\n\t}\n\n}\n", "idx": 22650}
{"project": "FFmpeg", "commit_id": "2711cb28f46463760f0326d806fe5ef9551ade2c", "target": 1, "func": "static double get_diff_limited_q(MpegEncContext *s, RateControlEntry *rce, double q){\n\n    RateControlContext *rcc= &s->rc_context;\n\n    AVCodecContext *a= s->avctx;\n\n    const int pict_type= rce->new_pict_type;\n\n    const double last_p_q    = rcc->last_qscale_for[P_TYPE];\n\n    const double last_non_b_q= rcc->last_qscale_for[rcc->last_non_b_pict_type];\n\n\n\n    if     (pict_type==I_TYPE && (a->i_quant_factor>0.0 || rcc->last_non_b_pict_type==P_TYPE))\n\n        q= last_p_q    *FFABS(a->i_quant_factor) + a->i_quant_offset;\n\n    else if(pict_type==B_TYPE && a->b_quant_factor>0.0)\n\n        q= last_non_b_q*    a->b_quant_factor  + a->b_quant_offset;\n\n\n\n\n    /* last qscale / qdiff stuff */\n\n    if(rcc->last_non_b_pict_type==pict_type || pict_type!=I_TYPE){\n\n        double last_q= rcc->last_qscale_for[pict_type];\n\n        const int maxdiff= FF_QP2LAMBDA * a->max_qdiff;\n\n\n\n        if     (q > last_q + maxdiff) q= last_q + maxdiff;\n\n        else if(q < last_q - maxdiff) q= last_q - maxdiff;\n\n    }\n\n\n\n    rcc->last_qscale_for[pict_type]= q; //Note we cannot do that after blurring\n\n\n\n    if(pict_type!=B_TYPE)\n\n        rcc->last_non_b_pict_type= pict_type;\n\n\n\n    return q;\n\n}", "idx": 22655}
{"project": "FFmpeg", "commit_id": "bc29acdc76fdbf70700cdc2f85fc2afb46e19e47", "target": 0, "func": "static int ftp_store(FTPContext *s)\n\n{\n\n    char command[CONTROL_BUFFER_SIZE];\n\n    const int stor_codes[] = {150, 0};\n\n\n\n    snprintf(command, sizeof(command), \"STOR %s\\r\\n\", s->path);\n\n    if (!ftp_send_command(s, command, stor_codes, NULL))\n\n        return AVERROR(EIO);\n\n\n\n    s->state = UPLOADING;\n\n\n\n    return 0;\n\n}\n", "idx": 22656}
{"project": "FFmpeg", "commit_id": "931da6a5e9dd54563fe5d4d30b7bd4d0a0218c87", "target": 0, "func": "enum AVPixelFormat avpriv_fmt_v4l2ff(uint32_t v4l2_fmt, enum AVCodecID codec_id)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; avpriv_fmt_conversion_table[i].codec_id != AV_CODEC_ID_NONE; i++) {\n\n        if (avpriv_fmt_conversion_table[i].v4l2_fmt == v4l2_fmt &&\n\n            avpriv_fmt_conversion_table[i].codec_id == codec_id) {\n\n            return avpriv_fmt_conversion_table[i].ff_fmt;\n\n        }\n\n    }\n\n\n\n    return AV_PIX_FMT_NONE;\n\n}\n", "idx": 22657}
{"project": "FFmpeg", "commit_id": "e9174641556b3ca38c56b9621e855cf636cdf12f", "target": 0, "func": "void ff_rtp_send_mpegvideo(AVFormatContext *s1, const uint8_t *buf1, int size)\n\n{\n\n    RTPDemuxContext *s = s1->priv_data;\n\n    int len, h, max_packet_size;\n\n    uint8_t *q;\n\n    int begin_of_slice, end_of_slice, frame_type, temporal_reference;\n\n\n\n    max_packet_size = s->max_payload_size;\n\n    begin_of_slice = 1;\n\n    end_of_slice = 0;\n\n    frame_type = 0;\n\n    temporal_reference = 0;\n\n\n\n    while (size > 0) {\n\n        int begin_of_sequence;\n\n\n\n        begin_of_sequence = 0;\n\n        len = max_packet_size - 4;\n\n\n\n        if (len >= size) {\n\n            len = size;\n\n            end_of_slice = 1;\n\n        } else {\n\n            const uint8_t *r, *r1;\n\n            int start_code;\n\n\n\n            r1 = buf1;\n\n            while (1) {\n\n                start_code = -1;\n\n                r = ff_find_start_code(r1, buf1 + size, &start_code);\n\n                if((start_code & 0xFFFFFF00) == 0x100) {\n\n                    /* New start code found */\n\n                    if (start_code == 0x100) {\n\n                        frame_type = (r[1] & 0x38) >> 3;\n\n                        temporal_reference = (int)r[0] << 2 | r[1] >> 6;\n\n                    }\n\n                    if (start_code == 0x1B8) {\n\n                        begin_of_sequence = 1;\n\n                    }\n\n\n\n                    if (r - buf1 < len) {\n\n                        /* The current slice fits in the packet */\n\n                        if (begin_of_slice == 0) {\n\n                            /* no slice at the beginning of the packet... */\n\n                            end_of_slice = 1;\n\n                            len = r - buf1 - 4;\n\n                            break;\n\n                        }\n\n                        r1 = r;\n\n                    } else {\n\n                        if (r - r1 < max_packet_size) {\n\n                            len = r1 - buf1 - 4;\n\n                            end_of_slice = 1;\n\n                        }\n\n                        break;\n\n                    }\n\n                } else {\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n\n\n        h = 0;\n\n        h |= temporal_reference << 16;\n\n        h |= begin_of_sequence << 13;\n\n        h |= begin_of_slice << 12;\n\n        h |= end_of_slice << 11;\n\n        h |= frame_type << 8;\n\n\n\n        q = s->buf;\n\n        *q++ = h >> 24;\n\n        *q++ = h >> 16;\n\n        *q++ = h >> 8;\n\n        *q++ = h;\n\n\n\n        memcpy(q, buf1, len);\n\n        q += len;\n\n\n\n        /* 90 KHz time stamp */\n\n        s->timestamp = s->cur_timestamp;\n\n        ff_rtp_send_data(s1, s->buf, q - s->buf, (len == size));\n\n\n\n        buf1 += len;\n\n        size -= len;\n\n        begin_of_slice = end_of_slice;\n\n        end_of_slice = 0;\n\n    }\n\n}\n", "idx": 22658}
{"project": "FFmpeg", "commit_id": "67400f6b6219892ab7a555fb61ef979c857692d7", "target": 0, "func": "static int mov_write_hdlr_tag(AVIOContext *pb, MOVTrack *track)\n\n{\n\n    const char *hdlr, *descr = NULL, *hdlr_type = NULL;\n\n    int64_t pos = avio_tell(pb);\n\n\n\n    if (!track) { /* no media --> data handler */\n\n        hdlr      = \"dhlr\";\n\n        hdlr_type = \"url \";\n\n        descr     = \"DataHandler\";\n\n    } else {\n\n        hdlr = (track->mode == MODE_MOV) ? \"mhlr\" : \"\\0\\0\\0\\0\";\n\n        if (track->enc->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            hdlr_type = \"vide\";\n\n            descr     = \"VideoHandler\";\n\n        } else if (track->enc->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            hdlr_type = \"soun\";\n\n            descr     = \"SoundHandler\";\n\n        } else if (track->enc->codec_type == AVMEDIA_TYPE_SUBTITLE) {\n\n            if (track->tag == MKTAG('t','x','3','g')) hdlr_type = \"sbtl\";\n\n            else                                      hdlr_type = \"text\";\n\n            descr = \"SubtitleHandler\";\n\n        } else if (track->enc->codec_tag == MKTAG('r','t','p',' ')) {\n\n            hdlr_type = \"hint\";\n\n            descr     = \"HintHandler\";\n\n        }\n\n    }\n\n\n\n    avio_wb32(pb, 0); /* size */\n\n    ffio_wfourcc(pb, \"hdlr\");\n\n    avio_wb32(pb, 0); /* Version & flags */\n\n    avio_write(pb, hdlr, 4); /* handler */\n\n    ffio_wfourcc(pb, hdlr_type); /* handler type */\n\n    avio_wb32(pb, 0); /* reserved */\n\n    avio_wb32(pb, 0); /* reserved */\n\n    avio_wb32(pb, 0); /* reserved */\n\n    if (!track || track->mode == MODE_MOV)\n\n        avio_w8(pb, strlen(descr)); /* pascal string */\n\n    avio_write(pb, descr, strlen(descr)); /* handler description */\n\n    if (track && track->mode != MODE_MOV)\n\n        avio_w8(pb, 0); /* c string */\n\n    return update_size(pb, pos);\n\n}\n", "idx": 22662}
{"project": "FFmpeg", "commit_id": "e1b8271949d3b70e820b8e08c542ad1586c96f9d", "target": 0, "func": "static void check_consistency(FFFrameQueue *fq)\n\n{\n\n#if ASSERT_LEVEL >= 2\n\n    uint64_t nb_samples = 0;\n\n    size_t i;\n\n\n\n    av_assert0(fq->queued == fq->total_frames_head - fq->total_frames_tail);\n\n    for (i = 0; i < fq->queued; i++)\n\n        nb_samples += bucket(fq, i)->frame->nb_samples;\n\n    av_assert0(nb_samples == fq->total_samples_head - fq->total_samples_tail);\n\n#endif\n\n}\n", "idx": 22663}
{"project": "FFmpeg", "commit_id": "c3d7f00ee3e09801f56f25db8b5961f25e842bd2", "target": 0, "func": "static void sdt_cb(MpegTSFilter *filter, const uint8_t *section, int section_len)\n\n{\n\n    MpegTSContext *ts = filter->u.section_filter.opaque;\n\n    SectionHeader h1, *h = &h1;\n\n    const uint8_t *p, *p_end, *desc_list_end, *desc_end;\n\n    int onid, val, sid, desc_list_len, desc_tag, desc_len, service_type;\n\n    char *name, *provider_name;\n\n\n\n    av_dlog(ts->stream, \"SDT:\\n\");\n\n    hex_dump_debug(ts->stream, section, section_len);\n\n\n\n    p_end = section + section_len - 4;\n\n    p     = section;\n\n    if (parse_section_header(h, &p, p_end) < 0)\n\n        return;\n\n    if (h->tid != SDT_TID)\n\n        return;\n\n    if (ts->skip_changes)\n\n        return;\n\n    onid = get16(&p, p_end);\n\n    if (onid < 0)\n\n        return;\n\n    val = get8(&p, p_end);\n\n    if (val < 0)\n\n        return;\n\n    for (;;) {\n\n        sid = get16(&p, p_end);\n\n        if (sid < 0)\n\n            break;\n\n        val = get8(&p, p_end);\n\n        if (val < 0)\n\n            break;\n\n        desc_list_len = get16(&p, p_end);\n\n        if (desc_list_len < 0)\n\n            break;\n\n        desc_list_len &= 0xfff;\n\n        desc_list_end  = p + desc_list_len;\n\n        if (desc_list_end > p_end)\n\n            break;\n\n        for (;;) {\n\n            desc_tag = get8(&p, desc_list_end);\n\n            if (desc_tag < 0)\n\n                break;\n\n            desc_len = get8(&p, desc_list_end);\n\n            desc_end = p + desc_len;\n\n            if (desc_end > desc_list_end)\n\n                break;\n\n\n\n            av_dlog(ts->stream, \"tag: 0x%02x len=%d\\n\",\n\n                    desc_tag, desc_len);\n\n\n\n            switch (desc_tag) {\n\n            case 0x48:\n\n                service_type = get8(&p, p_end);\n\n                if (service_type < 0)\n\n                    break;\n\n                provider_name = getstr8(&p, p_end);\n\n                if (!provider_name)\n\n                    break;\n\n                name = getstr8(&p, p_end);\n\n                if (name) {\n\n                    AVProgram *program = av_new_program(ts->stream, sid);\n\n                    if (program) {\n\n                        av_dict_set(&program->metadata, \"service_name\", name, 0);\n\n                        av_dict_set(&program->metadata, \"service_provider\",\n\n                                    provider_name, 0);\n\n                    }\n\n                }\n\n                av_free(name);\n\n                av_free(provider_name);\n\n                break;\n\n            default:\n\n                break;\n\n            }\n\n            p = desc_end;\n\n        }\n\n        p = desc_list_end;\n\n    }\n\n}\n", "idx": 22664}
{"project": "FFmpeg", "commit_id": "65b8b6c476454d201348737527a1d9471f689278", "target": 0, "func": "void ff_hevc_deblocking_boundary_strengths(HEVCContext *s, int x0, int y0,\n\n                                           int log2_trafo_size,\n\n                                           int slice_or_tiles_up_boundary,\n\n                                           int slice_or_tiles_left_boundary)\n\n{\n\n    MvField *tab_mvf     = s->ref->tab_mvf;\n\n    int log2_min_pu_size = s->sps->log2_min_pu_size;\n\n    int log2_min_tu_size = s->sps->log2_min_tb_size;\n\n    int min_pu_width     = s->sps->min_pu_width;\n\n    int min_tu_width     = s->sps->min_tb_width;\n\n    int is_intra = tab_mvf[(y0 >> log2_min_pu_size) * min_pu_width +\n\n                           (x0 >> log2_min_pu_size)].is_intra;\n\n    int i, j, bs;\n\n\n\n    if (y0 > 0 && (y0 & 7) == 0) {\n\n        int yp_pu = (y0 - 1) >> log2_min_pu_size;\n\n        int yq_pu =  y0      >> log2_min_pu_size;\n\n        int yp_tu = (y0 - 1) >> log2_min_tu_size;\n\n        int yq_tu =  y0      >> log2_min_tu_size;\n\n\n\n        for (i = 0; i < (1 << log2_trafo_size); i += 4) {\n\n            int x_pu = (x0 + i) >> log2_min_pu_size;\n\n            int x_tu = (x0 + i) >> log2_min_tu_size;\n\n            MvField *top  = &tab_mvf[yp_pu * min_pu_width + x_pu];\n\n            MvField *curr = &tab_mvf[yq_pu * min_pu_width + x_pu];\n\n            uint8_t top_cbf_luma  = s->cbf_luma[yp_tu * min_tu_width + x_tu];\n\n            uint8_t curr_cbf_luma = s->cbf_luma[yq_tu * min_tu_width + x_tu];\n\n            RefPicList *top_refPicList = ff_hevc_get_ref_list(s, s->ref,\n\n                                                              x0 + i, y0 - 1);\n\n\n\n            bs = boundary_strength(s, curr, curr_cbf_luma,\n\n                                   top, top_cbf_luma, top_refPicList, 1);\n\n            if (!s->sh.slice_loop_filter_across_slices_enabled_flag &&\n\n                (slice_or_tiles_up_boundary & 1) &&\n\n                (y0 % (1 << s->sps->log2_ctb_size)) == 0)\n\n                bs = 0;\n\n            else if (!s->pps->loop_filter_across_tiles_enabled_flag &&\n\n                     (slice_or_tiles_up_boundary & 2) &&\n\n                     (y0 % (1 << s->sps->log2_ctb_size)) == 0)\n\n                bs = 0;\n\n            if (y0 == 0 || s->sh.disable_deblocking_filter_flag == 1)\n\n                bs = 0;\n\n            if (bs)\n\n                s->horizontal_bs[((x0 + i) + y0 * s->bs_width) >> 2] = bs;\n\n        }\n\n    }\n\n\n\n    // bs for TU internal horizontal PU boundaries\n\n    if (log2_trafo_size > s->sps->log2_min_pu_size && !is_intra)\n\n        for (j = 8; j < (1 << log2_trafo_size); j += 8) {\n\n            int yp_pu = (y0 + j - 1) >> log2_min_pu_size;\n\n            int yq_pu = (y0 + j)     >> log2_min_pu_size;\n\n            int yp_tu = (y0 + j - 1) >> log2_min_tu_size;\n\n            int yq_tu = (y0 + j)     >> log2_min_tu_size;\n\n\n\n            for (i = 0; i < (1 << log2_trafo_size); i += 4) {\n\n                int x_pu = (x0 + i) >> log2_min_pu_size;\n\n                int x_tu = (x0 + i) >> log2_min_tu_size;\n\n                MvField *top  = &tab_mvf[yp_pu * min_pu_width + x_pu];\n\n                MvField *curr = &tab_mvf[yq_pu * min_pu_width + x_pu];\n\n                uint8_t top_cbf_luma  = s->cbf_luma[yp_tu * min_tu_width + x_tu];\n\n                uint8_t curr_cbf_luma = s->cbf_luma[yq_tu * min_tu_width + x_tu];\n\n                RefPicList *top_refPicList = ff_hevc_get_ref_list(s, s->ref,\n\n                                                                  x0 + i,\n\n                                                                  y0 + j - 1);\n\n\n\n                bs = boundary_strength(s, curr, curr_cbf_luma,\n\n                                       top, top_cbf_luma, top_refPicList, 0);\n\n                if (s->sh.disable_deblocking_filter_flag == 1)\n\n                    bs = 0;\n\n                if (bs)\n\n                    s->horizontal_bs[((x0 + i) + (y0 + j) * s->bs_width) >> 2] = bs;\n\n            }\n\n        }\n\n\n\n    // bs for vertical TU boundaries\n\n    if (x0 > 0 && (x0 & 7) == 0) {\n\n        int xp_pu = (x0 - 1) >> log2_min_pu_size;\n\n        int xq_pu =  x0      >> log2_min_pu_size;\n\n        int xp_tu = (x0 - 1) >> log2_min_tu_size;\n\n        int xq_tu =  x0      >> log2_min_tu_size;\n\n\n\n        for (i = 0; i < (1 << log2_trafo_size); i += 4) {\n\n            int y_pu      = (y0 + i) >> log2_min_pu_size;\n\n            int y_tu      = (y0 + i) >> log2_min_tu_size;\n\n            MvField *left = &tab_mvf[y_pu * min_pu_width + xp_pu];\n\n            MvField *curr = &tab_mvf[y_pu * min_pu_width + xq_pu];\n\n\n\n            uint8_t left_cbf_luma = s->cbf_luma[y_tu * min_tu_width + xp_tu];\n\n            uint8_t curr_cbf_luma = s->cbf_luma[y_tu * min_tu_width + xq_tu];\n\n            RefPicList *left_refPicList = ff_hevc_get_ref_list(s, s->ref,\n\n                                                               x0 - 1, y0 + i);\n\n\n\n            bs = boundary_strength(s, curr, curr_cbf_luma,\n\n                                   left, left_cbf_luma, left_refPicList, 1);\n\n            if (!s->sh.slice_loop_filter_across_slices_enabled_flag &&\n\n                (slice_or_tiles_left_boundary & 1) &&\n\n                (x0 % (1 << s->sps->log2_ctb_size)) == 0)\n\n                bs = 0;\n\n            else if (!s->pps->loop_filter_across_tiles_enabled_flag &&\n\n                     (slice_or_tiles_left_boundary & 2) &&\n\n                     (x0 % (1 << s->sps->log2_ctb_size)) == 0)\n\n                bs = 0;\n\n            if (x0 == 0 || s->sh.disable_deblocking_filter_flag == 1)\n\n                bs = 0;\n\n            if (bs)\n\n                s->vertical_bs[(x0 >> 3) + ((y0 + i) >> 2) * s->bs_width] = bs;\n\n        }\n\n    }\n\n\n\n    // bs for TU internal vertical PU boundaries\n\n    if (log2_trafo_size > log2_min_pu_size && !is_intra)\n\n        for (j = 0; j < (1 << log2_trafo_size); j += 4) {\n\n            int y_pu = (y0 + j) >> log2_min_pu_size;\n\n            int y_tu = (y0 + j) >> log2_min_tu_size;\n\n\n\n            for (i = 8; i < (1 << log2_trafo_size); i += 8) {\n\n                int xp_pu = (x0 + i - 1) >> log2_min_pu_size;\n\n                int xq_pu = (x0 + i)     >> log2_min_pu_size;\n\n                int xp_tu = (x0 + i - 1) >> log2_min_tu_size;\n\n                int xq_tu = (x0 + i)     >> log2_min_tu_size;\n\n                MvField *left = &tab_mvf[y_pu * min_pu_width + xp_pu];\n\n                MvField *curr = &tab_mvf[y_pu * min_pu_width + xq_pu];\n\n                uint8_t left_cbf_luma = s->cbf_luma[y_tu * min_tu_width + xp_tu];\n\n                uint8_t curr_cbf_luma = s->cbf_luma[y_tu * min_tu_width + xq_tu];\n\n                RefPicList *left_refPicList = ff_hevc_get_ref_list(s, s->ref,\n\n                                                                   x0 + i - 1,\n\n                                                                   y0 + j);\n\n\n\n                bs = boundary_strength(s, curr, curr_cbf_luma,\n\n                                       left, left_cbf_luma, left_refPicList, 0);\n\n                if (s->sh.disable_deblocking_filter_flag == 1)\n\n                    bs = 0;\n\n                if (bs)\n\n                    s->vertical_bs[((x0 + i) >> 3) + ((y0 + j) >> 2) * s->bs_width] = bs;\n\n            }\n\n        }\n\n}\n", "idx": 22665}
{"project": "FFmpeg", "commit_id": "747a0554ea8ad09404c1f5b80239ebd8d71b291e", "target": 1, "func": "static int swf_write_audio(AVFormatContext *s, const uint8_t *buf, int size)\n\n{\n\n    ByteIOContext *pb = &s->pb;\n\n\n\n    put_swf_tag(s, TAG_STREAMBLOCK | TAG_LONG);\n\n\n\n    put_buffer(pb, buf, size);\n\n    \n\n    put_swf_end_tag(s);\n\n    put_flush_packet(&s->pb);\n\n    return 0;\n\n}\n", "idx": 22670}
{"project": "FFmpeg", "commit_id": "ca3cef719e382b0bf44bdee1482ea89bb2d7f245", "target": 1, "func": "static int avisynth_read_packet_audio(AVFormatContext *s, AVPacket *pkt, int discard) {\n\n    AviSynthContext *avs = s->priv_data;\n\n    AVRational fps, samplerate;\n\n    int samples;\n\n    const char* error;\n\n\n\n    if (avs->curr_sample >= avs->vi->num_audio_samples)\n\n        return AVERROR_EOF;\n\n\n\n    fps.num = avs->vi->fps_numerator;\n\n    fps.den = avs->vi->fps_denominator;\n\n    samplerate.num = avs->vi->audio_samples_per_second;\n\n    samplerate.den = 1;\n\n\n\n    if (avs_has_video(avs->vi)) {\n\n        if (avs->curr_frame < avs->vi->num_frames)\n\n            samples = av_rescale_q(avs->curr_frame, samplerate, fps) - avs->curr_sample;\n\n        else\n\n            samples = av_rescale_q(1, samplerate, fps);\n\n    } else {\n\n        samples = 1000;\n\n    }\n\n\n\n    // After seeking, audio may catch up with video.\n\n    if (samples <= 0) {\n\n        pkt->size = 0;\n\n        pkt->data = NULL;\n\n        return 0;\n\n    }\n\n\n\n    if (avs->curr_sample + samples > avs->vi->num_audio_samples)\n\n        samples = avs->vi->num_audio_samples - avs->curr_sample;\n\n\n\n    // This must happen even if the stream is discarded to prevent desync.\n\n    avs->curr_sample += samples;\n\n    if (discard)\n\n        return 0;\n\n\n\n    pkt->pts = avs->curr_sample;\n\n    pkt->dts = avs->curr_sample;\n\n    pkt->duration = samples;\n\n\n\n    pkt->size = avs_bytes_per_channel_sample(avs->vi) * samples * avs->vi->nchannels;\n\n    if (!pkt->size)\n\n        return AVERROR_UNKNOWN;\n\n    pkt->data = av_malloc(pkt->size);\n\n    if (!pkt->data)\n\n        return AVERROR_UNKNOWN;\n\n\n\n    avs_library->avs_get_audio(avs->clip, pkt->data, avs->curr_sample, samples);\n\n    error = avs_library->avs_clip_get_error(avs->clip);\n\n    if (error) {\n\n        av_log(s, AV_LOG_ERROR, \"%s\\n\", error);\n\n        avs->error = 1;\n\n        av_freep(&pkt->data);\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n    return 0;\n\n}\n", "idx": 22671}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int vc1_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size, n_slices = 0, i, ret;\n\n    VC1Context *v = avctx->priv_data;\n\n    MpegEncContext *s = &v->s;\n\n    AVFrame *pict = data;\n\n    uint8_t *buf2 = NULL;\n\n    const uint8_t *buf_start = buf;\n\n    int mb_height, n_slices1;\n\n    struct {\n\n        uint8_t *buf;\n\n        GetBitContext gb;\n\n        int mby_start;\n\n    } *slices = NULL, *tmp;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == VC1_CODE_ENDOFSEQ)) {\n\n        /* special case for last picture */\n\n        if (s->low_delay == 0 && s->next_picture_ptr) {\n\n            if ((ret = av_frame_ref(pict, &s->next_picture_ptr->f)) < 0)\n\n                return ret;\n\n            s->next_picture_ptr = NULL;\n\n\n\n            *got_frame = 1;\n\n        }\n\n\n\n        return 0;\n\n    }\n\n\n\n    //for advanced profile we may need to parse and unescape data\n\n    if (avctx->codec_id == AV_CODEC_ID_VC1 || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n\n        int buf_size2 = 0;\n\n        buf2 = av_mallocz(buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n        if (IS_MARKER(AV_RB32(buf))) { /* frame starts with marker and needs to be parsed */\n\n            const uint8_t *start, *end, *next;\n\n            int size;\n\n\n\n            next = buf;\n\n            for (start = buf, end = buf + buf_size; next < end; start = next) {\n\n                next = find_next_marker(start + 4, end);\n\n                size = next - start - 4;\n\n                if (size <= 0) continue;\n\n                switch (AV_RB32(start)) {\n\n                case VC1_CODE_FRAME:\n\n                    if (avctx->hwaccel)\n\n                        buf_start = start;\n\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n\n                    break;\n\n                case VC1_CODE_FIELD: {\n\n                    int buf_size3;\n\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n\n                    if (!tmp)\n\n                        goto err;\n\n                    slices = tmp;\n\n                    slices[n_slices].buf = av_mallocz(buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                    if (!slices[n_slices].buf)\n\n                        goto err;\n\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n\n                                                    slices[n_slices].buf);\n\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n\n                                  buf_size3 << 3);\n\n                    /* assuming that the field marker is at the exact middle,\n\n                       hope it's correct */\n\n                    slices[n_slices].mby_start = s->mb_height >> 1;\n\n                    n_slices1 = n_slices - 1; // index of the last slice of the first field\n\n                    n_slices++;\n\n                    break;\n\n                }\n\n                case VC1_CODE_ENTRYPOINT: /* it should be before frame data */\n\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n\n                    init_get_bits(&s->gb, buf2, buf_size2 * 8);\n\n                    ff_vc1_decode_entry_point(avctx, v, &s->gb);\n\n                    break;\n\n                case VC1_CODE_SLICE: {\n\n                    int buf_size3;\n\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n\n                    if (!tmp)\n\n                        goto err;\n\n                    slices = tmp;\n\n                    slices[n_slices].buf = av_mallocz(buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                    if (!slices[n_slices].buf)\n\n                        goto err;\n\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n\n                                                    slices[n_slices].buf);\n\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n\n                                  buf_size3 << 3);\n\n                    slices[n_slices].mby_start = get_bits(&slices[n_slices].gb, 9);\n\n                    n_slices++;\n\n                    break;\n\n                }\n\n                }\n\n            }\n\n        } else if (v->interlace && ((buf[0] & 0xC0) == 0xC0)) { /* WVC1 interlaced stores both fields divided by marker */\n\n            const uint8_t *divider;\n\n            int buf_size3;\n\n\n\n            divider = find_next_marker(buf, buf + buf_size);\n\n            if ((divider == (buf + buf_size)) || AV_RB32(divider) != VC1_CODE_FIELD) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Error in WVC1 interlaced frame\\n\");\n\n                goto err;\n\n            } else { // found field marker, unescape second field\n\n                tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n\n                if (!tmp)\n\n                    goto err;\n\n                slices = tmp;\n\n                slices[n_slices].buf = av_mallocz(buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                if (!slices[n_slices].buf)\n\n                    goto err;\n\n                buf_size3 = vc1_unescape_buffer(divider + 4, buf + buf_size - divider - 4, slices[n_slices].buf);\n\n                init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n\n                              buf_size3 << 3);\n\n                slices[n_slices].mby_start = s->mb_height >> 1;\n\n                n_slices1 = n_slices - 1;\n\n                n_slices++;\n\n            }\n\n            buf_size2 = vc1_unescape_buffer(buf, divider - buf, buf2);\n\n        } else {\n\n            buf_size2 = vc1_unescape_buffer(buf, buf_size, buf2);\n\n        }\n\n        init_get_bits(&s->gb, buf2, buf_size2*8);\n\n    } else\n\n        init_get_bits(&s->gb, buf, buf_size*8);\n\n\n\n    if (v->res_sprite) {\n\n        v->new_sprite  = !get_bits1(&s->gb);\n\n        v->two_sprites =  get_bits1(&s->gb);\n\n        /* res_sprite means a Windows Media Image stream, AV_CODEC_ID_*IMAGE means\n\n           we're using the sprite compositor. These are intentionally kept separate\n\n           so you can get the raw sprites by using the wmv3 decoder for WMVP or\n\n           the vc1 one for WVP2 */\n\n        if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n\n            if (v->new_sprite) {\n\n                // switch AVCodecContext parameters to those of the sprites\n\n                avctx->width  = avctx->coded_width  = v->sprite_width;\n\n                avctx->height = avctx->coded_height = v->sprite_height;\n\n            } else {\n\n                goto image;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (s->context_initialized &&\n\n        (s->width  != avctx->coded_width ||\n\n         s->height != avctx->coded_height)) {\n\n        ff_vc1_decode_end(avctx);\n\n    }\n\n\n\n    if (!s->context_initialized) {\n\n        if (ff_msmpeg4_decode_init(avctx) < 0)\n\n            goto err;\n\n        if (ff_vc1_decode_init_alloc_tables(v) < 0) {\n\n            ff_MPV_common_end(s);\n\n            goto err;\n\n        }\n\n\n\n        s->low_delay = !avctx->has_b_frames || v->res_sprite;\n\n\n\n        if (v->profile == PROFILE_ADVANCED) {\n\n            s->h_edge_pos = avctx->coded_width;\n\n            s->v_edge_pos = avctx->coded_height;\n\n        }\n\n    }\n\n\n\n    // do parse frame header\n\n    v->pic_header_flag = 0;\n\n    v->first_pic_header_flag = 1;\n\n    if (v->profile < PROFILE_ADVANCED) {\n\n        if (ff_vc1_parse_frame_header(v, &s->gb) < 0) {\n\n            goto err;\n\n        }\n\n    } else {\n\n        if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n\n            goto err;\n\n        }\n\n    }\n\n    v->first_pic_header_flag = 0;\n\n\n\n    if ((avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE)\n\n        && s->pict_type != AV_PICTURE_TYPE_I) {\n\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Sprite decoder: expected I-frame\\n\");\n\n        goto err;\n\n    }\n\n\n\n    // for skipping the frame\n\n    s->current_picture.f.pict_type = s->pict_type;\n\n    s->current_picture.f.key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n\n\n    /* skip B-frames if we don't have reference frames */\n\n    if (s->last_picture_ptr == NULL && (s->pict_type == AV_PICTURE_TYPE_B || s->droppable)) {\n\n        goto err;\n\n    }\n\n    if ((avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type == AV_PICTURE_TYPE_B) ||\n\n        (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type != AV_PICTURE_TYPE_I) ||\n\n         avctx->skip_frame >= AVDISCARD_ALL) {\n\n        goto end;\n\n    }\n\n\n\n    if (s->next_p_frame_damaged) {\n\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n\n            goto end;\n\n        else\n\n            s->next_p_frame_damaged = 0;\n\n    }\n\n\n\n    if (ff_MPV_frame_start(s, avctx) < 0) {\n\n        goto err;\n\n    }\n\n\n\n    // process pulldown flags\n\n    s->current_picture_ptr->f.repeat_pict = 0;\n\n    // Pulldown flags are only valid when 'broadcast' has been set.\n\n    // So ticks_per_frame will be 2\n\n    if (v->rff) {\n\n        // repeat field\n\n        s->current_picture_ptr->f.repeat_pict = 1;\n\n    } else if (v->rptfrm) {\n\n        // repeat frames\n\n        s->current_picture_ptr->f.repeat_pict = v->rptfrm * 2;\n\n    }\n\n\n\n    s->me.qpel_put = s->dsp.put_qpel_pixels_tab;\n\n    s->me.qpel_avg = s->dsp.avg_qpel_pixels_tab;\n\n\n\n    if (avctx->hwaccel) {\n\n        if (avctx->hwaccel->start_frame(avctx, buf, buf_size) < 0)\n\n            goto err;\n\n        if (avctx->hwaccel->decode_slice(avctx, buf_start, (buf + buf_size) - buf_start) < 0)\n\n            goto err;\n\n        if (avctx->hwaccel->end_frame(avctx) < 0)\n\n            goto err;\n\n    } else {\n\n        int header_ret = 0;\n\n\n\n        ff_mpeg_er_frame_start(s);\n\n\n\n        v->bits = buf_size * 8;\n\n        v->end_mb_x = s->mb_width;\n\n        if (v->field_mode) {\n\n            s->current_picture.f.linesize[0] <<= 1;\n\n            s->current_picture.f.linesize[1] <<= 1;\n\n            s->current_picture.f.linesize[2] <<= 1;\n\n            s->linesize                      <<= 1;\n\n            s->uvlinesize                    <<= 1;\n\n        }\n\n        mb_height = s->mb_height >> v->field_mode;\n\n\n\n        if (!mb_height) {\n\n            av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid mb_height.\\n\");\n\n            goto err;\n\n        }\n\n\n\n        for (i = 0; i <= n_slices; i++) {\n\n            if (i > 0 &&  slices[i - 1].mby_start >= mb_height) {\n\n                if (v->field_mode <= 0) {\n\n                    av_log(v->s.avctx, AV_LOG_ERROR, \"Slice %d starts beyond \"\n\n                           \"picture boundary (%d >= %d)\\n\", i,\n\n                           slices[i - 1].mby_start, mb_height);\n\n                    continue;\n\n                }\n\n                v->second_field = 1;\n\n                v->blocks_off   = s->mb_width  * s->mb_height << 1;\n\n                v->mb_off       = s->mb_stride * s->mb_height >> 1;\n\n            } else {\n\n                v->second_field = 0;\n\n                v->blocks_off   = 0;\n\n                v->mb_off       = 0;\n\n            }\n\n            if (i) {\n\n                v->pic_header_flag = 0;\n\n                if (v->field_mode && i == n_slices1 + 2) {\n\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Field header damaged\\n\");\n\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n\n                            goto err;\n\n                        continue;\n\n                    }\n\n                } else if (get_bits1(&s->gb)) {\n\n                    v->pic_header_flag = 1;\n\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Slice header damaged\\n\");\n\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n\n                            goto err;\n\n                        continue;\n\n                    }\n\n                }\n\n            }\n\n            if (header_ret < 0)\n\n                continue;\n\n            s->start_mb_y = (i == 0) ? 0 : FFMAX(0, slices[i-1].mby_start % mb_height);\n\n            if (!v->field_mode || v->second_field)\n\n                s->end_mb_y = (i == n_slices     ) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n\n            else\n\n                s->end_mb_y = (i <= n_slices1 + 1) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n\n            ff_vc1_decode_blocks(v);\n\n            if (i != n_slices)\n\n                s->gb = slices[i].gb;\n\n        }\n\n        if (v->field_mode) {\n\n            v->second_field = 0;\n\n            s->current_picture.f.linesize[0] >>= 1;\n\n            s->current_picture.f.linesize[1] >>= 1;\n\n            s->current_picture.f.linesize[2] >>= 1;\n\n            s->linesize                      >>= 1;\n\n            s->uvlinesize                    >>= 1;\n\n            if (v->s.pict_type != AV_PICTURE_TYPE_BI && v->s.pict_type != AV_PICTURE_TYPE_B) {\n\n                FFSWAP(uint8_t *, v->mv_f_next[0], v->mv_f[0]);\n\n                FFSWAP(uint8_t *, v->mv_f_next[1], v->mv_f[1]);\n\n            }\n\n        }\n\n        av_dlog(s->avctx, \"Consumed %i/%i bits\\n\",\n\n                get_bits_count(&s->gb), s->gb.size_in_bits);\n\n//  if (get_bits_count(&s->gb) > buf_size * 8)\n\n//      return -1;\n\n        if (!v->field_mode)\n\n            ff_er_frame_end(&s->er);\n\n    }\n\n\n\n    ff_MPV_frame_end(s);\n\n\n\n    if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n\nimage:\n\n        avctx->width  = avctx->coded_width  = v->output_width;\n\n        avctx->height = avctx->coded_height = v->output_height;\n\n        if (avctx->skip_frame >= AVDISCARD_NONREF)\n\n            goto end;\n\n#if CONFIG_WMV3IMAGE_DECODER || CONFIG_VC1IMAGE_DECODER\n\n        if (vc1_decode_sprites(v, &s->gb))\n\n            goto err;\n\n#endif\n\n        if ((ret = av_frame_ref(pict, v->sprite_output_frame)) < 0)\n\n            goto err;\n\n        *got_frame = 1;\n\n    } else {\n\n        if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n\n            if ((ret = av_frame_ref(pict, &s->current_picture_ptr->f)) < 0)\n\n                goto err;\n\n            ff_print_debug_info(s, s->current_picture_ptr);\n\n            *got_frame = 1;\n\n        } else if (s->last_picture_ptr != NULL) {\n\n            if ((ret = av_frame_ref(pict, &s->last_picture_ptr->f)) < 0)\n\n                goto err;\n\n            ff_print_debug_info(s, s->last_picture_ptr);\n\n            *got_frame = 1;\n\n        }\n\n    }\n\n\n\nend:\n\n    av_free(buf2);\n\n    for (i = 0; i < n_slices; i++)\n\n        av_free(slices[i].buf);\n\n    av_free(slices);\n\n    return buf_size;\n\n\n\nerr:\n\n    av_free(buf2);\n\n    for (i = 0; i < n_slices; i++)\n\n        av_free(slices[i].buf);\n\n    av_free(slices);\n\n    return -1;\n\n}\n", "idx": 22672}
{"project": "FFmpeg", "commit_id": "be9d060d0c4f7e548bdb6ce96789b22bfd09a704", "target": 0, "func": "altivec_yuv2packedX (SwsContext *c,\n\n\t\t       int16_t *lumFilter, int16_t **lumSrc, int lumFilterSize,\n\n\t\t       int16_t *chrFilter, int16_t **chrSrc, int chrFilterSize,\n\n\t\t       uint8_t *dest, int dstW, int dstY)\n\n{\n\n  int i,j;\n\n  short tmp __attribute__((aligned (16)));\n\n  int16_t *p;\n\n  short *f;\n\n  vector signed short X,X0,X1,Y0,U0,V0,Y1,U1,V1,U,V;\n\n  vector signed short R0,G0,B0,R1,G1,B1;\n\n\n\n  vector unsigned char R,G,B,pels[3];\n\n  vector unsigned char *out,*nout;\n\n\n\n  vector signed short   RND = vec_splat((vector signed short)AVV(1<<3),0);\n\n  vector unsigned short SCL = vec_splat((vector unsigned short)AVV(4),0);\n\n  unsigned long scratch[16] __attribute__ ((aligned (16)));\n\n\n\n  vector signed short *vYCoeffsBank, *vCCoeffsBank;\n\n\n\n  vector signed short *YCoeffs, *CCoeffs;\n\n\n\n  vYCoeffsBank = malloc (sizeof (vector signed short)*lumFilterSize*dstW);\n\n  vCCoeffsBank = malloc (sizeof (vector signed short)*chrFilterSize*dstW);\n\n\n\n  for (i=0;i<lumFilterSize*dstW;i++) {\n\n    tmp = c->vLumFilter[i];\n\n    p = &vYCoeffsBank[i];\n\n    for (j=0;j<8;j++)\n\n      p[j] = tmp;\n\n  }\n\n\n\n  for (i=0;i<chrFilterSize*dstW;i++) {\n\n    tmp = c->vChrFilter[i];\n\n    p = &vCCoeffsBank[i];\n\n    for (j=0;j<8;j++)\n\n      p[j] = tmp;\n\n  }\n\n\n\n  YCoeffs = vYCoeffsBank+dstY*lumFilterSize;\n\n  CCoeffs = vCCoeffsBank+dstY*chrFilterSize;\n\n\n\n  out = (vector unsigned char *)dest;\n\n\n\n  for(i=0; i<dstW; i+=16){\n\n    Y0 = RND;\n\n    Y1 = RND;\n\n    /* extract 16 coeffs from lumSrc */\n\n    for(j=0; j<lumFilterSize; j++) {\n\n      X0 = vec_ld (0,  &lumSrc[j][i]);\n\n      X1 = vec_ld (16, &lumSrc[j][i]);\n\n      Y0 = vec_mradds (X0, YCoeffs[j], Y0);\n\n      Y1 = vec_mradds (X1, YCoeffs[j], Y1);\n\n    }\n\n\n\n    U = RND;\n\n    V = RND;\n\n    /* extract 8 coeffs from U,V */\n\n    for(j=0; j<chrFilterSize; j++) {\n\n      X  = vec_ld (0, &chrSrc[j][i/2]);\n\n      U  = vec_mradds (X, CCoeffs[j], U);\n\n      X  = vec_ld (0, &chrSrc[j][i/2+2048]);\n\n      V  = vec_mradds (X, CCoeffs[j], V);\n\n    }\n\n\n\n    /* scale and clip signals */\n\n    Y0 = vec_sra (Y0, SCL);\n\n    Y1 = vec_sra (Y1, SCL);\n\n    U  = vec_sra (U,  SCL);\n\n    V  = vec_sra (V,  SCL);\n\n\n\n    Y0 = vec_clip (Y0);\n\n    Y1 = vec_clip (Y1);\n\n    U  = vec_clip (U);\n\n    V  = vec_clip (V);\n\n\n\n    /* now we have\n\n      Y0= y0 y1 y2 y3 y4 y5 y6 y7     Y1= y8 y9 y10 y11 y12 y13 y14 y15\n\n      U= u0 u1 u2 u3 u4 u5 u6 u7      V= v0 v1 v2 v3 v4 v5 v6 v7\n\n\n\n      Y0= y0 y1 y2 y3 y4 y5 y6 y7    Y1= y8 y9 y10 y11 y12 y13 y14 y15\n\n      U0= u0 u0 u1 u1 u2 u2 u3 u3    U1= u4 u4 u5 u5 u6 u6 u7 u7\n\n      V0= v0 v0 v1 v1 v2 v2 v3 v3    V1= v4 v4 v5 v5 v6 v6 v7 v7\n\n    */\n\n\n\n    U0 = vec_mergeh (U,U);\n\n    V0 = vec_mergeh (V,V);\n\n\n\n    U1 = vec_mergel (U,U);\n\n    V1 = vec_mergel (V,V);\n\n\n\n    cvtyuvtoRGB (c, Y0,U0,V0,&R0,&G0,&B0);\n\n    cvtyuvtoRGB (c, Y1,U1,V1,&R1,&G1,&B1);\n\n\n\n    R  = vec_packclp (R0,R1);\n\n    G  = vec_packclp (G0,G1);\n\n    B  = vec_packclp (B0,B1);\n\n\n\n    out_rgba (R,G,B,out);\n\n  }\n\n\n\n  if (i < dstW) {\n\n    i -= 16;\n\n\n\n    Y0 = RND;\n\n    Y1 = RND;\n\n    /* extract 16 coeffs from lumSrc */\n\n    for(j=0; j<lumFilterSize; j++) {\n\n      X0 = vec_ld (0,  &lumSrc[j][i]);\n\n      X1 = vec_ld (16, &lumSrc[j][i]);\n\n      Y0 = vec_mradds (X0, YCoeffs[j], Y0);\n\n      Y1 = vec_mradds (X1, YCoeffs[j], Y1);\n\n    }\n\n\n\n    U = RND;\n\n    V = RND;\n\n    /* extract 8 coeffs from U,V */\n\n    for(j=0; j<chrFilterSize; j++) {\n\n      X  = vec_ld (0, &chrSrc[j][i/2]);\n\n      U  = vec_mradds (X, CCoeffs[j], U);\n\n      X  = vec_ld (0, &chrSrc[j][i/2+2048]);\n\n      V  = vec_mradds (X, CCoeffs[j], V);\n\n    }\n\n\n\n    /* scale and clip signals */\n\n    Y0 = vec_sra (Y0, SCL);\n\n    Y1 = vec_sra (Y1, SCL);\n\n    U  = vec_sra (U,  SCL);\n\n    V  = vec_sra (V,  SCL);\n\n\n\n    Y0 = vec_clip (Y0);\n\n    Y1 = vec_clip (Y1);\n\n    U  = vec_clip (U);\n\n    V  = vec_clip (V);\n\n\n\n    /* now we have\n\n       Y0= y0 y1 y2 y3 y4 y5 y6 y7     Y1= y8 y9 y10 y11 y12 y13 y14 y15\n\n       U= u0 u1 u2 u3 u4 u5 u6 u7      V= v0 v1 v2 v3 v4 v5 v6 v7\n\n\n\n       Y0= y0 y1 y2 y3 y4 y5 y6 y7    Y1= y8 y9 y10 y11 y12 y13 y14 y15\n\n       U0= u0 u0 u1 u1 u2 u2 u3 u3    U1= u4 u4 u5 u5 u6 u6 u7 u7\n\n       V0= v0 v0 v1 v1 v2 v2 v3 v3    V1= v4 v4 v5 v5 v6 v6 v7 v7\n\n    */\n\n\n\n    U0 = vec_mergeh (U,U);\n\n    V0 = vec_mergeh (V,V);\n\n\n\n    U1 = vec_mergel (U,U);\n\n    V1 = vec_mergel (V,V);\n\n\n\n    cvtyuvtoRGB (c, Y0,U0,V0,&R0,&G0,&B0);\n\n    cvtyuvtoRGB (c, Y1,U1,V1,&R1,&G1,&B1);\n\n\n\n    R  = vec_packclp (R0,R1);\n\n    G  = vec_packclp (G0,G1);\n\n    B  = vec_packclp (B0,B1);\n\n\n\n    nout = (vector unsigned char *)scratch;\n\n    out_rgba (R,G,B,nout);\n\n\n\n    memcpy (&((uint32_t*)dest)[i], scratch, (dstW-i)/4);\n\n  }\n\n\n\n  if (vYCoeffsBank) free (vYCoeffsBank);\n\n  if (vCCoeffsBank) free (vCCoeffsBank);\n\n\n\n}\n", "idx": 22673}
{"project": "FFmpeg", "commit_id": "80a5d05108cb218e8cd2e25c6621a3bfef0a832e", "target": 0, "func": "static av_cold int vaapi_encode_h265_init_fixed_qp(AVCodecContext *avctx)\n\n{\n\n    VAAPIEncodeContext      *ctx = avctx->priv_data;\n\n    VAAPIEncodeH265Context *priv = ctx->priv_data;\n\n    VAAPIEncodeH265Options  *opt = ctx->codec_options;\n\n\n\n    priv->fixed_qp_p = opt->qp;\n\n    if (avctx->i_quant_factor > 0.0)\n\n        priv->fixed_qp_idr = (int)((priv->fixed_qp_p * avctx->i_quant_factor +\n\n                                    avctx->i_quant_offset) + 0.5);\n\n    else\n\n        priv->fixed_qp_idr = priv->fixed_qp_p;\n\n    if (avctx->b_quant_factor > 0.0)\n\n        priv->fixed_qp_b = (int)((priv->fixed_qp_p * avctx->b_quant_factor +\n\n                                  avctx->b_quant_offset) + 0.5);\n\n    else\n\n        priv->fixed_qp_b = priv->fixed_qp_p;\n\n\n\n    av_log(avctx, AV_LOG_DEBUG, \"Using fixed QP = \"\n\n           \"%d / %d / %d for IDR- / P- / B-frames.\\n\",\n\n           priv->fixed_qp_idr, priv->fixed_qp_p, priv->fixed_qp_b);\n\n    return 0;\n\n}\n", "idx": 22674}
{"project": "FFmpeg", "commit_id": "69ee915e1c628fdf8b270de8c19ff357333e354a", "target": 1, "func": "int av_parser_parse2(AVCodecParserContext *s, AVCodecContext *avctx,\n\n                     uint8_t **poutbuf, int *poutbuf_size,\n\n                     const uint8_t *buf, int buf_size,\n\n                     int64_t pts, int64_t dts, int64_t pos)\n\n{\n\n    int index, i;\n\n    uint8_t dummy_buf[FF_INPUT_BUFFER_PADDING_SIZE];\n\n\n\n    if (!(s->flags & PARSER_FLAG_FETCHED_OFFSET)) {\n\n        s->next_frame_offset =\n\n        s->cur_offset        = pos;\n\n        s->flags            |= PARSER_FLAG_FETCHED_OFFSET;\n\n    }\n\n\n\n    if (buf_size == 0) {\n\n        /* padding is always necessary even if EOF, so we add it here */\n\n        memset(dummy_buf, 0, sizeof(dummy_buf));\n\n        buf = dummy_buf;\n\n    } else if (s->cur_offset + buf_size != s->cur_frame_end[s->cur_frame_start_index]) { /* skip remainder packets */\n\n        /* add a new packet descriptor */\n\n        i = (s->cur_frame_start_index + 1) & (AV_PARSER_PTS_NB - 1);\n\n        s->cur_frame_start_index = i;\n\n        s->cur_frame_offset[i]   = s->cur_offset;\n\n        s->cur_frame_end[i]      = s->cur_offset + buf_size;\n\n        s->cur_frame_pts[i]      = pts;\n\n        s->cur_frame_dts[i]      = dts;\n\n        s->cur_frame_pos[i]      = pos;\n\n    }\n\n\n\n    if (s->fetch_timestamp) {\n\n        s->fetch_timestamp = 0;\n\n        s->last_pts        = s->pts;\n\n        s->last_dts        = s->dts;\n\n        s->last_pos        = s->pos;\n\n        ff_fetch_timestamp(s, 0, 0);\n\n    }\n\n    /* WARNING: the returned index can be negative */\n\n    index = s->parser->parser_parse(s, avctx, (const uint8_t **) poutbuf,\n\n                                    poutbuf_size, buf, buf_size);\n\n    /* update the file pointer */\n\n    if (*poutbuf_size) {\n\n        /* fill the data for the current frame */\n\n        s->frame_offset = s->next_frame_offset;\n\n\n\n        /* offset of the next frame */\n\n        s->next_frame_offset = s->cur_offset + index;\n\n        s->fetch_timestamp   = 1;\n\n    }\n\n    if (index < 0)\n\n        index = 0;\n\n    s->cur_offset += index;\n\n    return index;\n\n}\n", "idx": 22675}
{"project": "FFmpeg", "commit_id": "2df0c32ea12ddfa72ba88309812bfb13b674130f", "target": 0, "func": "av_cold int ff_ac3_encode_init(AVCodecContext *avctx)\n\n{\n\n    AC3EncodeContext *s = avctx->priv_data;\n\n    int ret, frame_size_58;\n\n\n\n    s->avctx = avctx;\n\n\n\n    s->eac3 = avctx->codec_id == AV_CODEC_ID_EAC3;\n\n\n\n    ff_ac3_common_init();\n\n\n\n    ret = validate_options(s);\n\n    if (ret)\n\n        return ret;\n\n\n\n    avctx->frame_size = AC3_BLOCK_SIZE * s->num_blocks;\n\n    avctx->delay      = AC3_BLOCK_SIZE;\n\n\n\n    s->bitstream_mode = avctx->audio_service_type;\n\n    if (s->bitstream_mode == AV_AUDIO_SERVICE_TYPE_KARAOKE)\n\n        s->bitstream_mode = 0x7;\n\n\n\n    s->bits_written    = 0;\n\n    s->samples_written = 0;\n\n\n\n    /* calculate crc_inv for both possible frame sizes */\n\n    frame_size_58 = (( s->frame_size    >> 2) + ( s->frame_size    >> 4)) << 1;\n\n    s->crc_inv[0] = pow_poly((CRC16_POLY >> 1), (8 * frame_size_58) - 16, CRC16_POLY);\n\n    if (s->bit_alloc.sr_code == 1) {\n\n        frame_size_58 = (((s->frame_size+2) >> 2) + ((s->frame_size+2) >> 4)) << 1;\n\n        s->crc_inv[1] = pow_poly((CRC16_POLY >> 1), (8 * frame_size_58) - 16, CRC16_POLY);\n\n    }\n\n\n\n    /* set function pointers */\n\n    if (CONFIG_AC3_FIXED_ENCODER && s->fixed_point) {\n\n        s->mdct_end                     = ff_ac3_fixed_mdct_end;\n\n        s->mdct_init                    = ff_ac3_fixed_mdct_init;\n\n        s->allocate_sample_buffers      = ff_ac3_fixed_allocate_sample_buffers;\n\n    } else if (CONFIG_AC3_ENCODER || CONFIG_EAC3_ENCODER) {\n\n        s->mdct_end                     = ff_ac3_float_mdct_end;\n\n        s->mdct_init                    = ff_ac3_float_mdct_init;\n\n        s->allocate_sample_buffers      = ff_ac3_float_allocate_sample_buffers;\n\n    }\n\n    if (CONFIG_EAC3_ENCODER && s->eac3)\n\n        s->output_frame_header = ff_eac3_output_frame_header;\n\n    else\n\n        s->output_frame_header = ac3_output_frame_header;\n\n\n\n    set_bandwidth(s);\n\n\n\n    exponent_init(s);\n\n\n\n    bit_alloc_init(s);\n\n\n\n    ret = s->mdct_init(s);\n\n    if (ret)\n\n        goto init_fail;\n\n\n\n    ret = allocate_buffers(s);\n\n    if (ret)\n\n        goto init_fail;\n\n\n\n    ff_audiodsp_init(&s->adsp);\n\n    ff_me_cmp_init(&s->mecc, avctx);\n\n    ff_ac3dsp_init(&s->ac3dsp, avctx->flags & CODEC_FLAG_BITEXACT);\n\n\n\n    dprint_options(s);\n\n\n\n    return 0;\n\ninit_fail:\n\n    ff_ac3_encode_close(avctx);\n\n    return ret;\n\n}\n", "idx": 22677}
{"project": "FFmpeg", "commit_id": "fca712df09b92942ae95753062a43695b051a120", "target": 0, "func": "static int dirac_unpack_prediction_parameters(DiracContext *s)\n\n{\n\n    static const uint8_t default_blen[] = { 4, 12, 16, 24 };\n\n    static const uint8_t default_bsep[] = { 4,  8, 12, 16 };\n\n\n\n    GetBitContext *gb = &s->gb;\n\n    unsigned idx, ref;\n\n\n\n    align_get_bits(gb);\n\n    /* [DIRAC_STD] 11.2.2 Block parameters. block_parameters() */\n\n    /* Luma and Chroma are equal. 11.2.3 */\n\n    idx = svq3_get_ue_golomb(gb); /* [DIRAC_STD] index */\n\n\n\n    if (idx > 4)\n\n    {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Block prediction index too high\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (idx == 0) {\n\n        s->plane[0].xblen = svq3_get_ue_golomb(gb);\n\n        s->plane[0].yblen = svq3_get_ue_golomb(gb);\n\n        s->plane[0].xbsep = svq3_get_ue_golomb(gb);\n\n        s->plane[0].ybsep = svq3_get_ue_golomb(gb);\n\n    } else {\n\n        /*[DIRAC_STD] preset_block_params(index). Table 11.1 */\n\n        s->plane[0].xblen = default_blen[idx-1];\n\n        s->plane[0].yblen = default_blen[idx-1];\n\n        s->plane[0].xbsep = default_bsep[idx-1];\n\n        s->plane[0].ybsep = default_bsep[idx-1];\n\n    }\n\n    /*[DIRAC_STD] 11.2.4 motion_data_dimensions()\n\n      Calculated in function dirac_unpack_block_motion_data */\n\n\n\n    if (s->plane[0].xbsep < s->plane[0].xblen/2 || s->plane[0].ybsep < s->plane[0].yblen/2) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Block separation too small\\n\");\n\n        return -1;\n\n    }\n\n    if (s->plane[0].xbsep > s->plane[0].xblen || s->plane[0].ybsep > s->plane[0].yblen) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Block seperation greater than size\\n\");\n\n        return -1;\n\n    }\n\n    if (FFMAX(s->plane[0].xblen, s->plane[0].yblen) > MAX_BLOCKSIZE) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Unsupported large block size\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /*[DIRAC_STD] 11.2.5 Motion vector precision. motion_vector_precision()\n\n      Read motion vector precision */\n\n    s->mv_precision = svq3_get_ue_golomb(gb);\n\n    if (s->mv_precision > 3) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"MV precision finer than eighth-pel\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /*[DIRAC_STD] 11.2.6 Global motion. global_motion()\n\n      Read the global motion compensation parameters */\n\n    s->globalmc_flag = get_bits1(gb);\n\n    if (s->globalmc_flag) {\n\n        memset(s->globalmc, 0, sizeof(s->globalmc));\n\n        /* [DIRAC_STD] pan_tilt(gparams) */\n\n        for (ref = 0; ref < s->num_refs; ref++) {\n\n            if (get_bits1(gb)) {\n\n                s->globalmc[ref].pan_tilt[0] = dirac_get_se_golomb(gb);\n\n                s->globalmc[ref].pan_tilt[1] = dirac_get_se_golomb(gb);\n\n            }\n\n            /* [DIRAC_STD] zoom_rotate_shear(gparams)\n\n               zoom/rotation/shear parameters */\n\n            if (get_bits1(gb)) {\n\n                s->globalmc[ref].zrs_exp   = svq3_get_ue_golomb(gb);\n\n                s->globalmc[ref].zrs[0][0] = dirac_get_se_golomb(gb);\n\n                s->globalmc[ref].zrs[0][1] = dirac_get_se_golomb(gb);\n\n                s->globalmc[ref].zrs[1][0] = dirac_get_se_golomb(gb);\n\n                s->globalmc[ref].zrs[1][1] = dirac_get_se_golomb(gb);\n\n            } else {\n\n                s->globalmc[ref].zrs[0][0] = 1;\n\n                s->globalmc[ref].zrs[1][1] = 1;\n\n            }\n\n            /* [DIRAC_STD] perspective(gparams) */\n\n            if (get_bits1(gb)) {\n\n                s->globalmc[ref].perspective_exp = svq3_get_ue_golomb(gb);\n\n                s->globalmc[ref].perspective[0]  = dirac_get_se_golomb(gb);\n\n                s->globalmc[ref].perspective[1]  = dirac_get_se_golomb(gb);\n\n            }\n\n        }\n\n    }\n\n\n\n    /*[DIRAC_STD] 11.2.7 Picture prediction mode. prediction_mode()\n\n      Picture prediction mode, not currently used. */\n\n    if (svq3_get_ue_golomb(gb)) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Unknown picture prediction mode\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* [DIRAC_STD] 11.2.8 Reference picture weight. reference_picture_weights()\n\n       just data read, weight calculation will be done later on. */\n\n    s->weight_log2denom = 1;\n\n    s->weight[0]        = 1;\n\n    s->weight[1]        = 1;\n\n\n\n    if (get_bits1(gb)) {\n\n        s->weight_log2denom = svq3_get_ue_golomb(gb);\n\n        s->weight[0] = dirac_get_se_golomb(gb);\n\n        if (s->num_refs == 2)\n\n            s->weight[1] = dirac_get_se_golomb(gb);\n\n    }\n\n    return 0;\n\n}\n", "idx": 22678}
{"project": "FFmpeg", "commit_id": "d89dc06a96c32e5ccf9d56d7bc8549e84dfbc517", "target": 1, "func": "static inline void xchg_mb_border(H264Context *h, uint8_t *src_y, uint8_t *src_cb, uint8_t *src_cr, int linesize, int uvlinesize, int xchg){\n\n    MpegEncContext * const s = &h->s;\n\n    int temp8, i;\n\n    uint64_t temp64;\n\n\n\n    src_y  -=   linesize + 1;\n\n    src_cb -= uvlinesize + 1;\n\n    src_cr -= uvlinesize + 1;\n\n\n\n#define XCHG(a,b,t,xchg)\\\n\nt= a;\\\n\nif(xchg)\\\n\n    a= b;\\\n\nb= t;\n\n    \n\n    for(i=0; i<17; i++){\n\n        XCHG(h->left_border[i     ], src_y [i*  linesize], temp8, xchg);\n\n    }\n\n    \n\n    XCHG(*(uint64_t*)(h->top_border[s->mb_x]+0), *(uint64_t*)(src_y +1), temp64, xchg);\n\n    XCHG(*(uint64_t*)(h->top_border[s->mb_x]+8), *(uint64_t*)(src_y +9), temp64, 1);\n\n\n\n    if(!(s->flags&CODEC_FLAG_GRAY)){\n\n        for(i=0; i<9; i++){\n\n            XCHG(h->left_border[i+17  ], src_cb[i*uvlinesize], temp8, xchg);\n\n            XCHG(h->left_border[i+17+9], src_cr[i*uvlinesize], temp8, xchg);\n\n        }\n\n        XCHG(*(uint64_t*)(h->top_border[s->mb_x]+16), *(uint64_t*)(src_cb+1), temp64, 1);\n\n        XCHG(*(uint64_t*)(h->top_border[s->mb_x]+24), *(uint64_t*)(src_cr+1), temp64, 1);\n\n    }\n\n}\n", "idx": 22679}
{"project": "FFmpeg", "commit_id": "37ecd67b5e149e55d71b1d8950abc5476d56999a", "target": 1, "func": "void ff_free_stream(AVFormatContext *s, AVStream *st){\n\n    av_assert0(s->nb_streams>0);\n\n    av_assert0(s->streams[ s->nb_streams-1 ] == st);\n\n\n\n    if (st->codec) {\n\n        avcodec_close(st->codec);\n\n    }\n\n    if (st->parser) {\n\n        av_parser_close(st->parser);\n\n    }\n\n    if (st->attached_pic.data)\n\n        av_free_packet(&st->attached_pic);\n\n    av_dict_free(&st->metadata);\n\n    av_freep(&st->probe_data.buf);\n\n    av_freep(&st->index_entries);\n\n    av_freep(&st->codec->extradata);\n\n    av_freep(&st->codec->subtitle_header);\n\n    av_freep(&st->codec);\n\n    av_freep(&st->priv_data);\n\n    if (st->info)\n\n        av_freep(&st->info->duration_error);\n\n    av_freep(&st->info);\n\n    av_freep(&s->streams[ --s->nb_streams ]);\n\n}\n", "idx": 22685}
{"project": "FFmpeg", "commit_id": "d10dc61682b057d6f3a59aa23353e4f155f16d11", "target": 1, "func": "ImgReSampleContext *img_resample_full_init(int owidth, int oheight,\n                                      int iwidth, int iheight,\n                                      int topBand, int bottomBand,\n        int leftBand, int rightBand,\n        int padtop, int padbottom,\n        int padleft, int padright)\n{\n    ImgReSampleContext *s;\n    s = av_mallocz(sizeof(ImgReSampleContext));\n    if (!s)\n    if((unsigned)owidth >= UINT_MAX / (LINE_BUF_HEIGHT + NB_TAPS))\n    s->line_buf = av_mallocz(owidth * (LINE_BUF_HEIGHT + NB_TAPS));\n    if (!s->line_buf) \n        goto fail;\n    s->owidth = owidth;\n    s->oheight = oheight;\n    s->iwidth = iwidth;\n    s->iheight = iheight;\n    s->topBand = topBand;\n    s->bottomBand = bottomBand;\n    s->leftBand = leftBand;\n    s->rightBand = rightBand;\n    s->padtop = padtop;\n    s->padbottom = padbottom;\n    s->padleft = padleft;\n    s->padright = padright;\n    s->pad_owidth = owidth - (padleft + padright);\n    s->pad_oheight = oheight - (padtop + padbottom);\n    s->h_incr = ((iwidth - leftBand - rightBand) * POS_FRAC) / s->pad_owidth;\n    s->v_incr = ((iheight - topBand - bottomBand) * POS_FRAC) / s->pad_oheight; \n    av_build_filter(&s->h_filters[0][0], (float) s->pad_owidth  / \n            (float) (iwidth - leftBand - rightBand), NB_TAPS, NB_PHASES, 1<<FILTER_BITS, 0);\n    av_build_filter(&s->v_filters[0][0], (float) s->pad_oheight / \n            (float) (iheight - topBand - bottomBand), NB_TAPS, NB_PHASES, 1<<FILTER_BITS, 0);\n    return s;\nfail:\n    av_free(s);\n}", "idx": 22689}
{"project": "FFmpeg", "commit_id": "1acd7d594c15aa491729c837ad3519d3469e620a", "target": 0, "func": "static void FUNCC(pred8x16_vertical_add)(uint8_t *pix, const int *block_offset,\n\n                                         const int16_t *block, ptrdiff_t stride)\n\n{\n\n    int i;\n\n    for(i=0; i<4; i++)\n\n        FUNCC(pred4x4_vertical_add)(pix + block_offset[i], block + i*16*sizeof(pixel), stride);\n\n    for(i=4; i<8; i++)\n\n        FUNCC(pred4x4_vertical_add)(pix + block_offset[i+4], block + i*16*sizeof(pixel), stride);\n\n}\n", "idx": 22690}
{"project": "FFmpeg", "commit_id": "46cb2f6a2928a7fa4bee3f09b0475ccb8cdd2064", "target": 1, "func": "static int cmv_decode_frame(AVCodecContext *avctx,\n                            void *data, int *data_size,\n                            AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size;\n    CmvContext *s = avctx->priv_data;\n    const uint8_t *buf_end = buf + buf_size;\n    if (AV_RL32(buf)==MVIh_TAG||AV_RB32(buf)==MVIh_TAG) {\n        cmv_process_header(s, buf+EA_PREAMBLE_SIZE, buf_end);\n        return buf_size;\n    }\n    if (av_image_check_size(s->width, s->height, 0, s->avctx))\n        return -1;\n    /* shuffle */\n    if (s->last2_frame.data[0])\n        avctx->release_buffer(avctx, &s->last2_frame);\n    FFSWAP(AVFrame, s->last_frame, s->last2_frame);\n    FFSWAP(AVFrame, s->frame, s->last_frame);\n    s->frame.reference = 1;\n    s->frame.buffer_hints = FF_BUFFER_HINTS_VALID;\n    if (avctx->get_buffer(avctx, &s->frame)<0) {\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n        return -1;\n    }\n    memcpy(s->frame.data[1], s->palette, AVPALETTE_SIZE);\n    buf += EA_PREAMBLE_SIZE;\n    if ((buf[0]&1)) {  // subtype\n        cmv_decode_inter(s, buf+2, buf_end);\n        s->frame.key_frame = 0;\n        s->frame.pict_type = AV_PICTURE_TYPE_P;\n    }else{\n        s->frame.key_frame = 1;\n        s->frame.pict_type = AV_PICTURE_TYPE_I;\n        cmv_decode_intra(s, buf+2, buf_end);\n    }\n    *data_size = sizeof(AVFrame);\n    *(AVFrame*)data = s->frame;\n    return buf_size;\n}", "idx": 22694}
{"project": "FFmpeg", "commit_id": "e1c48b7aaedc5deb6f22ced02dfe4f356bf3f421", "target": 0, "func": "static void save_display_set(DVBSubContext *ctx)\n\n{\n\n    DVBSubRegion *region;\n\n    DVBSubRegionDisplay *display;\n\n    DVBSubCLUT *clut;\n\n    uint32_t *clut_table;\n\n    int x_pos, y_pos, width, height;\n\n    int x, y, y_off, x_off;\n\n    uint32_t *pbuf;\n\n    char filename[32];\n\n    static int fileno_index = 0;\n\n\n\n    x_pos = -1;\n\n    y_pos = -1;\n\n    width = 0;\n\n    height = 0;\n\n\n\n    for (display = ctx->display_list; display != NULL; display = display->next) {\n\n        region = get_region(ctx, display->region_id);\n\n\n\n        if (x_pos == -1) {\n\n            x_pos = display->x_pos;\n\n            y_pos = display->y_pos;\n\n            width = region->width;\n\n            height = region->height;\n\n        } else {\n\n            if (display->x_pos < x_pos) {\n\n                width += (x_pos - display->x_pos);\n\n                x_pos = display->x_pos;\n\n            }\n\n\n\n            if (display->y_pos < y_pos) {\n\n                height += (y_pos - display->y_pos);\n\n                y_pos = display->y_pos;\n\n            }\n\n\n\n            if (display->x_pos + region->width > x_pos + width) {\n\n                width = display->x_pos + region->width - x_pos;\n\n            }\n\n\n\n            if (display->y_pos + region->height > y_pos + height) {\n\n                height = display->y_pos + region->height - y_pos;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (x_pos >= 0) {\n\n\n\n        pbuf = av_malloc(width * height * 4);\n\n\n\n        for (display = ctx->display_list; display != NULL; display = display->next) {\n\n            region = get_region(ctx, display->region_id);\n\n\n\n            x_off = display->x_pos - x_pos;\n\n            y_off = display->y_pos - y_pos;\n\n\n\n            clut = get_clut(ctx, region->clut);\n\n\n\n            if (clut == 0)\n\n                clut = &default_clut;\n\n\n\n            switch (region->depth) {\n\n            case 2:\n\n                clut_table = clut->clut4;\n\n                break;\n\n            case 8:\n\n                clut_table = clut->clut256;\n\n                break;\n\n            case 4:\n\n            default:\n\n                clut_table = clut->clut16;\n\n                break;\n\n            }\n\n\n\n            for (y = 0; y < region->height; y++) {\n\n                for (x = 0; x < region->width; x++) {\n\n                    pbuf[((y + y_off) * width) + x_off + x] =\n\n                        clut_table[region->pbuf[y * region->width + x]];\n\n                }\n\n            }\n\n\n\n        }\n\n\n\n        snprintf(filename, 32, \"dvbs.%d\", fileno_index);\n\n\n\n        png_save2(filename, pbuf, width, height);\n\n\n\n        av_free(pbuf);\n\n    }\n\n\n\n    fileno_index++;\n\n}\n", "idx": 22695}
{"project": "FFmpeg", "commit_id": "6f243b17c537646b894857d43dfdac65f85ab377", "target": 0, "func": "static int fic_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame, AVPacket *avpkt)\n\n{\n\n    FICContext *ctx = avctx->priv_data;\n\n    uint8_t *src = avpkt->data;\n\n    int ret;\n\n    int slice, nslices;\n\n    int msize;\n\n    int tsize;\n\n    uint8_t *sdata;\n\n\n\n    if ((ret = ff_reget_buffer(avctx, ctx->frame)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n\n\n    /* Header + at least one slice (4) */\n\n    if (avpkt->size < FIC_HEADER_SIZE + 4) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Frame data is too small.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* Check for header. */\n\n    if (memcmp(src, fic_header, 7))\n\n        av_log(avctx, AV_LOG_WARNING, \"Invalid FIC Header.\\n\");\n\n\n\n    /* Is it a skip frame? */\n\n    if (src[17])\n\n        goto skip;\n\n\n\n    nslices = src[13];\n\n    if (!nslices) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Zero slices found.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* High or Low Quality Matrix? */\n\n    ctx->qmat = src[23] ? fic_qmat_hq : fic_qmat_lq;\n\n\n\n    /* Skip cursor data. */\n\n    tsize = AV_RB24(src + 24);\n\n    if (tsize > avpkt->size - FIC_HEADER_SIZE) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid cursor data size.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* Slice height for all but the last slice. */\n\n    ctx->slice_h = 16 * (ctx->aligned_height >> 4) / nslices;\n\n    if (ctx->slice_h % 16)\n\n        ctx->slice_h = FFALIGN(ctx->slice_h - 16, 16);\n\n\n\n    /* First slice offset and remaining data. */\n\n    sdata = src + tsize + FIC_HEADER_SIZE + 4 * nslices;\n\n    msize = avpkt->size - nslices * 4 - tsize - FIC_HEADER_SIZE;\n\n\n\n    if (msize <= 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Not enough frame data to decode.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /*\n\n     * Set the frametype to I initially. It will be set to P if the frame\n\n     * has any dependencies (skip blocks). There will be a race condition\n\n     * inside the slice decode function to set these, but we do not care.\n\n     * since they will only ever be set to 0/P.\n\n     */\n\n    ctx->frame->key_frame = 1;\n\n    ctx->frame->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    /* Allocate slice data. */\n\n    av_fast_malloc(&ctx->slice_data, &ctx->slice_data_size,\n\n                   nslices * sizeof(ctx->slice_data[0]));\n\n    if (!ctx->slice_data_size) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not allocate slice data.\\n\");\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    memset(ctx->slice_data, 0, nslices * sizeof(ctx->slice_data[0]));\n\n\n\n    for (slice = 0; slice < nslices; slice++) {\n\n        unsigned slice_off = AV_RB32(src + tsize + FIC_HEADER_SIZE + slice * 4);\n\n        unsigned slice_size;\n\n        int y_off   = ctx->slice_h * slice;\n\n        int slice_h = ctx->slice_h;\n\n\n\n        /*\n\n         * Either read the slice size, or consume all data left.\n\n         * Also, special case the last slight height.\n\n         */\n\n        if (slice == nslices - 1) {\n\n            slice_size   = msize;\n\n            slice_h      = FFALIGN(avctx->height - ctx->slice_h * (nslices - 1), 16);\n\n        } else {\n\n            slice_size = AV_RB32(src + tsize + FIC_HEADER_SIZE + slice * 4 + 4);\n\n        }\n\n\n\n        if (slice_size < slice_off || slice_size > msize)\n\n            continue;\n\n\n\n        slice_size -= slice_off;\n\n\n\n        ctx->slice_data[slice].src      = sdata + slice_off;\n\n        ctx->slice_data[slice].src_size = slice_size;\n\n        ctx->slice_data[slice].slice_h  = slice_h;\n\n        ctx->slice_data[slice].y_off    = y_off;\n\n    }\n\n\n\n    if (ret = avctx->execute(avctx, fic_decode_slice, ctx->slice_data,\n\n                             NULL, nslices, sizeof(ctx->slice_data[0])) < 0)\n\n        return ret;\n\n\n\nskip:\n\n    *got_frame = 1;\n\n    if ((ret = av_frame_ref(data, ctx->frame)) < 0)\n\n        return ret;\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 22696}
{"project": "FFmpeg", "commit_id": "88281a5256f0034451c09acab3aff44acb43c2a3", "target": 0, "func": "static int nppscale_query_formats(AVFilterContext *ctx)\n\n{\n\n    static const enum AVPixelFormat pixel_formats[] = {\n\n        AV_PIX_FMT_CUDA, AV_PIX_FMT_NONE,\n\n    };\n\n    AVFilterFormats *pix_fmts  = ff_make_format_list(pixel_formats);\n\n\n\n    ff_set_common_formats(ctx, pix_fmts);\n\n\n\n    return 0;\n\n}\n", "idx": 22697}
{"project": "FFmpeg", "commit_id": "05ebe51e00e900bcef7d3e9bcd6b91d4aab34de7", "target": 0, "func": "static int decode_update_thread_context(AVCodecContext *dst, const AVCodecContext *src){\n\n    H264Context *h= dst->priv_data, *h1= src->priv_data;\n\n    MpegEncContext * const s = &h->s, * const s1 = &h1->s;\n\n    int inited = s->context_initialized, err;\n\n    int i;\n\n\n\n    if(dst == src || !s1->context_initialized) return 0;\n\n\n\n    err = ff_mpeg_update_thread_context(dst, src);\n\n    if(err) return err;\n\n\n\n    //FIXME handle width/height changing\n\n    if(!inited){\n\n        for(i = 0; i < MAX_SPS_COUNT; i++)\n\n            av_freep(h->sps_buffers + i);\n\n\n\n        for(i = 0; i < MAX_PPS_COUNT; i++)\n\n            av_freep(h->pps_buffers + i);\n\n\n\n        memcpy(&h->s + 1, &h1->s + 1, sizeof(H264Context) - sizeof(MpegEncContext)); //copy all fields after MpegEnc\n\n        memset(h->sps_buffers, 0, sizeof(h->sps_buffers));\n\n        memset(h->pps_buffers, 0, sizeof(h->pps_buffers));\n\n        if (ff_h264_alloc_tables(h) < 0) {\n\n            av_log(dst, AV_LOG_ERROR, \"Could not allocate memory for h264\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        context_init(h);\n\n\n\n        for(i=0; i<2; i++){\n\n            h->rbsp_buffer[i] = NULL;\n\n            h->rbsp_buffer_size[i] = 0;\n\n        }\n\n\n\n        h->thread_context[0] = h;\n\n\n\n        // frame_start may not be called for the next thread (if it's decoding a bottom field)\n\n        // so this has to be allocated here\n\n        h->s.obmc_scratchpad = av_malloc(16*6*s->linesize);\n\n\n\n        s->dsp.clear_blocks(h->mb);\n\n        s->dsp.clear_blocks(h->mb+(24*16<<h->pixel_shift));\n\n    }\n\n\n\n    //extradata/NAL handling\n\n    h->is_avc          = h1->is_avc;\n\n\n\n    //SPS/PPS\n\n    copy_parameter_set((void**)h->sps_buffers, (void**)h1->sps_buffers, MAX_SPS_COUNT, sizeof(SPS));\n\n    h->sps             = h1->sps;\n\n    copy_parameter_set((void**)h->pps_buffers, (void**)h1->pps_buffers, MAX_PPS_COUNT, sizeof(PPS));\n\n    h->pps             = h1->pps;\n\n\n\n    //Dequantization matrices\n\n    //FIXME these are big - can they be only copied when PPS changes?\n\n    copy_fields(h, h1, dequant4_buffer, dequant4_coeff);\n\n\n\n    for(i=0; i<6; i++)\n\n        h->dequant4_coeff[i] = h->dequant4_buffer[0] + (h1->dequant4_coeff[i] - h1->dequant4_buffer[0]);\n\n\n\n    for(i=0; i<6; i++)\n\n        h->dequant8_coeff[i] = h->dequant8_buffer[0] + (h1->dequant8_coeff[i] - h1->dequant8_buffer[0]);\n\n\n\n    h->dequant_coeff_pps = h1->dequant_coeff_pps;\n\n\n\n    //POC timing\n\n    copy_fields(h, h1, poc_lsb, redundant_pic_count);\n\n\n\n    //reference lists\n\n    copy_fields(h, h1, ref_count, list_count);\n\n    copy_fields(h, h1, ref_list,  intra_gb);\n\n    copy_fields(h, h1, short_ref, cabac_init_idc);\n\n\n\n    copy_picture_range(h->short_ref,   h1->short_ref,   32, s, s1);\n\n    copy_picture_range(h->long_ref,    h1->long_ref,    32, s, s1);\n\n    copy_picture_range(h->delayed_pic, h1->delayed_pic, MAX_DELAYED_PIC_COUNT+2, s, s1);\n\n\n\n    h->last_slice_type = h1->last_slice_type;\n\n    h->sync            = h1->sync;\n\n\n\n    if(!s->current_picture_ptr) return 0;\n\n\n\n    if(!s->dropable) {\n\n        err = ff_h264_execute_ref_pic_marking(h, h->mmco, h->mmco_index);\n\n        h->prev_poc_msb     = h->poc_msb;\n\n        h->prev_poc_lsb     = h->poc_lsb;\n\n    }\n\n    h->prev_frame_num_offset= h->frame_num_offset;\n\n    h->prev_frame_num       = h->frame_num;\n\n    h->outputed_poc         = h->next_outputed_poc;\n\n\n\n    return err;\n\n}\n", "idx": 22698}
{"project": "FFmpeg", "commit_id": "36583d23bdbe31e8845d3ca9162bce33fef6e48c", "target": 0, "func": "static void delete_next_frame(AudioFrameQueue *afq)\n\n{\n\n    AudioFrame *f = afq->frame_queue;\n\n    if (f) {\n\n        afq->frame_queue = f->next;\n\n        f->next = NULL;\n\n        av_freep(&f);\n\n    }\n\n}\n", "idx": 22699}
{"project": "FFmpeg", "commit_id": "90fc00a623de44e137fe1601b91356e8cd8bdd54", "target": 1, "func": "static int srt_probe(AVProbeData *p)\n\n{\n\n    const unsigned char *ptr = p->buf;\n\n    int i, v, num = 0;\n\n\n\n    if (AV_RB24(ptr) == 0xEFBBBF)\n\n        ptr += 3;  /* skip UTF-8 BOM */\n\n\n\n    while (*ptr == '\\r' || *ptr == '\\n')\n\n        ptr++;\n\n    for (i=0; i<2; i++) {\n\n        if ((num == i || num + 1 == i)\n\n            && sscanf(ptr, \"%*d:%*2d:%*2d%*1[,.]%*3d --> %*d:%*2d:%*2d%*1[,.]%3d\", &v) == 1)\n\n            return AVPROBE_SCORE_MAX;\n\n        num = atoi(ptr);\n\n        ptr += strcspn(ptr, \"\\n\") + 1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 22702}
{"project": "FFmpeg", "commit_id": "aa06658248a49f6ebf381894b9426cdfb377cd32", "target": 1, "func": "static int dvvideo_close(AVCodecContext *c)\n\n{\n\n    DVVideoContext *s = c->priv_data;\n\n\n\n    av_free(s->dv_anchor);\n\n\n\n    return 0;\n\n}\n", "idx": 22704}
{"project": "FFmpeg", "commit_id": "e4eebc2da9da886e1bdf87d29e9a4c5b55111036", "target": 1, "func": "static int filter_frame(AVFilterLink *inlink, AVFilterBufferRef *insamples)\n\n{\n\n    AVFilterContext *ctx = inlink->dst;\n\n    AVFilterLink *outlink = ctx->outputs[0];\n\n    ShowWavesContext *showwaves = ctx->priv;\n\n    const int nb_samples = insamples->audio->nb_samples;\n\n    AVFilterBufferRef *outpicref = showwaves->outpicref;\n\n    int linesize = outpicref ? outpicref->linesize[0] : 0;\n\n    int16_t *p = (int16_t *)insamples->data[0];\n\n    int nb_channels = av_get_channel_layout_nb_channels(insamples->audio->channel_layout);\n\n    int i, j, h;\n\n    const int n = showwaves->n;\n\n    const int x = 255 / (nb_channels * n); /* multiplication factor, pre-computed to avoid in-loop divisions */\n\n\n\n    /* draw data in the buffer */\n\n    for (i = 0; i < nb_samples; i++) {\n\n        if (!outpicref) {\n\n            showwaves->outpicref = outpicref =\n\n                ff_get_video_buffer(outlink, AV_PERM_WRITE|AV_PERM_ALIGN,\n\n                                    outlink->w, outlink->h);\n\n            if (!outpicref)\n\n                return AVERROR(ENOMEM);\n\n            outpicref->video->w = outlink->w;\n\n            outpicref->video->h = outlink->h;\n\n            outpicref->pts = insamples->pts +\n\n                             av_rescale_q((p - (int16_t *)insamples->data[0]) / nb_channels,\n\n                                          (AVRational){ 1, inlink->sample_rate },\n\n                                          outlink->time_base);\n\n            linesize = outpicref->linesize[0];\n\n            memset(outpicref->data[0], 0, showwaves->h*linesize);\n\n        }\n\n        for (j = 0; j < nb_channels; j++) {\n\n            h = showwaves->h/2 - av_rescale(*p++, showwaves->h/2, MAX_INT16);\n\n            if (h >= 0 && h < outlink->h)\n\n                *(outpicref->data[0] + showwaves->buf_idx + h * linesize) += x;\n\n        }\n\n        showwaves->sample_count_mod++;\n\n        if (showwaves->sample_count_mod == n) {\n\n            showwaves->sample_count_mod = 0;\n\n            showwaves->buf_idx++;\n\n        }\n\n        if (showwaves->buf_idx == showwaves->w)\n\n            push_frame(outlink);\n\n\n    }\n\n\n\n    avfilter_unref_buffer(insamples);\n\n    return 0;\n\n}", "idx": 22707}
{"project": "FFmpeg", "commit_id": "4391805916a1557278351f25428d0145b1073520", "target": 1, "func": "rgb16_32ToUV_half_c_template(uint8_t *dstU, uint8_t *dstV,\n\n                             const uint8_t *src, int width,\n\n                             enum PixelFormat origin,\n\n                             int shr,   int shg,   int shb, int shp,\n\n                             int maskr, int maskg, int maskb,\n\n                             int rsh,   int gsh,   int bsh, int S)\n\n{\n\n    const int ru = RU << rsh, gu = GU << gsh, bu = BU << bsh,\n\n              rv = RV << rsh, gv = GV << gsh, bv = BV << bsh,\n\n              rnd = 257 << S, maskgx = ~(maskr | maskb);\n\n    int i;\n\n\n\n    maskr |= maskr << 1; maskb |= maskb << 1; maskg |= maskg << 1;\n\n    for (i = 0; i < width; i++) {\n\n        int px0 = input_pixel(2 * i + 0) >> shp;\n\n        int px1 = input_pixel(2 * i + 1) >> shp;\n\n        int b, r, g = (px0 & maskgx) + (px1 & maskgx);\n\n        int rb = px0 + px1 - g;\n\n\n\n        b = (rb & maskb) >> shb;\n\n        if (shp || origin == PIX_FMT_BGR565LE || origin == PIX_FMT_BGR565BE ||\n\n            origin == PIX_FMT_RGB565LE || origin == PIX_FMT_RGB565BE) {\n\n            g >>= shg;\n\n        } else {\n\n            g = (g  & maskg) >> shg;\n\n        }\n\n        r = (rb & maskr) >> shr;\n\n\n\n        dstU[i] = (ru * r + gu * g + bu * b + rnd) >> (S + 1);\n\n        dstV[i] = (rv * r + gv * g + bv * b + rnd) >> (S + 1);\n\n    }\n\n}\n", "idx": 22708}
{"project": "FFmpeg", "commit_id": "083300bea935d125b83f60d7030f78a7ffb0f3df", "target": 1, "func": "int ff_thread_get_buffer(AVCodecContext *avctx, ThreadFrame *f, int flags)\n\n{\n\n    f->owner = avctx;\n\n    return ff_get_buffer(avctx, f->f, flags);\n\n}\n", "idx": 22710}
{"project": "FFmpeg", "commit_id": "c94f9e854228e0ea00e1de8769d8d3f7cab84a55", "target": 1, "func": "int av_reallocp_array(void *ptr, size_t nmemb, size_t size)\n\n{\n\n    void **ptrptr = ptr;\n\n    *ptrptr = av_realloc_f(*ptrptr, nmemb, size);\n\n    if (!*ptrptr && !(nmemb && size))\n\n        return AVERROR(ENOMEM);\n\n    return 0;\n\n}\n", "idx": 22715}
{"project": "FFmpeg", "commit_id": "a5e0dbf530d447f36099aed575b34e9258c5d75a", "target": 1, "func": "static int aac_decode_frame_int(AVCodecContext *avctx, void *data,\n\n                                int *got_frame_ptr, GetBitContext *gb, AVPacket *avpkt)\n\n{\n\n    AACContext *ac = avctx->priv_data;\n\n    ChannelElement *che = NULL, *che_prev = NULL;\n\n    enum RawDataBlockType elem_type, che_prev_type = TYPE_END;\n\n    int err, elem_id;\n\n    int samples = 0, multiplier, audio_found = 0, pce_found = 0;\n\n    int is_dmono, sce_count = 0;\n\n    int payload_alignment;\n\n\n\n    ac->frame = data;\n\n\n\n    if (show_bits(gb, 12) == 0xfff) {\n\n        if ((err = parse_adts_frame_header(ac, gb)) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Error decoding AAC frame header.\\n\");\n\n            goto fail;\n\n        }\n\n        if (ac->oc[1].m4ac.sampling_index > 12) {\n\n            av_log(ac->avctx, AV_LOG_ERROR, \"invalid sampling rate index %d\\n\", ac->oc[1].m4ac.sampling_index);\n\n            err = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n    if ((err = frame_configure_elements(avctx)) < 0)\n\n        goto fail;\n\n\n\n    // The FF_PROFILE_AAC_* defines are all object_type - 1\n\n    // This may lead to an undefined profile being signaled\n\n    ac->avctx->profile = ac->oc[1].m4ac.object_type - 1;\n\n\n\n    payload_alignment = get_bits_count(gb);\n\n    ac->tags_mapped = 0;\n\n    // parse\n\n    while ((elem_type = get_bits(gb, 3)) != TYPE_END) {\n\n        elem_id = get_bits(gb, 4);\n\n\n\n        if (avctx->debug & FF_DEBUG_STARTCODE)\n\n            av_log(avctx, AV_LOG_DEBUG, \"Elem type:%x id:%x\\n\", elem_type, elem_id);\n\n\n\n        if (!avctx->channels && elem_type != TYPE_PCE) {\n\n            err = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n\n\n        if (elem_type < TYPE_DSE) {\n\n            if (!(che=get_che(ac, elem_type, elem_id))) {\n\n                av_log(ac->avctx, AV_LOG_ERROR, \"channel element %d.%d is not allocated\\n\",\n\n                       elem_type, elem_id);\n\n                err = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            samples = 1024;\n\n            che->present = 1;\n\n        }\n\n\n\n        switch (elem_type) {\n\n\n\n        case TYPE_SCE:\n\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n\n            audio_found = 1;\n\n            sce_count++;\n\n            break;\n\n\n\n        case TYPE_CPE:\n\n            err = decode_cpe(ac, gb, che);\n\n            audio_found = 1;\n\n            break;\n\n\n\n        case TYPE_CCE:\n\n            err = decode_cce(ac, gb, che);\n\n            break;\n\n\n\n        case TYPE_LFE:\n\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n\n            audio_found = 1;\n\n            break;\n\n\n\n        case TYPE_DSE:\n\n            err = skip_data_stream_element(ac, gb);\n\n            break;\n\n\n\n        case TYPE_PCE: {\n\n            uint8_t layout_map[MAX_ELEM_ID*4][3];\n\n            int tags;\n\n            push_output_configuration(ac);\n\n            tags = decode_pce(avctx, &ac->oc[1].m4ac, layout_map, gb,\n\n                              payload_alignment);\n\n            if (tags < 0) {\n\n                err = tags;\n\n                break;\n\n            }\n\n            if (pce_found) {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"Not evaluating a further program_config_element as this construct is dubious at best.\\n\");\n\n                pop_output_configuration(ac);\n\n            } else {\n\n                err = output_configure(ac, layout_map, tags, OC_TRIAL_PCE, 1);\n\n                if (!err)\n\n                    ac->oc[1].m4ac.chan_config = 0;\n\n                pce_found = 1;\n\n            }\n\n            break;\n\n        }\n\n\n\n        case TYPE_FIL:\n\n            if (elem_id == 15)\n\n                elem_id += get_bits(gb, 8) - 1;\n\n            if (get_bits_left(gb) < 8 * elem_id) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"TYPE_FIL: \"overread_err);\n\n                    err = AVERROR_INVALIDDATA;\n\n                    goto fail;\n\n            }\n\n            while (elem_id > 0)\n\n                elem_id -= decode_extension_payload(ac, gb, elem_id, che_prev, che_prev_type);\n\n            err = 0; /* FIXME */\n\n            break;\n\n\n\n        default:\n\n            err = AVERROR_BUG; /* should not happen, but keeps compiler happy */\n\n            break;\n\n        }\n\n\n\n        if (elem_type < TYPE_DSE) {\n\n            che_prev      = che;\n\n            che_prev_type = elem_type;\n\n        }\n\n\n\n        if (err)\n\n            goto fail;\n\n\n\n        if (get_bits_left(gb) < 3) {\n\n            av_log(avctx, AV_LOG_ERROR, overread_err);\n\n            err = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n    if (!avctx->channels) {\n\n        *got_frame_ptr = 0;\n\n        return 0;\n\n    }\n\n\n\n    multiplier = (ac->oc[1].m4ac.sbr == 1) ? ac->oc[1].m4ac.ext_sample_rate > ac->oc[1].m4ac.sample_rate : 0;\n\n    samples <<= multiplier;\n\n\n\n    spectral_to_sample(ac, samples);\n\n\n\n    if (ac->oc[1].status && audio_found) {\n\n        avctx->sample_rate = ac->oc[1].m4ac.sample_rate << multiplier;\n\n        avctx->frame_size = samples;\n\n        ac->oc[1].status = OC_LOCKED;\n\n    }\n\n\n\n    if (multiplier)\n\n        avctx->internal->skip_samples_multiplier = 2;\n\n\n\n    if (!ac->frame->data[0] && samples) {\n\n        av_log(avctx, AV_LOG_ERROR, \"no frame data found\\n\");\n\n        err = AVERROR_INVALIDDATA;\n\n        goto fail;\n\n    }\n\n\n\n    if (samples) {\n\n        ac->frame->nb_samples = samples;\n\n        ac->frame->sample_rate = avctx->sample_rate;\n\n    } else\n\n        av_frame_unref(ac->frame);\n\n    *got_frame_ptr = !!samples;\n\n\n\n    /* for dual-mono audio (SCE + SCE) */\n\n    is_dmono = ac->dmono_mode && sce_count == 2 &&\n\n               ac->oc[1].channel_layout == (AV_CH_FRONT_LEFT | AV_CH_FRONT_RIGHT);\n\n    if (is_dmono) {\n\n        if (ac->dmono_mode == 1)\n\n            ((AVFrame *)data)->data[1] =((AVFrame *)data)->data[0];\n\n        else if (ac->dmono_mode == 2)\n\n            ((AVFrame *)data)->data[0] =((AVFrame *)data)->data[1];\n\n    }\n\n\n\n    return 0;\n\nfail:\n\n    pop_output_configuration(ac);\n\n    return err;\n\n}\n", "idx": 22717}
{"project": "FFmpeg", "commit_id": "cea9eb9520fab9e5ec79d3a2d4dbd03eb71b7fa3", "target": 1, "func": "static av_cold int dnxhd_decode_close(AVCodecContext *avctx)\n\n{\n\n    DNXHDContext *ctx = avctx->priv_data;\n\n\n\n    ff_free_vlc(&ctx->ac_vlc);\n\n    ff_free_vlc(&ctx->dc_vlc);\n\n    ff_free_vlc(&ctx->run_vlc);\n\n\n\n    av_freep(&ctx->mb_scan_index);\n\n    av_freep(&ctx->rows);\n\n\n\n    return 0;\n\n}\n", "idx": 22718}
{"project": "FFmpeg", "commit_id": "13705b69ebe9e375fdb52469760a0fbb5f593cc1", "target": 1, "func": "static void spatial_compose97i_dy_buffered(dwt_compose_t *cs, slice_buffer * sb, int width, int height, int stride_line){\n\n    int y = cs->y;\n\n\n\n    int mirror0 = mirror(y - 1, height - 1);\n\n    int mirror1 = mirror(y + 0, height - 1);\n\n    int mirror2 = mirror(y + 1, height - 1);\n\n    int mirror3 = mirror(y + 2, height - 1);\n\n    int mirror4 = mirror(y + 3, height - 1);\n\n    int mirror5 = mirror(y + 4, height - 1);\n\n    DWTELEM *b0= cs->b0;\n\n    DWTELEM *b1= cs->b1;\n\n    DWTELEM *b2= cs->b2;\n\n    DWTELEM *b3= cs->b3;\n\n    DWTELEM *b4= slice_buffer_get_line(sb, mirror4 * stride_line);\n\n    DWTELEM *b5= slice_buffer_get_line(sb, mirror5 * stride_line);\n\n\n\n{START_TIMER\n\n    if(y>0 && y+4<height){\n\n        vertical_compose97i(b0, b1, b2, b3, b4, b5, width);\n\n    }else{\n\n        if(mirror3 <= mirror5) vertical_compose97iL1(b3, b4, b5, width);\n\n        if(mirror2 <= mirror4) vertical_compose97iH1(b2, b3, b4, width);\n\n        if(mirror1 <= mirror3) vertical_compose97iL0(b1, b2, b3, width);\n\n        if(mirror0 <= mirror2) vertical_compose97iH0(b0, b1, b2, width);\n\n    }\n\nif(width>400){\n\nSTOP_TIMER(\"vertical_compose97i\")}}\n\n\n\n{START_TIMER\n\n        if(y-1>=  0) horizontal_compose97i(b0, width);\n\n        if(mirror0 <= mirror2) horizontal_compose97i(b1, width);\n\nif(width>400 && mirror0 <= mirror2){\n\nSTOP_TIMER(\"horizontal_compose97i\")}}\n\n\n\n    cs->b0=b2;\n\n    cs->b1=b3;\n\n    cs->b2=b4;\n\n    cs->b3=b5;\n\n    cs->y += 2;\n\n}\n", "idx": 22719}
{"project": "FFmpeg", "commit_id": "f1c21a200bcbc9bbd54fc336016ac16c2e015012", "target": 1, "func": "static void read_table(AVFormatContext *avctx, AVStream *st,\n\n                       int (*parse)(AVFormatContext *avctx, AVStream *st,\n\n                                    const char *name, int size))\n\n{\n\n    int count, i;\n\n    AVIOContext *pb = avctx->pb;\n\n    avio_skip(pb, 4);\n\n    count = avio_rb32(pb);\n\n    avio_skip(pb, 4);\n\n    for (i = 0; i < count; i++) {\n\n        char name[17];\n\n        int size;\n\n        avio_read(pb, name, 16);\n\n        name[sizeof(name) - 1] = 0;\n\n        size = avio_rb32(pb);\n\n        if (parse(avctx, st, name, size) < 0) {\n\n            avpriv_request_sample(avctx, \"Variable %s\", name);\n\n            avio_skip(pb, size);\n\n        }\n\n    }\n\n}\n", "idx": 22720}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(rgb24to15)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n    const uint8_t *s = src;\n\n    const uint8_t *end;\n\n#if COMPILE_TEMPLATE_MMX\n\n    const uint8_t *mm_end;\n\n#endif\n\n    uint16_t *d = (uint16_t *)dst;\n\n    end = s + src_size;\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*src):\"memory\");\n\n    __asm__ volatile(\n\n        \"movq         %0, %%mm7     \\n\\t\"\n\n        \"movq         %1, %%mm6     \\n\\t\"\n\n        ::\"m\"(red_15mask),\"m\"(green_15mask));\n\n    mm_end = end - 15;\n\n    while (s < mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"   32%1            \\n\\t\"\n\n            \"movd         %1, %%mm0     \\n\\t\"\n\n            \"movd        3%1, %%mm3     \\n\\t\"\n\n            \"punpckldq   6%1, %%mm0     \\n\\t\"\n\n            \"punpckldq   9%1, %%mm3     \\n\\t\"\n\n            \"movq      %%mm0, %%mm1     \\n\\t\"\n\n            \"movq      %%mm0, %%mm2     \\n\\t\"\n\n            \"movq      %%mm3, %%mm4     \\n\\t\"\n\n            \"movq      %%mm3, %%mm5     \\n\\t\"\n\n            \"psllq        $7, %%mm0     \\n\\t\"\n\n            \"psllq        $7, %%mm3     \\n\\t\"\n\n            \"pand      %%mm7, %%mm0     \\n\\t\"\n\n            \"pand      %%mm7, %%mm3     \\n\\t\"\n\n            \"psrlq        $6, %%mm1     \\n\\t\"\n\n            \"psrlq        $6, %%mm4     \\n\\t\"\n\n            \"pand      %%mm6, %%mm1     \\n\\t\"\n\n            \"pand      %%mm6, %%mm4     \\n\\t\"\n\n            \"psrlq       $19, %%mm2     \\n\\t\"\n\n            \"psrlq       $19, %%mm5     \\n\\t\"\n\n            \"pand         %2, %%mm2     \\n\\t\"\n\n            \"pand         %2, %%mm5     \\n\\t\"\n\n            \"por       %%mm1, %%mm0     \\n\\t\"\n\n            \"por       %%mm4, %%mm3     \\n\\t\"\n\n            \"por       %%mm2, %%mm0     \\n\\t\"\n\n            \"por       %%mm5, %%mm3     \\n\\t\"\n\n            \"psllq       $16, %%mm3     \\n\\t\"\n\n            \"por       %%mm3, %%mm0     \\n\\t\"\n\n            MOVNTQ\"    %%mm0, %0        \\n\\t\"\n\n            :\"=m\"(*d):\"m\"(*s),\"m\"(blue_15mask):\"memory\");\n\n        d += 4;\n\n        s += 12;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n#endif\n\n    while (s < end) {\n\n        const int r = *s++;\n\n        const int g = *s++;\n\n        const int b = *s++;\n\n        *d++ = (b>>3) | ((g&0xF8)<<2) | ((r&0xF8)<<7);\n\n    }\n\n}\n", "idx": 22721}
{"project": "FFmpeg", "commit_id": "ae100046ca32b0b83031a60d0c3cdfc5ceb9f874", "target": 0, "func": "static int avi_extract_stream_metadata(AVFormatContext *s, AVStream *st)\n\n{\n\n    GetByteContext gb;\n\n    uint8_t *data = st->codecpar->extradata;\n\n    int data_size = st->codecpar->extradata_size;\n\n    int tag, offset;\n\n\n\n    if (!data || data_size < 8) {\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    bytestream2_init(&gb, data, data_size);\n\n\n\n    tag = bytestream2_get_le32(&gb);\n\n\n\n    switch (tag) {\n\n    case MKTAG('A', 'V', 'I', 'F'):\n\n        // skip 4 byte padding\n\n        bytestream2_skip(&gb, 4);\n\n        offset = bytestream2_tell(&gb);\n\n        bytestream2_init(&gb, data + offset, data_size - offset);\n\n\n\n        // decode EXIF tags from IFD, AVI is always little-endian\n\n        return avpriv_exif_decode_ifd(s, &gb, 1, 0, &st->metadata);\n\n        break;\n\n    case MKTAG('C', 'A', 'S', 'I'):\n\n        avpriv_request_sample(s, \"RIFF stream data tag type CASI (%u)\", tag);\n\n        break;\n\n    case MKTAG('Z', 'o', 'r', 'a'):\n\n        avpriv_request_sample(s, \"RIFF stream data tag type Zora (%u)\", tag);\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22722}
{"project": "FFmpeg", "commit_id": "f6b7f72461673e4d398b1edf9ed2a7fe70d99c47", "target": 0, "func": "static void av_always_inline filter_mb_edgecv( uint8_t *pix, int stride, const int16_t bS[4], unsigned int qp, H264Context *h, int intra ) {\n\n    const int qp_bd_offset = 6 * (h->sps.bit_depth_luma - 8);\n\n    const unsigned int index_a = qp - qp_bd_offset + h->slice_alpha_c0_offset;\n\n    const int alpha = alpha_table[index_a];\n\n    const int beta  = beta_table[qp - qp_bd_offset + h->slice_beta_offset];\n\n    if (alpha ==0 || beta == 0) return;\n\n\n\n    if( bS[0] < 4 || !intra ) {\n\n        int8_t tc[4];\n\n        tc[0] = tc0_table[index_a][bS[0]]+1;\n\n        tc[1] = tc0_table[index_a][bS[1]]+1;\n\n        tc[2] = tc0_table[index_a][bS[2]]+1;\n\n        tc[3] = tc0_table[index_a][bS[3]]+1;\n\n        h->h264dsp.h264_h_loop_filter_chroma(pix, stride, alpha, beta, tc);\n\n    } else {\n\n        h->h264dsp.h264_h_loop_filter_chroma_intra(pix, stride, alpha, beta);\n\n    }\n\n}\n", "idx": 22733}
{"project": "FFmpeg", "commit_id": "355e27e24dc88d6ba8f27501a34925d9d937a399", "target": 1, "func": "static int flic_decode_frame_8BPP(AVCodecContext *avctx,\n                                  void *data, int *got_frame,\n                                  const uint8_t *buf, int buf_size)\n{\n    FlicDecodeContext *s = avctx->priv_data;\n    GetByteContext g2;\n    int pixel_ptr;\n    int palette_ptr;\n    unsigned char palette_idx1;\n    unsigned char palette_idx2;\n    unsigned int frame_size;\n    int num_chunks;\n    unsigned int chunk_size;\n    int chunk_type;\n    int i, j, ret;\n    int color_packets;\n    int color_changes;\n    int color_shift;\n    unsigned char r, g, b;\n    int lines;\n    int compressed_lines;\n    int starting_line;\n    signed short line_packets;\n    int y_ptr;\n    int byte_run;\n    int pixel_skip;\n    int pixel_countdown;\n    unsigned char *pixels;\n    unsigned int pixel_limit;\n    bytestream2_init(&g2, buf, buf_size);\n    if ((ret = ff_reget_buffer(avctx, s->frame)) < 0)\n        return ret;\n    pixels = s->frame->data[0];\n    pixel_limit = s->avctx->height * s->frame->linesize[0];\n    if (buf_size < 16 || buf_size > INT_MAX - (3 * 256 + AV_INPUT_BUFFER_PADDING_SIZE))\n    frame_size = bytestream2_get_le32(&g2);\n    if (frame_size > buf_size)\n        frame_size = buf_size;\n    bytestream2_skip(&g2, 2); /* skip the magic number */\n    num_chunks = bytestream2_get_le16(&g2);\n    bytestream2_skip(&g2, 8);  /* skip padding */\n    frame_size -= 16;\n    /* iterate through the chunks */\n    while ((frame_size >= 6) && (num_chunks > 0) &&\n            bytestream2_get_bytes_left(&g2) >= 4) {\n        int stream_ptr_after_chunk;\n        chunk_size = bytestream2_get_le32(&g2);\n        if (chunk_size > frame_size) {\n            av_log(avctx, AV_LOG_WARNING,\n                   \"Invalid chunk_size = %u > frame_size = %u\\n\", chunk_size, frame_size);\n            chunk_size = frame_size;\n        }\n        stream_ptr_after_chunk = bytestream2_tell(&g2) - 4 + chunk_size;\n        chunk_type = bytestream2_get_le16(&g2);\n        switch (chunk_type) {\n        case FLI_256_COLOR:\n        case FLI_COLOR:\n            /* check special case: If this file is from the Magic Carpet\n             * game and uses 6-bit colors even though it reports 256-color\n             * chunks in a 0xAF12-type file (fli_type is set to 0xAF13 during\n             * initialization) */\n            if ((chunk_type == FLI_256_COLOR) && (s->fli_type != FLC_MAGIC_CARPET_SYNTHETIC_TYPE_CODE))\n                color_shift = 0;\n            else\n                color_shift = 2;\n            /* set up the palette */\n            color_packets = bytestream2_get_le16(&g2);\n            palette_ptr = 0;\n            for (i = 0; i < color_packets; i++) {\n                /* first byte is how many colors to skip */\n                palette_ptr += bytestream2_get_byte(&g2);\n                /* next byte indicates how many entries to change */\n                color_changes = bytestream2_get_byte(&g2);\n                /* if there are 0 color changes, there are actually 256 */\n                if (color_changes == 0)\n                    color_changes = 256;\n                if (bytestream2_tell(&g2) + color_changes * 3 > stream_ptr_after_chunk)\n                    break;\n                for (j = 0; j < color_changes; j++) {\n                    unsigned int entry;\n                    /* wrap around, for good measure */\n                    if ((unsigned)palette_ptr >= 256)\n                        palette_ptr = 0;\n                    r = bytestream2_get_byte(&g2) << color_shift;\n                    g = bytestream2_get_byte(&g2) << color_shift;\n                    b = bytestream2_get_byte(&g2) << color_shift;\n                    entry = 0xFFU << 24 | r << 16 | g << 8 | b;\n                    if (color_shift == 2)\n                        entry |= entry >> 6 & 0x30303;\n                    if (s->palette[palette_ptr] != entry)\n                        s->new_palette = 1;\n                    s->palette[palette_ptr++] = entry;\n                }\n            }\n            break;\n        case FLI_DELTA:\n            y_ptr = 0;\n            compressed_lines = bytestream2_get_le16(&g2);\n            while (compressed_lines > 0) {\n                if (bytestream2_tell(&g2) + 2 > stream_ptr_after_chunk)\n                    break;\n                line_packets = bytestream2_get_le16(&g2);\n                if ((line_packets & 0xC000) == 0xC000) {\n                    // line skip opcode\n                    line_packets = -line_packets;\n                    y_ptr += line_packets * s->frame->linesize[0];\n                } else if ((line_packets & 0xC000) == 0x4000) {\n                    av_log(avctx, AV_LOG_ERROR, \"Undefined opcode (%x) in DELTA_FLI\\n\", line_packets);\n                } else if ((line_packets & 0xC000) == 0x8000) {\n                    // \"last byte\" opcode\n                    pixel_ptr= y_ptr + s->frame->linesize[0] - 1;\n                    CHECK_PIXEL_PTR(0);\n                    pixels[pixel_ptr] = line_packets & 0xff;\n                } else {\n                    compressed_lines--;\n                    pixel_ptr = y_ptr;\n                    CHECK_PIXEL_PTR(0);\n                    pixel_countdown = s->avctx->width;\n                    for (i = 0; i < line_packets; i++) {\n                        if (bytestream2_tell(&g2) + 2 > stream_ptr_after_chunk)\n                            break;\n                        /* account for the skip bytes */\n                        pixel_skip = bytestream2_get_byte(&g2);\n                        pixel_ptr += pixel_skip;\n                        pixel_countdown -= pixel_skip;\n                        byte_run = sign_extend(bytestream2_get_byte(&g2), 8);\n                        if (byte_run < 0) {\n                            byte_run = -byte_run;\n                            palette_idx1 = bytestream2_get_byte(&g2);\n                            palette_idx2 = bytestream2_get_byte(&g2);\n                            CHECK_PIXEL_PTR(byte_run * 2);\n                            for (j = 0; j < byte_run; j++, pixel_countdown -= 2) {\n                                pixels[pixel_ptr++] = palette_idx1;\n                                pixels[pixel_ptr++] = palette_idx2;\n                            }\n                        } else {\n                            CHECK_PIXEL_PTR(byte_run * 2);\n                            if (bytestream2_tell(&g2) + byte_run * 2 > stream_ptr_after_chunk)\n                                break;\n                            for (j = 0; j < byte_run * 2; j++, pixel_countdown--) {\n                                pixels[pixel_ptr++] = bytestream2_get_byte(&g2);\n                            }\n                        }\n                    }\n                    y_ptr += s->frame->linesize[0];\n                }\n            }\n            break;\n        case FLI_LC:\n            /* line compressed */\n            starting_line = bytestream2_get_le16(&g2);\n            y_ptr = 0;\n            y_ptr += starting_line * s->frame->linesize[0];\n            compressed_lines = bytestream2_get_le16(&g2);\n            while (compressed_lines > 0) {\n                pixel_ptr = y_ptr;\n                CHECK_PIXEL_PTR(0);\n                pixel_countdown = s->avctx->width;\n                if (bytestream2_tell(&g2) + 1 > stream_ptr_after_chunk)\n                    break;\n                line_packets = bytestream2_get_byte(&g2);\n                if (line_packets > 0) {\n                    for (i = 0; i < line_packets; i++) {\n                        /* account for the skip bytes */\n                        if (bytestream2_tell(&g2) + 1 > stream_ptr_after_chunk)\n                            break;\n                        pixel_skip = bytestream2_get_byte(&g2);\n                        pixel_ptr += pixel_skip;\n                        pixel_countdown -= pixel_skip;\n                        byte_run = sign_extend(bytestream2_get_byte(&g2),8);\n                        if (byte_run > 0) {\n                            CHECK_PIXEL_PTR(byte_run);\n                            if (bytestream2_tell(&g2) + byte_run > stream_ptr_after_chunk)\n                                break;\n                            for (j = 0; j < byte_run; j++, pixel_countdown--) {\n                                pixels[pixel_ptr++] = bytestream2_get_byte(&g2);\n                            }\n                        } else if (byte_run < 0) {\n                            byte_run = -byte_run;\n                            palette_idx1 = bytestream2_get_byte(&g2);\n                            CHECK_PIXEL_PTR(byte_run);\n                            for (j = 0; j < byte_run; j++, pixel_countdown--) {\n                                pixels[pixel_ptr++] = palette_idx1;\n                            }\n                        }\n                    }\n                }\n                y_ptr += s->frame->linesize[0];\n                compressed_lines--;\n            }\n            break;\n        case FLI_BLACK:\n            /* set the whole frame to color 0 (which is usually black) */\n            memset(pixels, 0,\n                s->frame->linesize[0] * s->avctx->height);\n            break;\n        case FLI_BRUN:\n            /* Byte run compression: This chunk type only occurs in the first\n             * FLI frame and it will update the entire frame. */\n            y_ptr = 0;\n            for (lines = 0; lines < s->avctx->height; lines++) {\n                pixel_ptr = y_ptr;\n                /* disregard the line packets; instead, iterate through all\n                 * pixels on a row */\n                 bytestream2_skip(&g2, 1);\n                pixel_countdown = s->avctx->width;\n                while (pixel_countdown > 0) {\n                    if (bytestream2_tell(&g2) + 1 > stream_ptr_after_chunk)\n                        break;\n                    byte_run = sign_extend(bytestream2_get_byte(&g2), 8);\n                    if (!byte_run) {\n                        av_log(avctx, AV_LOG_ERROR, \"Invalid byte run value.\\n\");\n                    }\n                    if (byte_run > 0) {\n                        palette_idx1 = bytestream2_get_byte(&g2);\n                        CHECK_PIXEL_PTR(byte_run);\n                        for (j = 0; j < byte_run; j++) {\n                            pixels[pixel_ptr++] = palette_idx1;\n                            pixel_countdown--;\n                            if (pixel_countdown < 0)\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d) at line %d\\n\",\n                                       pixel_countdown, lines);\n                        }\n                    } else {  /* copy bytes if byte_run < 0 */\n                        byte_run = -byte_run;\n                        CHECK_PIXEL_PTR(byte_run);\n                        if (bytestream2_tell(&g2) + byte_run > stream_ptr_after_chunk)\n                            break;\n                        for (j = 0; j < byte_run; j++) {\n                            pixels[pixel_ptr++] = bytestream2_get_byte(&g2);\n                            pixel_countdown--;\n                            if (pixel_countdown < 0)\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d) at line %d\\n\",\n                                       pixel_countdown, lines);\n                        }\n                    }\n                }\n                y_ptr += s->frame->linesize[0];\n            }\n            break;\n        case FLI_COPY:\n            /* copy the chunk (uncompressed frame) */\n            if (chunk_size - 6 != FFALIGN(s->avctx->width, 4) * s->avctx->height) {\n                av_log(avctx, AV_LOG_ERROR, \"In chunk FLI_COPY : source data (%d bytes) \" \\\n                       \"has incorrect size, skipping chunk\\n\", chunk_size - 6);\n                bytestream2_skip(&g2, chunk_size - 6);\n            } else {\n                for (y_ptr = 0; y_ptr < s->frame->linesize[0] * s->avctx->height;\n                     y_ptr += s->frame->linesize[0]) {\n                    bytestream2_get_buffer(&g2, &pixels[y_ptr],\n                                           s->avctx->width);\n                    if (s->avctx->width & 3)\n                        bytestream2_skip(&g2, 4 - (s->avctx->width & 3));\n                }\n            }\n            break;\n        case FLI_MINI:\n            /* some sort of a thumbnail? disregard this chunk... */\n            break;\n        default:\n            av_log(avctx, AV_LOG_ERROR, \"Unrecognized chunk type: %d\\n\", chunk_type);\n            break;\n        }\n        if (stream_ptr_after_chunk - bytestream2_tell(&g2) >= 0) {\n            bytestream2_skip(&g2, stream_ptr_after_chunk - bytestream2_tell(&g2));\n        } else {\n            av_log(avctx, AV_LOG_ERROR, \"Chunk overread\\n\");\n            break;\n        }\n        frame_size -= chunk_size;\n        num_chunks--;\n    }\n    /* by the end of the chunk, the stream ptr should equal the frame\n     * size (minus 1 or 2, possibly); if it doesn't, issue a warning */\n    if (bytestream2_get_bytes_left(&g2) > 2)\n        av_log(avctx, AV_LOG_ERROR, \"Processed FLI chunk where chunk size = %d \" \\\n               \"and final chunk ptr = %d\\n\", buf_size,\n               buf_size - bytestream2_get_bytes_left(&g2));\n    /* make the palette available on the way out */\n    memcpy(s->frame->data[1], s->palette, AVPALETTE_SIZE);\n    if (s->new_palette) {\n        s->frame->palette_has_changed = 1;\n        s->new_palette = 0;\n    }\n    if ((ret = av_frame_ref(data, s->frame)) < 0)\n        return ret;\n    *got_frame = 1;\n    return buf_size;\n}", "idx": 22742}
{"project": "FFmpeg", "commit_id": "92e483f8ed70d88d4f64337f65bae212502735d4", "target": 1, "func": "static int cmp_color(const void *a, const void *b)\n\n{\n\n    const struct range_box *box1 = a;\n\n    const struct range_box *box2 = b;\n\n    return box1->color - box2->color;\n\n}\n", "idx": 22744}
{"project": "FFmpeg", "commit_id": "dbbb9262ca0fd09f2582b11157a74c88ab7e1db5", "target": 0, "func": "static void reconstruct_stereo_16(int32_t *buffer[MAX_CHANNELS],\n\n                                  int16_t *buffer_out,\n\n                                  int numchannels, int numsamples,\n\n                                  uint8_t interlacing_shift,\n\n                                  uint8_t interlacing_leftweight)\n\n{\n\n    int i;\n\n    if (numsamples <= 0)\n\n        return;\n\n\n\n    /* weighted interlacing */\n\n    if (interlacing_leftweight) {\n\n        for (i = 0; i < numsamples; i++) {\n\n            int32_t a, b;\n\n\n\n            a = buffer[0][i];\n\n            b = buffer[1][i];\n\n\n\n            a -= (b * interlacing_leftweight) >> interlacing_shift;\n\n            b += a;\n\n\n\n            buffer_out[i*numchannels] = b;\n\n            buffer_out[i*numchannels + 1] = a;\n\n        }\n\n\n\n        return;\n\n    }\n\n\n\n    /* otherwise basic interlacing took place */\n\n    for (i = 0; i < numsamples; i++) {\n\n        int16_t left, right;\n\n\n\n        left = buffer[0][i];\n\n        right = buffer[1][i];\n\n\n\n        buffer_out[i*numchannels] = left;\n\n        buffer_out[i*numchannels + 1] = right;\n\n    }\n\n}\n", "idx": 22747}
{"project": "FFmpeg", "commit_id": "e54061ae6a5e22bad5c66ef4411acc8f778a9f90", "target": 0, "func": "av_cold void ff_vp9_init_static(AVCodec *codec)\n\n{\n\n    if (    vpx_codec_version_major() < 1\n\n        || (vpx_codec_version_major() == 1 && vpx_codec_version_minor() < 3))\n\n        codec->capabilities |= AV_CODEC_CAP_EXPERIMENTAL;\n\n    codec->pix_fmts = vp9_pix_fmts_def;\n\n#if CONFIG_LIBVPX_VP9_ENCODER\n\n    if (    vpx_codec_version_major() > 1\n\n        || (vpx_codec_version_major() == 1 && vpx_codec_version_minor() >= 4)) {\n\n#ifdef VPX_CODEC_CAP_HIGHBITDEPTH\n\n        vpx_codec_caps_t codec_caps = vpx_codec_get_caps(vpx_codec_vp9_cx());\n\n        if (codec_caps & VPX_CODEC_CAP_HIGHBITDEPTH)\n\n            codec->pix_fmts = vp9_pix_fmts_highbd;\n\n        else\n\n#endif\n\n            codec->pix_fmts = vp9_pix_fmts_highcol;\n\n    }\n\n#endif\n\n}\n", "idx": 22748}
{"project": "FFmpeg", "commit_id": "d16ec1b6db25bc348b0d4800c9a0c9b7070e3710", "target": 0, "func": "static void decode_tones_amplitude(GetBitContext *gb, Atrac3pChanUnitCtx *ctx,\n\n                                   int ch_num, int band_has_tones[])\n\n{\n\n    int mode, sb, j, i, diff, maxdiff, fi, delta, pred;\n\n    Atrac3pWaveParam *wsrc, *wref;\n\n    int refwaves[48];\n\n    Atrac3pWavesData *dst = ctx->channels[ch_num].tones_info;\n\n    Atrac3pWavesData *ref = ctx->channels[0].tones_info;\n\n\n\n    if (ch_num) {\n\n        for (sb = 0; sb < ctx->waves_info->num_tone_bands; sb++) {\n\n            if (!band_has_tones[sb] || !dst[sb].num_wavs)\n\n                continue;\n\n            wsrc = &ctx->waves_info->waves[dst[sb].start_index];\n\n            wref = &ctx->waves_info->waves[ref[sb].start_index];\n\n            for (j = 0; j < dst[sb].num_wavs; j++) {\n\n                for (i = 0, fi = 0, maxdiff = 1024; i < ref[sb].num_wavs; i++) {\n\n                    diff = FFABS(wsrc[j].freq_index - wref[i].freq_index);\n\n                    if (diff < maxdiff) {\n\n                        maxdiff = diff;\n\n                        fi      = i;\n\n                    }\n\n                }\n\n\n\n                if (maxdiff < 8)\n\n                    refwaves[dst[sb].start_index + j] = fi + ref[sb].start_index;\n\n                else if (j < ref[sb].num_wavs)\n\n                    refwaves[dst[sb].start_index + j] = j + ref[sb].start_index;\n\n                else\n\n                    refwaves[dst[sb].start_index + j] = -1;\n\n            }\n\n        }\n\n    }\n\n\n\n    mode = get_bits(gb, ch_num + 1);\n\n\n\n    switch (mode) {\n\n    case 0: /** fixed-length coding */\n\n        for (sb = 0; sb < ctx->waves_info->num_tone_bands; sb++) {\n\n            if (!band_has_tones[sb] || !dst[sb].num_wavs)\n\n                continue;\n\n            if (ctx->waves_info->amplitude_mode)\n\n                for (i = 0; i < dst[sb].num_wavs; i++)\n\n                    ctx->waves_info->waves[dst[sb].start_index + i].amp_sf = get_bits(gb, 6);\n\n            else\n\n                ctx->waves_info->waves[dst[sb].start_index].amp_sf = get_bits(gb, 6);\n\n        }\n\n        break;\n\n    case 1: /** min + VLC delta */\n\n        for (sb = 0; sb < ctx->waves_info->num_tone_bands; sb++) {\n\n            if (!band_has_tones[sb] || !dst[sb].num_wavs)\n\n                continue;\n\n            if (ctx->waves_info->amplitude_mode)\n\n                for (i = 0; i < dst[sb].num_wavs; i++)\n\n                    ctx->waves_info->waves[dst[sb].start_index + i].amp_sf =\n\n                        get_vlc2(gb, tone_vlc_tabs[3].table,\n\n                                 tone_vlc_tabs[3].bits, 1) + 20;\n\n            else\n\n                ctx->waves_info->waves[dst[sb].start_index].amp_sf =\n\n                    get_vlc2(gb, tone_vlc_tabs[4].table,\n\n                             tone_vlc_tabs[4].bits, 1) + 24;\n\n        }\n\n        break;\n\n    case 2: /** VLC modulo delta to master (slave only) */\n\n        for (sb = 0; sb < ctx->waves_info->num_tone_bands; sb++) {\n\n            if (!band_has_tones[sb] || !dst[sb].num_wavs)\n\n                continue;\n\n            for (i = 0; i < dst[sb].num_wavs; i++) {\n\n                delta = get_vlc2(gb, tone_vlc_tabs[5].table,\n\n                                 tone_vlc_tabs[5].bits, 1);\n\n                delta = sign_extend(delta, 5);\n\n                pred  = refwaves[dst[sb].start_index + i] >= 0 ?\n\n                        ctx->waves_info->waves[refwaves[dst[sb].start_index + i]].amp_sf : 34;\n\n                ctx->waves_info->waves[dst[sb].start_index + i].amp_sf = (pred + delta) & 0x3F;\n\n            }\n\n        }\n\n        break;\n\n    case 3: /** clone master (slave only) */\n\n        for (sb = 0; sb < ctx->waves_info->num_tone_bands; sb++) {\n\n            if (!band_has_tones[sb])\n\n                continue;\n\n            for (i = 0; i < dst[sb].num_wavs; i++)\n\n                ctx->waves_info->waves[dst[sb].start_index + i].amp_sf =\n\n                    refwaves[dst[sb].start_index + i] >= 0\n\n                    ? ctx->waves_info->waves[refwaves[dst[sb].start_index + i]].amp_sf\n\n                    : 32;\n\n        }\n\n        break;\n\n    }\n\n}\n", "idx": 22751}
{"project": "FFmpeg", "commit_id": "985c5f226af35fff00a86bc36cc8eaa8da3d23b0", "target": 0, "func": "int attribute_align_arg avcodec_decode_video2(AVCodecContext *avctx, AVFrame *picture,\n\n                                              int *got_picture_ptr,\n\n                                              const AVPacket *avpkt)\n\n{\n\n    AVCodecInternal *avci = avctx->internal;\n\n    int ret;\n\n    // copy to ensure we do not change avpkt\n\n    AVPacket tmp = *avpkt;\n\n\n\n    if (!avctx->codec)\n\n        return AVERROR(EINVAL);\n\n    if (avctx->codec->type != AVMEDIA_TYPE_VIDEO) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid media type for video\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    *got_picture_ptr = 0;\n\n    if ((avctx->coded_width || avctx->coded_height) && av_image_check_size(avctx->coded_width, avctx->coded_height, 0, avctx))\n\n        return AVERROR(EINVAL);\n\n\n\n    avcodec_get_frame_defaults(picture);\n\n\n\n    if ((avctx->codec->capabilities & CODEC_CAP_DELAY) || avpkt->size || (avctx->active_thread_type & FF_THREAD_FRAME)) {\n\n        int did_split = av_packet_split_side_data(&tmp);\n\n        ret = apply_param_change(avctx, &tmp);\n\n        if (ret < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Error applying parameter changes.\\n\");\n\n            if (avctx->err_recognition & AV_EF_EXPLODE)\n\n                goto fail;\n\n        }\n\n\n\n        avctx->internal->pkt = &tmp;\n\n        if (HAVE_THREADS && avctx->active_thread_type & FF_THREAD_FRAME)\n\n            ret = ff_thread_decode_frame(avctx, picture, got_picture_ptr,\n\n                                         &tmp);\n\n        else {\n\n            ret = avctx->codec->decode(avctx, picture, got_picture_ptr,\n\n                                       &tmp);\n\n            picture->pkt_dts = avpkt->dts;\n\n\n\n            if(!avctx->has_b_frames){\n\n                av_frame_set_pkt_pos(picture, avpkt->pos);\n\n            }\n\n            //FIXME these should be under if(!avctx->has_b_frames)\n\n            /* get_buffer is supposed to set frame parameters */\n\n            if (!(avctx->codec->capabilities & CODEC_CAP_DR1)) {\n\n                if (!picture->sample_aspect_ratio.num)    picture->sample_aspect_ratio = avctx->sample_aspect_ratio;\n\n                if (!picture->width)                      picture->width               = avctx->width;\n\n                if (!picture->height)                     picture->height              = avctx->height;\n\n                if (picture->format == AV_PIX_FMT_NONE)   picture->format              = avctx->pix_fmt;\n\n            }\n\n        }\n\n        add_metadata_from_side_data(avctx, picture);\n\n\n\nfail:\n\n        emms_c(); //needed to avoid an emms_c() call before every return;\n\n\n\n        avctx->internal->pkt = NULL;\n\n        if (did_split) {\n\n            av_packet_free_side_data(&tmp);\n\n            if(ret == tmp.size)\n\n                ret = avpkt->size;\n\n        }\n\n\n\n        if (*got_picture_ptr) {\n\n            if (!avctx->refcounted_frames) {\n\n                int err = unrefcount_frame(avci, picture);\n\n                if (err < 0)\n\n                    return err;\n\n            }\n\n\n\n            avctx->frame_number++;\n\n            av_frame_set_best_effort_timestamp(picture,\n\n                                               guess_correct_pts(avctx,\n\n                                                                 picture->pkt_pts,\n\n                                                                 picture->pkt_dts));\n\n        } else\n\n            av_frame_unref(picture);\n\n    } else\n\n        ret = 0;\n\n\n\n    /* many decoders assign whole AVFrames, thus overwriting extended_data;\n\n     * make sure it's set correctly */\n\n    picture->extended_data = picture->data;\n\n\n\n    return ret;\n\n}\n", "idx": 22762}
{"project": "FFmpeg", "commit_id": "54d7fcc1207ed37356f06e3a31a4e6bdaa096958", "target": 0, "func": "static int init(AVFilterContext *ctx, const char *args, void *opaque)\n\n{\n\n    GraphContext *gctx = ctx->priv;\n\n\n\n    if(!args)\n\n        return 0;\n\n\n\n    if(!(gctx->link_filter = avfilter_open(&vf_graph_dummy, NULL)))\n\n        return -1;\n\n    if(avfilter_init_filter(gctx->link_filter, NULL, ctx))\n\n        goto fail;\n\n\n\n    return graph_load_chain_from_string(ctx, args, NULL, NULL);\n\n\n\nfail:\n\n    avfilter_destroy(gctx->link_filter);\n\n    return -1;\n\n}\n", "idx": 22773}
{"project": "FFmpeg", "commit_id": "6bed20f45a484f5709fec4c97a238240161b1797", "target": 0, "func": "matroska_parse_block(MatroskaDemuxContext *matroska, uint8_t *data, int size,\n\n                     int64_t pos, uint64_t cluster_time,\n\n                     int is_keyframe, int *ptrack, AVPacket **ppkt)\n\n{\n\n    int res = 0;\n\n    int track;\n\n    AVPacket *pkt;\n\n    uint8_t *origdata = data;\n\n    int16_t block_time;\n\n    uint32_t *lace_size = NULL;\n\n    int n, flags, laces = 0;\n\n    uint64_t num;\n\n\n\n    /* first byte(s): tracknum */\n\n    if ((n = matroska_ebmlnum_uint(data, size, &num)) < 0) {\n\n        av_log(matroska->ctx, AV_LOG_ERROR, \"EBML block data error\\n\");\n\n        av_free(origdata);\n\n        return res;\n\n    }\n\n    data += n;\n\n    size -= n;\n\n\n\n    /* fetch track from num */\n\n    track = matroska_find_track_by_num(matroska, num);\n\n    if (ptrack)  *ptrack = track;\n\n    if (size <= 3 || track < 0 || track >= matroska->num_tracks) {\n\n        av_log(matroska->ctx, AV_LOG_INFO,\n\n               \"Invalid stream %d or size %u\\n\", track, size);\n\n        av_free(origdata);\n\n        return res;\n\n    }\n\n    if(matroska->ctx->streams[ matroska->tracks[track]->stream_index ]->discard >= AVDISCARD_ALL){\n\n        av_free(origdata);\n\n        return res;\n\n    }\n\n\n\n    /* block_time (relative to cluster time) */\n\n    block_time = (data[0] << 8) | data[1];\n\n    data += 2;\n\n    size -= 2;\n\n    flags = *data;\n\n    data += 1;\n\n    size -= 1;\n\n    if (is_keyframe == -1)\n\n        is_keyframe = flags & 1 ? PKT_FLAG_KEY : 0;\n\n    switch ((flags & 0x06) >> 1) {\n\n        case 0x0: /* no lacing */\n\n            laces = 1;\n\n            lace_size = av_mallocz(sizeof(int));\n\n            lace_size[0] = size;\n\n            break;\n\n\n\n        case 0x1: /* xiph lacing */\n\n        case 0x2: /* fixed-size lacing */\n\n        case 0x3: /* EBML lacing */\n\n            if (size == 0) {\n\n                res = -1;\n\n                break;\n\n            }\n\n            laces = (*data) + 1;\n\n            data += 1;\n\n            size -= 1;\n\n            lace_size = av_mallocz(laces * sizeof(int));\n\n\n\n            switch ((flags & 0x06) >> 1) {\n\n                case 0x1: /* xiph lacing */ {\n\n                    uint8_t temp;\n\n                    uint32_t total = 0;\n\n                    for (n = 0; res == 0 && n < laces - 1; n++) {\n\n                        while (1) {\n\n                            if (size == 0) {\n\n                                res = -1;\n\n                                break;\n\n                            }\n\n                            temp = *data;\n\n                            lace_size[n] += temp;\n\n                            data += 1;\n\n                            size -= 1;\n\n                            if (temp != 0xff)\n\n                                break;\n\n                        }\n\n                        total += lace_size[n];\n\n                    }\n\n                    lace_size[n] = size - total;\n\n                    break;\n\n                }\n\n\n\n                case 0x2: /* fixed-size lacing */\n\n                    for (n = 0; n < laces; n++)\n\n                        lace_size[n] = size / laces;\n\n                    break;\n\n\n\n                case 0x3: /* EBML lacing */ {\n\n                    uint32_t total;\n\n                    n = matroska_ebmlnum_uint(data, size, &num);\n\n                    if (n < 0) {\n\n                        av_log(matroska->ctx, AV_LOG_INFO,\n\n                               \"EBML block data error\\n\");\n\n                        break;\n\n                    }\n\n                    data += n;\n\n                    size -= n;\n\n                    total = lace_size[0] = num;\n\n                    for (n = 1; res == 0 && n < laces - 1; n++) {\n\n                        int64_t snum;\n\n                        int r;\n\n                        r = matroska_ebmlnum_sint (data, size, &snum);\n\n                        if (r < 0) {\n\n                            av_log(matroska->ctx, AV_LOG_INFO,\n\n                                   \"EBML block data error\\n\");\n\n                            break;\n\n                        }\n\n                        data += r;\n\n                        size -= r;\n\n                        lace_size[n] = lace_size[n - 1] + snum;\n\n                        total += lace_size[n];\n\n                    }\n\n                    lace_size[n] = size - total;\n\n                    break;\n\n                }\n\n            }\n\n            break;\n\n    }\n\n\n\n    if (res == 0) {\n\n        int real_v = matroska->tracks[track]->flags & MATROSKA_TRACK_REAL_V;\n\n        for (n = 0; n < laces; n++) {\n\n            uint64_t timecode = AV_NOPTS_VALUE;\n\n            int slice, slices = 1;\n\n\n\n            if (real_v) {\n\n                slices = *data++ + 1;\n\n                lace_size[n]--;\n\n            }\n\n            if (cluster_time != (uint64_t)-1 && n == 0) {\n\n                if (cluster_time + block_time >= 0)\n\n                    timecode = (cluster_time + block_time) * matroska->time_scale;\n\n            }\n\n            /* FIXME: duration */\n\n\n\n            for (slice=0; slice<slices; slice++) {\n\n                int slice_size, slice_offset = 0;\n\n                if (real_v)\n\n                    slice_offset = rv_offset(data, slice, slices);\n\n                if (slice+1 == slices)\n\n                    slice_size = lace_size[n] - slice_offset;\n\n                else\n\n                    slice_size = rv_offset(data, slice+1, slices) - slice_offset;\n\n                pkt = av_mallocz(sizeof(AVPacket));\n\n                if (ppkt)  *ppkt = pkt;\n\n                /* XXX: prevent data copy... */\n\n                if (av_new_packet(pkt, slice_size) < 0) {\n\n                    res = AVERROR_NOMEM;\n\n                    n = laces-1;\n\n                    break;\n\n                }\n\n                memcpy (pkt->data, data+slice_offset, slice_size);\n\n\n\n                if (n == 0)\n\n                    pkt->flags = is_keyframe;\n\n                pkt->stream_index = matroska->tracks[track]->stream_index;\n\n\n\n                pkt->pts = timecode;\n\n                pkt->pos = pos;\n\n\n\n                matroska_queue_packet(matroska, pkt);\n\n            }\n\n            data += lace_size[n];\n\n        }\n\n    }\n\n\n\n    av_free(lace_size);\n\n    av_free(origdata);\n\n    return res;\n\n}\n", "idx": 22790}
{"project": "FFmpeg", "commit_id": "3825b5268844694ff50a0e0bfde64df43a862fae", "target": 0, "func": "static void return_frame(AVFilterContext *ctx, int is_second)\n\n{\n\n    YADIFContext *yadif = ctx->priv;\n\n    AVFilterLink *link= ctx->outputs[0];\n\n    int tff;\n\n\n\n    if (yadif->parity == -1) {\n\n        tff = yadif->cur->video->interlaced ?\n\n            yadif->cur->video->top_field_first : 1;\n\n    } else {\n\n        tff = yadif->parity^1;\n\n    }\n\n\n\n    if (is_second) {\n\n        yadif->out = ff_get_video_buffer(link, AV_PERM_WRITE | AV_PERM_PRESERVE |\n\n                                         AV_PERM_REUSE, link->w, link->h);\n\n        avfilter_copy_buffer_ref_props(yadif->out, yadif->cur);\n\n        yadif->out->video->interlaced = 0;\n\n    }\n\n\n\n    if (!yadif->csp)\n\n        yadif->csp = &av_pix_fmt_descriptors[link->format];\n\n    if (yadif->csp->comp[0].depth_minus1 / 8 == 1)\n\n        yadif->filter_line = filter_line_c_16bit;\n\n\n\n    filter(ctx, yadif->out, tff ^ !is_second, tff);\n\n\n\n    if (is_second) {\n\n        int64_t cur_pts  = yadif->cur->pts;\n\n        int64_t next_pts = yadif->next->pts;\n\n\n\n        if (next_pts != AV_NOPTS_VALUE && cur_pts != AV_NOPTS_VALUE) {\n\n            yadif->out->pts = cur_pts + next_pts;\n\n        } else {\n\n            yadif->out->pts = AV_NOPTS_VALUE;\n\n        }\n\n        ff_start_frame(ctx->outputs[0], yadif->out);\n\n    }\n\n    ff_draw_slice(ctx->outputs[0], 0, link->h, 1);\n\n    ff_end_frame(ctx->outputs[0]);\n\n\n\n    yadif->frame_pending = (yadif->mode&1) && !is_second;\n\n}\n", "idx": 22795}
{"project": "FFmpeg", "commit_id": "a71e9b62546e4467751c0219869a7f6d004a5986", "target": 0, "func": "static void quantize_and_encode_band(struct AACEncContext *s, PutBitContext *pb,\n\n                                     const float *in, int size, int scale_idx,\n\n                                     int cb, const float lambda)\n\n{\n\n    const float IQ = ff_aac_pow2sf_tab[200 + scale_idx - SCALE_ONE_POS + SCALE_DIV_512];\n\n    const float  Q = ff_aac_pow2sf_tab[200 - scale_idx + SCALE_ONE_POS - SCALE_DIV_512];\n\n    const float CLIPPED_ESCAPE = 165140.0f*IQ;\n\n    const int dim = (cb < FIRST_PAIR_BT) ? 4 : 2;\n\n    int i, j, k;\n\n#ifndef USE_REALLY_FULL_SEARCH\n\n    const float  Q34 = sqrtf(Q * sqrtf(Q));\n\n    const int range  = aac_cb_range[cb];\n\n    const int maxval = aac_cb_maxval[cb];\n\n    int offs[4];\n\n    float *scaled = s->scoefs;\n\n#endif /* USE_REALLY_FULL_SEARCH */\n\n\n\n//START_TIMER\n\n    if (!cb)\n\n        return;\n\n\n\n#ifndef USE_REALLY_FULL_SEARCH\n\n    offs[0] = 1;\n\n    for (i = 1; i < dim; i++)\n\n        offs[i] = offs[i-1]*range;\n\n    abs_pow34_v(scaled, in, size);\n\n    quantize_bands(s->qcoefs, in, scaled, size, Q34, !IS_CODEBOOK_UNSIGNED(cb), maxval);\n\n#endif /* USE_REALLY_FULL_SEARCH */\n\n    for (i = 0; i < size; i += dim) {\n\n        float mincost;\n\n        int minidx  = 0;\n\n        int minbits = 0;\n\n        const float *vec;\n\n#ifndef USE_REALLY_FULL_SEARCH\n\n        int (*quants)[2] = &s->qcoefs[i];\n\n        mincost = 0.0f;\n\n        for (j = 0; j < dim; j++)\n\n            mincost += in[i+j]*in[i+j]*lambda;\n\n        minidx = IS_CODEBOOK_UNSIGNED(cb) ? 0 : 40;\n\n        minbits = ff_aac_spectral_bits[cb-1][minidx];\n\n        mincost += minbits;\n\n        for (j = 0; j < (1<<dim); j++) {\n\n            float rd = 0.0f;\n\n            int curbits;\n\n            int curidx = IS_CODEBOOK_UNSIGNED(cb) ? 0 : 40;\n\n            int same   = 0;\n\n            for (k = 0; k < dim; k++) {\n\n                if ((j & (1 << k)) && quants[k][0] == quants[k][1]) {\n\n                    same = 1;\n\n                    break;\n\n                }\n\n            }\n\n            if (same)\n\n                continue;\n\n            for (k = 0; k < dim; k++)\n\n                curidx += quants[k][!!(j & (1 << k))] * offs[dim - 1 - k];\n\n            curbits =  ff_aac_spectral_bits[cb-1][curidx];\n\n            vec     = &ff_aac_codebook_vectors[cb-1][curidx*dim];\n\n#else\n\n        vec = ff_aac_codebook_vectors[cb-1];\n\n        mincost = INFINITY;\n\n        for (j = 0; j < ff_aac_spectral_sizes[cb-1]; j++, vec += dim) {\n\n            float rd = 0.0f;\n\n            int curbits = ff_aac_spectral_bits[cb-1][j];\n\n            int curidx  = j;\n\n#endif /* USE_REALLY_FULL_SEARCH */\n\n            if (IS_CODEBOOK_UNSIGNED(cb)) {\n\n                for (k = 0; k < dim; k++) {\n\n                    float t = fabsf(in[i+k]);\n\n                    float di;\n\n                    //do not code with escape sequence small values\n\n                    if (vec[k] == 64.0f && t < 39.0f*IQ) {\n\n                        rd = INFINITY;\n\n                        break;\n\n                    }\n\n                    if (vec[k] == 64.0f) { //FIXME: slow\n\n                        if (t >= CLIPPED_ESCAPE) {\n\n                            di = t - CLIPPED_ESCAPE;\n\n                            curbits += 21;\n\n                        } else {\n\n                            int c = av_clip(quant(t, Q), 0, 8191);\n\n                            di = t - c*cbrt(c)*IQ;\n\n                            curbits += av_log2(c)*2 - 4 + 1;\n\n                        }\n\n                    } else {\n\n                        di = t - vec[k]*IQ;\n\n                    }\n\n                    if (vec[k] != 0.0f)\n\n                        curbits++;\n\n                    rd += di*di*lambda;\n\n                }\n\n            } else {\n\n                for (k = 0; k < dim; k++) {\n\n                    float di = in[i+k] - vec[k]*IQ;\n\n                    rd += di*di*lambda;\n\n                }\n\n            }\n\n            rd += curbits;\n\n            if (rd < mincost) {\n\n                mincost = rd;\n\n                minidx  = curidx;\n\n                minbits = curbits;\n\n            }\n\n        }\n\n        put_bits(pb, ff_aac_spectral_bits[cb-1][minidx], ff_aac_spectral_codes[cb-1][minidx]);\n\n        if (IS_CODEBOOK_UNSIGNED(cb))\n\n            for (j = 0; j < dim; j++)\n\n                if (ff_aac_codebook_vectors[cb-1][minidx*dim+j] != 0.0f)\n\n                    put_bits(pb, 1, in[i+j] < 0.0f);\n\n        if (cb == ESC_BT) {\n\n            for (j = 0; j < 2; j++) {\n\n                if (ff_aac_codebook_vectors[cb-1][minidx*2+j] == 64.0f) {\n\n                    int coef = av_clip(quant(fabsf(in[i+j]), Q), 0, 8191);\n\n                    int len = av_log2(coef);\n\n\n\n                    put_bits(pb, len - 4 + 1, (1 << (len - 4 + 1)) - 2);\n\n                    put_bits(pb, len, coef & ((1 << len) - 1));\n\n                }\n\n            }\n\n        }\n\n    }\n\n//STOP_TIMER(\"quantize_and_encode\")\n\n}\n", "idx": 22796}
{"project": "FFmpeg", "commit_id": "e29d2d9c92e19b0caf05a2064d132ccdecdfc3d5", "target": 0, "func": "static int seg_check_bitstream(struct AVFormatContext *s, const AVPacket *pkt)\n\n{\n\n    SegmentContext *seg = s->priv_data;\n\n    AVFormatContext *oc = seg->avf;\n\n    if (oc->oformat->check_bitstream) {\n\n        int ret = oc->oformat->check_bitstream(oc, pkt);\n\n        if (ret == 1) {\n\n            AVStream *st = s->streams[pkt->stream_index];\n\n            AVStream *ost = oc->streams[pkt->stream_index];\n\n            st->internal->bsfcs = ost->internal->bsfcs;\n\n            st->internal->nb_bsfcs = ost->internal->nb_bsfcs;\n\n            ost->internal->bsfcs = NULL;\n\n            ost->internal->nb_bsfcs = 0;\n\n        }\n\n        return ret;\n\n    }\n\n    return 1;\n\n}\n", "idx": 22797}
{"project": "FFmpeg", "commit_id": "82613564cfae459796642b22fc0163927d7f49e0", "target": 0, "func": "static int gen_check_bw(URLContext *s, RTMPContext *rt)\n\n{\n\n    RTMPPacket pkt;\n\n    uint8_t *p;\n\n    int ret;\n\n\n\n    if ((ret = ff_rtmp_packet_create(&pkt, RTMP_SYSTEM_CHANNEL, RTMP_PT_INVOKE,\n\n                                     0, 21)) < 0)\n\n        return ret;\n\n\n\n    p = pkt.data;\n\n    ff_amf_write_string(&p, \"_checkbw\");\n\n    ff_amf_write_number(&p, ++rt->nb_invokes);\n\n    ff_amf_write_null(&p);\n\n\n\n    ret = ff_rtmp_packet_write(rt->stream, &pkt, rt->chunk_size,\n\n                               rt->prev_pkt[1]);\n\n    ff_rtmp_packet_destroy(&pkt);\n\n\n\n    return ret;\n\n}\n", "idx": 22798}
{"project": "FFmpeg", "commit_id": "27085d1b47c3741cc0fac284c916127c4066d049", "target": 1, "func": "static int decode_video(InputStream *ist, AVPacket *pkt, int *got_output)\n\n{\n\n    AVFrame *decoded_frame, *f;\n\n    int i, ret = 0, err = 0;\n\n\n\n    if (!ist->decoded_frame && !(ist->decoded_frame = av_frame_alloc()))\n\n        return AVERROR(ENOMEM);\n\n    if (!ist->filter_frame && !(ist->filter_frame = av_frame_alloc()))\n\n        return AVERROR(ENOMEM);\n\n    decoded_frame = ist->decoded_frame;\n\n\n\n    ret = decode(ist->dec_ctx, decoded_frame, got_output, pkt);\n\n    if (!*got_output || ret < 0)\n\n        return ret;\n\n\n\n    ist->frames_decoded++;\n\n\n\n    if (ist->hwaccel_retrieve_data && decoded_frame->format == ist->hwaccel_pix_fmt) {\n\n        err = ist->hwaccel_retrieve_data(ist->dec_ctx, decoded_frame);\n\n        if (err < 0)\n\n            goto fail;\n\n    }\n\n    ist->hwaccel_retrieved_pix_fmt = decoded_frame->format;\n\n\n\n    decoded_frame->pts = guess_correct_pts(&ist->pts_ctx, decoded_frame->pts,\n\n                                           decoded_frame->pkt_dts);\n\n    if (ist->framerate.num)\n\n        decoded_frame->pts = ist->cfr_next_pts++;\n\n\n\n    if (ist->st->sample_aspect_ratio.num)\n\n        decoded_frame->sample_aspect_ratio = ist->st->sample_aspect_ratio;\n\n\n\n    for (i = 0; i < ist->nb_filters; i++) {\n\n        if (i < ist->nb_filters - 1) {\n\n            f = ist->filter_frame;\n\n            err = av_frame_ref(f, decoded_frame);\n\n            if (err < 0)\n\n                break;\n\n        } else\n\n            f = decoded_frame;\n\n\n\n        err = ifilter_send_frame(ist->filters[i], f);\n\n        if (err < 0)\n\n            break;\n\n    }\n\n\n\nfail:\n\n    av_frame_unref(ist->filter_frame);\n\n    av_frame_unref(decoded_frame);\n\n    return err < 0 ? err : ret;\n\n}\n", "idx": 22800}
{"project": "FFmpeg", "commit_id": "f9e083a156f19094cb6fcd134c1ca4ca899a1a6d", "target": 1, "func": "static int avi_read_seek(AVFormatContext *s, int stream_index, int64_t timestamp, int flags)\n\n{\n\n    AVIContext *avi = s->priv_data;\n\n    AVStream *st;\n\n    int i, index;\n\n    int64_t pos, pos_min;\n\n    AVIStream *ast;\n\n\n\n    if (!avi->index_loaded) {\n\n        /* we only load the index on demand */\n\n        avi_load_index(s);\n\n        avi->index_loaded = 1;\n\n    }\n\n    assert(stream_index>= 0);\n\n\n\n    st = s->streams[stream_index];\n\n    ast= st->priv_data;\n\n    index= av_index_search_timestamp(st, timestamp * FFMAX(ast->sample_size, 1), flags);\n\n    if(index<0)\n\n        return -1;\n\n\n\n    /* find the position */\n\n    pos = st->index_entries[index].pos;\n\n    timestamp = st->index_entries[index].timestamp / FFMAX(ast->sample_size, 1);\n\n\n\n//    av_log(s, AV_LOG_DEBUG, \"XX %\"PRId64\" %d %\"PRId64\"\\n\", timestamp, index, st->index_entries[index].timestamp);\n\n\n\n    if (CONFIG_DV_DEMUXER && avi->dv_demux) {\n\n        /* One and only one real stream for DV in AVI, and it has video  */\n\n        /* offsets. Calling with other stream indexes should have failed */\n\n        /* the av_index_search_timestamp call above.                     */\n\n        assert(stream_index == 0);\n\n\n\n        /* Feed the DV video stream version of the timestamp to the */\n\n        /* DV demux so it can synthesize correct timestamps.        */\n\n        dv_offset_reset(avi->dv_demux, timestamp);\n\n\n\n        avio_seek(s->pb, pos, SEEK_SET);\n\n        avi->stream_index= -1;\n\n        return 0;\n\n    }\n\n\n\n    pos_min= pos;\n\n    for(i = 0; i < s->nb_streams; i++) {\n\n        AVStream *st2 = s->streams[i];\n\n        AVIStream *ast2 = st2->priv_data;\n\n\n\n        ast2->packet_size=\n\n        ast2->remaining= 0;\n\n\n\n        if (ast2->sub_ctx) {\n\n            seek_subtitle(st, st2, timestamp);\n\n            continue;\n\n        }\n\n\n\n        if (st2->nb_index_entries <= 0)\n\n            continue;\n\n\n\n//        assert(st2->codec->block_align);\n\n        assert((int64_t)st2->time_base.num*ast2->rate == (int64_t)st2->time_base.den*ast2->scale);\n\n        index = av_index_search_timestamp(\n\n                st2,\n\n                av_rescale_q(timestamp, st->time_base, st2->time_base) * FFMAX(ast2->sample_size, 1),\n\n                flags | AVSEEK_FLAG_BACKWARD | (st2->codec->codec_type != AVMEDIA_TYPE_VIDEO ? AVSEEK_FLAG_ANY : 0));\n\n        if(index<0)\n\n            index=0;\n\n        ast2->seek_pos= st2->index_entries[index].pos;\n\n        pos_min= FFMIN(pos_min,ast2->seek_pos);\n\n    }\n\n    for(i = 0; i < s->nb_streams; i++) {\n\n        AVStream *st2 = s->streams[i];\n\n        AVIStream *ast2 = st2->priv_data;\n\n\n\n        if (ast2->sub_ctx || st2->nb_index_entries <= 0)\n\n            continue;\n\n\n\n        index = av_index_search_timestamp(\n\n                st2,\n\n                av_rescale_q(timestamp, st->time_base, st2->time_base) * FFMAX(ast2->sample_size, 1),\n\n                flags | AVSEEK_FLAG_BACKWARD | (st2->codec->codec_type != AVMEDIA_TYPE_VIDEO ? AVSEEK_FLAG_ANY : 0));\n\n        if(index<0)\n\n            index=0;\n\n        while(!avi->non_interleaved && index>0 && st2->index_entries[index-1].pos >= pos_min)\n\n            index--;\n\n        ast2->frame_offset = st2->index_entries[index].timestamp;\n\n    }\n\n\n\n    /* do the seek */\n\n    avio_seek(s->pb, pos_min, SEEK_SET);\n\n    avi->stream_index= -1;\n\n    avi->dts_max= INT_MIN;\n\n    return 0;\n\n}\n", "idx": 22803}
{"project": "FFmpeg", "commit_id": "c71999ef97b7cc8b1cb6eaf39e72e9ecbf825d9e", "target": 1, "func": "static int dfa_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    uint32_t frame_size;\n\n    int ret, first = 1;\n\n\n\n    if (avio_feof(pb))\n\n        return AVERROR_EOF;\n\n\n\n    if (av_get_packet(pb, pkt, 12) != 12)\n\n        return AVERROR(EIO);\n\n    while (!avio_feof(pb)) {\n\n        if (!first) {\n\n            ret = av_append_packet(pb, pkt, 12);\n\n            if (ret < 0) {\n\n\n                return ret;\n\n            }\n\n        } else\n\n            first = 0;\n\n        frame_size = AV_RL32(pkt->data + pkt->size - 8);\n\n        if (frame_size > INT_MAX - 4) {\n\n            av_log(s, AV_LOG_ERROR, \"Too large chunk size: %\"PRIu32\"\\n\", frame_size);\n\n\n            return AVERROR(EIO);\n\n        }\n\n        if (AV_RL32(pkt->data + pkt->size - 12) == MKTAG('E', 'O', 'F', 'R')) {\n\n            if (frame_size) {\n\n                av_log(s, AV_LOG_WARNING,\n\n                       \"skipping %\"PRIu32\" bytes of end-of-frame marker chunk\\n\",\n\n                       frame_size);\n\n                avio_skip(pb, frame_size);\n\n            }\n\n            return 0;\n\n        }\n\n        ret = av_append_packet(pb, pkt, frame_size);\n\n        if (ret < 0) {\n\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}", "idx": 22806}
{"project": "FFmpeg", "commit_id": "27dbc47c05e07486feba1ab829db584da2159648", "target": 1, "func": "static int nut_read_close(AVFormatContext *s)\n\n{\n\n    NUTContext *nut = s->priv_data;\n\n\n\n\n    av_freep(&nut->time_base);\n\n    av_freep(&nut->stream);\n\n\n\n\n\n\n    return 0;\n\n}", "idx": 22807}
{"project": "FFmpeg", "commit_id": "896873b5648c1c6d379c35832e99d966fa56f87f", "target": 1, "func": "static int64_t pva_read_timestamp(struct AVFormatContext *s, int stream_index,\n\n                                          int64_t *pos, int64_t pos_limit) {\n\n    ByteIOContext *pb = s->pb;\n\n    PVAContext *pvactx = s->priv_data;\n\n    int length, streamid;\n\n    int64_t res;\n\n\n\n    pos_limit = FFMIN(*pos+PVA_MAX_PAYLOAD_LENGTH*8, (uint64_t)*pos+pos_limit);\n\n\n\n    while (*pos < pos_limit) {\n\n        res = AV_NOPTS_VALUE;\n\n        url_fseek(pb, *pos, SEEK_SET);\n\n\n\n        pvactx->continue_pes = 0;\n\n        if (read_part_of_packet(s, &res, &length, &streamid, 0)) {\n\n            (*pos)++;\n\n            continue;\n\n        }\n\n        if (streamid - 1 != stream_index || res == AV_NOPTS_VALUE) {\n\n            *pos = url_ftell(pb) + length;\n\n            continue;\n\n        }\n\n        break;\n\n    }\n\n\n\n    pvactx->continue_pes = 0;\n\n    return res;\n\n}\n", "idx": 22808}
{"project": "FFmpeg", "commit_id": "2cbe6bac0337939f023bd1c37a9c455e6d535f3a", "target": 1, "func": "static int filter_slice(AVFilterContext *ctx, void *arg, int job, int nb_jobs)\n\n{\n\n    FrameRateContext *s = ctx->priv;\n\n    ThreadData *td = arg;\n\n    uint16_t src1_factor = td->src1_factor;\n\n    uint16_t src2_factor = td->src2_factor;\n\n    int plane;\n\n\n\n    for (plane = 0; plane < 4 && td->copy_src1->data[plane] && td->copy_src2->data[plane]; plane++) {\n\n        int cpy_line_width = s->line_size[plane];\n\n        uint8_t *cpy_src1_data = td->copy_src1->data[plane];\n\n        int cpy_src1_line_size = td->copy_src1->linesize[plane];\n\n        uint8_t *cpy_src2_data = td->copy_src2->data[plane];\n\n        int cpy_src2_line_size = td->copy_src2->linesize[plane];\n\n        int cpy_src_h = (plane > 0 && plane < 3) ? (td->copy_src1->height >> s->vsub) : (td->copy_src1->height);\n\n        uint8_t *cpy_dst_data = s->work->data[plane];\n\n        int cpy_dst_line_size = s->work->linesize[plane];\n\n        const int start = (cpy_src_h *  job   ) / nb_jobs;\n\n        const int end   = (cpy_src_h * (job+1)) / nb_jobs;\n\n        cpy_src1_data += start * cpy_src1_line_size;\n\n        cpy_src2_data += start * cpy_src2_line_size;\n\n        cpy_dst_data += start * cpy_dst_line_size;\n\n\n\n        s->blend(cpy_src1_data, cpy_src1_line_size,\n\n                 cpy_src2_data, cpy_src2_line_size,\n\n                 cpy_dst_data,  cpy_dst_line_size,\n\n                 cpy_line_width, end - start,\n\n                 src1_factor, src2_factor, s->max / 2, s->bitdepth);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22810}
{"project": "FFmpeg", "commit_id": "073c2593c9f0aa4445a6fc1b9b24e6e52a8cc2c1", "target": 1, "func": "void ff_msmpeg4_encode_init(MpegEncContext *s)\n\n{\n\n    static int init_done=0;\n\n    int i;\n\n\n\n    common_init(s);\n\n    if(s->msmpeg4_version>=4){\n\n        s->min_qcoeff= -255;\n\n        s->max_qcoeff=  255;\n\n    }\n\n\n\n    if (!init_done) {\n\n        /* init various encoding tables */\n\n        init_done = 1;\n\n        init_mv_table(&mv_tables[0]);\n\n        init_mv_table(&mv_tables[1]);\n\n        for(i=0;i<NB_RL_TABLES;i++)\n\n            init_rl(&rl_table[i]);\n\n\n\n        for(i=0; i<NB_RL_TABLES; i++){\n\n            int level;\n\n            for(level=0; level<=MAX_LEVEL; level++){\n\n                int run;\n\n                for(run=0; run<=MAX_RUN; run++){\n\n                    int last;\n\n                    for(last=0; last<2; last++){\n\n                        rl_length[i][level][run][last]= get_size_of_code(s, &rl_table[  i], last, run, level, 0);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 22811}
{"project": "FFmpeg", "commit_id": "cafb19560401612a07760d230a50d9c1d0564daf", "target": 1, "func": "static void update_initial_timestamps(AVFormatContext *s, int stream_index,\n\n                                      int64_t dts, int64_t pts, AVPacket *pkt)\n\n{\n\n    AVStream *st       = s->streams[stream_index];\n\n    AVPacketList *pktl = s->internal->packet_buffer ? s->internal->packet_buffer : s->internal->parse_queue;\n\n    int64_t pts_buffer[MAX_REORDER_DELAY+1];\n\n    int64_t shift;\n\n    int i, delay;\n\n\n\n    if (st->first_dts != AV_NOPTS_VALUE ||\n\n        dts           == AV_NOPTS_VALUE ||\n\n        st->cur_dts   == AV_NOPTS_VALUE ||\n\n        is_relative(dts))\n\n        return;\n\n\n\n    delay         = st->codec->has_b_frames;\n\n    st->first_dts = dts - (st->cur_dts - RELATIVE_TS_BASE);\n\n    st->cur_dts   = dts;\n\n    shift         = st->first_dts - RELATIVE_TS_BASE;\n\n\n\n    for (i = 0; i<MAX_REORDER_DELAY+1; i++)\n\n        pts_buffer[i] = AV_NOPTS_VALUE;\n\n\n\n    if (is_relative(pts))\n\n        pts += shift;\n\n\n\n    for (; pktl; pktl = get_next_pkt(s, st, pktl)) {\n\n        if (pktl->pkt.stream_index != stream_index)\n\n            continue;\n\n        if (is_relative(pktl->pkt.pts))\n\n            pktl->pkt.pts += shift;\n\n\n\n        if (is_relative(pktl->pkt.dts))\n\n            pktl->pkt.dts += shift;\n\n\n\n        if (st->start_time == AV_NOPTS_VALUE && pktl->pkt.pts != AV_NOPTS_VALUE)\n\n            st->start_time = pktl->pkt.pts;\n\n\n\n        if (pktl->pkt.pts != AV_NOPTS_VALUE && delay <= MAX_REORDER_DELAY && has_decode_delay_been_guessed(st)) {\n\n            pts_buffer[0] = pktl->pkt.pts;\n\n            for (i = 0; i<delay && pts_buffer[i] > pts_buffer[i + 1]; i++)\n\n                FFSWAP(int64_t, pts_buffer[i], pts_buffer[i + 1]);\n\n\n\n            pktl->pkt.dts = select_from_pts_buffer(st, pts_buffer, pktl->pkt.dts);\n\n        }\n\n    }\n\n\n\n    if (st->start_time == AV_NOPTS_VALUE)\n\n        st->start_time = pts;\n\n}\n", "idx": 22812}
{"project": "FFmpeg", "commit_id": "e91f860ea74e11e9178500fe8794c47f57dbf48c", "target": 1, "func": "static int update_prob(VP56RangeCoder *c, int p)\n\n{\n\n    static const int inv_map_table[254] = {\n\n          7,  20,  33,  46,  59,  72,  85,  98, 111, 124, 137, 150, 163, 176,\n\n        189, 202, 215, 228, 241, 254,   1,   2,   3,   4,   5,   6,   8,   9,\n\n         10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  21,  22,  23,  24,\n\n         25,  26,  27,  28,  29,  30,  31,  32,  34,  35,  36,  37,  38,  39,\n\n         40,  41,  42,  43,  44,  45,  47,  48,  49,  50,  51,  52,  53,  54,\n\n         55,  56,  57,  58,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n\n         70,  71,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n\n         86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  99, 100,\n\n        101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115,\n\n        116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130,\n\n        131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145,\n\n        146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,\n\n        161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n\n        177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191,\n\n        192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206,\n\n        207, 208, 209, 210, 211, 212, 213, 214, 216, 217, 218, 219, 220, 221,\n\n        222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236,\n\n        237, 238, 239, 240, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n\n        252, 253,\n\n    };\n\n    int d;\n\n\n\n    /* This code is trying to do a differential probability update. For a\n\n     * current probability A in the range [1, 255], the difference to a new\n\n     * probability of any value can be expressed differentially as 1-A,255-A\n\n     * where some part of this (absolute range) exists both in positive as\n\n     * well as the negative part, whereas another part only exists in one\n\n     * half. We're trying to code this shared part differentially, i.e.\n\n     * times two where the value of the lowest bit specifies the sign, and\n\n     * the single part is then coded on top of this. This absolute difference\n\n     * then again has a value of [0,254], but a bigger value in this range\n\n     * indicates that we're further away from the original value A, so we\n\n     * can code this as a VLC code, since higher values are increasingly\n\n     * unlikely. The first 20 values in inv_map_table[] allow 'cheap, rough'\n\n     * updates vs. the 'fine, exact' updates further down the range, which\n\n     * adds one extra dimension to this differential update model. */\n\n\n\n    if (!vp8_rac_get(c)) {\n\n        d = vp8_rac_get_uint(c, 4) + 0;\n\n    } else if (!vp8_rac_get(c)) {\n\n        d = vp8_rac_get_uint(c, 4) + 16;\n\n    } else if (!vp8_rac_get(c)) {\n\n        d = vp8_rac_get_uint(c, 5) + 32;\n\n    } else {\n\n        d = vp8_rac_get_uint(c, 7);\n\n        if (d >= 65)\n\n            d = (d << 1) - 65 + vp8_rac_get(c);\n\n        d += 64;\n\n    }\n\n\n\n    return p <= 128 ? 1 + inv_recenter_nonneg(inv_map_table[d], p - 1) :\n\n                    255 - inv_recenter_nonneg(inv_map_table[d], 255 - p);\n\n}\n", "idx": 22814}
{"project": "FFmpeg", "commit_id": "da2e774fd6841da7cede8c8ef30337449329727c", "target": 1, "func": "static int kmvc_decode_inter_8x8(KmvcContext * ctx, const uint8_t * src, int src_size, int w, int h)\n\n{\n\n    BitBuf bb;\n\n    int res, val;\n\n    int i, j;\n\n    int bx, by;\n\n    int l0x, l1x, l0y, l1y;\n\n    int mx, my;\n\n    const uint8_t *src_end = src + src_size;\n\n\n\n    kmvc_init_getbits(bb, src);\n\n\n\n    for (by = 0; by < h; by += 8)\n\n        for (bx = 0; bx < w; bx += 8) {\n\n            kmvc_getbit(bb, src, src_end, res);\n\n            if (!res) {\n\n                kmvc_getbit(bb, src, src_end, res);\n\n                if (!res) {     // fill whole 8x8 block\n\n                    if (src >= src_end) {\n\n                        av_log(ctx->avctx, AV_LOG_ERROR, \"Data overrun\\n\");\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                    val = *src++;\n\n                    for (i = 0; i < 64; i++)\n\n                        BLK(ctx->cur, bx + (i & 0x7), by + (i >> 3)) = val;\n\n                } else {        // copy block from previous frame\n\n                    for (i = 0; i < 64; i++)\n\n                        BLK(ctx->cur, bx + (i & 0x7), by + (i >> 3)) =\n\n                            BLK(ctx->prev, bx + (i & 0x7), by + (i >> 3));\n\n                }\n\n            } else {            // handle four 4x4 subblocks\n\n                for (i = 0; i < 4; i++) {\n\n                    l0x = bx + (i & 1) * 4;\n\n                    l0y = by + (i & 2) * 2;\n\n                    kmvc_getbit(bb, src, src_end, res);\n\n                    if (!res) {\n\n                        kmvc_getbit(bb, src, src_end, res);\n\n                        if (!res) {     // fill whole 4x4 block\n\n                            if (src >= src_end) {\n\n                                av_log(ctx->avctx, AV_LOG_ERROR, \"Data overrun\\n\");\n\n                                return AVERROR_INVALIDDATA;\n\n                            }\n\n                            val = *src++;\n\n                            for (j = 0; j < 16; j++)\n\n                                BLK(ctx->cur, l0x + (j & 3), l0y + (j >> 2)) = val;\n\n                        } else {        // copy block\n\n                            if (src >= src_end) {\n\n                                av_log(ctx->avctx, AV_LOG_ERROR, \"Data overrun\\n\");\n\n                                return AVERROR_INVALIDDATA;\n\n                            }\n\n                            val = *src++;\n\n                            mx = (val & 0xF) - 8;\n\n                            my = (val >> 4) - 8;\n\n                            for (j = 0; j < 16; j++)\n\n                                BLK(ctx->cur, l0x + (j & 3), l0y + (j >> 2)) =\n\n                                    BLK(ctx->prev, l0x + (j & 3) + mx, l0y + (j >> 2) + my);\n\n                        }\n\n                    } else {    // descend to 2x2 sub-sub-blocks\n\n                        for (j = 0; j < 4; j++) {\n\n                            l1x = l0x + (j & 1) * 2;\n\n                            l1y = l0y + (j & 2);\n\n                            kmvc_getbit(bb, src, src_end, res);\n\n                            if (!res) {\n\n                                kmvc_getbit(bb, src, src_end, res);\n\n                                if (!res) {     // fill whole 2x2 block\n\n                                    if (src >= src_end) {\n\n                                        av_log(ctx->avctx, AV_LOG_ERROR, \"Data overrun\\n\");\n\n                                        return AVERROR_INVALIDDATA;\n\n                                    }\n\n                                    val = *src++;\n\n                                    BLK(ctx->cur, l1x, l1y) = val;\n\n                                    BLK(ctx->cur, l1x + 1, l1y) = val;\n\n                                    BLK(ctx->cur, l1x, l1y + 1) = val;\n\n                                    BLK(ctx->cur, l1x + 1, l1y + 1) = val;\n\n                                } else {        // copy block\n\n                                    if (src >= src_end) {\n\n                                        av_log(ctx->avctx, AV_LOG_ERROR, \"Data overrun\\n\");\n\n                                        return AVERROR_INVALIDDATA;\n\n                                    }\n\n                                    val = *src++;\n\n                                    mx = (val & 0xF) - 8;\n\n                                    my = (val >> 4) - 8;\n\n                                    BLK(ctx->cur, l1x, l1y) = BLK(ctx->prev, l1x + mx, l1y + my);\n\n                                    BLK(ctx->cur, l1x + 1, l1y) =\n\n                                        BLK(ctx->prev, l1x + 1 + mx, l1y + my);\n\n                                    BLK(ctx->cur, l1x, l1y + 1) =\n\n                                        BLK(ctx->prev, l1x + mx, l1y + 1 + my);\n\n                                    BLK(ctx->cur, l1x + 1, l1y + 1) =\n\n                                        BLK(ctx->prev, l1x + 1 + mx, l1y + 1 + my);\n\n                                }\n\n                            } else {    // read values for block\n\n                                BLK(ctx->cur, l1x, l1y) = *src++;\n\n                                BLK(ctx->cur, l1x + 1, l1y) = *src++;\n\n                                BLK(ctx->cur, l1x, l1y + 1) = *src++;\n\n                                BLK(ctx->cur, l1x + 1, l1y + 1) = *src++;\n\n                            }\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n\n\n    return 0;\n\n}\n", "idx": 22818}
{"project": "FFmpeg", "commit_id": "383a04a127734d25c1ef7839c489bba297855801", "target": 1, "func": "int ff_write_chained(AVFormatContext *dst, int dst_stream, AVPacket *pkt,\n\n                     AVFormatContext *src)\n\n{\n\n    AVPacket local_pkt;\n\n\n\n    local_pkt = *pkt;\n\n    local_pkt.stream_index = dst_stream;\n\n    if (pkt->pts != AV_NOPTS_VALUE)\n\n        local_pkt.pts = av_rescale_q(pkt->pts,\n\n                                     src->streams[pkt->stream_index]->time_base,\n\n                                     dst->streams[dst_stream]->time_base);\n\n    if (pkt->dts != AV_NOPTS_VALUE)\n\n        local_pkt.dts = av_rescale_q(pkt->dts,\n\n                                     src->streams[pkt->stream_index]->time_base,\n\n                                     dst->streams[dst_stream]->time_base);\n\n    if (pkt->duration)\n\n        local_pkt.duration = av_rescale_q(pkt->duration,\n\n                                          src->streams[pkt->stream_index]->time_base,\n\n                                          dst->streams[dst_stream]->time_base);\n\n    return av_write_frame(dst, &local_pkt);\n\n}\n", "idx": 22819}
{"project": "FFmpeg", "commit_id": "31fce399425b986557ab94a2dd8305b289710f0e", "target": 0, "func": "static int tm2_read_stream(TM2Context *ctx, const uint8_t *buf, int stream_id, int buf_size)\n\n{\n\n    int i;\n\n    int skip = 0;\n\n    int len, toks, pos;\n\n    TM2Codes codes;\n\n    GetByteContext gb;\n\n\n\n    if (buf_size < 4) {\n\n        av_log(ctx->avctx, AV_LOG_ERROR, \"not enough space for len left\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* get stream length in dwords */\n\n    bytestream2_init(&gb, buf, buf_size);\n\n    len  = bytestream2_get_be32(&gb);\n\n    skip = len * 4 + 4;\n\n\n\n    if(len == 0)\n\n        return 4;\n\n\n\n    if (len >= INT_MAX/4-1 || len < 0 || skip > buf_size) {\n\n        av_log(ctx->avctx, AV_LOG_ERROR, \"invalid stream size\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    toks = bytestream2_get_be32(&gb);\n\n    if(toks & 1) {\n\n        len = bytestream2_get_be32(&gb);\n\n        if(len == TM2_ESCAPE) {\n\n            len = bytestream2_get_be32(&gb);\n\n        }\n\n        if(len > 0) {\n\n            pos = bytestream2_tell(&gb);\n\n            if (skip <= pos)\n\n                return AVERROR_INVALIDDATA;\n\n            init_get_bits(&ctx->gb, buf + pos, (skip - pos) * 8);\n\n            if(tm2_read_deltas(ctx, stream_id) == -1)\n\n                return AVERROR_INVALIDDATA;\n\n            bytestream2_skip(&gb, ((get_bits_count(&ctx->gb) + 31) >> 5) << 2);\n\n        }\n\n    }\n\n    /* skip unused fields */\n\n    len = bytestream2_get_be32(&gb);\n\n    if(len == TM2_ESCAPE) { /* some unknown length - could be escaped too */\n\n        bytestream2_skip(&gb, 8); /* unused by decoder */\n\n    } else {\n\n        bytestream2_skip(&gb, 4); /* unused by decoder */\n\n    }\n\n\n\n    pos = bytestream2_tell(&gb);\n\n    if (skip <= pos)\n\n        return AVERROR_INVALIDDATA;\n\n    init_get_bits(&ctx->gb, buf + pos, (skip - pos) * 8);\n\n    if(tm2_build_huff_table(ctx, &codes) == -1)\n\n        return AVERROR_INVALIDDATA;\n\n    bytestream2_skip(&gb, ((get_bits_count(&ctx->gb) + 31) >> 5) << 2);\n\n\n\n    toks >>= 1;\n\n    /* check if we have sane number of tokens */\n\n    if((toks < 0) || (toks > 0xFFFFFF)){\n\n        av_log(ctx->avctx, AV_LOG_ERROR, \"Incorrect number of tokens: %i\\n\", toks);\n\n        tm2_free_codes(&codes);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    ctx->tokens[stream_id] = av_realloc(ctx->tokens[stream_id], toks * sizeof(int));\n\n    ctx->tok_lens[stream_id] = toks;\n\n    len = bytestream2_get_be32(&gb);\n\n    if(len > 0) {\n\n        pos = bytestream2_tell(&gb);\n\n        if (skip <= pos)\n\n            return AVERROR_INVALIDDATA;\n\n        init_get_bits(&ctx->gb, buf + pos, (skip - pos) * 8);\n\n        for(i = 0; i < toks; i++) {\n\n            if (get_bits_left(&ctx->gb) <= 0) {\n\n                av_log(ctx->avctx, AV_LOG_ERROR, \"Incorrect number of tokens: %i\\n\", toks);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            ctx->tokens[stream_id][i] = tm2_get_token(&ctx->gb, &codes);\n\n            if (stream_id <= TM2_MOT && ctx->tokens[stream_id][i] >= TM2_DELTAS) {\n\n                av_log(ctx->avctx, AV_LOG_ERROR, \"Invalid delta token index %d for type %d, n=%d\\n\",\n\n                       ctx->tokens[stream_id][i], stream_id, i);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    } else {\n\n        for(i = 0; i < toks; i++) {\n\n            ctx->tokens[stream_id][i] = codes.recode[0];\n\n            if (stream_id <= TM2_MOT && ctx->tokens[stream_id][i] >= TM2_DELTAS) {\n\n                av_log(ctx->avctx, AV_LOG_ERROR, \"Invalid delta token index %d for type %d, n=%d\\n\",\n\n                       ctx->tokens[stream_id][i], stream_id, i);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    }\n\n    tm2_free_codes(&codes);\n\n\n\n    return skip;\n\n}\n", "idx": 22820}
{"project": "FFmpeg", "commit_id": "205c31b301864e675d051b07b19b6c457cf2ab24", "target": 0, "func": "static int parse_section_header(GetByteContext *gbc, int *section_size,\n\n                                enum HapSectionType *section_type)\n\n{\n\n    if (bytestream2_get_bytes_left(gbc) < 4)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    *section_size = bytestream2_get_le24(gbc);\n\n    *section_type = bytestream2_get_byte(gbc);\n\n\n\n    if (*section_size == 0) {\n\n        if (bytestream2_get_bytes_left(gbc) < 4)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        *section_size = bytestream2_get_le32(gbc);\n\n    }\n\n\n\n    if (*section_size > bytestream2_get_bytes_left(gbc))\n\n        return AVERROR_INVALIDDATA;\n\n    else\n\n        return 0;\n\n}\n", "idx": 22821}
{"project": "FFmpeg", "commit_id": "4a6a29a7fbf023b19797c38a86099d9f81d25524", "target": 0, "func": "static int amr_nb_decode_frame(AVCodecContext *avctx, void *data,\n\n                               int *data_size, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    AMRContext *s      = avctx->priv_data;\n\n    static const uint8_t block_size[16] = { 12, 13, 15, 17, 19, 20, 26, 31, 5, 0, 0, 0, 0, 0, 0, 0 };\n\n    enum Mode dec_mode;\n\n    int packet_size;\n\n\n\n    av_dlog(avctx, \"amr_decode_frame buf=%p buf_size=%d frame_count=%d!!\\n\",\n\n            buf, buf_size, avctx->frame_number);\n\n\n\n    dec_mode    = (buf[0] >> 3) & 0x000F;\n\n    packet_size = block_size[dec_mode] + 1;\n\n\n\n    if (packet_size > buf_size) {\n\n        av_log(avctx, AV_LOG_ERROR, \"amr frame too short (%u, should be %u)\\n\",\n\n               buf_size, packet_size);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    av_dlog(avctx, \"packet_size=%d buf= 0x%X %X %X %X\\n\",\n\n              packet_size, buf[0], buf[1], buf[2], buf[3]);\n\n    /* call decoder */\n\n    Decoder_Interface_Decode(s->dec_state, buf, data, 0);\n\n    *data_size = 160 * 2;\n\n\n\n    return packet_size;\n\n}\n", "idx": 22822}
{"project": "FFmpeg", "commit_id": "e952d4b7ace607132130599905c75f25aaea9e56", "target": 0, "func": "static int pps_range_extensions(GetBitContext *gb, AVCodecContext *avctx,\n\n                                HEVCPPS *pps, HEVCSPS *sps) {\n\n    int i;\n\n\n\n    if (pps->transform_skip_enabled_flag) {\n\n        pps->log2_max_transform_skip_block_size = get_ue_golomb_long(gb) + 2;\n\n    }\n\n    pps->cross_component_prediction_enabled_flag = get_bits1(gb);\n\n    pps->chroma_qp_offset_list_enabled_flag = get_bits1(gb);\n\n    if (pps->chroma_qp_offset_list_enabled_flag) {\n\n        pps->diff_cu_chroma_qp_offset_depth = get_ue_golomb_long(gb);\n\n        pps->chroma_qp_offset_list_len_minus1 = get_ue_golomb_long(gb);\n\n        if (pps->chroma_qp_offset_list_len_minus1 && pps->chroma_qp_offset_list_len_minus1 >= 5) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"chroma_qp_offset_list_len_minus1 shall be in the range [0, 5].\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        for (i = 0; i <= pps->chroma_qp_offset_list_len_minus1; i++) {\n\n            pps->cb_qp_offset_list[i] = get_se_golomb_long(gb);\n\n            if (pps->cb_qp_offset_list[i]) {\n\n                av_log(avctx, AV_LOG_WARNING,\n\n                       \"cb_qp_offset_list not tested yet.\\n\");\n\n            }\n\n            pps->cr_qp_offset_list[i] = get_se_golomb_long(gb);\n\n            if (pps->cr_qp_offset_list[i]) {\n\n                av_log(avctx, AV_LOG_WARNING,\n\n                       \"cb_qp_offset_list not tested yet.\\n\");\n\n            }\n\n        }\n\n    }\n\n    pps->log2_sao_offset_scale_luma = get_ue_golomb_long(gb);\n\n    pps->log2_sao_offset_scale_chroma = get_ue_golomb_long(gb);\n\n\n\n    return(0);\n\n}\n", "idx": 22823}
{"project": "FFmpeg", "commit_id": "596b5c488fa1d40f114a64d3b73e1863cab073fb", "target": 0, "func": "av_cold int ff_wma_init(AVCodecContext *avctx, int flags2)\n\n{\n\n    WMACodecContext *s = avctx->priv_data;\n\n    int i;\n\n    float bps1, high_freq;\n\n    volatile float bps;\n\n    int sample_rate1;\n\n    int coef_vlc_table;\n\n\n\n    if (avctx->sample_rate <= 0 || avctx->sample_rate > 50000 ||\n\n        avctx->channels    <= 0 || avctx->channels    > 2     ||\n\n        avctx->bit_rate    <= 0)\n\n        return -1;\n\n\n\n    ff_fmt_convert_init(&s->fmt_conv, avctx);\n\n    avpriv_float_dsp_init(&s->fdsp, avctx->flags & CODEC_FLAG_BITEXACT);\n\n\n\n    if (avctx->codec->id == AV_CODEC_ID_WMAV1)\n\n        s->version = 1;\n\n    else\n\n        s->version = 2;\n\n\n\n    /* compute MDCT block size */\n\n    s->frame_len_bits = ff_wma_get_frame_len_bits(avctx->sample_rate,\n\n                                                  s->version, 0);\n\n    s->next_block_len_bits = s->frame_len_bits;\n\n    s->prev_block_len_bits = s->frame_len_bits;\n\n    s->block_len_bits      = s->frame_len_bits;\n\n\n\n    s->frame_len = 1 << s->frame_len_bits;\n\n    if (s->use_variable_block_len) {\n\n        int nb_max, nb;\n\n        nb = ((flags2 >> 3) & 3) + 1;\n\n        if ((avctx->bit_rate / avctx->channels) >= 32000)\n\n            nb += 2;\n\n        nb_max = s->frame_len_bits - BLOCK_MIN_BITS;\n\n        if (nb > nb_max)\n\n            nb = nb_max;\n\n        s->nb_block_sizes = nb + 1;\n\n    } else\n\n        s->nb_block_sizes = 1;\n\n\n\n    /* init rate dependent parameters */\n\n    s->use_noise_coding = 1;\n\n    high_freq           = avctx->sample_rate * 0.5;\n\n\n\n    /* if version 2, then the rates are normalized */\n\n    sample_rate1 = avctx->sample_rate;\n\n    if (s->version == 2) {\n\n        if (sample_rate1 >= 44100)\n\n            sample_rate1 = 44100;\n\n        else if (sample_rate1 >= 22050)\n\n            sample_rate1 = 22050;\n\n        else if (sample_rate1 >= 16000)\n\n            sample_rate1 = 16000;\n\n        else if (sample_rate1 >= 11025)\n\n            sample_rate1 = 11025;\n\n        else if (sample_rate1 >= 8000)\n\n            sample_rate1 = 8000;\n\n    }\n\n\n\n    bps                 = (float) avctx->bit_rate /\n\n                          (float) (avctx->channels * avctx->sample_rate);\n\n    s->byte_offset_bits = av_log2((int) (bps * s->frame_len / 8.0 + 0.5)) + 2;\n\n\n\n    /* compute high frequency value and choose if noise coding should\n\n     * be activated */\n\n    bps1 = bps;\n\n    if (avctx->channels == 2)\n\n        bps1 = bps * 1.6;\n\n    if (sample_rate1 == 44100) {\n\n        if (bps1 >= 0.61)\n\n            s->use_noise_coding = 0;\n\n        else\n\n            high_freq = high_freq * 0.4;\n\n    } else if (sample_rate1 == 22050) {\n\n        if (bps1 >= 1.16)\n\n            s->use_noise_coding = 0;\n\n        else if (bps1 >= 0.72)\n\n            high_freq = high_freq * 0.7;\n\n        else\n\n            high_freq = high_freq * 0.6;\n\n    } else if (sample_rate1 == 16000) {\n\n        if (bps > 0.5)\n\n            high_freq = high_freq * 0.5;\n\n        else\n\n            high_freq = high_freq * 0.3;\n\n    } else if (sample_rate1 == 11025)\n\n        high_freq = high_freq * 0.7;\n\n    else if (sample_rate1 == 8000) {\n\n        if (bps <= 0.625)\n\n            high_freq = high_freq * 0.5;\n\n        else if (bps > 0.75)\n\n            s->use_noise_coding = 0;\n\n        else\n\n            high_freq = high_freq * 0.65;\n\n    } else {\n\n        if (bps >= 0.8)\n\n            high_freq = high_freq * 0.75;\n\n        else if (bps >= 0.6)\n\n            high_freq = high_freq * 0.6;\n\n        else\n\n            high_freq = high_freq * 0.5;\n\n    }\n\n    av_dlog(s->avctx, \"flags2=0x%x\\n\", flags2);\n\n    av_dlog(s->avctx, \"version=%d channels=%d sample_rate=%d bitrate=%d block_align=%d\\n\",\n\n            s->version, avctx->channels, avctx->sample_rate, avctx->bit_rate,\n\n            avctx->block_align);\n\n    av_dlog(s->avctx, \"bps=%f bps1=%f high_freq=%f bitoffset=%d\\n\",\n\n            bps, bps1, high_freq, s->byte_offset_bits);\n\n    av_dlog(s->avctx, \"use_noise_coding=%d use_exp_vlc=%d nb_block_sizes=%d\\n\",\n\n            s->use_noise_coding, s->use_exp_vlc, s->nb_block_sizes);\n\n\n\n    /* compute the scale factor band sizes for each MDCT block size */\n\n    {\n\n        int a, b, pos, lpos, k, block_len, i, j, n;\n\n        const uint8_t *table;\n\n\n\n        if (s->version == 1)\n\n            s->coefs_start = 3;\n\n        else\n\n            s->coefs_start = 0;\n\n        for (k = 0; k < s->nb_block_sizes; k++) {\n\n            block_len = s->frame_len >> k;\n\n\n\n            if (s->version == 1) {\n\n                lpos = 0;\n\n                for (i = 0; i < 25; i++) {\n\n                    a   = ff_wma_critical_freqs[i];\n\n                    b   = avctx->sample_rate;\n\n                    pos = ((block_len * 2 * a) + (b >> 1)) / b;\n\n                    if (pos > block_len)\n\n                        pos = block_len;\n\n                    s->exponent_bands[0][i] = pos - lpos;\n\n                    if (pos >= block_len) {\n\n                        i++;\n\n                        break;\n\n                    }\n\n                    lpos = pos;\n\n                }\n\n                s->exponent_sizes[0] = i;\n\n            } else {\n\n                /* hardcoded tables */\n\n                table = NULL;\n\n                a     = s->frame_len_bits - BLOCK_MIN_BITS - k;\n\n                if (a < 3) {\n\n                    if (avctx->sample_rate >= 44100)\n\n                        table = exponent_band_44100[a];\n\n                    else if (avctx->sample_rate >= 32000)\n\n                        table = exponent_band_32000[a];\n\n                    else if (avctx->sample_rate >= 22050)\n\n                        table = exponent_band_22050[a];\n\n                }\n\n                if (table) {\n\n                    n = *table++;\n\n                    for (i = 0; i < n; i++)\n\n                        s->exponent_bands[k][i] = table[i];\n\n                    s->exponent_sizes[k] = n;\n\n                } else {\n\n                    j    = 0;\n\n                    lpos = 0;\n\n                    for (i = 0; i < 25; i++) {\n\n                        a     = ff_wma_critical_freqs[i];\n\n                        b     = avctx->sample_rate;\n\n                        pos   = ((block_len * 2 * a) + (b << 1)) / (4 * b);\n\n                        pos <<= 2;\n\n                        if (pos > block_len)\n\n                            pos = block_len;\n\n                        if (pos > lpos)\n\n                            s->exponent_bands[k][j++] = pos - lpos;\n\n                        if (pos >= block_len)\n\n                            break;\n\n                        lpos = pos;\n\n                    }\n\n                    s->exponent_sizes[k] = j;\n\n                }\n\n            }\n\n\n\n            /* max number of coefs */\n\n            s->coefs_end[k] = (s->frame_len - ((s->frame_len * 9) / 100)) >> k;\n\n            /* high freq computation */\n\n            s->high_band_start[k] = (int) ((block_len * 2 * high_freq) /\n\n                                           avctx->sample_rate + 0.5);\n\n            n   = s->exponent_sizes[k];\n\n            j   = 0;\n\n            pos = 0;\n\n            for (i = 0; i < n; i++) {\n\n                int start, end;\n\n                start = pos;\n\n                pos  += s->exponent_bands[k][i];\n\n                end   = pos;\n\n                if (start < s->high_band_start[k])\n\n                    start = s->high_band_start[k];\n\n                if (end > s->coefs_end[k])\n\n                    end = s->coefs_end[k];\n\n                if (end > start)\n\n                    s->exponent_high_bands[k][j++] = end - start;\n\n            }\n\n            s->exponent_high_sizes[k] = j;\n\n#if 0\n\n            tprintf(s->avctx, \"%5d: coefs_end=%d high_band_start=%d nb_high_bands=%d: \",\n\n                    s->frame_len >> k,\n\n                    s->coefs_end[k],\n\n                    s->high_band_start[k],\n\n                    s->exponent_high_sizes[k]);\n\n            for (j = 0; j < s->exponent_high_sizes[k]; j++)\n\n                tprintf(s->avctx, \" %d\", s->exponent_high_bands[k][j]);\n\n            tprintf(s->avctx, \"\\n\");\n\n#endif /* 0 */\n\n        }\n\n    }\n\n\n\n#ifdef TRACE\n\n    {\n\n        int i, j;\n\n        for (i = 0; i < s->nb_block_sizes; i++) {\n\n            tprintf(s->avctx, \"%5d: n=%2d:\",\n\n                    s->frame_len >> i,\n\n                    s->exponent_sizes[i]);\n\n            for (j = 0; j < s->exponent_sizes[i]; j++)\n\n                tprintf(s->avctx, \" %d\", s->exponent_bands[i][j]);\n\n            tprintf(s->avctx, \"\\n\");\n\n        }\n\n    }\n\n#endif /* TRACE */\n\n\n\n    /* init MDCT windows : simple sine window */\n\n    for (i = 0; i < s->nb_block_sizes; i++) {\n\n        ff_init_ff_sine_windows(s->frame_len_bits - i);\n\n        s->windows[i] = ff_sine_windows[s->frame_len_bits - i];\n\n    }\n\n\n\n    s->reset_block_lengths = 1;\n\n\n\n    if (s->use_noise_coding) {\n\n        /* init the noise generator */\n\n        if (s->use_exp_vlc)\n\n            s->noise_mult = 0.02;\n\n        else\n\n            s->noise_mult = 0.04;\n\n\n\n#ifdef TRACE\n\n        for (i = 0; i < NOISE_TAB_SIZE; i++)\n\n            s->noise_table[i] = 1.0 * s->noise_mult;\n\n#else\n\n        {\n\n            unsigned int seed;\n\n            float norm;\n\n            seed = 1;\n\n            norm = (1.0 / (float) (1LL << 31)) * sqrt(3) * s->noise_mult;\n\n            for (i = 0; i < NOISE_TAB_SIZE; i++) {\n\n                seed              = seed * 314159 + 1;\n\n                s->noise_table[i] = (float) ((int) seed) * norm;\n\n            }\n\n        }\n\n#endif /* TRACE */\n\n    }\n\n\n\n    /* choose the VLC tables for the coefficients */\n\n    coef_vlc_table = 2;\n\n    if (avctx->sample_rate >= 32000) {\n\n        if (bps1 < 0.72)\n\n            coef_vlc_table = 0;\n\n        else if (bps1 < 1.16)\n\n            coef_vlc_table = 1;\n\n    }\n\n    s->coef_vlcs[0] = &coef_vlcs[coef_vlc_table * 2];\n\n    s->coef_vlcs[1] = &coef_vlcs[coef_vlc_table * 2 + 1];\n\n    init_coef_vlc(&s->coef_vlc[0], &s->run_table[0], &s->level_table[0],\n\n                  &s->int_table[0], s->coef_vlcs[0]);\n\n    init_coef_vlc(&s->coef_vlc[1], &s->run_table[1], &s->level_table[1],\n\n                  &s->int_table[1], s->coef_vlcs[1]);\n\n\n\n    return 0;\n\n}\n", "idx": 22824}
{"project": "FFmpeg", "commit_id": "bcd7bf7eeb09a395cc01698842d1b8be9af483fc", "target": 0, "func": "static void avc_h_loop_filter_chroma422_mbaff_msa(uint8_t *src,\n\n                                                  int32_t stride,\n\n                                                  int32_t alpha_in,\n\n                                                  int32_t beta_in,\n\n                                                  int8_t *tc0)\n\n{\n\n    int32_t col, tc_val;\n\n    int16_t out0, out1;\n\n    v16u8 alpha, beta, res;\n\n\n\n    alpha = (v16u8) __msa_fill_b(alpha_in);\n\n    beta = (v16u8) __msa_fill_b(beta_in);\n\n\n\n    for (col = 0; col < 4; col++) {\n\n        tc_val = (tc0[col] - 1) + 1;\n\n\n\n        if (tc_val <= 0) {\n\n            src += 4 * stride;\n\n            continue;\n\n        }\n\n\n\n        AVC_LPF_H_2BYTE_CHROMA_422(src, stride, tc_val, alpha, beta, res);\n\n\n\n        out0 = __msa_copy_s_h((v8i16) res, 0);\n\n        out1 = __msa_copy_s_h((v8i16) res, 1);\n\n\n\n        STORE_HWORD((src - 1), out0);\n\n        src += stride;\n\n        STORE_HWORD((src - 1), out1);\n\n        src += stride;\n\n    }\n\n}\n", "idx": 22825}
{"project": "FFmpeg", "commit_id": "79997def65fd2313b48a5f3c3a884c6149ae9b5d", "target": 0, "func": "static void mdct_test(AC3MDCTContext *mdct, AVLFG *lfg)\n\n{\n\n    int16_t input[MDCT_SAMPLES];\n\n    int32_t output[AC3_MAX_COEFS];\n\n    float input1[MDCT_SAMPLES];\n\n    float output1[AC3_MAX_COEFS];\n\n    float s, a, err, e, emax;\n\n    int i, k, n;\n\n\n\n    for (i = 0; i < MDCT_SAMPLES; i++) {\n\n        input[i]  = (av_lfg_get(lfg) % 65535 - 32767) * 9 / 10;\n\n        input1[i] = input[i];\n\n    }\n\n\n\n    mdct512(mdct, output, input);\n\n\n\n    /* do it by hand */\n\n    for (k = 0; k < AC3_MAX_COEFS; k++) {\n\n        s = 0;\n\n        for (n = 0; n < MDCT_SAMPLES; n++) {\n\n            a = (2*M_PI*(2*n+1+MDCT_SAMPLES/2)*(2*k+1) / (4 * MDCT_SAMPLES));\n\n            s += input1[n] * cos(a);\n\n        }\n\n        output1[k] = -2 * s / MDCT_SAMPLES;\n\n    }\n\n\n\n    err  = 0;\n\n    emax = 0;\n\n    for (i = 0; i < AC3_MAX_COEFS; i++) {\n\n        av_log(NULL, AV_LOG_DEBUG, \"%3d: %7d %7.0f\\n\", i, output[i], output1[i]);\n\n        e = output[i] - output1[i];\n\n        if (e > emax)\n\n            emax = e;\n\n        err += e * e;\n\n    }\n\n    av_log(NULL, AV_LOG_DEBUG, \"err2=%f emax=%f\\n\", err / AC3_MAX_COEFS, emax);\n\n}\n", "idx": 22826}
{"project": "FFmpeg", "commit_id": "2aab7c2dfaca4386c38e5d565cd2bf73096bcc86", "target": 0, "func": "void ff_put_h264_qpel4_mc13_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_hv_qrt_4w_msa(src + stride - 2,\n\n                           src - (stride * 2), stride, dst, stride, 4);\n\n}\n", "idx": 22827}
{"project": "FFmpeg", "commit_id": "a0a872d0733f60876b0c93f236bc4606f36fbf89", "target": 0, "func": "static void copy_cell(Indeo3DecodeContext *ctx, Plane *plane, Cell *cell)\n\n{\n\n    int     h, w, mv_x, mv_y, offset, offset_dst;\n\n    uint8_t *src, *dst;\n\n\n\n    /* setup output and reference pointers */\n\n    offset_dst  = (cell->ypos << 2) * plane->pitch + (cell->xpos << 2);\n\n    dst         = plane->pixels[ctx->buf_sel] + offset_dst;\n\n    mv_y        = cell->mv_ptr[0];\n\n    mv_x        = cell->mv_ptr[1];\n\n    offset      = offset_dst + mv_y * plane->pitch + mv_x;\n\n    src         = plane->pixels[ctx->buf_sel ^ 1] + offset;\n\n\n\n    h = cell->height << 2;\n\n\n\n    for (w = cell->width; w > 0;) {\n\n        /* copy using 16xH blocks */\n\n        if (!((cell->xpos << 2) & 15) && w >= 4) {\n\n            for (; w >= 4; src += 16, dst += 16, w -= 4)\n\n                ctx->dsp.put_no_rnd_pixels_tab[0][0](dst, src, plane->pitch, h);\n\n        }\n\n\n\n        /* copy using 8xH blocks */\n\n        if (!((cell->xpos << 2) & 7) && w >= 2) {\n\n            ctx->dsp.put_no_rnd_pixels_tab[1][0](dst, src, plane->pitch, h);\n\n            w -= 2;\n\n            src += 8;\n\n            dst += 8;\n\n        }\n\n\n\n        if (w >= 1) {\n\n            ctx->dsp.put_no_rnd_pixels_tab[2][0](dst, src, plane->pitch, h);\n\n            w--;\n\n            src += 4;\n\n            dst += 4;\n\n        }\n\n    }\n\n}\n", "idx": 22828}
{"project": "FFmpeg", "commit_id": "390b4d7088b5cecace245fee0c54a57e24dabdf4", "target": 0, "func": "static int flv_same_audio_codec(AVCodecContext *acodec, int flags)\n\n{\n\n    int bits_per_coded_sample = (flags & FLV_AUDIO_SAMPLESIZE_MASK) ? 16 : 8;\n\n    int flv_codecid = flags & FLV_AUDIO_CODECID_MASK;\n\n    int codec_id;\n\n\n\n    if (!acodec->codec_id && !acodec->codec_tag)\n\n        return 1;\n\n\n\n    if (acodec->bits_per_coded_sample != bits_per_coded_sample)\n\n        return 0;\n\n\n\n    switch(flv_codecid) {\n\n        //no distinction between S16 and S8 PCM codec flags\n\n    case FLV_CODECID_PCM:\n\n        codec_id = bits_per_coded_sample == 8 ? AV_CODEC_ID_PCM_U8 :\n\n#if HAVE_BIGENDIAN\n\n                            AV_CODEC_ID_PCM_S16BE;\n\n#else\n\n                            AV_CODEC_ID_PCM_S16LE;\n\n#endif\n\n        return codec_id == acodec->codec_id;\n\n    case FLV_CODECID_PCM_LE:\n\n        codec_id = bits_per_coded_sample == 8 ? AV_CODEC_ID_PCM_U8 : AV_CODEC_ID_PCM_S16LE;\n\n        return codec_id == acodec->codec_id;\n\n    case FLV_CODECID_AAC:\n\n        return acodec->codec_id == AV_CODEC_ID_AAC;\n\n    case FLV_CODECID_ADPCM:\n\n        return acodec->codec_id == AV_CODEC_ID_ADPCM_SWF;\n\n    case FLV_CODECID_SPEEX:\n\n        return acodec->codec_id == AV_CODEC_ID_SPEEX;\n\n    case FLV_CODECID_MP3:\n\n        return acodec->codec_id == AV_CODEC_ID_MP3;\n\n    case FLV_CODECID_NELLYMOSER_8KHZ_MONO:\n\n    case FLV_CODECID_NELLYMOSER_16KHZ_MONO:\n\n    case FLV_CODECID_NELLYMOSER:\n\n        return acodec->codec_id == AV_CODEC_ID_NELLYMOSER;\n\n    case FLV_CODECID_PCM_MULAW:\n\n        return acodec->sample_rate == 8000 &&\n\n               acodec->codec_id == AV_CODEC_ID_PCM_MULAW;\n\n    case FLV_CODECID_PCM_ALAW:\n\n        return acodec->sample_rate = 8000 &&\n\n               acodec->codec_id == AV_CODEC_ID_PCM_ALAW;\n\n    default:\n\n        return acodec->codec_tag == (flv_codecid >> FLV_AUDIO_CODECID_OFFSET);\n\n    }\n\n}\n", "idx": 22829}
{"project": "FFmpeg", "commit_id": "deefdf9788467edd262b9c29a4f6e33d2ae84b8c", "target": 1, "func": "int avpriv_mpeg4audio_get_config(MPEG4AudioConfig *c, const uint8_t *buf,\n\n                                 int bit_size, int sync_extension)\n\n{\n\n    GetBitContext gb;\n\n    int specific_config_bitindex;\n\n\n\n    if(bit_size<=0)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    init_get_bits(&gb, buf, bit_size);\n\n    c->object_type = get_object_type(&gb);\n\n    c->sample_rate = get_sample_rate(&gb, &c->sampling_index);\n\n    c->chan_config = get_bits(&gb, 4);\n\n    if (c->chan_config < FF_ARRAY_ELEMS(ff_mpeg4audio_channels))\n\n        c->channels = ff_mpeg4audio_channels[c->chan_config];\n\n    c->sbr = -1;\n\n    c->ps  = -1;\n\n    if (c->object_type == AOT_SBR || (c->object_type == AOT_PS &&\n\n        // check for W6132 Annex YYYY draft MP3onMP4\n\n        !(show_bits(&gb, 3) & 0x03 && !(show_bits(&gb, 9) & 0x3F)))) {\n\n        if (c->object_type == AOT_PS)\n\n            c->ps = 1;\n\n        c->ext_object_type = AOT_SBR;\n\n        c->sbr = 1;\n\n        c->ext_sample_rate = get_sample_rate(&gb, &c->ext_sampling_index);\n\n        c->object_type = get_object_type(&gb);\n\n        if (c->object_type == AOT_ER_BSAC)\n\n            c->ext_chan_config = get_bits(&gb, 4);\n\n    } else {\n\n        c->ext_object_type = AOT_NULL;\n\n        c->ext_sample_rate = 0;\n\n    }\n\n    specific_config_bitindex = get_bits_count(&gb);\n\n\n\n    if (c->object_type == AOT_ALS) {\n\n        skip_bits(&gb, 5);\n\n        if (show_bits_long(&gb, 24) != MKBETAG('\\0','A','L','S'))\n\n            skip_bits_long(&gb, 24);\n\n\n\n        specific_config_bitindex = get_bits_count(&gb);\n\n\n\n        if (parse_config_ALS(&gb, c))\n\n            return -1;\n\n    }\n\n\n\n    if (c->ext_object_type != AOT_SBR && sync_extension) {\n\n        while (get_bits_left(&gb) > 15) {\n\n            if (show_bits(&gb, 11) == 0x2b7) { // sync extension\n\n                get_bits(&gb, 11);\n\n                c->ext_object_type = get_object_type(&gb);\n\n                if (c->ext_object_type == AOT_SBR && (c->sbr = get_bits1(&gb)) == 1) {\n\n                    c->ext_sample_rate = get_sample_rate(&gb, &c->ext_sampling_index);\n\n                    if (c->ext_sample_rate == c->sample_rate)\n\n                        c->sbr = -1;\n\n                }\n\n                if (get_bits_left(&gb) > 11 && get_bits(&gb, 11) == 0x548)\n\n                    c->ps = get_bits1(&gb);\n\n                break;\n\n            } else\n\n                get_bits1(&gb); // skip 1 bit\n\n        }\n\n    }\n\n\n\n    //PS requires SBR\n\n    if (!c->sbr)\n\n        c->ps = 0;\n\n    //Limit implicit PS to the HE-AACv2 Profile\n\n    if ((c->ps == -1 && c->object_type != AOT_AAC_LC) || c->channels & ~0x01)\n\n        c->ps = 0;\n\n\n\n    return specific_config_bitindex;\n\n}\n", "idx": 22831}
{"project": "FFmpeg", "commit_id": "a66c6e28b543804f50df1c6083a204219b6b1daa", "target": 1, "func": "static AVRational update_sar(int old_w, int old_h, AVRational sar, int new_w, int new_h)\n\n{\n\n    // attempt to keep aspect during typical resolution switches\n\n    if (!sar.num)\n\n        sar = (AVRational){1, 1};\n\n\n\n    sar = av_mul_q(sar, (AVRational){new_h * old_w, new_w * old_h});\n\n    return sar;\n\n}\n", "idx": 22833}
{"project": "FFmpeg", "commit_id": "f5475e1b38a37c6da2e26097242cf82a2b1a9ee9", "target": 1, "func": "vorbis_header (AVFormatContext * s, int idx)\n\n{\n\n    ogg_t *ogg = s->priv_data;\n\n    ogg_stream_t *os = ogg->streams + idx;\n\n    AVStream *st = s->streams[idx];\n\n    oggvorbis_private_t *priv;\n\n\n\n    if (os->seq > 2)\n\n        return 0;\n\n\n\n    if (os->seq == 0) {\n\n        os->private = av_mallocz(sizeof(oggvorbis_private_t));\n\n        if (!os->private)\n\n            return 0;\n\n    }\n\n\n\n    priv = os->private;\n\n    priv->len[os->seq] = os->psize;\n\n    priv->packet[os->seq] = av_mallocz(os->psize);\n\n    memcpy(priv->packet[os->seq], os->buf + os->pstart, os->psize);\n\n    if (os->buf[os->pstart] == 1) {\n\n        uint8_t *p = os->buf + os->pstart + 11; //skip up to the audio channels\n\n        st->codec->channels = *p++;\n\n        st->codec->sample_rate = AV_RL32(p);\n\n        p += 8; //skip maximum and and nominal bitrate\n\n        st->codec->bit_rate = AV_RL32(p); //Minimum bitrate\n\n\n\n        st->codec->codec_type = CODEC_TYPE_AUDIO;\n\n        st->codec->codec_id = CODEC_ID_VORBIS;\n\n\n\n        st->time_base.num = 1;\n\n        st->time_base.den = st->codec->sample_rate;\n\n    } else if (os->buf[os->pstart] == 3) {\n\n        vorbis_comment (s, os->buf + os->pstart + 7, os->psize - 8);\n\n    } else {\n\n        st->codec->extradata_size =\n\n            fixup_vorbis_headers(s, priv, &st->codec->extradata);\n\n    }\n\n\n\n    return os->seq < 3;\n\n}\n", "idx": 22835}
{"project": "FFmpeg", "commit_id": "984d58a3440d513f66344b5332f6b589c0a6bbc6", "target": 1, "func": "static struct URLProtocol *url_find_protocol(const char *filename)\n\n{\n\n    URLProtocol *up = NULL;\n\n    char proto_str[128], proto_nested[128], *ptr;\n\n    size_t proto_len = strspn(filename, URL_SCHEME_CHARS);\n\n\n\n    if (filename[proto_len] != ':' &&\n\n        (filename[proto_len] != ',' || !strchr(filename + proto_len + 1, ':')) ||\n\n        is_dos_path(filename))\n\n        strcpy(proto_str, \"file\");\n\n    else\n\n        av_strlcpy(proto_str, filename,\n\n                   FFMIN(proto_len + 1, sizeof(proto_str)));\n\n\n\n    if ((ptr = strchr(proto_str, ',')))\n\n        *ptr = '\\0';\n\n    av_strlcpy(proto_nested, proto_str, sizeof(proto_nested));\n\n    if ((ptr = strchr(proto_nested, '+')))\n\n        *ptr = '\\0';\n\n\n\n    while (up = ffurl_protocol_next(up)) {\n\n        if (!strcmp(proto_str, up->name))\n\n            break;\n\n        if (up->flags & URL_PROTOCOL_FLAG_NESTED_SCHEME &&\n\n            !strcmp(proto_nested, up->name))\n\n            break;\n\n    }\n\n\n\n    return up;\n\n}\n", "idx": 22840}
{"project": "FFmpeg", "commit_id": "ade8a46154cb45c88b1cb5c616eaa6320c941187", "target": 0, "func": "static av_cold int sonic_decode_init(AVCodecContext *avctx)\n\n{\n\n    SonicContext *s = avctx->priv_data;\n\n    GetBitContext gb;\n\n    int i;\n\n\n\n    s->channels = avctx->channels;\n\n    s->samplerate = avctx->sample_rate;\n\n\n\n    if (!avctx->extradata)\n\n    {\n\n        av_log(avctx, AV_LOG_ERROR, \"No mandatory headers present\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    init_get_bits8(&gb, avctx->extradata, avctx->extradata_size);\n\n\n\n    s->version = get_bits(&gb, 2);\n\n    if (s->version >= 2) {\n\n        s->version       = get_bits(&gb, 8);\n\n        s->minor_version = get_bits(&gb, 8);\n\n    }\n\n    if (s->version != 2)\n\n    {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported Sonic version, please report\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->version >= 1)\n\n    {\n\n        s->channels = get_bits(&gb, 2);\n\n        s->samplerate = samplerate_table[get_bits(&gb, 4)];\n\n        av_log(avctx, AV_LOG_INFO, \"Sonicv2 chans: %d samprate: %d\\n\",\n\n            s->channels, s->samplerate);\n\n    }\n\n\n\n    if (s->channels > MAX_CHANNELS)\n\n    {\n\n        av_log(avctx, AV_LOG_ERROR, \"Only mono and stereo streams are supported by now\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    s->lossless = get_bits1(&gb);\n\n    if (!s->lossless)\n\n        skip_bits(&gb, 3); // XXX FIXME\n\n    s->decorrelation = get_bits(&gb, 2);\n\n    if (s->decorrelation != 3 && s->channels != 2) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid decorrelation %d\\n\", s->decorrelation);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    s->downsampling = get_bits(&gb, 2);\n\n    if (!s->downsampling) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid downsampling value\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    s->num_taps = (get_bits(&gb, 5)+1)<<5;\n\n    if (get_bits1(&gb)) // XXX FIXME\n\n        av_log(avctx, AV_LOG_INFO, \"Custom quant table\\n\");\n\n\n\n    s->block_align = 2048LL*s->samplerate/(44100*s->downsampling);\n\n    s->frame_size = s->channels*s->block_align*s->downsampling;\n\n//    avctx->frame_size = s->block_align;\n\n\n\n    av_log(avctx, AV_LOG_INFO, \"Sonic: ver: %d.%d ls: %d dr: %d taps: %d block: %d frame: %d downsamp: %d\\n\",\n\n        s->version, s->minor_version, s->lossless, s->decorrelation, s->num_taps, s->block_align, s->frame_size, s->downsampling);\n\n\n\n    // generate taps\n\n    s->tap_quant = av_calloc(s->num_taps, sizeof(*s->tap_quant));\n\n    if (!s->tap_quant)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for (i = 0; i < s->num_taps; i++)\n\n        s->tap_quant[i] = ff_sqrt(i+1);\n\n\n\n    s->predictor_k = av_calloc(s->num_taps, sizeof(*s->predictor_k));\n\n\n\n    for (i = 0; i < s->channels; i++)\n\n    {\n\n        s->predictor_state[i] = av_calloc(s->num_taps, sizeof(**s->predictor_state));\n\n        if (!s->predictor_state[i])\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    for (i = 0; i < s->channels; i++)\n\n    {\n\n        s->coded_samples[i] = av_calloc(s->block_align, sizeof(**s->coded_samples));\n\n        if (!s->coded_samples[i])\n\n            return AVERROR(ENOMEM);\n\n    }\n\n    s->int_samples = av_calloc(s->frame_size, sizeof(*s->int_samples));\n\n    if (!s->int_samples)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_S16;\n\n    return 0;\n\n}\n", "idx": 22842}
{"project": "FFmpeg", "commit_id": "ee90119e9ee0e2c54f1017bbe1460bfcd50555d0", "target": 1, "func": "static int decode_block(BinkAudioContext *s, float **out, int use_dct)\n\n{\n\n    int ch, i, j, k;\n\n    float q, quant[25];\n\n    int width, coeff;\n\n    GetBitContext *gb = &s->gb;\n\n\n\n    if (use_dct)\n\n        skip_bits(gb, 2);\n\n\n\n    for (ch = 0; ch < s->channels; ch++) {\n\n        FFTSample *coeffs = out[ch];\n\n\n\n        if (s->version_b) {\n\n            if (get_bits_left(gb) < 64)\n\n                return AVERROR_INVALIDDATA;\n\n            coeffs[0] = av_int2float(get_bits_long(gb, 32)) * s->root;\n\n            coeffs[1] = av_int2float(get_bits_long(gb, 32)) * s->root;\n\n        } else {\n\n            if (get_bits_left(gb) < 58)\n\n                return AVERROR_INVALIDDATA;\n\n            coeffs[0] = get_float(gb) * s->root;\n\n            coeffs[1] = get_float(gb) * s->root;\n\n        }\n\n\n\n        if (get_bits_left(gb) < s->num_bands * 8)\n\n            return AVERROR_INVALIDDATA;\n\n        for (i = 0; i < s->num_bands; i++) {\n\n            int value = get_bits(gb, 8);\n\n            quant[i]  = quant_table[FFMIN(value, 95)];\n\n        }\n\n\n\n        k = 0;\n\n        q = quant[0];\n\n\n\n        // parse coefficients\n\n        i = 2;\n\n        while (i < s->frame_len) {\n\n            if (s->version_b) {\n\n                j = i + 16;\n\n            } else {\n\n                int v;\n\n                GET_BITS_SAFE(v, 1);\n\n                if (v) {\n\n                    GET_BITS_SAFE(v, 4);\n\n                    j = i + rle_length_tab[v] * 8;\n\n                } else {\n\n                    j = i + 8;\n\n                }\n\n            }\n\n\n\n            j = FFMIN(j, s->frame_len);\n\n\n\n            GET_BITS_SAFE(width, 4);\n\n            if (width == 0) {\n\n                memset(coeffs + i, 0, (j - i) * sizeof(*coeffs));\n\n                i = j;\n\n                while (s->bands[k] < i)\n\n                    q = quant[k++];\n\n            } else {\n\n                while (i < j) {\n\n                    if (s->bands[k] == i)\n\n                        q = quant[k++];\n\n                    GET_BITS_SAFE(coeff, width);\n\n                    if (coeff) {\n\n                        int v;\n\n                        GET_BITS_SAFE(v, 1);\n\n                        if (v)\n\n                            coeffs[i] = -q * coeff;\n\n                        else\n\n                            coeffs[i] =  q * coeff;\n\n                    } else {\n\n                        coeffs[i] = 0.0f;\n\n                    }\n\n                    i++;\n\n                }\n\n            }\n\n        }\n\n\n\n        if (CONFIG_BINKAUDIO_DCT_DECODER && use_dct) {\n\n            coeffs[0] /= 0.5;\n\n            s->trans.dct.dct_calc(&s->trans.dct,  coeffs);\n\n        }\n\n        else if (CONFIG_BINKAUDIO_RDFT_DECODER)\n\n            s->trans.rdft.rdft_calc(&s->trans.rdft, coeffs);\n\n    }\n\n\n\n    for (ch = 0; ch < s->channels; ch++) {\n\n        int j;\n\n        int count = s->overlap_len * s->channels;\n\n        if (!s->first) {\n\n            j = ch;\n\n            for (i = 0; i < s->overlap_len; i++, j += s->channels)\n\n                out[ch][i] = (s->previous[ch][i] * (count - j) +\n\n                                      out[ch][i] *          j) / count;\n\n        }\n\n        memcpy(s->previous[ch], &out[ch][s->frame_len - s->overlap_len],\n\n               s->overlap_len * sizeof(*s->previous[ch]));\n\n    }\n\n\n\n    s->first = 0;\n\n\n\n    return 0;\n\n}\n", "idx": 22844}
{"project": "FFmpeg", "commit_id": "831274fba4b14c542458ce5a3d0135b49499299a", "target": 1, "func": "static void flac_lpc_16_c(int32_t *decoded, const int coeffs[32],\n\n                          int pred_order, int qlevel, int len)\n\n{\n\n    int i, j;\n\n\n\n    for (i = pred_order; i < len - 1; i += 2, decoded += 2) {\n\n        int c = coeffs[0];\n\n        int d = decoded[0];\n\n        int s0 = 0, s1 = 0;\n\n        for (j = 1; j < pred_order; j++) {\n\n            s0 += c*d;\n\n            d = decoded[j];\n\n            s1 += c*d;\n\n            c = coeffs[j];\n\n        }\n\n        s0 += c*d;\n\n        d = decoded[j] += s0 >> qlevel;\n\n        s1 += c*d;\n\n        decoded[j + 1] += s1 >> qlevel;\n\n    }\n\n    if (i < len) {\n\n        int sum = 0;\n\n        for (j = 0; j < pred_order; j++)\n\n            sum += coeffs[j] * decoded[j];\n\n        decoded[j] += sum >> qlevel;\n\n    }\n\n}\n", "idx": 22850}
{"project": "FFmpeg", "commit_id": "bf1945af301aff54c33352e75f17aec6cb5269d7", "target": 0, "func": "static void hybrid_synthesis(float out[2][38][64], float in[91][32][2], int is34, int len)\n\n{\n\n    int i, n;\n\n    if (is34) {\n\n        for (n = 0; n < len; n++) {\n\n            memset(out[0][n], 0, 5*sizeof(out[0][n][0]));\n\n            memset(out[1][n], 0, 5*sizeof(out[1][n][0]));\n\n            for (i = 0; i < 12; i++) {\n\n                out[0][n][0] += in[   i][n][0];\n\n                out[1][n][0] += in[   i][n][1];\n\n            }\n\n            for (i = 0; i < 8; i++) {\n\n                out[0][n][1] += in[12+i][n][0];\n\n                out[1][n][1] += in[12+i][n][1];\n\n            }\n\n            for (i = 0; i < 4; i++) {\n\n                out[0][n][2] += in[20+i][n][0];\n\n                out[1][n][2] += in[20+i][n][1];\n\n                out[0][n][3] += in[24+i][n][0];\n\n                out[1][n][3] += in[24+i][n][1];\n\n                out[0][n][4] += in[28+i][n][0];\n\n                out[1][n][4] += in[28+i][n][1];\n\n            }\n\n        }\n\n        for (i = 0; i < 59; i++) {\n\n            for (n = 0; n < len; n++) {\n\n                out[0][n][i+5] = in[i+32][n][0];\n\n                out[1][n][i+5] = in[i+32][n][1];\n\n            }\n\n        }\n\n    } else {\n\n        for (n = 0; n < len; n++) {\n\n            out[0][n][0] = in[0][n][0] + in[1][n][0] + in[2][n][0] +\n\n                           in[3][n][0] + in[4][n][0] + in[5][n][0];\n\n            out[1][n][0] = in[0][n][1] + in[1][n][1] + in[2][n][1] +\n\n                           in[3][n][1] + in[4][n][1] + in[5][n][1];\n\n            out[0][n][1] = in[6][n][0] + in[7][n][0];\n\n            out[1][n][1] = in[6][n][1] + in[7][n][1];\n\n            out[0][n][2] = in[8][n][0] + in[9][n][0];\n\n            out[1][n][2] = in[8][n][1] + in[9][n][1];\n\n        }\n\n        for (i = 0; i < 61; i++) {\n\n            for (n = 0; n < len; n++) {\n\n                out[0][n][i+3] = in[i+10][n][0];\n\n                out[1][n][i+3] = in[i+10][n][1];\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 22861}
{"project": "FFmpeg", "commit_id": "e55c3857d20ba015e4914c2e80fcab037af0799d", "target": 0, "func": "static int audio_get_buffer(AVCodecContext *avctx, AVFrame *frame)\n\n{\n\n    AVCodecInternal *avci = avctx->internal;\n\n    InternalBuffer *buf;\n\n    int buf_size, ret;\n\n\n\n    buf_size = av_samples_get_buffer_size(NULL, avctx->channels,\n\n                                          frame->nb_samples, avctx->sample_fmt,\n\n                                          0);\n\n    if (buf_size < 0)\n\n        return AVERROR(EINVAL);\n\n\n\n    /* allocate InternalBuffer if needed */\n\n    if (!avci->buffer) {\n\n        avci->buffer = av_mallocz(sizeof(InternalBuffer));\n\n        if (!avci->buffer)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n    buf = avci->buffer;\n\n\n\n    /* if there is a previously-used internal buffer, check its size and\n\n     * channel count to see if we can reuse it */\n\n    if (buf->extended_data) {\n\n        /* if current buffer is too small, free it */\n\n        if (buf->extended_data[0] && buf_size > buf->audio_data_size) {\n\n            av_free(buf->extended_data[0]);\n\n            if (buf->extended_data != buf->data)\n\n                av_free(buf->extended_data);\n\n            buf->extended_data = NULL;\n\n            buf->data[0]       = NULL;\n\n        }\n\n        /* if number of channels has changed, reset and/or free extended data\n\n         * pointers but leave data buffer in buf->data[0] for reuse */\n\n        if (buf->nb_channels != avctx->channels) {\n\n            if (buf->extended_data != buf->data)\n\n                av_free(buf->extended_data);\n\n            buf->extended_data = NULL;\n\n        }\n\n    }\n\n\n\n    /* if there is no previous buffer or the previous buffer cannot be used\n\n     * as-is, allocate a new buffer and/or rearrange the channel pointers */\n\n    if (!buf->extended_data) {\n\n        if (!buf->data[0]) {\n\n            if (!(buf->data[0] = av_mallocz(buf_size)))\n\n                return AVERROR(ENOMEM);\n\n            buf->audio_data_size = buf_size;\n\n        }\n\n        if ((ret = avcodec_fill_audio_frame(frame, avctx->channels,\n\n                                            avctx->sample_fmt, buf->data[0],\n\n                                            buf->audio_data_size, 0)))\n\n            return ret;\n\n\n\n        if (frame->extended_data == frame->data)\n\n            buf->extended_data = buf->data;\n\n        else\n\n            buf->extended_data = frame->extended_data;\n\n        memcpy(buf->data, frame->data, sizeof(frame->data));\n\n        buf->linesize[0] = frame->linesize[0];\n\n        buf->nb_channels = avctx->channels;\n\n    } else {\n\n        /* copy InternalBuffer info to the AVFrame */\n\n        frame->extended_data = buf->extended_data;\n\n        frame->linesize[0]   = buf->linesize[0];\n\n        memcpy(frame->data, buf->data, sizeof(frame->data));\n\n    }\n\n\n\n    frame->type = FF_BUFFER_TYPE_INTERNAL;\n\n    ff_init_buffer_info(avctx, frame);\n\n\n\n    if (avctx->debug & FF_DEBUG_BUFFERS)\n\n        av_log(avctx, AV_LOG_DEBUG, \"default_get_buffer called on frame %p, \"\n\n                                    \"internal audio buffer used\\n\", frame);\n\n\n\n    return 0;\n\n}\n", "idx": 22862}
{"project": "FFmpeg", "commit_id": "a1926a29fb4325afa46842883f197c74d4535c36", "target": 0, "func": "static void luma_mc(HEVCContext *s, int16_t *dst, ptrdiff_t dststride,\n\n                    AVFrame *ref, const Mv *mv, int x_off, int y_off,\n\n                    int block_w, int block_h)\n\n{\n\n    HEVCLocalContext *lc = &s->HEVClc;\n\n    uint8_t *src         = ref->data[0];\n\n    ptrdiff_t srcstride  = ref->linesize[0];\n\n    int pic_width        = s->ps.sps->width;\n\n    int pic_height       = s->ps.sps->height;\n\n\n\n    int mx         = mv->x & 3;\n\n    int my         = mv->y & 3;\n\n    int extra_left = ff_hevc_qpel_extra_before[mx];\n\n    int extra_top  = ff_hevc_qpel_extra_before[my];\n\n\n\n    x_off += mv->x >> 2;\n\n    y_off += mv->y >> 2;\n\n    src   += y_off * srcstride + (x_off << s->ps.sps->pixel_shift);\n\n\n\n    if (x_off < extra_left || y_off < extra_top ||\n\n        x_off >= pic_width - block_w - ff_hevc_qpel_extra_after[mx] ||\n\n        y_off >= pic_height - block_h - ff_hevc_qpel_extra_after[my]) {\n\n        const int edge_emu_stride = EDGE_EMU_BUFFER_STRIDE << s->ps.sps->pixel_shift;\n\n        int offset = extra_top * srcstride + (extra_left << s->ps.sps->pixel_shift);\n\n        int buf_offset = extra_top *\n\n                         edge_emu_stride + (extra_left << s->ps.sps->pixel_shift);\n\n\n\n        s->vdsp.emulated_edge_mc(lc->edge_emu_buffer, src - offset,\n\n                                 edge_emu_stride, srcstride,\n\n                                 block_w + ff_hevc_qpel_extra[mx],\n\n                                 block_h + ff_hevc_qpel_extra[my],\n\n                                 x_off - extra_left, y_off - extra_top,\n\n                                 pic_width, pic_height);\n\n        src = lc->edge_emu_buffer + buf_offset;\n\n        srcstride = edge_emu_stride;\n\n    }\n\n    s->hevcdsp.put_hevc_qpel[my][mx](dst, dststride, src, srcstride, block_w,\n\n                                     block_h, lc->mc_buffer);\n\n}\n", "idx": 22873}
{"project": "FFmpeg", "commit_id": "ae5e1f3d663a8c9a532d89e588cbc61f171c9186", "target": 1, "func": "static int init_image(TiffContext *s, AVFrame *frame)\n{\n    int ret;\n    switch (s->planar * 1000 + s->bpp * 10 + s->bppcount) {\n    case 11:\n        s->avctx->pix_fmt = AV_PIX_FMT_MONOBLACK;\n        break;\n    case 81:\n        s->avctx->pix_fmt = s->palette_is_set ? AV_PIX_FMT_PAL8 : AV_PIX_FMT_GRAY8;\n        break;\n    case 243:\n        s->avctx->pix_fmt = AV_PIX_FMT_RGB24;\n        break;\n    case 161:\n        s->avctx->pix_fmt = s->le ? AV_PIX_FMT_GRAY16LE : AV_PIX_FMT_GRAY16BE;\n        break;\n    case 162:\n        s->avctx->pix_fmt = AV_PIX_FMT_YA8;\n        break;\n    case 322:\n        s->avctx->pix_fmt = s->le ? AV_PIX_FMT_YA16LE : AV_PIX_FMT_YA16BE;\n        break;\n    case 324:\n        s->avctx->pix_fmt = AV_PIX_FMT_RGBA;\n        break;\n    case 483:\n        s->avctx->pix_fmt = s->le ? AV_PIX_FMT_RGB48LE : AV_PIX_FMT_RGB48BE;\n        break;\n    case 644:\n        s->avctx->pix_fmt = s->le ? AV_PIX_FMT_RGBA64LE : AV_PIX_FMT_RGBA64BE;\n        break;\n    case 1243:\n        s->avctx->pix_fmt = AV_PIX_FMT_GBRP;\n        break;\n    case 1324:\n        s->avctx->pix_fmt = AV_PIX_FMT_GBRAP;\n        break;\n    case 1483:\n        s->avctx->pix_fmt = s->le ? AV_PIX_FMT_GBRP16LE : AV_PIX_FMT_GBRP16BE;\n        break;\n    case 1644:\n        s->avctx->pix_fmt = s->le ? AV_PIX_FMT_GBRAP16LE : AV_PIX_FMT_GBRAP16BE;\n        break;\n    default:\n               \"This format is not supported (bpp=%d, bppcount=%d)\\n\",\n    if (s->width != s->avctx->width || s->height != s->avctx->height) {\n        ret = ff_set_dimensions(s->avctx, s->width, s->height);\n        if (ret < 0)\n            return ret;\n    if ((ret = ff_get_buffer(s->avctx, frame, 0)) < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n        return ret;\n    if (s->avctx->pix_fmt == AV_PIX_FMT_PAL8) {\n        memcpy(frame->data[1], s->palette, sizeof(s->palette));\n    return 0;", "idx": 22881}
{"project": "FFmpeg", "commit_id": "4ec14ce121df4c33880251a96c2f3e7409eb14fe", "target": 0, "func": "static int jpeg2000_decode_packet(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile, int *tp_index,\n\n                                  Jpeg2000CodingStyle *codsty,\n\n                                  Jpeg2000ResLevel *rlevel, int precno,\n\n                                  int layno, uint8_t *expn, int numgbits)\n\n{\n\n    int bandno, cblkno, ret, nb_code_blocks;\n\n    int cwsno;\n\n\n\n    if (bytestream2_get_bytes_left(&s->g) == 0 && s->bit_index == 8) {\n\n        if (*tp_index < FF_ARRAY_ELEMS(tile->tile_part) - 1) {\n\n            s->g = tile->tile_part[++(*tp_index)].tpg;\n\n        }\n\n    }\n\n\n\n    if (bytestream2_peek_be32(&s->g) == 0xFF910004)\n\n        bytestream2_skip(&s->g, 6);\n\n\n\n    if (!(ret = get_bits(s, 1))) {\n\n        jpeg2000_flush(s);\n\n        return 0;\n\n    } else if (ret < 0)\n\n        return ret;\n\n\n\n    for (bandno = 0; bandno < rlevel->nbands; bandno++) {\n\n        Jpeg2000Band *band = rlevel->band + bandno;\n\n        Jpeg2000Prec *prec = band->prec + precno;\n\n\n\n        if (band->coord[0][0] == band->coord[0][1] ||\n\n            band->coord[1][0] == band->coord[1][1])\n\n            continue;\n\n        nb_code_blocks =  prec->nb_codeblocks_height *\n\n                          prec->nb_codeblocks_width;\n\n        for (cblkno = 0; cblkno < nb_code_blocks; cblkno++) {\n\n            Jpeg2000Cblk *cblk = prec->cblk + cblkno;\n\n            int incl, newpasses, llen;\n\n\n\n            if (cblk->npasses)\n\n                incl = get_bits(s, 1);\n\n            else\n\n                incl = tag_tree_decode(s, prec->cblkincl + cblkno, layno + 1) == layno;\n\n            if (!incl)\n\n                continue;\n\n            else if (incl < 0)\n\n                return incl;\n\n\n\n            if (!cblk->npasses) {\n\n                int v = expn[bandno] + numgbits - 1 -\n\n                        tag_tree_decode(s, prec->zerobits + cblkno, 100);\n\n                if (v < 0) {\n\n                    av_log(s->avctx, AV_LOG_ERROR,\n\n                           \"nonzerobits %d invalid\\n\", v);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                cblk->nonzerobits = v;\n\n            }\n\n            if ((newpasses = getnpasses(s)) < 0)\n\n                return newpasses;\n\n            av_assert2(newpasses > 0);\n\n            if (cblk->npasses + newpasses >= JPEG2000_MAX_PASSES) {\n\n                avpriv_request_sample(s->avctx, \"Too many passes\\n\");\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n            if ((llen = getlblockinc(s)) < 0)\n\n                return llen;\n\n            if (cblk->lblock + llen + av_log2(newpasses) > 16) {\n\n                avpriv_request_sample(s->avctx,\n\n                                      \"Block with length beyond 16 bits\\n\");\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n\n\n            cblk->lblock += llen;\n\n\n\n            cblk->nb_lengthinc = 0;\n\n            cblk->nb_terminationsinc = 0;\n\n            do {\n\n                int newpasses1 = 0;\n\n\n\n                while (newpasses1 < newpasses) {\n\n                    newpasses1 ++;\n\n                    if (needs_termination(codsty->cblk_style, cblk->npasses + newpasses1 - 1)) {\n\n                        cblk->nb_terminationsinc ++;\n\n                        break;\n\n                    }\n\n                }\n\n\n\n                if ((ret = get_bits(s, av_log2(newpasses1) + cblk->lblock)) < 0)\n\n                    return ret;\n\n                if (ret > sizeof(cblk->data)) {\n\n                    avpriv_request_sample(s->avctx,\n\n                                        \"Block with lengthinc greater than %\"SIZE_SPECIFIER\"\",\n\n                                        sizeof(cblk->data));\n\n                    return AVERROR_PATCHWELCOME;\n\n                }\n\n                cblk->lengthinc[cblk->nb_lengthinc++] = ret;\n\n                cblk->npasses  += newpasses1;\n\n                newpasses -= newpasses1;\n\n            } while(newpasses);\n\n        }\n\n    }\n\n    jpeg2000_flush(s);\n\n\n\n    if (codsty->csty & JPEG2000_CSTY_EPH) {\n\n        if (bytestream2_peek_be16(&s->g) == JPEG2000_EPH)\n\n            bytestream2_skip(&s->g, 2);\n\n        else\n\n            av_log(s->avctx, AV_LOG_ERROR, \"EPH marker not found.\\n\");\n\n    }\n\n\n\n    for (bandno = 0; bandno < rlevel->nbands; bandno++) {\n\n        Jpeg2000Band *band = rlevel->band + bandno;\n\n        Jpeg2000Prec *prec = band->prec + precno;\n\n\n\n        nb_code_blocks = prec->nb_codeblocks_height * prec->nb_codeblocks_width;\n\n        for (cblkno = 0; cblkno < nb_code_blocks; cblkno++) {\n\n            Jpeg2000Cblk *cblk = prec->cblk + cblkno;\n\n            for (cwsno = 0; cwsno < cblk->nb_lengthinc; cwsno ++) {\n\n                if (   bytestream2_get_bytes_left(&s->g) < cblk->lengthinc[cwsno]\n\n                    || sizeof(cblk->data) < cblk->length + cblk->lengthinc[cwsno] + 4\n\n                ) {\n\n                    av_log(s->avctx, AV_LOG_ERROR,\n\n                        \"Block length %\"PRIu16\" or lengthinc %d is too large, left %d\\n\",\n\n                        cblk->length, cblk->lengthinc[cwsno], bytestream2_get_bytes_left(&s->g));\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                bytestream2_get_bufferu(&s->g, cblk->data + cblk->length, cblk->lengthinc[cwsno]);\n\n                cblk->length   += cblk->lengthinc[cwsno];\n\n                cblk->lengthinc[cwsno] = 0;\n\n                if (cblk->nb_terminationsinc) {\n\n                    cblk->nb_terminationsinc--;\n\n                    cblk->nb_terminations++;\n\n                    cblk->data[cblk->length++] = 0xFF;\n\n                    cblk->data[cblk->length++] = 0xFF;\n\n                    cblk->data_start[cblk->nb_terminations] = cblk->length;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 22882}
{"project": "FFmpeg", "commit_id": "2dd18d4435c27a469b89e1d6b061eb9b4661687d", "target": 0, "func": "rdt_parse_sdp_line (AVFormatContext *s, int st_index,\n\n                    PayloadContext *rdt, const char *line)\n\n{\n\n    AVStream *stream = s->streams[st_index];\n\n    const char *p = line;\n\n\n\n    if (av_strstart(p, \"OpaqueData:buffer;\", &p)) {\n\n        rdt->mlti_data = rdt_parse_b64buf(&rdt->mlti_data_size, p);\n\n    } else if (av_strstart(p, \"StartTime:integer;\", &p))\n\n        stream->first_dts = atoi(p);\n\n    else if (av_strstart(p, \"ASMRuleBook:string;\", &p)) {\n\n        int n, first = -1;\n\n\n\n        for (n = 0; n < s->nb_streams; n++)\n\n            if (s->streams[n]->id == stream->id) {\n\n                int count = s->streams[n]->index + 1;\n\n                if (first == -1) first = n;\n\n                if (rdt->nb_rmst < count) {\n\n                    RMStream **rmst= av_realloc(rdt->rmst, count*sizeof(*rmst));\n\n                    if (!rmst)\n\n                        return AVERROR(ENOMEM);\n\n                    memset(rmst + rdt->nb_rmst, 0,\n\n                           (count - rdt->nb_rmst) * sizeof(*rmst));\n\n                    rdt->rmst    = rmst;\n\n                    rdt->nb_rmst = count;\n\n                }\n\n                rdt->rmst[s->streams[n]->index] = ff_rm_alloc_rmstream();\n\n                rdt_load_mdpr(rdt, s->streams[n], (n - first) * 2);\n\n\n\n                if (s->streams[n]->codec->codec_id == CODEC_ID_AAC)\n\n                    s->streams[n]->codec->frame_size = 1; // FIXME\n\n           }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22883}
{"project": "FFmpeg", "commit_id": "84f4be424d52b05fabe0fe8cfb569c77fc0c1f7b", "target": 0, "func": "static void psy_3gpp_analyze_channel(FFPsyContext *ctx, int channel,\n\n                                     const float *coefs, const FFPsyWindowInfo *wi)\n\n{\n\n    AacPsyContext *pctx = (AacPsyContext*) ctx->model_priv_data;\n\n    AacPsyChannel *pch  = &pctx->ch[channel];\n\n    int i, w, g;\n\n    float desired_bits, desired_pe, delta_pe, reduction= NAN, spread_en[128] = {0};\n\n    float a = 0.0f, active_lines = 0.0f, norm_fac = 0.0f;\n\n    float pe = pctx->chan_bitrate > 32000 ? 0.0f : FFMAX(50.0f, 100.0f - pctx->chan_bitrate * 100.0f / 32000.0f);\n\n    const int      num_bands   = ctx->num_bands[wi->num_windows == 8];\n\n    const uint8_t *band_sizes  = ctx->bands[wi->num_windows == 8];\n\n    AacPsyCoeffs  *coeffs      = pctx->psy_coef[wi->num_windows == 8];\n\n    const float avoid_hole_thr = wi->num_windows == 8 ? PSY_3GPP_AH_THR_SHORT : PSY_3GPP_AH_THR_LONG;\n\n\n\n    //calculate energies, initial thresholds and related values - 5.4.2 \"Threshold Calculation\"\n\n    calc_thr_3gpp(wi, num_bands, pch, band_sizes, coefs);\n\n\n\n    //modify thresholds and energies - spread, threshold in quiet, pre-echo control\n\n    for (w = 0; w < wi->num_windows*16; w += 16) {\n\n        AacPsyBand *bands = &pch->band[w];\n\n\n\n        /* 5.4.2.3 \"Spreading\" & 5.4.3 \"Spread Energy Calculation\" */\n\n        spread_en[0] = bands[0].energy;\n\n        for (g = 1; g < num_bands; g++) {\n\n            bands[g].thr   = FFMAX(bands[g].thr,    bands[g-1].thr * coeffs[g].spread_hi[0]);\n\n            spread_en[w+g] = FFMAX(bands[g].energy, spread_en[w+g-1] * coeffs[g].spread_hi[1]);\n\n        }\n\n        for (g = num_bands - 2; g >= 0; g--) {\n\n            bands[g].thr   = FFMAX(bands[g].thr,   bands[g+1].thr * coeffs[g].spread_low[0]);\n\n            spread_en[w+g] = FFMAX(spread_en[w+g], spread_en[w+g+1] * coeffs[g].spread_low[1]);\n\n        }\n\n        //5.4.2.4 \"Threshold in quiet\"\n\n        for (g = 0; g < num_bands; g++) {\n\n            AacPsyBand *band = &bands[g];\n\n\n\n            band->thr_quiet = band->thr = FFMAX(band->thr, coeffs[g].ath);\n\n            //5.4.2.5 \"Pre-echo control\"\n\n            if (!(wi->window_type[0] == LONG_STOP_SEQUENCE || (wi->window_type[1] == LONG_START_SEQUENCE && !w)))\n\n                band->thr = FFMAX(PSY_3GPP_RPEMIN*band->thr, FFMIN(band->thr,\n\n                                  PSY_3GPP_RPELEV*pch->prev_band[w+g].thr_quiet));\n\n\n\n            /* 5.6.1.3.1 \"Preparatory steps of the perceptual entropy calculation\" */\n\n            pe += calc_pe_3gpp(band);\n\n            a  += band->pe_const;\n\n            active_lines += band->active_lines;\n\n\n\n            /* 5.6.1.3.3 \"Selection of the bands for avoidance of holes\" */\n\n            if (spread_en[w+g] * avoid_hole_thr > band->energy || coeffs[g].min_snr > 1.0f)\n\n                band->avoid_holes = PSY_3GPP_AH_NONE;\n\n            else\n\n                band->avoid_holes = PSY_3GPP_AH_INACTIVE;\n\n        }\n\n    }\n\n\n\n    /* 5.6.1.3.2 \"Calculation of the desired perceptual entropy\" */\n\n    ctx->ch[channel].entropy = pe;\n\n    desired_bits = calc_bit_demand(pctx, pe, ctx->bitres.bits, ctx->bitres.size, wi->num_windows == 8);\n\n    desired_pe = PSY_3GPP_BITS_TO_PE(desired_bits);\n\n    /* NOTE: PE correction is kept simple. During initial testing it had very\n\n     *       little effect on the final bitrate. Probably a good idea to come\n\n     *       back and do more testing later.\n\n     */\n\n    if (ctx->bitres.bits > 0)\n\n        desired_pe *= av_clipf(pctx->pe.previous / PSY_3GPP_BITS_TO_PE(ctx->bitres.bits),\n\n                               0.85f, 1.15f);\n\n    pctx->pe.previous = PSY_3GPP_BITS_TO_PE(desired_bits);\n\n\n\n    if (desired_pe < pe) {\n\n        /* 5.6.1.3.4 \"First Estimation of the reduction value\" */\n\n        for (w = 0; w < wi->num_windows*16; w += 16) {\n\n            reduction = calc_reduction_3gpp(a, desired_pe, pe, active_lines);\n\n            pe = 0.0f;\n\n            a  = 0.0f;\n\n            active_lines = 0.0f;\n\n            for (g = 0; g < num_bands; g++) {\n\n                AacPsyBand *band = &pch->band[w+g];\n\n\n\n                band->thr = calc_reduced_thr_3gpp(band, coeffs[g].min_snr, reduction);\n\n                /* recalculate PE */\n\n                pe += calc_pe_3gpp(band);\n\n                a  += band->pe_const;\n\n                active_lines += band->active_lines;\n\n            }\n\n        }\n\n\n\n        /* 5.6.1.3.5 \"Second Estimation of the reduction value\" */\n\n        for (i = 0; i < 2; i++) {\n\n            float pe_no_ah = 0.0f, desired_pe_no_ah;\n\n            active_lines = a = 0.0f;\n\n            for (w = 0; w < wi->num_windows*16; w += 16) {\n\n                for (g = 0; g < num_bands; g++) {\n\n                    AacPsyBand *band = &pch->band[w+g];\n\n\n\n                    if (band->avoid_holes != PSY_3GPP_AH_ACTIVE) {\n\n                        pe_no_ah += band->pe;\n\n                        a        += band->pe_const;\n\n                        active_lines += band->active_lines;\n\n                    }\n\n                }\n\n            }\n\n            desired_pe_no_ah = FFMAX(desired_pe - (pe - pe_no_ah), 0.0f);\n\n            if (active_lines > 0.0f)\n\n                reduction += calc_reduction_3gpp(a, desired_pe_no_ah, pe_no_ah, active_lines);\n\n\n\n            pe = 0.0f;\n\n            for (w = 0; w < wi->num_windows*16; w += 16) {\n\n                for (g = 0; g < num_bands; g++) {\n\n                    AacPsyBand *band = &pch->band[w+g];\n\n\n\n                    if (active_lines > 0.0f)\n\n                        band->thr = calc_reduced_thr_3gpp(band, coeffs[g].min_snr, reduction);\n\n                    pe += calc_pe_3gpp(band);\n\n                    band->norm_fac = band->active_lines / band->thr;\n\n                    norm_fac += band->norm_fac;\n\n                }\n\n            }\n\n            delta_pe = desired_pe - pe;\n\n            if (fabs(delta_pe) > 0.05f * desired_pe)\n\n                break;\n\n        }\n\n\n\n        if (pe < 1.15f * desired_pe) {\n\n            /* 6.6.1.3.6 \"Final threshold modification by linearization\" */\n\n            norm_fac = 1.0f / norm_fac;\n\n            for (w = 0; w < wi->num_windows*16; w += 16) {\n\n                for (g = 0; g < num_bands; g++) {\n\n                    AacPsyBand *band = &pch->band[w+g];\n\n\n\n                    if (band->active_lines > 0.5f) {\n\n                        float delta_sfb_pe = band->norm_fac * norm_fac * delta_pe;\n\n                        float thr = band->thr;\n\n\n\n                        thr *= exp2f(delta_sfb_pe / band->active_lines);\n\n                        if (thr > coeffs[g].min_snr * band->energy && band->avoid_holes == PSY_3GPP_AH_INACTIVE)\n\n                            thr = FFMAX(band->thr, coeffs[g].min_snr * band->energy);\n\n                        band->thr = thr;\n\n                    }\n\n                }\n\n            }\n\n        } else {\n\n            /* 5.6.1.3.7 \"Further perceptual entropy reduction\" */\n\n            g = num_bands;\n\n            while (pe > desired_pe && g--) {\n\n                for (w = 0; w < wi->num_windows*16; w+= 16) {\n\n                    AacPsyBand *band = &pch->band[w+g];\n\n                    if (band->avoid_holes != PSY_3GPP_AH_NONE && coeffs[g].min_snr < PSY_SNR_1DB) {\n\n                        coeffs[g].min_snr = PSY_SNR_1DB;\n\n                        band->thr = band->energy * PSY_SNR_1DB;\n\n                        pe += band->active_lines * 1.5f - band->pe;\n\n                    }\n\n                }\n\n            }\n\n            /* TODO: allow more holes (unused without mid/side) */\n\n        }\n\n    }\n\n\n\n    for (w = 0; w < wi->num_windows*16; w += 16) {\n\n        for (g = 0; g < num_bands; g++) {\n\n            AacPsyBand *band     = &pch->band[w+g];\n\n            FFPsyBand  *psy_band = &ctx->ch[channel].psy_bands[w+g];\n\n\n\n            psy_band->threshold = band->thr;\n\n            psy_band->energy    = band->energy;\n\n        }\n\n    }\n\n\n\n    memcpy(pch->prev_band, pch->band, sizeof(pch->band));\n\n}\n", "idx": 22884}
{"project": "FFmpeg", "commit_id": "83548fe894cdb455cc127f754d09905b6d23c173", "target": 0, "func": "static int avi_write_ix(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    AVIContext *avi = s->priv_data;\n\n    char tag[5];\n\n    char ix_tag[] = \"ix00\";\n\n    int i, j;\n\n\n\n    assert(pb->seekable);\n\n\n\n    if (avi->riff_id > AVI_MASTER_INDEX_SIZE)\n\n        return -1;\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVIStream *avist = s->streams[i]->priv_data;\n\n        int64_t ix, pos;\n\n\n\n        avi_stream2fourcc(tag, i, s->streams[i]->codecpar->codec_type);\n\n        ix_tag[3] = '0' + i;\n\n\n\n        /* Writing AVI OpenDML leaf index chunk */\n\n        ix = avio_tell(pb);\n\n        ffio_wfourcc(pb, ix_tag);      /* ix?? */\n\n        avio_wl32(pb, avist->indexes.entry * 8 + 24);\n\n        /* chunk size */\n\n        avio_wl16(pb, 2);           /* wLongsPerEntry */\n\n        avio_w8(pb, 0);             /* bIndexSubType (0 == frame index) */\n\n        avio_w8(pb, 1);             /* bIndexType (1 == AVI_INDEX_OF_CHUNKS) */\n\n        avio_wl32(pb, avist->indexes.entry);\n\n        /* nEntriesInUse */\n\n        ffio_wfourcc(pb, tag);         /* dwChunkId */\n\n        avio_wl64(pb, avi->movi_list); /* qwBaseOffset */\n\n        avio_wl32(pb, 0);              /* dwReserved_3 (must be 0) */\n\n\n\n        for (j = 0; j < avist->indexes.entry; j++) {\n\n            AVIIentry *ie = avi_get_ientry(&avist->indexes, j);\n\n            avio_wl32(pb, ie->pos + 8);\n\n            avio_wl32(pb, ((uint32_t) ie->len & ~0x80000000) |\n\n                          (ie->flags & 0x10 ? 0 : 0x80000000));\n\n        }\n\n        avio_flush(pb);\n\n        pos = avio_tell(pb);\n\n\n\n        /* Updating one entry in the AVI OpenDML master index */\n\n        avio_seek(pb, avist->indexes.indx_start - 8, SEEK_SET);\n\n        ffio_wfourcc(pb, \"indx\");             /* enabling this entry */\n\n        avio_skip(pb, 8);\n\n        avio_wl32(pb, avi->riff_id);          /* nEntriesInUse */\n\n        avio_skip(pb, 16 * avi->riff_id);\n\n        avio_wl64(pb, ix);                    /* qwOffset */\n\n        avio_wl32(pb, pos - ix);              /* dwSize */\n\n        avio_wl32(pb, avist->indexes.entry);  /* dwDuration */\n\n\n\n        avio_seek(pb, pos, SEEK_SET);\n\n    }\n\n    return 0;\n\n}\n", "idx": 22885}
{"project": "FFmpeg", "commit_id": "e2afcc33e0bcba92ab6c767f09f17a67911a4928", "target": 0, "func": "int ff_dxva2_decode_init(AVCodecContext *avctx)\n\n{\n\n    FFDXVASharedContext *sctx = DXVA_SHARED_CONTEXT(avctx);\n\n    AVHWFramesContext *frames_ctx = NULL;\n\n    int ret = 0;\n\n\n\n    // Old API.\n\n    if (avctx->hwaccel_context)\n\n        return 0;\n\n\n\n    // (avctx->pix_fmt is not updated yet at this point)\n\n    sctx->pix_fmt = avctx->hwaccel->pix_fmt;\n\n\n\n    if (avctx->codec_id == AV_CODEC_ID_H264 &&\n\n        (avctx->profile & ~FF_PROFILE_H264_CONSTRAINED) > FF_PROFILE_H264_HIGH) {\n\n        av_log(avctx, AV_LOG_VERBOSE, \"Unsupported H.264 profile for DXVA HWAccel: %d\\n\",avctx->profile);\n\n        return AVERROR(ENOTSUP);\n\n    }\n\n\n\n    if (avctx->codec_id == AV_CODEC_ID_HEVC &&\n\n        avctx->profile != FF_PROFILE_HEVC_MAIN && avctx->profile != FF_PROFILE_HEVC_MAIN_10) {\n\n        av_log(avctx, AV_LOG_VERBOSE, \"Unsupported HEVC profile for DXVA HWAccel: %d\\n\", avctx->profile);\n\n        return AVERROR(ENOTSUP);\n\n    }\n\n\n\n    if (!avctx->hw_frames_ctx && !avctx->hw_device_ctx) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Either a hw_frames_ctx or a hw_device_ctx needs to be set for hardware decoding.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (avctx->hw_frames_ctx) {\n\n        frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n\n    } else {\n\n        avctx->hw_frames_ctx = av_hwframe_ctx_alloc(avctx->hw_device_ctx);\n\n        if (!avctx->hw_frames_ctx)\n\n            return AVERROR(ENOMEM);\n\n\n\n        frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n\n\n\n        dxva_adjust_hwframes(avctx, frames_ctx);\n\n\n\n        ret = av_hwframe_ctx_init(avctx->hw_frames_ctx);\n\n        if (ret < 0)\n\n            goto fail;\n\n    }\n\n\n\n    sctx->device_ctx = frames_ctx->device_ctx;\n\n\n\n    if (frames_ctx->format != sctx->pix_fmt ||\n\n        !((sctx->pix_fmt == AV_PIX_FMT_D3D11 && CONFIG_D3D11VA) ||\n\n          (sctx->pix_fmt == AV_PIX_FMT_DXVA2_VLD && CONFIG_DXVA2))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid pixfmt for hwaccel!\\n\");\n\n        ret = AVERROR(EINVAL);\n\n        goto fail;\n\n    }\n\n\n\n#if CONFIG_D3D11VA\n\n    if (sctx->pix_fmt == AV_PIX_FMT_D3D11) {\n\n        AVD3D11VADeviceContext *device_hwctx = frames_ctx->device_ctx->hwctx;\n\n        AVD3D11VAContext *d3d11_ctx = &sctx->ctx.d3d11va;\n\n        HRESULT hr;\n\n\n\n        ff_dxva2_lock(avctx);\n\n        ret = d3d11va_create_decoder(avctx);\n\n        ff_dxva2_unlock(avctx);\n\n        if (ret < 0)\n\n            goto fail;\n\n\n\n        d3d11_ctx->decoder       = sctx->d3d11_decoder;\n\n        d3d11_ctx->video_context = device_hwctx->video_context;\n\n        d3d11_ctx->cfg           = &sctx->d3d11_config;\n\n        d3d11_ctx->surface_count = sctx->nb_d3d11_views;\n\n        d3d11_ctx->surface       = sctx->d3d11_views;\n\n        d3d11_ctx->workaround    = sctx->workaround;\n\n        d3d11_ctx->context_mutex = INVALID_HANDLE_VALUE;\n\n    }\n\n#endif\n\n\n\n#if CONFIG_DXVA2\n\n    if (sctx->pix_fmt == AV_PIX_FMT_DXVA2_VLD) {\n\n        AVDXVA2FramesContext *frames_hwctx = frames_ctx->hwctx;\n\n        struct dxva_context *dxva_ctx = &sctx->ctx.dxva2;\n\n\n\n        ff_dxva2_lock(avctx);\n\n        ret = dxva2_create_decoder(avctx);\n\n        ff_dxva2_unlock(avctx);\n\n        if (ret < 0)\n\n            goto fail;\n\n\n\n        dxva_ctx->decoder       = sctx->dxva2_decoder;\n\n        dxva_ctx->cfg           = &sctx->dxva2_config;\n\n        dxva_ctx->surface       = frames_hwctx->surfaces;\n\n        dxva_ctx->surface_count = frames_hwctx->nb_surfaces;\n\n        dxva_ctx->workaround    = sctx->workaround;\n\n    }\n\n#endif\n\n\n\n    return 0;\n\n\n\nfail:\n\n    ff_dxva2_decode_uninit(avctx);\n\n    return ret;\n\n}\n", "idx": 22886}
{"project": "FFmpeg", "commit_id": "2df0c32ea12ddfa72ba88309812bfb13b674130f", "target": 0, "func": "static av_cold int twolame_encode_init(AVCodecContext *avctx)\n\n{\n\n    TWOLAMEContext *s = avctx->priv_data;\n\n    int ret;\n\n\n\n    avctx->frame_size = TWOLAME_SAMPLES_PER_FRAME;\n\n    avctx->delay      = 512 - 32 + 1;\n\n\n\n    s->glopts = twolame_init();\n\n    if (!s->glopts)\n\n        return AVERROR(ENOMEM);\n\n\n\n    twolame_set_verbosity(s->glopts, s->verbosity);\n\n    twolame_set_mode(s->glopts, s->mode);\n\n    twolame_set_psymodel(s->glopts, s->psymodel);\n\n    twolame_set_energy_levels(s->glopts, s->energy);\n\n    twolame_set_error_protection(s->glopts, s->error_protection);\n\n    twolame_set_copyright(s->glopts, s->copyright);\n\n    twolame_set_original(s->glopts, s->original);\n\n\n\n    twolame_set_num_channels(s->glopts, avctx->channels);\n\n    twolame_set_in_samplerate(s->glopts, avctx->sample_rate);\n\n    twolame_set_out_samplerate(s->glopts, avctx->sample_rate);\n\n    if (avctx->flags & CODEC_FLAG_QSCALE || !avctx->bit_rate) {\n\n        twolame_set_VBR(s->glopts, TRUE);\n\n        twolame_set_VBR_level(s->glopts,\n\n                              avctx->global_quality / (float) FF_QP2LAMBDA);\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"VBR in MP2 is a hack, use another codec that supports it.\\n\");\n\n    } else {\n\n        twolame_set_bitrate(s->glopts, avctx->bit_rate / 1000);\n\n    }\n\n\n\n    ret = twolame_init_params(s->glopts);\n\n    if (ret) {\n\n        twolame_encode_close(avctx);\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22887}
{"project": "FFmpeg", "commit_id": "d8030c14bd7ac983b81ebe898631979f6b5aea09", "target": 1, "func": "static int decode_frame(AVCodecContext *avctx,\n                        void *data, int *got_frame,\n                        AVPacket *avpkt)\n{\n    SheerVideoContext *s = avctx->priv_data;\n    ThreadFrame frame = { .f = data };\n    AVFrame *p = data;\n    GetBitContext gb;\n    unsigned format;\n    int ret;\n    if (avpkt->size <= 20)\n    if (AV_RL32(avpkt->data) != MKTAG('S','h','i','r') &&\n        AV_RL32(avpkt->data) != MKTAG('Z','w','a','k'))\n    s->alt = 0;\n    format = AV_RL32(avpkt->data + 16);\n    av_log(avctx, AV_LOG_DEBUG, \"format: %s\\n\", av_fourcc2str(format));\n    switch (format) {\n    case MKTAG(' ', 'R', 'G', 'B'):\n        avctx->pix_fmt = AV_PIX_FMT_RGB0;\n        s->decode_frame = decode_rgb;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_r_rgb, 256);\n            ret |= build_vlc(&s->vlc[1], l_g_rgb, 256);\n        break;\n    case MKTAG(' ', 'r', 'G', 'B'):\n        avctx->pix_fmt = AV_PIX_FMT_RGB0;\n        s->decode_frame = decode_rgbi;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_r_rgbi, 256);\n            ret |= build_vlc(&s->vlc[1], l_g_rgbi, 256);\n        break;\n    case MKTAG('A', 'R', 'G', 'X'):\n        avctx->pix_fmt = AV_PIX_FMT_GBRAP10;\n        s->decode_frame = decode_argx;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_r_rgbx, 1024);\n            ret |= build_vlc(&s->vlc[1], l_g_rgbx, 1024);\n        break;\n    case MKTAG('A', 'r', 'G', 'X'):\n        avctx->pix_fmt = AV_PIX_FMT_GBRAP10;\n        s->decode_frame = decode_argxi;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_r_rgbxi, 1024);\n            ret |= build_vlc(&s->vlc[1], l_g_rgbxi, 1024);\n        break;\n    case MKTAG('R', 'G', 'B', 'X'):\n        avctx->pix_fmt = AV_PIX_FMT_GBRP10;\n        s->decode_frame = decode_rgbx;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_r_rgbx, 1024);\n            ret |= build_vlc(&s->vlc[1], l_g_rgbx, 1024);\n        break;\n    case MKTAG('r', 'G', 'B', 'X'):\n        avctx->pix_fmt = AV_PIX_FMT_GBRP10;\n        s->decode_frame = decode_rgbxi;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_r_rgbxi, 1024);\n            ret |= build_vlc(&s->vlc[1], l_g_rgbxi, 1024);\n        break;\n    case MKTAG('A', 'R', 'G', 'B'):\n        avctx->pix_fmt = AV_PIX_FMT_ARGB;\n        s->decode_frame = decode_argb;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_r_rgb, 256);\n            ret |= build_vlc(&s->vlc[1], l_g_rgb, 256);\n        break;\n    case MKTAG('A', 'r', 'G', 'B'):\n        avctx->pix_fmt = AV_PIX_FMT_ARGB;\n        s->decode_frame = decode_argbi;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_r_rgbi, 256);\n            ret |= build_vlc(&s->vlc[1], l_g_rgbi, 256);\n        break;\n    case MKTAG('A', 'Y', 'B', 'R'):\n        s->alt = 1;\n    case MKTAG('A', 'Y', 'b', 'R'):\n        avctx->pix_fmt = AV_PIX_FMT_YUVA444P;\n        s->decode_frame = decode_aybr;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_ybr, 256);\n            ret |= build_vlc(&s->vlc[1], l_u_ybr, 256);\n        break;\n    case MKTAG('A', 'y', 'B', 'R'):\n        s->alt = 1;\n    case MKTAG('A', 'y', 'b', 'R'):\n        avctx->pix_fmt = AV_PIX_FMT_YUVA444P;\n        s->decode_frame = decode_aybri;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_ybri, 256);\n            ret |= build_vlc(&s->vlc[1], l_u_ybri, 256);\n        break;\n    case MKTAG(' ', 'Y', 'B', 'R'):\n        s->alt = 1;\n    case MKTAG(' ', 'Y', 'b', 'R'):\n        avctx->pix_fmt = AV_PIX_FMT_YUV444P;\n        s->decode_frame = decode_ybr;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_ybr, 256);\n            ret |= build_vlc(&s->vlc[1], l_u_ybr, 256);\n        break;\n    case MKTAG(' ', 'y', 'B', 'R'):\n        s->alt = 1;\n    case MKTAG(' ', 'y', 'b', 'R'):\n        avctx->pix_fmt = AV_PIX_FMT_YUV444P;\n        s->decode_frame = decode_ybri;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_ybri, 256);\n            ret |= build_vlc(&s->vlc[1], l_u_ybri, 256);\n        break;\n    case MKTAG('Y', 'B', 'R', 0x0a):\n        avctx->pix_fmt = AV_PIX_FMT_YUV444P10;\n        s->decode_frame = decode_ybr10;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_ybr10, 1024);\n            ret |= build_vlc(&s->vlc[1], l_u_ybr10, 1024);\n        break;\n    case MKTAG('y', 'B', 'R', 0x0a):\n        avctx->pix_fmt = AV_PIX_FMT_YUV444P10;\n        s->decode_frame = decode_ybr10i;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_ybr10i, 1024);\n            ret |= build_vlc(&s->vlc[1], l_u_ybr10i, 1024);\n        break;\n    case MKTAG('C', 'A', '4', 'p'):\n        avctx->pix_fmt = AV_PIX_FMT_YUVA444P10;\n        s->decode_frame = decode_ca4p;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_ybr10, 1024);\n            ret |= build_vlc(&s->vlc[1], l_u_ybr10, 1024);\n        break;\n    case MKTAG('C', 'A', '4', 'i'):\n        avctx->pix_fmt = AV_PIX_FMT_YUVA444P10;\n        s->decode_frame = decode_ca4i;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_ybr10i, 1024);\n            ret |= build_vlc(&s->vlc[1], l_u_ybr10i, 1024);\n        break;\n    case MKTAG('B', 'Y', 'R', 'Y'):\n        avctx->pix_fmt = AV_PIX_FMT_YUV422P;\n        s->decode_frame = decode_byry;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_byry, 256);\n            ret |= build_vlc(&s->vlc[1], l_u_byry, 256);\n        break;\n    case MKTAG('B', 'Y', 'R', 'y'):\n        avctx->pix_fmt = AV_PIX_FMT_YUV422P;\n        s->decode_frame = decode_byryi;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_byryi, 256);\n            ret |= build_vlc(&s->vlc[1], l_u_byryi, 256);\n        break;\n    case MKTAG('Y', 'b', 'Y', 'r'):\n        avctx->pix_fmt = AV_PIX_FMT_YUV422P;\n        s->decode_frame = decode_ybyr;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_ybyr, 256);\n            ret |= build_vlc(&s->vlc[1], l_u_ybyr, 256);\n        break;\n    case MKTAG('C', '8', '2', 'p'):\n        avctx->pix_fmt = AV_PIX_FMT_YUVA422P;\n        s->decode_frame = decode_c82p;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_byry, 256);\n            ret |= build_vlc(&s->vlc[1], l_u_byry, 256);\n        break;\n    case MKTAG('C', '8', '2', 'i'):\n        avctx->pix_fmt = AV_PIX_FMT_YUVA422P;\n        s->decode_frame = decode_c82i;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_byryi, 256);\n            ret |= build_vlc(&s->vlc[1], l_u_byryi, 256);\n        break;\n    case MKTAG(0xa2, 'Y', 'R', 'Y'):\n        avctx->pix_fmt = AV_PIX_FMT_YUV422P10;\n        s->decode_frame = decode_yry10;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_yry10, 1024);\n            ret |= build_vlc(&s->vlc[1], l_u_yry10, 1024);\n        break;\n    case MKTAG(0xa2, 'Y', 'R', 'y'):\n        avctx->pix_fmt = AV_PIX_FMT_YUV422P10;\n        s->decode_frame = decode_yry10i;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_yry10i, 1024);\n            ret |= build_vlc(&s->vlc[1], l_u_yry10i, 1024);\n        break;\n    case MKTAG('C', 'A', '2', 'p'):\n        avctx->pix_fmt = AV_PIX_FMT_YUVA422P10;\n        s->decode_frame = decode_ca2p;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_yry10, 1024);\n            ret |= build_vlc(&s->vlc[1], l_u_yry10, 1024);\n        break;\n    case MKTAG('C', 'A', '2', 'i'):\n        avctx->pix_fmt = AV_PIX_FMT_YUVA422P10;\n        s->decode_frame = decode_ca2i;\n        if (s->format != format) {\n            ret  = build_vlc(&s->vlc[0], l_y_yry10i, 1024);\n            ret |= build_vlc(&s->vlc[1], l_u_yry10i, 1024);\n        break;\n    default:\n        avpriv_request_sample(avctx, \"unsupported format: 0x%X\", format);\n        return AVERROR_PATCHWELCOME;\n    if (s->format != format) {\n        if (ret < 0)\n            return ret;\n        s->format = format;\n    p->pict_type = AV_PICTURE_TYPE_I;\n    p->key_frame = 1;\n    if ((ret = ff_thread_get_buffer(avctx, &frame, 0)) < 0)\n        return ret;\n    if ((ret = init_get_bits8(&gb, avpkt->data + 20, avpkt->size - 20)) < 0)\n        return ret;\n    s->decode_frame(avctx, p, &gb);\n    *got_frame = 1;\n    return avpkt->size;", "idx": 22888}
{"project": "FFmpeg", "commit_id": "fc86f88b32a288b252a088ee3c77b4f6219d54d5", "target": 1, "func": "int ff_h264_decode_ref_pic_marking(H264Context *h, GetBitContext *gb,\n\n                                   int first_slice)\n\n{\n\n    MpegEncContext * const s = &h->s;\n\n    int i, ret;\n\n    MMCO mmco_temp[MAX_MMCO_COUNT], *mmco = first_slice ? h->mmco : mmco_temp;\n\n    int mmco_index = 0;\n\n\n\n    if (h->nal_unit_type == NAL_IDR_SLICE){ // FIXME fields\n\n        s->broken_link = get_bits1(gb) - 1;\n\n        if (get_bits1(gb)){\n\n            mmco[0].opcode = MMCO_LONG;\n\n            mmco[0].long_arg = 0;\n\n            mmco_index = 1;\n\n        }\n\n    } else {\n\n        if (get_bits1(gb)) { // adaptive_ref_pic_marking_mode_flag\n\n            for (i = 0; i < MAX_MMCO_COUNT; i++) {\n\n                MMCOOpcode opcode = get_ue_golomb_31(gb);\n\n\n\n                mmco[i].opcode = opcode;\n\n                if (opcode == MMCO_SHORT2UNUSED || opcode == MMCO_SHORT2LONG){\n\n                    mmco[i].short_pic_num =\n\n                        (h->curr_pic_num - get_ue_golomb(gb) - 1) &\n\n                            (h->max_pic_num - 1);\n\n#if 0\n\n                    if (mmco[i].short_pic_num >= h->short_ref_count ||\n\n                        h->short_ref[ mmco[i].short_pic_num ] == NULL){\n\n                        av_log(s->avctx, AV_LOG_ERROR,\n\n                               \"illegal short ref in memory management control \"\n\n                               \"operation %d\\n\", mmco);\n\n                        return -1;\n\n                    }\n\n#endif\n\n                }\n\n                if (opcode == MMCO_SHORT2LONG || opcode == MMCO_LONG2UNUSED ||\n\n                    opcode == MMCO_LONG || opcode == MMCO_SET_MAX_LONG) {\n\n                    unsigned int long_arg = get_ue_golomb_31(gb);\n\n                    if (long_arg >= 32 ||\n\n                        (long_arg >= 16 && !(opcode == MMCO_SET_MAX_LONG &&\n\n                                             long_arg == 16) &&\n\n                         !(opcode == MMCO_LONG2UNUSED && FIELD_PICTURE))){\n\n                        av_log(h->s.avctx, AV_LOG_ERROR,\n\n                               \"illegal long ref in memory management control \"\n\n                               \"operation %d\\n\", opcode);\n\n                        return -1;\n\n                    }\n\n                    mmco[i].long_arg = long_arg;\n\n                }\n\n\n\n                if (opcode > (unsigned) MMCO_LONG){\n\n                    av_log(h->s.avctx, AV_LOG_ERROR,\n\n                           \"illegal memory management control operation %d\\n\",\n\n                           opcode);\n\n                    return -1;\n\n                }\n\n                if (opcode == MMCO_END)\n\n                    break;\n\n            }\n\n            mmco_index = i;\n\n        } else {\n\n            if (first_slice) {\n\n                ret = ff_generate_sliding_window_mmcos(h, first_slice);\n\n                if (ret < 0 && s->avctx->err_recognition & AV_EF_EXPLODE)\n\n                    return ret;\n\n            }\n\n            mmco_index = -1;\n\n        }\n\n    }\n\n\n\n    if (first_slice && mmco_index != -1) {\n\n        h->mmco_index = mmco_index;\n\n    } else if (!first_slice && mmco_index >= 0 &&\n\n               (mmco_index != h->mmco_index ||\n\n                (i = check_opcodes(h->mmco, mmco_temp, mmco_index)))) {\n\n        av_log(h->s.avctx, AV_LOG_ERROR,\n\n               \"Inconsistent MMCO state between slices [%d, %d, %d]\\n\",\n\n               mmco_index, h->mmco_index, i);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22890}
{"project": "FFmpeg", "commit_id": "838f461b0716393a1b5c70efd03de1e8bc197380", "target": 1, "func": "static int add_metadata_from_side_data(AVCodecContext *avctx, AVFrame *frame)\n\n{\n\n    int size, ret = 0;\n\n    const uint8_t *side_metadata;\n\n    const uint8_t *end;\n\n\n\n    side_metadata = av_packet_get_side_data(avctx->pkt,\n\n                                            AV_PKT_DATA_STRINGS_METADATA, &size);\n\n    if (!side_metadata)\n\n        goto end;\n\n    end = side_metadata + size;\n\n    while (side_metadata < end) {\n\n        const uint8_t *key = side_metadata;\n\n        const uint8_t *val = side_metadata + strlen(key) + 1;\n\n        int ret = av_dict_set(avpriv_frame_get_metadatap(frame), key, val, 0);\n\n        if (ret < 0)\n\n            break;\n\n        side_metadata = val + strlen(val) + 1;\n\n    }\n\nend:\n\n    return ret;\n\n}\n", "idx": 22891}
{"project": "FFmpeg", "commit_id": "58ac7fb9c395ab91cb321fa4c8c9e127ce8147c3", "target": 1, "func": "static int decode_wdlt(GetByteContext *gb, uint8_t *frame, int width, int height)\n\n{\n\n    const uint8_t *frame_end   = frame + width * height;\n\n    uint8_t *line_ptr;\n\n    int count, i, v, lines, segments;\n\n    int y = 0;\n\n\n\n    lines = bytestream2_get_le16(gb);\n\n    if (lines > height)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    while (lines--) {\n\n        if (bytestream2_get_bytes_left(gb) < 2)\n\n            return AVERROR_INVALIDDATA;\n\n        segments = bytestream2_get_le16u(gb);\n\n        while ((segments & 0xC000) == 0xC000) {\n\n            unsigned skip_lines = -(int16_t)segments;\n\n            unsigned delta = -((int16_t)segments * width);\n\n            if (frame_end - frame <= delta || y + lines + skip_lines > height)\n\n                return AVERROR_INVALIDDATA;\n\n            frame    += delta;\n\n            y        += skip_lines;\n\n            segments = bytestream2_get_le16(gb);\n\n        }\n\n\n\n        if (frame_end <= frame)\n\n            return AVERROR_INVALIDDATA;\n\n        if (segments & 0x8000) {\n\n            frame[width - 1] = segments & 0xFF;\n\n            segments = bytestream2_get_le16(gb);\n\n        }\n\n        line_ptr = frame;\n\n        if (frame_end - frame < width)\n\n            return AVERROR_INVALIDDATA;\n\n        frame += width;\n\n        y++;\n\n        while (segments--) {\n\n            if (frame - line_ptr <= bytestream2_peek_byte(gb))\n\n                return AVERROR_INVALIDDATA;\n\n            line_ptr += bytestream2_get_byte(gb);\n\n            count = (int8_t)bytestream2_get_byte(gb);\n\n            if (count >= 0) {\n\n                if (frame - line_ptr < count * 2)\n\n                    return AVERROR_INVALIDDATA;\n\n                if (bytestream2_get_buffer(gb, line_ptr, count * 2) != count * 2)\n\n                    return AVERROR_INVALIDDATA;\n\n                line_ptr += count * 2;\n\n            } else {\n\n                count = -count;\n\n                if (frame - line_ptr < count * 2)\n\n                    return AVERROR_INVALIDDATA;\n\n                v = bytestream2_get_le16(gb);\n\n                for (i = 0; i < count; i++)\n\n                    bytestream_put_le16(&line_ptr, v);\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22894}
{"project": "FFmpeg", "commit_id": "9d0b45ade864f3d2ccd8610149fe1fff53c4e937", "target": 1, "func": "static int rprobe(AVFormatContext *s, uint8_t *enc_header, const uint8_t *r_val)\n\n{\n\n    OMAContext *oc = s->priv_data;\n\n    unsigned int pos;\n\n    struct AVDES av_des;\n\n\n\n    if (!enc_header || !r_val)\n\n        return -1;\n\n\n\n    /* m_val */\n\n    av_des_init(&av_des, r_val, 192, 1);\n\n    av_des_crypt(&av_des, oc->m_val, &enc_header[48], 1, NULL, 1);\n\n\n\n    /* s_val */\n\n    av_des_init(&av_des, oc->m_val, 64, 0);\n\n    av_des_crypt(&av_des, oc->s_val, NULL, 1, NULL, 0);\n\n\n\n    /* sm_val */\n\n    pos = OMA_ENC_HEADER_SIZE + oc->k_size + oc->e_size;\n\n    av_des_init(&av_des, oc->s_val, 64, 0);\n\n    av_des_mac(&av_des, oc->sm_val, &enc_header[pos], (oc->i_size >> 3));\n\n\n\n    pos += oc->i_size;\n\n\n\n    return memcmp(&enc_header[pos], oc->sm_val, 8) ? -1 : 0;\n\n}\n", "idx": 22895}
{"project": "FFmpeg", "commit_id": "b7c96769c52a312c6f6abe43f5d8c83701118a0b", "target": 0, "func": "static FFPsyWindowInfo psy_lame_window(FFPsyContext *ctx,\n\n                                       const int16_t *audio, const int16_t *la,\n\n                                       int channel, int prev_type)\n\n{\n\n    AacPsyContext *pctx = (AacPsyContext*) ctx->model_priv_data;\n\n    AacPsyChannel *pch  = &pctx->ch[channel];\n\n    int grouping     = 0;\n\n    int uselongblock = 1;\n\n    int attacks[AAC_NUM_BLOCKS_SHORT + 1] = { 0 };\n\n    int i;\n\n    FFPsyWindowInfo wi;\n\n\n\n    memset(&wi, 0, sizeof(wi));\n\n    if (la) {\n\n        float hpfsmpl[AAC_BLOCK_SIZE_LONG];\n\n        float const *pf = hpfsmpl;\n\n        float attack_intensity[(AAC_NUM_BLOCKS_SHORT + 1) * PSY_LAME_NUM_SUBBLOCKS];\n\n        float energy_subshort[(AAC_NUM_BLOCKS_SHORT + 1) * PSY_LAME_NUM_SUBBLOCKS];\n\n        float energy_short[AAC_NUM_BLOCKS_SHORT + 1] = { 0 };\n\n        int chans = ctx->avctx->channels;\n\n        const int16_t *firbuf = la + (AAC_BLOCK_SIZE_SHORT/4 - PSY_LAME_FIR_LEN) * chans;\n\n        int j, att_sum = 0;\n\n\n\n        /* LAME comment: apply high pass filter of fs/4 */\n\n        for (i = 0; i < AAC_BLOCK_SIZE_LONG; i++) {\n\n            float sum1, sum2;\n\n            sum1 = firbuf[(i + ((PSY_LAME_FIR_LEN - 1) / 2)) * chans];\n\n            sum2 = 0.0;\n\n            for (j = 0; j < ((PSY_LAME_FIR_LEN - 1) / 2) - 1; j += 2) {\n\n                sum1 += psy_fir_coeffs[j] * (firbuf[(i + j) * chans] + firbuf[(i + PSY_LAME_FIR_LEN - j) * chans]);\n\n                sum2 += psy_fir_coeffs[j + 1] * (firbuf[(i + j + 1) * chans] + firbuf[(i + PSY_LAME_FIR_LEN - j - 1) * chans]);\n\n            }\n\n            hpfsmpl[i] = sum1 + sum2;\n\n        }\n\n\n\n        /* Calculate the energies of each sub-shortblock */\n\n        for (i = 0; i < PSY_LAME_NUM_SUBBLOCKS; i++) {\n\n            energy_subshort[i] = pch->prev_energy_subshort[i + ((AAC_NUM_BLOCKS_SHORT - 1) * PSY_LAME_NUM_SUBBLOCKS)];\n\n            assert(pch->prev_energy_subshort[i + ((AAC_NUM_BLOCKS_SHORT - 2) * PSY_LAME_NUM_SUBBLOCKS + 1)] > 0);\n\n            attack_intensity[i] = energy_subshort[i] / pch->prev_energy_subshort[i + ((AAC_NUM_BLOCKS_SHORT - 2) * PSY_LAME_NUM_SUBBLOCKS + 1)];\n\n            energy_short[0] += energy_subshort[i];\n\n        }\n\n\n\n        for (i = 0; i < AAC_NUM_BLOCKS_SHORT * PSY_LAME_NUM_SUBBLOCKS; i++) {\n\n            float const *const pfe = pf + AAC_BLOCK_SIZE_LONG / (AAC_NUM_BLOCKS_SHORT * PSY_LAME_NUM_SUBBLOCKS);\n\n            float p = 1.0f;\n\n            for (; pf < pfe; pf++)\n\n                if (p < fabsf(*pf))\n\n                    p = fabsf(*pf);\n\n            pch->prev_energy_subshort[i] = energy_subshort[i + PSY_LAME_NUM_SUBBLOCKS] = p;\n\n            energy_short[1 + i / PSY_LAME_NUM_SUBBLOCKS] += p;\n\n            /* FIXME: The indexes below are [i + 3 - 2] in the LAME source.\n\n             *          Obviously the 3 and 2 have some significance, or this would be just [i + 1]\n\n             *          (which is what we use here). What the 3 stands for is ambigious, as it is both\n\n             *          number of short blocks, and the number of sub-short blocks.\n\n             *          It seems that LAME is comparing each sub-block to sub-block + 1 in the\n\n             *          previous block.\n\n             */\n\n            if (p > energy_subshort[i + 1])\n\n                p = p / energy_subshort[i + 1];\n\n            else if (energy_subshort[i + 1] > p * 10.0f)\n\n                p = energy_subshort[i + 1] / (p * 10.0f);\n\n            else\n\n                p = 0.0;\n\n            attack_intensity[i + PSY_LAME_NUM_SUBBLOCKS] = p;\n\n        }\n\n\n\n        /* compare energy between sub-short blocks */\n\n        for (i = 0; i < (AAC_NUM_BLOCKS_SHORT + 1) * PSY_LAME_NUM_SUBBLOCKS; i++)\n\n            if (!attacks[i / PSY_LAME_NUM_SUBBLOCKS])\n\n                if (attack_intensity[i] > pch->attack_threshold)\n\n                    attacks[i / PSY_LAME_NUM_SUBBLOCKS] = (i % PSY_LAME_NUM_SUBBLOCKS) + 1;\n\n\n\n        /* should have energy change between short blocks, in order to avoid periodic signals */\n\n        /* Good samples to show the effect are Trumpet test songs */\n\n        /* GB: tuned (1) to avoid too many short blocks for test sample TRUMPET */\n\n        /* RH: tuned (2) to let enough short blocks through for test sample FSOL and SNAPS */\n\n        for (i = 1; i < AAC_NUM_BLOCKS_SHORT + 1; i++) {\n\n            float const u = energy_short[i - 1];\n\n            float const v = energy_short[i];\n\n            float const m = FFMAX(u, v);\n\n            if (m < 40000) {                          /* (2) */\n\n                if (u < 1.7f * v && v < 1.7f * u) {   /* (1) */\n\n                    if (i == 1 && attacks[0] < attacks[i])\n\n                        attacks[0] = 0;\n\n                    attacks[i] = 0;\n\n                }\n\n            }\n\n            att_sum += attacks[i];\n\n        }\n\n\n\n        if (attacks[0] <= pch->prev_attack)\n\n            attacks[0] = 0;\n\n\n\n        att_sum += attacks[0];\n\n        /* 3 below indicates the previous attack happened in the last sub-block of the previous sequence */\n\n        if (pch->prev_attack == 3 || att_sum) {\n\n            uselongblock = 0;\n\n\n\n            if (attacks[1] && attacks[0])\n\n                attacks[1] = 0;\n\n            if (attacks[2] && attacks[1])\n\n                attacks[2] = 0;\n\n            if (attacks[3] && attacks[2])\n\n                attacks[3] = 0;\n\n            if (attacks[4] && attacks[3])\n\n                attacks[4] = 0;\n\n            if (attacks[5] && attacks[4])\n\n                attacks[5] = 0;\n\n            if (attacks[6] && attacks[5])\n\n                attacks[6] = 0;\n\n            if (attacks[7] && attacks[6])\n\n                attacks[7] = 0;\n\n            if (attacks[8] && attacks[7])\n\n                attacks[8] = 0;\n\n        }\n\n    } else {\n\n        /* We have no lookahead info, so just use same type as the previous sequence. */\n\n        uselongblock = !(prev_type == EIGHT_SHORT_SEQUENCE);\n\n    }\n\n\n\n    lame_apply_block_type(pch, &wi, uselongblock);\n\n\n\n    wi.window_type[1] = prev_type;\n\n    if (wi.window_type[0] != EIGHT_SHORT_SEQUENCE) {\n\n        wi.num_windows  = 1;\n\n        wi.grouping[0]  = 1;\n\n        if (wi.window_type[0] == LONG_START_SEQUENCE)\n\n            wi.window_shape = 0;\n\n        else\n\n            wi.window_shape = 1;\n\n    } else {\n\n        int lastgrp = 0;\n\n\n\n        wi.num_windows = 8;\n\n        wi.window_shape = 0;\n\n        for (i = 0; i < 8; i++) {\n\n            if (!((pch->next_grouping >> i) & 1))\n\n                lastgrp = i;\n\n            wi.grouping[lastgrp]++;\n\n        }\n\n    }\n\n\n\n    /* Determine grouping, based on the location of the first attack, and save for\n\n     * the next frame.\n\n     * FIXME: Move this to analysis.\n\n     * TODO: Tune groupings depending on attack location\n\n     * TODO: Handle more than one attack in a group\n\n     */\n\n    for (i = 0; i < 9; i++) {\n\n        if (attacks[i]) {\n\n            grouping = i;\n\n            break;\n\n        }\n\n    }\n\n    pch->next_grouping = window_grouping[grouping];\n\n\n\n    pch->prev_attack = attacks[8];\n\n\n\n    return wi;\n\n}\n", "idx": 22899}
{"project": "FFmpeg", "commit_id": "f79364b2c30aaaec9f0b1500a74da5a859c2ff37", "target": 0, "func": "static void float_to_int16_stride_altivec(int16_t *dst, const float *src,\n\n                                          long len, int stride)\n\n{\n\n    int i, j;\n\n    vector signed short d, s;\n\n\n\n    for (i = 0; i < len - 7; i += 8) {\n\n        d = float_to_int16_one_altivec(src + i);\n\n        for (j = 0; j < 8; j++) {\n\n            s = vec_splat(d, j);\n\n            vec_ste(s, 0, dst);\n\n            dst += stride;\n\n        }\n\n    }\n\n}\n", "idx": 22900}
{"project": "FFmpeg", "commit_id": "dcbe15813ed09cf491e75a21cce0e751f5bc2b34", "target": 0, "func": "static int check_opcodes(MMCO *mmco1, MMCO *mmco2, int n_mmcos)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < n_mmcos; i++) {\n\n        if (mmco1[i].opcode != mmco2[i].opcode)\n\n            return -1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22902}
{"project": "FFmpeg", "commit_id": "aeaf268e52fc11c1f64914a319e0edddf1346d6a", "target": 0, "func": "static void vp3_idct_dc_add_c(uint8_t *dest/*align 8*/, int line_size,\n\n                              const DCTELEM *block/*align 16*/){\n\n    int i, dc = (block[0] + 15) >> 5;\n\n\n\n    for(i = 0; i < 8; i++){\n\n        dest[0] = av_clip_uint8(dest[0] + dc);\n\n        dest[1] = av_clip_uint8(dest[1] + dc);\n\n        dest[2] = av_clip_uint8(dest[2] + dc);\n\n        dest[3] = av_clip_uint8(dest[3] + dc);\n\n        dest[4] = av_clip_uint8(dest[4] + dc);\n\n        dest[5] = av_clip_uint8(dest[5] + dc);\n\n        dest[6] = av_clip_uint8(dest[6] + dc);\n\n        dest[7] = av_clip_uint8(dest[7] + dc);\n\n        dest += line_size;\n\n    }\n\n}\n", "idx": 22903}
{"project": "FFmpeg", "commit_id": "ecc92ee717eac18540e236ee27e9052cd2917800", "target": 1, "func": "static av_cold int libopenjpeg_encode_close(AVCodecContext *avctx)\n\n{\n\n    LibOpenJPEGContext *ctx = avctx->priv_data;\n\n\n\n    opj_cio_close(ctx->stream);\n\n    ctx->stream = NULL;\n\n    opj_destroy_compress(ctx->compress);\n\n    ctx->compress = NULL;\n\n    opj_image_destroy(ctx->image);\n\n    ctx->image = NULL;\n\n    av_freep(&avctx->coded_frame);\n\n    return 0;\n\n}\n", "idx": 22905}
{"project": "FFmpeg", "commit_id": "224bb46fb857dab589597bdab302ba8ba012008c", "target": 1, "func": "FFAMediaFormat *ff_AMediaFormat_new(void)\n\n{\n\n    JNIEnv *env = NULL;\n\n    FFAMediaFormat *format = NULL;\n\n\n\n    format = av_mallocz(sizeof(FFAMediaFormat));\n\n    if (!format) {\n\n        return NULL;\n\n    }\n\n    format->class = &amediaformat_class;\n\n\n\n    env = ff_jni_get_env(format);\n\n    if (!env) {\n\n        av_freep(&format);\n\n        return NULL;\n\n    }\n\n\n\n    if (ff_jni_init_jfields(env, &format->jfields, jni_amediaformat_mapping, 1, format) < 0) {\n\n        goto fail;\n\n    }\n\n\n\n    format->object = (*env)->NewObject(env, format->jfields.mediaformat_class, format->jfields.init_id);\n\n    if (!format->object) {\n\n        goto fail;\n\n    }\n\n\n\n    format->object = (*env)->NewGlobalRef(env, format->object);\n\n    if (!format->object) {\n\n        goto fail;\n\n    }\n\n\n\n    return format;\n\nfail:\n\n    ff_jni_reset_jfields(env, &format->jfields, jni_amediaformat_mapping, 1, format);\n\n\n\n    av_freep(&format);\n\n\n\n    return NULL;\n\n}\n", "idx": 22907}
{"project": "FFmpeg", "commit_id": "9b26bf7e2a3904d0e4b80f8d771223d3045013db", "target": 1, "func": "static int deband_8_coupling_c(AVFilterContext *ctx, void *arg, int jobnr, int nb_jobs)\n\n{\n\n    DebandContext *s = ctx->priv;\n\n    ThreadData *td = arg;\n\n    AVFrame *in = td->in;\n\n    AVFrame *out = td->out;\n\n    const int start = (s->planeheight[0] *  jobnr   ) / nb_jobs;\n\n    const int end   = (s->planeheight[0] * (jobnr+1)) / nb_jobs;\n\n    int x, y, p;\n\n\n\n    for (y = start; y < end; y++) {\n\n        const int pos = y * s->planewidth[0];\n\n\n\n        for (x = 0; x < s->planewidth[p]; x++) {\n\n            const int x_pos = s->x_pos[pos + x];\n\n            const int y_pos = s->y_pos[pos + x];\n\n            int avg[4], cmp[4] = { 0 }, src[4];\n\n\n\n            for (p = 0; p < s->nb_components; p++) {\n\n                const uint8_t *src_ptr = (const uint8_t *)in->data[p];\n\n                const int src_linesize = in->linesize[p];\n\n                const int thr = s->thr[p];\n\n                const int w = s->planewidth[p] - 1;\n\n                const int h = s->planeheight[p] - 1;\n\n                const int ref0 = src_ptr[av_clip(y +  y_pos, 0, h) * src_linesize + av_clip(x +  x_pos, 0, w)];\n\n                const int ref1 = src_ptr[av_clip(y + -y_pos, 0, h) * src_linesize + av_clip(x +  x_pos, 0, w)];\n\n                const int ref2 = src_ptr[av_clip(y + -y_pos, 0, h) * src_linesize + av_clip(x + -x_pos, 0, w)];\n\n                const int ref3 = src_ptr[av_clip(y +  y_pos, 0, h) * src_linesize + av_clip(x + -x_pos, 0, w)];\n\n                const int src0 = src_ptr[y * src_linesize + x];\n\n\n\n                src[p] = src0;\n\n                avg[p] = get_avg(ref0, ref1, ref2, ref3);\n\n\n\n                if (s->blur) {\n\n                    cmp[p] = FFABS(src0 - avg[p]) < thr;\n\n                } else {\n\n                    cmp[p] = (FFABS(src0 - ref0) < thr) &&\n\n                             (FFABS(src0 - ref1) < thr) &&\n\n                             (FFABS(src0 - ref2) < thr) &&\n\n                             (FFABS(src0 - ref3) < thr);\n\n                }\n\n            }\n\n\n\n            for (p = 0; p < s->nb_components; p++)\n\n                if (!cmp[p])\n\n                    break;\n\n            if (p == s->nb_components) {\n\n                for (p = 0; p < s->nb_components; p++) {\n\n                    const int dst_linesize = out->linesize[p];\n\n\n\n                    out->data[p][y * dst_linesize + x] = avg[p];\n\n                }\n\n            } else {\n\n                for (p = 0; p < s->nb_components; p++) {\n\n                    const int dst_linesize = out->linesize[p];\n\n\n\n                    out->data[p][y * dst_linesize + x] = src[p];\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22908}
{"project": "FFmpeg", "commit_id": "941b2240f2ce59c41f4a9ffec88c512f64c75613", "target": 1, "func": "int ff_MPV_frame_start(MpegEncContext *s, AVCodecContext *avctx)\n\n{\n\n    int i, ret;\n\n    Picture *pic;\n\n    s->mb_skipped = 0;\n\n\n\n    if (!ff_thread_can_start_frame(avctx)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Attempt to start a frame outside SETUP state\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* mark & release old frames */\n\n    if (s->pict_type != AV_PICTURE_TYPE_B && s->last_picture_ptr &&\n\n        s->last_picture_ptr != s->next_picture_ptr &&\n\n        s->last_picture_ptr->f->buf[0]) {\n\n        ff_mpeg_unref_picture(s, s->last_picture_ptr);\n\n    }\n\n\n\n    /* release forgotten pictures */\n\n    /* if (mpeg124/h263) */\n\n    for (i = 0; i < MAX_PICTURE_COUNT; i++) {\n\n        if (&s->picture[i] != s->last_picture_ptr &&\n\n            &s->picture[i] != s->next_picture_ptr &&\n\n            s->picture[i].reference && !s->picture[i].needs_realloc) {\n\n            if (!(avctx->active_thread_type & FF_THREAD_FRAME))\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"releasing zombie picture\\n\");\n\n            ff_mpeg_unref_picture(s, &s->picture[i]);\n\n        }\n\n    }\n\n\n\n    ff_mpeg_unref_picture(s, &s->current_picture);\n\n\n\n    release_unused_pictures(s);\n\n\n\n    if (s->current_picture_ptr &&\n\n        s->current_picture_ptr->f->buf[0] == NULL) {\n\n        // we already have a unused image\n\n        // (maybe it was set before reading the header)\n\n        pic = s->current_picture_ptr;\n\n    } else {\n\n        i   = ff_find_unused_picture(s, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        pic = &s->picture[i];\n\n    }\n\n\n\n    pic->reference = 0;\n\n    if (!s->droppable) {\n\n        if (s->pict_type != AV_PICTURE_TYPE_B)\n\n            pic->reference = 3;\n\n    }\n\n\n\n    pic->f->coded_picture_number = s->coded_picture_number++;\n\n\n\n    if (ff_alloc_picture(s, pic, 0) < 0)\n\n        return -1;\n\n\n\n    s->current_picture_ptr = pic;\n\n    // FIXME use only the vars from current_pic\n\n    s->current_picture_ptr->f->top_field_first = s->top_field_first;\n\n    if (s->codec_id == AV_CODEC_ID_MPEG1VIDEO ||\n\n        s->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n        if (s->picture_structure != PICT_FRAME)\n\n            s->current_picture_ptr->f->top_field_first =\n\n                (s->picture_structure == PICT_TOP_FIELD) == s->first_field;\n\n    }\n\n    s->current_picture_ptr->f->interlaced_frame = !s->progressive_frame &&\n\n                                                 !s->progressive_sequence;\n\n    s->current_picture_ptr->field_picture      =  s->picture_structure != PICT_FRAME;\n\n\n\n    s->current_picture_ptr->f->pict_type = s->pict_type;\n\n    // if (s->flags && CODEC_FLAG_QSCALE)\n\n    //     s->current_picture_ptr->quality = s->new_picture_ptr->quality;\n\n    s->current_picture_ptr->f->key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n\n\n    if ((ret = ff_mpeg_ref_picture(s, &s->current_picture,\n\n                                   s->current_picture_ptr)) < 0)\n\n        return ret;\n\n\n\n    if (s->pict_type != AV_PICTURE_TYPE_B) {\n\n        s->last_picture_ptr = s->next_picture_ptr;\n\n        if (!s->droppable)\n\n            s->next_picture_ptr = s->current_picture_ptr;\n\n    }\n\n    av_dlog(s->avctx, \"L%p N%p C%p L%p N%p C%p type:%d drop:%d\\n\",\n\n            s->last_picture_ptr, s->next_picture_ptr,s->current_picture_ptr,\n\n            s->last_picture_ptr    ? s->last_picture_ptr->f->data[0]    : NULL,\n\n            s->next_picture_ptr    ? s->next_picture_ptr->f->data[0]    : NULL,\n\n            s->current_picture_ptr ? s->current_picture_ptr->f->data[0] : NULL,\n\n            s->pict_type, s->droppable);\n\n\n\n    if ((s->last_picture_ptr == NULL ||\n\n         s->last_picture_ptr->f->buf[0] == NULL) &&\n\n        (s->pict_type != AV_PICTURE_TYPE_I ||\n\n         s->picture_structure != PICT_FRAME)) {\n\n        int h_chroma_shift, v_chroma_shift;\n\n        av_pix_fmt_get_chroma_sub_sample(s->avctx->pix_fmt,\n\n                                         &h_chroma_shift, &v_chroma_shift);\n\n        if (s->pict_type == AV_PICTURE_TYPE_B && s->next_picture_ptr && s->next_picture_ptr->f->buf[0])\n\n            av_log(avctx, AV_LOG_DEBUG,\n\n                   \"allocating dummy last picture for B frame\\n\");\n\n        else if (s->pict_type != AV_PICTURE_TYPE_I)\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"warning: first frame is no keyframe\\n\");\n\n        else if (s->picture_structure != PICT_FRAME)\n\n            av_log(avctx, AV_LOG_DEBUG,\n\n                   \"allocate dummy last picture for field based first keyframe\\n\");\n\n\n\n        /* Allocate a dummy frame */\n\n        i = ff_find_unused_picture(s, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        s->last_picture_ptr = &s->picture[i];\n\n\n\n        s->last_picture_ptr->reference   = 3;\n\n        s->last_picture_ptr->f->key_frame = 0;\n\n        s->last_picture_ptr->f->pict_type = AV_PICTURE_TYPE_P;\n\n\n\n        if (ff_alloc_picture(s, s->last_picture_ptr, 0) < 0) {\n\n            s->last_picture_ptr = NULL;\n\n            return -1;\n\n        }\n\n\n\n        if (!avctx->hwaccel) {\n\n            for(i=0; i<avctx->height; i++)\n\n                memset(s->last_picture_ptr->f->data[0] + s->last_picture_ptr->f->linesize[0]*i,\n\n                       0x80, avctx->width);\n\n            for(i=0; i<FF_CEIL_RSHIFT(avctx->height, v_chroma_shift); i++) {\n\n                memset(s->last_picture_ptr->f->data[1] + s->last_picture_ptr->f->linesize[1]*i,\n\n                       0x80, FF_CEIL_RSHIFT(avctx->width, h_chroma_shift));\n\n                memset(s->last_picture_ptr->f->data[2] + s->last_picture_ptr->f->linesize[2]*i,\n\n                       0x80, FF_CEIL_RSHIFT(avctx->width, h_chroma_shift));\n\n            }\n\n\n\n            if(s->codec_id == AV_CODEC_ID_FLV1 || s->codec_id == AV_CODEC_ID_H263){\n\n                for(i=0; i<avctx->height; i++)\n\n                memset(s->last_picture_ptr->f->data[0] + s->last_picture_ptr->f->linesize[0]*i, 16, avctx->width);\n\n            }\n\n        }\n\n\n\n        ff_thread_report_progress(&s->last_picture_ptr->tf, INT_MAX, 0);\n\n        ff_thread_report_progress(&s->last_picture_ptr->tf, INT_MAX, 1);\n\n    }\n\n    if ((s->next_picture_ptr == NULL ||\n\n         s->next_picture_ptr->f->buf[0] == NULL) &&\n\n        s->pict_type == AV_PICTURE_TYPE_B) {\n\n        /* Allocate a dummy frame */\n\n        i = ff_find_unused_picture(s, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        s->next_picture_ptr = &s->picture[i];\n\n\n\n        s->next_picture_ptr->reference   = 3;\n\n        s->next_picture_ptr->f->key_frame = 0;\n\n        s->next_picture_ptr->f->pict_type = AV_PICTURE_TYPE_P;\n\n\n\n        if (ff_alloc_picture(s, s->next_picture_ptr, 0) < 0) {\n\n            s->next_picture_ptr = NULL;\n\n            return -1;\n\n        }\n\n        ff_thread_report_progress(&s->next_picture_ptr->tf, INT_MAX, 0);\n\n        ff_thread_report_progress(&s->next_picture_ptr->tf, INT_MAX, 1);\n\n    }\n\n\n\n#if 0 // BUFREF-FIXME\n\n    memset(s->last_picture.f->data, 0, sizeof(s->last_picture.f->data));\n\n    memset(s->next_picture.f->data, 0, sizeof(s->next_picture.f->data));\n\n#endif\n\n    if (s->last_picture_ptr) {\n\n        ff_mpeg_unref_picture(s, &s->last_picture);\n\n        if (s->last_picture_ptr->f->buf[0] &&\n\n            (ret = ff_mpeg_ref_picture(s, &s->last_picture,\n\n                                       s->last_picture_ptr)) < 0)\n\n            return ret;\n\n    }\n\n    if (s->next_picture_ptr) {\n\n        ff_mpeg_unref_picture(s, &s->next_picture);\n\n        if (s->next_picture_ptr->f->buf[0] &&\n\n            (ret = ff_mpeg_ref_picture(s, &s->next_picture,\n\n                                       s->next_picture_ptr)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    av_assert0(s->pict_type == AV_PICTURE_TYPE_I || (s->last_picture_ptr &&\n\n                                                 s->last_picture_ptr->f->buf[0]));\n\n\n\n    if (s->picture_structure!= PICT_FRAME) {\n\n        int i;\n\n        for (i = 0; i < 4; i++) {\n\n            if (s->picture_structure == PICT_BOTTOM_FIELD) {\n\n                s->current_picture.f->data[i] +=\n\n                    s->current_picture.f->linesize[i];\n\n            }\n\n            s->current_picture.f->linesize[i] *= 2;\n\n            s->last_picture.f->linesize[i]    *= 2;\n\n            s->next_picture.f->linesize[i]    *= 2;\n\n        }\n\n    }\n\n\n\n    s->err_recognition = avctx->err_recognition;\n\n\n\n    /* set dequantizer, we can't do it during init as\n\n     * it might change for mpeg4 and we can't do it in the header\n\n     * decode as init is not called for mpeg4 there yet */\n\n    if (s->mpeg_quant || s->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n        s->dct_unquantize_intra = s->dct_unquantize_mpeg2_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_mpeg2_inter;\n\n    } else if (s->out_format == FMT_H263 || s->out_format == FMT_H261) {\n\n        s->dct_unquantize_intra = s->dct_unquantize_h263_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_h263_inter;\n\n    } else {\n\n        s->dct_unquantize_intra = s->dct_unquantize_mpeg1_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_mpeg1_inter;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22911}
{"project": "FFmpeg", "commit_id": "bd70a527129a1c049a8ab38236bf87f7d459df10", "target": 1, "func": "static int decode_0(AVCodecContext *avctx, uint8_t code, uint8_t *pkt)\n\n{\n\n    PAFVideoDecContext *c = avctx->priv_data;\n\n    uint32_t opcode_size, offset;\n\n    uint8_t *dst, *dend, mask = 0, color = 0, a, b, p;\n\n    const uint8_t *src, *send, *opcodes;\n\n    int  i, j, x = 0;\n\n\n\n    i = bytestream2_get_byte(&c->gb);\n\n    if (i) {\n\n        if (code & 0x10) {\n\n            int align;\n\n\n\n            align = bytestream2_tell(&c->gb) & 3;\n\n            if (align)\n\n                bytestream2_skip(&c->gb, 4 - align);\n\n        }\n\n        do {\n\n            a      = bytestream2_get_byte(&c->gb);\n\n            b      = bytestream2_get_byte(&c->gb);\n\n            p      = (a & 0xC0) >> 6;\n\n            dst    = c->frame[p] + get_video_page_offset(avctx, a, b);\n\n            dend   = c->frame[p] + c->frame_size;\n\n            offset = (b & 0x7F) * 2;\n\n            j      = bytestream2_get_le16(&c->gb) + offset;\n\n\n\n            do {\n\n                offset++;\n\n                if (dst + 3 * avctx->width + 4 > dend)\n\n                    return AVERROR_INVALIDDATA;\n\n                copy4h(avctx, dst);\n\n                if ((offset & 0x3F) == 0)\n\n                    dst += avctx->width * 3;\n\n                dst += 4;\n\n            } while (offset < j);\n\n        } while (--i);\n\n    }\n\n\n\n    dst = c->frame[c->current_frame];\n\n    do {\n\n        a    = bytestream2_get_byte(&c->gb);\n\n        b    = bytestream2_get_byte(&c->gb);\n\n        p    = (a & 0xC0) >> 6;\n\n        src  = c->frame[p] + get_video_page_offset(avctx, a, b);\n\n        send = c->frame[p] + c->frame_size;\n\n        if (src + 3 * avctx->width + 4 > send)\n\n            return AVERROR_INVALIDDATA;\n\n        copy_block4(dst, src, avctx->width, avctx->width, 4);\n\n        i++;\n\n        if ((i & 0x3F) == 0)\n\n            dst += avctx->width * 3;\n\n        dst += 4;\n\n    } while (i < c->video_size / 16);\n\n\n\n    opcode_size = bytestream2_get_le16(&c->gb);\n\n    bytestream2_skip(&c->gb, 2);\n\n\n\n    if (bytestream2_get_bytes_left(&c->gb) < opcode_size)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    opcodes = pkt + bytestream2_tell(&c->gb);\n\n    bytestream2_skipu(&c->gb, opcode_size);\n\n\n\n    dst = c->frame[c->current_frame];\n\n\n\n    for (i = 0; i < avctx->height; i += 4, dst += avctx->width * 3) {\n\n        for (j = 0; j < avctx->width; j += 4, dst += 4) {\n\n            int opcode, k = 0;\n\n\n\n            if (x > opcode_size)\n\n                return AVERROR_INVALIDDATA;\n\n            if (j & 4) {\n\n                opcode = opcodes[x] & 15;\n\n                x++;\n\n            } else {\n\n                opcode = opcodes[x] >> 4;\n\n            }\n\n\n\n            while (block_sequences[opcode][k]) {\n\n\n\n                offset = avctx->width * 2;\n\n                code   = block_sequences[opcode][k++];\n\n\n\n                switch (code) {\n\n                case 2:\n\n                    offset = 0;\n\n                case 3:\n\n                    color  = bytestream2_get_byte(&c->gb);\n\n                case 4:\n\n                    mask   = bytestream2_get_byte(&c->gb);\n\n                    copy_color_mask(avctx, mask, dst + offset, color);\n\n                    break;\n\n                case 5:\n\n                    offset = 0;\n\n                case 6:\n\n                    a    = bytestream2_get_byte(&c->gb);\n\n                    b    = bytestream2_get_byte(&c->gb);\n\n                    p    = (a & 0xC0) >> 6;\n\n                    src  = c->frame[p] + get_video_page_offset(avctx, a, b);\n\n                    send = c->frame[p] + c->frame_size;\n\n                case 7:\n\n                    if (src + offset + avctx->width + 4 > send)\n\n                        return AVERROR_INVALIDDATA;\n\n                    mask = bytestream2_get_byte(&c->gb);\n\n                    copy_src_mask(avctx, mask, dst + offset, src + offset);\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22914}
{"project": "FFmpeg", "commit_id": "4cc3467e7abfea7e8d03b6af511f7719038a5a98", "target": 1, "func": "static int64_t ogg_read_timestamp(AVFormatContext *s, int stream_index,\n\n                                  int64_t *pos_arg, int64_t pos_limit)\n\n{\n\n    struct ogg *ogg = s->priv_data;\n\n    struct ogg_stream *os = ogg->streams + stream_index;\n\n    AVIOContext *bc = s->pb;\n\n    int64_t pts = AV_NOPTS_VALUE;\n\n    int i;\n\n    avio_seek(bc, *pos_arg, SEEK_SET);\n\n    ogg_reset(ogg);\n\n\n\n    while (avio_tell(bc) < pos_limit && !ogg_packet(s, &i, NULL, NULL, pos_arg)) {\n\n        if (i == stream_index) {\n\n            pts = ogg_calc_pts(s, i, NULL);\n\n            if (os->keyframe_seek && !(os->pflags & AV_PKT_FLAG_KEY))\n\n                pts = AV_NOPTS_VALUE;\n\n        }\n\n        if (pts != AV_NOPTS_VALUE)\n\n            break;\n\n    }\n\n    ogg_reset(ogg);\n\n    return pts;\n\n}\n", "idx": 22915}
{"project": "FFmpeg", "commit_id": "6726328f7940a76c43b4d97ac37ababf363d042f", "target": 1, "func": "static int scaling_list_data(GetBitContext *gb, AVCodecContext *avctx, ScalingList *sl, HEVCSPS *sps)\n\n{\n\n    uint8_t scaling_list_pred_mode_flag;\n\n    int32_t scaling_list_dc_coef[2][6];\n\n    int size_id, matrix_id, pos;\n\n    int i;\n\n\n\n    for (size_id = 0; size_id < 4; size_id++)\n\n        for (matrix_id = 0; matrix_id < 6; matrix_id += ((size_id == 3) ? 3 : 1)) {\n\n            scaling_list_pred_mode_flag = get_bits1(gb);\n\n            if (!scaling_list_pred_mode_flag) {\n\n                unsigned int delta = get_ue_golomb_long(gb);\n\n                /* Only need to handle non-zero delta. Zero means default,\n\n                 * which should already be in the arrays. */\n\n                if (delta) {\n\n                    // Copy from previous array.\n\n                    if (matrix_id < delta) {\n\n                        av_log(avctx, AV_LOG_ERROR,\n\n                               \"Invalid delta in scaling list data: %d.\\n\", delta);\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n\n\n                    memcpy(sl->sl[size_id][matrix_id],\n\n                           sl->sl[size_id][matrix_id - delta],\n\n                           size_id > 0 ? 64 : 16);\n\n                    if (size_id > 1)\n\n                        sl->sl_dc[size_id - 2][matrix_id] = sl->sl_dc[size_id - 2][matrix_id - delta];\n\n                }\n\n            } else {\n\n                int next_coef, coef_num;\n\n                int32_t scaling_list_delta_coef;\n\n\n\n                next_coef = 8;\n\n                coef_num  = FFMIN(64, 1 << (4 + (size_id << 1)));\n\n                if (size_id > 1) {\n\n                    scaling_list_dc_coef[size_id - 2][matrix_id] = get_se_golomb(gb) + 8;\n\n                    next_coef = scaling_list_dc_coef[size_id - 2][matrix_id];\n\n                    sl->sl_dc[size_id - 2][matrix_id] = next_coef;\n\n                }\n\n                for (i = 0; i < coef_num; i++) {\n\n                    if (size_id == 0)\n\n                        pos = 4 * ff_hevc_diag_scan4x4_y[i] +\n\n                                  ff_hevc_diag_scan4x4_x[i];\n\n                    else\n\n                        pos = 8 * ff_hevc_diag_scan8x8_y[i] +\n\n                                  ff_hevc_diag_scan8x8_x[i];\n\n\n\n                    scaling_list_delta_coef = get_se_golomb(gb);\n\n                    next_coef = (next_coef + scaling_list_delta_coef + 256) % 256;\n\n                    sl->sl[size_id][matrix_id][pos] = next_coef;\n\n                }\n\n            }\n\n        }\n\n\n\n    if (sps->chroma_format_idc == 3) {\n\n        for (i = 0; i < 64; i++) {\n\n            sl->sl[3][1][i] = sl->sl[2][1][i];\n\n            sl->sl[3][2][i] = sl->sl[2][2][i];\n\n            sl->sl[3][4][i] = sl->sl[2][4][i];\n\n            sl->sl[3][5][i] = sl->sl[2][5][i];\n\n        }\n\n        sl->sl_dc[1][1] = sl->sl_dc[0][1];\n\n        sl->sl_dc[1][2] = sl->sl_dc[0][2];\n\n        sl->sl_dc[1][4] = sl->sl_dc[0][4];\n\n        sl->sl_dc[1][5] = sl->sl_dc[0][5];\n\n    }\n\n\n\n\n\n    return 0;\n\n}\n", "idx": 22916}
{"project": "FFmpeg", "commit_id": "0884d04dc329087e287cab345330303f8972f270", "target": 1, "func": "static int recode_subtitle(AVCodecContext *avctx,\n\n                           AVPacket *outpkt, const AVPacket *inpkt)\n\n{\n\n#if CONFIG_ICONV\n\n    iconv_t cd = (iconv_t)-1;\n\n    int ret = 0;\n\n    char *inb, *outb;\n\n    size_t inl, outl;\n\n    AVPacket tmp;\n\n#endif\n\n\n\n    if (avctx->sub_charenc_mode != FF_SUB_CHARENC_MODE_PRE_DECODER)\n\n        return 0;\n\n\n\n#if CONFIG_ICONV\n\n    cd = iconv_open(\"UTF-8\", avctx->sub_charenc);\n\n    av_assert0(cd != (iconv_t)-1);\n\n\n\n    inb = inpkt->data;\n\n    inl = inpkt->size;\n\n\n\n    if (inl >= INT_MAX / UTF8_MAX_BYTES - FF_INPUT_BUFFER_PADDING_SIZE) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Subtitles packet is too big for recoding\\n\");\n\n        ret = AVERROR(ENOMEM);\n\n        goto end;\n\n    }\n\n\n\n    ret = av_new_packet(&tmp, inl * UTF8_MAX_BYTES);\n\n    if (ret < 0)\n\n        goto end;\n\n    outpkt->buf  = tmp.buf;\n\n    outpkt->data = tmp.data;\n\n    outpkt->size = tmp.size;\n\n    outb = outpkt->data;\n\n    outl = outpkt->size;\n\n\n\n    if (iconv(cd, &inb, &inl, &outb, &outl) == (size_t)-1 ||\n\n        iconv(cd, NULL, NULL, &outb, &outl) == (size_t)-1 ||\n\n        outl >= outpkt->size || inl != 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unable to recode subtitle event \\\"%s\\\" \"\n\n               \"from %s to UTF-8\\n\", inpkt->data, avctx->sub_charenc);\n\n        av_free_packet(&tmp);\n\n        ret = AVERROR(errno);\n\n        goto end;\n\n    }\n\n    outpkt->size -= outl;\n\n    outpkt->data[outpkt->size - 1] = '\\0';\n\n\n\nend:\n\n    if (cd != (iconv_t)-1)\n\n        iconv_close(cd);\n\n    return ret;\n\n#else\n\n    av_assert0(!\"requesting subtitles recoding without iconv\");\n\n#endif\n\n}\n", "idx": 22917}
{"project": "FFmpeg", "commit_id": "eea2f032ad45777c008837fc6469f9f0a06e8d56", "target": 0, "func": "static int ffm_read_data(AVFormatContext *s,\n\n                         uint8_t *buf, int size, int first)\n\n{\n\n    FFMContext *ffm = s->priv_data;\n\n    ByteIOContext *pb = s->pb;\n\n    int len, fill_size, size1, frame_offset;\n\n\n\n    size1 = size;\n\n    while (size > 0) {\n\n    redo:\n\n        len = ffm->packet_end - ffm->packet_ptr;\n\n        if (len < 0)\n\n            return -1;\n\n        if (len > size)\n\n            len = size;\n\n        if (len == 0) {\n\n            if (url_ftell(pb) == ffm->file_size)\n\n                url_fseek(pb, ffm->packet_size, SEEK_SET);\n\n    retry_read:\n\n            get_be16(pb); /* PACKET_ID */\n\n            fill_size = get_be16(pb);\n\n            ffm->pts = get_be64(pb);\n\n            ffm->first_frame_in_packet = 1;\n\n            frame_offset = get_be16(pb);\n\n            get_buffer(pb, ffm->packet, ffm->packet_size - FFM_HEADER_SIZE);\n\n            ffm->packet_end = ffm->packet + (ffm->packet_size - FFM_HEADER_SIZE - fill_size);\n\n            if (ffm->packet_end < ffm->packet)\n\n                return -1;\n\n            /* if first packet or resynchronization packet, we must\n\n               handle it specifically */\n\n            if (ffm->first_packet || (frame_offset & 0x8000)) {\n\n                if (!frame_offset) {\n\n                    /* This packet has no frame headers in it */\n\n                    if (url_ftell(pb) >= ffm->packet_size * 3) {\n\n                        url_fseek(pb, -ffm->packet_size * 2, SEEK_CUR);\n\n                        goto retry_read;\n\n                    }\n\n                    /* This is bad, we cannot find a valid frame header */\n\n                    return 0;\n\n                }\n\n                ffm->first_packet = 0;\n\n                if ((frame_offset & 0x7ffff) < FFM_HEADER_SIZE)\n\n                    return -1;\n\n                ffm->packet_ptr = ffm->packet + (frame_offset & 0x7fff) - FFM_HEADER_SIZE;\n\n                if (!first)\n\n                    break;\n\n            } else {\n\n                ffm->packet_ptr = ffm->packet;\n\n            }\n\n            goto redo;\n\n        }\n\n        memcpy(buf, ffm->packet_ptr, len);\n\n        buf += len;\n\n        ffm->packet_ptr += len;\n\n        size -= len;\n\n        first = 0;\n\n    }\n\n    return size1 - size;\n\n}\n", "idx": 22920}
{"project": "FFmpeg", "commit_id": "8dca0877e3e1457e9ec79ffa1ead1135aabb791c", "target": 0, "func": "static int mpegts_write_section1(MpegTSSection *s, int tid, int id,\n\n                                 int version, int sec_num, int last_sec_num,\n\n                                 uint8_t *buf, int len)\n\n{\n\n    uint8_t section[1024], *q;\n\n    unsigned int tot_len;\n\n    /* reserved_future_use field must be set to 1 for SDT */\n\n    unsigned int flags = tid == SDT_TID ? 0xf000 : 0xb000;\n\n\n\n    tot_len = 3 + 5 + len + 4;\n\n    /* check if not too big */\n\n    if (tot_len > 1024)\n\n        return -1;\n\n\n\n    q    = section;\n\n    *q++ = tid;\n\n    put16(&q, flags | (len + 5 + 4)); /* 5 byte header + 4 byte CRC */\n\n    put16(&q, id);\n\n    *q++ = 0xc1 | (version << 1); /* current_next_indicator = 1 */\n\n    *q++ = sec_num;\n\n    *q++ = last_sec_num;\n\n    memcpy(q, buf, len);\n\n\n\n    mpegts_write_section(s, section, tot_len);\n\n    return 0;\n\n}\n", "idx": 22921}
{"project": "FFmpeg", "commit_id": "e53c9065ca08a9153ecc73a6a8940bcc6d667e58", "target": 0, "func": "static int compare_doubles(const double *a, const double *b, int len,\n\n                           double max_diff)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < len; i++) {\n\n        if (fabs(a[i] - b[i]) > max_diff) {\n\n            av_log(NULL, AV_LOG_ERROR, \"%d: %- .12f - %- .12f = % .12g\\n\",\n\n                   i, a[i], b[i], a[i] - b[i]);\n\n            return -1;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 22922}
{"project": "FFmpeg", "commit_id": "59afda9f61c8d3b23699e72939858ce25b4ed2a8", "target": 0, "func": "static int fourxm_read_header(AVFormatContext *s,\n\n                              AVFormatParameters *ap)\n\n{\n\n    ByteIOContext *pb = s->pb;\n\n    unsigned int fourcc_tag;\n\n    unsigned int size;\n\n    int header_size;\n\n    FourxmDemuxContext *fourxm = s->priv_data;\n\n    unsigned char *header;\n\n    int i;\n\n    int current_track = -1;\n\n    AVStream *st;\n\n\n\n    fourxm->track_count = 0;\n\n    fourxm->tracks = NULL;\n\n    fourxm->selected_track = 0;\n\n    fourxm->fps = 1.0;\n\n\n\n    /* skip the first 3 32-bit numbers */\n\n    url_fseek(pb, 12, SEEK_CUR);\n\n\n\n    /* check for LIST-HEAD */\n\n    GET_LIST_HEADER();\n\n    header_size = size - 4;\n\n    if (fourcc_tag != HEAD_TAG || size < 4)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    /* allocate space for the header and load the whole thing */\n\n    header = av_malloc(header_size);\n\n    if (!header)\n\n        return AVERROR(ENOMEM);\n\n    if (get_buffer(pb, header, header_size) != header_size)\n\n        return AVERROR(EIO);\n\n\n\n    /* take the lazy approach and search for any and all vtrk and strk chunks */\n\n    for (i = 0; i < header_size - 8; i++) {\n\n        fourcc_tag = AV_RL32(&header[i]);\n\n        size = AV_RL32(&header[i + 4]);\n\n\n\n        if (fourcc_tag == std__TAG) {\n\n            fourxm->fps = av_int2flt(AV_RL32(&header[i + 12]));\n\n        } else if (fourcc_tag == vtrk_TAG) {\n\n            /* check that there is enough data */\n\n            if (size != vtrk_SIZE) {\n\n                av_free(header);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            fourxm->width = AV_RL32(&header[i + 36]);\n\n            fourxm->height = AV_RL32(&header[i + 40]);\n\n\n\n            /* allocate a new AVStream */\n\n            st = av_new_stream(s, 0);\n\n            if (!st)\n\n                return AVERROR(ENOMEM);\n\n            av_set_pts_info(st, 60, 1, fourxm->fps);\n\n\n\n            fourxm->video_stream_index = st->index;\n\n\n\n            st->codec->codec_type = CODEC_TYPE_VIDEO;\n\n            st->codec->codec_id = CODEC_ID_4XM;\n\n            st->codec->extradata_size = 4;\n\n            st->codec->extradata = av_malloc(4);\n\n            AV_WL32(st->codec->extradata, AV_RL32(&header[i + 16]));\n\n            st->codec->width = fourxm->width;\n\n            st->codec->height = fourxm->height;\n\n\n\n            i += 8 + size;\n\n        } else if (fourcc_tag == strk_TAG) {\n\n            /* check that there is enough data */\n\n            if (size != strk_SIZE) {\n\n                av_free(header);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            current_track = AV_RL32(&header[i + 8]);\n\n            if (current_track + 1 > fourxm->track_count) {\n\n                fourxm->track_count = current_track + 1;\n\n                if((unsigned)fourxm->track_count >= UINT_MAX / sizeof(AudioTrack))\n\n                    return -1;\n\n                fourxm->tracks = av_realloc(fourxm->tracks,\n\n                    fourxm->track_count * sizeof(AudioTrack));\n\n                if (!fourxm->tracks) {\n\n                    av_free(header);\n\n                    return AVERROR(ENOMEM);\n\n                }\n\n            }\n\n            fourxm->tracks[current_track].adpcm = AV_RL32(&header[i + 12]);\n\n            fourxm->tracks[current_track].channels = AV_RL32(&header[i + 36]);\n\n            fourxm->tracks[current_track].sample_rate = AV_RL32(&header[i + 40]);\n\n            fourxm->tracks[current_track].bits = AV_RL32(&header[i + 44]);\n\n            i += 8 + size;\n\n\n\n            /* allocate a new AVStream */\n\n            st = av_new_stream(s, current_track);\n\n            if (!st)\n\n                return AVERROR(ENOMEM);\n\n\n\n            av_set_pts_info(st, 60, 1, fourxm->tracks[current_track].sample_rate);\n\n\n\n            fourxm->tracks[current_track].stream_index = st->index;\n\n\n\n            st->codec->codec_type = CODEC_TYPE_AUDIO;\n\n            st->codec->codec_tag = 0;\n\n            st->codec->channels = fourxm->tracks[current_track].channels;\n\n            st->codec->sample_rate = fourxm->tracks[current_track].sample_rate;\n\n            st->codec->bits_per_coded_sample = fourxm->tracks[current_track].bits;\n\n            st->codec->bit_rate = st->codec->channels * st->codec->sample_rate *\n\n                st->codec->bits_per_coded_sample;\n\n            st->codec->block_align = st->codec->channels * st->codec->bits_per_coded_sample;\n\n            if (fourxm->tracks[current_track].adpcm)\n\n                st->codec->codec_id = CODEC_ID_ADPCM_4XM;\n\n            else if (st->codec->bits_per_coded_sample == 8)\n\n                st->codec->codec_id = CODEC_ID_PCM_U8;\n\n            else\n\n                st->codec->codec_id = CODEC_ID_PCM_S16LE;\n\n        }\n\n    }\n\n\n\n    av_free(header);\n\n\n\n    /* skip over the LIST-MOVI chunk (which is where the stream should be */\n\n    GET_LIST_HEADER();\n\n    if (fourcc_tag != MOVI_TAG)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    /* initialize context members */\n\n    fourxm->video_pts = -1;  /* first frame will push to 0 */\n\n    fourxm->audio_pts = 0;\n\n\n\n    return 0;\n\n}\n", "idx": 22923}
{"project": "FFmpeg", "commit_id": "24dc7776ff4452764d0365b12d0728153f879cf8", "target": 0, "func": "static int flush_packet(AVFormatContext *ctx, int stream_index,\n\n                         int64_t pts, int64_t dts, int64_t scr, int trailer_size)\n\n{\n\n    MpegMuxContext *s = ctx->priv_data;\n\n    StreamInfo *stream = ctx->streams[stream_index]->priv_data;\n\n    uint8_t *buf_ptr;\n\n    int size, payload_size, startcode, id, stuffing_size, i, header_len;\n\n    int packet_size;\n\n    uint8_t buffer[128];\n\n    int zero_trail_bytes = 0;\n\n    int pad_packet_bytes = 0;\n\n    int pes_flags;\n\n    int general_pack = 0;  /*\"general\" pack without data specific to one stream?*/\n\n    int nb_frames;\n\n\n\n    id = stream->id;\n\n\n\n#if 0\n\n    printf(\"packet ID=%2x PTS=%0.3f\\n\",\n\n           id, pts / 90000.0);\n\n#endif\n\n\n\n    buf_ptr = buffer;\n\n\n\n    if ((s->packet_number % s->pack_header_freq) == 0 || s->last_scr != scr) {\n\n        /* output pack and systems header if needed */\n\n        size = put_pack_header(ctx, buf_ptr, scr);\n\n        buf_ptr += size;\n\n        s->last_scr= scr;\n\n\n\n        if (s->is_vcd) {\n\n            /* there is exactly one system header for each stream in a VCD MPEG,\n\n               One in the very first video packet and one in the very first\n\n               audio packet (see VCD standard p. IV-7 and IV-8).*/\n\n\n\n            if (stream->packet_number==0) {\n\n                size = put_system_header(ctx, buf_ptr, id);\n\n                buf_ptr += size;\n\n            }\n\n        } else if (s->is_dvd) {\n\n            if (stream->align_iframe || s->packet_number == 0){\n\n                int PES_bytes_to_fill = s->packet_size - size - 10;\n\n\n\n                if (pts != AV_NOPTS_VALUE) {\n\n                    if (dts != pts)\n\n                        PES_bytes_to_fill -= 5 + 5;\n\n                    else\n\n                        PES_bytes_to_fill -= 5;\n\n                }\n\n\n\n                if (stream->bytes_to_iframe == 0 || s->packet_number == 0) {\n\n                    size = put_system_header(ctx, buf_ptr, 0);\n\n                    buf_ptr += size;\n\n                    size = buf_ptr - buffer;\n\n                    put_buffer(ctx->pb, buffer, size);\n\n\n\n                    put_be32(ctx->pb, PRIVATE_STREAM_2);\n\n                    put_be16(ctx->pb, 0x03d4);         // length\n\n                    put_byte(ctx->pb, 0x00);           // substream ID, 00=PCI\n\n                    for (i = 0; i < 979; i++)\n\n                        put_byte(ctx->pb, 0x00);\n\n\n\n                    put_be32(ctx->pb, PRIVATE_STREAM_2);\n\n                    put_be16(ctx->pb, 0x03fa);         // length\n\n                    put_byte(ctx->pb, 0x01);           // substream ID, 01=DSI\n\n                    for (i = 0; i < 1017; i++)\n\n                        put_byte(ctx->pb, 0x00);\n\n\n\n                    memset(buffer, 0, 128);\n\n                    buf_ptr = buffer;\n\n                    s->packet_number++;\n\n                    stream->align_iframe = 0;\n\n                    scr += s->packet_size*90000LL / (s->mux_rate*50LL); //FIXME rounding and first few bytes of each packet\n\n                    size = put_pack_header(ctx, buf_ptr, scr);\n\n                    s->last_scr= scr;\n\n                    buf_ptr += size;\n\n                    /* GOP Start */\n\n                } else if (stream->bytes_to_iframe < PES_bytes_to_fill) {\n\n                    pad_packet_bytes = PES_bytes_to_fill - stream->bytes_to_iframe;\n\n                }\n\n            }\n\n        } else {\n\n            if ((s->packet_number % s->system_header_freq) == 0) {\n\n                size = put_system_header(ctx, buf_ptr, 0);\n\n                buf_ptr += size;\n\n            }\n\n        }\n\n    }\n\n    size = buf_ptr - buffer;\n\n    put_buffer(ctx->pb, buffer, size);\n\n\n\n    packet_size = s->packet_size - size;\n\n\n\n    if (s->is_vcd && id == AUDIO_ID)\n\n        /* The VCD standard demands that 20 zero bytes follow\n\n           each audio pack (see standard p. IV-8).*/\n\n        zero_trail_bytes += 20;\n\n\n\n    if ((s->is_vcd && stream->packet_number==0)\n\n        || (s->is_svcd && s->packet_number==0)) {\n\n        /* for VCD the first pack of each stream contains only the pack header,\n\n           the system header and lots of padding (see VCD standard p. IV-6).\n\n           In the case of an audio pack, 20 zero bytes are also added at\n\n           the end.*/\n\n        /* For SVCD we fill the very first pack to increase compatibility with\n\n           some DVD players. Not mandated by the standard.*/\n\n        if (s->is_svcd)\n\n            general_pack = 1;    /* the system header refers to both streams and no stream data*/\n\n        pad_packet_bytes = packet_size - zero_trail_bytes;\n\n    }\n\n\n\n    packet_size -= pad_packet_bytes + zero_trail_bytes;\n\n\n\n    if (packet_size > 0) {\n\n\n\n        /* packet header size */\n\n        packet_size -= 6;\n\n\n\n        /* packet header */\n\n        if (s->is_mpeg2) {\n\n            header_len = 3;\n\n            if (stream->packet_number==0)\n\n                header_len += 3; /* PES extension */\n\n            header_len += 1; /* obligatory stuffing byte */\n\n        } else {\n\n            header_len = 0;\n\n        }\n\n        if (pts != AV_NOPTS_VALUE) {\n\n            if (dts != pts)\n\n                header_len += 5 + 5;\n\n            else\n\n                header_len += 5;\n\n        } else {\n\n            if (!s->is_mpeg2)\n\n                header_len++;\n\n        }\n\n\n\n        payload_size = packet_size - header_len;\n\n        if (id < 0xc0) {\n\n            startcode = PRIVATE_STREAM_1;\n\n            payload_size -= 1;\n\n            if (id >= 0x40) {\n\n                payload_size -= 3;\n\n                if (id >= 0xa0)\n\n                    payload_size -= 3;\n\n            }\n\n        } else {\n\n            startcode = 0x100 + id;\n\n        }\n\n\n\n        stuffing_size = payload_size - av_fifo_size(stream->fifo);\n\n\n\n        // first byte does not fit -> reset pts/dts + stuffing\n\n        if(payload_size <= trailer_size && pts != AV_NOPTS_VALUE){\n\n            int timestamp_len=0;\n\n            if(dts != pts)\n\n                timestamp_len += 5;\n\n            if(pts != AV_NOPTS_VALUE)\n\n                timestamp_len += s->is_mpeg2 ? 5 : 4;\n\n            pts=dts= AV_NOPTS_VALUE;\n\n            header_len -= timestamp_len;\n\n            if (s->is_dvd && stream->align_iframe) {\n\n                pad_packet_bytes += timestamp_len;\n\n                packet_size  -= timestamp_len;\n\n            } else {\n\n                payload_size += timestamp_len;\n\n            }\n\n            stuffing_size += timestamp_len;\n\n            if(payload_size > trailer_size)\n\n                stuffing_size += payload_size - trailer_size;\n\n        }\n\n\n\n        if (pad_packet_bytes > 0 && pad_packet_bytes <= 7) { // can't use padding, so use stuffing\n\n            packet_size += pad_packet_bytes;\n\n            payload_size += pad_packet_bytes; // undo the previous adjustment\n\n            if (stuffing_size < 0) {\n\n                stuffing_size  = pad_packet_bytes;\n\n            } else {\n\n                stuffing_size += pad_packet_bytes;\n\n            }\n\n            pad_packet_bytes = 0;\n\n        }\n\n\n\n        if (stuffing_size < 0)\n\n            stuffing_size = 0;\n\n        if (stuffing_size > 16) {    /*<=16 for MPEG-1, <=32 for MPEG-2*/\n\n            pad_packet_bytes += stuffing_size;\n\n            packet_size      -= stuffing_size;\n\n            payload_size     -= stuffing_size;\n\n            stuffing_size = 0;\n\n        }\n\n\n\n        nb_frames= get_nb_frames(ctx, stream, payload_size - stuffing_size);\n\n\n\n        put_be32(ctx->pb, startcode);\n\n\n\n        put_be16(ctx->pb, packet_size);\n\n\n\n        if (!s->is_mpeg2)\n\n            for(i=0;i<stuffing_size;i++)\n\n                put_byte(ctx->pb, 0xff);\n\n\n\n        if (s->is_mpeg2) {\n\n            put_byte(ctx->pb, 0x80); /* mpeg2 id */\n\n\n\n            pes_flags=0;\n\n\n\n            if (pts != AV_NOPTS_VALUE) {\n\n                pes_flags |= 0x80;\n\n                if (dts != pts)\n\n                    pes_flags |= 0x40;\n\n            }\n\n\n\n            /* Both the MPEG-2 and the SVCD standards demand that the\n\n               P-STD_buffer_size field be included in the first packet of\n\n               every stream. (see SVCD standard p. 26 V.2.3.1 and V.2.3.2\n\n               and MPEG-2 standard 2.7.7) */\n\n            if (stream->packet_number == 0)\n\n                pes_flags |= 0x01;\n\n\n\n            put_byte(ctx->pb, pes_flags); /* flags */\n\n            put_byte(ctx->pb, header_len - 3 + stuffing_size);\n\n\n\n            if (pes_flags & 0x80)  /*write pts*/\n\n                put_timestamp(ctx->pb, (pes_flags & 0x40) ? 0x03 : 0x02, pts);\n\n            if (pes_flags & 0x40)  /*write dts*/\n\n                put_timestamp(ctx->pb, 0x01, dts);\n\n\n\n            if (pes_flags & 0x01) {  /*write pes extension*/\n\n                put_byte(ctx->pb, 0x10); /* flags */\n\n\n\n                /* P-STD buffer info */\n\n                if (id == AUDIO_ID)\n\n                    put_be16(ctx->pb, 0x4000 | stream->max_buffer_size/ 128);\n\n                else\n\n                    put_be16(ctx->pb, 0x6000 | stream->max_buffer_size/1024);\n\n            }\n\n\n\n        } else {\n\n            if (pts != AV_NOPTS_VALUE) {\n\n                if (dts != pts) {\n\n                    put_timestamp(ctx->pb, 0x03, pts);\n\n                    put_timestamp(ctx->pb, 0x01, dts);\n\n                } else {\n\n                    put_timestamp(ctx->pb, 0x02, pts);\n\n                }\n\n            } else {\n\n                put_byte(ctx->pb, 0x0f);\n\n            }\n\n        }\n\n\n\n        if (s->is_mpeg2) {\n\n            /* special stuffing byte that is always written\n\n               to prevent accidental generation of start codes. */\n\n            put_byte(ctx->pb, 0xff);\n\n\n\n            for(i=0;i<stuffing_size;i++)\n\n                put_byte(ctx->pb, 0xff);\n\n        }\n\n\n\n        if (startcode == PRIVATE_STREAM_1) {\n\n            put_byte(ctx->pb, id);\n\n            if (id >= 0xa0) {\n\n                /* LPCM (XXX: check nb_frames) */\n\n                put_byte(ctx->pb, 7);\n\n                put_be16(ctx->pb, 4); /* skip 3 header bytes */\n\n                put_byte(ctx->pb, stream->lpcm_header[0]);\n\n                put_byte(ctx->pb, stream->lpcm_header[1]);\n\n                put_byte(ctx->pb, stream->lpcm_header[2]);\n\n            } else if (id >= 0x40) {\n\n                /* AC-3 */\n\n                put_byte(ctx->pb, nb_frames);\n\n                put_be16(ctx->pb, trailer_size+1);\n\n            }\n\n        }\n\n\n\n        /* output data */\n\n        assert(payload_size - stuffing_size <= av_fifo_size(stream->fifo));\n\n        av_fifo_generic_read(stream->fifo, ctx->pb, payload_size - stuffing_size, &put_buffer);\n\n        stream->bytes_to_iframe -= payload_size - stuffing_size;\n\n    }else{\n\n        payload_size=\n\n        stuffing_size= 0;\n\n    }\n\n\n\n    if (pad_packet_bytes > 0)\n\n        put_padding_packet(ctx,ctx->pb, pad_packet_bytes);\n\n\n\n    for(i=0;i<zero_trail_bytes;i++)\n\n        put_byte(ctx->pb, 0x00);\n\n\n\n    put_flush_packet(ctx->pb);\n\n\n\n    s->packet_number++;\n\n\n\n    /* only increase the stream packet number if this pack actually contains\n\n       something that is specific to this stream! I.e. a dedicated header\n\n       or some data.*/\n\n    if (!general_pack)\n\n        stream->packet_number++;\n\n\n\n    return payload_size - stuffing_size;\n\n}\n", "idx": 22924}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static int _decode_exponents(int expstr, int ngrps, uint8_t absexp, uint8_t *gexps, uint8_t *dexps)\n\n{\n\n    int exps;\n\n    int i = 0;\n\n\n\n    while (ngrps--) {\n\n        exps = gexps[i++];\n\n\n\n        absexp += exp_1[exps];\n\n        assert(absexp <= 24);\n\n        switch (expstr) {\n\n            case AC3_EXPSTR_D45:\n\n                *(dexps++) = absexp;\n\n                *(dexps++) = absexp;\n\n            case AC3_EXPSTR_D25:\n\n                *(dexps++) = absexp;\n\n            case AC3_EXPSTR_D15:\n\n                *(dexps++) = absexp;\n\n        }\n\n        absexp += exp_2[exps];\n\n        assert(absexp <= 24);\n\n        switch (expstr) {\n\n            case AC3_EXPSTR_D45:\n\n                *(dexps++) = absexp;\n\n                *(dexps++) = absexp;\n\n            case AC3_EXPSTR_D25:\n\n                *(dexps++) = absexp;\n\n            case AC3_EXPSTR_D15:\n\n                *(dexps++) = absexp;\n\n        }\n\n\n\n        absexp += exp_3[exps];\n\n        assert(absexp <= 24);\n\n        switch (expstr) {\n\n            case AC3_EXPSTR_D45:\n\n                *(dexps++) = absexp;\n\n                *(dexps++) = absexp;\n\n            case AC3_EXPSTR_D25:\n\n                *(dexps++) = absexp;\n\n            case AC3_EXPSTR_D15:\n\n                *(dexps++) = absexp;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22925}
{"project": "FFmpeg", "commit_id": "6df2c94130b026930d1f7148699925dcaa08759c", "target": 0, "func": "static void draw_axis_yuv(AVFrame *out, AVFrame *axis, const ColorFloat *c, int off)\n\n{\n\n    int fmt = out->format, x, y, yh, w = axis->width, h = axis->height;\n\n    int offh = (fmt == AV_PIX_FMT_YUV420P) ? off / 2 : off;\n\n    float a, rcp_255 = 1.0f / 255.0f;\n\n    uint8_t *vy = out->data[0], *vu = out->data[1], *vv = out->data[2];\n\n    uint8_t *vay = axis->data[0], *vau = axis->data[1], *vav = axis->data[2], *vaa = axis->data[3];\n\n    int lsy = out->linesize[0], lsu = out->linesize[1], lsv = out->linesize[2];\n\n    int lsay = axis->linesize[0], lsau = axis->linesize[1], lsav = axis->linesize[2], lsaa = axis->linesize[3];\n\n    uint8_t *lpy, *lpu, *lpv, *lpay, *lpau, *lpav, *lpaa;\n\n\n\n    for (y = 0; y < h; y += 2) {\n\n        yh = (fmt == AV_PIX_FMT_YUV420P) ? y / 2 : y;\n\n        lpy = vy + (off + y) * lsy;\n\n        lpu = vu + (offh + yh) * lsu;\n\n        lpv = vv + (offh + yh) * lsv;\n\n        lpay = vay + y * lsay;\n\n        lpau = vau + yh * lsau;\n\n        lpav = vav + yh * lsav;\n\n        lpaa = vaa + y * lsaa;\n\n        for (x = 0; x < w; x += 2) {\n\n            a = rcp_255 * (*lpaa++);\n\n            *lpy++ = a * (*lpay++) + (1.0f - a) * c[x].yuv.y + 0.5f;\n\n            *lpu++ = a * (*lpau++) + (1.0f - a) * c[x].yuv.u + 0.5f;\n\n            *lpv++ = a * (*lpav++) + (1.0f - a) * c[x].yuv.v + 0.5f;\n\n            /* u and v are skipped on yuv422p and yuv420p */\n\n            a = rcp_255 * (*lpaa++);\n\n            *lpy++ = a * (*lpay++) + (1.0f - a) * c[x+1].yuv.y + 0.5f;\n\n            if (fmt == AV_PIX_FMT_YUV444P) {\n\n                *lpu++ = a * (*lpau++) + (1.0f - a) * c[x+1].yuv.u + 0.5f;\n\n                *lpv++ = a * (*lpav++) + (1.0f - a) * c[x+1].yuv.v + 0.5f;\n\n            }\n\n        }\n\n\n\n        lpy = vy + (off + y + 1) * lsy;\n\n        lpu = vu + (off + y + 1) * lsu;\n\n        lpv = vv + (off + y + 1) * lsv;\n\n        lpay = vay + (y + 1) * lsay;\n\n        lpau = vau + (y + 1) * lsau;\n\n        lpav = vav + (y + 1) * lsav;\n\n        lpaa = vaa + (y + 1) * lsaa;\n\n        for (x = 0; x < out->width; x += 2) {\n\n            /* u and v are skipped on yuv420p */\n\n            a = rcp_255 * (*lpaa++);\n\n            *lpy++ = a * (*lpay++) + (1.0f - a) * c[x].yuv.y + 0.5f;\n\n            if (fmt != AV_PIX_FMT_YUV420P) {\n\n                *lpu++ = a * (*lpau++) + (1.0f - a) * c[x].yuv.u + 0.5f;\n\n                *lpv++ = a * (*lpav++) + (1.0f - a) * c[x].yuv.v + 0.5f;\n\n            }\n\n            /* u and v are skipped on yuv422p and yuv420p */\n\n            a = rcp_255 * (*lpaa++);\n\n            *lpy++ = a * (*lpay++) + (1.0f - a) * c[x+1].yuv.y + 0.5f;\n\n            if (fmt == AV_PIX_FMT_YUV444P) {\n\n                *lpu++ = a * (*lpau++) + (1.0f - a) * c[x+1].yuv.u + 0.5f;\n\n                *lpv++ = a * (*lpav++) + (1.0f - a) * c[x+1].yuv.v + 0.5f;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 22926}
{"project": "FFmpeg", "commit_id": "9f61abc8111c7c43f49ca012e957a108b9cc7610", "target": 0, "func": "static int shift_data(AVFormatContext *s)\n\n{\n\n    int ret = 0, moov_size;\n\n    MOVMuxContext *mov = s->priv_data;\n\n    int64_t pos, pos_end = avio_tell(s->pb);\n\n    uint8_t *buf, *read_buf[2];\n\n    int read_buf_id = 0;\n\n    int read_size[2];\n\n    AVIOContext *read_pb;\n\n\n\n    if (mov->flags & FF_MOV_FLAG_FRAGMENT)\n\n        moov_size = compute_sidx_size(s);\n\n    else\n\n        moov_size = compute_moov_size(s);\n\n    if (moov_size < 0)\n\n        return moov_size;\n\n\n\n    buf = av_malloc(moov_size * 2);\n\n    if (!buf)\n\n        return AVERROR(ENOMEM);\n\n    read_buf[0] = buf;\n\n    read_buf[1] = buf + moov_size;\n\n\n\n    /* Shift the data: the AVIO context of the output can only be used for\n\n     * writing, so we re-open the same output, but for reading. It also avoids\n\n     * a read/seek/write/seek back and forth. */\n\n    avio_flush(s->pb);\n\n    ret = avio_open(&read_pb, s->filename, AVIO_FLAG_READ);\n\n    if (ret < 0) {\n\n        av_log(s, AV_LOG_ERROR, \"Unable to re-open %s output file for \"\n\n               \"the second pass (faststart)\\n\", s->filename);\n\n        goto end;\n\n    }\n\n\n\n    /* mark the end of the shift to up to the last data we wrote, and get ready\n\n     * for writing */\n\n    pos_end = avio_tell(s->pb);\n\n    avio_seek(s->pb, mov->reserved_header_pos + moov_size, SEEK_SET);\n\n\n\n    /* start reading at where the new moov will be placed */\n\n    avio_seek(read_pb, mov->reserved_header_pos, SEEK_SET);\n\n    pos = avio_tell(read_pb);\n\n\n\n#define READ_BLOCK do {                                                             \\\n\n    read_size[read_buf_id] = avio_read(read_pb, read_buf[read_buf_id], moov_size);  \\\n\n    read_buf_id ^= 1;                                                               \\\n\n} while (0)\n\n\n\n    /* shift data by chunk of at most moov_size */\n\n    READ_BLOCK;\n\n    do {\n\n        int n;\n\n        READ_BLOCK;\n\n        n = read_size[read_buf_id];\n\n        if (n <= 0)\n\n            break;\n\n        avio_write(s->pb, read_buf[read_buf_id], n);\n\n        pos += n;\n\n    } while (pos < pos_end);\n\n    avio_close(read_pb);\n\n\n\nend:\n\n    av_free(buf);\n\n    return ret;\n\n}\n", "idx": 22927}
{"project": "FFmpeg", "commit_id": "ae2d41ec875965ce4ab9fdd88a5e8ba57cada67a", "target": 0, "func": "void ff_do_elbg(int *points, int dim, int numpoints, int *codebook,\n\n                int numCB, int max_steps, int *closest_cb,\n\n                AVLFG *rand_state)\n\n{\n\n    int dist;\n\n    elbg_data elbg_d;\n\n    elbg_data *elbg = &elbg_d;\n\n    int i, j, k, last_error, steps=0;\n\n    int *dist_cb = av_malloc(numpoints*sizeof(int));\n\n    int *size_part = av_malloc(numCB*sizeof(int));\n\n    cell *list_buffer = av_malloc(numpoints*sizeof(cell));\n\n    cell *free_cells;\n\n    int best_dist, best_idx = 0;\n\n\n\n    elbg->error = INT_MAX;\n\n    elbg->dim = dim;\n\n    elbg->numCB = numCB;\n\n    elbg->codebook = codebook;\n\n    elbg->cells = av_malloc(numCB*sizeof(cell *));\n\n    elbg->utility = av_malloc(numCB*sizeof(int));\n\n    elbg->nearest_cb = closest_cb;\n\n    elbg->points = points;\n\n    elbg->utility_inc = av_malloc(numCB*sizeof(int));\n\n    elbg->scratchbuf = av_malloc(5*dim*sizeof(int));\n\n\n\n    elbg->rand_state = rand_state;\n\n\n\n    do {\n\n        free_cells = list_buffer;\n\n        last_error = elbg->error;\n\n        steps++;\n\n        memset(elbg->utility, 0, numCB*sizeof(int));\n\n        memset(elbg->cells, 0, numCB*sizeof(cell *));\n\n\n\n        elbg->error = 0;\n\n\n\n        /* This loop evaluate the actual Voronoi partition. It is the most\n\n           costly part of the algorithm. */\n\n        for (i=0; i < numpoints; i++) {\n\n            best_dist = distance_limited(elbg->points + i*elbg->dim, elbg->codebook + best_idx*elbg->dim, dim, INT_MAX);\n\n            for (k=0; k < elbg->numCB; k++) {\n\n                dist = distance_limited(elbg->points + i*elbg->dim, elbg->codebook + k*elbg->dim, dim, best_dist);\n\n                if (dist < best_dist) {\n\n                    best_dist = dist;\n\n                    best_idx = k;\n\n                }\n\n            }\n\n            elbg->nearest_cb[i] = best_idx;\n\n            dist_cb[i] = best_dist;\n\n            elbg->error += dist_cb[i];\n\n            elbg->utility[elbg->nearest_cb[i]] += dist_cb[i];\n\n            free_cells->index = i;\n\n            free_cells->next = elbg->cells[elbg->nearest_cb[i]];\n\n            elbg->cells[elbg->nearest_cb[i]] = free_cells;\n\n            free_cells++;\n\n        }\n\n\n\n        do_shiftings(elbg);\n\n\n\n        memset(size_part, 0, numCB*sizeof(int));\n\n\n\n        memset(elbg->codebook, 0, elbg->numCB*dim*sizeof(int));\n\n\n\n        for (i=0; i < numpoints; i++) {\n\n            size_part[elbg->nearest_cb[i]]++;\n\n            for (j=0; j < elbg->dim; j++)\n\n                elbg->codebook[elbg->nearest_cb[i]*elbg->dim + j] +=\n\n                    elbg->points[i*elbg->dim + j];\n\n        }\n\n\n\n        for (i=0; i < elbg->numCB; i++)\n\n            vect_division(elbg->codebook + i*elbg->dim,\n\n                          elbg->codebook + i*elbg->dim, size_part[i], elbg->dim);\n\n\n\n    } while(((last_error - elbg->error) > DELTA_ERR_MAX*elbg->error) &&\n\n            (steps < max_steps));\n\n\n\n    av_free(dist_cb);\n\n    av_free(size_part);\n\n    av_free(elbg->utility);\n\n    av_free(list_buffer);\n\n    av_free(elbg->cells);\n\n    av_free(elbg->utility_inc);\n\n    av_free(elbg->scratchbuf);\n\n}\n", "idx": 22928}
{"project": "FFmpeg", "commit_id": "676e61c7bbc5b48a7b9f6ca2ca227e345e3d4580", "target": 0, "func": "int ff_h263_decode_frame(AVCodecContext *avctx, \n\n                             void *data, int *data_size,\n\n                             uint8_t *buf, int buf_size)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int ret;\n\n    AVFrame *pict = data; \n\n    \n\n#ifdef PRINT_FRAME_TIME\n\nuint64_t time= rdtsc();\n\n#endif\n\n#ifdef DEBUG\n\n    printf(\"*****frame %d size=%d\\n\", avctx->frame_number, buf_size);\n\n    printf(\"bytes=%x %x %x %x\\n\", buf[0], buf[1], buf[2], buf[3]);\n\n#endif\n\n    s->flags= avctx->flags;\n\n    s->flags2= avctx->flags2;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0) {\n\n        /* special case for last picture */\n\n        if (s->low_delay==0 && s->next_picture_ptr) {\n\n            *pict= *(AVFrame*)s->next_picture_ptr;\n\n            s->next_picture_ptr= NULL;\n\n\n\n            *data_size = sizeof(AVFrame);\n\n        }\n\n\n\n        return 0;\n\n    }\n\n\n\n    if(s->flags&CODEC_FLAG_TRUNCATED){\n\n        int next;\n\n        \n\n        if(s->codec_id==CODEC_ID_MPEG4){\n\n            next= ff_mpeg4_find_frame_end(&s->parse_context, buf, buf_size);\n\n        }else if(s->codec_id==CODEC_ID_H263){\n\n            next= h263_find_frame_end(&s->parse_context, buf, buf_size);\n\n        }else{\n\n            av_log(s->avctx, AV_LOG_ERROR, \"this codec doesnt support truncated bitstreams\\n\");\n\n            return -1;\n\n        }\n\n        \n\n        if( ff_combine_frame(&s->parse_context, next, &buf, &buf_size) < 0 )\n\n            return buf_size;\n\n    }\n\n\n\n    \n\nretry:\n\n    \n\n    if(s->bitstream_buffer_size && (s->divx_packed || buf_size<20)){ //divx 5.01+/xvid frame reorder\n\n        init_get_bits(&s->gb, s->bitstream_buffer, s->bitstream_buffer_size*8);\n\n    }else\n\n        init_get_bits(&s->gb, buf, buf_size*8);\n\n    s->bitstream_buffer_size=0;\n\n\n\n    if (!s->context_initialized) {\n\n        if (MPV_common_init(s) < 0) //we need the idct permutaton for reading a custom matrix\n\n            return -1;\n\n    }\n\n    \n\n    //we need to set current_picture_ptr before reading the header, otherwise we cant store anyting im there\n\n    if(s->current_picture_ptr==NULL || s->current_picture_ptr->data[0]){\n\n        int i= ff_find_unused_picture(s, 0);\n\n        s->current_picture_ptr= &s->picture[i];\n\n    }\n\n      \n\n    /* let's go :-) */\n\n    if (s->msmpeg4_version==5) {\n\n        ret= ff_wmv2_decode_picture_header(s);\n\n    } else if (s->msmpeg4_version) {\n\n        ret = msmpeg4_decode_picture_header(s);\n\n    } else if (s->h263_pred) {\n\n        if(s->avctx->extradata_size && s->picture_number==0){\n\n            GetBitContext gb;\n\n            \n\n            init_get_bits(&gb, s->avctx->extradata, s->avctx->extradata_size*8);\n\n            ret = ff_mpeg4_decode_picture_header(s, &gb);\n\n        }\n\n        ret = ff_mpeg4_decode_picture_header(s, &s->gb);\n\n\n\n        if(s->flags& CODEC_FLAG_LOW_DELAY)\n\n            s->low_delay=1;\n\n    } else if (s->codec_id == CODEC_ID_H263I) {\n\n        ret = intel_h263_decode_picture_header(s);\n\n    } else if (s->h263_flv) {\n\n        ret = flv_h263_decode_picture_header(s);\n\n    } else {\n\n        ret = h263_decode_picture_header(s);\n\n    }\n\n    \n\n    if(ret==FRAME_SKIPED) return get_consumed_bytes(s, buf_size);\n\n\n\n    /* skip if the header was thrashed */\n\n    if (ret < 0){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"header damaged\\n\");\n\n        return -1;\n\n    }\n\n    \n\n    avctx->has_b_frames= !s->low_delay;\n\n    \n\n    if(s->xvid_build==0 && s->divx_version==0 && s->lavc_build==0){\n\n        if(s->avctx->stream_codec_tag == ff_get_fourcc(\"XVID\") || \n\n           s->avctx->codec_tag == ff_get_fourcc(\"XVID\") || s->avctx->codec_tag == ff_get_fourcc(\"XVIX\"))\n\n            s->xvid_build= -1;\n\n#if 0\n\n        if(s->avctx->codec_tag == ff_get_fourcc(\"DIVX\") && s->vo_type==0 && s->vol_control_parameters==1\n\n           && s->padding_bug_score > 0 && s->low_delay) // XVID with modified fourcc \n\n            s->xvid_build= -1;\n\n#endif\n\n    }\n\n\n\n    if(s->xvid_build==0 && s->divx_version==0 && s->lavc_build==0){\n\n        if(s->avctx->codec_tag == ff_get_fourcc(\"DIVX\") && s->vo_type==0 && s->vol_control_parameters==0)\n\n            s->divx_version= 400; //divx 4\n\n    }\n\n\n\n    if(s->workaround_bugs&FF_BUG_AUTODETECT){\n\n        s->workaround_bugs &= ~FF_BUG_NO_PADDING;\n\n        \n\n        if(s->padding_bug_score > -2 && !s->data_partitioning && (s->divx_version || !s->resync_marker))\n\n            s->workaround_bugs |=  FF_BUG_NO_PADDING;\n\n\n\n        if(s->avctx->codec_tag == ff_get_fourcc(\"XVIX\")) \n\n            s->workaround_bugs|= FF_BUG_XVID_ILACE;\n\n\n\n        if(s->avctx->codec_tag == ff_get_fourcc(\"UMP4\")){\n\n            s->workaround_bugs|= FF_BUG_UMP4;\n\n        }\n\n\n\n        if(s->divx_version>=500){\n\n            s->workaround_bugs|= FF_BUG_QPEL_CHROMA;\n\n        }\n\n\n\n        if(s->divx_version>502){\n\n            s->workaround_bugs|= FF_BUG_QPEL_CHROMA2;\n\n        }\n\n\n\n        if(s->xvid_build && s->xvid_build<=3)\n\n            s->padding_bug_score= 256*256*256*64;\n\n        \n\n        if(s->xvid_build && s->xvid_build<=1)\n\n            s->workaround_bugs|= FF_BUG_QPEL_CHROMA;\n\n\n\n        if(s->xvid_build && s->xvid_build<=12)\n\n            s->workaround_bugs|= FF_BUG_EDGE;\n\n\n\n        if(s->xvid_build && s->xvid_build<=32)\n\n            s->workaround_bugs|= FF_BUG_DC_CLIP;\n\n\n\n#define SET_QPEL_FUNC(postfix1, postfix2) \\\n\n    s->dsp.put_ ## postfix1 = ff_put_ ## postfix2;\\\n\n    s->dsp.put_no_rnd_ ## postfix1 = ff_put_no_rnd_ ## postfix2;\\\n\n    s->dsp.avg_ ## postfix1 = ff_avg_ ## postfix2;\n\n\n\n        if(s->lavc_build && s->lavc_build<4653)\n\n            s->workaround_bugs|= FF_BUG_STD_QPEL;\n\n        \n\n        if(s->lavc_build && s->lavc_build<4655)\n\n            s->workaround_bugs|= FF_BUG_DIRECT_BLOCKSIZE;\n\n\n\n        if(s->lavc_build && s->lavc_build<4670){\n\n            s->workaround_bugs|= FF_BUG_EDGE;\n\n        }\n\n        \n\n        if(s->lavc_build && s->lavc_build<=4712)\n\n            s->workaround_bugs|= FF_BUG_DC_CLIP;\n\n\n\n        if(s->divx_version)\n\n            s->workaround_bugs|= FF_BUG_DIRECT_BLOCKSIZE;\n\n//printf(\"padding_bug_score: %d\\n\", s->padding_bug_score);\n\n        if(s->divx_version==501 && s->divx_build==20020416)\n\n            s->padding_bug_score= 256*256*256*64;\n\n\n\n        if(s->divx_version && s->divx_version<500){\n\n            s->workaround_bugs|= FF_BUG_EDGE;\n\n        }\n\n        \n\n        if(s->divx_version)\n\n            s->workaround_bugs|= FF_BUG_HPEL_CHROMA;\n\n#if 0\n\n        if(s->divx_version==500)\n\n            s->padding_bug_score= 256*256*256*64;\n\n\n\n        /* very ugly XVID padding bug detection FIXME/XXX solve this differently\n\n         * lets hope this at least works\n\n         */\n\n        if(   s->resync_marker==0 && s->data_partitioning==0 && s->divx_version==0\n\n           && s->codec_id==CODEC_ID_MPEG4 && s->vo_type==0)\n\n            s->workaround_bugs|= FF_BUG_NO_PADDING;\n\n        \n\n        if(s->lavc_build && s->lavc_build<4609) //FIXME not sure about the version num but a 4609 file seems ok\n\n            s->workaround_bugs|= FF_BUG_NO_PADDING;\n\n#endif\n\n    }\n\n    \n\n    if(s->workaround_bugs& FF_BUG_STD_QPEL){\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][ 5], qpel16_mc11_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][ 7], qpel16_mc31_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][ 9], qpel16_mc12_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][11], qpel16_mc32_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][13], qpel16_mc13_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][15], qpel16_mc33_old_c)\n\n\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][ 5], qpel8_mc11_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][ 7], qpel8_mc31_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][ 9], qpel8_mc12_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][11], qpel8_mc32_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][13], qpel8_mc13_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][15], qpel8_mc33_old_c)\n\n    }\n\n\n\n    if(avctx->debug & FF_DEBUG_BUGS)\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"bugs: %X lavc_build:%d xvid_build:%d divx_version:%d divx_build:%d %s\\n\", \n\n               s->workaround_bugs, s->lavc_build, s->xvid_build, s->divx_version, s->divx_build,\n\n               s->divx_packed ? \"p\" : \"\");\n\n    \n\n#if 0 // dump bits per frame / qp / complexity\n\n{\n\n    static FILE *f=NULL;\n\n    if(!f) f=fopen(\"rate_qp_cplx.txt\", \"w\");\n\n    fprintf(f, \"%d %d %f\\n\", buf_size, s->qscale, buf_size*(double)s->qscale);\n\n}\n\n#endif\n\n       \n\n        /* After H263 & mpeg4 header decode we have the height, width,*/\n\n        /* and other parameters. So then we could init the picture   */\n\n        /* FIXME: By the way H263 decoder is evolving it should have */\n\n        /* an H263EncContext                                         */\n\n    \n\n    if (   s->width != avctx->width || s->height != avctx->height) {\n\n        /* H.263 could change picture size any time */\n\n        ParseContext pc= s->parse_context; //FIXME move these demuxng hack to avformat\n\n        s->parse_context.buffer=0;\n\n        MPV_common_end(s);\n\n        s->parse_context= pc;\n\n    }\n\n    if (!s->context_initialized) {\n\n        avctx->width = s->width;\n\n        avctx->height = s->height;\n\n\n\n        goto retry;\n\n    }\n\n\n\n    if((s->codec_id==CODEC_ID_H263 || s->codec_id==CODEC_ID_H263P))\n\n        s->gob_index = ff_h263_get_gob_height(s);\n\n    \n\n    // for hurry_up==5\n\n    s->current_picture.pict_type= s->pict_type;\n\n    s->current_picture.key_frame= s->pict_type == I_TYPE;\n\n\n\n    /* skip b frames if we dont have reference frames */\n\n    if(s->last_picture_ptr==NULL && s->pict_type==B_TYPE) return get_consumed_bytes(s, buf_size);\n\n    /* skip b frames if we are in a hurry */\n\n    if(avctx->hurry_up && s->pict_type==B_TYPE) return get_consumed_bytes(s, buf_size);\n\n    /* skip everything if we are in a hurry>=5 */\n\n    if(avctx->hurry_up>=5) return get_consumed_bytes(s, buf_size);\n\n    \n\n    if(s->next_p_frame_damaged){\n\n        if(s->pict_type==B_TYPE)\n\n            return get_consumed_bytes(s, buf_size);\n\n        else\n\n            s->next_p_frame_damaged=0;\n\n    }\n\n\n\n    if(MPV_frame_start(s, avctx) < 0)\n\n        return -1;\n\n\n\n#ifdef DEBUG\n\n    printf(\"qscale=%d\\n\", s->qscale);\n\n#endif\n\n\n\n    ff_er_frame_start(s);\n\n    \n\n    //the second part of the wmv2 header contains the MB skip bits which are stored in current_picture->mb_type\n\n    //which isnt available before MPV_frame_start()\n\n    if (s->msmpeg4_version==5){\n\n        if(ff_wmv2_decode_secondary_picture_header(s) < 0)\n\n            return -1;\n\n    }\n\n\n\n    /* decode each macroblock */\n\n    s->mb_x=0; \n\n    s->mb_y=0;\n\n    \n\n    decode_slice(s);\n\n    while(s->mb_y<s->mb_height){\n\n        if(s->msmpeg4_version){\n\n            if(s->mb_x!=0 || (s->mb_y%s->slice_height)!=0 || get_bits_count(&s->gb) > s->gb.size_in_bits)\n\n                break;\n\n        }else{\n\n            if(ff_h263_resync(s)<0)\n\n                break;\n\n        }\n\n        \n\n        if(s->msmpeg4_version<4 && s->h263_pred)\n\n            ff_mpeg4_clean_buffers(s);\n\n\n\n        decode_slice(s);\n\n    }\n\n\n\n    if (s->h263_msmpeg4 && s->msmpeg4_version<4 && s->pict_type==I_TYPE)\n\n        if(msmpeg4_decode_ext_header(s, buf_size) < 0){\n\n            s->error_status_table[s->mb_num-1]= AC_ERROR|DC_ERROR|MV_ERROR;\n\n        }\n\n    \n\n    /* divx 5.01+ bistream reorder stuff */\n\n    if(s->codec_id==CODEC_ID_MPEG4 && s->bitstream_buffer_size==0 && s->divx_packed){\n\n        int current_pos= get_bits_count(&s->gb)>>3;\n\n        int startcode_found=0;\n\n\n\n        if(   buf_size - current_pos > 5 \n\n           && buf_size - current_pos < BITSTREAM_BUFFER_SIZE){\n\n            int i;\n\n            for(i=current_pos; i<buf_size-3; i++){\n\n                if(buf[i]==0 && buf[i+1]==0 && buf[i+2]==1 && buf[i+3]==0xB6){\n\n                    startcode_found=1;\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n        if(s->gb.buffer == s->bitstream_buffer && buf_size>20){ //xvid style\n\n            startcode_found=1;\n\n            current_pos=0;\n\n        }\n\n\n\n        if(startcode_found){\n\n            memcpy(s->bitstream_buffer, buf + current_pos, buf_size - current_pos);\n\n            s->bitstream_buffer_size= buf_size - current_pos;\n\n        }\n\n    }\n\n\n\n    ff_er_frame_end(s);\n\n\n\n    MPV_frame_end(s);\n\n\n\nassert(s->current_picture.pict_type == s->current_picture_ptr->pict_type);\n\nassert(s->current_picture.pict_type == s->pict_type);\n\n    if(s->pict_type==B_TYPE || s->low_delay){\n\n        *pict= *(AVFrame*)&s->current_picture;\n\n        ff_print_debug_info(s, pict);\n\n    } else {\n\n        *pict= *(AVFrame*)&s->last_picture;\n\n        if(pict)\n\n            ff_print_debug_info(s, pict);\n\n    }\n\n\n\n    /* Return the Picture timestamp as the frame number */\n\n    /* we substract 1 because it is added on utils.c    */\n\n    avctx->frame_number = s->picture_number - 1;\n\n\n\n    /* dont output the last pic after seeking */\n\n    if(s->last_picture_ptr || s->low_delay)\n\n        *data_size = sizeof(AVFrame);\n\n#ifdef PRINT_FRAME_TIME\n\nprintf(\"%Ld\\n\", rdtsc()-time);\n\n#endif\n\n\n\n    return get_consumed_bytes(s, buf_size);\n\n}\n", "idx": 22929}
{"project": "FFmpeg", "commit_id": "2caf19e90f270abe1e80a3e85acaf0eb5c9d0aac", "target": 1, "func": "static void FUNCC(pred8x8_vertical)(uint8_t *_src, int _stride){\n\n    int i;\n\n    pixel *src = (pixel*)_src;\n\n    int stride = _stride/sizeof(pixel);\n\n    const pixel4 a= ((pixel4*)(src-stride))[0];\n\n    const pixel4 b= ((pixel4*)(src-stride))[1];\n\n\n\n    for(i=0; i<8; i++){\n\n        ((pixel4*)(src+i*stride))[0]= a;\n\n        ((pixel4*)(src+i*stride))[1]= b;\n\n    }\n\n}\n", "idx": 22932}
{"project": "FFmpeg", "commit_id": "02d248d5828dbbfecfb37597c626900f41448bea", "target": 1, "func": "static int videotoolbox_buffer_create(AVCodecContext *avctx, AVFrame *frame)\n\n{\n\n    VTContext *vtctx = avctx->internal->hwaccel_priv_data;\n\n    CVPixelBufferRef pixbuf = (CVPixelBufferRef)vtctx->frame;\n\n    OSType pixel_format = CVPixelBufferGetPixelFormatType(pixbuf);\n\n    enum AVPixelFormat sw_format = av_map_videotoolbox_format_to_pixfmt(pixel_format);\n\n    int width = CVPixelBufferGetWidth(pixbuf);\n\n    int height = CVPixelBufferGetHeight(pixbuf);\n\n    AVHWFramesContext *cached_frames;\n\n    int ret;\n\n\n\n    ret = ff_videotoolbox_buffer_create(vtctx, frame);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    // Old API code path.\n\n    if (!vtctx->cached_hw_frames_ctx)\n\n        return 0;\n\n\n\n    cached_frames = (AVHWFramesContext*)vtctx->cached_hw_frames_ctx->data;\n\n\n\n    if (cached_frames->sw_format != sw_format ||\n\n        cached_frames->width != width ||\n\n        cached_frames->height != height) {\n\n        AVBufferRef *hw_frames_ctx = av_hwframe_ctx_alloc(cached_frames->device_ref);\n\n        AVHWFramesContext *hw_frames;\n\n        if (!hw_frames_ctx)\n\n            return AVERROR(ENOMEM);\n\n\n\n        hw_frames = (AVHWFramesContext*)hw_frames_ctx->data;\n\n        hw_frames->format = cached_frames->format;\n\n        hw_frames->sw_format = sw_format;\n\n        hw_frames->width = width;\n\n        hw_frames->height = height;\n\n\n\n        ret = av_hwframe_ctx_init(hw_frames_ctx);\n\n        if (ret < 0) {\n\n            av_buffer_unref(&hw_frames_ctx);\n\n            return ret;\n\n        }\n\n\n\n        av_buffer_unref(&vtctx->cached_hw_frames_ctx);\n\n        vtctx->cached_hw_frames_ctx = hw_frames_ctx;\n\n    }\n\n\n\n    av_assert0(!frame->hw_frames_ctx);\n\n    frame->hw_frames_ctx = av_buffer_ref(vtctx->cached_hw_frames_ctx);\n\n    if (!frame->hw_frames_ctx)\n\n        return AVERROR(ENOMEM);\n\n\n\n    return 0;\n\n}\n", "idx": 22933}
{"project": "FFmpeg", "commit_id": "3e0f7126b53b395d9e79df57b2e626eb99ad846b", "target": 1, "func": "static void inner_add_yblock_bw_16_obmc_32_sse2(const uint8_t *obmc, const long obmc_stride, uint8_t * * block, int b_w, long b_h,\n\n                      int src_x, int src_y, long src_stride, slice_buffer * sb, int add, uint8_t * dst8){\n\nsnow_inner_add_yblock_sse2_header\n\nsnow_inner_add_yblock_sse2_start_16(\"xmm1\", \"xmm5\", \"3\", \"0\")\n\nsnow_inner_add_yblock_sse2_accum_16(\"2\", \"16\")\n\nsnow_inner_add_yblock_sse2_accum_16(\"1\", \"512\")\n\nsnow_inner_add_yblock_sse2_accum_16(\"0\", \"528\")\n\n\n\n             \"mov %0, %%\"REG_d\"              \\n\\t\"\n\n             \"movdqa %%xmm1, %%xmm0          \\n\\t\"\n\n             \"movdqa %%xmm5, %%xmm4          \\n\\t\"\n\n             \"punpcklwd %%xmm7, %%xmm0       \\n\\t\"\n\n             \"paddd (%%\"REG_D\"), %%xmm0      \\n\\t\"\n\n             \"punpckhwd %%xmm7, %%xmm1       \\n\\t\"\n\n             \"paddd 16(%%\"REG_D\"), %%xmm1    \\n\\t\"\n\n             \"punpcklwd %%xmm7, %%xmm4       \\n\\t\"\n\n             \"paddd 32(%%\"REG_D\"), %%xmm4    \\n\\t\"\n\n             \"punpckhwd %%xmm7, %%xmm5       \\n\\t\"\n\n             \"paddd 48(%%\"REG_D\"), %%xmm5    \\n\\t\"\n\n             \"paddd %%xmm3, %%xmm0           \\n\\t\"\n\n             \"paddd %%xmm3, %%xmm1           \\n\\t\"\n\n             \"paddd %%xmm3, %%xmm4           \\n\\t\"\n\n             \"paddd %%xmm3, %%xmm5           \\n\\t\"\n\n             \"psrad $8, %%xmm0               \\n\\t\" /* FRAC_BITS. */\n\n             \"psrad $8, %%xmm1               \\n\\t\" /* FRAC_BITS. */\n\n             \"psrad $8, %%xmm4               \\n\\t\" /* FRAC_BITS. */\n\n             \"psrad $8, %%xmm5               \\n\\t\" /* FRAC_BITS. */\n\n\n\n             \"packssdw %%xmm1, %%xmm0        \\n\\t\"\n\n             \"packssdw %%xmm5, %%xmm4        \\n\\t\"\n\n             \"packuswb %%xmm4, %%xmm0        \\n\\t\"\n\n\n\n             \"movdqu %%xmm0, (%%\"REG_d\")       \\n\\t\"\n\n\n\nsnow_inner_add_yblock_sse2_end_16\n\n}\n", "idx": 22934}
{"project": "FFmpeg", "commit_id": "6796a1dd8c14843b77925cb83a3ef88706ae1dd0", "target": 0, "func": "void ff_put_h264_qpel4_mc03_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_vt_qrt_4w_msa(src - (stride * 2), stride, dst, stride, 4, 1);\n\n}\n", "idx": 22937}
{"project": "FFmpeg", "commit_id": "0d4404ed65e6ebfdf5e3c09f9e3a2a41dde18e4a", "target": 0, "func": "static int ff_asf_get_packet(AVFormatContext *s, AVIOContext *pb)\n\n{\n\n    ASFContext *asf = s->priv_data;\n\n    uint32_t packet_length, padsize;\n\n    int rsize = 8;\n\n    int c, d, e, off;\n\n\n\n    // if we do not know packet size, allow skipping up to 32 kB\n\n    off= 32768;\n\n    if (s->packet_size > 0)\n\n        off= (avio_tell(pb) - s->data_offset) % s->packet_size + 3;\n\n\n\n    c=d=e=-1;\n\n    while(off-- > 0){\n\n        c=d; d=e;\n\n        e= avio_r8(pb);\n\n        if(c == 0x82 && !d && !e)\n\n            break;\n\n    }\n\n\n\n    if (c != 0x82) {\n\n        /**\n\n         * This code allows handling of -EAGAIN at packet boundaries (i.e.\n\n         * if the packet sync code above triggers -EAGAIN). This does not\n\n         * imply complete -EAGAIN handling support at random positions in\n\n         * the stream.\n\n         */\n\n        if (pb->error == AVERROR(EAGAIN))\n\n            return AVERROR(EAGAIN);\n\n        if (!url_feof(pb))\n\n            av_log(s, AV_LOG_ERROR, \"ff asf bad header %x  at:%\"PRId64\"\\n\", c, avio_tell(pb));\n\n    }\n\n    if ((c & 0x8f) == 0x82) {\n\n        if (d || e) {\n\n            if (!url_feof(pb))\n\n                av_log(s, AV_LOG_ERROR, \"ff asf bad non zero\\n\");\n\n            return -1;\n\n        }\n\n        c= avio_r8(pb);\n\n        d= avio_r8(pb);\n\n        rsize+=3;\n\n    }else{\n\n        avio_seek(pb, -1, SEEK_CUR); //FIXME\n\n    }\n\n\n\n    asf->packet_flags    = c;\n\n    asf->packet_property = d;\n\n\n\n    DO_2BITS(asf->packet_flags >> 5, packet_length, s->packet_size);\n\n    DO_2BITS(asf->packet_flags >> 1, padsize, 0); // sequence ignored\n\n    DO_2BITS(asf->packet_flags >> 3, padsize, 0); // padding length\n\n\n\n    //the following checks prevent overflows and infinite loops\n\n    if(!packet_length || packet_length >= (1U<<29)){\n\n        av_log(s, AV_LOG_ERROR, \"invalid packet_length %d at:%\"PRId64\"\\n\", packet_length, avio_tell(pb));\n\n        return -1;\n\n    }\n\n    if(padsize >= packet_length){\n\n        av_log(s, AV_LOG_ERROR, \"invalid padsize %d at:%\"PRId64\"\\n\", padsize, avio_tell(pb));\n\n        return -1;\n\n    }\n\n\n\n    asf->packet_timestamp = avio_rl32(pb);\n\n    avio_rl16(pb); /* duration */\n\n    // rsize has at least 11 bytes which have to be present\n\n\n\n    if (asf->packet_flags & 0x01) {\n\n        asf->packet_segsizetype = avio_r8(pb); rsize++;\n\n        asf->packet_segments = asf->packet_segsizetype & 0x3f;\n\n    } else {\n\n        asf->packet_segments = 1;\n\n        asf->packet_segsizetype = 0x80;\n\n    }\n\n    asf->packet_size_left = packet_length - padsize - rsize;\n\n    if (packet_length < asf->hdr.min_pktsize)\n\n        padsize += asf->hdr.min_pktsize - packet_length;\n\n    asf->packet_padsize = padsize;\n\n    av_dlog(s, \"packet: size=%d padsize=%d  left=%d\\n\", s->packet_size, asf->packet_padsize, asf->packet_size_left);\n\n    return 0;\n\n}\n", "idx": 22938}
{"project": "FFmpeg", "commit_id": "dcc39ee10e82833ce24aa57926c00ffeb1948198", "target": 0, "func": "void checkasm_check_blockdsp(void)\n\n{\n\n    LOCAL_ALIGNED_16(uint16_t, buf0, [6 * 8 * 8]);\n\n    LOCAL_ALIGNED_16(uint16_t, buf1, [6 * 8 * 8]);\n\n\n\n    AVCodecContext avctx = { 0 };\n\n    BlockDSPContext h;\n\n\n\n    ff_blockdsp_init(&h, &avctx);\n\n\n\n    check_clear(clear_block,  8 * 8);\n\n    check_clear(clear_blocks, 8 * 8 * 6);\n\n\n\n    report(\"blockdsp\");\n\n}\n", "idx": 22939}
{"project": "FFmpeg", "commit_id": "a4cd057bc7ddd2dd094d2ae7b0d6843ade95a626", "target": 1, "func": "static int mkv_write_chapters(AVFormatContext *s)\n\n{\n\n    MatroskaMuxContext *mkv = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    ebml_master chapters, editionentry;\n\n    AVRational scale = {1, 1E9};\n\n    int i, ret;\n\n\n\n    if (!s->nb_chapters || mkv->wrote_chapters)\n\n        return 0;\n\n\n\n    ret = mkv_add_seekhead_entry(mkv->main_seekhead, MATROSKA_ID_CHAPTERS, avio_tell(pb));\n\n    if (ret < 0) return ret;\n\n\n\n    chapters     = start_ebml_master(pb, MATROSKA_ID_CHAPTERS    , 0);\n\n    editionentry = start_ebml_master(pb, MATROSKA_ID_EDITIONENTRY, 0);\n\n    put_ebml_uint(pb, MATROSKA_ID_EDITIONFLAGDEFAULT, 1);\n\n    put_ebml_uint(pb, MATROSKA_ID_EDITIONFLAGHIDDEN , 0);\n\n    for (i = 0; i < s->nb_chapters; i++) {\n\n        ebml_master chapteratom, chapterdisplay;\n\n        AVChapter *c     = s->chapters[i];\n\n        int chapterstart = av_rescale_q(c->start, c->time_base, scale);\n\n        int chapterend   = av_rescale_q(c->end,   c->time_base, scale);\n\n        AVDictionaryEntry *t = NULL;\n\n        if (chapterstart < 0 || chapterstart > chapterend)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        chapteratom = start_ebml_master(pb, MATROSKA_ID_CHAPTERATOM, 0);\n\n        put_ebml_uint(pb, MATROSKA_ID_CHAPTERUID, c->id + mkv->chapter_id_offset);\n\n        put_ebml_uint(pb, MATROSKA_ID_CHAPTERTIMESTART, chapterstart);\n\n        put_ebml_uint(pb, MATROSKA_ID_CHAPTERTIMEEND, chapterend);\n\n        put_ebml_uint(pb, MATROSKA_ID_CHAPTERFLAGHIDDEN , 0);\n\n        put_ebml_uint(pb, MATROSKA_ID_CHAPTERFLAGENABLED, 1);\n\n        if ((t = av_dict_get(c->metadata, \"title\", NULL, 0))) {\n\n            chapterdisplay = start_ebml_master(pb, MATROSKA_ID_CHAPTERDISPLAY, 0);\n\n            put_ebml_string(pb, MATROSKA_ID_CHAPSTRING, t->value);\n\n            put_ebml_string(pb, MATROSKA_ID_CHAPLANG  , \"und\");\n\n            end_ebml_master(pb, chapterdisplay);\n\n        }\n\n        end_ebml_master(pb, chapteratom);\n\n    }\n\n    end_ebml_master(pb, editionentry);\n\n    end_ebml_master(pb, chapters);\n\n\n\n    mkv->wrote_chapters = 1;\n\n    return 0;\n\n}\n", "idx": 22941}
{"project": "FFmpeg", "commit_id": "afb18c55783362546b5e512ce01b7fe7bf5744d9", "target": 0, "func": "void ff_er_frame_end(ERContext *s)\n\n{\n\n    int *linesize = s->cur_pic->f.linesize;\n\n    int i, mb_x, mb_y, error, error_type, dc_error, mv_error, ac_error;\n\n    int distance;\n\n    int threshold_part[4] = { 100, 100, 100 };\n\n    int threshold = 50;\n\n    int is_intra_likely;\n\n    int size = s->b8_stride * 2 * s->mb_height;\n\n\n\n    /* We do not support ER of field pictures yet,\n\n     * though it should not crash if enabled. */\n\n    if (!s->avctx->error_concealment || s->error_count == 0            ||\n\n        s->avctx->lowres                                               ||\n\n        s->avctx->hwaccel                                              ||\n\n        s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU          ||\n\n        !s->cur_pic || s->cur_pic->field_picture                               ||\n\n        s->error_count == 3 * s->mb_width *\n\n                          (s->avctx->skip_top + s->avctx->skip_bottom)) {\n\n        return;\n\n    }\n\n    for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n        int status = s->error_status_table[mb_x + (s->mb_height - 1) * s->mb_stride];\n\n        if (status != 0x7F)\n\n            break;\n\n    }\n\n\n\n    if (   mb_x == s->mb_width\n\n        && s->avctx->codec_id == AV_CODEC_ID_MPEG2VIDEO\n\n        && (s->avctx->height&16)\n\n        && s->error_count == 3 * s->mb_width * (s->avctx->skip_top + s->avctx->skip_bottom + 1)\n\n    ) {\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"ignoring last missing slice\\n\");\n\n        return;\n\n    }\n\n\n\n    if (s->last_pic) {\n\n        if (s->last_pic->f.width  != s->cur_pic->f.width  ||\n\n            s->last_pic->f.height != s->cur_pic->f.height ||\n\n            s->last_pic->f.format != s->cur_pic->f.format) {\n\n            av_log(s->avctx, AV_LOG_WARNING, \"Cannot use previous picture in error concealment\\n\");\n\n            s->last_pic = NULL;\n\n        }\n\n    }\n\n    if (s->next_pic) {\n\n        if (s->next_pic->f.width  != s->cur_pic->f.width  ||\n\n            s->next_pic->f.height != s->cur_pic->f.height ||\n\n            s->next_pic->f.format != s->cur_pic->f.format) {\n\n            av_log(s->avctx, AV_LOG_WARNING, \"Cannot use next picture in error concealment\\n\");\n\n            s->next_pic = NULL;\n\n        }\n\n    }\n\n\n\n    if (s->cur_pic->motion_val[0] == NULL) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Warning MVs not available\\n\");\n\n\n\n        for (i = 0; i < 2; i++) {\n\n            s->cur_pic->ref_index_buf[i]  = av_buffer_allocz(s->mb_stride * s->mb_height * 4 * sizeof(uint8_t));\n\n            s->cur_pic->motion_val_buf[i] = av_buffer_allocz((size + 4) * 2 * sizeof(uint16_t));\n\n            if (!s->cur_pic->ref_index_buf[i] || !s->cur_pic->motion_val_buf[i])\n\n                break;\n\n            s->cur_pic->ref_index[i]  = s->cur_pic->ref_index_buf[i]->data;\n\n            s->cur_pic->motion_val[i] = (int16_t (*)[2])s->cur_pic->motion_val_buf[i]->data + 4;\n\n        }\n\n        if (i < 2) {\n\n            for (i = 0; i < 2; i++) {\n\n                av_buffer_unref(&s->cur_pic->ref_index_buf[i]);\n\n                av_buffer_unref(&s->cur_pic->motion_val_buf[i]);\n\n                s->cur_pic->ref_index[i]  = NULL;\n\n                s->cur_pic->motion_val[i] = NULL;\n\n            }\n\n            return;\n\n        }\n\n    }\n\n\n\n    if (s->avctx->debug & FF_DEBUG_ER) {\n\n        for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n\n            for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n                int status = s->error_status_table[mb_x + mb_y * s->mb_stride];\n\n\n\n                av_log(s->avctx, AV_LOG_DEBUG, \"%2X \", status);\n\n            }\n\n            av_log(s->avctx, AV_LOG_DEBUG, \"\\n\");\n\n        }\n\n    }\n\n\n\n#if 1\n\n    /* handle overlapping slices */\n\n    for (error_type = 1; error_type <= 3; error_type++) {\n\n        int end_ok = 0;\n\n\n\n        for (i = s->mb_num - 1; i >= 0; i--) {\n\n            const int mb_xy = s->mb_index2xy[i];\n\n            int error       = s->error_status_table[mb_xy];\n\n\n\n            if (error & (1 << error_type))\n\n                end_ok = 1;\n\n            if (error & (8 << error_type))\n\n                end_ok = 1;\n\n\n\n            if (!end_ok)\n\n                s->error_status_table[mb_xy] |= 1 << error_type;\n\n\n\n            if (error & VP_START)\n\n                end_ok = 0;\n\n        }\n\n    }\n\n#endif\n\n#if 1\n\n    /* handle slices with partitions of different length */\n\n    if (s->partitioned_frame) {\n\n        int end_ok = 0;\n\n\n\n        for (i = s->mb_num - 1; i >= 0; i--) {\n\n            const int mb_xy = s->mb_index2xy[i];\n\n            int error       = s->error_status_table[mb_xy];\n\n\n\n            if (error & ER_AC_END)\n\n                end_ok = 0;\n\n            if ((error & ER_MV_END) ||\n\n                (error & ER_DC_END) ||\n\n                (error & ER_AC_ERROR))\n\n                end_ok = 1;\n\n\n\n            if (!end_ok)\n\n                s->error_status_table[mb_xy]|= ER_AC_ERROR;\n\n\n\n            if (error & VP_START)\n\n                end_ok = 0;\n\n        }\n\n    }\n\n#endif\n\n    /* handle missing slices */\n\n    if (s->avctx->err_recognition & AV_EF_EXPLODE) {\n\n        int end_ok = 1;\n\n\n\n        // FIXME + 100 hack\n\n        for (i = s->mb_num - 2; i >= s->mb_width + 100; i--) {\n\n            const int mb_xy = s->mb_index2xy[i];\n\n            int error1 = s->error_status_table[mb_xy];\n\n            int error2 = s->error_status_table[s->mb_index2xy[i + 1]];\n\n\n\n            if (error1 & VP_START)\n\n                end_ok = 1;\n\n\n\n            if (error2 == (VP_START | ER_MB_ERROR | ER_MB_END) &&\n\n                error1 != (VP_START | ER_MB_ERROR | ER_MB_END) &&\n\n                ((error1 & ER_AC_END) || (error1 & ER_DC_END) ||\n\n                (error1 & ER_MV_END))) {\n\n                // end & uninit\n\n                end_ok = 0;\n\n            }\n\n\n\n            if (!end_ok)\n\n                s->error_status_table[mb_xy] |= ER_MB_ERROR;\n\n        }\n\n    }\n\n\n\n#if 1\n\n    /* backward mark errors */\n\n    distance = 9999999;\n\n    for (error_type = 1; error_type <= 3; error_type++) {\n\n        for (i = s->mb_num - 1; i >= 0; i--) {\n\n            const int mb_xy = s->mb_index2xy[i];\n\n            int       error = s->error_status_table[mb_xy];\n\n\n\n            if (!s->mbskip_table[mb_xy]) // FIXME partition specific\n\n                distance++;\n\n            if (error & (1 << error_type))\n\n                distance = 0;\n\n\n\n            if (s->partitioned_frame) {\n\n                if (distance < threshold_part[error_type - 1])\n\n                    s->error_status_table[mb_xy] |= 1 << error_type;\n\n            } else {\n\n                if (distance < threshold)\n\n                    s->error_status_table[mb_xy] |= 1 << error_type;\n\n            }\n\n\n\n            if (error & VP_START)\n\n                distance = 9999999;\n\n        }\n\n    }\n\n#endif\n\n\n\n    /* forward mark errors */\n\n    error = 0;\n\n    for (i = 0; i < s->mb_num; i++) {\n\n        const int mb_xy = s->mb_index2xy[i];\n\n        int old_error   = s->error_status_table[mb_xy];\n\n\n\n        if (old_error & VP_START) {\n\n            error = old_error & ER_MB_ERROR;\n\n        } else {\n\n            error |= old_error & ER_MB_ERROR;\n\n            s->error_status_table[mb_xy] |= error;\n\n        }\n\n    }\n\n#if 1\n\n    /* handle not partitioned case */\n\n    if (!s->partitioned_frame) {\n\n        for (i = 0; i < s->mb_num; i++) {\n\n            const int mb_xy = s->mb_index2xy[i];\n\n            error = s->error_status_table[mb_xy];\n\n            if (error & ER_MB_ERROR)\n\n                error |= ER_MB_ERROR;\n\n            s->error_status_table[mb_xy] = error;\n\n        }\n\n    }\n\n#endif\n\n\n\n    dc_error = ac_error = mv_error = 0;\n\n    for (i = 0; i < s->mb_num; i++) {\n\n        const int mb_xy = s->mb_index2xy[i];\n\n        error = s->error_status_table[mb_xy];\n\n        if (error & ER_DC_ERROR)\n\n            dc_error++;\n\n        if (error & ER_AC_ERROR)\n\n            ac_error++;\n\n        if (error & ER_MV_ERROR)\n\n            mv_error++;\n\n    }\n\n    av_log(s->avctx, AV_LOG_INFO, \"concealing %d DC, %d AC, %d MV errors in %c frame\\n\",\n\n           dc_error, ac_error, mv_error, av_get_picture_type_char(s->cur_pic->f.pict_type));\n\n\n\n    is_intra_likely = is_intra_more_likely(s);\n\n\n\n    /* set unknown mb-type to most likely */\n\n    for (i = 0; i < s->mb_num; i++) {\n\n        const int mb_xy = s->mb_index2xy[i];\n\n        error = s->error_status_table[mb_xy];\n\n        if (!((error & ER_DC_ERROR) && (error & ER_MV_ERROR)))\n\n            continue;\n\n\n\n        if (is_intra_likely)\n\n            s->cur_pic->mb_type[mb_xy] = MB_TYPE_INTRA4x4;\n\n        else\n\n            s->cur_pic->mb_type[mb_xy] = MB_TYPE_16x16 | MB_TYPE_L0;\n\n    }\n\n\n\n    // change inter to intra blocks if no reference frames are available\n\n    if (!(s->last_pic && s->last_pic->f.data[0]) &&\n\n        !(s->next_pic && s->next_pic->f.data[0]))\n\n        for (i = 0; i < s->mb_num; i++) {\n\n            const int mb_xy = s->mb_index2xy[i];\n\n            if (!IS_INTRA(s->cur_pic->mb_type[mb_xy]))\n\n                s->cur_pic->mb_type[mb_xy] = MB_TYPE_INTRA4x4;\n\n        }\n\n\n\n    /* handle inter blocks with damaged AC */\n\n    for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n\n        for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n            const int mb_xy   = mb_x + mb_y * s->mb_stride;\n\n            const int mb_type = s->cur_pic->mb_type[mb_xy];\n\n            const int dir     = !(s->last_pic && s->last_pic->f.data[0]);\n\n            const int mv_dir  = dir ? MV_DIR_BACKWARD : MV_DIR_FORWARD;\n\n            int mv_type;\n\n\n\n            error = s->error_status_table[mb_xy];\n\n\n\n            if (IS_INTRA(mb_type))\n\n                continue; // intra\n\n            if (error & ER_MV_ERROR)\n\n                continue; // inter with damaged MV\n\n            if (!(error & ER_AC_ERROR))\n\n                continue; // undamaged inter\n\n\n\n            if (IS_8X8(mb_type)) {\n\n                int mb_index = mb_x * 2 + mb_y * 2 * s->b8_stride;\n\n                int j;\n\n                mv_type = MV_TYPE_8X8;\n\n                for (j = 0; j < 4; j++) {\n\n                    s->mv[0][j][0] = s->cur_pic->motion_val[dir][mb_index + (j & 1) + (j >> 1) * s->b8_stride][0];\n\n                    s->mv[0][j][1] = s->cur_pic->motion_val[dir][mb_index + (j & 1) + (j >> 1) * s->b8_stride][1];\n\n                }\n\n            } else {\n\n                mv_type     = MV_TYPE_16X16;\n\n                s->mv[0][0][0] = s->cur_pic->motion_val[dir][mb_x * 2 + mb_y * 2 * s->b8_stride][0];\n\n                s->mv[0][0][1] = s->cur_pic->motion_val[dir][mb_x * 2 + mb_y * 2 * s->b8_stride][1];\n\n            }\n\n\n\n            s->decode_mb(s->opaque, 0 /* FIXME h264 partitioned slices need this set */,\n\n                         mv_dir, mv_type, &s->mv, mb_x, mb_y, 0, 0);\n\n        }\n\n    }\n\n\n\n    /* guess MVs */\n\n    if (s->cur_pic->f.pict_type == AV_PICTURE_TYPE_B) {\n\n        for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n\n            for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n                int       xy      = mb_x * 2 + mb_y * 2 * s->b8_stride;\n\n                const int mb_xy   = mb_x + mb_y * s->mb_stride;\n\n                const int mb_type = s->cur_pic->mb_type[mb_xy];\n\n                int mv_dir = MV_DIR_FORWARD | MV_DIR_BACKWARD;\n\n\n\n                error = s->error_status_table[mb_xy];\n\n\n\n                if (IS_INTRA(mb_type))\n\n                    continue;\n\n                if (!(error & ER_MV_ERROR))\n\n                    continue; // inter with undamaged MV\n\n                if (!(error & ER_AC_ERROR))\n\n                    continue; // undamaged inter\n\n\n\n                if (!(s->last_pic && s->last_pic->f.data[0]))\n\n                    mv_dir &= ~MV_DIR_FORWARD;\n\n                if (!(s->next_pic && s->next_pic->f.data[0]))\n\n                    mv_dir &= ~MV_DIR_BACKWARD;\n\n\n\n                if (s->pp_time) {\n\n                    int time_pp = s->pp_time;\n\n                    int time_pb = s->pb_time;\n\n\n\n                    av_assert0(s->avctx->codec_id != AV_CODEC_ID_H264);\n\n                    ff_thread_await_progress(&s->next_pic->tf, mb_y, 0);\n\n\n\n                    s->mv[0][0][0] = s->next_pic->motion_val[0][xy][0] *  time_pb            / time_pp;\n\n                    s->mv[0][0][1] = s->next_pic->motion_val[0][xy][1] *  time_pb            / time_pp;\n\n                    s->mv[1][0][0] = s->next_pic->motion_val[0][xy][0] * (time_pb - time_pp) / time_pp;\n\n                    s->mv[1][0][1] = s->next_pic->motion_val[0][xy][1] * (time_pb - time_pp) / time_pp;\n\n                } else {\n\n                    s->mv[0][0][0] = 0;\n\n                    s->mv[0][0][1] = 0;\n\n                    s->mv[1][0][0] = 0;\n\n                    s->mv[1][0][1] = 0;\n\n                }\n\n\n\n                s->decode_mb(s->opaque, 0, mv_dir, MV_TYPE_16X16, &s->mv,\n\n                             mb_x, mb_y, 0, 0);\n\n            }\n\n        }\n\n    } else\n\n        guess_mv(s);\n\n\n\n#if FF_API_XVMC\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    /* the filters below are not XvMC compatible, skip them */\n\n    if (CONFIG_MPEG_XVMC_DECODER && s->avctx->xvmc_acceleration)\n\n        goto ec_clean;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif /* FF_API_XVMC */\n\n    /* fill DC for inter blocks */\n\n    for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n\n        for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n            int dc, dcu, dcv, y, n;\n\n            int16_t *dc_ptr;\n\n            uint8_t *dest_y, *dest_cb, *dest_cr;\n\n            const int mb_xy   = mb_x + mb_y * s->mb_stride;\n\n            const int mb_type = s->cur_pic->mb_type[mb_xy];\n\n\n\n            error = s->error_status_table[mb_xy];\n\n\n\n            if (IS_INTRA(mb_type) && s->partitioned_frame)\n\n                continue;\n\n            // if (error & ER_MV_ERROR)\n\n            //     continue; // inter data damaged FIXME is this good?\n\n\n\n            dest_y  = s->cur_pic->f.data[0] + mb_x * 16 + mb_y * 16 * linesize[0];\n\n            dest_cb = s->cur_pic->f.data[1] + mb_x *  8 + mb_y *  8 * linesize[1];\n\n            dest_cr = s->cur_pic->f.data[2] + mb_x *  8 + mb_y *  8 * linesize[2];\n\n\n\n            dc_ptr = &s->dc_val[0][mb_x * 2 + mb_y * 2 * s->b8_stride];\n\n            for (n = 0; n < 4; n++) {\n\n                dc = 0;\n\n                for (y = 0; y < 8; y++) {\n\n                    int x;\n\n                    for (x = 0; x < 8; x++)\n\n                       dc += dest_y[x + (n & 1) * 8 +\n\n                             (y + (n >> 1) * 8) * linesize[0]];\n\n                }\n\n                dc_ptr[(n & 1) + (n >> 1) * s->b8_stride] = (dc + 4) >> 3;\n\n            }\n\n\n\n            dcu = dcv = 0;\n\n            for (y = 0; y < 8; y++) {\n\n                int x;\n\n                for (x = 0; x < 8; x++) {\n\n                    dcu += dest_cb[x + y * linesize[1]];\n\n                    dcv += dest_cr[x + y * linesize[2]];\n\n                }\n\n            }\n\n            s->dc_val[1][mb_x + mb_y * s->mb_stride] = (dcu + 4) >> 3;\n\n            s->dc_val[2][mb_x + mb_y * s->mb_stride] = (dcv + 4) >> 3;\n\n        }\n\n    }\n\n#if 1\n\n    /* guess DC for damaged blocks */\n\n    guess_dc(s, s->dc_val[0], s->mb_width*2, s->mb_height*2, s->b8_stride, 1);\n\n    guess_dc(s, s->dc_val[1], s->mb_width  , s->mb_height  , s->mb_stride, 0);\n\n    guess_dc(s, s->dc_val[2], s->mb_width  , s->mb_height  , s->mb_stride, 0);\n\n#endif\n\n\n\n    /* filter luma DC */\n\n    filter181(s->dc_val[0], s->mb_width * 2, s->mb_height * 2, s->b8_stride);\n\n\n\n#if 1\n\n    /* render DC only intra */\n\n    for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n\n        for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n            uint8_t *dest_y, *dest_cb, *dest_cr;\n\n            const int mb_xy   = mb_x + mb_y * s->mb_stride;\n\n            const int mb_type = s->cur_pic->mb_type[mb_xy];\n\n\n\n            error = s->error_status_table[mb_xy];\n\n\n\n            if (IS_INTER(mb_type))\n\n                continue;\n\n            if (!(error & ER_AC_ERROR))\n\n                continue; // undamaged\n\n\n\n            dest_y  = s->cur_pic->f.data[0] + mb_x * 16 + mb_y * 16 * linesize[0];\n\n            dest_cb = s->cur_pic->f.data[1] + mb_x *  8 + mb_y *  8 * linesize[1];\n\n            dest_cr = s->cur_pic->f.data[2] + mb_x *  8 + mb_y *  8 * linesize[2];\n\n\n\n            put_dc(s, dest_y, dest_cb, dest_cr, mb_x, mb_y);\n\n        }\n\n    }\n\n#endif\n\n\n\n    if (s->avctx->error_concealment & FF_EC_DEBLOCK) {\n\n        /* filter horizontal block boundaries */\n\n        h_block_filter(s, s->cur_pic->f.data[0], s->mb_width * 2,\n\n                       s->mb_height * 2, linesize[0], 1);\n\n        h_block_filter(s, s->cur_pic->f.data[1], s->mb_width,\n\n                       s->mb_height, linesize[1], 0);\n\n        h_block_filter(s, s->cur_pic->f.data[2], s->mb_width,\n\n                       s->mb_height, linesize[2], 0);\n\n\n\n        /* filter vertical block boundaries */\n\n        v_block_filter(s, s->cur_pic->f.data[0], s->mb_width * 2,\n\n                       s->mb_height * 2, linesize[0], 1);\n\n        v_block_filter(s, s->cur_pic->f.data[1], s->mb_width,\n\n                       s->mb_height, linesize[1], 0);\n\n        v_block_filter(s, s->cur_pic->f.data[2], s->mb_width,\n\n                       s->mb_height, linesize[2], 0);\n\n    }\n\n\n\nec_clean:\n\n    /* clean a few tables */\n\n    for (i = 0; i < s->mb_num; i++) {\n\n        const int mb_xy = s->mb_index2xy[i];\n\n        int       error = s->error_status_table[mb_xy];\n\n\n\n        if (s->cur_pic->f.pict_type != AV_PICTURE_TYPE_B &&\n\n            (error & (ER_DC_ERROR | ER_MV_ERROR | ER_AC_ERROR))) {\n\n            s->mbskip_table[mb_xy] = 0;\n\n        }\n\n        s->mbintra_table[mb_xy] = 1;\n\n    }\n\n    s->cur_pic = NULL;\n\n    s->next_pic    = NULL;\n\n    s->last_pic    = NULL;\n\n}\n", "idx": 22943}
{"project": "FFmpeg", "commit_id": "e3e6a2cff4af9542455d416faec4584d5e823d5d", "target": 1, "func": "static void create_default_qtables(uint8_t *qtables, uint8_t q)\n\n{\n\n    int factor = q;\n\n    int i;\n\n\n\n    factor = av_clip(q, 1, 99);\n\n\n\n    if (q < 50)\n\n        q = 5000 / factor;\n\n    else\n\n        q = 200 - factor * 2;\n\n\n\n    for (i = 0; i < 128; i++) {\n\n        int val = (default_quantizers[i] * q + 50) / 100;\n\n\n\n        /* Limit the quantizers to 1 <= q <= 255. */\n\n        val = av_clip(val, 1, 255);\n\n        qtables[i] = val;\n\n    }\n\n}\n", "idx": 22944}
{"project": "FFmpeg", "commit_id": "cd523888f304d297bb7dec5d358d0ee92576cc44", "target": 0, "func": "void ff_acelp_weighted_filter(\n\n        int16_t *out,\n\n        const int16_t* in,\n\n        const int16_t *weight_pow,\n\n        int filter_length)\n\n{\n\n    int n;\n\n    for(n=0; n<filter_length; n++)\n\n        out[n] = (in[n] * weight_pow[n] + 0x4000) >> 15; /* (3.12) = (0.15) * (3.12) with rounding */\n\n}\n", "idx": 22946}
{"project": "FFmpeg", "commit_id": "28f9ab7029bd1a02f659995919f899f84ee7361b", "target": 0, "func": "void ff_vp3_idct_c(DCTELEM *block/* align 16*/){\n\n    idct(NULL, 0, block, 0);\n\n}\n", "idx": 22947}
{"project": "FFmpeg", "commit_id": "591944cd0c4f10ddf0eaee9298553633e12a26d0", "target": 0, "func": "static int seq_fill_buffer(SeqDemuxContext *seq, ByteIOContext *pb, int buffer_num, unsigned int data_offs, int data_size)\n\n{\n\n    TiertexSeqFrameBuffer *seq_buffer;\n\n\n\n    if (buffer_num >= SEQ_NUM_FRAME_BUFFERS)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    seq_buffer = &seq->frame_buffers[buffer_num];\n\n    if (seq_buffer->fill_size + data_size > seq_buffer->data_size)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    url_fseek(pb, seq->current_frame_offs + data_offs, SEEK_SET);\n\n    if (get_buffer(pb, seq_buffer->data + seq_buffer->fill_size, data_size) != data_size)\n\n        return AVERROR(EIO);\n\n\n\n    seq_buffer->fill_size += data_size;\n\n    return 0;\n\n}\n", "idx": 22948}
{"project": "FFmpeg", "commit_id": "36583d23bdbe31e8845d3ca9162bce33fef6e48c", "target": 0, "func": "void ff_af_queue_close(AudioFrameQueue *afq)\n\n{\n\n    /* remove/free any remaining frames */\n\n    while (afq->frame_queue)\n\n        delete_next_frame(afq);\n\n    memset(afq, 0, sizeof(*afq));\n\n}\n", "idx": 22949}
{"project": "FFmpeg", "commit_id": "dd561441b1e849df7d8681c6f32af82d4088dafd", "target": 0, "func": "static av_always_inline av_flatten void h264_loop_filter_luma_c(uint8_t *pix, int xstride, int ystride, int alpha, int beta, int8_t *tc0)\n\n{\n\n    int i, d;\n\n    for( i = 0; i < 4; i++ ) {\n\n        if( tc0[i] < 0 ) {\n\n            pix += 4*ystride;\n\n            continue;\n\n        }\n\n        for( d = 0; d < 4; d++ ) {\n\n            const int p0 = pix[-1*xstride];\n\n            const int p1 = pix[-2*xstride];\n\n            const int p2 = pix[-3*xstride];\n\n            const int q0 = pix[0];\n\n            const int q1 = pix[1*xstride];\n\n            const int q2 = pix[2*xstride];\n\n\n\n            if( FFABS( p0 - q0 ) < alpha &&\n\n                FFABS( p1 - p0 ) < beta &&\n\n                FFABS( q1 - q0 ) < beta ) {\n\n\n\n                int tc = tc0[i];\n\n                int i_delta;\n\n\n\n                if( FFABS( p2 - p0 ) < beta ) {\n\n                    if(tc0[i])\n\n                    pix[-2*xstride] = p1 + av_clip( (( p2 + ( ( p0 + q0 + 1 ) >> 1 ) ) >> 1) - p1, -tc0[i], tc0[i] );\n\n                    tc++;\n\n                }\n\n                if( FFABS( q2 - q0 ) < beta ) {\n\n                    if(tc0[i])\n\n                    pix[   xstride] = q1 + av_clip( (( q2 + ( ( p0 + q0 + 1 ) >> 1 ) ) >> 1) - q1, -tc0[i], tc0[i] );\n\n                    tc++;\n\n                }\n\n\n\n                i_delta = av_clip( (((q0 - p0 ) << 2) + (p1 - q1) + 4) >> 3, -tc, tc );\n\n                pix[-xstride] = av_clip_uint8( p0 + i_delta );    /* p0' */\n\n                pix[0]        = av_clip_uint8( q0 - i_delta );    /* q0' */\n\n            }\n\n            pix += ystride;\n\n        }\n\n    }\n\n}\n", "idx": 22950}
{"project": "FFmpeg", "commit_id": "ec4c48397641dbaf4ae8df36c32aaa5a311a11bf", "target": 1, "func": "static int io_open_default(AVFormatContext *s, AVIOContext **pb,\n\n                           const char *url, int flags, AVDictionary **options)\n\n{\n\n    return avio_open2(pb, url, flags, &s->interrupt_callback, options);\n\n}\n", "idx": 22951}
{"project": "FFmpeg", "commit_id": "d0393d79bc3d61c9f2ff832c0e273b7774ff0269", "target": 1, "func": "static int read_huffman_tables(HYuvContext *s, const uint8_t *src, int length)\n\n{\n\n    GetBitContext gb;\n\n    int i;\n\n\n\n    init_get_bits(&gb, src, length * 8);\n\n\n\n    for (i = 0; i < 3; i++) {\n\n        if (read_len_table(s->len[i], &gb) < 0)\n\n            return -1;\n\n        if (ff_huffyuv_generate_bits_table(s->bits[i], s->len[i]) < 0)\n\n            return -1;\n\n        ff_free_vlc(&s->vlc[i]);\n\n        init_vlc(&s->vlc[i], VLC_BITS, 256, s->len[i], 1, 1,\n\n                 s->bits[i], 4, 4, 0);\n\n    }\n\n\n\n    generate_joint_tables(s);\n\n\n\n    return (get_bits_count(&gb) + 7) / 8;\n\n}\n", "idx": 22952}
{"project": "FFmpeg", "commit_id": "190a0998c353879c8f79f47678752dbb8fa62bb2", "target": 1, "func": "int ff_pnm_decode_header(AVCodecContext *avctx, PNMContext * const s)\n\n{\n\n    char buf1[32], tuple_type[32];\n\n    int h, w, depth, maxval;\n\n\n\n    pnm_get(s, buf1, sizeof(buf1));\n\n    s->type= buf1[1]-'0';\n\n    if(buf1[0] != 'P')\n\n        return -1;\n\n\n\n    if (s->type==1 || s->type==4) {\n\n        avctx->pix_fmt = PIX_FMT_MONOWHITE;\n\n    } else if (s->type==2 || s->type==5) {\n\n        if (avctx->codec_id == CODEC_ID_PGMYUV)\n\n            avctx->pix_fmt = PIX_FMT_YUV420P;\n\n        else\n\n            avctx->pix_fmt = PIX_FMT_GRAY8;\n\n    } else if (s->type==3 || s->type==6) {\n\n        avctx->pix_fmt = PIX_FMT_RGB24;\n\n    } else if (s->type==7) {\n\n        w      = -1;\n\n        h      = -1;\n\n        maxval = -1;\n\n        depth  = -1;\n\n        tuple_type[0] = '\\0';\n\n        for (;;) {\n\n            pnm_get(s, buf1, sizeof(buf1));\n\n            if (!strcmp(buf1, \"WIDTH\")) {\n\n                pnm_get(s, buf1, sizeof(buf1));\n\n                w = strtol(buf1, NULL, 10);\n\n            } else if (!strcmp(buf1, \"HEIGHT\")) {\n\n                pnm_get(s, buf1, sizeof(buf1));\n\n                h = strtol(buf1, NULL, 10);\n\n            } else if (!strcmp(buf1, \"DEPTH\")) {\n\n                pnm_get(s, buf1, sizeof(buf1));\n\n                depth = strtol(buf1, NULL, 10);\n\n            } else if (!strcmp(buf1, \"MAXVAL\")) {\n\n                pnm_get(s, buf1, sizeof(buf1));\n\n                maxval = strtol(buf1, NULL, 10);\n\n            } else if (!strcmp(buf1, \"TUPLTYPE\") ||\n\n            // FFmpeg used to write invalid files\n\n                       !strcmp(buf1, \"TUPLETYPE\")) {\n\n                pnm_get(s, tuple_type, sizeof(tuple_type));\n\n            } else if (!strcmp(buf1, \"ENDHDR\")) {\n\n                break;\n\n            } else {\n\n                return -1;\n\n            }\n\n        }\n\n        /* check that all tags are present */\n\n        if (w <= 0 || h <= 0 || maxval <= 0 || depth <= 0 || tuple_type[0] == '\\0' || av_image_check_size(w, h, 0, avctx))\n\n            return -1;\n\n\n\n        avctx->width  = w;\n\n        avctx->height = h;\n\n\n        if (depth == 1) {\n\n            if (maxval == 1)\n\n                avctx->pix_fmt = PIX_FMT_MONOWHITE;\n\n            else\n\n                avctx->pix_fmt = PIX_FMT_GRAY8;\n\n        } else if (depth == 3) {\n\n            if (maxval < 256) {\n\n            avctx->pix_fmt = PIX_FMT_RGB24;\n\n            } else {\n\n                av_log(avctx, AV_LOG_ERROR, \"16-bit components are only supported for grayscale\\n\");\n\n                avctx->pix_fmt = PIX_FMT_NONE;\n\n                return -1;\n\n            }\n\n        } else if (depth == 4) {\n\n            avctx->pix_fmt = PIX_FMT_RGB32;\n\n        } else {\n\n            return -1;\n\n        }\n\n        return 0;\n\n    } else {\n\n        return -1;\n\n    }\n\n    pnm_get(s, buf1, sizeof(buf1));\n\n    avctx->width = atoi(buf1);\n\n    if (avctx->width <= 0)\n\n        return -1;\n\n    pnm_get(s, buf1, sizeof(buf1));\n\n    avctx->height = atoi(buf1);\n\n    if(avctx->height <= 0 || av_image_check_size(avctx->width, avctx->height, 0, avctx))\n\n        return -1;\n\n    if (avctx->pix_fmt != PIX_FMT_MONOWHITE) {\n\n        pnm_get(s, buf1, sizeof(buf1));\n\n        s->maxval = atoi(buf1);\n\n        if (s->maxval <= 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Invalid maxval: %d\\n\", s->maxval);\n\n            s->maxval = 255;\n\n        }\n\n        if (s->maxval >= 256) {\n\n            if (avctx->pix_fmt == PIX_FMT_GRAY8) {\n\n                avctx->pix_fmt = PIX_FMT_GRAY16BE;\n\n                if (s->maxval != 65535)\n\n                    avctx->pix_fmt = PIX_FMT_GRAY16;\n\n            } else if (avctx->pix_fmt == PIX_FMT_RGB24) {\n\n                if (s->maxval > 255)\n\n                    avctx->pix_fmt = PIX_FMT_RGB48BE;\n\n            } else {\n\n                av_log(avctx, AV_LOG_ERROR, \"Unsupported pixel format\\n\");\n\n                avctx->pix_fmt = PIX_FMT_NONE;\n\n                return -1;\n\n            }\n\n        }\n\n    }else\n\n        s->maxval=1;\n\n    /* more check if YUV420 */\n\n    if (avctx->pix_fmt == PIX_FMT_YUV420P) {\n\n        if ((avctx->width & 1) != 0)\n\n            return -1;\n\n        h = (avctx->height * 2);\n\n        if ((h % 3) != 0)\n\n            return -1;\n\n        h /= 3;\n\n        avctx->height = h;\n\n    }\n\n    return 0;\n\n}", "idx": 22953}
{"project": "FFmpeg", "commit_id": "81cc7d0bd1eab0aa782ff8dd49e087025a42cdee", "target": 1, "func": "static void lumRangeToJpeg16_c(int16_t *_dst, int width)\n\n{\n\n    int i;\n\n    int32_t *dst = (int32_t *) _dst;\n\n    for (i = 0; i < width; i++)\n\n        dst[i] = (FFMIN(dst[i],30189<<4)*19077 - (39057361<<4))>>14;\n\n}\n", "idx": 22955}
{"project": "FFmpeg", "commit_id": "1f80742f49a9a4e846c9f099387881abc87150b2", "target": 1, "func": "static void fill_coding_method_array(sb_int8_array tone_level_idx,\n\n                                     sb_int8_array tone_level_idx_temp,\n\n                                     sb_int8_array coding_method,\n\n                                     int nb_channels,\n\n                                     int c, int superblocktype_2_3,\n\n                                     int cm_table_select)\n\n{\n\n    int ch, sb, j;\n\n    int tmp, acc, esp_40, comp;\n\n    int add1, add2, add3, add4;\n\n    int64_t multres;\n\n\n\n    if (!superblocktype_2_3) {\n\n        /* This case is untested, no samples available */\n\n        SAMPLES_NEEDED\n\n        for (ch = 0; ch < nb_channels; ch++)\n\n            for (sb = 0; sb < 30; sb++) {\n\n                for (j = 1; j < 63; j++) {  // The loop only iterates to 63 so the code doesn't overflow the buffer\n\n                    add1 = tone_level_idx[ch][sb][j] - 10;\n\n                    if (add1 < 0)\n\n                        add1 = 0;\n\n                    add2 = add3 = add4 = 0;\n\n                    if (sb > 1) {\n\n                        add2 = tone_level_idx[ch][sb - 2][j] + tone_level_idx_offset_table[sb][0] - 6;\n\n                        if (add2 < 0)\n\n                            add2 = 0;\n\n                    }\n\n                    if (sb > 0) {\n\n                        add3 = tone_level_idx[ch][sb - 1][j] + tone_level_idx_offset_table[sb][1] - 6;\n\n                        if (add3 < 0)\n\n                            add3 = 0;\n\n                    }\n\n                    if (sb < 29) {\n\n                        add4 = tone_level_idx[ch][sb + 1][j] + tone_level_idx_offset_table[sb][3] - 6;\n\n                        if (add4 < 0)\n\n                            add4 = 0;\n\n                    }\n\n                    tmp = tone_level_idx[ch][sb][j + 1] * 2 - add4 - add3 - add2 - add1;\n\n                    if (tmp < 0)\n\n                        tmp = 0;\n\n                    tone_level_idx_temp[ch][sb][j + 1] = tmp & 0xff;\n\n                }\n\n                tone_level_idx_temp[ch][sb][0] = tone_level_idx_temp[ch][sb][1];\n\n            }\n\n            acc = 0;\n\n            for (ch = 0; ch < nb_channels; ch++)\n\n                for (sb = 0; sb < 30; sb++)\n\n                    for (j = 0; j < 64; j++)\n\n                        acc += tone_level_idx_temp[ch][sb][j];\n\n\n\n            multres = 0x66666667 * (acc * 10);\n\n            esp_40 = (multres >> 32) / 8 + ((multres & 0xffffffff) >> 31);\n\n            for (ch = 0;  ch < nb_channels; ch++)\n\n                for (sb = 0; sb < 30; sb++)\n\n                    for (j = 0; j < 64; j++) {\n\n                        comp = tone_level_idx_temp[ch][sb][j]* esp_40 * 10;\n\n                        if (comp < 0)\n\n                            comp += 0xff;\n\n                        comp /= 256; // signed shift\n\n                        switch(sb) {\n\n                            case 0:\n\n                                if (comp < 30)\n\n                                    comp = 30;\n\n                                comp += 15;\n\n                                break;\n\n                            case 1:\n\n                                if (comp < 24)\n\n                                    comp = 24;\n\n                                comp += 10;\n\n                                break;\n\n                            case 2:\n\n                            case 3:\n\n                            case 4:\n\n                                if (comp < 16)\n\n                                    comp = 16;\n\n                        }\n\n                        if (comp <= 5)\n\n                            tmp = 0;\n\n                        else if (comp <= 10)\n\n                            tmp = 10;\n\n                        else if (comp <= 16)\n\n                            tmp = 16;\n\n                        else if (comp <= 24)\n\n                            tmp = -1;\n\n                        else\n\n                            tmp = 0;\n\n                        coding_method[ch][sb][j] = ((tmp & 0xfffa) + 30 )& 0xff;\n\n                    }\n\n            for (sb = 0; sb < 30; sb++)\n\n                fix_coding_method_array(sb, nb_channels, coding_method);\n\n            for (ch = 0; ch < nb_channels; ch++)\n\n                for (sb = 0; sb < 30; sb++)\n\n                    for (j = 0; j < 64; j++)\n\n                        if (sb >= 10) {\n\n                            if (coding_method[ch][sb][j] < 10)\n\n                                coding_method[ch][sb][j] = 10;\n\n                        } else {\n\n                            if (sb >= 2) {\n\n                                if (coding_method[ch][sb][j] < 16)\n\n                                    coding_method[ch][sb][j] = 16;\n\n                            } else {\n\n                                if (coding_method[ch][sb][j] < 30)\n\n                                    coding_method[ch][sb][j] = 30;\n\n                            }\n\n                        }\n\n    } else { // superblocktype_2_3 != 0\n\n        for (ch = 0; ch < nb_channels; ch++)\n\n            for (sb = 0; sb < 30; sb++)\n\n                for (j = 0; j < 64; j++)\n\n                    coding_method[ch][sb][j] = coding_method_table[cm_table_select][sb];\n\n    }\n\n}\n", "idx": 22956}
{"project": "FFmpeg", "commit_id": "189fbcede89bb5d7ec6c3b05d1e30f1bab3a060a", "target": 0, "func": "static int tak_parse(AVCodecParserContext *s, AVCodecContext *avctx,\n\n                     const uint8_t **poutbuf, int *poutbuf_size,\n\n                     const uint8_t *buf, int buf_size)\n\n{\n\n    TAKParseContext *t = s->priv_data;\n\n    ParseContext *pc = &t->pc;\n\n    int next = END_NOT_FOUND;\n\n    GetBitContext gb;\n\n    int consumed = 0;\n\n    int needed = buf_size ? TAK_MAX_FRAME_HEADER_BYTES : 8;\n\n\n\n    if (s->flags & PARSER_FLAG_COMPLETE_FRAMES) {\n\n        TAKStreamInfo ti;\n\n        init_get_bits(&gb, buf, buf_size);\n\n        if (!ff_tak_decode_frame_header(avctx, &gb, &ti, 127))\n\n            s->duration = t->ti.last_frame_samples ? t->ti.last_frame_samples :\n\n                                                     t->ti.frame_samples;\n\n        *poutbuf      = buf;\n\n        *poutbuf_size = buf_size;\n\n        return buf_size;\n\n    }\n\n\n\n    while (buf_size || t->index + needed <= pc->index) {\n\n        if (buf_size && t->index + TAK_MAX_FRAME_HEADER_BYTES > pc->index) {\n\n            int tmp_buf_size = FFMIN(2 * TAK_MAX_FRAME_HEADER_BYTES, buf_size);\n\n            const uint8_t *tmp_buf = buf;\n\n\n\n            ff_combine_frame(pc, END_NOT_FOUND, &tmp_buf, &tmp_buf_size);\n\n            consumed += tmp_buf_size;\n\n            buf      += tmp_buf_size;\n\n            buf_size -= tmp_buf_size;\n\n        }\n\n\n\n        for (; t->index + needed <= pc->index; t->index++) {\n\n            if (pc->buffer[ t->index     ] == 0xFF &&\n\n                pc->buffer[ t->index + 1 ] == 0xA0) {\n\n                TAKStreamInfo ti;\n\n\n\n                init_get_bits(&gb, pc->buffer + t->index,\n\n                              8 * (pc->index - t->index));\n\n                if (!ff_tak_decode_frame_header(avctx, &gb,\n\n                        pc->frame_start_found ? &ti : &t->ti, 127) &&\n\n                    !ff_tak_check_crc(pc->buffer + t->index,\n\n                                      get_bits_count(&gb) / 8)) {\n\n                    if (!pc->frame_start_found) {\n\n                        pc->frame_start_found = 1;\n\n                        s->duration = t->ti.last_frame_samples ?\n\n                                      t->ti.last_frame_samples :\n\n                                      t->ti.frame_samples;\n\n                    } else {\n\n                        pc->frame_start_found = 0;\n\n                        next = t->index - pc->index;\n\n                        t->index = 0;\n\n                        goto found;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\nfound:\n\n\n\n    if (consumed && !buf_size && next == END_NOT_FOUND ||\n\n        ff_combine_frame(pc, next, &buf, &buf_size) < 0) {\n\n        *poutbuf      = NULL;\n\n        *poutbuf_size = 0;\n\n        return buf_size + consumed;\n\n    }\n\n\n\n    if (next != END_NOT_FOUND) {\n\n        next += consumed;\n\n        pc->overread = FFMAX(0, -next);\n\n    }\n\n\n\n    *poutbuf      = buf;\n\n    *poutbuf_size = buf_size;\n\n    return next;\n\n}\n", "idx": 22958}
{"project": "FFmpeg", "commit_id": "9ec39937f9c7f28a2279a19f71f290d8161eb52f", "target": 1, "func": "static void find_motion(DeshakeContext *deshake, uint8_t *src1, uint8_t *src2,\n\n                        int width, int height, int stride, Transform *t)\n\n{\n\n    int x, y;\n\n    IntMotionVector mv = {0, 0};\n\n    int counts[128][128];\n\n    int count_max_value = 0;\n\n    int contrast;\n\n\n\n    int pos;\n\n    double *angles = av_malloc(sizeof(*angles) * width * height / (16 * deshake->blocksize));\n\n    int center_x = 0, center_y = 0;\n\n    double p_x, p_y;\n\n\n\n    // Reset counts to zero\n\n    for (x = 0; x < deshake->rx * 2 + 1; x++) {\n\n        for (y = 0; y < deshake->ry * 2 + 1; y++) {\n\n            counts[x][y] = 0;\n\n        }\n\n    }\n\n\n\n    pos = 0;\n\n    // Find motion for every block and store the motion vector in the counts\n\n    for (y = deshake->ry; y < height - deshake->ry - (deshake->blocksize * 2); y += deshake->blocksize * 2) {\n\n        // We use a width of 16 here to match the libavcodec sad functions\n\n        for (x = deshake->rx; x < width - deshake->rx - 16; x += 16) {\n\n            // If the contrast is too low, just skip this block as it probably\n\n            // won't be very useful to us.\n\n            contrast = block_contrast(src2, x, y, stride, deshake->blocksize);\n\n            if (contrast > deshake->contrast) {\n\n                //av_log(NULL, AV_LOG_ERROR, \"%d\\n\", contrast);\n\n                find_block_motion(deshake, src1, src2, x, y, stride, &mv);\n\n                if (mv.x != -1 && mv.y != -1) {\n\n                    counts[mv.x + deshake->rx][mv.y + deshake->ry] += 1;\n\n                    if (x > deshake->rx && y > deshake->ry)\n\n                        angles[pos++] = block_angle(x, y, 0, 0, &mv);\n\n\n\n                    center_x += mv.x;\n\n                    center_y += mv.y;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    pos = FFMAX(1, pos);\n\n\n\n    center_x /= pos;\n\n    center_y /= pos;\n\n\n\n    t->angle = clean_mean(angles, pos);\n\n    if (t->angle < 0.001)\n\n        t->angle = 0;\n\n\n\n    // Find the most common motion vector in the frame and use it as the gmv\n\n    for (y = deshake->ry * 2; y >= 0; y--) {\n\n        for (x = 0; x < deshake->rx * 2 + 1; x++) {\n\n            //av_log(NULL, AV_LOG_ERROR, \"%5d \", counts[x][y]);\n\n            if (counts[x][y] > count_max_value) {\n\n                t->vector.x = x - deshake->rx;\n\n                t->vector.y = y - deshake->ry;\n\n                count_max_value = counts[x][y];\n\n            }\n\n        }\n\n        //av_log(NULL, AV_LOG_ERROR, \"\\n\");\n\n    }\n\n\n\n    p_x = (center_x - width / 2);\n\n    p_y = (center_y - height / 2);\n\n    t->vector.x += (cos(t->angle)-1)*p_x  - sin(t->angle)*p_y;\n\n    t->vector.y += sin(t->angle)*p_x  + (cos(t->angle)-1)*p_y;\n\n\n\n    // Clamp max shift & rotation?\n\n    t->vector.x = av_clipf(t->vector.x, -deshake->rx * 2, deshake->rx * 2);\n\n    t->vector.y = av_clipf(t->vector.y, -deshake->ry * 2, deshake->ry * 2);\n\n    t->angle = av_clipf(t->angle, -0.1, 0.1);\n\n\n\n    //av_log(NULL, AV_LOG_ERROR, \"%d x %d\\n\", avg->x, avg->y);\n\n    av_free(angles);\n\n}\n", "idx": 22959}
{"project": "FFmpeg", "commit_id": "e3e6f18f1693a99c1e26e7e2ff109b2a4de9c51e", "target": 0, "func": "static int decode_ref_pic_list_reordering(H264Context *h){\n\n    MpegEncContext * const s = &h->s;\n\n    int list, index, pic_structure;\n\n\n\n    print_short_term(h);\n\n    print_long_term(h);\n\n    if(h->slice_type==FF_I_TYPE || h->slice_type==FF_SI_TYPE) return 0; //FIXME move before func\n\n\n\n    for(list=0; list<h->list_count; list++){\n\n        memcpy(h->ref_list[list], h->default_ref_list[list], sizeof(Picture)*h->ref_count[list]);\n\n\n\n        if(get_bits1(&s->gb)){\n\n            int pred= h->curr_pic_num;\n\n\n\n            for(index=0; ; index++){\n\n                unsigned int reordering_of_pic_nums_idc= get_ue_golomb(&s->gb);\n\n                unsigned int pic_id;\n\n                int i;\n\n                Picture *ref = NULL;\n\n\n\n                if(reordering_of_pic_nums_idc==3)\n\n                    break;\n\n\n\n                if(index >= h->ref_count[list]){\n\n                    av_log(h->s.avctx, AV_LOG_ERROR, \"reference count overflow\\n\");\n\n                    return -1;\n\n                }\n\n\n\n                if(reordering_of_pic_nums_idc<3){\n\n                    if(reordering_of_pic_nums_idc<2){\n\n                        const unsigned int abs_diff_pic_num= get_ue_golomb(&s->gb) + 1;\n\n                        int frame_num;\n\n\n\n                        if(abs_diff_pic_num > h->max_pic_num){\n\n                            av_log(h->s.avctx, AV_LOG_ERROR, \"abs_diff_pic_num overflow\\n\");\n\n                            return -1;\n\n                        }\n\n\n\n                        if(reordering_of_pic_nums_idc == 0) pred-= abs_diff_pic_num;\n\n                        else                                pred+= abs_diff_pic_num;\n\n                        pred &= h->max_pic_num - 1;\n\n\n\n                        frame_num = pic_num_extract(h, pred, &pic_structure);\n\n\n\n                        for(i= h->short_ref_count-1; i>=0; i--){\n\n                            ref = h->short_ref[i];\n\n                            assert(ref->reference);\n\n                            assert(!ref->long_ref);\n\n                            if(ref->data[0] != NULL &&\n\n                                   ref->frame_num == frame_num &&\n\n                                   (ref->reference & pic_structure) &&\n\n                                   ref->long_ref == 0) // ignore non existing pictures by testing data[0] pointer\n\n                                break;\n\n                        }\n\n                        if(i>=0)\n\n                            ref->pic_id= pred;\n\n                    }else{\n\n                        int long_idx;\n\n                        pic_id= get_ue_golomb(&s->gb); //long_term_pic_idx\n\n\n\n                        long_idx= pic_num_extract(h, pic_id, &pic_structure);\n\n\n\n                        if(long_idx>31){\n\n                            av_log(h->s.avctx, AV_LOG_ERROR, \"long_term_pic_idx overflow\\n\");\n\n                            return -1;\n\n                        }\n\n                        ref = h->long_ref[long_idx];\n\n                        assert(!(ref && !ref->reference));\n\n                        if(ref && (ref->reference & pic_structure)){\n\n                            ref->pic_id= pic_id;\n\n                            assert(ref->long_ref);\n\n                            i=0;\n\n                        }else{\n\n                            i=-1;\n\n                        }\n\n                    }\n\n\n\n                    if (i < 0) {\n\n                        av_log(h->s.avctx, AV_LOG_ERROR, \"reference picture missing during reorder\\n\");\n\n                        memset(&h->ref_list[list][index], 0, sizeof(Picture)); //FIXME\n\n                    } else {\n\n                        for(i=index; i+1<h->ref_count[list]; i++){\n\n                            if(ref->long_ref == h->ref_list[list][i].long_ref && ref->pic_id == h->ref_list[list][i].pic_id)\n\n                                break;\n\n                        }\n\n                        for(; i > index; i--){\n\n                            h->ref_list[list][i]= h->ref_list[list][i-1];\n\n                        }\n\n                        h->ref_list[list][index]= *ref;\n\n                        if (FIELD_PICTURE){\n\n                            pic_as_field(&h->ref_list[list][index], pic_structure);\n\n                        }\n\n                    }\n\n                }else{\n\n                    av_log(h->s.avctx, AV_LOG_ERROR, \"illegal reordering_of_pic_nums_idc\\n\");\n\n                    return -1;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    for(list=0; list<h->list_count; list++){\n\n        for(index= 0; index < h->ref_count[list]; index++){\n\n            if(!h->ref_list[list][index].data[0])\n\n                h->ref_list[list][index]= s->current_picture;\n\n        }\n\n    }\n\n\n\n    if(h->slice_type==FF_B_TYPE && !h->direct_spatial_mv_pred)\n\n        direct_dist_scale_factor(h);\n\n    direct_ref_list_init(h);\n\n    return 0;\n\n}\n", "idx": 22961}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int X264_close(AVCodecContext *avctx)\n\n{\n\n    X264Context *x4 = avctx->priv_data;\n\n\n\n    av_freep(&avctx->extradata);\n\n    av_freep(&x4->sei);\n\n\n\n    if (x4->enc) {\n\n        x264_encoder_close(x4->enc);\n\n        x4->enc = NULL;\n\n    }\n\n\n\n    av_frame_free(&avctx->coded_frame);\n\n\n\n    return 0;\n\n}\n", "idx": 22962}
{"project": "FFmpeg", "commit_id": "984f50deb2d48f6844d65e10991b996a6d29e87c", "target": 1, "func": "static int dirac_decode_frame(AVCodecContext *avctx, void *data, int *got_frame, AVPacket *pkt)\n\n{\n\n    DiracContext *s     = avctx->priv_data;\n\n    AVFrame *picture    = data;\n\n    uint8_t *buf        = pkt->data;\n\n    int buf_size        = pkt->size;\n\n    int i, data_unit_size, buf_idx = 0;\n\n    int ret;\n\n\n\n    /* release unused frames */\n\n    for (i = 0; i < MAX_FRAMES; i++)\n\n        if (s->all_frames[i].avframe->data[0] && !s->all_frames[i].avframe->reference) {\n\n            av_frame_unref(s->all_frames[i].avframe);\n\n            memset(s->all_frames[i].interpolated, 0, sizeof(s->all_frames[i].interpolated));\n\n        }\n\n\n\n    s->current_picture = NULL;\n\n    *got_frame = 0;\n\n\n\n    /* end of stream, so flush delayed pics */\n\n    if (buf_size == 0)\n\n        return get_delayed_pic(s, (AVFrame *)data, got_frame);\n\n\n\n    for (;;) {\n\n        /*[DIRAC_STD] Here starts the code from parse_info() defined in 9.6\n\n          [DIRAC_STD] PARSE_INFO_PREFIX = \"BBCD\" as defined in ISO/IEC 646\n\n          BBCD start code search */\n\n        for (; buf_idx + DATA_UNIT_HEADER_SIZE < buf_size; buf_idx++) {\n\n            if (buf[buf_idx  ] == 'B' && buf[buf_idx+1] == 'B' &&\n\n                buf[buf_idx+2] == 'C' && buf[buf_idx+3] == 'D')\n\n                break;\n\n        }\n\n        /* BBCD found or end of data */\n\n        if (buf_idx + DATA_UNIT_HEADER_SIZE >= buf_size)\n\n            break;\n\n\n\n        data_unit_size = AV_RB32(buf+buf_idx+5);\n\n        if (buf_idx + data_unit_size > buf_size || !data_unit_size) {\n\n            if(buf_idx + data_unit_size > buf_size)\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Data unit with size %d is larger than input buffer, discarding\\n\",\n\n                   data_unit_size);\n\n            buf_idx += 4;\n\n            continue;\n\n        }\n\n        /* [DIRAC_STD] dirac_decode_data_unit makes reference to the while defined in 9.3 inside the function parse_sequence() */\n\n        if (dirac_decode_data_unit(avctx, buf+buf_idx, data_unit_size))\n\n        {\n\n            av_log(s->avctx, AV_LOG_ERROR,\"Error in dirac_decode_data_unit\\n\");\n\n            return -1;\n\n        }\n\n        buf_idx += data_unit_size;\n\n    }\n\n\n\n    if (!s->current_picture)\n\n        return buf_size;\n\n\n\n    if (s->current_picture->avframe->display_picture_number > s->frame_number) {\n\n        DiracFrame *delayed_frame = remove_frame(s->delay_frames, s->frame_number);\n\n\n\n        s->current_picture->avframe->reference |= DELAYED_PIC_REF;\n\n\n\n        if (add_frame(s->delay_frames, MAX_DELAY, s->current_picture)) {\n\n            int min_num = s->delay_frames[0]->avframe->display_picture_number;\n\n            /* Too many delayed frames, so we display the frame with the lowest pts */\n\n            av_log(avctx, AV_LOG_ERROR, \"Delay frame overflow\\n\");\n\n\n\n            for (i = 1; s->delay_frames[i]; i++)\n\n                if (s->delay_frames[i]->avframe->display_picture_number < min_num)\n\n                    min_num = s->delay_frames[i]->avframe->display_picture_number;\n\n\n\n            delayed_frame = remove_frame(s->delay_frames, min_num);\n\n            add_frame(s->delay_frames, MAX_DELAY, s->current_picture);\n\n        }\n\n\n\n        if (delayed_frame) {\n\n            delayed_frame->avframe->reference ^= DELAYED_PIC_REF;\n\n            if((ret=av_frame_ref(data, delayed_frame->avframe)) < 0)\n\n                return ret;\n\n            *got_frame = 1;\n\n        }\n\n    } else if (s->current_picture->avframe->display_picture_number == s->frame_number) {\n\n        /* The right frame at the right time :-) */\n\n        if((ret=av_frame_ref(data, s->current_picture->avframe)) < 0)\n\n            return ret;\n\n        *got_frame = 1;\n\n    }\n\n\n\n    if (*got_frame)\n\n        s->frame_number = picture->display_picture_number + 1;\n\n\n\n    return buf_idx;\n\n}\n", "idx": 22966}
{"project": "FFmpeg", "commit_id": "44ae98ddef565e03080012bb22467bc7ed1ca1d2", "target": 1, "func": "static void unpack_vectors(Vp3DecodeContext *s, GetBitContext *gb)\n\n{\n\n    int i, j, k;\n\n    int coding_mode;\n\n    int motion_x[6];\n\n    int motion_y[6];\n\n    int last_motion_x = 0;\n\n    int last_motion_y = 0;\n\n    int prior_last_motion_x = 0;\n\n    int prior_last_motion_y = 0;\n\n    int current_macroblock;\n\n    int current_fragment;\n\n\n\n    debug_vp3(\"  vp3: unpacking motion vectors\\n\");\n\n\n\n    if (s->keyframe) {\n\n\n\n        debug_vp3(\"    keyframe-- there are no motion vectors\\n\");\n\n\n\n    } else {\n\n\n\n        memset(motion_x, 0, 6 * sizeof(int));\n\n        memset(motion_y, 0, 6 * sizeof(int));\n\n\n\n        /* coding mode 0 is the VLC scheme; 1 is the fixed code scheme */\n\n        coding_mode = get_bits(gb, 1);\n\n        debug_vectors(\"    using %s scheme for unpacking motion vectors\\n\",\n\n            (coding_mode == 0) ? \"VLC\" : \"fixed-length\");\n\n\n\n        /* iterate through all of the macroblocks that contain 1 or more\n\n         * coded fragments */\n\n        for (i = 0; i < s->u_superblock_start; i++) {\n\n\n\n            for (j = 0; j < 4; j++) {\n\n                current_macroblock = s->superblock_macroblocks[i * 4 + j];\n\n                if ((current_macroblock == -1) ||\n\n                    (!s->macroblock_coded[current_macroblock]))\n\n                    continue;\n\n\n\n                current_fragment = s->macroblock_fragments[current_macroblock * 6];\n\n                switch (s->all_fragments[current_fragment].coding_method) {\n\n\n\n                case MODE_INTER_PLUS_MV:\n\n                case MODE_GOLDEN_MV:\n\n                    /* all 6 fragments use the same motion vector */\n\n                    if (coding_mode == 0) {\n\n                        motion_x[0] = get_motion_vector_vlc(gb);\n\n                        motion_y[0] = get_motion_vector_vlc(gb);\n\n                    } else {\n\n                        motion_x[0] = get_motion_vector_fixed(gb);\n\n                        motion_y[0] = get_motion_vector_fixed(gb);\n\n                    }\n\n                    for (k = 1; k < 6; k++) {\n\n                        motion_x[k] = motion_x[0];\n\n                        motion_y[k] = motion_y[0];\n\n                    }\n\n\n\n                    /* vector maintenance, only on MODE_INTER_PLUS_MV */\n\n                    if (s->all_fragments[current_fragment].coding_method ==\n\n                        MODE_INTER_PLUS_MV) {\n\n                        prior_last_motion_x = last_motion_x;\n\n                        prior_last_motion_y = last_motion_y;\n\n                        last_motion_x = motion_x[0];\n\n                        last_motion_y = motion_y[0];\n\n                    }\n\n                    break;\n\n\n\n                case MODE_INTER_FOURMV:\n\n                    /* fetch 4 vectors from the bitstream, one for each\n\n                     * Y fragment, then average for the C fragment vectors */\n\n                    motion_x[4] = motion_y[4] = 0;\n\n                    for (k = 0; k < 4; k++) {\n\n                        if (coding_mode == 0) {\n\n                            motion_x[k] = get_motion_vector_vlc(gb);\n\n                            motion_y[k] = get_motion_vector_vlc(gb);\n\n                        } else {\n\n                            motion_x[k] = get_motion_vector_fixed(gb);\n\n                            motion_y[k] = get_motion_vector_fixed(gb);\n\n                        }\n\n                        motion_x[4] += motion_x[k];\n\n                        motion_y[4] += motion_y[k];\n\n                    }\n\n\n\n                    if (motion_x[4] >= 0) \n\n                        motion_x[4] = (motion_x[4] + 2) / 4;\n\n                    else\n\n                        motion_x[4] = (motion_x[4] - 2) / 4;\n\n                    motion_x[5] = motion_x[4];\n\n\n\n                    if (motion_y[4] >= 0) \n\n                        motion_y[4] = (motion_y[4] + 2) / 4;\n\n                    else\n\n                        motion_y[4] = (motion_y[4] - 2) / 4;\n\n                    motion_y[5] = motion_y[4];\n\n\n\n                    /* vector maintenance; vector[3] is treated as the\n\n                     * last vector in this case */\n\n                    prior_last_motion_x = last_motion_x;\n\n                    prior_last_motion_y = last_motion_y;\n\n                    last_motion_x = motion_x[3];\n\n                    last_motion_y = motion_y[3];\n\n                    break;\n\n\n\n                case MODE_INTER_LAST_MV:\n\n                    /* all 6 fragments use the last motion vector */\n\n                    motion_x[0] = last_motion_x;\n\n                    motion_y[0] = last_motion_y;\n\n                    for (k = 1; k < 6; k++) {\n\n                        motion_x[k] = motion_x[0];\n\n                        motion_y[k] = motion_y[0];\n\n                    }\n\n\n\n                    /* no vector maintenance (last vector remains the\n\n                     * last vector) */\n\n                    break;\n\n\n\n                case MODE_INTER_PRIOR_LAST:\n\n                    /* all 6 fragments use the motion vector prior to the\n\n                     * last motion vector */\n\n                    motion_x[0] = prior_last_motion_x;\n\n                    motion_y[0] = prior_last_motion_y;\n\n                    for (k = 1; k < 6; k++) {\n\n                        motion_x[k] = motion_x[0];\n\n                        motion_y[k] = motion_y[0];\n\n                    }\n\n\n\n                    /* vector maintenance */\n\n                    prior_last_motion_x = last_motion_x;\n\n                    prior_last_motion_y = last_motion_y;\n\n                    last_motion_x = motion_x[0];\n\n                    last_motion_y = motion_y[0];\n\n                    break;\n\n                }\n\n\n\n                /* assign the motion vectors to the correct fragments */\n\n                debug_vectors(\"    vectors for macroblock starting @ fragment %d (coding method %d):\\n\",\n\n                    current_fragment,\n\n                    s->all_fragments[current_fragment].coding_method);\n\n                for (k = 0; k < 6; k++) {\n\n                    current_fragment = \n\n                        s->macroblock_fragments[current_macroblock * 6 + k];\n\n                    s->all_fragments[current_fragment].motion_x = motion_x[k];\n\n                    s->all_fragments[current_fragment].motion_x = motion_y[k];\n\n                    debug_vectors(\"    vector %d: fragment %d = (%d, %d)\\n\",\n\n                        k, current_fragment, motion_x[k], motion_y[k]);\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 22967}
{"project": "FFmpeg", "commit_id": "2f74f8d7dce2baff3a4401130a8e479c2899fd16", "target": 1, "func": "static int imc_decode_block(AVCodecContext *avctx, IMCContext *q, int ch)\n{\n    int stream_format_code;\n    int imc_hdr, i, j, ret;\n    int flag;\n    int bits, summer;\n    int counter, bitscount;\n    IMCChannel *chctx = q->chctx + ch;\n    /* Check the frame header */\n    imc_hdr = get_bits(&q->gb, 9);\n    if (imc_hdr & 0x18) {\n        av_log(avctx, AV_LOG_ERROR, \"frame header check failed!\\n\");\n        av_log(avctx, AV_LOG_ERROR, \"got %X.\\n\", imc_hdr);\n    stream_format_code = get_bits(&q->gb, 3);\n    if (stream_format_code & 1) {\n        av_log_ask_for_sample(avctx, \"Stream format %X is not supported\\n\",\n                              stream_format_code);\n        return AVERROR_PATCHWELCOME;\n    if (stream_format_code & 0x04)\n        chctx->decoder_reset = 1;\n    if (chctx->decoder_reset) {\n        for (i = 0; i < BANDS; i++)\n            chctx->old_floor[i] = 1.0;\n        for (i = 0; i < COEFFS; i++)\n            chctx->CWdecoded[i] = 0;\n        chctx->decoder_reset = 0;\n    flag = get_bits1(&q->gb);\n    imc_read_level_coeffs(q, stream_format_code, chctx->levlCoeffBuf);\n    if (stream_format_code & 0x4)\n        imc_decode_level_coefficients(q, chctx->levlCoeffBuf,\n                                      chctx->flcoeffs1, chctx->flcoeffs2);\n    else\n        imc_decode_level_coefficients2(q, chctx->levlCoeffBuf, chctx->old_floor,\n                                       chctx->flcoeffs1, chctx->flcoeffs2);\n    memcpy(chctx->old_floor, chctx->flcoeffs1, 32 * sizeof(float));\n    counter = 0;\n    for (i = 0; i < BANDS; i++) {\n        if (chctx->levlCoeffBuf[i] == 16) {\n            chctx->bandWidthT[i] = 0;\n            counter++;\n        } else\n            chctx->bandWidthT[i] = band_tab[i + 1] - band_tab[i];\n    memset(chctx->bandFlagsBuf, 0, BANDS * sizeof(int));\n    for (i = 0; i < BANDS - 1; i++) {\n        if (chctx->bandWidthT[i])\n            chctx->bandFlagsBuf[i] = get_bits1(&q->gb);\n    imc_calculate_coeffs(q, chctx->flcoeffs1, chctx->flcoeffs2, chctx->bandWidthT, chctx->flcoeffs3, chctx->flcoeffs5);\n    bitscount = 0;\n    /* first 4 bands will be assigned 5 bits per coefficient */\n    if (stream_format_code & 0x2) {\n        bitscount += 15;\n        chctx->bitsBandT[0] = 5;\n        chctx->CWlengthT[0] = 5;\n        chctx->CWlengthT[1] = 5;\n        chctx->CWlengthT[2] = 5;\n        for (i = 1; i < 4; i++) {\n            bits = (chctx->levlCoeffBuf[i] == 16) ? 0 : 5;\n            chctx->bitsBandT[i] = bits;\n            for (j = band_tab[i]; j < band_tab[i + 1]; j++) {\n                chctx->CWlengthT[j] = bits;\n                bitscount      += bits;\n    if (avctx->codec_id == AV_CODEC_ID_IAC) {\n        bitscount += !!chctx->bandWidthT[BANDS - 1];\n        if (!(stream_format_code & 0x2))\n            bitscount += 16;\n    if ((ret = bit_allocation(q, chctx, stream_format_code,\n                              512 - bitscount - get_bits_count(&q->gb),\n                              flag)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Bit allocations failed\\n\");\n        chctx->decoder_reset = 1;\n        return ret;\n    for (i = 0; i < BANDS; i++) {\n        chctx->sumLenArr[i]   = 0;\n        chctx->skipFlagRaw[i] = 0;\n        for (j = band_tab[i]; j < band_tab[i + 1]; j++)\n            chctx->sumLenArr[i] += chctx->CWlengthT[j];\n        if (chctx->bandFlagsBuf[i])\n            if ((((band_tab[i + 1] - band_tab[i]) * 1.5) > chctx->sumLenArr[i]) && (chctx->sumLenArr[i] > 0))\n                chctx->skipFlagRaw[i] = 1;\n    imc_get_skip_coeff(q, chctx);\n    for (i = 0; i < BANDS; i++) {\n        chctx->flcoeffs6[i] = chctx->flcoeffs1[i];\n        /* band has flag set and at least one coded coefficient */\n        if (chctx->bandFlagsBuf[i] && (band_tab[i + 1] - band_tab[i]) != chctx->skipFlagCount[i]) {\n            chctx->flcoeffs6[i] *= q->sqrt_tab[ band_tab[i + 1] - band_tab[i]] /\n                                   q->sqrt_tab[(band_tab[i + 1] - band_tab[i] - chctx->skipFlagCount[i])];\n    /* calculate bits left, bits needed and adjust bit allocation */\n    bits = summer = 0;\n    for (i = 0; i < BANDS; i++) {\n        if (chctx->bandFlagsBuf[i]) {\n            for (j = band_tab[i]; j < band_tab[i + 1]; j++) {\n                if (chctx->skipFlags[j]) {\n                    summer += chctx->CWlengthT[j];\n                    chctx->CWlengthT[j] = 0;\n            bits   += chctx->skipFlagBits[i];\n            summer -= chctx->skipFlagBits[i];\n    imc_adjust_bit_allocation(q, chctx, summer);\n    for (i = 0; i < BANDS; i++) {\n        chctx->sumLenArr[i] = 0;\n        for (j = band_tab[i]; j < band_tab[i + 1]; j++)\n            if (!chctx->skipFlags[j])\n                chctx->sumLenArr[i] += chctx->CWlengthT[j];\n    memset(chctx->codewords, 0, sizeof(chctx->codewords));\n    if (imc_get_coeffs(q, chctx) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Read coefficients failed\\n\");\n        chctx->decoder_reset = 1;\n    if (inverse_quant_coeff(q, chctx, stream_format_code) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Inverse quantization of coefficients failed\\n\");\n        chctx->decoder_reset = 1;\n    memset(chctx->skipFlags, 0, sizeof(chctx->skipFlags));\n    imc_imdct256(q, chctx, avctx->channels);\n    return 0;", "idx": 22968}
{"project": "FFmpeg", "commit_id": "1330a0f31f373f3b9f1ea53d48b94edc47759b76", "target": 1, "func": "static av_cold void nvenc_setup_rate_control(AVCodecContext *avctx)\n\n{\n\n    NvencContext *ctx = avctx->priv_data;\n\n\n\n    if (avctx->bit_rate > 0) {\n\n        ctx->encode_config.rcParams.averageBitRate = avctx->bit_rate;\n\n    } else if (ctx->encode_config.rcParams.averageBitRate > 0) {\n\n        ctx->encode_config.rcParams.maxBitRate = ctx->encode_config.rcParams.averageBitRate;\n\n    }\n\n\n\n    if (avctx->rc_max_rate > 0)\n\n        ctx->encode_config.rcParams.maxBitRate = avctx->rc_max_rate;\n\n\n\n    if (ctx->rc < 0) {\n\n        if (ctx->flags & NVENC_ONE_PASS)\n\n            ctx->twopass = 0;\n\n        if (ctx->flags & NVENC_TWO_PASSES)\n\n            ctx->twopass = 1;\n\n\n\n        if (ctx->twopass < 0)\n\n            ctx->twopass = (ctx->flags & NVENC_LOWLATENCY) != 0;\n\n\n\n        if (ctx->cbr) {\n\n            if (ctx->twopass) {\n\n                ctx->rc = NV_ENC_PARAMS_RC_2_PASS_QUALITY;\n\n            } else {\n\n                ctx->rc = NV_ENC_PARAMS_RC_CBR;\n\n            }\n\n        } else if (avctx->global_quality > 0) {\n\n            ctx->rc = NV_ENC_PARAMS_RC_CONSTQP;\n\n        } else if (ctx->twopass) {\n\n            ctx->rc = NV_ENC_PARAMS_RC_2_PASS_VBR;\n\n        } else if (avctx->qmin >= 0 && avctx->qmax >= 0) {\n\n            ctx->rc = NV_ENC_PARAMS_RC_VBR_MINQP;\n\n        }\n\n    }\n\n\n\n    if (ctx->flags & NVENC_LOSSLESS) {\n\n        set_lossless(avctx);\n\n    } else if (ctx->rc > 0) {\n\n        nvenc_override_rate_control(avctx);\n\n    } else {\n\n        ctx->encode_config.rcParams.rateControlMode = NV_ENC_PARAMS_RC_VBR;\n\n        set_vbr(avctx);\n\n    }\n\n\n\n    if (avctx->rc_buffer_size > 0) {\n\n        ctx->encode_config.rcParams.vbvBufferSize = avctx->rc_buffer_size;\n\n    } else if (ctx->encode_config.rcParams.averageBitRate > 0) {\n\n        ctx->encode_config.rcParams.vbvBufferSize = 2 * ctx->encode_config.rcParams.averageBitRate;\n\n    }\n\n}\n", "idx": 22970}
{"project": "FFmpeg", "commit_id": "db5dc02bd7d31243d2c4f84294907d657ab3d070", "target": 1, "func": "static int get_audio_frame_size(AVCodecContext *enc, int size)\n\n{\n\n    int frame_size;\n\n\n\n    if(enc->codec_id == CODEC_ID_VORBIS)\n\n        return -1;\n\n\n\n    if (enc->frame_size <= 1) {\n\n        int bits_per_sample = av_get_bits_per_sample(enc->codec_id);\n\n\n\n        if (bits_per_sample) {\n\n            if (enc->channels == 0)\n\n                return -1;\n\n            frame_size = (size << 3) / (bits_per_sample * enc->channels);\n\n        } else {\n\n            /* used for example by ADPCM codecs */\n\n            if (enc->bit_rate == 0)\n\n                return -1;\n\n            frame_size = (size * 8 * enc->sample_rate) / enc->bit_rate;\n\n        }\n\n    } else {\n\n        frame_size = enc->frame_size;\n\n    }\n\n    return frame_size;\n\n}\n", "idx": 22971}
{"project": "FFmpeg", "commit_id": "6d499ecef9c2467772b6066176ffda0b7ab27cc2", "target": 1, "func": "static void apply_dependent_coupling_fixed(AACContext *ac,\n\n                                     SingleChannelElement *target,\n\n                                     ChannelElement *cce, int index)\n\n{\n\n    IndividualChannelStream *ics = &cce->ch[0].ics;\n\n    const uint16_t *offsets = ics->swb_offset;\n\n    int *dest = target->coeffs;\n\n    const int *src = cce->ch[0].coeffs;\n\n    int g, i, group, k, idx = 0;\n\n    if (ac->oc[1].m4ac.object_type == AOT_AAC_LTP) {\n\n        av_log(ac->avctx, AV_LOG_ERROR,\n\n               \"Dependent coupling is not supported together with LTP\\n\");\n\n        return;\n\n    }\n\n    for (g = 0; g < ics->num_window_groups; g++) {\n\n        for (i = 0; i < ics->max_sfb; i++, idx++) {\n\n            if (cce->ch[0].band_type[idx] != ZERO_BT) {\n\n                const int gain = cce->coup.gain[index][idx];\n\n                int shift, round, c, tmp;\n\n\n\n                if (gain < 0) {\n\n                    c = -cce_scale_fixed[-gain & 7];\n\n                    shift = (-gain-1024) >> 3;\n\n                }\n\n                else {\n\n                    c = cce_scale_fixed[gain & 7];\n\n                    shift = (gain-1024) >> 3;\n\n                }\n\n\n\n                if (shift < -31) {\n\n                    // Nothing to do\n\n                } else if (shift < 0) {\n\n                    shift = -shift;\n\n                    round = 1 << (shift - 1);\n\n\n\n                    for (group = 0; group < ics->group_len[g]; group++) {\n\n                        for (k = offsets[i]; k < offsets[i + 1]; k++) {\n\n                            tmp = (int)(((int64_t)src[group * 128 + k] * c + \\\n\n                                       (int64_t)0x1000000000) >> 37);\n\n                            dest[group * 128 + k] += (tmp + round) >> shift;\n\n                        }\n\n                    }\n\n                }\n\n                else {\n\n                    for (group = 0; group < ics->group_len[g]; group++) {\n\n                        for (k = offsets[i]; k < offsets[i + 1]; k++) {\n\n                            tmp = (int)(((int64_t)src[group * 128 + k] * c + \\\n\n                                        (int64_t)0x1000000000) >> 37);\n\n                            dest[group * 128 + k] += tmp << shift;\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        dest += ics->group_len[g] * 128;\n\n        src  += ics->group_len[g] * 128;\n\n    }\n\n}\n", "idx": 22972}
{"project": "FFmpeg", "commit_id": "c29c1a1b6bade2b9118c7fa01239c622c2238656", "target": 1, "func": "static int copy_metadata(char *outspec, char *inspec, AVFormatContext *oc, AVFormatContext *ic, OptionsContext *o)\n\n{\n\n    AVDictionary **meta_in = NULL;\n\n    AVDictionary **meta_out;\n\n    int i, ret = 0;\n\n    char type_in, type_out;\n\n    const char *istream_spec = NULL, *ostream_spec = NULL;\n\n    int idx_in = 0, idx_out = 0;\n\n\n\n    parse_meta_type(inspec,  &type_in,  &idx_in,  &istream_spec);\n\n    parse_meta_type(outspec, &type_out, &idx_out, &ostream_spec);\n\n\n\n    if (type_in == 'g' || type_out == 'g')\n\n        o->metadata_global_manual = 1;\n\n    if (type_in == 's' || type_out == 's')\n\n        o->metadata_streams_manual = 1;\n\n    if (type_in == 'c' || type_out == 'c')\n\n        o->metadata_chapters_manual = 1;\n\n\n\n#define METADATA_CHECK_INDEX(index, nb_elems, desc)\\\n\n    if ((index) < 0 || (index) >= (nb_elems)) {\\\n\n        av_log(NULL, AV_LOG_FATAL, \"Invalid %s index %d while processing metadata maps.\\n\",\\\n\n                (desc), (index));\\\n\n        exit_program(1);\\\n\n    }\n\n\n\n#define SET_DICT(type, meta, context, index)\\\n\n        switch (type) {\\\n\n        case 'g':\\\n\n            meta = &context->metadata;\\\n\n            break;\\\n\n        case 'c':\\\n\n            METADATA_CHECK_INDEX(index, context->nb_chapters, \"chapter\")\\\n\n            meta = &context->chapters[index]->metadata;\\\n\n            break;\\\n\n        case 'p':\\\n\n            METADATA_CHECK_INDEX(index, context->nb_programs, \"program\")\\\n\n            meta = &context->programs[index]->metadata;\\\n\n            break;\\\n\n\n        }\\\n\n\n\n    SET_DICT(type_in, meta_in, ic, idx_in);\n\n    SET_DICT(type_out, meta_out, oc, idx_out);\n\n\n\n    /* for input streams choose first matching stream */\n\n    if (type_in == 's') {\n\n        for (i = 0; i < ic->nb_streams; i++) {\n\n            if ((ret = check_stream_specifier(ic, ic->streams[i], istream_spec)) > 0) {\n\n                meta_in = &ic->streams[i]->metadata;\n\n                break;\n\n            } else if (ret < 0)\n\n                exit_program(1);\n\n        }\n\n        if (!meta_in) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Stream specifier %s does not match  any streams.\\n\", istream_spec);\n\n            exit_program(1);\n\n        }\n\n    }\n\n\n\n    if (type_out == 's') {\n\n        for (i = 0; i < oc->nb_streams; i++) {\n\n            if ((ret = check_stream_specifier(oc, oc->streams[i], ostream_spec)) > 0) {\n\n                meta_out = &oc->streams[i]->metadata;\n\n                av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);\n\n            } else if (ret < 0)\n\n                exit_program(1);\n\n        }\n\n    } else\n\n        av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);\n\n\n\n    return 0;\n\n}", "idx": 22974}
{"project": "FFmpeg", "commit_id": "8370e426e42f2e4b9d14a1fb8107ecfe5163ce7f", "target": 1, "func": "static av_cold int vp3_decode_end(AVCodecContext *avctx)\n\n{\n\n    Vp3DecodeContext *s = avctx->priv_data;\n\n    int i;\n\n\n\n    if (avctx->is_copy && !s->current_frame.data[0])\n\n        return 0;\n\n\n\n    av_free(s->superblock_coding);\n\n    av_free(s->all_fragments);\n\n    av_free(s->coded_fragment_list[0]);\n\n    av_free(s->dct_tokens_base);\n\n    av_free(s->superblock_fragments);\n\n    av_free(s->macroblock_coding);\n\n    av_free(s->motion_val[0]);\n\n    av_free(s->motion_val[1]);\n\n    av_free(s->edge_emu_buffer);\n\n\n\n    if (avctx->is_copy) return 0;\n\n\n\n    for (i = 0; i < 16; i++) {\n\n        free_vlc(&s->dc_vlc[i]);\n\n        free_vlc(&s->ac_vlc_1[i]);\n\n        free_vlc(&s->ac_vlc_2[i]);\n\n        free_vlc(&s->ac_vlc_3[i]);\n\n        free_vlc(&s->ac_vlc_4[i]);\n\n    }\n\n\n\n    free_vlc(&s->superblock_run_length_vlc);\n\n    free_vlc(&s->fragment_run_length_vlc);\n\n    free_vlc(&s->mode_code_vlc);\n\n    free_vlc(&s->motion_vector_vlc);\n\n\n\n    /* release all frames */\n\n    if (s->golden_frame.data[0])\n\n        ff_thread_release_buffer(avctx, &s->golden_frame);\n\n    if (s->last_frame.data[0] && s->last_frame.type != FF_BUFFER_TYPE_COPY)\n\n        ff_thread_release_buffer(avctx, &s->last_frame);\n\n    /* no need to release the current_frame since it will always be pointing\n\n     * to the same frame as either the golden or last frame */\n\n\n\n    return 0;\n\n}\n", "idx": 22976}
{"project": "FFmpeg", "commit_id": "61cd19b8bc32185c8caf64d89d1b0909877a0707", "target": 1, "func": "static av_always_inline void paint_raw(uint8_t *dst, int w, int h,\n\n                                       const uint8_t *src, int bpp,\n\n                                       int be, int stride)\n\n{\n\n    int i, j, p;\n\n    for (j = 0; j < h; j++) {\n\n        for (i = 0; i < w; i++) {\n\n            p = vmnc_get_pixel(src, bpp, be);\n\n            src += bpp;\n\n            switch (bpp) {\n\n            case 1:\n\n                dst[i] = p;\n\n                break;\n\n            case 2:\n\n                ((uint16_t*)dst)[i] = p;\n\n                break;\n\n            case 4:\n\n                ((uint32_t*)dst)[i] = p;\n\n                break;\n\n            }\n\n        }\n\n        dst += stride;\n\n    }\n\n}\n", "idx": 22977}
{"project": "FFmpeg", "commit_id": "0b54f3c0878a3acaa9142e4f24942e762d97e350", "target": 1, "func": "static int gif_read_header(AVFormatContext * s1,\n\n                           AVFormatParameters * ap)\n\n{\n\n    GifState *s = s1->priv_data;\n\n    ByteIOContext *f = s1->pb;\n\n    AVStream *st;\n\n\n\n    s->f = f;\n\n    if (gif_read_header1(s) < 0)\n\n        return -1;\n\n\n\n    /* allocate image buffer */\n\n    s->image_linesize = s->screen_width * 3;\n\n    s->image_buf = av_malloc(s->screen_height * s->image_linesize);\n\n    if (!s->image_buf)\n\n        return AVERROR(ENOMEM);\n\n    s->pix_fmt = PIX_FMT_RGB24;\n\n    /* now we are ready: build format streams */\n\n    st = av_new_stream(s1, 0);\n\n    if (!st)\n\n        return -1;\n\n\n\n    st->codec->codec_type = CODEC_TYPE_VIDEO;\n\n    st->codec->codec_id = CODEC_ID_RAWVIDEO;\n\n    st->codec->time_base.den = 5;\n\n    st->codec->time_base.num = 1;\n\n    /* XXX: check if screen size is always valid */\n\n    st->codec->width = s->screen_width;\n\n    st->codec->height = s->screen_height;\n\n    st->codec->pix_fmt = PIX_FMT_RGB24;\n\n    return 0;\n\n}\n", "idx": 22978}
{"project": "FFmpeg", "commit_id": "03616af2c91309d58f9419becf45d292cb93e625", "target": 1, "func": "static int decorrelate(TAKDecContext *s, int c1, int c2, int length)\n\n{\n\n    GetBitContext *gb = &s->gb;\n\n    int32_t *p1       = s->decoded[c1] + 1;\n\n    int32_t *p2       = s->decoded[c2] + 1;\n\n    int i;\n\n    int dshift, dfactor;\n\n\n\n    switch (s->dmode) {\n\n    case 1: /* left/side */\n\n        for (i = 0; i < length; i++) {\n\n            int32_t a = p1[i];\n\n            int32_t b = p2[i];\n\n            p2[i]     = a + b;\n\n        }\n\n        break;\n\n    case 2: /* side/right */\n\n        for (i = 0; i < length; i++) {\n\n            int32_t a = p1[i];\n\n            int32_t b = p2[i];\n\n            p1[i]     = b - a;\n\n        }\n\n        break;\n\n    case 3: /* side/mid */\n\n        for (i = 0; i < length; i++) {\n\n            int32_t a = p1[i];\n\n            int32_t b = p2[i];\n\n            a        -= b >> 1;\n\n            p1[i]     = a;\n\n            p2[i]     = a + b;\n\n        }\n\n        break;\n\n    case 4: /* side/left with scale factor */\n\n        FFSWAP(int32_t*, p1, p2);\n\n    case 5: /* side/right with scale factor */\n\n        dshift  = get_bits_esc4(gb);\n\n        dfactor = get_sbits(gb, 10);\n\n        for (i = 0; i < length; i++) {\n\n            int32_t a = p1[i];\n\n            int32_t b = p2[i];\n\n            b         = dfactor * (b >> dshift) + 128 >> 8 << dshift;\n\n            p1[i]     = b - a;\n\n        }\n\n        break;\n\n    case 6:\n\n        FFSWAP(int32_t*, p1, p2);\n\n    case 7: {\n\n        int length2, order_half, filter_order, dval1, dval2;\n\n        int tmp, x, code_size;\n\n\n\n        if (length < 256)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        dshift       = get_bits_esc4(gb);\n\n        filter_order = 8 << get_bits1(gb);\n\n        dval1        = get_bits1(gb);\n\n        dval2        = get_bits1(gb);\n\n\n\n        AV_ZERO128(s->filter + 8);\n\n        for (i = 0; i < filter_order; i++) {\n\n            if (!(i & 3))\n\n                code_size = 14 - get_bits(gb, 3);\n\n            s->filter[i] = get_sbits(gb, code_size);\n\n        }\n\n\n\n        order_half = filter_order / 2;\n\n        length2    = length - (filter_order - 1);\n\n\n\n        /* decorrelate beginning samples */\n\n        if (dval1) {\n\n            for (i = 0; i < order_half; i++) {\n\n                int32_t a = p1[i];\n\n                int32_t b = p2[i];\n\n                p1[i]     = a + b;\n\n            }\n\n        }\n\n\n\n        /* decorrelate ending samples */\n\n        if (dval2) {\n\n            for (i = length2 + order_half; i < length; i++) {\n\n                int32_t a = p1[i];\n\n                int32_t b = p2[i];\n\n                p1[i]     = a + b;\n\n            }\n\n        }\n\n\n\n\n\n        for (i = 0; i < filter_order; i++)\n\n            s->residues[i] = *p2++ >> dshift;\n\n\n\n        p1 += order_half;\n\n        x = FF_ARRAY_ELEMS(s->residues) - filter_order;\n\n        for (; length2 > 0; length2 -= tmp) {\n\n            tmp = FFMIN(length2, x);\n\n\n\n            for (i = 0; i < tmp; i++)\n\n                s->residues[filter_order + i] = *p2++ >> dshift;\n\n\n\n            for (i = 0; i < tmp; i++) {\n\n                int v = 1 << 9;\n\n\n\n                v += s->adsp.scalarproduct_int16(&s->residues[i], s->filter, 16);\n\n                v = (av_clip_intp2(v >> 10, 13) << dshift) - *p1;\n\n                *p1++ = v;\n\n            }\n\n\n\n            memcpy(s->residues, &s->residues[tmp], 2 * filter_order);\n\n        }\n\n\n\n        emms_c();\n\n        break;\n\n    }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22979}
{"project": "FFmpeg", "commit_id": "9543cd593ed8249e9885598fc53de163c9d4e2d3", "target": 1, "func": "static void show_format(WriterContext *w, AVFormatContext *fmt_ctx)\n\n{\n\n    char val_str[128];\n\n    int64_t size = fmt_ctx->pb ? avio_size(fmt_ctx->pb) : -1;\n\n\n\n    print_section_header(\"format\");\n\n    print_str(\"filename\",         fmt_ctx->filename);\n\n    print_int(\"nb_streams\",       fmt_ctx->nb_streams);\n\n    print_str(\"format_name\",      fmt_ctx->iformat->name);\n\n    print_str(\"format_long_name\", fmt_ctx->iformat->long_name);\n\n    print_time(\"start_time\",      fmt_ctx->start_time, &AV_TIME_BASE_Q);\n\n    print_time(\"duration\",        fmt_ctx->duration,   &AV_TIME_BASE_Q);\n\n    if (size >= 0) print_val    (\"size\", size, unit_byte_str);\n\n    else           print_str_opt(\"size\", \"N/A\");\n\n    if (fmt_ctx->bit_rate > 0) print_val    (\"bit_rate\", fmt_ctx->bit_rate, unit_bit_per_second_str);\n\n    else                       print_str_opt(\"bit_rate\", \"N/A\");\n\n    show_tags(fmt_ctx->metadata);\n\n    print_section_footer(\"format\");\n\n    fflush(stdout);\n\n}\n", "idx": 22982}
{"project": "FFmpeg", "commit_id": "220b24c7c97dc033ceab1510549f66d0e7b52ef1", "target": 1, "func": "static SchroFrame *libschroedinger_frame_from_data(AVCodecContext *avctx,\n\n                                                   const AVFrame *frame)\n\n{\n\n    SchroEncoderParams *p_schro_params = avctx->priv_data;\n\n    SchroFrame *in_frame = ff_create_schro_frame(avctx,\n\n                                                 p_schro_params->frame_format);\n\n\n\n    if (in_frame) {\n\n        /* Copy input data to SchroFrame buffers (they match the ones\n\n         * referenced by the AVFrame stored in priv) */\n\n        if (av_frame_copy(in_frame->priv, frame) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Failed to copy input data\\n\");\n\n            return NULL;\n\n        }\n\n    }\n\n\n\n    return in_frame;\n\n}\n", "idx": 22983}
{"project": "FFmpeg", "commit_id": "354db19ff44c3e33ba1a4298d1b3eaefb0ddc7e3", "target": 1, "func": "int ff_h264_update_thread_context(AVCodecContext *dst,\n\n                                  const AVCodecContext *src)\n\n{\n\n    H264Context *h = dst->priv_data, *h1 = src->priv_data;\n\n    int inited = h->context_initialized, err = 0;\n\n    int context_reinitialized = 0;\n\n    int i, ret;\n\n\n\n    if (dst == src)\n\n        return 0;\n\n\n\n    if (inited &&\n\n        (h->width                 != h1->width                 ||\n\n         h->height                != h1->height                ||\n\n         h->mb_width              != h1->mb_width              ||\n\n         h->mb_height             != h1->mb_height             ||\n\n         h->sps.bit_depth_luma    != h1->sps.bit_depth_luma    ||\n\n         h->sps.chroma_format_idc != h1->sps.chroma_format_idc ||\n\n         h->sps.colorspace        != h1->sps.colorspace)) {\n\n\n\n        /* set bits_per_raw_sample to the previous value. the check for changed\n\n         * bit depth in h264_set_parameter_from_sps() uses it and sets it to\n\n         * the current value */\n\n        h->avctx->bits_per_raw_sample = h->sps.bit_depth_luma;\n\n\n\n        h->width     = h1->width;\n\n        h->height    = h1->height;\n\n        h->mb_height = h1->mb_height;\n\n        h->mb_width  = h1->mb_width;\n\n        h->mb_num    = h1->mb_num;\n\n        h->mb_stride = h1->mb_stride;\n\n        h->b_stride  = h1->b_stride;\n\n        // SPS/PPS\n\n        if ((ret = copy_parameter_set((void **)h->sps_buffers,\n\n                                      (void **)h1->sps_buffers,\n\n                                      MAX_SPS_COUNT, sizeof(SPS))) < 0)\n\n            return ret;\n\n        h->sps = h1->sps;\n\n        if ((ret = copy_parameter_set((void **)h->pps_buffers,\n\n                                      (void **)h1->pps_buffers,\n\n                                      MAX_PPS_COUNT, sizeof(PPS))) < 0)\n\n            return ret;\n\n        h->pps = h1->pps;\n\n\n\n        if ((err = h264_slice_header_init(h, 1)) < 0) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"h264_slice_header_init() failed\\n\");\n\n            return err;\n\n        }\n\n        context_reinitialized = 1;\n\n\n\n#if 0\n\n        h264_set_parameter_from_sps(h);\n\n        //Note we set context_reinitialized which will cause h264_set_parameter_from_sps to be reexecuted\n\n        h->cur_chroma_format_idc = h1->cur_chroma_format_idc;\n\n#endif\n\n    }\n\n\n\n    /* copy block_offset since frame_start may not be called */\n\n    memcpy(h->block_offset, h1->block_offset, sizeof(h->block_offset));\n\n\n\n    if (!inited) {\n\n        H264SliceContext *orig_slice_ctx = h->slice_ctx;\n\n\n\n        for (i = 0; i < MAX_SPS_COUNT; i++)\n\n            av_freep(h->sps_buffers + i);\n\n\n\n        for (i = 0; i < MAX_PPS_COUNT; i++)\n\n            av_freep(h->pps_buffers + i);\n\n\n\n        ff_h264_unref_picture(h, &h->last_pic_for_ec);\n\n        memcpy(h, h1, sizeof(H264Context));\n\n\n\n        memset(h->sps_buffers, 0, sizeof(h->sps_buffers));\n\n        memset(h->pps_buffers, 0, sizeof(h->pps_buffers));\n\n\n\n        memset(&h->cur_pic, 0, sizeof(h->cur_pic));\n\n        memset(&h->last_pic_for_ec, 0, sizeof(h->last_pic_for_ec));\n\n\n\n        h->slice_ctx = orig_slice_ctx;\n\n\n\n        memset(&h->slice_ctx[0].er,         0, sizeof(h->slice_ctx[0].er));\n\n        memset(&h->slice_ctx[0].mb,         0, sizeof(h->slice_ctx[0].mb));\n\n        memset(&h->slice_ctx[0].mb_luma_dc, 0, sizeof(h->slice_ctx[0].mb_luma_dc));\n\n        memset(&h->slice_ctx[0].mb_padding, 0, sizeof(h->slice_ctx[0].mb_padding));\n\n\n\n        h->avctx             = dst;\n\n        h->DPB               = NULL;\n\n        h->qscale_table_pool = NULL;\n\n        h->mb_type_pool      = NULL;\n\n        h->ref_index_pool    = NULL;\n\n        h->motion_val_pool   = NULL;\n\n        h->intra4x4_pred_mode= NULL;\n\n        h->non_zero_count    = NULL;\n\n        h->slice_table_base  = NULL;\n\n        h->slice_table       = NULL;\n\n        h->cbp_table         = NULL;\n\n        h->chroma_pred_mode_table = NULL;\n\n        memset(h->mvd_table, 0, sizeof(h->mvd_table));\n\n        h->direct_table      = NULL;\n\n        h->list_counts       = NULL;\n\n        h->mb2b_xy           = NULL;\n\n        h->mb2br_xy          = NULL;\n\n\n\n        if (h1->context_initialized) {\n\n        h->context_initialized = 0;\n\n\n\n        memset(&h->cur_pic, 0, sizeof(h->cur_pic));\n\n        av_frame_unref(&h->cur_pic.f);\n\n        h->cur_pic.tf.f = &h->cur_pic.f;\n\n\n\n        ret = ff_h264_alloc_tables(h);\n\n        if (ret < 0) {\n\n            av_log(dst, AV_LOG_ERROR, \"Could not allocate memory\\n\");\n\n            return ret;\n\n        }\n\n        ret = ff_h264_slice_context_init(h, &h->slice_ctx[0]);\n\n        if (ret < 0) {\n\n            av_log(dst, AV_LOG_ERROR, \"context_init() failed.\\n\");\n\n            return ret;\n\n        }\n\n        }\n\n\n\n        h->context_initialized = h1->context_initialized;\n\n    }\n\n\n\n    h->avctx->coded_height  = h1->avctx->coded_height;\n\n    h->avctx->coded_width   = h1->avctx->coded_width;\n\n    h->avctx->width         = h1->avctx->width;\n\n    h->avctx->height        = h1->avctx->height;\n\n    h->coded_picture_number = h1->coded_picture_number;\n\n    h->first_field          = h1->first_field;\n\n    h->picture_structure    = h1->picture_structure;\n\n    h->droppable            = h1->droppable;\n\n    h->low_delay            = h1->low_delay;\n\n\n\n    for (i = 0; h->DPB && i < H264_MAX_PICTURE_COUNT; i++) {\n\n        ff_h264_unref_picture(h, &h->DPB[i]);\n\n        if (h1->DPB && h1->DPB[i].f.buf[0] &&\n\n            (ret = ff_h264_ref_picture(h, &h->DPB[i], &h1->DPB[i])) < 0)\n\n            return ret;\n\n    }\n\n\n\n    h->cur_pic_ptr = REBASE_PICTURE(h1->cur_pic_ptr, h, h1);\n\n    ff_h264_unref_picture(h, &h->cur_pic);\n\n    if (h1->cur_pic.f.buf[0]) {\n\n        ret = ff_h264_ref_picture(h, &h->cur_pic, &h1->cur_pic);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    h->workaround_bugs = h1->workaround_bugs;\n\n    h->low_delay       = h1->low_delay;\n\n    h->droppable       = h1->droppable;\n\n\n\n    // extradata/NAL handling\n\n    h->is_avc = h1->is_avc;\n\n\n\n    // SPS/PPS\n\n    if ((ret = copy_parameter_set((void **)h->sps_buffers,\n\n                                  (void **)h1->sps_buffers,\n\n                                  MAX_SPS_COUNT, sizeof(SPS))) < 0)\n\n        return ret;\n\n    h->sps = h1->sps;\n\n    if ((ret = copy_parameter_set((void **)h->pps_buffers,\n\n                                  (void **)h1->pps_buffers,\n\n                                  MAX_PPS_COUNT, sizeof(PPS))) < 0)\n\n        return ret;\n\n    h->pps = h1->pps;\n\n\n\n    // Dequantization matrices\n\n    // FIXME these are big - can they be only copied when PPS changes?\n\n    copy_fields(h, h1, dequant4_buffer, dequant4_coeff);\n\n\n\n    for (i = 0; i < 6; i++)\n\n        h->dequant4_coeff[i] = h->dequant4_buffer[0] +\n\n                               (h1->dequant4_coeff[i] - h1->dequant4_buffer[0]);\n\n\n\n    for (i = 0; i < 6; i++)\n\n        h->dequant8_coeff[i] = h->dequant8_buffer[0] +\n\n                               (h1->dequant8_coeff[i] - h1->dequant8_buffer[0]);\n\n\n\n    h->dequant_coeff_pps = h1->dequant_coeff_pps;\n\n\n\n    // POC timing\n\n    copy_fields(h, h1, poc_lsb, default_ref_list);\n\n\n\n    // reference lists\n\n    copy_fields(h, h1, short_ref, current_slice);\n\n\n\n    copy_picture_range(h->short_ref, h1->short_ref, 32, h, h1);\n\n    copy_picture_range(h->long_ref, h1->long_ref, 32, h, h1);\n\n    copy_picture_range(h->delayed_pic, h1->delayed_pic,\n\n                       MAX_DELAYED_PIC_COUNT + 2, h, h1);\n\n\n\n    h->frame_recovered       = h1->frame_recovered;\n\n\n\n    if (context_reinitialized)\n\n        ff_h264_set_parameter_from_sps(h);\n\n\n\n    if (!h->cur_pic_ptr)\n\n        return 0;\n\n\n\n    if (!h->droppable) {\n\n        err = ff_h264_execute_ref_pic_marking(h, h->mmco, h->mmco_index);\n\n        h->prev_poc_msb = h->poc_msb;\n\n        h->prev_poc_lsb = h->poc_lsb;\n\n    }\n\n    h->prev_frame_num_offset = h->frame_num_offset;\n\n    h->prev_frame_num        = h->frame_num;\n\n    h->outputed_poc          = h->next_outputed_poc;\n\n\n\n    h->recovery_frame        = h1->recovery_frame;\n\n\n\n    return err;\n\n}\n", "idx": 22986}
{"project": "FFmpeg", "commit_id": "8e2555d3b1855374707a4d53bf93d3e07d61e05c", "target": 0, "func": "static av_cold int g722_encode_close(AVCodecContext *avctx)\n\n{\n\n    G722Context *c = avctx->priv_data;\n\n    int i;\n\n    for (i = 0; i < 2; i++) {\n\n        av_freep(&c->paths[i]);\n\n        av_freep(&c->node_buf[i]);\n\n        av_freep(&c->nodep_buf[i]);\n\n    }\n\n    return 0;\n\n}\n", "idx": 22991}
{"project": "FFmpeg", "commit_id": "92216453dbcce0f946eaf74bec075791a3edecb5", "target": 0, "func": "static int asf_get_packet(AVFormatContext *s)\n\n{\n\n    ASFContext *asf = s->priv_data;\n\n    ByteIOContext *pb = &s->pb;\n\n    uint32_t packet_length, padsize;\n\n    int rsize = 9;\n\n    int c;\n\n\n\n    c = get_byte(pb);\n\n    if (c != 0x82) {\n\n        if (!url_feof(pb))\n\n            av_log(s, AV_LOG_ERROR, \"ff asf bad header %x  at:%\"PRId64\"\\n\", c, url_ftell(pb));\n\n    }\n\n    if ((c & 0x0f) == 2) { // always true for now\n\n        if (get_le16(pb) != 0) {\n\n            if (!url_feof(pb))\n\n                av_log(s, AV_LOG_ERROR, \"ff asf bad non zero\\n\");\n\n            return AVERROR_IO;\n\n        }\n\n        rsize+=2;\n\n/*    }else{\n\n        if (!url_feof(pb))\n\n            printf(\"ff asf bad header %x  at:%\"PRId64\"\\n\", c, url_ftell(pb));\n\n        return AVERROR_IO;*/\n\n    }\n\n\n\n    asf->packet_flags = get_byte(pb);\n\n    asf->packet_property = get_byte(pb);\n\n\n\n    DO_2BITS(asf->packet_flags >> 5, packet_length, asf->packet_size);\n\n    DO_2BITS(asf->packet_flags >> 1, padsize, 0); // sequence ignored\n\n    DO_2BITS(asf->packet_flags >> 3, padsize, 0); // padding length\n\n\n\n    //the following checks prevent overflows and infinite loops\n\n    if(packet_length >= (1U<<29)){\n\n        av_log(s, AV_LOG_ERROR, \"invalid packet_length %d at:%\"PRId64\"\\n\", packet_length, url_ftell(pb));\n\n        return -1;\n\n    }\n\n    if(padsize >= (1U<<29)){\n\n        av_log(s, AV_LOG_ERROR, \"invalid padsize %d at:%\"PRId64\"\\n\", padsize, url_ftell(pb));\n\n        return -1;\n\n    }\n\n\n\n    asf->packet_timestamp = get_le32(pb);\n\n    get_le16(pb); /* duration */\n\n    // rsize has at least 11 bytes which have to be present\n\n\n\n    if (asf->packet_flags & 0x01) {\n\n        asf->packet_segsizetype = get_byte(pb); rsize++;\n\n        asf->packet_segments = asf->packet_segsizetype & 0x3f;\n\n    } else {\n\n        asf->packet_segments = 1;\n\n        asf->packet_segsizetype = 0x80;\n\n    }\n\n    asf->packet_size_left = packet_length - padsize - rsize;\n\n    if (packet_length < asf->hdr.min_pktsize)\n\n        padsize += asf->hdr.min_pktsize - packet_length;\n\n    asf->packet_padsize = padsize;\n\n#ifdef DEBUG\n\n    printf(\"packet: size=%d padsize=%d  left=%d\\n\", asf->packet_size, asf->packet_padsize, asf->packet_size_left);\n\n#endif\n\n    return 0;\n\n}\n", "idx": 22992}
{"project": "FFmpeg", "commit_id": "a9eb4f0899de04a3093a04f461611c6f0664398e", "target": 0, "func": "static void new_video_stream(AVFormatContext *oc, int file_idx)\n\n{\n\n    AVStream *st;\n\n    OutputStream *ost;\n\n    AVCodecContext *video_enc;\n\n    enum CodecID codec_id = CODEC_ID_NONE;\n\n    AVCodec *codec= NULL;\n\n\n\n    if(!video_stream_copy){\n\n        if (video_codec_name) {\n\n            codec_id = find_codec_or_die(video_codec_name, AVMEDIA_TYPE_VIDEO, 1,\n\n                                         avcodec_opts[AVMEDIA_TYPE_VIDEO]->strict_std_compliance);\n\n            codec = avcodec_find_encoder_by_name(video_codec_name);\n\n        } else {\n\n            codec_id = av_guess_codec(oc->oformat, NULL, oc->filename, NULL, AVMEDIA_TYPE_VIDEO);\n\n            codec = avcodec_find_encoder(codec_id);\n\n        }\n\n    }\n\n\n\n    ost = new_output_stream(oc, file_idx, codec);\n\n    st  = ost->st;\n\n    if (!video_stream_copy) {\n\n        ost->frame_aspect_ratio = frame_aspect_ratio;\n\n        frame_aspect_ratio = 0;\n\n#if CONFIG_AVFILTER\n\n        ost->avfilter= vfilters;\n\n        vfilters = NULL;\n\n#endif\n\n    }\n\n\n\n    ost->bitstream_filters = video_bitstream_filters;\n\n    video_bitstream_filters= NULL;\n\n\n\n    st->codec->thread_count= thread_count;\n\n\n\n    video_enc = st->codec;\n\n\n\n    if(video_codec_tag)\n\n        video_enc->codec_tag= video_codec_tag;\n\n\n\n    if(oc->oformat->flags & AVFMT_GLOBALHEADER) {\n\n        video_enc->flags |= CODEC_FLAG_GLOBAL_HEADER;\n\n    }\n\n\n\n    if (video_stream_copy) {\n\n        st->stream_copy = 1;\n\n        video_enc->codec_type = AVMEDIA_TYPE_VIDEO;\n\n        video_enc->sample_aspect_ratio =\n\n        st->sample_aspect_ratio = av_d2q(frame_aspect_ratio*frame_height/frame_width, 255);\n\n    } else {\n\n        const char *p;\n\n        int i;\n\n\n\n        if (frame_rate.num)\n\n            ost->frame_rate = frame_rate;\n\n        video_enc->codec_id = codec_id;\n\n        set_context_opts(video_enc, avcodec_opts[AVMEDIA_TYPE_VIDEO], AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM, codec);\n\n\n\n        video_enc->width = frame_width;\n\n        video_enc->height = frame_height;\n\n        video_enc->pix_fmt = frame_pix_fmt;\n\n        st->sample_aspect_ratio = video_enc->sample_aspect_ratio;\n\n\n\n        if (intra_only)\n\n            video_enc->gop_size = 0;\n\n        if (video_qscale || same_quality) {\n\n            video_enc->flags |= CODEC_FLAG_QSCALE;\n\n            video_enc->global_quality = FF_QP2LAMBDA * video_qscale;\n\n        }\n\n\n\n        if(intra_matrix)\n\n            video_enc->intra_matrix = intra_matrix;\n\n        if(inter_matrix)\n\n            video_enc->inter_matrix = inter_matrix;\n\n\n\n        p= video_rc_override_string;\n\n        for(i=0; p; i++){\n\n            int start, end, q;\n\n            int e=sscanf(p, \"%d,%d,%d\", &start, &end, &q);\n\n            if(e!=3){\n\n                fprintf(stderr, \"error parsing rc_override\\n\");\n\n                ffmpeg_exit(1);\n\n            }\n\n            video_enc->rc_override=\n\n                av_realloc(video_enc->rc_override,\n\n                           sizeof(RcOverride)*(i+1));\n\n            video_enc->rc_override[i].start_frame= start;\n\n            video_enc->rc_override[i].end_frame  = end;\n\n            if(q>0){\n\n                video_enc->rc_override[i].qscale= q;\n\n                video_enc->rc_override[i].quality_factor= 1.0;\n\n            }\n\n            else{\n\n                video_enc->rc_override[i].qscale= 0;\n\n                video_enc->rc_override[i].quality_factor= -q/100.0;\n\n            }\n\n            p= strchr(p, '/');\n\n            if(p) p++;\n\n        }\n\n        video_enc->rc_override_count=i;\n\n        if (!video_enc->rc_initial_buffer_occupancy)\n\n            video_enc->rc_initial_buffer_occupancy = video_enc->rc_buffer_size*3/4;\n\n        video_enc->me_threshold= me_threshold;\n\n        video_enc->intra_dc_precision= intra_dc_precision - 8;\n\n\n\n        if (do_psnr)\n\n            video_enc->flags|= CODEC_FLAG_PSNR;\n\n\n\n        /* two pass mode */\n\n        if (do_pass) {\n\n            if (do_pass == 1) {\n\n                video_enc->flags |= CODEC_FLAG_PASS1;\n\n            } else {\n\n                video_enc->flags |= CODEC_FLAG_PASS2;\n\n            }\n\n        }\n\n\n\n        if (forced_key_frames)\n\n            parse_forced_key_frames(forced_key_frames, ost, video_enc);\n\n    }\n\n    if (video_language) {\n\n        av_dict_set(&st->metadata, \"language\", video_language, 0);\n\n        av_freep(&video_language);\n\n    }\n\n\n\n    /* reset some key parameters */\n\n    video_disable = 0;\n\n    av_freep(&video_codec_name);\n\n    av_freep(&forced_key_frames);\n\n    video_stream_copy = 0;\n\n    frame_pix_fmt = PIX_FMT_NONE;\n\n}\n", "idx": 22993}
{"project": "FFmpeg", "commit_id": "f807d6d2009b9f2e70d9a204a0e8b6140a87ec85", "target": 0, "func": "void ff_check_pixfmt_descriptors(void){\n\n    int i, j;\n\n\n\n    for (i=0; i<FF_ARRAY_ELEMS(av_pix_fmt_descriptors); i++) {\n\n        const AVPixFmtDescriptor *d = &av_pix_fmt_descriptors[i];\n\n\n\n        if (!d->name && !d->nb_components && !d->log2_chroma_w && !d->log2_chroma_h && !d->flags)\n\n            continue;\n\n//         av_log(NULL, AV_LOG_DEBUG, \"Checking: %s\\n\", d->name);\n\n        av_assert0(d->log2_chroma_w <= 3);\n\n        av_assert0(d->log2_chroma_h <= 3);\n\n        av_assert0(d->nb_components <= 4);\n\n        av_assert0(d->name && d->name[0]);\n\n        av_assert0((d->nb_components==4 || d->nb_components==2) == !!(d->flags & PIX_FMT_ALPHA));\n\n        av_assert2(av_get_pix_fmt(d->name) == i);\n\n\n\n        for (j=0; j<FF_ARRAY_ELEMS(d->comp); j++) {\n\n            const AVComponentDescriptor *c = &d->comp[j];\n\n            if(j>=d->nb_components)\n\n                av_assert0(!c->plane && !c->step_minus1 && !c->offset_plus1 && !c->shift && !c->depth_minus1);\n\n        }\n\n    }\n\n}\n", "idx": 22999}
{"project": "FFmpeg", "commit_id": "a2f55f22b342202e6925561b9ee0b7ec76e8bcd0", "target": 0, "func": "static void mxf_write_generic_desc(ByteIOContext *pb, const MXFDescriptorWriteTableEntry *desc_tbl, AVStream *st)\n\n{\n\n    const MXFCodecUL *codec_ul;\n\n\n\n    put_buffer(pb, desc_tbl->key, 16);\n\n    klv_encode_ber_length(pb, 108);\n\n\n\n    mxf_write_local_tag(pb, 16, 0x3C0A);\n\n    mxf_write_uuid(pb, SubDescriptor, st->index);\n\n\n\n    mxf_write_local_tag(pb, 4, 0x3006);\n\n    put_be32(pb, st->index);\n\n\n\n    mxf_write_local_tag(pb, 8, 0x3001);\n\n    put_be32(pb, st->time_base.den);\n\n    put_be32(pb, st->time_base.num);\n\n\n\n    codec_ul = mxf_get_essence_container_ul(st->codec->codec_id);\n\n    mxf_write_local_tag(pb, 16, 0x3004);\n\n    put_buffer(pb, codec_ul->uid, 16);\n\n}\n", "idx": 23010}
{"project": "FFmpeg", "commit_id": "0a771e6b32429f9195d431415bf707c28ef31fff", "target": 0, "func": "static int decode_frame_common(AVCodecContext *avctx, PNGDecContext *s,\n\n                               AVFrame *p, AVPacket *avpkt)\n\n{\n\n    AVDictionary **metadatap = NULL;\n\n    uint32_t tag, length;\n\n    int decode_next_dat = 0;\n\n    int ret;\n\n\n\n    for (;;) {\n\n        length = bytestream2_get_bytes_left(&s->gb);\n\n        if (length <= 0) {\n\n\n\n            if (avctx->codec_id == AV_CODEC_ID_PNG &&\n\n                avctx->skip_frame == AVDISCARD_ALL) {\n\n                return 0;\n\n            }\n\n\n\n            if (CONFIG_APNG_DECODER && avctx->codec_id == AV_CODEC_ID_APNG && length == 0) {\n\n                if (!(s->pic_state & PNG_IDAT))\n\n                    return 0;\n\n                else\n\n                    goto exit_loop;\n\n            }\n\n            av_log(avctx, AV_LOG_ERROR, \"%d bytes left\\n\", length);\n\n            if (   s->pic_state & PNG_ALLIMAGE\n\n                && avctx->strict_std_compliance <= FF_COMPLIANCE_NORMAL)\n\n                goto exit_loop;\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n\n\n        length = bytestream2_get_be32(&s->gb);\n\n        if (length > 0x7fffffff || length > bytestream2_get_bytes_left(&s->gb)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"chunk too big\\n\");\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n        tag = bytestream2_get_le32(&s->gb);\n\n        if (avctx->debug & FF_DEBUG_STARTCODE)\n\n            av_log(avctx, AV_LOG_DEBUG, \"png: tag=%s length=%u\\n\",\n\n                   av_fourcc2str(tag), length);\n\n\n\n        if (avctx->codec_id == AV_CODEC_ID_PNG &&\n\n            avctx->skip_frame == AVDISCARD_ALL) {\n\n            switch(tag) {\n\n            case MKTAG('I', 'H', 'D', 'R'):\n\n            case MKTAG('p', 'H', 'Y', 's'):\n\n            case MKTAG('t', 'E', 'X', 't'):\n\n            case MKTAG('I', 'D', 'A', 'T'):\n\n            case MKTAG('t', 'R', 'N', 'S'):\n\n                break;\n\n            default:\n\n                goto skip_tag;\n\n            }\n\n        }\n\n\n\n        metadatap = &p->metadata;\n\n        switch (tag) {\n\n        case MKTAG('I', 'H', 'D', 'R'):\n\n            if ((ret = decode_ihdr_chunk(avctx, s, length)) < 0)\n\n                goto fail;\n\n            break;\n\n        case MKTAG('p', 'H', 'Y', 's'):\n\n            if ((ret = decode_phys_chunk(avctx, s)) < 0)\n\n                goto fail;\n\n            break;\n\n        case MKTAG('f', 'c', 'T', 'L'):\n\n            if (!CONFIG_APNG_DECODER || avctx->codec_id != AV_CODEC_ID_APNG)\n\n                goto skip_tag;\n\n            if ((ret = decode_fctl_chunk(avctx, s, length)) < 0)\n\n                goto fail;\n\n            decode_next_dat = 1;\n\n            break;\n\n        case MKTAG('f', 'd', 'A', 'T'):\n\n            if (!CONFIG_APNG_DECODER || avctx->codec_id != AV_CODEC_ID_APNG)\n\n                goto skip_tag;\n\n            if (!decode_next_dat) {\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            bytestream2_get_be32(&s->gb);\n\n            length -= 4;\n\n            /* fallthrough */\n\n        case MKTAG('I', 'D', 'A', 'T'):\n\n            if (CONFIG_APNG_DECODER && avctx->codec_id == AV_CODEC_ID_APNG && !decode_next_dat)\n\n                goto skip_tag;\n\n            if ((ret = decode_idat_chunk(avctx, s, length, p)) < 0)\n\n                goto fail;\n\n            break;\n\n        case MKTAG('P', 'L', 'T', 'E'):\n\n            if (decode_plte_chunk(avctx, s, length) < 0)\n\n                goto skip_tag;\n\n            break;\n\n        case MKTAG('t', 'R', 'N', 'S'):\n\n            if (decode_trns_chunk(avctx, s, length) < 0)\n\n                goto skip_tag;\n\n            break;\n\n        case MKTAG('t', 'E', 'X', 't'):\n\n            if (decode_text_chunk(s, length, 0, metadatap) < 0)\n\n                av_log(avctx, AV_LOG_WARNING, \"Broken tEXt chunk\\n\");\n\n            bytestream2_skip(&s->gb, length + 4);\n\n            break;\n\n        case MKTAG('z', 'T', 'X', 't'):\n\n            if (decode_text_chunk(s, length, 1, metadatap) < 0)\n\n                av_log(avctx, AV_LOG_WARNING, \"Broken zTXt chunk\\n\");\n\n            bytestream2_skip(&s->gb, length + 4);\n\n            break;\n\n        case MKTAG('s', 'T', 'E', 'R'): {\n\n            int mode = bytestream2_get_byte(&s->gb);\n\n            AVStereo3D *stereo3d = av_stereo3d_create_side_data(p);\n\n            if (!stereo3d)\n\n                goto fail;\n\n\n\n            if (mode == 0 || mode == 1) {\n\n                stereo3d->type  = AV_STEREO3D_SIDEBYSIDE;\n\n                stereo3d->flags = mode ? 0 : AV_STEREO3D_FLAG_INVERT;\n\n            } else {\n\n                 av_log(avctx, AV_LOG_WARNING,\n\n                        \"Unknown value in sTER chunk (%d)\\n\", mode);\n\n            }\n\n            bytestream2_skip(&s->gb, 4); /* crc */\n\n            break;\n\n        }\n\n        case MKTAG('i', 'C', 'C', 'P'): {\n\n            if (decode_iccp_chunk(s, length, p) < 0)\n\n                goto fail;\n\n            break;\n\n        }\n\n        case MKTAG('I', 'E', 'N', 'D'):\n\n            if (!(s->pic_state & PNG_ALLIMAGE))\n\n                av_log(avctx, AV_LOG_ERROR, \"IEND without all image\\n\");\n\n            if (!(s->pic_state & (PNG_ALLIMAGE|PNG_IDAT))) {\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            bytestream2_skip(&s->gb, 4); /* crc */\n\n            goto exit_loop;\n\n        default:\n\n            /* skip tag */\n\nskip_tag:\n\n            bytestream2_skip(&s->gb, length + 4);\n\n            break;\n\n        }\n\n    }\n\nexit_loop:\n\n\n\n    if (avctx->codec_id == AV_CODEC_ID_PNG &&\n\n        avctx->skip_frame == AVDISCARD_ALL) {\n\n        return 0;\n\n    }\n\n\n\n    if (s->bits_per_pixel <= 4)\n\n        handle_small_bpp(s, p);\n\n\n\n    /* apply transparency if needed */\n\n    if (s->has_trns && s->color_type != PNG_COLOR_TYPE_PALETTE) {\n\n        size_t byte_depth = s->bit_depth > 8 ? 2 : 1;\n\n        size_t raw_bpp = s->bpp - byte_depth;\n\n        unsigned x, y;\n\n\n\n        av_assert0(s->bit_depth > 1);\n\n\n\n        for (y = 0; y < s->height; ++y) {\n\n            uint8_t *row = &s->image_buf[s->image_linesize * y];\n\n\n\n            /* since we're updating in-place, we have to go from right to left */\n\n            for (x = s->width; x > 0; --x) {\n\n                uint8_t *pixel = &row[s->bpp * (x - 1)];\n\n                memmove(pixel, &row[raw_bpp * (x - 1)], raw_bpp);\n\n\n\n                if (!memcmp(pixel, s->transparent_color_be, raw_bpp)) {\n\n                    memset(&pixel[raw_bpp], 0, byte_depth);\n\n                } else {\n\n                    memset(&pixel[raw_bpp], 0xff, byte_depth);\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    /* handle P-frames only if a predecessor frame is available */\n\n    if (s->last_picture.f->data[0]) {\n\n        if (   !(avpkt->flags & AV_PKT_FLAG_KEY) && avctx->codec_tag != AV_RL32(\"MPNG\")\n\n            && s->last_picture.f->width == p->width\n\n            && s->last_picture.f->height== p->height\n\n            && s->last_picture.f->format== p->format\n\n         ) {\n\n            if (CONFIG_PNG_DECODER && avctx->codec_id != AV_CODEC_ID_APNG)\n\n                handle_p_frame_png(s, p);\n\n            else if (CONFIG_APNG_DECODER &&\n\n                     avctx->codec_id == AV_CODEC_ID_APNG &&\n\n                     (ret = handle_p_frame_apng(avctx, s, p)) < 0)\n\n                goto fail;\n\n        }\n\n    }\n\n    ff_thread_report_progress(&s->picture, INT_MAX, 0);\n\n    ff_thread_report_progress(&s->previous_picture, INT_MAX, 0);\n\n\n\n    return 0;\n\n\n\nfail:\n\n    ff_thread_report_progress(&s->picture, INT_MAX, 0);\n\n    ff_thread_report_progress(&s->previous_picture, INT_MAX, 0);\n\n    return ret;\n\n}\n", "idx": 23017}
{"project": "FFmpeg", "commit_id": "2131e8590c447575a1c23bbc9f7e0bf9592d8997", "target": 0, "func": "static void init_demo(const char *filename)\n\n{\n\n    int i, j;\n\n    int h;\n\n    int radian;\n\n    char line[3 * W];\n\n\n\n    FILE *fichier;\n\n\n\n    fichier = fopen(filename, \"rb\");\n\n    if (!fichier) {\n\n        perror(filename);\n\n        exit(1);\n\n    }\n\n\n\n    fread(line, 1, 15, fichier);\n\n    for (i = 0; i < H; i++) {\n\n        fread(line, 1, 3 * W, fichier);\n\n        for (j = 0; j < W; j++) {\n\n            tab_r[W * i + j] = line[3 * j    ];\n\n            tab_g[W * i + j] = line[3 * j + 1];\n\n            tab_b[W * i + j] = line[3 * j + 2];\n\n        }\n\n    }\n\n    fclose(fichier);\n\n\n\n    /* tables sin/cos */\n\n    for (i = 0; i < 360; i++) {\n\n        radian = 2 * i * MY_PI / 360;\n\n        h      = 2 * FIXP + int_sin (radian);\n\n        h_cos[i] = h * int_sin(radian + MY_PI / 2) / 2 / FIXP;\n\n        h_sin[i] = h * int_sin(radian)             / 2 / FIXP;\n\n    }\n\n}\n", "idx": 23018}
{"project": "FFmpeg", "commit_id": "e75e603c1a5d1b56b6297d2cbc1f32e6bf7b2b15", "target": 0, "func": "static int sync(AVFormatContext *s, int64_t *timestamp, int *flags, int *stream_index, int64_t *pos){\n\n    RMDemuxContext *rm = s->priv_data;\n\n    ByteIOContext *pb = s->pb;\n\n    int len, num, res, i;\n\n    AVStream *st;\n\n    uint32_t state=0xFFFFFFFF;\n\n\n\n    while(!url_feof(pb)){\n\n        *pos= url_ftell(pb) - 3;\n\n        if(rm->remaining_len > 0){\n\n            num= rm->current_stream;\n\n            len= rm->remaining_len;\n\n            *timestamp = AV_NOPTS_VALUE;\n\n            *flags= 0;\n\n        }else{\n\n            state= (state<<8) + get_byte(pb);\n\n\n\n            if(state == MKBETAG('I', 'N', 'D', 'X')){\n\n                int n_pkts, expected_len;\n\n                len = get_be32(pb);\n\n                url_fskip(pb, 2);\n\n                n_pkts = get_be32(pb);\n\n                expected_len = 20 + n_pkts * 14;\n\n                if (len == 20)\n\n                    /* some files don't add index entries to chunk size... */\n\n                    len = expected_len;\n\n                else if (len != expected_len)\n\n                    av_log(s, AV_LOG_WARNING,\n\n                           \"Index size %d (%d pkts) is wrong, should be %d.\\n\",\n\n                           len, n_pkts, expected_len);\n\n                len -= 14; // we already read part of the index header\n\n                if(len<0)\n\n                    continue;\n\n                goto skip;\n\n            }\n\n\n\n            if(state > (unsigned)0xFFFF || state < 12)\n\n                continue;\n\n            len=state;\n\n            state= 0xFFFFFFFF;\n\n\n\n            num = get_be16(pb);\n\n            *timestamp = get_be32(pb);\n\n            res= get_byte(pb); /* reserved */\n\n            *flags = get_byte(pb); /* flags */\n\n\n\n\n\n            len -= 12;\n\n        }\n\n        for(i=0;i<s->nb_streams;i++) {\n\n            st = s->streams[i];\n\n            if (num == st->id)\n\n                break;\n\n        }\n\n        if (i == s->nb_streams) {\n\nskip:\n\n            /* skip packet if unknown number */\n\n            url_fskip(pb, len);\n\n            rm->remaining_len = 0;\n\n            continue;\n\n        }\n\n        *stream_index= i;\n\n\n\n        return len;\n\n    }\n\n    return -1;\n\n}\n", "idx": 23019}
{"project": "FFmpeg", "commit_id": "03cef34aa66662e2ab3681d290e7c5a6634f4058", "target": 0, "func": "static int qsv_get_buffer(AVCodecContext *s, AVFrame *frame, int flags)\n\n{\n\n    InputStream *ist = s->opaque;\n\n    QSVContext  *qsv = ist->hwaccel_ctx;\n\n    int i;\n\n\n\n    for (i = 0; i < qsv->nb_surfaces; i++) {\n\n        if (qsv->surface_used[i])\n\n            continue;\n\n\n\n        frame->buf[0] = av_buffer_create((uint8_t*)qsv->surface_ptrs[i], sizeof(*qsv->surface_ptrs[i]),\n\n                                         buffer_release, &qsv->surface_used[i], 0);\n\n        if (!frame->buf[0])\n\n            return AVERROR(ENOMEM);\n\n        frame->data[3]       = (uint8_t*)qsv->surface_ptrs[i];\n\n        qsv->surface_used[i] = 1;\n\n        return 0;\n\n    }\n\n\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 23020}
{"project": "FFmpeg", "commit_id": "f320fb894c695044ef15239d27844d9ac01c9d16", "target": 0, "func": "static int vid_read_packet(AVFormatContext *s,\n\n                           AVPacket *pkt)\n\n{\n\n    BVID_DemuxContext *vid = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    unsigned char block_type;\n\n    int audio_length;\n\n    int ret_value;\n\n\n\n    if(vid->is_finished || pb->eof_reached)\n\n        return AVERROR(EIO);\n\n\n\n    block_type = avio_r8(pb);\n\n    switch(block_type){\n\n        case PALETTE_BLOCK:\n\n            avio_seek(pb, -1, SEEK_CUR);     // include block type\n\n            ret_value = av_get_packet(pb, pkt, 3 * 256 + 1);\n\n            if(ret_value != 3 * 256 + 1){\n\n                av_free_packet(pkt);\n\n                return AVERROR(EIO);\n\n            }\n\n            pkt->stream_index = 0;\n\n            return ret_value;\n\n\n\n        case FIRST_AUDIO_BLOCK:\n\n            avio_rl16(pb);\n\n            // soundblaster DAC used for sample rate, as on specification page (link above)\n\n            s->streams[1]->codec->sample_rate = 1000000 / (256 - avio_r8(pb));\n\n            s->streams[1]->codec->bit_rate = s->streams[1]->codec->channels * s->streams[1]->codec->sample_rate * s->streams[1]->codec->bits_per_coded_sample;\n\n        case AUDIO_BLOCK:\n\n            audio_length = avio_rl16(pb);\n\n            ret_value = av_get_packet(pb, pkt, audio_length);\n\n            pkt->stream_index = 1;\n\n            return ret_value != audio_length ? AVERROR(EIO) : ret_value;\n\n\n\n        case VIDEO_P_FRAME:\n\n        case VIDEO_YOFF_P_FRAME:\n\n        case VIDEO_I_FRAME:\n\n            return read_frame(vid, pb, pkt, block_type, s,\n\n                              s->streams[0]->codec->width * s->streams[0]->codec->height);\n\n\n\n        case EOF_BLOCK:\n\n            if(vid->nframes != 0)\n\n                av_log(s, AV_LOG_VERBOSE, \"reached terminating character but not all frames read.\\n\");\n\n            vid->is_finished = 1;\n\n            return AVERROR(EIO);\n\n        default:\n\n            av_log(s, AV_LOG_ERROR, \"unknown block (character = %c, decimal = %d, hex = %x)!!!\\n\",\n\n                   block_type, block_type, block_type); return -1;\n\n    }\n\n}\n", "idx": 23021}
{"project": "FFmpeg", "commit_id": "ef4c71e8f83a46fb31a11f0a066efb90821c579f", "target": 0, "func": "static int config_props(AVFilterLink *link)\n\n{\n\n    UnsharpContext *unsharp = link->dst->priv;\n\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(link->format);\n\n\n\n    unsharp->hsub = desc->log2_chroma_w;\n\n    unsharp->vsub = desc->log2_chroma_h;\n\n\n\n    init_filter_param(link->dst, &unsharp->luma,   \"luma\",   link->w);\n\n    init_filter_param(link->dst, &unsharp->chroma, \"chroma\", SHIFTUP(link->w, unsharp->hsub));\n\n\n\n    return 0;\n\n}\n", "idx": 23022}
{"project": "FFmpeg", "commit_id": "68e79b27a5ed7cab55ab3c84c7b707d45fc81b61", "target": 0, "func": "void avpriv_solve_lls(LLSModel *m, double threshold, unsigned short min_order)\n\n{\n\n    int i, j, k;\n\n    double (*factor)[MAX_VARS_ALIGN] = (void *) &m->covariance[1][0];\n\n    double (*covar) [MAX_VARS_ALIGN] = (void *) &m->covariance[1][1];\n\n    double *covar_y                = m->covariance[0];\n\n    int count                      = m->indep_count;\n\n\n\n    for (i = 0; i < count; i++) {\n\n        for (j = i; j < count; j++) {\n\n            double sum = covar[i][j];\n\n\n\n            for (k = i - 1; k >= 0; k--)\n\n                sum -= factor[i][k] * factor[j][k];\n\n\n\n            if (i == j) {\n\n                if (sum < threshold)\n\n                    sum = 1.0;\n\n                factor[i][i] = sqrt(sum);\n\n            } else {\n\n                factor[j][i] = sum / factor[i][i];\n\n            }\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < count; i++) {\n\n        double sum = covar_y[i + 1];\n\n\n\n        for (k = i - 1; k >= 0; k--)\n\n            sum -= factor[i][k] * m->coeff[0][k];\n\n\n\n        m->coeff[0][i] = sum / factor[i][i];\n\n    }\n\n\n\n    for (j = count - 1; j >= min_order; j--) {\n\n        for (i = j; i >= 0; i--) {\n\n            double sum = m->coeff[0][i];\n\n\n\n            for (k = i + 1; k <= j; k++)\n\n                sum -= factor[k][i] * m->coeff[j][k];\n\n\n\n            m->coeff[j][i] = sum / factor[i][i];\n\n        }\n\n\n\n        m->variance[j] = covar_y[0];\n\n\n\n        for (i = 0; i <= j; i++) {\n\n            double sum = m->coeff[j][i] * covar[i][i] - 2 * covar_y[i + 1];\n\n\n\n            for (k = 0; k < i; k++)\n\n                sum += 2 * m->coeff[j][k] * covar[k][i];\n\n\n\n            m->variance[j] += m->coeff[j][i] * sum;\n\n        }\n\n    }\n\n}\n", "idx": 23023}
{"project": "FFmpeg", "commit_id": "bd6fa80d56fcda385da1c8f21eb83282a7930899", "target": 0, "func": "static int hap_encode(AVCodecContext *avctx, AVPacket *pkt,\n\n                      const AVFrame *frame, int *got_packet)\n\n{\n\n    HapContext *ctx = avctx->priv_data;\n\n    int header_length = hap_header_length(ctx);\n\n    int final_data_size, ret;\n\n    int pktsize = FFMAX(ctx->tex_size, ctx->max_snappy * ctx->chunk_count) + header_length;\n\n\n\n    /* Allocate maximum size packet, shrink later. */\n\n    ret = ff_alloc_packet2(avctx, pkt, pktsize, header_length);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    /* DXTC compression. */\n\n    ret = compress_texture(avctx, ctx->tex_buf, ctx->tex_size, frame);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    /* Compress (using Snappy) the frame */\n\n    final_data_size = hap_compress_frame(avctx, pkt->data + header_length);\n\n    if (final_data_size < 0)\n\n        return final_data_size;\n\n\n\n    /* Write header at the start. */\n\n    hap_write_frame_header(ctx, pkt->data, final_data_size + header_length);\n\n\n\n    av_shrink_packet(pkt, final_data_size + header_length);\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n\n    *got_packet = 1;\n\n    return 0;\n\n}\n", "idx": 23024}
{"project": "FFmpeg", "commit_id": "6eda91ad54fd3214610edb1e4a5adb58806c243e", "target": 0, "func": "static void add_pid_to_pmt(MpegTSContext *ts, unsigned int programid, unsigned int pid)\n\n{\n\n    int i;\n\n    struct Program *p = NULL;\n\n    for(i=0; i<ts->nb_prg; i++) {\n\n        if(ts->prg[i].id == programid) {\n\n            p = &ts->prg[i];\n\n            break;\n\n        }\n\n    }\n\n    if(!p)\n\n        return;\n\n\n\n    if(p->nb_pids >= MAX_PIDS_PER_PROGRAM)\n\n        return;\n\n    p->pids[p->nb_pids++] = pid;\n\n}\n", "idx": 23025}
{"project": "FFmpeg", "commit_id": "fdbbf2e0fc1bb91a5d735a49f39337eb172e68a7", "target": 0, "func": "void ff_h261_loop_filter(H261Context * h){\n\n    MpegEncContext * const s = &h->s;\n\n    int i;\n\n    const int linesize  = s->linesize;\n\n    const int uvlinesize= s->uvlinesize;\n\n    uint8_t *dest_y = s->dest[0];\n\n    uint8_t *dest_cb= s->dest[1];\n\n    uint8_t *dest_cr= s->dest[2];\n\n    uint8_t *src;\n\n\n\n    CHECKED_ALLOCZ((src),sizeof(uint8_t) * 64 );\n\n\n\n    for(i=0; i<8;i++)\n\n        memcpy(src+i*8,dest_y+i*linesize,sizeof(uint8_t) * 8 );\n\n    s->dsp.h261_v_loop_filter(dest_y, src, linesize);\n\n    s->dsp.h261_h_loop_filter(dest_y, src, linesize);\n\n\n\n    for(i=0; i<8;i++)\n\n        memcpy(src+i*8,dest_y+i*linesize + 8,sizeof(uint8_t) * 8 );\n\n    s->dsp.h261_v_loop_filter(dest_y + 8, src, linesize);\n\n    s->dsp.h261_h_loop_filter(dest_y + 8, src, linesize);\n\n\n\n    for(i=0; i<8;i++)\n\n        memcpy(src+i*8,dest_y+(i+8)*linesize,sizeof(uint8_t) * 8 );\n\n    s->dsp.h261_v_loop_filter(dest_y + 8 * linesize, src, linesize);\n\n    s->dsp.h261_h_loop_filter(dest_y + 8 * linesize, src, linesize);\n\n\n\n    for(i=0; i<8;i++)\n\n        memcpy(src+i*8,dest_y+(i+8)*linesize + 8,sizeof(uint8_t) * 8 );\n\n    s->dsp.h261_v_loop_filter(dest_y + 8 * linesize + 8, src, linesize);\n\n    s->dsp.h261_h_loop_filter(dest_y + 8 * linesize + 8, src, linesize);\n\n\n\n    for(i=0; i<8;i++)\n\n        memcpy(src+i*8,dest_cb+i*uvlinesize,sizeof(uint8_t) * 8 );\n\n    s->dsp.h261_v_loop_filter(dest_cb, src, uvlinesize);\n\n    s->dsp.h261_h_loop_filter(dest_cb, src, uvlinesize);\n\n\n\n    for(i=0; i<8;i++)\n\n        memcpy(src+i*8,dest_cr+i*uvlinesize,sizeof(uint8_t) * 8 );\n\n    s->dsp.h261_v_loop_filter(dest_cr, src, uvlinesize);\n\n    s->dsp.h261_h_loop_filter(dest_cr, src, uvlinesize);\n\n\n\nfail:\n\n    av_free(src);\n\n\n\n    return;\n\n}\n", "idx": 23026}
{"project": "FFmpeg", "commit_id": "dc2e4c2e532b80565f5fbacd3a24a6db7567c257", "target": 0, "func": "static int64_t wav_seek_tag(AVIOContext *s, int64_t offset, int whence)\n\n{\n\n    offset += offset < INT64_MAX && offset & 1;\n\n\n\n    return avio_seek(s, offset, whence);\n\n}\n", "idx": 23027}
{"project": "FFmpeg", "commit_id": "e549933a270dd2cfc36f2cf9bb6b29acf3dc6d08", "target": 0, "func": "void ff_put_h264_qpel8_mc32_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_midh_qrt_8w_msa(src - (2 * stride) - 2, stride, dst, stride, 8, 1);\n\n}\n", "idx": 23028}
{"project": "FFmpeg", "commit_id": "ce558c8f590610fc68596ef0b4ac2a9d299fbcb2", "target": 0, "func": "x11grab_read_header(AVFormatContext *s1, AVFormatParameters *ap)\n\n{\n\n    struct x11_grab *x11grab = s1->priv_data;\n\n    Display *dpy;\n\n    AVStream *st = NULL;\n\n    enum PixelFormat input_pixfmt;\n\n    XImage *image;\n\n    int x_off = 0;\n\n    int y_off = 0;\n\n    int use_shm;\n\n    char *param, *offset;\n\n    int ret = 0;\n\n    AVRational framerate;\n\n\n\n    param = av_strdup(s1->filename);\n\n    offset = strchr(param, '+');\n\n    if (offset) {\n\n        sscanf(offset, \"%d,%d\", &x_off, &y_off);\n\n        x11grab->nomouse= strstr(offset, \"nomouse\");\n\n        *offset= 0;\n\n    }\n\n\n\n    if ((ret = av_parse_video_size(&x11grab->width, &x11grab->height, x11grab->video_size)) < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"Couldn't parse video size.\\n\");\n\n        goto out;\n\n    }\n\n    if ((ret = av_parse_video_rate(&framerate, x11grab->framerate)) < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"Could not parse framerate: %s.\\n\", x11grab->framerate);\n\n        goto out;\n\n    }\n\n#if FF_API_FORMAT_PARAMETERS\n\n    if (ap->width > 0)\n\n        x11grab->width = ap->width;\n\n    if (ap->height > 0)\n\n        x11grab->height = ap->height;\n\n    if (ap->time_base.num)\n\n        framerate = (AVRational){ap->time_base.den, ap->time_base.num};\n\n#endif\n\n    av_log(s1, AV_LOG_INFO, \"device: %s -> display: %s x: %d y: %d width: %d height: %d\\n\",\n\n           s1->filename, param, x_off, y_off, x11grab->width, x11grab->height);\n\n\n\n    dpy = XOpenDisplay(param);\n\n    if(!dpy) {\n\n        av_log(s1, AV_LOG_ERROR, \"Could not open X display.\\n\");\n\n        ret = AVERROR(EIO);\n\n        goto out;\n\n    }\n\n\n\n    st = av_new_stream(s1, 0);\n\n    if (!st) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto out;\n\n    }\n\n    av_set_pts_info(st, 64, 1, 1000000); /* 64 bits pts in us */\n\n\n\n    use_shm = XShmQueryExtension(dpy);\n\n    av_log(s1, AV_LOG_INFO, \"shared memory extension %s found\\n\", use_shm ? \"\" : \"not\");\n\n\n\n    if(use_shm) {\n\n        int scr = XDefaultScreen(dpy);\n\n        image = XShmCreateImage(dpy,\n\n                                DefaultVisual(dpy, scr),\n\n                                DefaultDepth(dpy, scr),\n\n                                ZPixmap,\n\n                                NULL,\n\n                                &x11grab->shminfo,\n\n                                x11grab->width, x11grab->height);\n\n        x11grab->shminfo.shmid = shmget(IPC_PRIVATE,\n\n                                        image->bytes_per_line * image->height,\n\n                                        IPC_CREAT|0777);\n\n        if (x11grab->shminfo.shmid == -1) {\n\n            av_log(s1, AV_LOG_ERROR, \"Fatal: Can't get shared memory!\\n\");\n\n            ret = AVERROR(ENOMEM);\n\n            goto out;\n\n        }\n\n        x11grab->shminfo.shmaddr = image->data = shmat(x11grab->shminfo.shmid, 0, 0);\n\n        x11grab->shminfo.readOnly = False;\n\n\n\n        if (!XShmAttach(dpy, &x11grab->shminfo)) {\n\n            av_log(s1, AV_LOG_ERROR, \"Fatal: Failed to attach shared memory!\\n\");\n\n            /* needs some better error subroutine :) */\n\n            ret = AVERROR(EIO);\n\n            goto out;\n\n        }\n\n    } else {\n\n        image = XGetImage(dpy, RootWindow(dpy, DefaultScreen(dpy)),\n\n                          x_off,y_off,\n\n                          x11grab->width, x11grab->height,\n\n                          AllPlanes, ZPixmap);\n\n    }\n\n\n\n    switch (image->bits_per_pixel) {\n\n    case 8:\n\n        av_log (s1, AV_LOG_DEBUG, \"8 bit palette\\n\");\n\n        input_pixfmt = PIX_FMT_PAL8;\n\n        break;\n\n    case 16:\n\n        if (       image->red_mask   == 0xf800 &&\n\n                   image->green_mask == 0x07e0 &&\n\n                   image->blue_mask  == 0x001f ) {\n\n            av_log (s1, AV_LOG_DEBUG, \"16 bit RGB565\\n\");\n\n            input_pixfmt = PIX_FMT_RGB565;\n\n        } else if (image->red_mask   == 0x7c00 &&\n\n                   image->green_mask == 0x03e0 &&\n\n                   image->blue_mask  == 0x001f ) {\n\n            av_log(s1, AV_LOG_DEBUG, \"16 bit RGB555\\n\");\n\n            input_pixfmt = PIX_FMT_RGB555;\n\n        } else {\n\n            av_log(s1, AV_LOG_ERROR, \"RGB ordering at image depth %i not supported ... aborting\\n\", image->bits_per_pixel);\n\n            av_log(s1, AV_LOG_ERROR, \"color masks: r 0x%.6lx g 0x%.6lx b 0x%.6lx\\n\", image->red_mask, image->green_mask, image->blue_mask);\n\n            ret = AVERROR(EIO);\n\n            goto out;\n\n        }\n\n        break;\n\n    case 24:\n\n        if (        image->red_mask   == 0xff0000 &&\n\n                    image->green_mask == 0x00ff00 &&\n\n                    image->blue_mask  == 0x0000ff ) {\n\n            input_pixfmt = PIX_FMT_BGR24;\n\n        } else if ( image->red_mask   == 0x0000ff &&\n\n                    image->green_mask == 0x00ff00 &&\n\n                    image->blue_mask  == 0xff0000 ) {\n\n            input_pixfmt = PIX_FMT_RGB24;\n\n        } else {\n\n            av_log(s1, AV_LOG_ERROR,\"rgb ordering at image depth %i not supported ... aborting\\n\", image->bits_per_pixel);\n\n            av_log(s1, AV_LOG_ERROR, \"color masks: r 0x%.6lx g 0x%.6lx b 0x%.6lx\\n\", image->red_mask, image->green_mask, image->blue_mask);\n\n            ret = AVERROR(EIO);\n\n            goto out;\n\n        }\n\n        break;\n\n    case 32:\n\n        input_pixfmt = PIX_FMT_RGB32;\n\n        break;\n\n    default:\n\n        av_log(s1, AV_LOG_ERROR, \"image depth %i not supported ... aborting\\n\", image->bits_per_pixel);\n\n        ret = AVERROR(EINVAL);\n\n        goto out;\n\n    }\n\n\n\n    x11grab->frame_size = x11grab->width * x11grab->height * image->bits_per_pixel/8;\n\n    x11grab->dpy = dpy;\n\n    x11grab->time_base  = (AVRational){framerate.den, framerate.num};\n\n    x11grab->time_frame = av_gettime() / av_q2d(x11grab->time_base);\n\n    x11grab->x_off = x_off;\n\n    x11grab->y_off = y_off;\n\n    x11grab->image = image;\n\n    x11grab->use_shm = use_shm;\n\n\n\n    st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id = CODEC_ID_RAWVIDEO;\n\n    st->codec->width  = x11grab->width;\n\n    st->codec->height = x11grab->height;\n\n    st->codec->pix_fmt = input_pixfmt;\n\n    st->codec->time_base = x11grab->time_base;\n\n    st->codec->bit_rate = x11grab->frame_size * 1/av_q2d(x11grab->time_base) * 8;\n\n\n\nout:\n\n    return ret;\n\n}\n", "idx": 23029}
{"project": "FFmpeg", "commit_id": "009f829dde811af654af7110326aea3a72c05d5e", "target": 1, "func": "static inline void RENAME(yuv2yuyv422_1)(SwsContext *c, const uint16_t *buf0,\n\n                                         const uint16_t *ubuf0, const uint16_t *ubuf1,\n\n                                         const uint16_t *vbuf0, const uint16_t *vbuf1,\n\n                                         const uint16_t *abuf0, uint8_t *dest,\n\n                                         int dstW, int uvalpha, enum PixelFormat dstFormat,\n\n                                         int flags, int y)\n\n{\n\n    x86_reg uv_off = c->uv_off << 1;\n\n    const uint16_t *buf1= buf0; //FIXME needed for RGB1/BGR1\n\n\n\n    if (uvalpha < 2048) { // note this is not correct (shifts chrominance by 0.5 pixels) but it is a bit faster\n\n        __asm__ volatile(\n\n            \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n            \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n            \"push %%\"REG_BP\"                        \\n\\t\"\n\n            YSCALEYUV2PACKED1(%%REGBP, %5, %6)\n\n            WRITEYUY2(%%REGb, 8280(%5), %%REGBP)\n\n            \"pop %%\"REG_BP\"                         \\n\\t\"\n\n            \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n            :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n               \"a\" (&c->redDither), \"m\"(uv_off)\n\n        );\n\n    } else {\n\n        __asm__ volatile(\n\n            \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n            \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n            \"push %%\"REG_BP\"                        \\n\\t\"\n\n            YSCALEYUV2PACKED1b(%%REGBP, %5, %6)\n\n            WRITEYUY2(%%REGb, 8280(%5), %%REGBP)\n\n            \"pop %%\"REG_BP\"                         \\n\\t\"\n\n            \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n            :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n               \"a\" (&c->redDither), \"m\"(uv_off)\n\n        );\n\n    }\n\n}\n", "idx": 23031}
{"project": "FFmpeg", "commit_id": "80ca19f766aea8f4724aac1b3faa772d25163c8a", "target": 0, "func": "static int ipvideo_decode_block_opcode_0x4(IpvideoContext *s)\n\n{\n\n    int x, y;\n\n    unsigned char B, BL, BH;\n\n\n\n    /* copy a block from the previous frame; need 1 more byte */\n\n    CHECK_STREAM_PTR(1);\n\n\n\n    B = *s->stream_ptr++;\n\n    BL = B & 0x0F;\n\n    BH = (B >> 4) & 0x0F;\n\n    x = -8 + BL;\n\n    y = -8 + BH;\n\n\n\n    debug_interplay (\"    motion byte = %d, (x, y) = (%d, %d)\\n\", B, x, y);\n\n    return copy_from(s, &s->last_frame, x, y);\n\n}\n", "idx": 23035}
{"project": "FFmpeg", "commit_id": "20f93c3ccf03f258a5bb658565665a68b61f4996", "target": 0, "func": "static int open_input_stream(HTTPContext *c, const char *info)\n\n{\n\n    char buf[128];\n\n    char input_filename[1024];\n\n    AVFormatContext *s;\n\n    int buf_size, i, ret;\n\n    int64_t stream_pos;\n\n\n\n    /* find file name */\n\n    if (c->stream->feed) {\n\n        strcpy(input_filename, c->stream->feed->feed_filename);\n\n        buf_size = FFM_PACKET_SIZE;\n\n        /* compute position (absolute time) */\n\n        if (find_info_tag(buf, sizeof(buf), \"date\", info)) {\n\n            stream_pos = parse_date(buf, 0);\n\n            if (stream_pos == INT64_MIN)\n\n                return -1;\n\n        } else if (find_info_tag(buf, sizeof(buf), \"buffer\", info)) {\n\n            int prebuffer = strtol(buf, 0, 10);\n\n            stream_pos = av_gettime() - prebuffer * (int64_t)1000000;\n\n        } else\n\n            stream_pos = av_gettime() - c->stream->prebuffer * (int64_t)1000;\n\n    } else {\n\n        strcpy(input_filename, c->stream->feed_filename);\n\n        buf_size = 0;\n\n        /* compute position (relative time) */\n\n        if (find_info_tag(buf, sizeof(buf), \"date\", info)) {\n\n            stream_pos = parse_date(buf, 1);\n\n            if (stream_pos == INT64_MIN)\n\n                return -1;\n\n        } else\n\n            stream_pos = 0;\n\n    }\n\n    if (input_filename[0] == '\\0')\n\n        return -1;\n\n\n\n#if 0\n\n    { time_t when = stream_pos / 1000000;\n\n    http_log(\"Stream pos = %\"PRId64\", time=%s\", stream_pos, ctime(&when));\n\n    }\n\n#endif\n\n\n\n    /* open stream */\n\n    if ((ret = av_open_input_file(&s, input_filename, c->stream->ifmt,\n\n                                  buf_size, c->stream->ap_in)) < 0) {\n\n        http_log(\"could not open %s: %d\\n\", input_filename, ret);\n\n        return -1;\n\n    }\n\n    s->flags |= AVFMT_FLAG_GENPTS;\n\n    c->fmt_in = s;\n\n    av_find_stream_info(c->fmt_in);\n\n\n\n    /* open each parser */\n\n    for(i=0;i<s->nb_streams;i++)\n\n        open_parser(s, i);\n\n\n\n    /* choose stream as clock source (we favorize video stream if\n\n       present) for packet sending */\n\n    c->pts_stream_index = 0;\n\n    for(i=0;i<c->stream->nb_streams;i++) {\n\n        if (c->pts_stream_index == 0 &&\n\n            c->stream->streams[i]->codec->codec_type == CODEC_TYPE_VIDEO) {\n\n            c->pts_stream_index = i;\n\n        }\n\n    }\n\n\n\n#if 1\n\n    if (c->fmt_in->iformat->read_seek)\n\n        av_seek_frame(c->fmt_in, -1, stream_pos, 0);\n\n#endif\n\n    /* set the start time (needed for maxtime and RTP packet timing) */\n\n    c->start_time = cur_time;\n\n    c->first_pts = AV_NOPTS_VALUE;\n\n    return 0;\n\n}\n", "idx": 23036}
{"project": "FFmpeg", "commit_id": "73029abddc14c8a376ff81968fe9b1e171e4e9eb", "target": 0, "func": "static int rtcp_parse_packet(RTPDemuxContext *s, const unsigned char *buf,\n\n                             int len)\n\n{\n\n    int payload_len;\n\n    while (len >= 4) {\n\n        payload_len = FFMIN(len, (AV_RB16(buf + 2) + 1) * 4);\n\n\n\n        switch (buf[1]) {\n\n        case RTCP_SR:\n\n            if (payload_len < 20) {\n\n                av_log(NULL, AV_LOG_ERROR,\n\n                       \"Invalid length for RTCP SR packet\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            s->last_rtcp_reception_time = av_gettime_relative();\n\n            s->last_rtcp_ntp_time  = AV_RB64(buf + 8);\n\n            s->last_rtcp_timestamp = AV_RB32(buf + 16);\n\n            if (s->first_rtcp_ntp_time == AV_NOPTS_VALUE) {\n\n                s->first_rtcp_ntp_time = s->last_rtcp_ntp_time;\n\n                if (!s->base_timestamp)\n\n                    s->base_timestamp = s->last_rtcp_timestamp;\n\n                s->rtcp_ts_offset = s->last_rtcp_timestamp - s->base_timestamp;\n\n            }\n\n\n\n            break;\n\n        case RTCP_BYE:\n\n            return -RTCP_BYE;\n\n        }\n\n\n\n        buf += payload_len;\n\n        len -= payload_len;\n\n    }\n\n    return -1;\n\n}\n", "idx": 23037}
{"project": "FFmpeg", "commit_id": "e45a2872fafe631c14aee9f79d0963d68c4fc1fd", "target": 0, "func": "void idct_add_altivec(uint8_t* dest, int stride, vector_s16_t* block)\n\n{\n\nPOWERPC_TBL_DECLARE(altivec_idct_add_num, 1);\n\n#ifdef ALTIVEC_USE_REFERENCE_C_CODE\n\nPOWERPC_TBL_START_COUNT(altivec_idct_add_num, 1);\n\n    void simple_idct_add(uint8_t *dest, int line_size, int16_t *block);\n\n    simple_idct_add(dest, stride, (int16_t*)block);\n\nPOWERPC_TBL_STOP_COUNT(altivec_idct_add_num, 1);\n\n#else /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n    vector_u8_t tmp;\n\n    vector_s16_t tmp2, tmp3;\n\n    vector_u8_t perm0;\n\n    vector_u8_t perm1;\n\n    vector_u8_t p0, p1, p;\n\n\n\nPOWERPC_TBL_START_COUNT(altivec_idct_add_num, 1);\n\n\n\n    IDCT\n\n\n\n    p0 = vec_lvsl (0, dest);\n\n    p1 = vec_lvsl (stride, dest);\n\n    p = vec_splat_u8 (-1);\n\n    perm0 = vec_mergeh (p, p0);\n\n    perm1 = vec_mergeh (p, p1);\n\n\n\n#define ADD(dest,src,perm)\t\t\t\t\t\t\\\n\n    /* *(uint64_t *)&tmp = *(uint64_t *)dest; */\t\t\t\\\n\n    tmp = vec_ld (0, dest);\t\t\t\t\t\t\\\n\n    tmp2 = (vector_s16_t)vec_perm (tmp, (vector_u8_t)zero, perm);\t\\\n\n    tmp3 = vec_adds (tmp2, src);\t\t\t\t\t\\\n\n    tmp = vec_packsu (tmp3, tmp3);\t\t\t\t\t\\\n\n    vec_ste ((vector_u32_t)tmp, 0, (unsigned int *)dest);\t\t\\\n\n    vec_ste ((vector_u32_t)tmp, 4, (unsigned int *)dest);\n\n\n\n    ADD (dest, vx0, perm0)\tdest += stride;\n\n    ADD (dest, vx1, perm1)\tdest += stride;\n\n    ADD (dest, vx2, perm0)\tdest += stride;\n\n    ADD (dest, vx3, perm1)\tdest += stride;\n\n    ADD (dest, vx4, perm0)\tdest += stride;\n\n    ADD (dest, vx5, perm1)\tdest += stride;\n\n    ADD (dest, vx6, perm0)\tdest += stride;\n\n    ADD (dest, vx7, perm1)\n\n\n\nPOWERPC_TBL_STOP_COUNT(altivec_idct_add_num, 1);\n\n#endif /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n}\n", "idx": 23038}
{"project": "FFmpeg", "commit_id": "8e944891ce95ec8cf9f492d41cb9dac869449210", "target": 0, "func": "AVBufferRef *av_buffer_alloc(int size)\n\n{\n\n    AVBufferRef *ret = NULL;\n\n    uint8_t    *data = NULL;\n\n\n\n    data = av_malloc(size);\n\n    if (!data)\n\n        return NULL;\n\n\n\n    if(CONFIG_MEMORY_POISONING)\n\n        memset(data, 0x2a, size);\n\n\n\n    ret = av_buffer_create(data, size, av_buffer_default_free, NULL, 0);\n\n    if (!ret)\n\n        av_freep(&data);\n\n\n\n    return ret;\n\n}\n", "idx": 23039}
{"project": "FFmpeg", "commit_id": "83548fe894cdb455cc127f754d09905b6d23c173", "target": 0, "func": "static int gxf_write_header(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    GXFContext *gxf = s->priv_data;\n\n    GXFStreamContext *vsc = NULL;\n\n    uint8_t tracks[255] = {0};\n\n    int i, media_info = 0;\n\n\n\n    if (!pb->seekable) {\n\n        av_log(s, AV_LOG_ERROR, \"gxf muxer does not support streamed output, patch welcome\");\n\n        return -1;\n\n    }\n\n\n\n    gxf->flags |= 0x00080000; /* material is simple clip */\n\n    for (i = 0; i < s->nb_streams; ++i) {\n\n        AVStream *st = s->streams[i];\n\n        GXFStreamContext *sc = av_mallocz(sizeof(*sc));\n\n        if (!sc)\n\n            return AVERROR(ENOMEM);\n\n        st->priv_data = sc;\n\n\n\n        sc->media_type = ff_codec_get_tag(gxf_media_types, st->codecpar->codec_id);\n\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            if (st->codecpar->codec_id != AV_CODEC_ID_PCM_S16LE) {\n\n                av_log(s, AV_LOG_ERROR, \"only 16 BIT PCM LE allowed for now\\n\");\n\n                return -1;\n\n            }\n\n            if (st->codecpar->sample_rate != 48000) {\n\n                av_log(s, AV_LOG_ERROR, \"only 48000hz sampling rate is allowed\\n\");\n\n                return -1;\n\n            }\n\n            if (st->codecpar->channels != 1) {\n\n                av_log(s, AV_LOG_ERROR, \"only mono tracks are allowed\\n\");\n\n                return -1;\n\n            }\n\n            sc->track_type = 2;\n\n            sc->sample_rate = st->codecpar->sample_rate;\n\n            avpriv_set_pts_info(st, 64, 1, sc->sample_rate);\n\n            sc->sample_size = 16;\n\n            sc->frame_rate_index = -2;\n\n            sc->lines_index = -2;\n\n            sc->fields = -2;\n\n            gxf->audio_tracks++;\n\n            gxf->flags |= 0x04000000; /* audio is 16 bit pcm */\n\n            media_info = 'A';\n\n        } else if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            if (i != 0) {\n\n                av_log(s, AV_LOG_ERROR, \"video stream must be the first track\\n\");\n\n                return -1;\n\n            }\n\n            /* FIXME check from time_base ? */\n\n            if (st->codecpar->height == 480 || st->codecpar->height == 512) { /* NTSC or NTSC+VBI */\n\n                sc->frame_rate_index = 5;\n\n                sc->sample_rate = 60;\n\n                gxf->flags |= 0x00000080;\n\n                gxf->time_base = (AVRational){ 1001, 60000 };\n\n            } else if (st->codecpar->height == 576 || st->codecpar->height == 608) { /* PAL or PAL+VBI */\n\n                sc->frame_rate_index = 6;\n\n                sc->media_type++;\n\n                sc->sample_rate = 50;\n\n                gxf->flags |= 0x00000040;\n\n                gxf->time_base = (AVRational){ 1, 50 };\n\n            } else {\n\n                av_log(s, AV_LOG_ERROR, \"unsupported video resolution, \"\n\n                       \"gxf muxer only accepts PAL or NTSC resolutions currently\\n\");\n\n                return -1;\n\n            }\n\n            avpriv_set_pts_info(st, 64, gxf->time_base.num, gxf->time_base.den);\n\n            if (gxf_find_lines_index(st) < 0)\n\n                sc->lines_index = -1;\n\n            sc->sample_size = st->codecpar->bit_rate;\n\n            sc->fields = 2; /* interlaced */\n\n\n\n            vsc = sc;\n\n\n\n            switch (st->codecpar->codec_id) {\n\n            case AV_CODEC_ID_MJPEG:\n\n                sc->track_type = 1;\n\n                gxf->flags |= 0x00004000;\n\n                media_info = 'J';\n\n                break;\n\n            case AV_CODEC_ID_MPEG1VIDEO:\n\n                sc->track_type = 9;\n\n                gxf->mpeg_tracks++;\n\n                media_info = 'L';\n\n                break;\n\n            case AV_CODEC_ID_MPEG2VIDEO:\n\n                sc->first_gop_closed = -1;\n\n                sc->track_type = 4;\n\n                gxf->mpeg_tracks++;\n\n                gxf->flags |= 0x00008000;\n\n                media_info = 'M';\n\n                break;\n\n            case AV_CODEC_ID_DVVIDEO:\n\n                if (st->codecpar->format == AV_PIX_FMT_YUV422P) {\n\n                    sc->media_type += 2;\n\n                    sc->track_type = 6;\n\n                    gxf->flags |= 0x00002000;\n\n                    media_info = 'E';\n\n                } else {\n\n                    sc->track_type = 5;\n\n                    gxf->flags |= 0x00001000;\n\n                    media_info = 'D';\n\n                }\n\n                break;\n\n            default:\n\n                av_log(s, AV_LOG_ERROR, \"video codec not supported\\n\");\n\n                return -1;\n\n            }\n\n        }\n\n        /* FIXME first 10 audio tracks are 0 to 9 next 22 are A to V */\n\n        sc->media_info = media_info<<8 | ('0'+tracks[media_info]++);\n\n        sc->order = s->nb_streams - st->index;\n\n    }\n\n\n\n    if (ff_audio_interleave_init(s, GXF_samples_per_frame, (AVRational){ 1, 48000 }) < 0)\n\n        return -1;\n\n\n\n    gxf_init_timecode_track(&gxf->timecode_track, vsc);\n\n    gxf->flags |= 0x200000; // time code track is non-drop frame\n\n\n\n    gxf_write_map_packet(s, 0);\n\n    gxf_write_flt_packet(s);\n\n    gxf_write_umf_packet(s);\n\n\n\n    gxf->packet_count = 3;\n\n\n\n    avio_flush(pb);\n\n    return 0;\n\n}\n", "idx": 23049}
{"project": "FFmpeg", "commit_id": "1ec83d9a9e472f485897ac92bad9631d551a8c5b", "target": 0, "func": "static unsigned tget(const uint8_t **p, int type, int le)\n\n{\n\n    switch (type) {\n\n    case TIFF_BYTE : return *(*p)++;\n\n    case TIFF_SHORT: return tget_short(p, le);\n\n    case TIFF_LONG : return tget_long(p, le);\n\n    default        : return UINT_MAX;\n\n    }\n\n}\n", "idx": 23060}
{"project": "FFmpeg", "commit_id": "68f593b48433842f3407586679fe07f3e5199ab9", "target": 0, "func": "static int mpeg4_decode_partitioned_mb(MpegEncContext *s, DCTELEM block[6][64])\n\n{\n\n    int cbp, mb_type;\n\n    const int xy= s->mb_x + s->mb_y*s->mb_width;\n\n\n\n    mb_type= s->mb_type[xy];\n\n    cbp = s->cbp_table[xy];\n\n\n\n    if(s->current_picture.qscale_table[xy] != s->qscale){\n\n        s->qscale= s->current_picture.qscale_table[xy];\n\n        s->y_dc_scale= s->y_dc_scale_table[ s->qscale ];\n\n        s->c_dc_scale= s->c_dc_scale_table[ s->qscale ];\n\n    }\n\n    \n\n    if (s->pict_type == P_TYPE || s->pict_type==S_TYPE) {\n\n        int i;\n\n        for(i=0; i<4; i++){\n\n            s->mv[0][i][0] = s->motion_val[ s->block_index[i] ][0];\n\n            s->mv[0][i][1] = s->motion_val[ s->block_index[i] ][1];\n\n        }\n\n        s->mb_intra = mb_type&MB_TYPE_INTRA;\n\n\n\n        if (mb_type&MB_TYPE_SKIPED) {\n\n            /* skip mb */\n\n            for(i=0;i<6;i++)\n\n                s->block_last_index[i] = -1;\n\n            s->mv_dir = MV_DIR_FORWARD;\n\n            s->mv_type = MV_TYPE_16X16;\n\n            if(s->pict_type==S_TYPE && s->vol_sprite_usage==GMC_SPRITE){\n\n                s->mcsel=1;\n\n                s->mb_skiped = 0;\n\n            }else{\n\n                s->mcsel=0;\n\n                s->mb_skiped = 1;\n\n            }\n\n        }else if(s->mb_intra){\n\n            s->ac_pred = s->pred_dir_table[xy]>>7;\n\n\n\n            /* decode each block */\n\n            for (i = 0; i < 6; i++) {\n\n                if(mpeg4_decode_block(s, block[i], i, cbp&32, 1) < 0){\n\n                    fprintf(stderr, \"texture corrupted at %d %d\\n\", s->mb_x, s->mb_y);\n\n                    return -1;\n\n                }\n\n                cbp+=cbp;\n\n            }\n\n        }else if(!s->mb_intra){\n\n//            s->mcsel= 0; //FIXME do we need to init that\n\n            \n\n            s->mv_dir = MV_DIR_FORWARD;\n\n            if (mb_type&MB_TYPE_INTER4V) {\n\n                s->mv_type = MV_TYPE_8X8;\n\n            } else {\n\n                s->mv_type = MV_TYPE_16X16;\n\n            }\n\n            /* decode each block */\n\n            for (i = 0; i < 6; i++) {\n\n                if(mpeg4_decode_block(s, block[i], i, cbp&32, 0) < 0){\n\n                    fprintf(stderr, \"texture corrupted at %d %d (trying to continue with mc/dc only)\\n\", s->mb_x, s->mb_y);\n\n                    return -1;\n\n                }\n\n                cbp+=cbp;\n\n            }\n\n        }\n\n    } else { /* I-Frame */\n\n        int i;\n\n        s->mb_intra = 1;\n\n        s->ac_pred = s->pred_dir_table[xy]>>7;\n\n        \n\n        /* decode each block */\n\n        for (i = 0; i < 6; i++) {\n\n            if(mpeg4_decode_block(s, block[i], i, cbp&32, 1) < 0){\n\n                fprintf(stderr, \"texture corrupted at %d %d (trying to continue with dc only)\\n\", s->mb_x, s->mb_y);\n\n                return -1;\n\n            }\n\n            cbp+=cbp;\n\n        }\n\n    }\n\n\n\n    s->error_status_table[xy]&= ~AC_ERROR;\n\n\n\n    /* per-MB end of slice check */\n\n\n\n    if(--s->mb_num_left <= 0){\n\n//printf(\"%06X %d\\n\", show_bits(&s->gb, 24), s->gb.size*8 - get_bits_count(&s->gb));\n\n        if(mpeg4_is_resync(s))\n\n            return SLICE_END;\n\n        else\n\n            return SLICE_NOEND;     \n\n    }else{\n\n        if(s->cbp_table[xy+1] && mpeg4_is_resync(s))\n\n            return SLICE_END;\n\n        else\n\n            return SLICE_OK;\n\n    }\n\n}\n", "idx": 23069}
{"project": "FFmpeg", "commit_id": "32c3047cac9294bb56d23c89a40a22409db5cc70", "target": 0, "func": "static int roq_decode_init(AVCodecContext *avctx)\n\n{\n\n    RoqContext *s = avctx->priv_data;\n\n\n\n    s->avctx = avctx;\n\n    s->width = avctx->width;\n\n    s->height = avctx->height;\n\n    s->last_frame    = &s->frames[0];\n\n    s->current_frame = &s->frames[1];\n\n    avctx->pix_fmt = PIX_FMT_YUV444P;\n\n    dsputil_init(&s->dsp, avctx);\n\n\n\n    return 0;\n\n}\n", "idx": 23080}
{"project": "FFmpeg", "commit_id": "5b6d5596807e546d87f0afd1fb760b0f887b5c97", "target": 0, "func": "static void opt_format(const char *arg)\n\n{\n\n    /* compatibility stuff for pgmyuv */\n\n    if (!strcmp(arg, \"pgmyuv\")) {\n\n        opt_image_format(arg);\n\n        arg = \"image\";\n\n    }\n\n\n\n    file_iformat = av_find_input_format(arg);\n\n    file_oformat = guess_format(arg, NULL, NULL);\n\n    if (!file_iformat && !file_oformat) {\n\n        fprintf(stderr, \"Unknown input or output format: %s\\n\", arg);\n\n        exit(1);\n\n    }\n\n}\n", "idx": 23091}
{"project": "FFmpeg", "commit_id": "073c2593c9f0aa4445a6fc1b9b24e6e52a8cc2c1", "target": 1, "func": "void init_vlc_rl(RLTable *rl)\n\n{\n\n    int i, q;\n\n    \n\n    init_vlc(&rl->vlc, 9, rl->n + 1, \n\n             &rl->table_vlc[0][1], 4, 2,\n\n             &rl->table_vlc[0][0], 4, 2);\n\n\n\n    \n\n    for(q=0; q<32; q++){\n\n        int qmul= q*2;\n\n        int qadd= (q-1)|1;\n\n        \n\n        if(q==0){\n\n            qmul=1;\n\n            qadd=0;\n\n        }\n\n        \n\n        rl->rl_vlc[q]= av_malloc(rl->vlc.table_size*sizeof(RL_VLC_ELEM));\n\n        for(i=0; i<rl->vlc.table_size; i++){\n\n            int code= rl->vlc.table[i][0];\n\n            int len = rl->vlc.table[i][1];\n\n            int level, run;\n\n        \n\n            if(len==0){ // illegal code\n\n                run= 66;\n\n                level= MAX_LEVEL;\n\n            }else if(len<0){ //more bits needed\n\n                run= 0;\n\n                level= code;\n\n            }else{\n\n                if(code==rl->n){ //esc\n\n                    run= 66;\n\n                    level= 0;\n\n                }else{\n\n                    run=   rl->table_run  [code] + 1;\n\n                    level= rl->table_level[code] * qmul + qadd;\n\n                    if(code >= rl->last) run+=192;\n\n                }\n\n            }\n\n            rl->rl_vlc[q][i].len= len;\n\n            rl->rl_vlc[q][i].level= level;\n\n            rl->rl_vlc[q][i].run= run;\n\n        }\n\n    }\n\n}\n", "idx": 23095}
{"project": "FFmpeg", "commit_id": "39bb30f6640fe1faf4bbc779a79786028febc95d", "target": 1, "func": "static int mxf_read_material_package(MXFPackage *package, ByteIOContext *pb, int tag)\n\n{\n\n    switch(tag) {\n\n    case 0x4403:\n\n        package->tracks_count = get_be32(pb);\n\n        if (package->tracks_count >= UINT_MAX / sizeof(UID))\n\n            return -1;\n\n        package->tracks_refs = av_malloc(package->tracks_count * sizeof(UID));\n\n        if (!package->tracks_refs)\n\n            return -1;\n\n        url_fskip(pb, 4); /* useless size of objects, always 16 according to specs */\n\n        get_buffer(pb, (uint8_t *)package->tracks_refs, package->tracks_count * sizeof(UID));\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 23098}
{"project": "FFmpeg", "commit_id": "f8f7ad758d0e1f36915467567f4d75541d98c12f", "target": 0, "func": "static int select_rc_mode(AVCodecContext *avctx, QSVEncContext *q)\n\n{\n\n    const char *rc_desc;\n\n    mfxU16      rc_mode;\n\n\n\n    int want_la     = q->la_depth >= 0;\n\n    int want_qscale = !!(avctx->flags & AV_CODEC_FLAG_QSCALE);\n\n    int want_vcm    = q->vcm;\n\n\n\n    if (want_la && !QSV_HAVE_LA) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Lookahead ratecontrol mode requested, but is not supported by this SDK version\\n\");\n\n        return AVERROR(ENOSYS);\n\n    }\n\n    if (want_vcm && !QSV_HAVE_VCM) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"VCM ratecontrol mode requested, but is not supported by this SDK version\\n\");\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    if (want_la + want_qscale + want_vcm > 1) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"More than one of: { constant qscale, lookahead, VCM } requested, \"\n\n               \"only one of them can be used at a time.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (want_qscale) {\n\n        rc_mode = MFX_RATECONTROL_CQP;\n\n        rc_desc = \"constant quantization parameter (CQP)\";\n\n    }\n\n#if QSV_HAVE_VCM\n\n    else if (want_vcm) {\n\n        rc_mode = MFX_RATECONTROL_VCM;\n\n        rc_desc = \"video conferencing mode (VCM)\";\n\n    }\n\n#endif\n\n#if QSV_HAVE_LA\n\n    else if (want_la) {\n\n        rc_mode = MFX_RATECONTROL_LA;\n\n        rc_desc = \"VBR with lookahead (LA)\";\n\n\n\n#if QSV_HAVE_ICQ\n\n        if (avctx->global_quality > 0) {\n\n            rc_mode = MFX_RATECONTROL_LA_ICQ;\n\n            rc_desc = \"intelligent constant quality with lookahead (LA_ICQ)\";\n\n        }\n\n#endif\n\n    }\n\n#endif\n\n#if QSV_HAVE_ICQ\n\n    else if (avctx->global_quality > 0) {\n\n        rc_mode = MFX_RATECONTROL_ICQ;\n\n        rc_desc = \"intelligent constant quality (ICQ)\";\n\n    }\n\n#endif\n\n    else if (avctx->rc_max_rate == avctx->bit_rate) {\n\n        rc_mode = MFX_RATECONTROL_CBR;\n\n        rc_desc = \"constant bitrate (CBR)\";\n\n    } else if (!avctx->rc_max_rate) {\n\n        rc_mode = MFX_RATECONTROL_AVBR;\n\n        rc_desc = \"average variable bitrate (AVBR)\";\n\n    } else {\n\n        rc_mode = MFX_RATECONTROL_VBR;\n\n        rc_desc = \"variable bitrate (VBR)\";\n\n    }\n\n\n\n    q->param.mfx.RateControlMethod = rc_mode;\n\n    av_log(avctx, AV_LOG_VERBOSE, \"Using the %s ratecontrol method\\n\", rc_desc);\n\n\n\n    return 0;\n\n}\n", "idx": 23100}
{"project": "FFmpeg", "commit_id": "0105ed551cb9610c62b6920a301125781e1161a0", "target": 0, "func": "void ff_avg_h264_qpel4_mc00_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avg_width4_msa(src, stride, dst, stride, 4);\n\n}\n", "idx": 23111}
{"project": "FFmpeg", "commit_id": "91abb473fb8432226918da4fe03365ebaf688978", "target": 0, "func": "static void put_pixels_y2_mmx(UINT8 *block, const UINT8 *pixels, int line_size, int h)\n\n{\n\n#if 0\n\n  UINT8 *p;\n\n  const UINT8 *pix;\n\n  p = block;\n\n  pix = pixels;\n\n  MOVQ_ZERO(mm7);\n\n  MOVQ_WONE(mm4);\n\n  JUMPALIGN();\n\n  do {\n\n    __asm __volatile(\n\n\t\"movq\t%1, %%mm0\\n\\t\"\n\n\t\"movq\t%2, %%mm1\\n\\t\"\n\n\t\"movq\t%%mm0, %%mm2\\n\\t\"\n\n\t\"movq\t%%mm1, %%mm3\\n\\t\"\n\n\t\"punpcklbw %%mm7, %%mm0\\n\\t\"\n\n\t\"punpcklbw %%mm7, %%mm1\\n\\t\"\n\n\t\"punpckhbw %%mm7, %%mm2\\n\\t\"\n\n\t\"punpckhbw %%mm7, %%mm3\\n\\t\"\n\n\t\"paddusw %%mm1, %%mm0\\n\\t\"\n\n\t\"paddusw %%mm3, %%mm2\\n\\t\"\n\n\t\"paddusw %%mm4, %%mm0\\n\\t\"\n\n\t\"paddusw %%mm4, %%mm2\\n\\t\"\n\n\t\"psrlw\t$1, %%mm0\\n\\t\"\n\n\t\"psrlw\t$1, %%mm2\\n\\t\"\n\n\t\"packuswb  %%mm2, %%mm0\\n\\t\"\n\n\t\"movq\t%%mm0, %0\\n\\t\"\n\n\t:\"=m\"(*p)\n\n\t:\"m\"(*pix),\n\n\t \"m\"(*(pix+line_size))\n\n\t:\"memory\");\n\n   pix += line_size;\n\n   p += line_size;\n\n  } while (--h);\n\n#else\n\n  __asm __volatile(\n\n  \tMOVQ_BFE(%%mm7)\n\n\t\"lea (%3, %3), %%eax\t\\n\\t\"\n\n\t\"movq (%1), %%mm0\t\\n\\t\"\n\n\t\".balign 8     \t\t\\n\\t\"\n\n\t\"1:\t\t\t\\n\\t\"\n\n\t\"movq (%1, %3), %%mm1\t\\n\\t\"\n\n\t\"movq (%1, %%eax),%%mm2\t\\n\\t\"\n\n\tPAVG_MMX(%%mm1, %%mm0)\n\n\t\"movq %%mm6, (%2)\t\\n\\t\"\n\n\tPAVG_MMX(%%mm2, %%mm1)\n\n\t\"movq %%mm6, (%2, %3)\t\\n\\t\"\n\n\t\"addl %%eax, %1\t\t\\n\\t\"\n\n\t\"addl %%eax, %2\t\t\\n\\t\"\n\n#ifdef LONG_UNROLL\n\n\t\"movq (%1, %3), %%mm1\t\\n\\t\"\n\n\t\"movq (%1, %%eax),%%mm0\t\\n\\t\"\n\n\tPAVG_MMX(%%mm1, %%mm2)\n\n\t\"movq %%mm6, (%2)\t\\n\\t\"\n\n\tPAVG_MMX(%%mm0, %%mm1)\n\n\t\"movq %%mm6, (%2, %3)\t\\n\\t\"\n\n\t\"addl %%eax, %1\t\t\\n\\t\"\n\n\t\"addl %%eax, %2\t\t\\n\\t\"\n\n\t\"subl $4, %0\t\t\\n\\t\"\n\n#else\n\n\t\"subl $2, %0\t\t\\n\\t\"\n\n#endif\n\n\t\"jnz 1b\t\t\t\\n\\t\"\n\n\t:\"+g\"(h), \"+S\"(pixels), \"+D\"(block)\n\n\t:\"r\"(line_size)\n\n\t:\"eax\", \"memory\");\n\n#endif\n\n\n\n\n\n}\n", "idx": 23112}
{"project": "FFmpeg", "commit_id": "9a0f60a0f89a7a71839dfa9def5a26f2037aed62", "target": 0, "func": "static int mpeg4_decode_gop_header(MpegEncContext *s, GetBitContext *gb)\n\n{\n\n    int hours, minutes, seconds;\n\n\n\n    if (!show_bits(gb, 23)) {\n\n        av_log(s->avctx, AV_LOG_WARNING, \"GOP header invalid\\n\");\n\n        return -1;\n\n    }\n\n\n\n    hours   = get_bits(gb, 5);\n\n    minutes = get_bits(gb, 6);\n\n    skip_bits1(gb);\n\n    seconds = get_bits(gb, 6);\n\n\n\n    s->time_base = seconds + 60*(minutes + 60*hours);\n\n\n\n    skip_bits1(gb);\n\n    skip_bits1(gb);\n\n\n\n    return 0;\n\n}\n", "idx": 23123}
{"project": "FFmpeg", "commit_id": "60819e694ee5733741da91ebc237b20621de5bc3", "target": 1, "func": "static av_cold int decode_close(AVCodecContext *avctx)\n{\n    IVI5DecContext *ctx = avctx->priv_data;\n    ff_ivi_free_buffers(&ctx->planes[0]);\n    if (ctx->frame.data[0])\n        avctx->release_buffer(avctx, &ctx->frame);\n    return 0;\n}", "idx": 23127}
{"project": "FFmpeg", "commit_id": "2c28e26913df927e71d87fa851c9d950f281523b", "target": 1, "func": "static int input_get_buffer(AVCodecContext *codec, AVFrame *pic)\n\n{\n\n    AVFilterContext *ctx = codec->opaque;\n\n    AVFilterBufferRef  *ref;\n\n    int perms = AV_PERM_WRITE;\n\n    int i, w, h, stride[4];\n\n    unsigned edge;\n\n    int pixel_size;\n\n\n\n    av_assert0(codec->flags & CODEC_FLAG_EMU_EDGE);\n\n\n\n    if (codec->codec->capabilities & CODEC_CAP_NEG_LINESIZES)\n\n        perms |= AV_PERM_NEG_LINESIZES;\n\n\n\n    if(pic->buffer_hints & FF_BUFFER_HINTS_VALID) {\n\n        if(pic->buffer_hints & FF_BUFFER_HINTS_READABLE) perms |= AV_PERM_READ;\n\n        if(pic->buffer_hints & FF_BUFFER_HINTS_PRESERVE) perms |= AV_PERM_PRESERVE;\n\n        if(pic->buffer_hints & FF_BUFFER_HINTS_REUSABLE) perms |= AV_PERM_REUSE2;\n\n    }\n\n    if(pic->reference) perms |= AV_PERM_READ | AV_PERM_PRESERVE;\n\n\n\n    w = codec->width;\n\n    h = codec->height;\n\n\n\n    if(av_image_check_size(w, h, 0, codec))\n\n        return -1;\n\n\n\n    avcodec_align_dimensions2(codec, &w, &h, stride);\n\n    edge = codec->flags & CODEC_FLAG_EMU_EDGE ? 0 : avcodec_get_edge_width();\n\n    w += edge << 1;\n\n    h += edge << 1;\n\n\n\n    if(!(ref = avfilter_get_video_buffer(ctx->outputs[0], perms, w, h)))\n\n        return -1;\n\n\n\n    pixel_size = av_pix_fmt_descriptors[ref->format].comp[0].step_minus1+1;\n\n    ref->video->w = codec->width;\n\n    ref->video->h = codec->height;\n\n    for(i = 0; i < 4; i ++) {\n\n        unsigned hshift = (i == 1 || i == 2) ? av_pix_fmt_descriptors[ref->format].log2_chroma_w : 0;\n\n        unsigned vshift = (i == 1 || i == 2) ? av_pix_fmt_descriptors[ref->format].log2_chroma_h : 0;\n\n\n\n        if (ref->data[i]) {\n\n            ref->data[i]    += ((edge * pixel_size) >> hshift) + ((edge * ref->linesize[i]) >> vshift);\n\n        }\n\n        pic->data[i]     = ref->data[i];\n\n        pic->linesize[i] = ref->linesize[i];\n\n    }\n\n    pic->opaque = ref;\n\n    pic->age    = INT_MAX;\n\n    pic->type   = FF_BUFFER_TYPE_USER;\n\n    pic->reordered_opaque = codec->reordered_opaque;\n\n    if(codec->pkt) pic->pkt_pts = codec->pkt->pts;\n\n    else           pic->pkt_pts = AV_NOPTS_VALUE;\n\n    return 0;\n\n}\n", "idx": 23132}
{"project": "FFmpeg", "commit_id": "ddbcc48b646737c8bff7f8e28e0a69dca65509cf", "target": 0, "func": "static int ftp_restart(FTPContext *s, int64_t pos)\n\n{\n\n    char command[CONTROL_BUFFER_SIZE];\n\n    const int rest_codes[] = {350, 0};\n\n\n\n    snprintf(command, sizeof(command), \"REST %\"PRId64\"\\r\\n\", pos);\n\n    if (!ftp_send_command(s, command, rest_codes, NULL))\n\n        return AVERROR(EIO);\n\n\n\n    return 0;\n\n}\n", "idx": 23136}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int idcin_probe(AVProbeData *p)\n\n{\n\n    unsigned int number;\n\n\n\n    /*\n\n     * This is what you could call a \"probabilistic\" file check: Id CIN\n\n     * files don't have a definite file signature. In lieu of such a marker,\n\n     * perform sanity checks on the 5 32-bit header fields:\n\n     *  width, height: greater than 0, less than or equal to 1024\n\n     * audio sample rate: greater than or equal to 8000, less than or\n\n     *  equal to 48000, or 0 for no audio\n\n     * audio sample width (bytes/sample): 0 for no audio, or 1 or 2\n\n     * audio channels: 0 for no audio, or 1 or 2\n\n     */\n\n\n\n    /* cannot proceed without 20 bytes */\n\n    if (p->buf_size < 20)\n\n        return 0;\n\n\n\n    /* check the video width */\n\n    number = AV_RL32(&p->buf[0]);\n\n    if ((number == 0) || (number > 1024))\n\n       return 0;\n\n\n\n    /* check the video height */\n\n    number = AV_RL32(&p->buf[4]);\n\n    if ((number == 0) || (number > 1024))\n\n       return 0;\n\n\n\n    /* check the audio sample rate */\n\n    number = AV_RL32(&p->buf[8]);\n\n    if ((number != 0) && ((number < 8000) | (number > 48000)))\n\n        return 0;\n\n\n\n    /* check the audio bytes/sample */\n\n    number = AV_RL32(&p->buf[12]);\n\n    if (number > 2)\n\n        return 0;\n\n\n\n    /* check the audio channels */\n\n    number = AV_RL32(&p->buf[16]);\n\n    if (number > 2)\n\n        return 0;\n\n\n\n    /* return half certainly since this check is a bit sketchy */\n\n    return AVPROBE_SCORE_MAX / 2;\n\n}\n", "idx": 23147}
{"project": "FFmpeg", "commit_id": "b754978a3b0aa17e7794f64c69bf4491762797fd", "target": 0, "func": "static int av_seek_frame_generic(AVFormatContext *s, \n\n                                 int stream_index, int64_t timestamp)\n\n{\n\n    int index;\n\n    AVStream *st;\n\n    AVIndexEntry *ie;\n\n\n\n    if (!s->index_built) {\n\n        if (is_raw_stream(s)) {\n\n            av_build_index_raw(s);\n\n        } else {\n\n            return -1;\n\n        }\n\n        s->index_built = 1;\n\n    }\n\n\n\n    if (stream_index < 0)\n\n        stream_index = 0;\n\n    st = s->streams[stream_index];\n\n    index = index_search_timestamp(st->index_entries, st->nb_index_entries,\n\n                                   timestamp);\n\n    if (index < 0)\n\n        return -1;\n\n\n\n    /* now we have found the index, we can seek */\n\n    ie = &st->index_entries[index];\n\n    av_read_frame_flush(s);\n\n    url_fseek(&s->pb, ie->pos, SEEK_SET);\n\n    st->cur_dts = ie->timestamp;\n\n    return 0;\n\n}\n", "idx": 23156}
{"project": "FFmpeg", "commit_id": "4b54c6d08437e5e3dd9359f29b247be58fef965f", "target": 0, "func": "static int read_key(void)\n\n{\n\n#if defined(HAVE_CONIO_H)\n\n    if(kbhit())\n\n        return(getch());\n\n#elif defined(HAVE_TERMIOS_H)\n\n    int n = 1;\n\n    unsigned char ch;\n\n#ifndef CONFIG_BEOS_NETSERVER\n\n    struct timeval tv;\n\n    fd_set rfds;\n\n\n\n    FD_ZERO(&rfds);\n\n    FD_SET(0, &rfds);\n\n    tv.tv_sec = 0;\n\n    tv.tv_usec = 0;\n\n    n = select(1, &rfds, NULL, NULL, &tv);\n\n#endif\n\n    if (n > 0) {\n\n        n = read(0, &ch, 1);\n\n        if (n == 1)\n\n            return ch;\n\n\n\n        return n;\n\n    }\n\n#endif\n\n    return -1;\n\n}\n", "idx": 23157}
{"project": "FFmpeg", "commit_id": "bb146bb57bea6647f9c080aa4f9323a3a789ad22", "target": 0, "func": "theora_gptopts(AVFormatContext *ctx, int idx, uint64_t gp, int64_t *dts)\n\n{\n\n    struct ogg *ogg = ctx->priv_data;\n\n    struct ogg_stream *os = ogg->streams + idx;\n\n    struct theora_params *thp = os->private;\n\n    uint64_t iframe = gp >> thp->gpshift;\n\n    uint64_t pframe = gp & thp->gpmask;\n\n\n\n    if (thp->version < 0x030201)\n\n        iframe++;\n\n\n\n    if(!pframe)\n\n        os->pflags |= AV_PKT_FLAG_KEY;\n\n\n\n    if (dts)\n\n        *dts = iframe + pframe;\n\n\n\n    return iframe + pframe;\n\n}\n", "idx": 23159}
{"project": "FFmpeg", "commit_id": "fd34dbea58e097609ff09cf7dcc59f74930195d3", "target": 1, "func": "static int mxf_read_index_table_segment(void *arg, AVIOContext *pb, int tag, int size, UID uid)\n\n{\n\n    MXFIndexTableSegment *segment = arg;\n\n    switch(tag) {\n\n    case 0x3F05:\n\n        segment->edit_unit_byte_count = avio_rb32(pb);\n\n        av_dlog(NULL, \"EditUnitByteCount %d\\n\", segment->edit_unit_byte_count);\n\n        break;\n\n    case 0x3F06:\n\n        segment->index_sid = avio_rb32(pb);\n\n        av_dlog(NULL, \"IndexSID %d\\n\", segment->index_sid);\n\n        break;\n\n    case 0x3F07:\n\n        segment->body_sid = avio_rb32(pb);\n\n        av_dlog(NULL, \"BodySID %d\\n\", segment->body_sid);\n\n        break;\n\n    case 0x3F08:\n\n        segment->slice_count = avio_r8(pb);\n\n        av_dlog(NULL, \"SliceCount %d\\n\", segment->slice_count);\n\n        break;\n\n    case 0x3F09:\n\n        av_dlog(NULL, \"DeltaEntryArray found\\n\");\n\n        return mxf_read_delta_entry_array(pb, segment);\n\n    case 0x3F0A:\n\n        av_dlog(NULL, \"IndexEntryArray found\\n\");\n\n        return mxf_read_index_entry_array(pb, segment);\n\n    case 0x3F0B:\n\n        segment->index_edit_rate.num = avio_rb32(pb);\n\n        segment->index_edit_rate.den = avio_rb32(pb);\n\n        av_dlog(NULL, \"IndexEditRate %d/%d\\n\", segment->index_edit_rate.num,\n\n                segment->index_edit_rate.den);\n\n        break;\n\n    case 0x3F0C:\n\n        segment->index_start_position = avio_rb64(pb);\n\n        av_dlog(NULL, \"IndexStartPosition %\"PRId64\"\\n\", segment->index_start_position);\n\n        break;\n\n    case 0x3F0D:\n\n        segment->index_duration = avio_rb64(pb);\n\n        av_dlog(NULL, \"IndexDuration %\"PRId64\"\\n\", segment->index_duration);\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 23160}
{"project": "FFmpeg", "commit_id": "b754978a3b0aa17e7794f64c69bf4491762797fd", "target": 0, "func": "static void av_build_index_raw(AVFormatContext *s)\n\n{\n\n    AVPacket pkt1, *pkt = &pkt1;\n\n    int ret;\n\n    AVStream *st;\n\n\n\n    st = s->streams[0];\n\n    av_read_frame_flush(s);\n\n    url_fseek(&s->pb, s->data_offset, SEEK_SET);\n\n\n\n    for(;;) {\n\n        ret = av_read_frame(s, pkt);\n\n        if (ret < 0)\n\n            break;\n\n        if (pkt->stream_index == 0 && st->parser &&\n\n            (pkt->flags & PKT_FLAG_KEY)) {\n\n            add_index_entry(st, st->parser->frame_offset, pkt->dts, \n\n                            AVINDEX_KEYFRAME);\n\n        }\n\n        av_free_packet(pkt);\n\n    }\n\n}\n", "idx": 23161}
{"project": "FFmpeg", "commit_id": "f684f3c58a77a20f18b80f888d69c2bacb53ca9b", "target": 0, "func": "SwsContext *sws_getContext(int srcW, int srcH, enum PixelFormat srcFormat,\n\n                           int dstW, int dstH, enum PixelFormat dstFormat, int flags,\n\n                           SwsFilter *srcFilter, SwsFilter *dstFilter, const double *param)\n\n{\n\n    SwsContext *c;\n\n    int i;\n\n    int usesVFilter, usesHFilter;\n\n    int unscaled;\n\n    int srcRange, dstRange;\n\n    SwsFilter dummyFilter= {NULL, NULL, NULL, NULL};\n\n#if ARCH_X86\n\n    if (flags & SWS_CPU_CAPS_MMX)\n\n        __asm__ volatile(\"emms\\n\\t\"::: \"memory\");\n\n#endif\n\n\n\n#if !CONFIG_RUNTIME_CPUDETECT //ensure that the flags match the compiled variant if cpudetect is off\n\n    flags &= ~(SWS_CPU_CAPS_MMX|SWS_CPU_CAPS_MMX2|SWS_CPU_CAPS_3DNOW|SWS_CPU_CAPS_ALTIVEC|SWS_CPU_CAPS_BFIN);\n\n    flags |= ff_hardcodedcpuflags();\n\n#endif /* CONFIG_RUNTIME_CPUDETECT */\n\n    if (!rgb15to16) sws_rgb2rgb_init(flags);\n\n\n\n    unscaled = (srcW == dstW && srcH == dstH);\n\n\n\n    srcRange = handle_jpeg(&srcFormat);\n\n    dstRange = handle_jpeg(&dstFormat);\n\n\n\n    if (!isSupportedIn(srcFormat)) {\n\n        av_log(NULL, AV_LOG_ERROR, \"swScaler: %s is not supported as input pixel format\\n\", sws_format_name(srcFormat));\n\n        return NULL;\n\n    }\n\n    if (!isSupportedOut(dstFormat)) {\n\n        av_log(NULL, AV_LOG_ERROR, \"swScaler: %s is not supported as output pixel format\\n\", sws_format_name(dstFormat));\n\n        return NULL;\n\n    }\n\n\n\n    i= flags & ( SWS_POINT\n\n                |SWS_AREA\n\n                |SWS_BILINEAR\n\n                |SWS_FAST_BILINEAR\n\n                |SWS_BICUBIC\n\n                |SWS_X\n\n                |SWS_GAUSS\n\n                |SWS_LANCZOS\n\n                |SWS_SINC\n\n                |SWS_SPLINE\n\n                |SWS_BICUBLIN);\n\n    if(!i || (i & (i-1))) {\n\n        av_log(NULL, AV_LOG_ERROR, \"swScaler: Exactly one scaler algorithm must be chosen\\n\");\n\n        return NULL;\n\n    }\n\n\n\n    /* sanity check */\n\n    if (srcW<4 || srcH<1 || dstW<8 || dstH<1) { //FIXME check if these are enough and try to lowwer them after fixing the relevant parts of the code\n\n        av_log(NULL, AV_LOG_ERROR, \"swScaler: %dx%d -> %dx%d is invalid scaling dimension\\n\",\n\n               srcW, srcH, dstW, dstH);\n\n        return NULL;\n\n    }\n\n    if(srcW > VOFW || dstW > VOFW) {\n\n        av_log(NULL, AV_LOG_ERROR, \"swScaler: Compile-time maximum width is \"AV_STRINGIFY(VOFW)\" change VOF/VOFW and recompile\\n\");\n\n        return NULL;\n\n    }\n\n\n\n    if (!dstFilter) dstFilter= &dummyFilter;\n\n    if (!srcFilter) srcFilter= &dummyFilter;\n\n\n\n    FF_ALLOCZ_OR_GOTO(NULL, c, sizeof(SwsContext), fail);\n\n\n\n    c->av_class = &sws_context_class;\n\n    c->srcW= srcW;\n\n    c->srcH= srcH;\n\n    c->dstW= dstW;\n\n    c->dstH= dstH;\n\n    c->lumXInc= ((srcW<<16) + (dstW>>1))/dstW;\n\n    c->lumYInc= ((srcH<<16) + (dstH>>1))/dstH;\n\n    c->flags= flags;\n\n    c->dstFormat= dstFormat;\n\n    c->srcFormat= srcFormat;\n\n    c->dstFormatBpp = av_get_bits_per_pixel(&av_pix_fmt_descriptors[dstFormat]);\n\n    c->srcFormatBpp = av_get_bits_per_pixel(&av_pix_fmt_descriptors[srcFormat]);\n\n    c->vRounder= 4* 0x0001000100010001ULL;\n\n\n\n    usesVFilter = (srcFilter->lumV && srcFilter->lumV->length>1) ||\n\n                  (srcFilter->chrV && srcFilter->chrV->length>1) ||\n\n                  (dstFilter->lumV && dstFilter->lumV->length>1) ||\n\n                  (dstFilter->chrV && dstFilter->chrV->length>1);\n\n    usesHFilter = (srcFilter->lumH && srcFilter->lumH->length>1) ||\n\n                  (srcFilter->chrH && srcFilter->chrH->length>1) ||\n\n                  (dstFilter->lumH && dstFilter->lumH->length>1) ||\n\n                  (dstFilter->chrH && dstFilter->chrH->length>1);\n\n\n\n    getSubSampleFactors(&c->chrSrcHSubSample, &c->chrSrcVSubSample, srcFormat);\n\n    getSubSampleFactors(&c->chrDstHSubSample, &c->chrDstVSubSample, dstFormat);\n\n\n\n    // reuse chroma for 2 pixels RGB/BGR unless user wants full chroma interpolation\n\n    if (isAnyRGB(dstFormat) && !(flags&SWS_FULL_CHR_H_INT)) c->chrDstHSubSample=1;\n\n\n\n    // drop some chroma lines if the user wants it\n\n    c->vChrDrop= (flags&SWS_SRC_V_CHR_DROP_MASK)>>SWS_SRC_V_CHR_DROP_SHIFT;\n\n    c->chrSrcVSubSample+= c->vChrDrop;\n\n\n\n    // drop every other pixel for chroma calculation unless user wants full chroma\n\n    if (isAnyRGB(srcFormat) && !(flags&SWS_FULL_CHR_H_INP)\n\n      && srcFormat!=PIX_FMT_RGB8      && srcFormat!=PIX_FMT_BGR8\n\n      && srcFormat!=PIX_FMT_RGB4      && srcFormat!=PIX_FMT_BGR4\n\n      && srcFormat!=PIX_FMT_RGB4_BYTE && srcFormat!=PIX_FMT_BGR4_BYTE\n\n      && ((dstW>>c->chrDstHSubSample) <= (srcW>>1) || (flags&(SWS_FAST_BILINEAR|SWS_POINT))))\n\n        c->chrSrcHSubSample=1;\n\n\n\n    if (param) {\n\n        c->param[0] = param[0];\n\n        c->param[1] = param[1];\n\n    } else {\n\n        c->param[0] =\n\n        c->param[1] = SWS_PARAM_DEFAULT;\n\n    }\n\n\n\n    // Note the -((-x)>>y) is so that we always round toward +inf.\n\n    c->chrSrcW= -((-srcW) >> c->chrSrcHSubSample);\n\n    c->chrSrcH= -((-srcH) >> c->chrSrcVSubSample);\n\n    c->chrDstW= -((-dstW) >> c->chrDstHSubSample);\n\n    c->chrDstH= -((-dstH) >> c->chrDstVSubSample);\n\n\n\n    sws_setColorspaceDetails(c, ff_yuv2rgb_coeffs[SWS_CS_DEFAULT], srcRange, ff_yuv2rgb_coeffs[SWS_CS_DEFAULT] /* FIXME*/, dstRange, 0, 1<<16, 1<<16);\n\n\n\n    /* unscaled special cases */\n\n    if (unscaled && !usesHFilter && !usesVFilter && (srcRange == dstRange || isAnyRGB(dstFormat))) {\n\n        ff_get_unscaled_swscale(c);\n\n\n\n        if (c->swScale) {\n\n            if (flags&SWS_PRINT_INFO)\n\n                av_log(c, AV_LOG_INFO, \"using unscaled %s -> %s special converter\\n\",\n\n                       sws_format_name(srcFormat), sws_format_name(dstFormat));\n\n            return c;\n\n        }\n\n    }\n\n\n\n    if (flags & SWS_CPU_CAPS_MMX2) {\n\n        c->canMMX2BeUsed= (dstW >=srcW && (dstW&31)==0 && (srcW&15)==0) ? 1 : 0;\n\n        if (!c->canMMX2BeUsed && dstW >=srcW && (srcW&15)==0 && (flags&SWS_FAST_BILINEAR)) {\n\n            if (flags&SWS_PRINT_INFO)\n\n                av_log(c, AV_LOG_INFO, \"output width is not a multiple of 32 -> no MMX2 scaler\\n\");\n\n        }\n\n        if (usesHFilter) c->canMMX2BeUsed=0;\n\n    }\n\n    else\n\n        c->canMMX2BeUsed=0;\n\n\n\n    c->chrXInc= ((c->chrSrcW<<16) + (c->chrDstW>>1))/c->chrDstW;\n\n    c->chrYInc= ((c->chrSrcH<<16) + (c->chrDstH>>1))/c->chrDstH;\n\n\n\n    // match pixel 0 of the src to pixel 0 of dst and match pixel n-2 of src to pixel n-2 of dst\n\n    // but only for the FAST_BILINEAR mode otherwise do correct scaling\n\n    // n-2 is the last chrominance sample available\n\n    // this is not perfect, but no one should notice the difference, the more correct variant\n\n    // would be like the vertical one, but that would require some special code for the\n\n    // first and last pixel\n\n    if (flags&SWS_FAST_BILINEAR) {\n\n        if (c->canMMX2BeUsed) {\n\n            c->lumXInc+= 20;\n\n            c->chrXInc+= 20;\n\n        }\n\n        //we don't use the x86 asm scaler if MMX is available\n\n        else if (flags & SWS_CPU_CAPS_MMX) {\n\n            c->lumXInc = ((srcW-2)<<16)/(dstW-2) - 20;\n\n            c->chrXInc = ((c->chrSrcW-2)<<16)/(c->chrDstW-2) - 20;\n\n        }\n\n    }\n\n\n\n    /* precalculate horizontal scaler filter coefficients */\n\n    {\n\n#if ARCH_X86 && (HAVE_MMX2 || CONFIG_RUNTIME_CPUDETECT) && CONFIG_GPL\n\n// can't downscale !!!\n\n        if (c->canMMX2BeUsed && (flags & SWS_FAST_BILINEAR)) {\n\n            c->lumMmx2FilterCodeSize = initMMX2HScaler(      dstW, c->lumXInc, NULL, NULL, NULL, 8);\n\n            c->chrMmx2FilterCodeSize = initMMX2HScaler(c->chrDstW, c->chrXInc, NULL, NULL, NULL, 4);\n\n\n\n#ifdef MAP_ANONYMOUS\n\n            c->lumMmx2FilterCode = mmap(NULL, c->lumMmx2FilterCodeSize, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);\n\n            c->chrMmx2FilterCode = mmap(NULL, c->chrMmx2FilterCodeSize, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);\n\n#elif HAVE_VIRTUALALLOC\n\n            c->lumMmx2FilterCode = VirtualAlloc(NULL, c->lumMmx2FilterCodeSize, MEM_COMMIT, PAGE_EXECUTE_READWRITE);\n\n            c->chrMmx2FilterCode = VirtualAlloc(NULL, c->chrMmx2FilterCodeSize, MEM_COMMIT, PAGE_EXECUTE_READWRITE);\n\n#else\n\n            c->lumMmx2FilterCode = av_malloc(c->lumMmx2FilterCodeSize);\n\n            c->chrMmx2FilterCode = av_malloc(c->chrMmx2FilterCodeSize);\n\n#endif\n\n\n\n            if (!c->lumMmx2FilterCode || !c->chrMmx2FilterCode)\n\n                goto fail;\n\n            FF_ALLOCZ_OR_GOTO(c, c->hLumFilter   , (dstW        /8+8)*sizeof(int16_t), fail);\n\n            FF_ALLOCZ_OR_GOTO(c, c->hChrFilter   , (c->chrDstW  /4+8)*sizeof(int16_t), fail);\n\n            FF_ALLOCZ_OR_GOTO(c, c->hLumFilterPos, (dstW      /2/8+8)*sizeof(int32_t), fail);\n\n            FF_ALLOCZ_OR_GOTO(c, c->hChrFilterPos, (c->chrDstW/2/4+8)*sizeof(int32_t), fail);\n\n\n\n            initMMX2HScaler(      dstW, c->lumXInc, c->lumMmx2FilterCode, c->hLumFilter, c->hLumFilterPos, 8);\n\n            initMMX2HScaler(c->chrDstW, c->chrXInc, c->chrMmx2FilterCode, c->hChrFilter, c->hChrFilterPos, 4);\n\n\n\n#ifdef MAP_ANONYMOUS\n\n            mprotect(c->lumMmx2FilterCode, c->lumMmx2FilterCodeSize, PROT_EXEC | PROT_READ);\n\n            mprotect(c->chrMmx2FilterCode, c->chrMmx2FilterCodeSize, PROT_EXEC | PROT_READ);\n\n#endif\n\n        } else\n\n#endif /* ARCH_X86 && (HAVE_MMX2 || CONFIG_RUNTIME_CPUDETECT) && CONFIG_GPL */\n\n        {\n\n            const int filterAlign=\n\n                (flags & SWS_CPU_CAPS_MMX) ? 4 :\n\n                (flags & SWS_CPU_CAPS_ALTIVEC) ? 8 :\n\n                1;\n\n\n\n            if (initFilter(&c->hLumFilter, &c->hLumFilterPos, &c->hLumFilterSize, c->lumXInc,\n\n                           srcW      ,       dstW, filterAlign, 1<<14,\n\n                           (flags&SWS_BICUBLIN) ? (flags|SWS_BICUBIC)  : flags,\n\n                           srcFilter->lumH, dstFilter->lumH, c->param) < 0)\n\n                goto fail;\n\n            if (initFilter(&c->hChrFilter, &c->hChrFilterPos, &c->hChrFilterSize, c->chrXInc,\n\n                           c->chrSrcW, c->chrDstW, filterAlign, 1<<14,\n\n                           (flags&SWS_BICUBLIN) ? (flags|SWS_BILINEAR) : flags,\n\n                           srcFilter->chrH, dstFilter->chrH, c->param) < 0)\n\n                goto fail;\n\n        }\n\n    } // initialize horizontal stuff\n\n\n\n    /* precalculate vertical scaler filter coefficients */\n\n    {\n\n        const int filterAlign=\n\n            (flags & SWS_CPU_CAPS_MMX) && (flags & SWS_ACCURATE_RND) ? 2 :\n\n            (flags & SWS_CPU_CAPS_ALTIVEC) ? 8 :\n\n            1;\n\n\n\n        if (initFilter(&c->vLumFilter, &c->vLumFilterPos, &c->vLumFilterSize, c->lumYInc,\n\n                       srcH      ,        dstH, filterAlign, (1<<12),\n\n                       (flags&SWS_BICUBLIN) ? (flags|SWS_BICUBIC)  : flags,\n\n                       srcFilter->lumV, dstFilter->lumV, c->param) < 0)\n\n            goto fail;\n\n        if (initFilter(&c->vChrFilter, &c->vChrFilterPos, &c->vChrFilterSize, c->chrYInc,\n\n                       c->chrSrcH, c->chrDstH, filterAlign, (1<<12),\n\n                       (flags&SWS_BICUBLIN) ? (flags|SWS_BILINEAR) : flags,\n\n                       srcFilter->chrV, dstFilter->chrV, c->param) < 0)\n\n            goto fail;\n\n\n\n#if ARCH_PPC && HAVE_ALTIVEC\n\n        FF_ALLOC_OR_GOTO(c, c->vYCoeffsBank, sizeof (vector signed short)*c->vLumFilterSize*c->dstH, fail);\n\n        FF_ALLOC_OR_GOTO(c, c->vCCoeffsBank, sizeof (vector signed short)*c->vChrFilterSize*c->chrDstH, fail);\n\n\n\n        for (i=0;i<c->vLumFilterSize*c->dstH;i++) {\n\n            int j;\n\n            short *p = (short *)&c->vYCoeffsBank[i];\n\n            for (j=0;j<8;j++)\n\n                p[j] = c->vLumFilter[i];\n\n        }\n\n\n\n        for (i=0;i<c->vChrFilterSize*c->chrDstH;i++) {\n\n            int j;\n\n            short *p = (short *)&c->vCCoeffsBank[i];\n\n            for (j=0;j<8;j++)\n\n                p[j] = c->vChrFilter[i];\n\n        }\n\n#endif\n\n    }\n\n\n\n    // calculate buffer sizes so that they won't run out while handling these damn slices\n\n    c->vLumBufSize= c->vLumFilterSize;\n\n    c->vChrBufSize= c->vChrFilterSize;\n\n    for (i=0; i<dstH; i++) {\n\n        int chrI= i*c->chrDstH / dstH;\n\n        int nextSlice= FFMAX(c->vLumFilterPos[i   ] + c->vLumFilterSize - 1,\n\n                           ((c->vChrFilterPos[chrI] + c->vChrFilterSize - 1)<<c->chrSrcVSubSample));\n\n\n\n        nextSlice>>= c->chrSrcVSubSample;\n\n        nextSlice<<= c->chrSrcVSubSample;\n\n        if (c->vLumFilterPos[i   ] + c->vLumBufSize < nextSlice)\n\n            c->vLumBufSize= nextSlice - c->vLumFilterPos[i];\n\n        if (c->vChrFilterPos[chrI] + c->vChrBufSize < (nextSlice>>c->chrSrcVSubSample))\n\n            c->vChrBufSize= (nextSlice>>c->chrSrcVSubSample) - c->vChrFilterPos[chrI];\n\n    }\n\n\n\n    // allocate pixbufs (we use dynamic allocation because otherwise we would need to\n\n    // allocate several megabytes to handle all possible cases)\n\n    FF_ALLOC_OR_GOTO(c, c->lumPixBuf, c->vLumBufSize*2*sizeof(int16_t*), fail);\n\n    FF_ALLOC_OR_GOTO(c, c->chrPixBuf, c->vChrBufSize*2*sizeof(int16_t*), fail);\n\n    if (CONFIG_SWSCALE_ALPHA && isALPHA(c->srcFormat) && isALPHA(c->dstFormat))\n\n        FF_ALLOCZ_OR_GOTO(c, c->alpPixBuf, c->vLumBufSize*2*sizeof(int16_t*), fail);\n\n    //Note we need at least one pixel more at the end because of the MMX code (just in case someone wanna replace the 4000/8000)\n\n    /* align at 16 bytes for AltiVec */\n\n    for (i=0; i<c->vLumBufSize; i++) {\n\n        FF_ALLOCZ_OR_GOTO(c, c->lumPixBuf[i+c->vLumBufSize], VOF+1, fail);\n\n        c->lumPixBuf[i] = c->lumPixBuf[i+c->vLumBufSize];\n\n    }\n\n    for (i=0; i<c->vChrBufSize; i++) {\n\n        FF_ALLOC_OR_GOTO(c, c->chrPixBuf[i+c->vChrBufSize], (VOF+1)*2, fail);\n\n        c->chrPixBuf[i] = c->chrPixBuf[i+c->vChrBufSize];\n\n    }\n\n    if (CONFIG_SWSCALE_ALPHA && c->alpPixBuf)\n\n        for (i=0; i<c->vLumBufSize; i++) {\n\n            FF_ALLOCZ_OR_GOTO(c, c->alpPixBuf[i+c->vLumBufSize], VOF+1, fail);\n\n            c->alpPixBuf[i] = c->alpPixBuf[i+c->vLumBufSize];\n\n        }\n\n\n\n    //try to avoid drawing green stuff between the right end and the stride end\n\n    for (i=0; i<c->vChrBufSize; i++) memset(c->chrPixBuf[i], 64, (VOF+1)*2);\n\n\n\n    assert(2*VOFW == VOF);\n\n\n\n    assert(c->chrDstH <= dstH);\n\n\n\n    if (flags&SWS_PRINT_INFO) {\n\n        if (flags&SWS_FAST_BILINEAR)\n\n            av_log(c, AV_LOG_INFO, \"FAST_BILINEAR scaler, \");\n\n        else if (flags&SWS_BILINEAR)\n\n            av_log(c, AV_LOG_INFO, \"BILINEAR scaler, \");\n\n        else if (flags&SWS_BICUBIC)\n\n            av_log(c, AV_LOG_INFO, \"BICUBIC scaler, \");\n\n        else if (flags&SWS_X)\n\n            av_log(c, AV_LOG_INFO, \"Experimental scaler, \");\n\n        else if (flags&SWS_POINT)\n\n            av_log(c, AV_LOG_INFO, \"Nearest Neighbor / POINT scaler, \");\n\n        else if (flags&SWS_AREA)\n\n            av_log(c, AV_LOG_INFO, \"Area Averaging scaler, \");\n\n        else if (flags&SWS_BICUBLIN)\n\n            av_log(c, AV_LOG_INFO, \"luma BICUBIC / chroma BILINEAR scaler, \");\n\n        else if (flags&SWS_GAUSS)\n\n            av_log(c, AV_LOG_INFO, \"Gaussian scaler, \");\n\n        else if (flags&SWS_SINC)\n\n            av_log(c, AV_LOG_INFO, \"Sinc scaler, \");\n\n        else if (flags&SWS_LANCZOS)\n\n            av_log(c, AV_LOG_INFO, \"Lanczos scaler, \");\n\n        else if (flags&SWS_SPLINE)\n\n            av_log(c, AV_LOG_INFO, \"Bicubic spline scaler, \");\n\n        else\n\n            av_log(c, AV_LOG_INFO, \"ehh flags invalid?! \");\n\n\n\n        av_log(c, AV_LOG_INFO, \"from %s to %s%s \",\n\n               sws_format_name(srcFormat),\n\n#ifdef DITHER1XBPP\n\n               dstFormat == PIX_FMT_BGR555 || dstFormat == PIX_FMT_BGR565 ||\n\n               dstFormat == PIX_FMT_RGB444BE || dstFormat == PIX_FMT_RGB444LE ||\n\n               dstFormat == PIX_FMT_BGR444BE || dstFormat == PIX_FMT_BGR444LE ? \"dithered \" : \"\",\n\n#else\n\n               \"\",\n\n#endif\n\n               sws_format_name(dstFormat));\n\n\n\n        if (flags & SWS_CPU_CAPS_MMX2)\n\n            av_log(c, AV_LOG_INFO, \"using MMX2\\n\");\n\n        else if (flags & SWS_CPU_CAPS_3DNOW)\n\n            av_log(c, AV_LOG_INFO, \"using 3DNOW\\n\");\n\n        else if (flags & SWS_CPU_CAPS_MMX)\n\n            av_log(c, AV_LOG_INFO, \"using MMX\\n\");\n\n        else if (flags & SWS_CPU_CAPS_ALTIVEC)\n\n            av_log(c, AV_LOG_INFO, \"using AltiVec\\n\");\n\n        else\n\n            av_log(c, AV_LOG_INFO, \"using C\\n\");\n\n\n\n        if (flags & SWS_CPU_CAPS_MMX) {\n\n            if (c->canMMX2BeUsed && (flags&SWS_FAST_BILINEAR))\n\n                av_log(c, AV_LOG_VERBOSE, \"using FAST_BILINEAR MMX2 scaler for horizontal scaling\\n\");\n\n            else {\n\n                if (c->hLumFilterSize==4)\n\n                    av_log(c, AV_LOG_VERBOSE, \"using 4-tap MMX scaler for horizontal luminance scaling\\n\");\n\n                else if (c->hLumFilterSize==8)\n\n                    av_log(c, AV_LOG_VERBOSE, \"using 8-tap MMX scaler for horizontal luminance scaling\\n\");\n\n                else\n\n                    av_log(c, AV_LOG_VERBOSE, \"using n-tap MMX scaler for horizontal luminance scaling\\n\");\n\n\n\n                if (c->hChrFilterSize==4)\n\n                    av_log(c, AV_LOG_VERBOSE, \"using 4-tap MMX scaler for horizontal chrominance scaling\\n\");\n\n                else if (c->hChrFilterSize==8)\n\n                    av_log(c, AV_LOG_VERBOSE, \"using 8-tap MMX scaler for horizontal chrominance scaling\\n\");\n\n                else\n\n                    av_log(c, AV_LOG_VERBOSE, \"using n-tap MMX scaler for horizontal chrominance scaling\\n\");\n\n            }\n\n        } else {\n\n#if ARCH_X86\n\n            av_log(c, AV_LOG_VERBOSE, \"using x86 asm scaler for horizontal scaling\\n\");\n\n#else\n\n            if (flags & SWS_FAST_BILINEAR)\n\n                av_log(c, AV_LOG_VERBOSE, \"using FAST_BILINEAR C scaler for horizontal scaling\\n\");\n\n            else\n\n                av_log(c, AV_LOG_VERBOSE, \"using C scaler for horizontal scaling\\n\");\n\n#endif\n\n        }\n\n        if (isPlanarYUV(dstFormat)) {\n\n            if (c->vLumFilterSize==1)\n\n                av_log(c, AV_LOG_VERBOSE, \"using 1-tap %s \\\"scaler\\\" for vertical scaling (YV12 like)\\n\", (flags & SWS_CPU_CAPS_MMX) ? \"MMX\" : \"C\");\n\n            else\n\n                av_log(c, AV_LOG_VERBOSE, \"using n-tap %s scaler for vertical scaling (YV12 like)\\n\", (flags & SWS_CPU_CAPS_MMX) ? \"MMX\" : \"C\");\n\n        } else {\n\n            if (c->vLumFilterSize==1 && c->vChrFilterSize==2)\n\n                av_log(c, AV_LOG_VERBOSE, \"using 1-tap %s \\\"scaler\\\" for vertical luminance scaling (BGR)\\n\"\n\n                       \"      2-tap scaler for vertical chrominance scaling (BGR)\\n\", (flags & SWS_CPU_CAPS_MMX) ? \"MMX\" : \"C\");\n\n            else if (c->vLumFilterSize==2 && c->vChrFilterSize==2)\n\n                av_log(c, AV_LOG_VERBOSE, \"using 2-tap linear %s scaler for vertical scaling (BGR)\\n\", (flags & SWS_CPU_CAPS_MMX) ? \"MMX\" : \"C\");\n\n            else\n\n                av_log(c, AV_LOG_VERBOSE, \"using n-tap %s scaler for vertical scaling (BGR)\\n\", (flags & SWS_CPU_CAPS_MMX) ? \"MMX\" : \"C\");\n\n        }\n\n\n\n        if (dstFormat==PIX_FMT_BGR24)\n\n            av_log(c, AV_LOG_VERBOSE, \"using %s YV12->BGR24 converter\\n\",\n\n                   (flags & SWS_CPU_CAPS_MMX2) ? \"MMX2\" : ((flags & SWS_CPU_CAPS_MMX) ? \"MMX\" : \"C\"));\n\n        else if (dstFormat==PIX_FMT_RGB32)\n\n            av_log(c, AV_LOG_VERBOSE, \"using %s YV12->BGR32 converter\\n\", (flags & SWS_CPU_CAPS_MMX) ? \"MMX\" : \"C\");\n\n        else if (dstFormat==PIX_FMT_BGR565)\n\n            av_log(c, AV_LOG_VERBOSE, \"using %s YV12->BGR16 converter\\n\", (flags & SWS_CPU_CAPS_MMX) ? \"MMX\" : \"C\");\n\n        else if (dstFormat==PIX_FMT_BGR555)\n\n            av_log(c, AV_LOG_VERBOSE, \"using %s YV12->BGR15 converter\\n\", (flags & SWS_CPU_CAPS_MMX) ? \"MMX\" : \"C\");\n\n        else if (dstFormat == PIX_FMT_RGB444BE || dstFormat == PIX_FMT_RGB444LE ||\n\n                 dstFormat == PIX_FMT_BGR444BE || dstFormat == PIX_FMT_BGR444LE)\n\n            av_log(c, AV_LOG_VERBOSE, \"using %s YV12->BGR12 converter\\n\", (flags & SWS_CPU_CAPS_MMX) ? \"MMX\" : \"C\");\n\n\n\n        av_log(c, AV_LOG_VERBOSE, \"%dx%d -> %dx%d\\n\", srcW, srcH, dstW, dstH);\n\n        av_log(c, AV_LOG_DEBUG, \"lum srcW=%d srcH=%d dstW=%d dstH=%d xInc=%d yInc=%d\\n\",\n\n               c->srcW, c->srcH, c->dstW, c->dstH, c->lumXInc, c->lumYInc);\n\n        av_log(c, AV_LOG_DEBUG, \"chr srcW=%d srcH=%d dstW=%d dstH=%d xInc=%d yInc=%d\\n\",\n\n               c->chrSrcW, c->chrSrcH, c->chrDstW, c->chrDstH, c->chrXInc, c->chrYInc);\n\n    }\n\n\n\n    c->swScale= ff_getSwsFunc(c);\n\n    return c;\n\n\n\nfail:\n\n    sws_freeContext(c);\n\n    return NULL;\n\n}\n", "idx": 23172}
{"project": "FFmpeg", "commit_id": "2207ea44fb4fad4d47646a789bc244e3e84c1726", "target": 0, "func": "void FUNC(ff_emulated_edge_mc)(uint8_t *buf, const uint8_t *src, int linesize, int block_w, int block_h,\n\n                                    int src_x, int src_y, int w, int h){\n\n    int x, y;\n\n    int start_y, start_x, end_y, end_x;\n\n\n\n    if(src_y>= h){\n\n        src+= (h-1-src_y)*linesize;\n\n        src_y=h-1;\n\n    }else if(src_y<=-block_h){\n\n        src+= (1-block_h-src_y)*linesize;\n\n        src_y=1-block_h;\n\n    }\n\n    if(src_x>= w){\n\n        src+= (w-1-src_x)*sizeof(pixel);\n\n        src_x=w-1;\n\n    }else if(src_x<=-block_w){\n\n        src+= (1-block_w-src_x)*sizeof(pixel);\n\n        src_x=1-block_w;\n\n    }\n\n\n\n    start_y= FFMAX(0, -src_y);\n\n    start_x= FFMAX(0, -src_x);\n\n    end_y= FFMIN(block_h, h-src_y);\n\n    end_x= FFMIN(block_w, w-src_x);\n\n    av_assert2(start_y < end_y && block_h);\n\n    av_assert2(start_x < end_x && block_w);\n\n\n\n    w    = end_x - start_x;\n\n    src += start_y*linesize + start_x*sizeof(pixel);\n\n    buf += start_x*sizeof(pixel);\n\n\n\n    //top\n\n    for(y=0; y<start_y; y++){\n\n        memcpy(buf, src, w*sizeof(pixel));\n\n        buf += linesize;\n\n    }\n\n\n\n    // copy existing part\n\n    for(; y<end_y; y++){\n\n        memcpy(buf, src, w*sizeof(pixel));\n\n        src += linesize;\n\n        buf += linesize;\n\n    }\n\n\n\n    //bottom\n\n    src -= linesize;\n\n    for(; y<block_h; y++){\n\n        memcpy(buf, src, w*sizeof(pixel));\n\n        buf += linesize;\n\n    }\n\n\n\n    buf -= block_h * linesize + start_x*sizeof(pixel);\n\n    while (block_h--){\n\n        pixel *bufp = (pixel*)buf;\n\n       //left\n\n        for(x=0; x<start_x; x++){\n\n            bufp[x] = bufp[start_x];\n\n        }\n\n\n\n       //right\n\n        for(x=end_x; x<block_w; x++){\n\n            bufp[x] = bufp[end_x - 1];\n\n        }\n\n        buf += linesize;\n\n    }\n\n}\n", "idx": 23182}
{"project": "FFmpeg", "commit_id": "afebf470ca73c17cc8393bfd7eeebfdf6809c2b8", "target": 0, "func": "static void test_separators(const AVDictionary *m, const char pair, const char val)\n\n{\n\n    AVDictionary *dict = NULL;\n\n    char pairs[] = {pair , '\\0'};\n\n    char vals[]  = {val, '\\0'};\n\n\n\n    char *buffer = NULL;\n\n    av_dict_copy(&dict, m, 0);\n\n    print_dict(dict);\n\n    av_dict_get_string(dict, &buffer, val, pair);\n\n    printf(\"%s\\n\", buffer);\n\n    av_dict_free(&dict);\n\n    av_dict_parse_string(&dict, buffer, vals, pairs, 0);\n\n    av_freep(&buffer);\n\n    print_dict(dict);\n\n    av_dict_free(&dict);\n\n}\n", "idx": 23183}
{"project": "FFmpeg", "commit_id": "dbc1163b203b175d246b7454c32ac176f84006d1", "target": 0, "func": "static inline int decode_ac_coeffs(GetBitContext *gb, int16_t *out,\n\n                                   int blocks_per_slice,\n\n                                   int plane_size_factor,\n\n                                   const uint8_t *scan)\n\n{\n\n    int pos, block_mask, run, level, sign, run_cb_index, lev_cb_index;\n\n    int max_coeffs, bits_left;\n\n\n\n    /* set initial prediction values */\n\n    run   = 4;\n\n    level = 2;\n\n\n\n    max_coeffs = blocks_per_slice << 6;\n\n    block_mask = blocks_per_slice - 1;\n\n\n\n    for (pos = blocks_per_slice - 1; pos < max_coeffs;) {\n\n        run_cb_index = ff_prores_run_to_cb_index[FFMIN(run, 15)];\n\n        lev_cb_index = ff_prores_lev_to_cb_index[FFMIN(level, 9)];\n\n\n\n        bits_left = get_bits_left(gb);\n\n        if (bits_left <= 0 || (bits_left <= 8 && !show_bits(gb, bits_left)))\n\n            return 0;\n\n\n\n        run = decode_vlc_codeword(gb, ff_prores_ac_codebook[run_cb_index]);\n\n        if (run < 0)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        bits_left = get_bits_left(gb);\n\n        if (bits_left <= 0 || (bits_left <= 8 && !show_bits(gb, bits_left)))\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        level = decode_vlc_codeword(gb, ff_prores_ac_codebook[lev_cb_index]) + 1;\n\n        if (level < 0)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        pos += run + 1;\n\n        if (pos >= max_coeffs)\n\n            break;\n\n\n\n        sign = get_sbits(gb, 1);\n\n        out[((pos & block_mask) << 6) + scan[pos >> plane_size_factor]] =\n\n            (level ^ sign) - sign;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23184}
{"project": "FFmpeg", "commit_id": "95bde49982a82bc10470c0adab5969ffe635d064", "target": 0, "func": "static int flac_read_header(AVFormatContext *s)\n\n{\n\n    int ret, metadata_last=0, metadata_type, metadata_size, found_streaminfo=0;\n\n    uint8_t header[4];\n\n    uint8_t *buffer=NULL;\n\n    FLACDecContext *flac = s->priv_data;\n\n    AVStream *st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n    st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n\n    st->codecpar->codec_id = AV_CODEC_ID_FLAC;\n\n    st->need_parsing = AVSTREAM_PARSE_FULL_RAW;\n\n    /* the parameters will be extracted from the compressed bitstream */\n\n\n\n    /* if fLaC marker is not found, assume there is no header */\n\n    if (avio_rl32(s->pb) != MKTAG('f','L','a','C')) {\n\n        avio_seek(s->pb, -4, SEEK_CUR);\n\n        return 0;\n\n    }\n\n\n\n    /* process metadata blocks */\n\n    while (!avio_feof(s->pb) && !metadata_last) {\n\n        avio_read(s->pb, header, 4);\n\n        flac_parse_block_header(header, &metadata_last, &metadata_type,\n\n                                   &metadata_size);\n\n        switch (metadata_type) {\n\n        /* allocate and read metadata block for supported types */\n\n        case FLAC_METADATA_TYPE_STREAMINFO:\n\n        case FLAC_METADATA_TYPE_CUESHEET:\n\n        case FLAC_METADATA_TYPE_PICTURE:\n\n        case FLAC_METADATA_TYPE_VORBIS_COMMENT:\n\n        case FLAC_METADATA_TYPE_SEEKTABLE:\n\n            buffer = av_mallocz(metadata_size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n            if (!buffer) {\n\n                return AVERROR(ENOMEM);\n\n            }\n\n            if (avio_read(s->pb, buffer, metadata_size) != metadata_size) {\n\n                RETURN_ERROR(AVERROR(EIO));\n\n            }\n\n            break;\n\n        /* skip metadata block for unsupported types */\n\n        default:\n\n            ret = avio_skip(s->pb, metadata_size);\n\n            if (ret < 0)\n\n                return ret;\n\n        }\n\n\n\n        if (metadata_type == FLAC_METADATA_TYPE_STREAMINFO) {\n\n            uint32_t samplerate;\n\n            uint64_t samples;\n\n\n\n            /* STREAMINFO can only occur once */\n\n            if (found_streaminfo) {\n\n                RETURN_ERROR(AVERROR_INVALIDDATA);\n\n            }\n\n            if (metadata_size != FLAC_STREAMINFO_SIZE) {\n\n                RETURN_ERROR(AVERROR_INVALIDDATA);\n\n            }\n\n            found_streaminfo = 1;\n\n            st->codecpar->extradata      = buffer;\n\n            st->codecpar->extradata_size = metadata_size;\n\n            buffer = NULL;\n\n\n\n            /* get sample rate and sample count from STREAMINFO header;\n\n             * other parameters will be extracted by the parser */\n\n            samplerate = AV_RB24(st->codecpar->extradata + 10) >> 4;\n\n            samples    = (AV_RB64(st->codecpar->extradata + 13) >> 24) & ((1ULL << 36) - 1);\n\n\n\n            /* set time base and duration */\n\n            if (samplerate > 0) {\n\n                avpriv_set_pts_info(st, 64, 1, samplerate);\n\n                if (samples > 0)\n\n                    st->duration = samples;\n\n            }\n\n        } else if (metadata_type == FLAC_METADATA_TYPE_CUESHEET) {\n\n            uint8_t isrc[13];\n\n            uint64_t start;\n\n            const uint8_t *offset;\n\n            int i, chapters, track, ti;\n\n            if (metadata_size < 431)\n\n                RETURN_ERROR(AVERROR_INVALIDDATA);\n\n            offset = buffer + 395;\n\n            chapters = bytestream_get_byte(&offset) - 1;\n\n            if (chapters <= 0)\n\n                RETURN_ERROR(AVERROR_INVALIDDATA);\n\n            for (i = 0; i < chapters; i++) {\n\n                if (offset + 36 - buffer > metadata_size)\n\n                    RETURN_ERROR(AVERROR_INVALIDDATA);\n\n                start = bytestream_get_be64(&offset);\n\n                track = bytestream_get_byte(&offset);\n\n                bytestream_get_buffer(&offset, isrc, 12);\n\n                isrc[12] = 0;\n\n                offset += 14;\n\n                ti = bytestream_get_byte(&offset);\n\n                if (ti <= 0) RETURN_ERROR(AVERROR_INVALIDDATA);\n\n                offset += ti * 12;\n\n                avpriv_new_chapter(s, track, st->time_base, start, AV_NOPTS_VALUE, isrc);\n\n            }\n\n            av_freep(&buffer);\n\n        } else if (metadata_type == FLAC_METADATA_TYPE_PICTURE) {\n\n            ret = ff_flac_parse_picture(s, buffer, metadata_size);\n\n            av_freep(&buffer);\n\n            if (ret < 0) {\n\n                av_log(s, AV_LOG_ERROR, \"Error parsing attached picture.\\n\");\n\n                return ret;\n\n            }\n\n        } else if (metadata_type == FLAC_METADATA_TYPE_SEEKTABLE) {\n\n            const uint8_t *seekpoint = buffer;\n\n            int i, seek_point_count = metadata_size/SEEKPOINT_SIZE;\n\n            flac->found_seektable = 1;\n\n            if ((s->flags&AVFMT_FLAG_FAST_SEEK)) {\n\n                for(i=0; i<seek_point_count; i++) {\n\n                    int64_t timestamp = bytestream_get_be64(&seekpoint);\n\n                    int64_t pos = bytestream_get_be64(&seekpoint);\n\n                    /* skip number of samples */\n\n                    bytestream_get_be16(&seekpoint);\n\n                    av_add_index_entry(st, pos, timestamp, 0, 0, AVINDEX_KEYFRAME);\n\n                }\n\n            }\n\n            av_freep(&buffer);\n\n        }\n\n        else {\n\n\n\n            /* STREAMINFO must be the first block */\n\n            if (!found_streaminfo) {\n\n                RETURN_ERROR(AVERROR_INVALIDDATA);\n\n            }\n\n            /* process supported blocks other than STREAMINFO */\n\n            if (metadata_type == FLAC_METADATA_TYPE_VORBIS_COMMENT) {\n\n                AVDictionaryEntry *chmask;\n\n\n\n                ret = ff_vorbis_comment(s, &s->metadata, buffer, metadata_size, 1);\n\n                if (ret < 0) {\n\n                    av_log(s, AV_LOG_WARNING, \"error parsing VorbisComment metadata\\n\");\n\n                } else if (ret > 0) {\n\n                    s->event_flags |= AVFMT_EVENT_FLAG_METADATA_UPDATED;\n\n                }\n\n\n\n                /* parse the channels mask if present */\n\n                chmask = av_dict_get(s->metadata, \"WAVEFORMATEXTENSIBLE_CHANNEL_MASK\", NULL, 0);\n\n                if (chmask) {\n\n                    uint64_t mask = strtol(chmask->value, NULL, 0);\n\n                    if (!mask || mask & ~0x3ffffULL) {\n\n                        av_log(s, AV_LOG_WARNING,\n\n                               \"Invalid value of WAVEFORMATEXTENSIBLE_CHANNEL_MASK\\n\");\n\n                    } else {\n\n                        st->codecpar->channel_layout = mask;\n\n                        av_dict_set(&s->metadata, \"WAVEFORMATEXTENSIBLE_CHANNEL_MASK\", NULL, 0);\n\n                    }\n\n                }\n\n            }\n\n            av_freep(&buffer);\n\n        }\n\n    }\n\n\n\n    ret = ff_replaygain_export(st, s->metadata);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    reset_index_position(avio_tell(s->pb), st);\n\n    return 0;\n\n\n\nfail:\n\n    av_free(buffer);\n\n    return ret;\n\n}\n", "idx": 23185}
{"project": "FFmpeg", "commit_id": "31c7c0e156975be615479948824c1528952c0731", "target": 1, "func": "static int mov_write_video_tag(AVIOContext *pb, MOVMuxContext *mov, MOVTrack *track)\n\n{\n\n    int64_t pos = avio_tell(pb);\n\n    char compressor_name[32] = { 0 };\n\n\n\n    avio_wb32(pb, 0); /* size */\n\n    avio_wl32(pb, track->tag); // store it byteswapped\n\n    avio_wb32(pb, 0); /* Reserved */\n\n    avio_wb16(pb, 0); /* Reserved */\n\n    avio_wb16(pb, 1); /* Data-reference index */\n\n\n\n    avio_wb16(pb, 0); /* Codec stream version */\n\n    avio_wb16(pb, 0); /* Codec stream revision (=0) */\n\n    if (track->mode == MODE_MOV) {\n\n        ffio_wfourcc(pb, \"FFMP\"); /* Vendor */\n\n        if (track->enc->codec_id == AV_CODEC_ID_RAWVIDEO) {\n\n            avio_wb32(pb, 0); /* Temporal Quality */\n\n            avio_wb32(pb, 0x400); /* Spatial Quality = lossless*/\n\n        } else {\n\n            avio_wb32(pb, 0x200); /* Temporal Quality = normal */\n\n            avio_wb32(pb, 0x200); /* Spatial Quality = normal */\n\n        }\n\n    } else {\n\n        avio_wb32(pb, 0); /* Reserved */\n\n        avio_wb32(pb, 0); /* Reserved */\n\n        avio_wb32(pb, 0); /* Reserved */\n\n    }\n\n    avio_wb16(pb, track->enc->width); /* Video width */\n\n    avio_wb16(pb, track->height); /* Video height */\n\n    avio_wb32(pb, 0x00480000); /* Horizontal resolution 72dpi */\n\n    avio_wb32(pb, 0x00480000); /* Vertical resolution 72dpi */\n\n    avio_wb32(pb, 0); /* Data size (= 0) */\n\n    avio_wb16(pb, 1); /* Frame count (= 1) */\n\n\n\n    /* FIXME not sure, ISO 14496-1 draft where it shall be set to 0 */\n\n    find_compressor(compressor_name, 32, track);\n\n    avio_w8(pb, strlen(compressor_name));\n\n    avio_write(pb, compressor_name, 31);\n\n\n\n    if (track->mode == MODE_MOV && track->enc->bits_per_coded_sample)\n\n        avio_wb16(pb, track->enc->bits_per_coded_sample);\n\n    else\n\n        avio_wb16(pb, 0x18); /* Reserved */\n\n    avio_wb16(pb, 0xffff); /* Reserved */\n\n    if (track->tag == MKTAG('m','p','4','v'))\n\n        mov_write_esds_tag(pb, track);\n\n    else if (track->enc->codec_id == AV_CODEC_ID_H263)\n\n        mov_write_d263_tag(pb);\n\n    else if (track->enc->codec_id == AV_CODEC_ID_AVUI ||\n\n            track->enc->codec_id == AV_CODEC_ID_SVQ3) {\n\n        mov_write_extradata_tag(pb, track);\n\n        avio_wb32(pb, 0);\n\n    } else if (track->enc->codec_id == AV_CODEC_ID_DNXHD)\n\n        mov_write_avid_tag(pb, track);\n\n    else if (track->enc->codec_id == AV_CODEC_ID_HEVC)\n\n        mov_write_hvcc_tag(pb, track);\n\n    else if (track->enc->codec_id == AV_CODEC_ID_H264 && !TAG_IS_AVCI(track->tag)) {\n\n        mov_write_avcc_tag(pb, track);\n\n        if (track->mode == MODE_IPOD)\n\n            mov_write_uuid_tag_ipod(pb);\n\n    } else if (track->enc->codec_id == AV_CODEC_ID_VC1 && track->vos_len > 0)\n\n        mov_write_dvc1_tag(pb, track);\n\n    else if (track->enc->codec_id == AV_CODEC_ID_VP6F ||\n\n             track->enc->codec_id == AV_CODEC_ID_VP6A) {\n\n        /* Don't write any potential extradata here - the cropping\n\n         * is signalled via the normal width/height fields. */\n\n    } else if (track->enc->codec_id == AV_CODEC_ID_R10K) {\n\n        if (track->enc->codec_tag == MKTAG('R','1','0','k'))\n\n            mov_write_dpxe_tag(pb, track);\n\n    } else if (track->vos_len > 0)\n\n        mov_write_glbl_tag(pb, track);\n\n\n\n    if (track->enc->codec_id != AV_CODEC_ID_H264 &&\n\n        track->enc->codec_id != AV_CODEC_ID_MPEG4 &&\n\n        track->enc->codec_id != AV_CODEC_ID_DNXHD)\n\n        if (track->enc->field_order != AV_FIELD_UNKNOWN)\n\n            mov_write_fiel_tag(pb, track);\n\n\n\n    if (mov->flags & FF_MOV_FLAG_WRITE_COLR)\n\n        mov_write_colr_tag(pb, track);\n\n\n\n    if (track->enc->sample_aspect_ratio.den && track->enc->sample_aspect_ratio.num &&\n\n        track->enc->sample_aspect_ratio.den != track->enc->sample_aspect_ratio.num) {\n\n        mov_write_pasp_tag(pb, track);\n\n    }\n\n\n\n    return update_size(pb, pos);\n\n}\n", "idx": 23187}
{"project": "FFmpeg", "commit_id": "b0c7f5a9d82feb7f4c4cdf77f1537193670ab58b", "target": 0, "func": "static int ogg_write_packet(AVFormatContext *avfcontext,\n\n\t\t\t    int stream_index,\n\n\t\t\t    const uint8_t *buf, int size, int64_t pts)\n\n{\n\n    OggContext *context = avfcontext->priv_data ;\n\n    AVCodecContext *avctx= &avfcontext->streams[stream_index]->codec;\n\n    ogg_packet *op= &context->op;\n\n    ogg_page og ;\n\n\n\n    pts= av_rescale(pts, avctx->sample_rate, AV_TIME_BASE);\n\n\n\n    if(!size){\n\n//        av_log(avfcontext, AV_LOG_DEBUG, \"zero packet\\n\");\n\n        return 0;\n\n    }\n\n//    av_log(avfcontext, AV_LOG_DEBUG, \"M%d\\n\", size);\n\n\n\n    /* flush header packets so audio starts on a new page */\n\n\n\n    if(!context->header_handled) {\n\n\twhile(ogg_stream_flush(&context->os, &og)) {\n\n\t    put_buffer(&avfcontext->pb, og.header, og.header_len) ;\n\n\t    put_buffer(&avfcontext->pb, og.body, og.body_len) ;\n\n\t    put_flush_packet(&avfcontext->pb);\n\n\t}\n\n\tcontext->header_handled = 1 ;\n\n    }\n\n\n\n    op->packet = (uint8_t*) buf;\n\n    op->bytes  = size;\n\n    op->b_o_s  = op->packetno == 0;\n\n    op->granulepos= pts;\n\n\n\n    /* correct the fields in the packet -- essential for streaming */\n\n                                                        \n\n    ogg_stream_packetin(&context->os, op);              \n\n                                                        \n\n    while(ogg_stream_pageout(&context->os, &og)) {\n\n        put_buffer(&avfcontext->pb, og.header, og.header_len);\n\n\tput_buffer(&avfcontext->pb, og.body, og.body_len);     \n\n\tput_flush_packet(&avfcontext->pb);\n\n    }                                                   \n\n    op->packetno++;\n\n\n\n    return 0;\n\n}\n", "idx": 23188}
{"project": "FFmpeg", "commit_id": "0dbb48d91e9e97c7eb11f4ebc03c4ff4b6f5b692", "target": 1, "func": "static int mpeg_mux_init(AVFormatContext *ctx)\n\n{\n\n    MpegMuxContext *s = ctx->priv_data;\n\n    int bitrate, i, mpa_id, mpv_id, ac3_id;\n\n    AVStream *st;\n\n    StreamInfo *stream;\n\n\n\n    s->packet_number = 0;\n\n    s->is_vcd = (ctx->oformat == &mpeg1vcd_mux);\n\n    s->is_mpeg2 = (ctx->oformat == &mpeg2vob_mux);\n\n    \n\n    if (s->is_vcd)\n\n        s->packet_size = 2324; /* VCD packet size */\n\n    else\n\n        s->packet_size = 2048;\n\n        \n\n    /* startcode(4) + length(2) + flags(1) */\n\n    s->packet_data_max_size = s->packet_size - 7;\n\n    if (s->is_mpeg2)\n\n        s->packet_data_max_size -= 2;\n\n    s->audio_bound = 0;\n\n    s->video_bound = 0;\n\n    mpa_id = AUDIO_ID;\n\n    ac3_id = 0x80;\n\n    mpv_id = VIDEO_ID;\n\n    s->scr_stream_index = -1;\n\n    for(i=0;i<ctx->nb_streams;i++) {\n\n        st = ctx->streams[i];\n\n        stream = av_mallocz(sizeof(StreamInfo));\n\n        if (!stream)\n\n            goto fail;\n\n        st->priv_data = stream;\n\n\n\n        switch(st->codec.codec_type) {\n\n        case CODEC_TYPE_AUDIO:\n\n            if (st->codec.codec_id == CODEC_ID_AC3)\n\n                stream->id = ac3_id++;\n\n            else\n\n                stream->id = mpa_id++;\n\n            stream->max_buffer_size = 4 * 1024; \n\n            s->audio_bound++;\n\n            break;\n\n        case CODEC_TYPE_VIDEO:\n\n            /* by default, video is used for the SCR computation */\n\n            if (s->scr_stream_index == -1)\n\n                s->scr_stream_index = i;\n\n            stream->id = mpv_id++;\n\n            stream->max_buffer_size = 46 * 1024; \n\n            s->video_bound++;\n\n            break;\n\n        default:\n\n            av_abort();\n\n        }\n\n    }\n\n    /* if no SCR, use first stream (audio) */\n\n    if (s->scr_stream_index == -1)\n\n        s->scr_stream_index = 0;\n\n\n\n    /* we increase slightly the bitrate to take into account the\n\n       headers. XXX: compute it exactly */\n\n    bitrate = 2000;\n\n    for(i=0;i<ctx->nb_streams;i++) {\n\n        st = ctx->streams[i];\n\n        bitrate += st->codec.bit_rate;\n\n    }\n\n    s->mux_rate = (bitrate + (8 * 50) - 1) / (8 * 50);\n\n    \n\n    if (s->is_vcd || s->is_mpeg2)\n\n        /* every packet */\n\n        s->pack_header_freq = 1;\n\n    else\n\n        /* every 2 seconds */\n\n        s->pack_header_freq = 2 * bitrate / s->packet_size / 8;\n\n\n\n    /* the above seems to make pack_header_freq zero sometimes */\n\n    if (s->pack_header_freq == 0)\n\n       s->pack_header_freq = 1;\n\n    \n\n    if (s->is_mpeg2)\n\n        /* every 200 packets. Need to look at the spec.  */\n\n        s->system_header_freq = s->pack_header_freq * 40;\n\n    else if (s->is_vcd)\n\n        /* every 40 packets, this is my invention */\n\n        s->system_header_freq = s->pack_header_freq * 40;\n\n    else\n\n        s->system_header_freq = s->pack_header_freq * 5;\n\n    \n\n    for(i=0;i<ctx->nb_streams;i++) {\n\n        stream = ctx->streams[i]->priv_data;\n\n        stream->buffer_ptr = 0;\n\n        stream->packet_number = 0;\n\n        stream->start_pts = AV_NOPTS_VALUE;\n\n        stream->start_dts = AV_NOPTS_VALUE;\n\n    }\n\n    s->last_scr = 0;\n\n    return 0;\n\n fail:\n\n    for(i=0;i<ctx->nb_streams;i++) {\n\n        av_free(ctx->streams[i]->priv_data);\n\n    }\n\n    return -ENOMEM;\n\n}\n", "idx": 23193}
{"project": "FFmpeg", "commit_id": "14f063d294a18a31928d2167a66b1087910e14c8", "target": 1, "func": "void *av_malloc(size_t size)\n\n{\n\n    void *ptr = NULL;\n\n#if CONFIG_MEMALIGN_HACK\n\n    long diff;\n\n#endif\n\n\n\n    /* let's disallow possible ambiguous cases */\n\n    if(size > (INT_MAX-32) )\n\n        return NULL;\n\n\n\n#if CONFIG_MEMALIGN_HACK\n\n    ptr = malloc(size+32);\n\n    if(!ptr)\n\n        return ptr;\n\n    diff= ((-(long)ptr - 1)&31) + 1;\n\n    ptr = (char*)ptr + diff;\n\n    ((char*)ptr)[-1]= diff;\n\n#elif HAVE_POSIX_MEMALIGN\n\n    if (posix_memalign(&ptr,32,size))\n\n        ptr = NULL;\n\n#elif HAVE_MEMALIGN\n\n    ptr = memalign(32,size);\n\n    /* Why 64?\n\n       Indeed, we should align it:\n\n         on 4 for 386\n\n         on 16 for 486\n\n         on 32 for 586, PPro - K6-III\n\n         on 64 for K7 (maybe for P3 too).\n\n       Because L1 and L2 caches are aligned on those values.\n\n       But I don't want to code such logic here!\n\n     */\n\n     /* Why 32?\n\n        For AVX ASM. SSE / NEON needs only 16.\n\n        Why not larger? Because I did not see a difference in benchmarks ...\n\n     */\n\n     /* benchmarks with P3\n\n        memalign(64)+1          3071,3051,3032\n\n        memalign(64)+2          3051,3032,3041\n\n        memalign(64)+4          2911,2896,2915\n\n        memalign(64)+8          2545,2554,2550\n\n        memalign(64)+16         2543,2572,2563\n\n        memalign(64)+32         2546,2545,2571\n\n        memalign(64)+64         2570,2533,2558\n\n\n\n        BTW, malloc seems to do 8-byte alignment by default here.\n\n     */\n\n#else\n\n    ptr = malloc(size);\n\n#endif\n\n    return ptr;\n\n}\n", "idx": 23196}
{"project": "FFmpeg", "commit_id": "949d2176ef0a37c6ecbb65be0f1199536a2d9278", "target": 1, "func": "static void decor_c(int32_t *dst, const int32_t *src, int coeff, ptrdiff_t len)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < len; i++)\n\n        dst[i] += (int)(src[i] * (SUINT)coeff + (1 << 2)) >> 3;\n\n}\n", "idx": 23197}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(rgb32to16)(const uint8_t *src, uint8_t *dst, unsigned src_size)\n\n{\n\n\tconst uint8_t *s = src;\n\n\tconst uint8_t *end;\n\n#ifdef HAVE_MMX\n\n\tconst uint8_t *mm_end;\n\n#endif\n\n\tuint16_t *d = (uint16_t *)dst;\n\n\tend = s + src_size;\n\n#ifdef HAVE_MMX\n\n\tmm_end = end - 15;\n\n#if 1 //is faster only if multiplies are reasonable fast (FIXME figure out on which cpus this is faster, on Athlon its slightly faster)\n\n\tasm volatile(\n\n\t\t\"movq %3, %%mm5\t\t\t\\n\\t\"\n\n\t\t\"movq %4, %%mm6\t\t\t\\n\\t\"\n\n\t\t\"movq %5, %%mm7\t\t\t\\n\\t\"\n\n\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\tPREFETCH\" 32(%1)\t\t\\n\\t\"\n\n\t\t\"movd\t(%1), %%mm0\t\t\\n\\t\"\n\n\t\t\"movd\t4(%1), %%mm3\t\t\\n\\t\"\n\n\t\t\"punpckldq 8(%1), %%mm0\t\t\\n\\t\"\n\n\t\t\"punpckldq 12(%1), %%mm3\t\\n\\t\"\n\n\t\t\"movq %%mm0, %%mm1\t\t\\n\\t\"\n\n\t\t\"movq %%mm3, %%mm4\t\t\\n\\t\"\n\n\t\t\"pand %%mm6, %%mm0\t\t\\n\\t\"\n\n\t\t\"pand %%mm6, %%mm3\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm7, %%mm3\t\t\\n\\t\"\n\n\t\t\"pand %%mm5, %%mm1\t\t\\n\\t\"\n\n\t\t\"pand %%mm5, %%mm4\t\t\\n\\t\"\n\n\t\t\"por %%mm1, %%mm0\t\t\\n\\t\"\t\n\n\t\t\"por %%mm4, %%mm3\t\t\\n\\t\"\n\n\t\t\"psrld $5, %%mm0\t\t\\n\\t\"\n\n\t\t\"pslld $11, %%mm3\t\t\\n\\t\"\n\n\t\t\"por %%mm3, %%mm0\t\t\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, (%0)\t\t\\n\\t\"\n\n\t\t\"add $16, %1\t\t\t\\n\\t\"\n\n\t\t\"add $8, %0\t\t\t\\n\\t\"\n\n\t\t\"cmp %2, %1\t\t\t\\n\\t\"\n\n\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\t\t: \"+r\" (d), \"+r\"(s)\n\n\t\t: \"r\" (mm_end), \"m\" (mask3216g), \"m\" (mask3216br), \"m\" (mul3216)\n\n\t);\n\n#else\n\n\t__asm __volatile(PREFETCH\"\t%0\"::\"m\"(*src):\"memory\");\n\n\t__asm __volatile(\n\n\t    \"movq\t%0, %%mm7\\n\\t\"\n\n\t    \"movq\t%1, %%mm6\\n\\t\"\n\n\t    ::\"m\"(red_16mask),\"m\"(green_16mask));\n\n\twhile(s < mm_end)\n\n\t{\n\n\t    __asm __volatile(\n\n\t\tPREFETCH\" 32%1\\n\\t\"\n\n\t\t\"movd\t%1, %%mm0\\n\\t\"\n\n\t\t\"movd\t4%1, %%mm3\\n\\t\"\n\n\t\t\"punpckldq 8%1, %%mm0\\n\\t\"\n\n\t\t\"punpckldq 12%1, %%mm3\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm1\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm2\\n\\t\"\n\n\t\t\"movq\t%%mm3, %%mm4\\n\\t\"\n\n\t\t\"movq\t%%mm3, %%mm5\\n\\t\"\n\n\t\t\"psrlq\t$3, %%mm0\\n\\t\"\n\n\t\t\"psrlq\t$3, %%mm3\\n\\t\"\n\n\t\t\"pand\t%2, %%mm0\\n\\t\"\n\n\t\t\"pand\t%2, %%mm3\\n\\t\"\n\n\t\t\"psrlq\t$5, %%mm1\\n\\t\"\n\n\t\t\"psrlq\t$5, %%mm4\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm1\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm4\\n\\t\"\n\n\t\t\"psrlq\t$8, %%mm2\\n\\t\"\n\n\t\t\"psrlq\t$8, %%mm5\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm2\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm5\\n\\t\"\n\n\t\t\"por\t%%mm1, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm4, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm2, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm5, %%mm3\\n\\t\"\n\n\t\t\"psllq\t$16, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm3, %%mm0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\t:\"=m\"(*d):\"m\"(*s),\"m\"(blue_16mask):\"memory\");\n\n\t\td += 4;\n\n\t\ts += 16;\n\n\t}\n\n#endif\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\twhile(s < end)\n\n\t{\n\n\t\tregister int rgb = *(uint32_t*)s; s += 4;\n\n\t\t*d++ = ((rgb&0xFF)>>3) + ((rgb&0xFC00)>>5) + ((rgb&0xF80000)>>8);\n\n\t}\n\n}\n", "idx": 23205}
{"project": "FFmpeg", "commit_id": "d7da4d47a6841444f12bf56dfe4230d3e4af8646", "target": 1, "func": "static int mxf_read_header(AVFormatContext *s)\n\n{\n\n    MXFContext *mxf = s->priv_data;\n\n    KLVPacket klv;\n\n    int64_t essence_offset = 0;\n\n    int ret;\n\n\n\n    mxf->last_forward_tell = INT64_MAX;\n\n    mxf->edit_units_per_packet = 1;\n\n\n\n    if (!mxf_read_sync(s->pb, mxf_header_partition_pack_key, 14)) {\n\n        av_log(s, AV_LOG_ERROR, \"could not find header partition pack key\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avio_seek(s->pb, -14, SEEK_CUR);\n\n    mxf->fc = s;\n\n    mxf->run_in = avio_tell(s->pb);\n\n\n\n    while (!url_feof(s->pb)) {\n\n        const MXFMetadataReadTableEntry *metadata;\n\n\n\n        if (klv_read_packet(&klv, s->pb) < 0) {\n\n            /* EOF - seek to previous partition or stop */\n\n            if(mxf_parse_handle_partition_or_eof(mxf) <= 0)\n\n                break;\n\n            else\n\n                continue;\n\n        }\n\n\n\n        PRINT_KEY(s, \"read header\", klv.key);\n\n        av_dlog(s, \"size %\"PRIu64\" offset %#\"PRIx64\"\\n\", klv.length, klv.offset);\n\n        if (IS_KLV_KEY(klv.key, mxf_encrypted_triplet_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_essence_element_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_avid_essence_element_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_system_item_key)) {\n\n\n\n            if (!mxf->current_partition) {\n\n                av_log(mxf->fc, AV_LOG_ERROR, \"found essence prior to first PartitionPack\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            if (!mxf->current_partition->essence_offset) {\n\n                /* for OP1a we compute essence_offset\n\n                 * for OPAtom we point essence_offset after the KL (usually op1a_essence_offset + 20 or 25)\n\n                 * TODO: for OP1a we could eliminate this entire if statement, always stopping parsing at op1a_essence_offset\n\n                 *       for OPAtom we still need the actual essence_offset though (the KL's length can vary)\n\n                 */\n\n                int64_t op1a_essence_offset =\n\n                    round_to_kag(mxf->current_partition->this_partition +\n\n                                 mxf->current_partition->pack_length,       mxf->current_partition->kag_size) +\n\n                    round_to_kag(mxf->current_partition->header_byte_count, mxf->current_partition->kag_size) +\n\n                    round_to_kag(mxf->current_partition->index_byte_count,  mxf->current_partition->kag_size);\n\n\n\n                if (mxf->op == OPAtom) {\n\n                    /* point essence_offset to the actual data\n\n                    * OPAtom has all the essence in one big KLV\n\n                    */\n\n                    mxf->current_partition->essence_offset = avio_tell(s->pb);\n\n                    mxf->current_partition->essence_length = klv.length;\n\n                } else {\n\n                    /* NOTE: op1a_essence_offset may be less than to klv.offset (C0023S01.mxf)  */\n\n                    mxf->current_partition->essence_offset = op1a_essence_offset;\n\n                }\n\n            }\n\n\n\n            if (!essence_offset)\n\n                essence_offset = klv.offset;\n\n\n\n            /* seek to footer, previous partition or stop */\n\n            if (mxf_parse_handle_essence(mxf) <= 0)\n\n                break;\n\n            continue;\n\n        } else if (!memcmp(klv.key, mxf_header_partition_pack_key, 13) &&\n\n                   klv.key[13] >= 2 && klv.key[13] <= 4 && mxf->current_partition) {\n\n            /* next partition pack - keep going, seek to previous partition or stop */\n\n            if(mxf_parse_handle_partition_or_eof(mxf) <= 0)\n\n                break;\n\n            else if (mxf->parsing_backward)\n\n                continue;\n\n            /* we're still parsing forward. proceed to parsing this partition pack */\n\n        }\n\n\n\n        for (metadata = mxf_metadata_read_table; metadata->read; metadata++) {\n\n            if (IS_KLV_KEY(klv.key, metadata->key)) {\n\n                int res;\n\n                if (klv.key[5] == 0x53) {\n\n                    res = mxf_read_local_tags(mxf, &klv, metadata->read, metadata->ctx_size, metadata->type);\n\n                } else {\n\n                    uint64_t next = avio_tell(s->pb) + klv.length;\n\n                    res = metadata->read(mxf, s->pb, 0, klv.length, klv.key, klv.offset);\n\n\n\n                    /* only seek forward, else this can loop for a long time */\n\n                    if (avio_tell(s->pb) > next) {\n\n                        av_log(s, AV_LOG_ERROR, \"read past end of KLV @ %#\"PRIx64\"\\n\",\n\n                               klv.offset);\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n\n\n                    avio_seek(s->pb, next, SEEK_SET);\n\n                }\n\n                if (res < 0) {\n\n                    av_log(s, AV_LOG_ERROR, \"error reading header metadata\\n\");\n\n                    return res;\n\n                }\n\n                break;\n\n            }\n\n        }\n\n        if (!metadata->read)\n\n            avio_skip(s->pb, klv.length);\n\n    }\n\n    /* FIXME avoid seek */\n\n    if (!essence_offset)  {\n\n        av_log(s, AV_LOG_ERROR, \"no essence\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avio_seek(s->pb, essence_offset, SEEK_SET);\n\n\n\n    mxf_compute_essence_containers(mxf);\n\n\n\n    /* we need to do this before computing the index tables\n\n     * to be able to fill in zero IndexDurations with st->duration */\n\n    if ((ret = mxf_parse_structural_metadata(mxf)) < 0)\n\n        return ret;\n\n\n\n    if ((ret = mxf_compute_index_tables(mxf)) < 0)\n\n        return ret;\n\n\n\n    if (mxf->nb_index_tables > 1) {\n\n        /* TODO: look up which IndexSID to use via EssenceContainerData */\n\n        av_log(mxf->fc, AV_LOG_INFO, \"got %i index tables - only the first one (IndexSID %i) will be used\\n\",\n\n               mxf->nb_index_tables, mxf->index_tables[0].index_sid);\n\n    } else if (mxf->nb_index_tables == 0 && mxf->op == OPAtom) {\n\n        av_log(mxf->fc, AV_LOG_ERROR, \"cannot demux OPAtom without an index\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    mxf_handle_small_eubc(s);\n\n\n\n    return 0;\n\n}\n", "idx": 23206}
{"project": "FFmpeg", "commit_id": "7f5e75eea94020aaddeda1960186ceee73ca1c36", "target": 0, "func": "static av_cold int pulse_write_header(AVFormatContext *h)\n\n{\n\n    PulseData *s = h->priv_data;\n\n    AVStream *st = NULL;\n\n    int ret;\n\n    unsigned int i;\n\n    pa_sample_spec ss;\n\n    pa_buffer_attr attr = { -1, -1, -1, -1, -1 };\n\n    const char *stream_name = s->stream_name;\n\n\n\n    for (i = 0; i < h->nb_streams; i++) {\n\n        if (h->streams[i]->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            st = h->streams[i];\n\n            s->stream_index = i;\n\n            break;\n\n        }\n\n    }\n\n\n\n    if (!st) {\n\n        av_log(s, AV_LOG_ERROR, \"No audio stream found.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (!stream_name) {\n\n        if (h->filename[0])\n\n            stream_name = h->filename;\n\n        else\n\n            stream_name = \"Playback\";\n\n    }\n\n\n\n    ss.format = codec_id_to_pulse_format(st->codec->codec_id);\n\n    ss.rate = st->codec->sample_rate;\n\n    ss.channels = st->codec->channels;\n\n\n\n    s->pa = pa_simple_new(s->server,                 // Server\n\n                          s->name,                   // Application name\n\n                          PA_STREAM_PLAYBACK,\n\n                          s->device,                 // Device\n\n                          stream_name,               // Description of a stream\n\n                          &ss,                       // Sample format\n\n                          NULL,                      // Use default channel map\n\n                          &attr,                     // Buffering attributes\n\n                          &ret);                     // Result\n\n\n\n    if (!s->pa) {\n\n        av_log(s, AV_LOG_ERROR, \"pa_simple_new failed: %s\\n\", pa_strerror(ret));\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    avpriv_set_pts_info(st, 64, 1, 1000000);  /* 64 bits pts in us */\n\n\n\n    return 0;\n\n}\n", "idx": 23208}
{"project": "FFmpeg", "commit_id": "9f61abc8111c7c43f49ca012e957a108b9cc7610", "target": 0, "func": "static int seg_write_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    SegmentContext *seg = s->priv_data;\n\n    AVFormatContext *oc = seg->avf;\n\n    AVStream *st = s->streams[pkt->stream_index];\n\n    int64_t end_pts = seg->recording_time * seg->number;\n\n    int ret, can_split = 1;\n\n\n\n    if (!oc)\n\n        return AVERROR(EINVAL);\n\n\n\n    if (seg->has_video) {\n\n        can_split = st->codec->codec_type == AVMEDIA_TYPE_VIDEO &&\n\n                    pkt->flags & AV_PKT_FLAG_KEY;\n\n    }\n\n\n\n    if (can_split && av_compare_ts(pkt->pts, st->time_base, end_pts,\n\n                                   AV_TIME_BASE_Q) >= 0) {\n\n        av_log(s, AV_LOG_DEBUG, \"Next segment starts at %d %\"PRId64\"\\n\",\n\n               pkt->stream_index, pkt->pts);\n\n\n\n        ret = segment_end(oc, seg->individual_header_trailer);\n\n\n\n        if (!ret)\n\n            ret = segment_start(s, seg->individual_header_trailer);\n\n\n\n        if (ret)\n\n            goto fail;\n\n\n\n        oc = seg->avf;\n\n\n\n        if (seg->list) {\n\n            if (seg->list_type == LIST_HLS) {\n\n                if ((ret = segment_hls_window(s, 0)) < 0)\n\n                    goto fail;\n\n            } else {\n\n                avio_printf(seg->pb, \"%s\\n\", oc->filename);\n\n                avio_flush(seg->pb);\n\n                if (seg->size && !(seg->number % seg->size)) {\n\n                    avio_closep(&seg->pb);\n\n                    if ((ret = avio_open2(&seg->pb, seg->list, AVIO_FLAG_WRITE,\n\n                                          &s->interrupt_callback, NULL)) < 0)\n\n                        goto fail;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    ret = ff_write_chained(oc, pkt->stream_index, pkt, s);\n\n\n\nfail:\n\n    if (ret < 0)\n\n        seg_free_context(seg);\n\n\n\n    return ret;\n\n}\n", "idx": 23209}
{"project": "FFmpeg", "commit_id": "76e65a1b731e28d8382d500c3a7740b65df9f7b2", "target": 1, "func": "avs_decode_frame(AVCodecContext * avctx,\n\n                 void *data, int *got_frame, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    const uint8_t *buf_end = avpkt->data + avpkt->size;\n\n    int buf_size = avpkt->size;\n\n    AvsContext *const avs = avctx->priv_data;\n\n    AVFrame *picture = data;\n\n    AVFrame *const p =  &avs->picture;\n\n    const uint8_t *table, *vect;\n\n    uint8_t *out;\n\n    int i, j, x, y, stride, vect_w = 3, vect_h = 3;\n\n    AvsVideoSubType sub_type;\n\n    AvsBlockType type;\n\n    GetBitContext change_map;\n\n\n\n    if (avctx->reget_buffer(avctx, p)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n    p->reference = 3;\n\n    p->pict_type = AV_PICTURE_TYPE_P;\n\n    p->key_frame = 0;\n\n\n\n    out = avs->picture.data[0];\n\n    stride = avs->picture.linesize[0];\n\n\n\n    if (buf_end - buf < 4)\n\n        return AVERROR_INVALIDDATA;\n\n    sub_type = buf[0];\n\n    type = buf[1];\n\n    buf += 4;\n\n\n\n    if (type == AVS_PALETTE) {\n\n        int first, last;\n\n        uint32_t *pal = (uint32_t *) avs->picture.data[1];\n\n\n\n        first = AV_RL16(buf);\n\n        last = first + AV_RL16(buf + 2);\n\n        if (first >= 256 || last > 256 || buf_end - buf < 4 + 4 + 3 * (last - first))\n\n            return AVERROR_INVALIDDATA;\n\n        buf += 4;\n\n        for (i=first; i<last; i++, buf+=3) {\n\n            pal[i] = (buf[0] << 18) | (buf[1] << 10) | (buf[2] << 2);\n\n            pal[i] |= 0xFFU << 24 | (pal[i] >> 6) & 0x30303;\n\n        }\n\n\n\n        sub_type = buf[0];\n\n        type = buf[1];\n\n        buf += 4;\n\n    }\n\n\n\n    if (type != AVS_VIDEO)\n\n        return -1;\n\n\n\n    switch (sub_type) {\n\n    case AVS_I_FRAME:\n\n        p->pict_type = AV_PICTURE_TYPE_I;\n\n        p->key_frame = 1;\n\n    case AVS_P_FRAME_3X3:\n\n        vect_w = 3;\n\n        vect_h = 3;\n\n        break;\n\n\n\n    case AVS_P_FRAME_2X2:\n\n        vect_w = 2;\n\n        vect_h = 2;\n\n        break;\n\n\n\n    case AVS_P_FRAME_2X3:\n\n        vect_w = 2;\n\n        vect_h = 3;\n\n        break;\n\n\n\n    default:\n\n      return -1;\n\n    }\n\n\n\n    if (buf_end - buf < 256 * vect_w * vect_h)\n\n        return AVERROR_INVALIDDATA;\n\n    table = buf + (256 * vect_w * vect_h);\n\n    if (sub_type != AVS_I_FRAME) {\n\n        int map_size = ((318 / vect_w + 7) / 8) * (198 / vect_h);\n\n        if (buf_end - table < map_size)\n\n            return AVERROR_INVALIDDATA;\n\n        init_get_bits(&change_map, table, map_size * 8);\n\n        table += map_size;\n\n    }\n\n\n\n    for (y=0; y<198; y+=vect_h) {\n\n        for (x=0; x<318; x+=vect_w) {\n\n            if (sub_type == AVS_I_FRAME || get_bits1(&change_map)) {\n\n                if (buf_end - table < 1)\n\n                    return AVERROR_INVALIDDATA;\n\n                vect = &buf[*table++ * (vect_w * vect_h)];\n\n                for (j=0; j<vect_w; j++) {\n\n                    out[(y + 0) * stride + x + j] = vect[(0 * vect_w) + j];\n\n                    out[(y + 1) * stride + x + j] = vect[(1 * vect_w) + j];\n\n                    if (vect_h == 3)\n\n                        out[(y + 2) * stride + x + j] =\n\n                            vect[(2 * vect_w) + j];\n\n                }\n\n            }\n\n        }\n\n        if (sub_type != AVS_I_FRAME)\n\n            align_get_bits(&change_map);\n\n    }\n\n\n\n    *picture   = avs->picture;\n\n    *got_frame = 1;\n\n\n\n    return buf_size;\n\n}\n", "idx": 23210}
{"project": "FFmpeg", "commit_id": "241f8465d07ecc0696bcda994a1f44d836b8809c", "target": 1, "func": "int av_asrc_buffer_add_buffer(AVFilterContext *ctx,\n\n                              uint8_t *buf, int buf_size, int sample_rate,\n\n                              int sample_fmt, int64_t channel_layout, int planar,\n\n                              int64_t pts, int av_unused flags)\n\n{\n\n    uint8_t *data[8];\n\n    int linesize[8];\n\n    int nb_channels = av_get_channel_layout_nb_channels(channel_layout),\n\n        nb_samples  = buf_size / nb_channels / av_get_bytes_per_sample(sample_fmt);\n\n\n\n    av_samples_fill_arrays(data, linesize,\n\n                           buf, nb_channels, nb_samples,\n\n                           sample_fmt, 16);\n\n\n\n    return av_asrc_buffer_add_samples(ctx,\n\n                                      data, linesize, nb_samples,\n\n                                      sample_rate,\n\n                                      sample_fmt, channel_layout, planar,\n\n                                      pts, flags);\n\n}\n", "idx": 23211}
{"project": "FFmpeg", "commit_id": "00cbe9e4053fd562b6f21e76aca6636ff926b637", "target": 1, "func": "static int vmdaudio_decode_frame(AVCodecContext *avctx,\n\n                                 void *data, int *data_size,\n\n                                 AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    VmdAudioContext *s = avctx->priv_data;\n\n    int block_type, silent_chunks;\n\n    unsigned char *output_samples = (unsigned char *)data;\n\n\n\n    if (buf_size < 16) {\n\n        av_log(avctx, AV_LOG_WARNING, \"skipping small junk packet\\n\");\n\n        *data_size = 0;\n\n        return buf_size;\n\n    }\n\n\n\n    block_type = buf[6];\n\n    if (block_type < BLOCK_TYPE_AUDIO || block_type > BLOCK_TYPE_SILENCE) {\n\n        av_log(avctx, AV_LOG_ERROR, \"unknown block type: %d\\n\", block_type);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    buf      += 16;\n\n    buf_size -= 16;\n\n\n\n    silent_chunks = 0;\n\n    if (block_type == BLOCK_TYPE_INITIAL) {\n\n        uint32_t flags = AV_RB32(buf);\n\n        silent_chunks  = av_popcount(flags);\n\n        buf      += 4;\n\n        buf_size -= 4;\n\n    } else if (block_type == BLOCK_TYPE_SILENCE) {\n\n        silent_chunks = 1;\n\n        buf_size = 0; // should already be zero but set it just to be sure\n\n    }\n\n\n\n    /* ensure output buffer is large enough */\n\n    if (*data_size < (avctx->block_align*silent_chunks + buf_size) * s->out_bps)\n\n        return -1;\n\n\n\n    *data_size = vmdaudio_loadsound(s, output_samples, buf, silent_chunks, buf_size);\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 23212}
{"project": "FFmpeg", "commit_id": "2afe05402f05d485f0c356b04dc562f0510d317d", "target": 1, "func": "static void ps_decorrelate_c(INTFLOAT (*out)[2], INTFLOAT (*delay)[2],\n\n                             INTFLOAT (*ap_delay)[PS_QMF_TIME_SLOTS + PS_MAX_AP_DELAY][2],\n\n                             const INTFLOAT phi_fract[2], const INTFLOAT (*Q_fract)[2],\n\n                             const INTFLOAT *transient_gain,\n\n                             INTFLOAT g_decay_slope,\n\n                             int len)\n\n{\n\n    static const INTFLOAT a[] = { Q31(0.65143905753106f),\n\n                               Q31(0.56471812200776f),\n\n                               Q31(0.48954165955695f) };\n\n    INTFLOAT ag[PS_AP_LINKS];\n\n    int m, n;\n\n\n\n    for (m = 0; m < PS_AP_LINKS; m++)\n\n        ag[m] = AAC_MUL30(a[m], g_decay_slope);\n\n\n\n    for (n = 0; n < len; n++) {\n\n        INTFLOAT in_re = AAC_MSUB30(delay[n][0], phi_fract[0], delay[n][1], phi_fract[1]);\n\n        INTFLOAT in_im = AAC_MADD30(delay[n][0], phi_fract[1], delay[n][1], phi_fract[0]);\n\n        for (m = 0; m < PS_AP_LINKS; m++) {\n\n            INTFLOAT a_re                = AAC_MUL31(ag[m], in_re);\n\n            INTFLOAT a_im                = AAC_MUL31(ag[m], in_im);\n\n            INTFLOAT link_delay_re       = ap_delay[m][n+2-m][0];\n\n            INTFLOAT link_delay_im       = ap_delay[m][n+2-m][1];\n\n            INTFLOAT fractional_delay_re = Q_fract[m][0];\n\n            INTFLOAT fractional_delay_im = Q_fract[m][1];\n\n            INTFLOAT apd_re = in_re;\n\n            INTFLOAT apd_im = in_im;\n\n            in_re = AAC_MSUB30(link_delay_re, fractional_delay_re,\n\n                    link_delay_im, fractional_delay_im);\n\n            in_re -= a_re;\n\n            in_im = AAC_MADD30(link_delay_re, fractional_delay_im,\n\n                    link_delay_im, fractional_delay_re);\n\n            in_im -= a_im;\n\n            ap_delay[m][n+5][0] = apd_re + AAC_MUL31(ag[m], in_re);\n\n            ap_delay[m][n+5][1] = apd_im + AAC_MUL31(ag[m], in_im);\n\n        }\n\n        out[n][0] = AAC_MUL16(transient_gain[n], in_re);\n\n        out[n][1] = AAC_MUL16(transient_gain[n], in_im);\n\n    }\n\n}\n", "idx": 23214}
{"project": "FFmpeg", "commit_id": "89bcb77726e222aee9d8536f0310d805f7d39fac", "target": 1, "func": "static int parse_presentation_segment(AVCodecContext *avctx,\n                                      const uint8_t *buf, int buf_size,\n                                      int64_t pts)\n{\n    PGSSubContext *ctx = avctx->priv_data;\n    int i, state, ret;\n    const uint8_t *buf_end = buf + buf_size;\n    // Video descriptor\n    int w = bytestream_get_be16(&buf);\n    int h = bytestream_get_be16(&buf);\n    uint16_t object_index;\n    ctx->presentation.pts = pts;\n    av_dlog(avctx, \"Video Dimensions %dx%d\\n\",\n            w, h);\n    ret = ff_set_dimensions(avctx, w, h);\n    if (ret < 0)\n        return ret;\n    /* Skip 1 bytes of unknown, frame rate */\n    buf++;\n    // Composition descriptor\n    ctx->presentation.id_number = bytestream_get_be16(&buf);\n    /*\n     * state is a 2 bit field that defines pgs epoch boundaries\n     * 00 - Normal, previously defined objects and palettes are still valid\n     * 01 - Acquisition point, previous objects and palettes can be released\n     * 10 - Epoch start, previous objects and palettes can be released\n     * 11 - Epoch continue, previous objects and palettes can be released\n     *\n     * reserved 6 bits discarded\n     */\n    state = bytestream_get_byte(&buf) >> 6;\n    if (state != 0) {\n        flush_cache(avctx);\n    /*\n     * skip palette_update_flag (0x80),\n     */\n    buf += 1;\n    ctx->presentation.palette_id = bytestream_get_byte(&buf);\n    ctx->presentation.object_count = bytestream_get_byte(&buf);\n    if (ctx->presentation.object_count > MAX_OBJECT_REFS) {\n        av_log(avctx, AV_LOG_ERROR,\n               \"Invalid number of presentation objects %d\\n\",\n               ctx->presentation.object_count);\n        ctx->presentation.object_count = 2;\n        if (avctx->err_recognition & AV_EF_EXPLODE) {\n    for (i = 0; i < ctx->presentation.object_count; i++)\n    {\n        ctx->presentation.objects[i].id = bytestream_get_be16(&buf);\n        ctx->presentation.objects[i].window_id = bytestream_get_byte(&buf);\n        ctx->presentation.objects[i].composition_flag = bytestream_get_byte(&buf);\n        ctx->presentation.objects[i].x = bytestream_get_be16(&buf);\n        ctx->presentation.objects[i].y = bytestream_get_be16(&buf);\n        // If cropping\n        if (ctx->presentation.objects[i].composition_flag & 0x80) {\n            ctx->presentation.objects[i].crop_x = bytestream_get_be16(&buf);\n            ctx->presentation.objects[i].crop_y = bytestream_get_be16(&buf);\n            ctx->presentation.objects[i].crop_w = bytestream_get_be16(&buf);\n            ctx->presentation.objects[i].crop_h = bytestream_get_be16(&buf);\n        av_dlog(avctx, \"Subtitle Placement x=%d, y=%d\\n\",\n                ctx->presentation.objects[i].x, ctx->presentation.objects[i].y);\n        if (ctx->presentation.objects[i].x > avctx->width ||\n            ctx->presentation.objects[i].y > avctx->height) {\n            av_log(avctx, AV_LOG_ERROR, \"Subtitle out of video bounds. x = %d, y = %d, video width = %d, video height = %d.\\n\",\n                   ctx->presentation.objects[i].x,\n                   ctx->presentation.objects[i].y,\n                    avctx->width, avctx->height);\n            ctx->presentation.objects[i].x = 0;\n            ctx->presentation.objects[i].y = 0;\n            if (avctx->err_recognition & AV_EF_EXPLODE) {\n    return 0;", "idx": 23216}
{"project": "FFmpeg", "commit_id": "9937362c54be085e75c90c55dad443329be59e69", "target": 0, "func": "PROTO4(_pack_2ch_)\n\nPROTO4(_pack_6ch_)\n\nPROTO4(_unpack_2ch_)\n\n\n\nav_cold void swri_audio_convert_init_x86(struct AudioConvert *ac,\n\n                                 enum AVSampleFormat out_fmt,\n\n                                 enum AVSampleFormat in_fmt,\n\n                                 int channels){\n\n    int mm_flags = av_get_cpu_flags();\n\n\n\n    ac->simd_f= NULL;\n\n\n\n//FIXME add memcpy case\n\n\n\n#define MULTI_CAPS_FUNC(flag, cap) \\\n\n    if (mm_flags & flag) {\\\n\n        if(   out_fmt == AV_SAMPLE_FMT_S32  && in_fmt == AV_SAMPLE_FMT_S16 || out_fmt == AV_SAMPLE_FMT_S32P && in_fmt == AV_SAMPLE_FMT_S16P)\\\n\n            ac->simd_f =  ff_int16_to_int32_a_ ## cap;\\\n\n        if(   out_fmt == AV_SAMPLE_FMT_S16  && in_fmt == AV_SAMPLE_FMT_S32 || out_fmt == AV_SAMPLE_FMT_S16P && in_fmt == AV_SAMPLE_FMT_S32P)\\\n\n            ac->simd_f =  ff_int32_to_int16_a_ ## cap;\\\n\n    }\n\n\n\nMULTI_CAPS_FUNC(AV_CPU_FLAG_MMX, mmx)\n\nMULTI_CAPS_FUNC(AV_CPU_FLAG_SSE2, sse2)\n\n\n\n    if(mm_flags & AV_CPU_FLAG_MMX) {\n\n        if(channels == 6) {\n\n            if(   out_fmt == AV_SAMPLE_FMT_FLT  && in_fmt == AV_SAMPLE_FMT_FLTP || out_fmt == AV_SAMPLE_FMT_S32 && in_fmt == AV_SAMPLE_FMT_S32P)\n\n                ac->simd_f =  ff_pack_6ch_float_to_float_a_mmx;\n\n        }\n\n    }\n\n\n\n    if(mm_flags & AV_CPU_FLAG_SSE2) {\n\n        if(   out_fmt == AV_SAMPLE_FMT_FLT  && in_fmt == AV_SAMPLE_FMT_S32 || out_fmt == AV_SAMPLE_FMT_FLTP && in_fmt == AV_SAMPLE_FMT_S32P)\n\n            ac->simd_f =  ff_int32_to_float_a_sse2;\n\n        if(   out_fmt == AV_SAMPLE_FMT_FLT  && in_fmt == AV_SAMPLE_FMT_S16 || out_fmt == AV_SAMPLE_FMT_FLTP && in_fmt == AV_SAMPLE_FMT_S16P)\n\n            ac->simd_f =  ff_int16_to_float_a_sse2;\n\n        if(   out_fmt == AV_SAMPLE_FMT_S32  && in_fmt == AV_SAMPLE_FMT_FLT || out_fmt == AV_SAMPLE_FMT_S32P && in_fmt == AV_SAMPLE_FMT_FLTP)\n\n            ac->simd_f =  ff_float_to_int32_a_sse2;\n\n        if(   out_fmt == AV_SAMPLE_FMT_S16  && in_fmt == AV_SAMPLE_FMT_FLT || out_fmt == AV_SAMPLE_FMT_S16P && in_fmt == AV_SAMPLE_FMT_FLTP)\n\n            ac->simd_f =  ff_float_to_int16_a_sse2;\n\n\n\n        if(channels == 2) {\n\n            if(   out_fmt == AV_SAMPLE_FMT_FLT  && in_fmt == AV_SAMPLE_FMT_FLTP || out_fmt == AV_SAMPLE_FMT_S32 && in_fmt == AV_SAMPLE_FMT_S32P)\n\n                ac->simd_f =  ff_pack_2ch_int32_to_int32_a_sse2;\n\n            if(   out_fmt == AV_SAMPLE_FMT_S16  && in_fmt == AV_SAMPLE_FMT_S16P)\n\n                ac->simd_f =  ff_pack_2ch_int16_to_int16_a_sse2;\n\n            if(   out_fmt == AV_SAMPLE_FMT_S32  && in_fmt == AV_SAMPLE_FMT_S16P)\n\n                ac->simd_f =  ff_pack_2ch_int16_to_int32_a_sse2;\n\n            if(   out_fmt == AV_SAMPLE_FMT_S16  && in_fmt == AV_SAMPLE_FMT_S32P)\n\n                ac->simd_f =  ff_pack_2ch_int32_to_int16_a_sse2;\n\n\n\n            if(   out_fmt == AV_SAMPLE_FMT_FLTP  && in_fmt == AV_SAMPLE_FMT_FLT || out_fmt == AV_SAMPLE_FMT_S32P && in_fmt == AV_SAMPLE_FMT_S32)\n\n                ac->simd_f =  ff_unpack_2ch_int32_to_int32_a_sse2;\n\n            if(   out_fmt == AV_SAMPLE_FMT_S16P  && in_fmt == AV_SAMPLE_FMT_S16)\n\n                ac->simd_f =  ff_unpack_2ch_int16_to_int16_a_sse2;\n\n            if(   out_fmt == AV_SAMPLE_FMT_S32P  && in_fmt == AV_SAMPLE_FMT_S16)\n\n                ac->simd_f =  ff_unpack_2ch_int16_to_int32_a_sse2;\n\n            if(   out_fmt == AV_SAMPLE_FMT_S16P  && in_fmt == AV_SAMPLE_FMT_S32)\n\n                ac->simd_f =  ff_unpack_2ch_int32_to_int16_a_sse2;\n\n\n\n            if(   out_fmt == AV_SAMPLE_FMT_FLT  && in_fmt == AV_SAMPLE_FMT_S32P)\n\n                ac->simd_f =  ff_pack_2ch_int32_to_float_a_sse2;\n\n            if(   out_fmt == AV_SAMPLE_FMT_S32  && in_fmt == AV_SAMPLE_FMT_FLTP)\n\n                ac->simd_f =  ff_pack_2ch_float_to_int32_a_sse2;\n\n            if(   out_fmt == AV_SAMPLE_FMT_FLT  && in_fmt == AV_SAMPLE_FMT_S16P)\n\n                ac->simd_f =  ff_pack_2ch_int16_to_float_a_sse2;\n\n            if(   out_fmt == AV_SAMPLE_FMT_S16  && in_fmt == AV_SAMPLE_FMT_FLTP)\n\n                ac->simd_f =  ff_pack_2ch_float_to_int16_a_sse2;\n\n            if(   out_fmt == AV_SAMPLE_FMT_FLTP  && in_fmt == AV_SAMPLE_FMT_S32)\n\n                ac->simd_f =  ff_unpack_2ch_int32_to_float_a_sse2;\n\n            if(   out_fmt == AV_SAMPLE_FMT_S32P  && in_fmt == AV_SAMPLE_FMT_FLT)\n\n                ac->simd_f =  ff_unpack_2ch_float_to_int32_a_sse2;\n\n            if(   out_fmt == AV_SAMPLE_FMT_FLTP  && in_fmt == AV_SAMPLE_FMT_S16)\n\n                ac->simd_f =  ff_unpack_2ch_int16_to_float_a_sse2;\n\n            if(   out_fmt == AV_SAMPLE_FMT_S16P  && in_fmt == AV_SAMPLE_FMT_FLT)\n\n                ac->simd_f =  ff_unpack_2ch_float_to_int16_a_sse2;\n\n        }\n\n    }\n\n    if(mm_flags & AV_CPU_FLAG_SSSE3) {\n\n        if(channels == 2) {\n\n            if(   out_fmt == AV_SAMPLE_FMT_S16P  && in_fmt == AV_SAMPLE_FMT_S16)\n\n                ac->simd_f =  ff_unpack_2ch_int16_to_int16_a_ssse3;\n\n            if(   out_fmt == AV_SAMPLE_FMT_S32P  && in_fmt == AV_SAMPLE_FMT_S16)\n\n                ac->simd_f =  ff_unpack_2ch_int16_to_int32_a_ssse3;\n\n            if(   out_fmt == AV_SAMPLE_FMT_FLTP  && in_fmt == AV_SAMPLE_FMT_S16)\n\n                ac->simd_f =  ff_unpack_2ch_int16_to_float_a_ssse3;\n\n        }\n\n    }\n\n    if(mm_flags & AV_CPU_FLAG_SSE4) {\n\n        if(channels == 6) {\n\n            if(   out_fmt == AV_SAMPLE_FMT_FLT  && in_fmt == AV_SAMPLE_FMT_FLTP || out_fmt == AV_SAMPLE_FMT_S32 && in_fmt == AV_SAMPLE_FMT_S32P)\n\n                ac->simd_f =  ff_pack_6ch_float_to_float_a_sse4;\n\n            if(   out_fmt == AV_SAMPLE_FMT_FLT  && in_fmt == AV_SAMPLE_FMT_S32P)\n\n                ac->simd_f =  ff_pack_6ch_int32_to_float_a_sse4;\n\n            if(   out_fmt == AV_SAMPLE_FMT_S32  && in_fmt == AV_SAMPLE_FMT_FLTP)\n\n                ac->simd_f =  ff_pack_6ch_float_to_int32_a_sse4;\n\n        }\n\n    }\n\n    if(HAVE_AVX_EXTERNAL && mm_flags & AV_CPU_FLAG_AVX) {\n\n        if(   out_fmt == AV_SAMPLE_FMT_FLT  && in_fmt == AV_SAMPLE_FMT_S32 || out_fmt == AV_SAMPLE_FMT_FLTP && in_fmt == AV_SAMPLE_FMT_S32P)\n\n            ac->simd_f =  ff_int32_to_float_a_avx;\n\n        if(channels == 6) {\n\n            if(   out_fmt == AV_SAMPLE_FMT_FLT  && in_fmt == AV_SAMPLE_FMT_FLTP || out_fmt == AV_SAMPLE_FMT_S32 && in_fmt == AV_SAMPLE_FMT_S32P)\n\n                ac->simd_f =  ff_pack_6ch_float_to_float_a_avx;\n\n            if(   out_fmt == AV_SAMPLE_FMT_FLT  && in_fmt == AV_SAMPLE_FMT_S32P)\n\n                ac->simd_f =  ff_pack_6ch_int32_to_float_a_avx;\n\n            if(   out_fmt == AV_SAMPLE_FMT_S32  && in_fmt == AV_SAMPLE_FMT_FLTP)\n\n                ac->simd_f =  ff_pack_6ch_float_to_int32_a_avx;\n\n        }\n\n    }\n\n}\n", "idx": 23217}
{"project": "FFmpeg", "commit_id": "f1caaa1c61310beba705957e6366f0392a0b005b", "target": 0, "func": "static av_cold int dnxhd_init_rc(DNXHDEncContext *ctx)\n\n{\n\n    FF_ALLOCZ_OR_GOTO(ctx->m.avctx, ctx->mb_rc, 8160*ctx->m.avctx->qmax*sizeof(RCEntry), fail);\n\n    if (ctx->m.avctx->mb_decision != FF_MB_DECISION_RD)\n\n        FF_ALLOCZ_OR_GOTO(ctx->m.avctx, ctx->mb_cmp, ctx->m.mb_num*sizeof(RCCMPEntry), fail);\n\n\n\n    ctx->frame_bits = (ctx->cid_table->coding_unit_size - 640 - 4 - ctx->min_padding) * 8;\n\n    ctx->qscale = 1;\n\n    ctx->lambda = 2<<LAMBDA_FRAC_BITS; // qscale 2\n\n    return 0;\n\n fail:\n\n    return -1;\n\n}\n", "idx": 23218}
{"project": "FFmpeg", "commit_id": "6a052e64b5d14ce2800eb45c699857347d9a78c9", "target": 0, "func": "static int dirac_decode_frame(AVCodecContext *avctx, void *data, int *data_size, AVPacket *pkt)\n\n{\n\n    DiracContext *s     = avctx->priv_data;\n\n    DiracFrame *picture = data;\n\n    uint8_t *buf        = pkt->data;\n\n    int buf_size        = pkt->size;\n\n    int i, data_unit_size, buf_idx = 0;\n\n\n\n    /* release unused frames */\n\n    for (i = 0; i < MAX_FRAMES; i++)\n\n        if (s->all_frames[i].avframe.data[0] && !s->all_frames[i].avframe.reference) {\n\n            avctx->release_buffer(avctx, &s->all_frames[i].avframe);\n\n            memset(s->all_frames[i].interpolated, 0, sizeof(s->all_frames[i].interpolated));\n\n        }\n\n\n\n    s->current_picture = NULL;\n\n    *data_size = 0;\n\n\n\n    /* end of stream, so flush delayed pics */\n\n    if (buf_size == 0)\n\n        return get_delayed_pic(s, (AVFrame *)data, data_size);\n\n\n\n    for (;;) {\n\n        /*[DIRAC_STD] Here starts the code from parse_info() defined in 9.6\n\n          [DIRAC_STD] PARSE_INFO_PREFIX = \"BBCD\" as defined in ISO/IEC 646\n\n          BBCD start code search */\n\n        for (; buf_idx + DATA_UNIT_HEADER_SIZE < buf_size; buf_idx++) {\n\n            if (buf[buf_idx  ] == 'B' && buf[buf_idx+1] == 'B' &&\n\n                buf[buf_idx+2] == 'C' && buf[buf_idx+3] == 'D')\n\n                break;\n\n        }\n\n        /* BBCD found or end of data */\n\n        if (buf_idx + DATA_UNIT_HEADER_SIZE >= buf_size)\n\n            break;\n\n\n\n        data_unit_size = AV_RB32(buf+buf_idx+5);\n\n        if (buf_idx + data_unit_size > buf_size || !data_unit_size) {\n\n            if(buf_idx + data_unit_size > buf_size)\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Data unit with size %d is larger than input buffer, discarding\\n\",\n\n                   data_unit_size);\n\n            buf_idx += 4;\n\n            continue;\n\n        }\n\n        /* [DIRAC_STD] dirac_decode_data_unit makes reference to the while defined in 9.3 inside the function parse_sequence() */\n\n        if (dirac_decode_data_unit(avctx, buf+buf_idx, data_unit_size))\n\n        {\n\n            av_log(s->avctx, AV_LOG_ERROR,\"Error in dirac_decode_data_unit\\n\");\n\n            return -1;\n\n        }\n\n        buf_idx += data_unit_size;\n\n    }\n\n\n\n    if (!s->current_picture)\n\n        return 0;\n\n\n\n    if (s->current_picture->avframe.display_picture_number > s->frame_number) {\n\n        DiracFrame *delayed_frame = remove_frame(s->delay_frames, s->frame_number);\n\n\n\n        s->current_picture->avframe.reference |= DELAYED_PIC_REF;\n\n\n\n        if (add_frame(s->delay_frames, MAX_DELAY, s->current_picture)) {\n\n            int min_num = s->delay_frames[0]->avframe.display_picture_number;\n\n            /* Too many delayed frames, so we display the frame with the lowest pts */\n\n            av_log(avctx, AV_LOG_ERROR, \"Delay frame overflow\\n\");\n\n            delayed_frame = s->delay_frames[0];\n\n\n\n            for (i = 1; s->delay_frames[i]; i++)\n\n                if (s->delay_frames[i]->avframe.display_picture_number < min_num)\n\n                    min_num = s->delay_frames[i]->avframe.display_picture_number;\n\n\n\n            delayed_frame = remove_frame(s->delay_frames, min_num);\n\n            add_frame(s->delay_frames, MAX_DELAY, s->current_picture);\n\n        }\n\n\n\n        if (delayed_frame) {\n\n            delayed_frame->avframe.reference ^= DELAYED_PIC_REF;\n\n            *(AVFrame*)data = delayed_frame->avframe;\n\n            *data_size = sizeof(AVFrame);\n\n        }\n\n    } else if (s->current_picture->avframe.display_picture_number == s->frame_number) {\n\n        /* The right frame at the right time :-) */\n\n        *(AVFrame*)data = s->current_picture->avframe;\n\n        *data_size = sizeof(AVFrame);\n\n    }\n\n\n\n    if (*data_size)\n\n        s->frame_number = picture->avframe.display_picture_number + 1;\n\n\n\n    return buf_idx;\n\n}\n", "idx": 23228}
{"project": "FFmpeg", "commit_id": "3438d82d4b3bd987304975961e2a42e82767107d", "target": 0, "func": "static int opt_default(const char *opt, const char *arg){\n\n    int type;\n\n    const AVOption *o= NULL;\n\n    int opt_types[]={AV_OPT_FLAG_VIDEO_PARAM, AV_OPT_FLAG_AUDIO_PARAM, 0, AV_OPT_FLAG_SUBTITLE_PARAM, 0};\n\n\n\n    for(type=0; type<CODEC_TYPE_NB; type++){\n\n        const AVOption *o2 = av_find_opt(avctx_opts[0], opt, NULL, opt_types[type], opt_types[type]);\n\n        if(o2)\n\n            o = av_set_string(avctx_opts[type], opt, arg);\n\n    }\n\n    if(!o)\n\n        o = av_set_string(avformat_opts, opt, arg);\n\n    if(!o)\n\n        o = av_set_string(sws_opts, opt, arg);\n\n    if(!o){\n\n        if(opt[0] == 'a')\n\n            o = av_set_string(avctx_opts[CODEC_TYPE_AUDIO], opt+1, arg);\n\n        else if(opt[0] == 'v')\n\n            o = av_set_string(avctx_opts[CODEC_TYPE_VIDEO], opt+1, arg);\n\n        else if(opt[0] == 's')\n\n            o = av_set_string(avctx_opts[CODEC_TYPE_SUBTITLE], opt+1, arg);\n\n    }\n\n    if(!o)\n\n        return -1;\n\n\n\n//    av_log(NULL, AV_LOG_ERROR, \"%s:%s: %f 0x%0X\\n\", opt, arg, av_get_double(avctx_opts, opt, NULL), (int)av_get_int(avctx_opts, opt, NULL));\n\n\n\n    //FIXME we should always use avctx_opts, ... for storing options so there wont be any need to keep track of whats set over this\n\n    opt_names= av_realloc(opt_names, sizeof(void*)*(opt_name_count+1));\n\n    opt_names[opt_name_count++]= o->name;\n\n\n\n#ifdef CONFIG_FFM_MUXER\n\n    /* disable generate of real time pts in ffm (need to be supressed anyway) */\n\n    if(avctx_opts[0]->flags & CODEC_FLAG_BITEXACT)\n\n        ffm_nopts = 1;\n\n#endif\n\n\n\n    if(avctx_opts[0]->debug)\n\n        av_log_set_level(AV_LOG_DEBUG);\n\n    return 0;\n\n}\n", "idx": 23239}
{"project": "FFmpeg", "commit_id": "fef7b2e0bef6972d8d48df51e477af7b017d1a38", "target": 0, "func": "static int null_draw_slice(AVFilterLink *link, int y, int h, int slice_dir) { return 0; }\n", "idx": 23249}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(yuv422ptoyuy2)(const uint8_t *ysrc, const uint8_t *usrc, const uint8_t *vsrc, uint8_t *dst,\n\n                                         long width, long height,\n\n                                         long lumStride, long chromStride, long dstStride)\n\n{\n\n    RENAME(yuvPlanartoyuy2)(ysrc, usrc, vsrc, dst, width, height, lumStride, chromStride, dstStride, 1);\n\n}\n", "idx": 23250}
{"project": "FFmpeg", "commit_id": "c16e99e3b3c02edcf33245468731d414eab97dac", "target": 0, "func": "D(float, sse)\n\nD(float, avx)\n\nD(int16, mmx)\n\nD(int16, sse2)\n\n\n\nav_cold int swri_rematrix_init_x86(struct SwrContext *s){\n\n#if HAVE_YASM\n\n    int mm_flags = av_get_cpu_flags();\n\n    int nb_in  = av_get_channel_layout_nb_channels(s->in_ch_layout);\n\n    int nb_out = av_get_channel_layout_nb_channels(s->out_ch_layout);\n\n    int num    = nb_in * nb_out;\n\n    int i,j;\n\n\n\n    s->mix_1_1_simd = NULL;\n\n    s->mix_2_1_simd = NULL;\n\n\n\n    if (s->midbuf.fmt == AV_SAMPLE_FMT_S16P){\n\n        if(EXTERNAL_MMX(mm_flags)) {\n\n            s->mix_1_1_simd = ff_mix_1_1_a_int16_mmx;\n\n            s->mix_2_1_simd = ff_mix_2_1_a_int16_mmx;\n\n        }\n\n        if(EXTERNAL_SSE2(mm_flags)) {\n\n            s->mix_1_1_simd = ff_mix_1_1_a_int16_sse2;\n\n            s->mix_2_1_simd = ff_mix_2_1_a_int16_sse2;\n\n        }\n\n        s->native_simd_matrix = av_mallocz_array(num,  2 * sizeof(int16_t));\n\n        s->native_simd_one    = av_mallocz(2 * sizeof(int16_t));\n\n        if (!s->native_simd_matrix || !s->native_simd_one)\n\n            return AVERROR(ENOMEM);\n\n\n\n        for(i=0; i<nb_out; i++){\n\n            int sh = 0;\n\n            for(j=0; j<nb_in; j++)\n\n                sh = FFMAX(sh, FFABS(((int*)s->native_matrix)[i * nb_in + j]));\n\n            sh = FFMAX(av_log2(sh) - 14, 0);\n\n            for(j=0; j<nb_in; j++) {\n\n                ((int16_t*)s->native_simd_matrix)[2*(i * nb_in + j)+1] = 15 - sh;\n\n                ((int16_t*)s->native_simd_matrix)[2*(i * nb_in + j)] =\n\n                    ((((int*)s->native_matrix)[i * nb_in + j]) + (1<<sh>>1)) >> sh;\n\n            }\n\n        }\n\n        ((int16_t*)s->native_simd_one)[1] = 14;\n\n        ((int16_t*)s->native_simd_one)[0] = 16384;\n\n    } else if(s->midbuf.fmt == AV_SAMPLE_FMT_FLTP){\n\n        if(EXTERNAL_SSE(mm_flags)) {\n\n            s->mix_1_1_simd = ff_mix_1_1_a_float_sse;\n\n            s->mix_2_1_simd = ff_mix_2_1_a_float_sse;\n\n        }\n\n        if(EXTERNAL_AVX(mm_flags)) {\n\n            s->mix_1_1_simd = ff_mix_1_1_a_float_avx;\n\n            s->mix_2_1_simd = ff_mix_2_1_a_float_avx;\n\n        }\n\n        s->native_simd_matrix = av_mallocz_array(num, sizeof(float));\n\n        s->native_simd_one = av_mallocz(sizeof(float));\n\n        if (!s->native_simd_matrix || !s->native_simd_one)\n\n            return AVERROR(ENOMEM);\n\n        memcpy(s->native_simd_matrix, s->native_matrix, num * sizeof(float));\n\n        memcpy(s->native_simd_one, s->native_one, sizeof(float));\n\n    }\n\n#endif\n\n\n\n    return 0;\n\n}\n", "idx": 23251}
{"project": "FFmpeg", "commit_id": "bd31c61cf94d01dbe1051cf65874e7b2c0ac5454", "target": 0, "func": "static int configure_output_video_filter(FilterGraph *fg, OutputFilter *ofilter, AVFilterInOut *out)\n\n{\n\n    char *pix_fmts;\n\n    OutputStream *ost = ofilter->ost;\n\n    OutputFile    *of = output_files[ost->file_index];\n\n    AVFilterContext *last_filter = out->filter_ctx;\n\n    int pad_idx = out->pad_idx;\n\n    int ret;\n\n    char name[255];\n\n\n\n    snprintf(name, sizeof(name), \"output stream %d:%d\", ost->file_index, ost->index);\n\n    ret = avfilter_graph_create_filter(&ofilter->filter,\n\n                                       avfilter_get_by_name(\"buffersink\"),\n\n                                       name, NULL, NULL, fg->graph);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (!hw_device_ctx && (ofilter->width || ofilter->height)) {\n\n        char args[255];\n\n        AVFilterContext *filter;\n\n\n\n        snprintf(args, sizeof(args), \"%d:%d:0x%X\",\n\n                 ofilter->width, ofilter->height,\n\n                 (unsigned)ost->sws_flags);\n\n        snprintf(name, sizeof(name), \"scaler for output stream %d:%d\",\n\n                 ost->file_index, ost->index);\n\n        if ((ret = avfilter_graph_create_filter(&filter, avfilter_get_by_name(\"scale\"),\n\n                                                name, args, NULL, fg->graph)) < 0)\n\n            return ret;\n\n        if ((ret = avfilter_link(last_filter, pad_idx, filter, 0)) < 0)\n\n            return ret;\n\n\n\n        last_filter = filter;\n\n        pad_idx = 0;\n\n    }\n\n\n\n    if ((pix_fmts = choose_pix_fmts(ofilter))) {\n\n        AVFilterContext *filter;\n\n        snprintf(name, sizeof(name), \"pixel format for output stream %d:%d\",\n\n                 ost->file_index, ost->index);\n\n        ret = avfilter_graph_create_filter(&filter,\n\n                                           avfilter_get_by_name(\"format\"),\n\n                                           \"format\", pix_fmts, NULL, fg->graph);\n\n        av_freep(&pix_fmts);\n\n        if (ret < 0)\n\n            return ret;\n\n        if ((ret = avfilter_link(last_filter, pad_idx, filter, 0)) < 0)\n\n            return ret;\n\n\n\n        last_filter = filter;\n\n        pad_idx     = 0;\n\n    }\n\n\n\n    if (ost->frame_rate.num) {\n\n        AVFilterContext *fps;\n\n        char args[255];\n\n\n\n        snprintf(args, sizeof(args), \"fps=%d/%d\", ost->frame_rate.num,\n\n                 ost->frame_rate.den);\n\n        snprintf(name, sizeof(name), \"fps for output stream %d:%d\",\n\n                 ost->file_index, ost->index);\n\n        ret = avfilter_graph_create_filter(&fps, avfilter_get_by_name(\"fps\"),\n\n                                           name, args, NULL, fg->graph);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        ret = avfilter_link(last_filter, pad_idx, fps, 0);\n\n        if (ret < 0)\n\n            return ret;\n\n        last_filter = fps;\n\n        pad_idx = 0;\n\n    }\n\n\n\n    snprintf(name, sizeof(name), \"trim for output stream %d:%d\",\n\n             ost->file_index, ost->index);\n\n    ret = insert_trim(of->start_time, of->recording_time,\n\n                      &last_filter, &pad_idx, name);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n\n\n    if ((ret = avfilter_link(last_filter, pad_idx, ofilter->filter, 0)) < 0)\n\n        return ret;\n\n\n\n    return 0;\n\n}\n", "idx": 23252}
{"project": "FFmpeg", "commit_id": "2caf19e90f270abe1e80a3e85acaf0eb5c9d0aac", "target": 1, "func": "static void FUNCC(pred4x4_left_dc)(uint8_t *_src, const uint8_t *topright, int _stride){\n\n    pixel *src = (pixel*)_src;\n\n    int stride = _stride/sizeof(pixel);\n\n    const int dc= (  src[-1+0*stride] + src[-1+1*stride] + src[-1+2*stride] + src[-1+3*stride] + 2) >>2;\n\n\n\n    ((pixel4*)(src+0*stride))[0]=\n\n    ((pixel4*)(src+1*stride))[0]=\n\n    ((pixel4*)(src+2*stride))[0]=\n\n    ((pixel4*)(src+3*stride))[0]= PIXEL_SPLAT_X4(dc);\n\n}\n", "idx": 23254}
{"project": "FFmpeg", "commit_id": "5183fac92fc5c574a053dd06b84e735a1ec1cfa6", "target": 1, "func": "static void decode_nal_sei_decoded_picture_hash(HEVCContext *s)\n\n{\n\n    int cIdx, i;\n\n    uint8_t hash_type;\n\n    //uint16_t picture_crc;\n\n    //uint32_t picture_checksum;\n\n    GetBitContext *gb = &s->HEVClc->gb;\n\n    hash_type = get_bits(gb, 8);\n\n\n\n    for (cIdx = 0; cIdx < 3/*((s->sps->chroma_format_idc == 0) ? 1 : 3)*/; cIdx++) {\n\n        if (hash_type == 0) {\n\n            s->is_md5 = 1;\n\n            for (i = 0; i < 16; i++)\n\n                s->md5[cIdx][i] = get_bits(gb, 8);\n\n        } else if (hash_type == 1) {\n\n            // picture_crc = get_bits(gb, 16);\n\n            skip_bits(gb, 16);\n\n        } else if (hash_type == 2) {\n\n            // picture_checksum = get_bits(gb, 32);\n\n            skip_bits(gb, 32);\n\n        }\n\n    }\n\n}\n", "idx": 23255}
{"project": "FFmpeg", "commit_id": "b7d9b4a1f1fcd01084ccbec6f7ef32c853681833", "target": 1, "func": "int ff_h263_decode_mb(MpegEncContext *s,\n                      int16_t block[6][64])\n{\n    int cbpc, cbpy, i, cbp, pred_x, pred_y, mx, my, dquant;\n    int16_t *mot_val;\n    const int xy= s->mb_x + s->mb_y * s->mb_stride;\n    int cbpb = 0, pb_mv_count = 0;\n    av_assert2(!s->h263_pred);\n    if (s->pict_type == AV_PICTURE_TYPE_P) {\n        do{\n            if (get_bits1(&s->gb)) {\n                /* skip mb */\n                s->mb_intra = 0;\n                for(i=0;i<6;i++)\n                    s->block_last_index[i] = -1;\n                s->mv_dir = MV_DIR_FORWARD;\n                s->mv_type = MV_TYPE_16X16;\n                s->current_picture.mb_type[xy] = MB_TYPE_SKIP | MB_TYPE_16x16 | MB_TYPE_L0;\n                s->mv[0][0][0] = 0;\n                s->mv[0][0][1] = 0;\n                s->mb_skipped = !(s->obmc | s->loop_filter);\n                goto end;\n            cbpc = get_vlc2(&s->gb, ff_h263_inter_MCBPC_vlc.table, INTER_MCBPC_VLC_BITS, 2);\n            if (cbpc < 0){\n                av_log(s->avctx, AV_LOG_ERROR, \"cbpc damaged at %d %d\\n\", s->mb_x, s->mb_y);\n        }while(cbpc == 20);\n        s->bdsp.clear_blocks(s->block[0]);\n        dquant = cbpc & 8;\n        s->mb_intra = ((cbpc & 4) != 0);\n        if (s->mb_intra) goto intra;\n        if(s->pb_frame && get_bits1(&s->gb))\n            pb_mv_count = h263_get_modb(&s->gb, s->pb_frame, &cbpb);\n        cbpy = get_vlc2(&s->gb, ff_h263_cbpy_vlc.table, CBPY_VLC_BITS, 1);\n        if(s->alt_inter_vlc==0 || (cbpc & 3)!=3)\n            cbpy ^= 0xF;\n        cbp = (cbpc & 3) | (cbpy << 2);\n        if (dquant) {\n            h263_decode_dquant(s);\n        s->mv_dir = MV_DIR_FORWARD;\n        if ((cbpc & 16) == 0) {\n            s->current_picture.mb_type[xy] = MB_TYPE_16x16 | MB_TYPE_L0;\n            /* 16x16 motion prediction */\n            s->mv_type = MV_TYPE_16X16;\n            ff_h263_pred_motion(s, 0, 0, &pred_x, &pred_y);\n            if (s->umvplus)\n               mx = h263p_decode_umotion(s, pred_x);\n            else\n               mx = ff_h263_decode_motion(s, pred_x, 1);\n            if (mx >= 0xffff)\n            if (s->umvplus)\n               my = h263p_decode_umotion(s, pred_y);\n            else\n               my = ff_h263_decode_motion(s, pred_y, 1);\n            if (my >= 0xffff)\n            s->mv[0][0][0] = mx;\n            s->mv[0][0][1] = my;\n            if (s->umvplus && (mx - pred_x) == 1 && (my - pred_y) == 1)\n               skip_bits1(&s->gb); /* Bit stuffing to prevent PSC */\n        } else {\n            s->current_picture.mb_type[xy] = MB_TYPE_8x8 | MB_TYPE_L0;\n            s->mv_type = MV_TYPE_8X8;\n            for(i=0;i<4;i++) {\n                mot_val = ff_h263_pred_motion(s, i, 0, &pred_x, &pred_y);\n                if (s->umvplus)\n                    mx = h263p_decode_umotion(s, pred_x);\n                else\n                    mx = ff_h263_decode_motion(s, pred_x, 1);\n                if (mx >= 0xffff)\n                if (s->umvplus)\n                    my = h263p_decode_umotion(s, pred_y);\n                else\n                    my = ff_h263_decode_motion(s, pred_y, 1);\n                if (my >= 0xffff)\n                s->mv[0][i][0] = mx;\n                s->mv[0][i][1] = my;\n                if (s->umvplus && (mx - pred_x) == 1 && (my - pred_y) == 1)\n                  skip_bits1(&s->gb); /* Bit stuffing to prevent PSC */\n                mot_val[0] = mx;\n                mot_val[1] = my;\n    } else if(s->pict_type==AV_PICTURE_TYPE_B) {\n        int mb_type;\n        const int stride= s->b8_stride;\n        int16_t *mot_val0 = s->current_picture.motion_val[0][2 * (s->mb_x + s->mb_y * stride)];\n        int16_t *mot_val1 = s->current_picture.motion_val[1][2 * (s->mb_x + s->mb_y * stride)];\n//        const int mv_xy= s->mb_x + 1 + s->mb_y * s->mb_stride;\n        //FIXME ugly\n        mot_val0[0       ]= mot_val0[2       ]= mot_val0[0+2*stride]= mot_val0[2+2*stride]=\n        mot_val0[1       ]= mot_val0[3       ]= mot_val0[1+2*stride]= mot_val0[3+2*stride]=\n        mot_val1[0       ]= mot_val1[2       ]= mot_val1[0+2*stride]= mot_val1[2+2*stride]=\n        mot_val1[1       ]= mot_val1[3       ]= mot_val1[1+2*stride]= mot_val1[3+2*stride]= 0;\n        do{\n            mb_type= get_vlc2(&s->gb, h263_mbtype_b_vlc.table, H263_MBTYPE_B_VLC_BITS, 2);\n            if (mb_type < 0){\n                av_log(s->avctx, AV_LOG_ERROR, \"b mb_type damaged at %d %d\\n\", s->mb_x, s->mb_y);\n            mb_type= h263_mb_type_b_map[ mb_type ];\n        }while(!mb_type);\n        s->mb_intra = IS_INTRA(mb_type);\n        if(HAS_CBP(mb_type)){\n            s->bdsp.clear_blocks(s->block[0]);\n            cbpc = get_vlc2(&s->gb, cbpc_b_vlc.table, CBPC_B_VLC_BITS, 1);\n            if(s->mb_intra){\n                dquant = IS_QUANT(mb_type);\n                goto intra;\n            cbpy = get_vlc2(&s->gb, ff_h263_cbpy_vlc.table, CBPY_VLC_BITS, 1);\n            if (cbpy < 0){\n                av_log(s->avctx, AV_LOG_ERROR, \"b cbpy damaged at %d %d\\n\", s->mb_x, s->mb_y);\n            if(s->alt_inter_vlc==0 || (cbpc & 3)!=3)\n                cbpy ^= 0xF;\n            cbp = (cbpc & 3) | (cbpy << 2);\n        }else\n            cbp=0;\n        av_assert2(!s->mb_intra);\n        if(IS_QUANT(mb_type)){\n            h263_decode_dquant(s);\n        if(IS_DIRECT(mb_type)){\n            s->mv_dir = MV_DIR_FORWARD | MV_DIR_BACKWARD | MV_DIRECT;\n            mb_type |= set_direct_mv(s);\n        }else{\n            s->mv_dir = 0;\n            s->mv_type= MV_TYPE_16X16;\n//FIXME UMV\n            if(USES_LIST(mb_type, 0)){\n                int16_t *mot_val= ff_h263_pred_motion(s, 0, 0, &pred_x, &pred_y);\n                s->mv_dir = MV_DIR_FORWARD;\n                if (s->umvplus)\n                    mx = h263p_decode_umotion(s, pred_x);\n                else\n                    mx = ff_h263_decode_motion(s, pred_x, 1);\n                if (mx >= 0xffff)\n                if (s->umvplus)\n                    my = h263p_decode_umotion(s, pred_y);\n                else\n                    my = ff_h263_decode_motion(s, pred_y, 1);\n                if (my >= 0xffff)\n                if (s->umvplus && (mx - pred_x) == 1 && (my - pred_y) == 1)\n                    skip_bits1(&s->gb); /* Bit stuffing to prevent PSC */\n                s->mv[0][0][0] = mx;\n                s->mv[0][0][1] = my;\n                mot_val[0       ]= mot_val[2       ]= mot_val[0+2*stride]= mot_val[2+2*stride]= mx;\n                mot_val[1       ]= mot_val[3       ]= mot_val[1+2*stride]= mot_val[3+2*stride]= my;\n            if(USES_LIST(mb_type, 1)){\n                int16_t *mot_val= ff_h263_pred_motion(s, 0, 1, &pred_x, &pred_y);\n                s->mv_dir |= MV_DIR_BACKWARD;\n                if (s->umvplus)\n                    mx = h263p_decode_umotion(s, pred_x);\n                else\n                    mx = ff_h263_decode_motion(s, pred_x, 1);\n                if (mx >= 0xffff)\n                if (s->umvplus)\n                    my = h263p_decode_umotion(s, pred_y);\n                else\n                    my = ff_h263_decode_motion(s, pred_y, 1);\n                if (my >= 0xffff)\n                if (s->umvplus && (mx - pred_x) == 1 && (my - pred_y) == 1)\n                    skip_bits1(&s->gb); /* Bit stuffing to prevent PSC */\n                s->mv[1][0][0] = mx;\n                s->mv[1][0][1] = my;\n                mot_val[0       ]= mot_val[2       ]= mot_val[0+2*stride]= mot_val[2+2*stride]= mx;\n                mot_val[1       ]= mot_val[3       ]= mot_val[1+2*stride]= mot_val[3+2*stride]= my;\n        s->current_picture.mb_type[xy] = mb_type;\n    } else { /* I-Frame */\n        do{\n            cbpc = get_vlc2(&s->gb, ff_h263_intra_MCBPC_vlc.table, INTRA_MCBPC_VLC_BITS, 2);\n            if (cbpc < 0){\n                av_log(s->avctx, AV_LOG_ERROR, \"I cbpc damaged at %d %d\\n\", s->mb_x, s->mb_y);\n        }while(cbpc == 8);\n        s->bdsp.clear_blocks(s->block[0]);\n        dquant = cbpc & 4;\n        s->mb_intra = 1;\nintra:\n        s->current_picture.mb_type[xy] = MB_TYPE_INTRA;\n        if (s->h263_aic) {\n            s->ac_pred = get_bits1(&s->gb);\n            if(s->ac_pred){\n                s->current_picture.mb_type[xy] = MB_TYPE_INTRA | MB_TYPE_ACPRED;\n                s->h263_aic_dir = get_bits1(&s->gb);\n        }else\n            s->ac_pred = 0;\n        if(s->pb_frame && get_bits1(&s->gb))\n            pb_mv_count = h263_get_modb(&s->gb, s->pb_frame, &cbpb);\n        cbpy = get_vlc2(&s->gb, ff_h263_cbpy_vlc.table, CBPY_VLC_BITS, 1);\n        if(cbpy<0){\n            av_log(s->avctx, AV_LOG_ERROR, \"I cbpy damaged at %d %d\\n\", s->mb_x, s->mb_y);\n        cbp = (cbpc & 3) | (cbpy << 2);\n        if (dquant) {\n            h263_decode_dquant(s);\n        pb_mv_count += !!s->pb_frame;\n    while(pb_mv_count--){\n        ff_h263_decode_motion(s, 0, 1);\n        ff_h263_decode_motion(s, 0, 1);\n    /* decode each block */\n    for (i = 0; i < 6; i++) {\n        if (h263_decode_block(s, block[i], i, cbp&32) < 0)\n            return -1;\n        cbp+=cbp;\n    if(s->pb_frame && h263_skip_b_part(s, cbpb) < 0)\n        return -1;\n    if(s->obmc && !s->mb_intra){\n        if(s->pict_type == AV_PICTURE_TYPE_P && s->mb_x+1<s->mb_width && s->mb_num_left != 1)\n            preview_obmc(s);\nend:\n        /* per-MB end of slice check */\n    {\n        int v= show_bits(&s->gb, 16);\n        if (get_bits_left(&s->gb) < 16) {\n            v >>= 16 - get_bits_left(&s->gb);\n        if(v==0)\n            return SLICE_END;\n    return SLICE_OK;", "idx": 23256}
{"project": "FFmpeg", "commit_id": "801dbf0269b1bb5bc70c550e971491e0aea9eb70", "target": 0, "func": "static av_cold void dcadec_flush(AVCodecContext *avctx)\n\n{\n\n    DCAContext *s = avctx->priv_data;\n\n\n\n    ff_dca_core_flush(&s->core);\n\n    ff_dca_xll_flush(&s->xll);\n\n    ff_dca_lbr_flush(&s->lbr);\n\n\n\n    s->core_residual_valid = 0;\n\n}\n", "idx": 23257}
{"project": "FFmpeg", "commit_id": "93c04e095dc37ebdab22174e88cfa91e24940866", "target": 0, "func": "static int amf_parse_object(AVFormatContext *s, AVStream *astream,\n\n                            AVStream *vstream, const char *key,\n\n                            int64_t max_pos, int depth)\n\n{\n\n    AVCodecContext *acodec, *vcodec;\n\n    FLVContext *flv = s->priv_data;\n\n    AVIOContext *ioc;\n\n    AMFDataType amf_type;\n\n    char str_val[256];\n\n    double num_val;\n\n\n\n    num_val  = 0;\n\n    ioc      = s->pb;\n\n    amf_type = avio_r8(ioc);\n\n\n\n    switch (amf_type) {\n\n    case AMF_DATA_TYPE_NUMBER:\n\n        num_val = av_int2double(avio_rb64(ioc));\n\n        break;\n\n    case AMF_DATA_TYPE_BOOL:\n\n        num_val = avio_r8(ioc);\n\n        break;\n\n    case AMF_DATA_TYPE_STRING:\n\n        if (amf_get_string(ioc, str_val, sizeof(str_val)) < 0)\n\n            return -1;\n\n        break;\n\n    case AMF_DATA_TYPE_OBJECT:\n\n        if ((vstream || astream) && key &&\n\n            !strcmp(KEYFRAMES_TAG, key) && depth == 1)\n\n            if (parse_keyframes_index(s, ioc, vstream ? vstream : astream,\n\n                                      max_pos) < 0)\n\n                return -1;\n\n\n\n        while (avio_tell(ioc) < max_pos - 2 &&\n\n               amf_get_string(ioc, str_val, sizeof(str_val)) > 0)\n\n            if (amf_parse_object(s, astream, vstream, str_val, max_pos,\n\n                                 depth + 1) < 0)\n\n                return -1;     // if we couldn't skip, bomb out.\n\n        if (avio_r8(ioc) != AMF_END_OF_OBJECT)\n\n            return -1;\n\n        break;\n\n    case AMF_DATA_TYPE_NULL:\n\n    case AMF_DATA_TYPE_UNDEFINED:\n\n    case AMF_DATA_TYPE_UNSUPPORTED:\n\n        break;     // these take up no additional space\n\n    case AMF_DATA_TYPE_MIXEDARRAY:\n\n        avio_skip(ioc, 4);     // skip 32-bit max array index\n\n        while (avio_tell(ioc) < max_pos - 2 &&\n\n               amf_get_string(ioc, str_val, sizeof(str_val)) > 0)\n\n            // this is the only case in which we would want a nested\n\n            // parse to not skip over the object\n\n            if (amf_parse_object(s, astream, vstream, str_val, max_pos,\n\n                                 depth + 1) < 0)\n\n                return -1;\n\n        if (avio_r8(ioc) != AMF_END_OF_OBJECT)\n\n            return -1;\n\n        break;\n\n    case AMF_DATA_TYPE_ARRAY:\n\n    {\n\n        unsigned int arraylen, i;\n\n\n\n        arraylen = avio_rb32(ioc);\n\n        for (i = 0; i < arraylen && avio_tell(ioc) < max_pos - 1; i++)\n\n            if (amf_parse_object(s, NULL, NULL, NULL, max_pos,\n\n                                 depth + 1) < 0)\n\n                return -1;      // if we couldn't skip, bomb out.\n\n    }\n\n    break;\n\n    case AMF_DATA_TYPE_DATE:\n\n        avio_skip(ioc, 8 + 2);  // timestamp (double) and UTC offset (int16)\n\n        break;\n\n    default:                    // unsupported type, we couldn't skip\n\n        return -1;\n\n    }\n\n\n\n    // only look for metadata values when we are not nested and key != NULL\n\n    if (depth == 1 && key) {\n\n        acodec = astream ? astream->codec : NULL;\n\n        vcodec = vstream ? vstream->codec : NULL;\n\n\n\n        if (amf_type == AMF_DATA_TYPE_NUMBER ||\n\n            amf_type == AMF_DATA_TYPE_BOOL) {\n\n            if (!strcmp(key, \"duration\"))\n\n                s->duration = num_val * AV_TIME_BASE;\n\n            else if (!strcmp(key, \"videodatarate\") && vcodec &&\n\n                     0 <= (int)(num_val * 1024.0))\n\n                vcodec->bit_rate = num_val * 1024.0;\n\n            else if (!strcmp(key, \"audiodatarate\") && acodec &&\n\n                     0 <= (int)(num_val * 1024.0))\n\n                acodec->bit_rate = num_val * 1024.0;\n\n            else if (!strcmp(key, \"datastream\")) {\n\n                AVStream *st = create_stream(s, AVMEDIA_TYPE_DATA);\n\n                if (!st)\n\n                    return AVERROR(ENOMEM);\n\n                st->codec->codec_id = AV_CODEC_ID_TEXT;\n\n            } else if (flv->trust_metadata) {\n\n                if (!strcmp(key, \"videocodecid\") && vcodec) {\n\n                    flv_set_video_codec(s, vstream, num_val, 0);\n\n                } else if (!strcmp(key, \"audiocodecid\") && acodec) {\n\n                    int id = ((int)num_val) << FLV_AUDIO_CODECID_OFFSET;\n\n                    flv_set_audio_codec(s, astream, acodec, id);\n\n                } else if (!strcmp(key, \"audiosamplerate\") && acodec) {\n\n                    acodec->sample_rate = num_val;\n\n                } else if (!strcmp(key, \"audiosamplesize\") && acodec) {\n\n                    acodec->bits_per_coded_sample = num_val;\n\n                } else if (!strcmp(key, \"stereo\") && acodec) {\n\n                    acodec->channels       = num_val + 1;\n\n                    acodec->channel_layout = acodec->channels == 2 ?\n\n                                             AV_CH_LAYOUT_STEREO :\n\n                                             AV_CH_LAYOUT_MONO;\n\n                } else if (!strcmp(key, \"width\") && vcodec) {\n\n                    vcodec->width = num_val;\n\n                } else if (!strcmp(key, \"height\") && vcodec) {\n\n                    vcodec->height = num_val;\n\n                }\n\n            }\n\n        }\n\n\n\n        if (!strcmp(key, \"duration\")        ||\n\n            !strcmp(key, \"filesize\")        ||\n\n            !strcmp(key, \"width\")           ||\n\n            !strcmp(key, \"height\")          ||\n\n            !strcmp(key, \"videodatarate\")   ||\n\n            !strcmp(key, \"framerate\")       ||\n\n            !strcmp(key, \"videocodecid\")    ||\n\n            !strcmp(key, \"audiodatarate\")   ||\n\n            !strcmp(key, \"audiosamplerate\") ||\n\n            !strcmp(key, \"audiosamplesize\") ||\n\n            !strcmp(key, \"stereo\")          ||\n\n            !strcmp(key, \"audiocodecid\")    ||\n\n            !strcmp(key, \"datastream\"))\n\n            return 0;\n\n\n\n        if (amf_type == AMF_DATA_TYPE_BOOL) {\n\n            av_strlcpy(str_val, num_val > 0 ? \"true\" : \"false\",\n\n                       sizeof(str_val));\n\n            av_dict_set(&s->metadata, key, str_val, 0);\n\n        } else if (amf_type == AMF_DATA_TYPE_NUMBER) {\n\n            snprintf(str_val, sizeof(str_val), \"%.f\", num_val);\n\n            av_dict_set(&s->metadata, key, str_val, 0);\n\n        } else if (amf_type == AMF_DATA_TYPE_STRING)\n\n            av_dict_set(&s->metadata, key, str_val, 0);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23258}
{"project": "FFmpeg", "commit_id": "92fabca427ff2d8fffa4bd4f09839d8d3822ef31", "target": 0, "func": "static void DEF(put, pixels16_x2)(uint8_t *block, const uint8_t *pixels, ptrdiff_t line_size, int h)\n\n{\n\n    MOVQ_BFE(mm6);\n\n    __asm__ volatile(\n\n        \"lea        (%3, %3), %%\"REG_a\" \\n\\t\"\n\n        \".p2align 3                     \\n\\t\"\n\n        \"1:                             \\n\\t\"\n\n        \"movq   (%1), %%mm0             \\n\\t\"\n\n        \"movq   1(%1), %%mm1            \\n\\t\"\n\n        \"movq   (%1, %3), %%mm2         \\n\\t\"\n\n        \"movq   1(%1, %3), %%mm3        \\n\\t\"\n\n        PAVGBP(%%mm0, %%mm1, %%mm4,   %%mm2, %%mm3, %%mm5)\n\n        \"movq   %%mm4, (%2)             \\n\\t\"\n\n        \"movq   %%mm5, (%2, %3)         \\n\\t\"\n\n        \"movq   8(%1), %%mm0            \\n\\t\"\n\n        \"movq   9(%1), %%mm1            \\n\\t\"\n\n        \"movq   8(%1, %3), %%mm2        \\n\\t\"\n\n        \"movq   9(%1, %3), %%mm3        \\n\\t\"\n\n        PAVGBP(%%mm0, %%mm1, %%mm4,   %%mm2, %%mm3, %%mm5)\n\n        \"movq   %%mm4, 8(%2)            \\n\\t\"\n\n        \"movq   %%mm5, 8(%2, %3)        \\n\\t\"\n\n        \"add    %%\"REG_a\", %1           \\n\\t\"\n\n        \"add    %%\"REG_a\", %2           \\n\\t\"\n\n        \"movq   (%1), %%mm0             \\n\\t\"\n\n        \"movq   1(%1), %%mm1            \\n\\t\"\n\n        \"movq   (%1, %3), %%mm2         \\n\\t\"\n\n        \"movq   1(%1, %3), %%mm3        \\n\\t\"\n\n        PAVGBP(%%mm0, %%mm1, %%mm4,   %%mm2, %%mm3, %%mm5)\n\n        \"movq   %%mm4, (%2)             \\n\\t\"\n\n        \"movq   %%mm5, (%2, %3)         \\n\\t\"\n\n        \"movq   8(%1), %%mm0            \\n\\t\"\n\n        \"movq   9(%1), %%mm1            \\n\\t\"\n\n        \"movq   8(%1, %3), %%mm2        \\n\\t\"\n\n        \"movq   9(%1, %3), %%mm3        \\n\\t\"\n\n        PAVGBP(%%mm0, %%mm1, %%mm4,   %%mm2, %%mm3, %%mm5)\n\n        \"movq   %%mm4, 8(%2)            \\n\\t\"\n\n        \"movq   %%mm5, 8(%2, %3)        \\n\\t\"\n\n        \"add    %%\"REG_a\", %1           \\n\\t\"\n\n        \"add    %%\"REG_a\", %2           \\n\\t\"\n\n        \"subl   $4, %0                  \\n\\t\"\n\n        \"jnz    1b                      \\n\\t\"\n\n        :\"+g\"(h), \"+S\"(pixels), \"+D\"(block)\n\n        :\"r\"((x86_reg)line_size)\n\n        :REG_a, \"memory\");\n\n}\n", "idx": 23259}
{"project": "FFmpeg", "commit_id": "0c22311b56e66115675c4a96e4c78547886a4171", "target": 0, "func": "static int av_transcode(AVFormatContext **output_files,\n\n                        int nb_output_files,\n\n                        AVFormatContext **input_files,\n\n                        int nb_input_files,\n\n                        AVStreamMap *stream_maps, int nb_stream_maps)\n\n{\n\n    int ret = 0, i, j, k, n, nb_istreams = 0, nb_ostreams = 0;\n\n    AVFormatContext *is, *os;\n\n    AVCodecContext *codec, *icodec;\n\n    AVOutputStream *ost, **ost_table = NULL;\n\n    AVInputStream *ist, **ist_table = NULL;\n\n    AVInputFile *file_table;\n\n    char error[1024];\n\n    int key;\n\n    int want_sdp = 1;\n\n    uint8_t no_packet[MAX_FILES]={0};\n\n    int no_packet_count=0;\n\n\n\n    file_table= av_mallocz(nb_input_files * sizeof(AVInputFile));\n\n    if (!file_table)\n\n        goto fail;\n\n\n\n    /* input stream init */\n\n    j = 0;\n\n    for(i=0;i<nb_input_files;i++) {\n\n        is = input_files[i];\n\n        file_table[i].ist_index = j;\n\n        file_table[i].nb_streams = is->nb_streams;\n\n        j += is->nb_streams;\n\n    }\n\n    nb_istreams = j;\n\n\n\n    ist_table = av_mallocz(nb_istreams * sizeof(AVInputStream *));\n\n    if (!ist_table)\n\n        goto fail;\n\n\n\n    for(i=0;i<nb_istreams;i++) {\n\n        ist = av_mallocz(sizeof(AVInputStream));\n\n        if (!ist)\n\n            goto fail;\n\n        ist_table[i] = ist;\n\n    }\n\n    j = 0;\n\n    for(i=0;i<nb_input_files;i++) {\n\n        is = input_files[i];\n\n        for(k=0;k<is->nb_streams;k++) {\n\n            ist = ist_table[j++];\n\n            ist->st = is->streams[k];\n\n            ist->file_index = i;\n\n            ist->index = k;\n\n            ist->discard = 1; /* the stream is discarded by default\n\n                                 (changed later) */\n\n\n\n            if (rate_emu) {\n\n                ist->start = av_gettime();\n\n            }\n\n        }\n\n    }\n\n\n\n    /* output stream init */\n\n    nb_ostreams = 0;\n\n    for(i=0;i<nb_output_files;i++) {\n\n        os = output_files[i];\n\n        if (!os->nb_streams) {\n\n            dump_format(output_files[i], i, output_files[i]->filename, 1);\n\n            fprintf(stderr, \"Output file #%d does not contain any stream\\n\", i);\n\n            av_exit(1);\n\n        }\n\n        nb_ostreams += os->nb_streams;\n\n    }\n\n    if (nb_stream_maps > 0 && nb_stream_maps != nb_ostreams) {\n\n        fprintf(stderr, \"Number of stream maps must match number of output streams\\n\");\n\n        av_exit(1);\n\n    }\n\n\n\n    /* Sanity check the mapping args -- do the input files & streams exist? */\n\n    for(i=0;i<nb_stream_maps;i++) {\n\n        int fi = stream_maps[i].file_index;\n\n        int si = stream_maps[i].stream_index;\n\n\n\n        if (fi < 0 || fi > nb_input_files - 1 ||\n\n            si < 0 || si > file_table[fi].nb_streams - 1) {\n\n            fprintf(stderr,\"Could not find input stream #%d.%d\\n\", fi, si);\n\n            av_exit(1);\n\n        }\n\n        fi = stream_maps[i].sync_file_index;\n\n        si = stream_maps[i].sync_stream_index;\n\n        if (fi < 0 || fi > nb_input_files - 1 ||\n\n            si < 0 || si > file_table[fi].nb_streams - 1) {\n\n            fprintf(stderr,\"Could not find sync stream #%d.%d\\n\", fi, si);\n\n            av_exit(1);\n\n        }\n\n    }\n\n\n\n    ost_table = av_mallocz(sizeof(AVOutputStream *) * nb_ostreams);\n\n    if (!ost_table)\n\n        goto fail;\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        ost = av_mallocz(sizeof(AVOutputStream));\n\n        if (!ost)\n\n            goto fail;\n\n        ost_table[i] = ost;\n\n    }\n\n\n\n    n = 0;\n\n    for(k=0;k<nb_output_files;k++) {\n\n        os = output_files[k];\n\n        for(i=0;i<os->nb_streams;i++,n++) {\n\n            int found;\n\n            ost = ost_table[n];\n\n            ost->file_index = k;\n\n            ost->index = i;\n\n            ost->st = os->streams[i];\n\n            if (nb_stream_maps > 0) {\n\n                ost->source_index = file_table[stream_maps[n].file_index].ist_index +\n\n                    stream_maps[n].stream_index;\n\n\n\n                /* Sanity check that the stream types match */\n\n                if (ist_table[ost->source_index]->st->codec->codec_type != ost->st->codec->codec_type) {\n\n                    int i= ost->file_index;\n\n                    dump_format(output_files[i], i, output_files[i]->filename, 1);\n\n                    fprintf(stderr, \"Codec type mismatch for mapping #%d.%d -> #%d.%d\\n\",\n\n                        stream_maps[n].file_index, stream_maps[n].stream_index,\n\n                        ost->file_index, ost->index);\n\n                    av_exit(1);\n\n                }\n\n\n\n            } else {\n\n                int best_nb_frames=-1;\n\n                    /* get corresponding input stream index : we select the first one with the right type */\n\n                    found = 0;\n\n                    for(j=0;j<nb_istreams;j++) {\n\n                        int skip=0;\n\n                        ist = ist_table[j];\n\n                        if(opt_programid){\n\n                            int pi,si;\n\n                            AVFormatContext *f= input_files[ ist->file_index ];\n\n                            skip=1;\n\n                            for(pi=0; pi<f->nb_programs; pi++){\n\n                                AVProgram *p= f->programs[pi];\n\n                                if(p->id == opt_programid)\n\n                                    for(si=0; si<p->nb_stream_indexes; si++){\n\n                                        if(f->streams[ p->stream_index[si] ] == ist->st)\n\n                                            skip=0;\n\n                                    }\n\n                            }\n\n                        }\n\n                        if (ist->discard && ist->st->discard != AVDISCARD_ALL && !skip &&\n\n                            ist->st->codec->codec_type == ost->st->codec->codec_type) {\n\n                            if(best_nb_frames < ist->st->codec_info_nb_frames){\n\n                                best_nb_frames= ist->st->codec_info_nb_frames;\n\n                                ost->source_index = j;\n\n                                found = 1;\n\n                            }\n\n                        }\n\n                    }\n\n\n\n                if (!found) {\n\n                    if(! opt_programid) {\n\n                        /* try again and reuse existing stream */\n\n                        for(j=0;j<nb_istreams;j++) {\n\n                            ist = ist_table[j];\n\n                            if (   ist->st->codec->codec_type == ost->st->codec->codec_type\n\n                                && ist->st->discard != AVDISCARD_ALL) {\n\n                                ost->source_index = j;\n\n                                found = 1;\n\n                            }\n\n                        }\n\n                    }\n\n                    if (!found) {\n\n                        int i= ost->file_index;\n\n                        dump_format(output_files[i], i, output_files[i]->filename, 1);\n\n                        fprintf(stderr, \"Could not find input stream matching output stream #%d.%d\\n\",\n\n                                ost->file_index, ost->index);\n\n                        av_exit(1);\n\n                    }\n\n                }\n\n            }\n\n            ist = ist_table[ost->source_index];\n\n            ist->discard = 0;\n\n            ost->sync_ist = (nb_stream_maps > 0) ?\n\n                ist_table[file_table[stream_maps[n].sync_file_index].ist_index +\n\n                         stream_maps[n].sync_stream_index] : ist;\n\n        }\n\n    }\n\n\n\n    /* for each output stream, we compute the right encoding parameters */\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        AVMetadataTag *t = NULL;\n\n        ost = ost_table[i];\n\n        os = output_files[ost->file_index];\n\n        ist = ist_table[ost->source_index];\n\n\n\n        codec = ost->st->codec;\n\n        icodec = ist->st->codec;\n\n\n\n        while ((t = av_metadata_get(ist->st->metadata, \"\", t, AV_METADATA_IGNORE_SUFFIX))) {\n\n            av_metadata_set2(&ost->st->metadata, t->key, t->value, AV_METADATA_DONT_OVERWRITE);\n\n        }\n\n\n\n        ost->st->disposition = ist->st->disposition;\n\n        codec->bits_per_raw_sample= icodec->bits_per_raw_sample;\n\n        codec->chroma_sample_location = icodec->chroma_sample_location;\n\n\n\n        if (ost->st->stream_copy) {\n\n            /* if stream_copy is selected, no need to decode or encode */\n\n            codec->codec_id = icodec->codec_id;\n\n            codec->codec_type = icodec->codec_type;\n\n\n\n            if(!codec->codec_tag){\n\n                if(   !os->oformat->codec_tag\n\n                   || av_codec_get_id (os->oformat->codec_tag, icodec->codec_tag) == codec->codec_id\n\n                   || av_codec_get_tag(os->oformat->codec_tag, icodec->codec_id) <= 0)\n\n                    codec->codec_tag = icodec->codec_tag;\n\n            }\n\n\n\n            codec->bit_rate = icodec->bit_rate;\n\n            codec->extradata= icodec->extradata;\n\n            codec->extradata_size= icodec->extradata_size;\n\n            if(av_q2d(icodec->time_base)*icodec->ticks_per_frame > av_q2d(ist->st->time_base) && av_q2d(ist->st->time_base) < 1.0/1000){\n\n                codec->time_base = icodec->time_base;\n\n                codec->time_base.num *= icodec->ticks_per_frame;\n\n            }else\n\n                codec->time_base = ist->st->time_base;\n\n            switch(codec->codec_type) {\n\n            case AVMEDIA_TYPE_AUDIO:\n\n                if(audio_volume != 256) {\n\n                    fprintf(stderr,\"-acodec copy and -vol are incompatible (frames are not decoded)\\n\");\n\n                    av_exit(1);\n\n                }\n\n                codec->channel_layout = icodec->channel_layout;\n\n                codec->sample_rate = icodec->sample_rate;\n\n                codec->channels = icodec->channels;\n\n                codec->frame_size = icodec->frame_size;\n\n                codec->block_align= icodec->block_align;\n\n                if(codec->block_align == 1 && codec->codec_id == CODEC_ID_MP3)\n\n                    codec->block_align= 0;\n\n                if(codec->codec_id == CODEC_ID_AC3)\n\n                    codec->block_align= 0;\n\n                break;\n\n            case AVMEDIA_TYPE_VIDEO:\n\n                codec->pix_fmt = icodec->pix_fmt;\n\n                codec->width = icodec->width;\n\n                codec->height = icodec->height;\n\n                codec->has_b_frames = icodec->has_b_frames;\n\n                break;\n\n            case AVMEDIA_TYPE_SUBTITLE:\n\n                codec->width = icodec->width;\n\n                codec->height = icodec->height;\n\n                break;\n\n            default:\n\n                abort();\n\n            }\n\n        } else {\n\n            switch(codec->codec_type) {\n\n            case AVMEDIA_TYPE_AUDIO:\n\n                ost->fifo= av_fifo_alloc(1024);\n\n                if(!ost->fifo)\n\n                    goto fail;\n\n                ost->reformat_pair = MAKE_SFMT_PAIR(SAMPLE_FMT_NONE,SAMPLE_FMT_NONE);\n\n                ost->audio_resample = codec->sample_rate != icodec->sample_rate || audio_sync_method > 1;\n\n                icodec->request_channels = codec->channels;\n\n                ist->decoding_needed = 1;\n\n                ost->encoding_needed = 1;\n\n                break;\n\n            case AVMEDIA_TYPE_VIDEO:\n\n                if (ost->st->codec->pix_fmt == PIX_FMT_NONE) {\n\n                    fprintf(stderr, \"Video pixel format is unknown, stream cannot be encoded\\n\");\n\n                    av_exit(1);\n\n                }\n\n                ost->video_crop = ((frame_leftBand + frame_rightBand + frame_topBand + frame_bottomBand) != 0);\n\n                ost->video_pad = ((frame_padleft + frame_padright + frame_padtop + frame_padbottom) != 0);\n\n                ost->video_resample = ((codec->width != icodec->width -\n\n                                (frame_leftBand + frame_rightBand) +\n\n                                (frame_padleft + frame_padright)) ||\n\n                        (codec->height != icodec->height -\n\n                                (frame_topBand  + frame_bottomBand) +\n\n                                (frame_padtop + frame_padbottom)) ||\n\n                        (codec->pix_fmt != icodec->pix_fmt));\n\n                if (ost->video_crop) {\n\n                    ost->topBand    = ost->original_topBand    = frame_topBand;\n\n                    ost->bottomBand = ost->original_bottomBand = frame_bottomBand;\n\n                    ost->leftBand   = ost->original_leftBand   = frame_leftBand;\n\n                    ost->rightBand  = ost->original_rightBand  = frame_rightBand;\n\n                }\n\n                if (ost->video_pad) {\n\n                    ost->padtop = frame_padtop;\n\n                    ost->padleft = frame_padleft;\n\n                    ost->padbottom = frame_padbottom;\n\n                    ost->padright = frame_padright;\n\n                    if (!ost->video_resample) {\n\n                        avcodec_get_frame_defaults(&ost->pict_tmp);\n\n                        if(avpicture_alloc((AVPicture*)&ost->pict_tmp, codec->pix_fmt,\n\n                                         codec->width, codec->height))\n\n                            goto fail;\n\n                    }\n\n                }\n\n                if (ost->video_resample) {\n\n                    avcodec_get_frame_defaults(&ost->pict_tmp);\n\n                    if(avpicture_alloc((AVPicture*)&ost->pict_tmp, codec->pix_fmt,\n\n                                         codec->width, codec->height)) {\n\n                        fprintf(stderr, \"Cannot allocate temp picture, check pix fmt\\n\");\n\n                        av_exit(1);\n\n                    }\n\n                    sws_flags = av_get_int(sws_opts, \"sws_flags\", NULL);\n\n                    ost->img_resample_ctx = sws_getContext(\n\n                            icodec->width - (frame_leftBand + frame_rightBand),\n\n                            icodec->height - (frame_topBand + frame_bottomBand),\n\n                            icodec->pix_fmt,\n\n                            codec->width - (frame_padleft + frame_padright),\n\n                            codec->height - (frame_padtop + frame_padbottom),\n\n                            codec->pix_fmt,\n\n                            sws_flags, NULL, NULL, NULL);\n\n                    if (ost->img_resample_ctx == NULL) {\n\n                        fprintf(stderr, \"Cannot get resampling context\\n\");\n\n                        av_exit(1);\n\n                    }\n\n\n\n#if !CONFIG_AVFILTER\n\n                    ost->original_height = icodec->height;\n\n                    ost->original_width  = icodec->width;\n\n#endif\n\n                    codec->bits_per_raw_sample= 0;\n\n                }\n\n                ost->resample_height = icodec->height - (frame_topBand  + frame_bottomBand);\n\n                ost->resample_width  = icodec->width  - (frame_leftBand + frame_rightBand);\n\n                ost->resample_pix_fmt= icodec->pix_fmt;\n\n                ost->encoding_needed = 1;\n\n                ist->decoding_needed = 1;\n\n\n\n#if CONFIG_AVFILTER\n\n                if (configure_filters(ist, ost)) {\n\n                    fprintf(stderr, \"Error opening filters!\\n\");\n\n                    exit(1);\n\n                }\n\n#endif\n\n                break;\n\n            case AVMEDIA_TYPE_SUBTITLE:\n\n                ost->encoding_needed = 1;\n\n                ist->decoding_needed = 1;\n\n                break;\n\n            default:\n\n                abort();\n\n                break;\n\n            }\n\n            /* two pass mode */\n\n            if (ost->encoding_needed &&\n\n                (codec->flags & (CODEC_FLAG_PASS1 | CODEC_FLAG_PASS2))) {\n\n                char logfilename[1024];\n\n                FILE *f;\n\n\n\n                snprintf(logfilename, sizeof(logfilename), \"%s-%d.log\",\n\n                         pass_logfilename_prefix ? pass_logfilename_prefix : DEFAULT_PASS_LOGFILENAME_PREFIX,\n\n                         i);\n\n                if (codec->flags & CODEC_FLAG_PASS1) {\n\n                    f = fopen(logfilename, \"w\");\n\n                    if (!f) {\n\n                        fprintf(stderr, \"Cannot write log file '%s' for pass-1 encoding: %s\\n\", logfilename, strerror(errno));\n\n                        av_exit(1);\n\n                    }\n\n                    ost->logfile = f;\n\n                } else {\n\n                    char  *logbuffer;\n\n                    size_t logbuffer_size;\n\n                    if (read_file(logfilename, &logbuffer, &logbuffer_size) < 0) {\n\n                        fprintf(stderr, \"Error reading log file '%s' for pass-2 encoding\\n\", logfilename);\n\n                        av_exit(1);\n\n                    }\n\n                    codec->stats_in = logbuffer;\n\n                }\n\n            }\n\n        }\n\n        if(codec->codec_type == AVMEDIA_TYPE_VIDEO){\n\n            int size= codec->width * codec->height;\n\n            bit_buffer_size= FFMAX(bit_buffer_size, 6*size + 200);\n\n        }\n\n    }\n\n\n\n    if (!bit_buffer)\n\n        bit_buffer = av_malloc(bit_buffer_size);\n\n    if (!bit_buffer) {\n\n        fprintf(stderr, \"Cannot allocate %d bytes output buffer\\n\",\n\n                bit_buffer_size);\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    /* open each encoder */\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        ost = ost_table[i];\n\n        if (ost->encoding_needed) {\n\n            AVCodec *codec = output_codecs[i];\n\n            if (!codec)\n\n                codec = avcodec_find_encoder(ost->st->codec->codec_id);\n\n            if (!codec) {\n\n                snprintf(error, sizeof(error), \"Encoder (codec id %d) not found for output stream #%d.%d\",\n\n                         ost->st->codec->codec_id, ost->file_index, ost->index);\n\n                ret = AVERROR(EINVAL);\n\n                goto dump_format;\n\n            }\n\n            if (avcodec_open(ost->st->codec, codec) < 0) {\n\n                snprintf(error, sizeof(error), \"Error while opening encoder for output stream #%d.%d - maybe incorrect parameters such as bit_rate, rate, width or height\",\n\n                        ost->file_index, ost->index);\n\n                ret = AVERROR(EINVAL);\n\n                goto dump_format;\n\n            }\n\n            extra_size += ost->st->codec->extradata_size;\n\n        }\n\n    }\n\n\n\n    /* open each decoder */\n\n    for(i=0;i<nb_istreams;i++) {\n\n        ist = ist_table[i];\n\n        if (ist->decoding_needed) {\n\n            AVCodec *codec = input_codecs[i];\n\n            if (!codec)\n\n                codec = avcodec_find_decoder(ist->st->codec->codec_id);\n\n            if (!codec) {\n\n                snprintf(error, sizeof(error), \"Decoder (codec id %d) not found for input stream #%d.%d\",\n\n                        ist->st->codec->codec_id, ist->file_index, ist->index);\n\n                ret = AVERROR(EINVAL);\n\n                goto dump_format;\n\n            }\n\n            if (avcodec_open(ist->st->codec, codec) < 0) {\n\n                snprintf(error, sizeof(error), \"Error while opening decoder for input stream #%d.%d\",\n\n                        ist->file_index, ist->index);\n\n                ret = AVERROR(EINVAL);\n\n                goto dump_format;\n\n            }\n\n            //if (ist->st->codec->codec_type == AVMEDIA_TYPE_VIDEO)\n\n            //    ist->st->codec->flags |= CODEC_FLAG_REPEAT_FIELD;\n\n        }\n\n    }\n\n\n\n    /* init pts */\n\n    for(i=0;i<nb_istreams;i++) {\n\n        AVStream *st;\n\n        ist = ist_table[i];\n\n        st= ist->st;\n\n        ist->pts = st->avg_frame_rate.num ? - st->codec->has_b_frames*AV_TIME_BASE / av_q2d(st->avg_frame_rate) : 0;\n\n        ist->next_pts = AV_NOPTS_VALUE;\n\n        ist->is_start = 1;\n\n    }\n\n\n\n    /* set meta data information from input file if required */\n\n    for (i=0;i<nb_meta_data_maps;i++) {\n\n        AVFormatContext *out_file;\n\n        AVFormatContext *in_file;\n\n        AVMetadataTag *mtag;\n\n\n\n        int out_file_index = meta_data_maps[i].out_file;\n\n        int in_file_index = meta_data_maps[i].in_file;\n\n        if (out_file_index < 0 || out_file_index >= nb_output_files) {\n\n            snprintf(error, sizeof(error), \"Invalid output file index %d map_meta_data(%d,%d)\",\n\n                     out_file_index, out_file_index, in_file_index);\n\n            ret = AVERROR(EINVAL);\n\n            goto dump_format;\n\n        }\n\n        if (in_file_index < 0 || in_file_index >= nb_input_files) {\n\n            snprintf(error, sizeof(error), \"Invalid input file index %d map_meta_data(%d,%d)\",\n\n                     in_file_index, out_file_index, in_file_index);\n\n            ret = AVERROR(EINVAL);\n\n            goto dump_format;\n\n        }\n\n\n\n        out_file = output_files[out_file_index];\n\n        in_file = input_files[in_file_index];\n\n\n\n\n\n        mtag=NULL;\n\n        while((mtag=av_metadata_get(in_file->metadata, \"\", mtag, AV_METADATA_IGNORE_SUFFIX)))\n\n            av_metadata_set2(&out_file->metadata, mtag->key, mtag->value, AV_METADATA_DONT_OVERWRITE);\n\n        av_metadata_conv(out_file, out_file->oformat->metadata_conv,\n\n                                    in_file->iformat->metadata_conv);\n\n    }\n\n\n\n    /* copy chapters from the first input file that has them*/\n\n    for (i = 0; i < nb_input_files; i++) {\n\n        if (!input_files[i]->nb_chapters)\n\n            continue;\n\n\n\n        for (j = 0; j < nb_output_files; j++)\n\n            if ((ret = copy_chapters(i, j)) < 0)\n\n                goto dump_format;\n\n    }\n\n\n\n    /* open files and write file headers */\n\n    for(i=0;i<nb_output_files;i++) {\n\n        os = output_files[i];\n\n        if (av_write_header(os) < 0) {\n\n            snprintf(error, sizeof(error), \"Could not write header for output file #%d (incorrect codec parameters ?)\", i);\n\n            ret = AVERROR(EINVAL);\n\n            goto dump_format;\n\n        }\n\n        if (strcmp(output_files[i]->oformat->name, \"rtp\")) {\n\n            want_sdp = 0;\n\n        }\n\n    }\n\n\n\n dump_format:\n\n    /* dump the file output parameters - cannot be done before in case\n\n       of stream copy */\n\n    for(i=0;i<nb_output_files;i++) {\n\n        dump_format(output_files[i], i, output_files[i]->filename, 1);\n\n    }\n\n\n\n    /* dump the stream mapping */\n\n    if (verbose >= 0) {\n\n        fprintf(stderr, \"Stream mapping:\\n\");\n\n        for(i=0;i<nb_ostreams;i++) {\n\n            ost = ost_table[i];\n\n            fprintf(stderr, \"  Stream #%d.%d -> #%d.%d\",\n\n                    ist_table[ost->source_index]->file_index,\n\n                    ist_table[ost->source_index]->index,\n\n                    ost->file_index,\n\n                    ost->index);\n\n            if (ost->sync_ist != ist_table[ost->source_index])\n\n                fprintf(stderr, \" [sync #%d.%d]\",\n\n                        ost->sync_ist->file_index,\n\n                        ost->sync_ist->index);\n\n            fprintf(stderr, \"\\n\");\n\n        }\n\n    }\n\n\n\n    if (ret) {\n\n        fprintf(stderr, \"%s\\n\", error);\n\n        goto fail;\n\n    }\n\n\n\n    if (want_sdp) {\n\n        print_sdp(output_files, nb_output_files);\n\n    }\n\n\n\n    if (!using_stdin && verbose >= 0) {\n\n        fprintf(stderr, \"Press [q] to stop encoding\\n\");\n\n        url_set_interrupt_cb(decode_interrupt_cb);\n\n    }\n\n    term_init();\n\n\n\n    timer_start = av_gettime();\n\n\n\n    for(; received_sigterm == 0;) {\n\n        int file_index, ist_index;\n\n        AVPacket pkt;\n\n        double ipts_min;\n\n        double opts_min;\n\n\n\n    redo:\n\n        ipts_min= 1e100;\n\n        opts_min= 1e100;\n\n        /* if 'q' pressed, exits */\n\n        if (!using_stdin) {\n\n            if (q_pressed)\n\n                break;\n\n            /* read_key() returns 0 on EOF */\n\n            key = read_key();\n\n            if (key == 'q')\n\n                break;\n\n        }\n\n\n\n        /* select the stream that we must read now by looking at the\n\n           smallest output pts */\n\n        file_index = -1;\n\n        for(i=0;i<nb_ostreams;i++) {\n\n            double ipts, opts;\n\n            ost = ost_table[i];\n\n            os = output_files[ost->file_index];\n\n            ist = ist_table[ost->source_index];\n\n            if(ist->is_past_recording_time || no_packet[ist->file_index])\n\n                continue;\n\n                opts = ost->st->pts.val * av_q2d(ost->st->time_base);\n\n            ipts = (double)ist->pts;\n\n            if (!file_table[ist->file_index].eof_reached){\n\n                if(ipts < ipts_min) {\n\n                    ipts_min = ipts;\n\n                    if(input_sync ) file_index = ist->file_index;\n\n                }\n\n                if(opts < opts_min) {\n\n                    opts_min = opts;\n\n                    if(!input_sync) file_index = ist->file_index;\n\n                }\n\n            }\n\n            if(ost->frame_number >= max_frames[ost->st->codec->codec_type]){\n\n                file_index= -1;\n\n                break;\n\n            }\n\n        }\n\n        /* if none, if is finished */\n\n        if (file_index < 0) {\n\n            if(no_packet_count){\n\n                no_packet_count=0;\n\n                memset(no_packet, 0, sizeof(no_packet));\n\n                usleep(10000);\n\n                continue;\n\n            }\n\n            break;\n\n        }\n\n\n\n        /* finish if limit size exhausted */\n\n        if (limit_filesize != 0 && limit_filesize < url_ftell(output_files[0]->pb))\n\n            break;\n\n\n\n        /* read a frame from it and output it in the fifo */\n\n        is = input_files[file_index];\n\n        ret= av_read_frame(is, &pkt);\n\n        if(ret == AVERROR(EAGAIN)){\n\n            no_packet[file_index]=1;\n\n            no_packet_count++;\n\n            continue;\n\n        }\n\n        if (ret < 0) {\n\n            file_table[file_index].eof_reached = 1;\n\n            if (opt_shortest)\n\n                break;\n\n            else\n\n                continue;\n\n        }\n\n\n\n        no_packet_count=0;\n\n        memset(no_packet, 0, sizeof(no_packet));\n\n\n\n        if (do_pkt_dump) {\n\n            av_pkt_dump_log(NULL, AV_LOG_DEBUG, &pkt, do_hex_dump);\n\n        }\n\n        /* the following test is needed in case new streams appear\n\n           dynamically in stream : we ignore them */\n\n        if (pkt.stream_index >= file_table[file_index].nb_streams)\n\n            goto discard_packet;\n\n        ist_index = file_table[file_index].ist_index + pkt.stream_index;\n\n        ist = ist_table[ist_index];\n\n        if (ist->discard)\n\n            goto discard_packet;\n\n\n\n        if (pkt.dts != AV_NOPTS_VALUE)\n\n            pkt.dts += av_rescale_q(input_files_ts_offset[ist->file_index], AV_TIME_BASE_Q, ist->st->time_base);\n\n        if (pkt.pts != AV_NOPTS_VALUE)\n\n            pkt.pts += av_rescale_q(input_files_ts_offset[ist->file_index], AV_TIME_BASE_Q, ist->st->time_base);\n\n\n\n        if(input_files_ts_scale[file_index][pkt.stream_index]){\n\n            if(pkt.pts != AV_NOPTS_VALUE)\n\n                pkt.pts *= input_files_ts_scale[file_index][pkt.stream_index];\n\n            if(pkt.dts != AV_NOPTS_VALUE)\n\n                pkt.dts *= input_files_ts_scale[file_index][pkt.stream_index];\n\n        }\n\n\n\n//        fprintf(stderr, \"next:%\"PRId64\" dts:%\"PRId64\" off:%\"PRId64\" %d\\n\", ist->next_pts, pkt.dts, input_files_ts_offset[ist->file_index], ist->st->codec->codec_type);\n\n        if (pkt.dts != AV_NOPTS_VALUE && ist->next_pts != AV_NOPTS_VALUE\n\n            && (is->iformat->flags & AVFMT_TS_DISCONT)) {\n\n            int64_t pkt_dts= av_rescale_q(pkt.dts, ist->st->time_base, AV_TIME_BASE_Q);\n\n            int64_t delta= pkt_dts - ist->next_pts;\n\n            if((FFABS(delta) > 1LL*dts_delta_threshold*AV_TIME_BASE || pkt_dts+1<ist->pts)&& !copy_ts){\n\n                input_files_ts_offset[ist->file_index]-= delta;\n\n                if (verbose > 2)\n\n                    fprintf(stderr, \"timestamp discontinuity %\"PRId64\", new offset= %\"PRId64\"\\n\", delta, input_files_ts_offset[ist->file_index]);\n\n                pkt.dts-= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);\n\n                if(pkt.pts != AV_NOPTS_VALUE)\n\n                    pkt.pts-= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);\n\n            }\n\n        }\n\n\n\n        /* finish if recording time exhausted */\n\n        if (recording_time != INT64_MAX &&\n\n            av_compare_ts(pkt.pts, ist->st->time_base, recording_time + start_time, (AVRational){1, 1000000}) >= 0) {\n\n            ist->is_past_recording_time = 1;\n\n            goto discard_packet;\n\n        }\n\n\n\n        //fprintf(stderr,\"read #%d.%d size=%d\\n\", ist->file_index, ist->index, pkt.size);\n\n        if (output_packet(ist, ist_index, ost_table, nb_ostreams, &pkt) < 0) {\n\n\n\n            if (verbose >= 0)\n\n                fprintf(stderr, \"Error while decoding stream #%d.%d\\n\",\n\n                        ist->file_index, ist->index);\n\n            if (exit_on_error)\n\n                av_exit(1);\n\n            av_free_packet(&pkt);\n\n            goto redo;\n\n        }\n\n\n\n    discard_packet:\n\n        av_free_packet(&pkt);\n\n\n\n        /* dump report by using the output first video and audio streams */\n\n        print_report(output_files, ost_table, nb_ostreams, 0);\n\n    }\n\n\n\n    /* at the end of stream, we must flush the decoder buffers */\n\n    for(i=0;i<nb_istreams;i++) {\n\n        ist = ist_table[i];\n\n        if (ist->decoding_needed) {\n\n            output_packet(ist, i, ost_table, nb_ostreams, NULL);\n\n        }\n\n    }\n\n\n\n    term_exit();\n\n\n\n    /* write the trailer if needed and close file */\n\n    for(i=0;i<nb_output_files;i++) {\n\n        os = output_files[i];\n\n        av_write_trailer(os);\n\n    }\n\n\n\n    /* dump report by using the first video and audio streams */\n\n    print_report(output_files, ost_table, nb_ostreams, 1);\n\n\n\n    /* close each encoder */\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        ost = ost_table[i];\n\n        if (ost->encoding_needed) {\n\n            av_freep(&ost->st->codec->stats_in);\n\n            avcodec_close(ost->st->codec);\n\n        }\n\n    }\n\n\n\n    /* close each decoder */\n\n    for(i=0;i<nb_istreams;i++) {\n\n        ist = ist_table[i];\n\n        if (ist->decoding_needed) {\n\n            avcodec_close(ist->st->codec);\n\n        }\n\n    }\n\n#if CONFIG_AVFILTER\n\n    if (filt_graph_all) {\n\n        avfilter_graph_destroy(filt_graph_all);\n\n        av_freep(&filt_graph_all);\n\n    }\n\n#endif\n\n\n\n    /* finished ! */\n\n    ret = 0;\n\n\n\n fail:\n\n    av_freep(&bit_buffer);\n\n    av_free(file_table);\n\n\n\n    if (ist_table) {\n\n        for(i=0;i<nb_istreams;i++) {\n\n            ist = ist_table[i];\n\n            av_free(ist);\n\n        }\n\n        av_free(ist_table);\n\n    }\n\n    if (ost_table) {\n\n        for(i=0;i<nb_ostreams;i++) {\n\n            ost = ost_table[i];\n\n            if (ost) {\n\n                if (ost->logfile) {\n\n                    fclose(ost->logfile);\n\n                    ost->logfile = NULL;\n\n                }\n\n                av_fifo_free(ost->fifo); /* works even if fifo is not\n\n                                             initialized but set to zero */\n\n                av_free(ost->pict_tmp.data[0]);\n\n                if (ost->video_resample)\n\n                    sws_freeContext(ost->img_resample_ctx);\n\n                if (ost->resample)\n\n                    audio_resample_close(ost->resample);\n\n                if (ost->reformat_ctx)\n\n                    av_audio_convert_free(ost->reformat_ctx);\n\n                av_free(ost);\n\n            }\n\n        }\n\n        av_free(ost_table);\n\n    }\n\n    return ret;\n\n}\n", "idx": 23260}
{"project": "FFmpeg", "commit_id": "955aec3c7c7be39b659197e1ec379a09f2b7c41c", "target": 0, "func": "static int check(AVIOContext *pb, int64_t pos, int64_t *out_pos)\n\n{\n\n    MPADecodeHeader mh = { 0 };\n\n    int i;\n\n    uint32_t header;\n\n    int64_t off = 0;\n\n\n\n\n\n    for (i = 0; i < SEEK_PACKETS; i++) {\n\n        off = avio_seek(pb, pos + mh.frame_size, SEEK_SET);\n\n        if (off < 0)\n\n            break;\n\n\n\n        header = avio_rb32(pb);\n\n\n\n        if (ff_mpa_check_header(header) < 0 ||\n\n            avpriv_mpegaudio_decode_header(&mh, header))\n\n            break;\n\n        out_pos[i] = off;\n\n    }\n\n\n\n    return i;\n\n}\n", "idx": 23261}
{"project": "FFmpeg", "commit_id": "fd2982a0a01942091b2f08e17486ff4562f675a6", "target": 0, "func": "int av_read_play(AVFormatContext *s)\n\n{\n\n    if (s->iformat->read_play)\n\n        return s->iformat->read_play(s);\n\n    if (s->pb && s->pb->read_pause)\n\n        return av_url_read_fpause(s->pb, 0);\n\n    return AVERROR(ENOSYS);\n\n}\n", "idx": 23262}
{"project": "FFmpeg", "commit_id": "46911c7ab803607fd9285927ed23426a9d297723", "target": 0, "func": "static int mpegts_write_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    AVStream *st = s->streams[pkt->stream_index];\n\n    int size= pkt->size;\n\n    uint8_t *buf= pkt->data;\n\n    MpegTSWriteStream *ts_st = st->priv_data;\n\n    int len, max_payload_size;\n\n    const uint8_t *access_unit_index = NULL;\n\n\n\n    if (st->codec->codec_type == CODEC_TYPE_SUBTITLE) {\n\n        /* for subtitle, a single PES packet must be generated */\n\n        mpegts_write_pes(s, st, buf, size, pkt->pts, AV_NOPTS_VALUE);\n\n        return 0;\n\n    }\n\n\n\n    if (st->codec->codec_id == CODEC_ID_DIRAC) {\n\n        /* for Dirac, a single PES packet must be generated */\n\n        mpegts_write_pes(s, st, buf, size, pkt->pts, pkt->dts);\n\n        return 0;\n\n    }\n\n    max_payload_size = DEFAULT_PES_PAYLOAD_SIZE;\n\n    if (st->codec->codec_id == CODEC_ID_MPEG2VIDEO ||\n\n        st->codec->codec_id == CODEC_ID_MPEG1VIDEO) {\n\n        const uint8_t *p = pkt->data;\n\n        const uint8_t *end = pkt->data+pkt->size;\n\n        uint32_t state = -1;\n\n        while (p < end) {\n\n            p = ff_find_start_code(p, end, &state);\n\n            if (state == PICTURE_START_CODE) {\n\n                access_unit_index = p - 4;\n\n                break;\n\n            }\n\n        }\n\n    } else if (st->codec->codec_type == CODEC_TYPE_AUDIO) {\n\n        access_unit_index = pkt->data;\n\n    }\n\n\n\n    if (!access_unit_index) {\n\n        av_log(s, AV_LOG_ERROR, \"error, could not find access unit start\\n\");\n\n        return -1;\n\n    }\n\n\n\n    while (size > 0) {\n\n        len = max_payload_size - ts_st->payload_index;\n\n        if (len > size)\n\n            len = size;\n\n        memcpy(ts_st->payload + ts_st->payload_index, buf, len);\n\n        buf += len;\n\n        size -= len;\n\n        ts_st->payload_index += len;\n\n        if (access_unit_index && access_unit_index < buf &&\n\n            ts_st->payload_pts == AV_NOPTS_VALUE &&\n\n            ts_st->payload_dts == AV_NOPTS_VALUE) {\n\n            ts_st->payload_dts = pkt->dts;\n\n            ts_st->payload_pts = pkt->pts;\n\n        }\n\n        if (ts_st->payload_index >= max_payload_size) {\n\n            mpegts_write_pes(s, st, ts_st->payload, ts_st->payload_index,\n\n                             ts_st->payload_pts, ts_st->payload_dts);\n\n            ts_st->payload_pts = AV_NOPTS_VALUE;\n\n            ts_st->payload_dts = AV_NOPTS_VALUE;\n\n            ts_st->payload_index = 0;\n\n            access_unit_index = NULL; // unset access unit to avoid setting pts/dts again\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 23263}
{"project": "FFmpeg", "commit_id": "4791a910c0dc3dd5861d38202457c9fb9bf1154c", "target": 0, "func": "int ff_hevc_extract_rbsp(HEVCContext *s, const uint8_t *src, int length,\n\n                         HEVCNAL *nal)\n\n{\n\n    int i, si, di;\n\n    uint8_t *dst;\n\n\n\n    if (s)\n\n        nal->skipped_bytes = 0;\n\n#define STARTCODE_TEST                                                  \\\n\n        if (i + 2 < length && src[i + 1] == 0 && src[i + 2] <= 3) {     \\\n\n            if (src[i + 2] != 3) {                                      \\\n\n                /* startcode, so we must be past the end */             \\\n\n                length = i;                                             \\\n\n            }                                                           \\\n\n            break;                                                      \\\n\n        }\n\n#if HAVE_FAST_UNALIGNED\n\n#define FIND_FIRST_ZERO                                                 \\\n\n        if (i > 0 && !src[i])                                           \\\n\n            i--;                                                        \\\n\n        while (src[i])                                                  \\\n\n            i++\n\n#if HAVE_FAST_64BIT\n\n    for (i = 0; i + 1 < length; i += 9) {\n\n        if (!((~AV_RN64A(src + i) &\n\n               (AV_RN64A(src + i) - 0x0100010001000101ULL)) &\n\n              0x8000800080008080ULL))\n\n            continue;\n\n        FIND_FIRST_ZERO;\n\n        STARTCODE_TEST;\n\n        i -= 7;\n\n    }\n\n#else\n\n    for (i = 0; i + 1 < length; i += 5) {\n\n        if (!((~AV_RN32A(src + i) &\n\n               (AV_RN32A(src + i) - 0x01000101U)) &\n\n              0x80008080U))\n\n            continue;\n\n        FIND_FIRST_ZERO;\n\n        STARTCODE_TEST;\n\n        i -= 3;\n\n    }\n\n#endif /* HAVE_FAST_64BIT */\n\n#else\n\n    for (i = 0; i + 1 < length; i += 2) {\n\n        if (src[i])\n\n            continue;\n\n        if (i > 0 && src[i - 1] == 0)\n\n            i--;\n\n        STARTCODE_TEST;\n\n    }\n\n#endif /* HAVE_FAST_UNALIGNED */\n\n\n\n    if (i >= length - 1) { // no escaped 0\n\n        nal->data     =\n\n        nal->raw_data = src;\n\n        nal->size     =\n\n        nal->raw_size = length;\n\n        return length;\n\n    }\n\n\n\n    av_fast_malloc(&nal->rbsp_buffer, &nal->rbsp_buffer_size,\n\n                   length + AV_INPUT_BUFFER_PADDING_SIZE);\n\n    if (!nal->rbsp_buffer)\n\n        return AVERROR(ENOMEM);\n\n\n\n    dst = nal->rbsp_buffer;\n\n\n\n    memcpy(dst, src, i);\n\n    si = di = i;\n\n    while (si + 2 < length) {\n\n        // remove escapes (very rare 1:2^22)\n\n        if (src[si + 2] > 3) {\n\n            dst[di++] = src[si++];\n\n            dst[di++] = src[si++];\n\n        } else if (src[si] == 0 && src[si + 1] == 0) {\n\n            if (src[si + 2] == 3) { // escape\n\n                dst[di++] = 0;\n\n                dst[di++] = 0;\n\n                si       += 3;\n\n\n\n                if (s && nal->skipped_bytes_pos) {\n\n                    nal->skipped_bytes++;\n\n                    if (nal->skipped_bytes_pos_size < nal->skipped_bytes) {\n\n                        nal->skipped_bytes_pos_size *= 2;\n\n                        av_assert0(nal->skipped_bytes_pos_size >= nal->skipped_bytes);\n\n                        av_reallocp_array(&nal->skipped_bytes_pos,\n\n                                nal->skipped_bytes_pos_size,\n\n                                sizeof(*nal->skipped_bytes_pos));\n\n                        if (!nal->skipped_bytes_pos) {\n\n                            nal->skipped_bytes_pos_size = 0;\n\n                            return AVERROR(ENOMEM);\n\n                        }\n\n                    }\n\n                    if (nal->skipped_bytes_pos)\n\n                        nal->skipped_bytes_pos[nal->skipped_bytes-1] = di - 1;\n\n                }\n\n                continue;\n\n            } else // next start code\n\n                goto nsc;\n\n        }\n\n\n\n        dst[di++] = src[si++];\n\n    }\n\n    while (si < length)\n\n        dst[di++] = src[si++];\n\n\n\nnsc:\n\n    memset(dst + di, 0, AV_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n    nal->data = dst;\n\n    nal->size = di;\n\n    nal->raw_data = src;\n\n    nal->raw_size = si;\n\n    return si;\n\n}\n", "idx": 23264}
{"project": "FFmpeg", "commit_id": "1ec83d9a9e472f485897ac92bad9631d551a8c5b", "target": 0, "func": "static int tiff_decode_tag(TiffContext *s, const uint8_t *start,\n\n                           const uint8_t *buf, const uint8_t *end_buf)\n\n{\n\n    unsigned tag, type, count, off, value = 0;\n\n    int i, j;\n\n    int ret;\n\n    uint32_t *pal;\n\n    const uint8_t *rp, *gp, *bp;\n\n    double *dp;\n\n\n\n    if (end_buf - buf < 12)\n\n        return -1;\n\n    tag = tget_short(&buf, s->le);\n\n    type = tget_short(&buf, s->le);\n\n    count = tget_long(&buf, s->le);\n\n    off = tget_long(&buf, s->le);\n\n\n\n    if (type == 0 || type >= FF_ARRAY_ELEMS(type_sizes)) {\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"Unknown tiff type (%u) encountered\\n\",\n\n               type);\n\n        return 0;\n\n    }\n\n\n\n    if (count == 1) {\n\n        switch (type) {\n\n        case TIFF_BYTE:\n\n        case TIFF_SHORT:\n\n            buf -= 4;\n\n            value = tget(&buf, type, s->le);\n\n            buf = NULL;\n\n            break;\n\n        case TIFF_LONG:\n\n            value = off;\n\n            buf = NULL;\n\n            break;\n\n        case TIFF_STRING:\n\n            if (count <= 4) {\n\n                buf -= 4;\n\n                break;\n\n            }\n\n        default:\n\n            value = UINT_MAX;\n\n            buf = start + off;\n\n        }\n\n    } else {\n\n        if (count <= 4 && type_sizes[type] * count <= 4) {\n\n            buf -= 4;\n\n        } else {\n\n            buf = start + off;\n\n        }\n\n    }\n\n\n\n    if (buf && (buf < start || buf > end_buf)) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"Tag referencing position outside the image\\n\");\n\n        return -1;\n\n    }\n\n\n\n    switch (tag) {\n\n    case TIFF_WIDTH:\n\n        s->width = value;\n\n        break;\n\n    case TIFF_HEIGHT:\n\n        s->height = value;\n\n        break;\n\n    case TIFF_BPP:\n\n        s->bppcount = count;\n\n        if (count > 4) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"This format is not supported (bpp=%d, %d components)\\n\",\n\n                   s->bpp, count);\n\n            return -1;\n\n        }\n\n        if (count == 1)\n\n            s->bpp = value;\n\n        else {\n\n            switch (type) {\n\n            case TIFF_BYTE:\n\n                s->bpp = (off & 0xFF) + ((off >> 8) & 0xFF) +\n\n                         ((off >> 16) & 0xFF) + ((off >> 24) & 0xFF);\n\n                break;\n\n            case TIFF_SHORT:\n\n            case TIFF_LONG:\n\n                s->bpp = 0;\n\n                for (i = 0; i < count && buf < end_buf; i++)\n\n                    s->bpp += tget(&buf, type, s->le);\n\n                break;\n\n            default:\n\n                s->bpp = -1;\n\n            }\n\n        }\n\n        break;\n\n    case TIFF_SAMPLES_PER_PIXEL:\n\n        if (count != 1) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Samples per pixel requires a single value, many provided\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (s->bppcount == 1)\n\n            s->bpp *= value;\n\n        s->bppcount = value;\n\n        break;\n\n    case TIFF_COMPR:\n\n        s->compr = value;\n\n        s->predictor = 0;\n\n        switch (s->compr) {\n\n        case TIFF_RAW:\n\n        case TIFF_PACKBITS:\n\n        case TIFF_LZW:\n\n        case TIFF_CCITT_RLE:\n\n            break;\n\n        case TIFF_G3:\n\n        case TIFF_G4:\n\n            s->fax_opts = 0;\n\n            break;\n\n        case TIFF_DEFLATE:\n\n        case TIFF_ADOBE_DEFLATE:\n\n#if CONFIG_ZLIB\n\n            break;\n\n#else\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Deflate: ZLib not compiled in\\n\");\n\n            return -1;\n\n#endif\n\n        case TIFF_JPEG:\n\n        case TIFF_NEWJPEG:\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"JPEG compression is not supported\\n\");\n\n            return -1;\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Unknown compression method %i\\n\",\n\n                   s->compr);\n\n            return -1;\n\n        }\n\n        break;\n\n    case TIFF_ROWSPERSTRIP:\n\n        if (type == TIFF_LONG && value == UINT_MAX)\n\n            value = s->avctx->height;\n\n        if (value < 1) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Incorrect value of rows per strip\\n\");\n\n            return -1;\n\n        }\n\n        s->rps = value;\n\n        break;\n\n    case TIFF_STRIP_OFFS:\n\n        if (count == 1) {\n\n            s->stripdata = NULL;\n\n            s->stripoff = value;\n\n        } else\n\n            s->stripdata = start + off;\n\n        s->strips = count;\n\n        if (s->strips == 1)\n\n            s->rps = s->height;\n\n        s->sot = type;\n\n        if (s->stripdata > end_buf) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Tag referencing position outside the image\\n\");\n\n            return -1;\n\n        }\n\n        break;\n\n    case TIFF_STRIP_SIZE:\n\n        if (count == 1) {\n\n            s->stripsizes = NULL;\n\n            s->stripsize = value;\n\n            s->strips = 1;\n\n        } else {\n\n            s->stripsizes = start + off;\n\n        }\n\n        s->strips = count;\n\n        s->sstype = type;\n\n        if (s->stripsizes > end_buf) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Tag referencing position outside the image\\n\");\n\n            return -1;\n\n        }\n\n        break;\n\n    case TIFF_TILE_BYTE_COUNTS:\n\n    case TIFF_TILE_LENGTH:\n\n    case TIFF_TILE_OFFSETS:\n\n    case TIFF_TILE_WIDTH:\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Tiled images are not supported\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n        break;\n\n    case TIFF_PREDICTOR:\n\n        s->predictor = value;\n\n        break;\n\n    case TIFF_INVERT:\n\n        switch (value) {\n\n        case 0:\n\n            s->invert = 1;\n\n            break;\n\n        case 1:\n\n            s->invert = 0;\n\n            break;\n\n        case 2:\n\n        case 3:\n\n            break;\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Color mode %d is not supported\\n\",\n\n                   value);\n\n            return -1;\n\n        }\n\n        break;\n\n    case TIFF_FILL_ORDER:\n\n        if (value < 1 || value > 2) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Unknown FillOrder value %d, trying default one\\n\", value);\n\n            value = 1;\n\n        }\n\n        s->fill_order = value - 1;\n\n        break;\n\n    case TIFF_PAL:\n\n        pal = (uint32_t *) s->palette;\n\n        off = type_sizes[type];\n\n        if (count / 3 > 256 || end_buf - buf < count / 3 * off * 3)\n\n            return -1;\n\n        rp = buf;\n\n        gp = buf + count / 3 * off;\n\n        bp = buf + count / 3 * off * 2;\n\n        off = (type_sizes[type] - 1) << 3;\n\n        for (i = 0; i < count / 3; i++) {\n\n            j = 0xff << 24;\n\n            j |= (tget(&rp, type, s->le) >> off) << 16;\n\n            j |= (tget(&gp, type, s->le) >> off) << 8;\n\n            j |=  tget(&bp, type, s->le) >> off;\n\n            pal[i] = j;\n\n        }\n\n        s->palette_is_set = 1;\n\n        break;\n\n    case TIFF_PLANAR:\n\n        if (value == 2) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Planar format is not supported\\n\");\n\n            return -1;\n\n        }\n\n        break;\n\n    case TIFF_T4OPTIONS:\n\n        if (s->compr == TIFF_G3)\n\n            s->fax_opts = value;\n\n        break;\n\n    case TIFF_T6OPTIONS:\n\n        if (s->compr == TIFF_G4)\n\n            s->fax_opts = value;\n\n        break;\n\n#define ADD_METADATA(count, name, sep)\\\n\n    if (ret = add_metadata(&buf, count, type, name, sep, s) < 0) {\\\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\\\n\n        return ret;\\\n\n    }\n\n    case TIFF_MODEL_PIXEL_SCALE:\n\n        ADD_METADATA(count, \"ModelPixelScaleTag\", NULL);\n\n        break;\n\n    case TIFF_MODEL_TRANSFORMATION:\n\n        ADD_METADATA(count, \"ModelTransformationTag\", NULL);\n\n        break;\n\n    case TIFF_MODEL_TIEPOINT:\n\n        ADD_METADATA(count, \"ModelTiepointTag\", NULL);\n\n        break;\n\n    case TIFF_GEO_KEY_DIRECTORY:\n\n        ADD_METADATA(1, \"GeoTIFF_Version\", NULL);\n\n        ADD_METADATA(2, \"GeoTIFF_Key_Revision\", \".\");\n\n        s->geotag_count   = tget_short(&buf, s->le);\n\n        if (s->geotag_count > count / 4 - 1) {\n\n            s->geotag_count = count / 4 - 1;\n\n            av_log(s->avctx, AV_LOG_WARNING, \"GeoTIFF key directory buffer shorter than specified\\n\");\n\n        }\n\n        s->geotags = av_mallocz(sizeof(TiffGeoTag) * s->geotag_count);\n\n        if (!s->geotags) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        for (i = 0; i < s->geotag_count; i++) {\n\n            s->geotags[i].key    = tget_short(&buf, s->le);\n\n            s->geotags[i].type   = tget_short(&buf, s->le);\n\n            s->geotags[i].count  = tget_short(&buf, s->le);\n\n\n\n            if (!s->geotags[i].type)\n\n                s->geotags[i].val  = get_geokey_val(s->geotags[i].key, tget_short(&buf, s->le));\n\n            else\n\n                s->geotags[i].offset = tget_short(&buf, s->le);\n\n        }\n\n        break;\n\n    case TIFF_GEO_DOUBLE_PARAMS:\n\n        dp = av_malloc(count * sizeof(double));\n\n        if (!dp) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        for (i = 0; i < count; i++)\n\n            dp[i] = tget_double(&buf, s->le);\n\n        for (i = 0; i < s->geotag_count; i++) {\n\n            if (s->geotags[i].type == TIFF_GEO_DOUBLE_PARAMS) {\n\n                if (s->geotags[i].count == 0\n\n                    || s->geotags[i].offset + s->geotags[i].count > count) {\n\n                    av_log(s->avctx, AV_LOG_WARNING, \"Invalid GeoTIFF key %d\\n\", s->geotags[i].key);\n\n                } else {\n\n                    char *ap = doubles2str(&dp[s->geotags[i].offset], s->geotags[i].count, \", \");\n\n                    if (!ap) {\n\n                        av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n                        av_freep(&dp);\n\n                        return AVERROR(ENOMEM);\n\n                    }\n\n                    s->geotags[i].val = ap;\n\n                }\n\n            }\n\n        }\n\n        av_freep(&dp);\n\n        break;\n\n    case TIFF_GEO_ASCII_PARAMS:\n\n        for (i = 0; i < s->geotag_count; i++) {\n\n            if (s->geotags[i].type == TIFF_GEO_ASCII_PARAMS) {\n\n                if (s->geotags[i].count == 0\n\n                    || s->geotags[i].offset +  s->geotags[i].count > count) {\n\n                    av_log(s->avctx, AV_LOG_WARNING, \"Invalid GeoTIFF key %d\\n\", s->geotags[i].key);\n\n                } else {\n\n                    char *ap = av_malloc(s->geotags[i].count);\n\n                    if (!ap) {\n\n                        av_log(s->avctx, AV_LOG_ERROR, \"Error allocating temporary buffer\\n\");\n\n                        return AVERROR(ENOMEM);\n\n                    }\n\n                    memcpy(ap, &buf[s->geotags[i].offset], s->geotags[i].count);\n\n                    ap[s->geotags[i].count - 1] = '\\0'; //replace the \"|\" delimiter with a 0 byte\n\n                    s->geotags[i].val = ap;\n\n                }\n\n            }\n\n        }\n\n        break;\n\n    default:\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"Unknown or unsupported tag %d/0X%0X\\n\",\n\n               tag, tag);\n\n    }\n\n    return 0;\n\n}\n", "idx": 23265}
{"project": "FFmpeg", "commit_id": "3e0c78bac63c213649c3e8c2fa49e9f3c9848d5a", "target": 0, "func": "static int bit_allocation(IMCContext *q, IMCChannel *chctx,\n\n                          int stream_format_code, int freebits, int flag)\n\n{\n\n    int i, j;\n\n    const float limit = -1.e20;\n\n    float highest = 0.0;\n\n    int indx;\n\n    int t1 = 0;\n\n    int t2 = 1;\n\n    float summa = 0.0;\n\n    int iacc = 0;\n\n    int summer = 0;\n\n    int rres, cwlen;\n\n    float lowest = 1.e10;\n\n    int low_indx = 0;\n\n    float workT[32];\n\n    int flg;\n\n    int found_indx = 0;\n\n\n\n    for (i = 0; i < BANDS; i++)\n\n        highest = FFMAX(highest, chctx->flcoeffs1[i]);\n\n\n\n    for (i = 0; i < BANDS - 1; i++)\n\n        chctx->flcoeffs4[i] = chctx->flcoeffs3[i] - log2f(chctx->flcoeffs5[i]);\n\n    chctx->flcoeffs4[BANDS - 1] = limit;\n\n\n\n    highest = highest * 0.25;\n\n\n\n    for (i = 0; i < BANDS; i++) {\n\n        indx = -1;\n\n        if ((band_tab[i + 1] - band_tab[i]) == chctx->bandWidthT[i])\n\n            indx = 0;\n\n\n\n        if ((band_tab[i + 1] - band_tab[i]) > chctx->bandWidthT[i])\n\n            indx = 1;\n\n\n\n        if (((band_tab[i + 1] - band_tab[i]) / 2) >= chctx->bandWidthT[i])\n\n            indx = 2;\n\n\n\n        if (indx == -1)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        chctx->flcoeffs4[i] += xTab[(indx * 2 + (chctx->flcoeffs1[i] < highest)) * 2 + flag];\n\n    }\n\n\n\n    if (stream_format_code & 0x2) {\n\n        chctx->flcoeffs4[0] = limit;\n\n        chctx->flcoeffs4[1] = limit;\n\n        chctx->flcoeffs4[2] = limit;\n\n        chctx->flcoeffs4[3] = limit;\n\n    }\n\n\n\n    for (i = (stream_format_code & 0x2) ? 4 : 0; i < BANDS - 1; i++) {\n\n        iacc  += chctx->bandWidthT[i];\n\n        summa += chctx->bandWidthT[i] * chctx->flcoeffs4[i];\n\n    }\n\n\n\n    if (!iacc)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    chctx->bandWidthT[BANDS - 1] = 0;\n\n    summa = (summa * 0.5 - freebits) / iacc;\n\n\n\n\n\n    for (i = 0; i < BANDS / 2; i++) {\n\n        rres = summer - freebits;\n\n        if ((rres >= -8) && (rres <= 8))\n\n            break;\n\n\n\n        summer = 0;\n\n        iacc   = 0;\n\n\n\n        for (j = (stream_format_code & 0x2) ? 4 : 0; j < BANDS; j++) {\n\n            cwlen = av_clipf(((chctx->flcoeffs4[j] * 0.5) - summa + 0.5), 0, 6);\n\n\n\n            chctx->bitsBandT[j] = cwlen;\n\n            summer += chctx->bandWidthT[j] * cwlen;\n\n\n\n            if (cwlen > 0)\n\n                iacc += chctx->bandWidthT[j];\n\n        }\n\n\n\n        flg = t2;\n\n        t2 = 1;\n\n        if (freebits < summer)\n\n            t2 = -1;\n\n        if (i == 0)\n\n            flg = t2;\n\n        if (flg != t2)\n\n            t1++;\n\n\n\n        summa = (float)(summer - freebits) / ((t1 + 1) * iacc) + summa;\n\n    }\n\n\n\n    for (i = (stream_format_code & 0x2) ? 4 : 0; i < BANDS; i++) {\n\n        for (j = band_tab[i]; j < band_tab[i + 1]; j++)\n\n            chctx->CWlengthT[j] = chctx->bitsBandT[i];\n\n    }\n\n\n\n    if (freebits > summer) {\n\n        for (i = 0; i < BANDS; i++) {\n\n            workT[i] = (chctx->bitsBandT[i] == 6) ? -1.e20\n\n                                              : (chctx->bitsBandT[i] * -2 + chctx->flcoeffs4[i] - 0.415);\n\n        }\n\n\n\n        highest = 0.0;\n\n\n\n        do {\n\n            if (highest <= -1.e20)\n\n                break;\n\n\n\n            found_indx = 0;\n\n            highest = -1.e20;\n\n\n\n            for (i = 0; i < BANDS; i++) {\n\n                if (workT[i] > highest) {\n\n                    highest = workT[i];\n\n                    found_indx = i;\n\n                }\n\n            }\n\n\n\n            if (highest > -1.e20) {\n\n                workT[found_indx] -= 2.0;\n\n                if (++chctx->bitsBandT[found_indx] == 6)\n\n                    workT[found_indx] = -1.e20;\n\n\n\n                for (j = band_tab[found_indx]; j < band_tab[found_indx + 1] && (freebits > summer); j++) {\n\n                    chctx->CWlengthT[j]++;\n\n                    summer++;\n\n                }\n\n            }\n\n        } while (freebits > summer);\n\n    }\n\n    if (freebits < summer) {\n\n        for (i = 0; i < BANDS; i++) {\n\n            workT[i] = chctx->bitsBandT[i] ? (chctx->bitsBandT[i] * -2 + chctx->flcoeffs4[i] + 1.585)\n\n                                       : 1.e20;\n\n        }\n\n        if (stream_format_code & 0x2) {\n\n            workT[0] = 1.e20;\n\n            workT[1] = 1.e20;\n\n            workT[2] = 1.e20;\n\n            workT[3] = 1.e20;\n\n        }\n\n        while (freebits < summer) {\n\n            lowest   = 1.e10;\n\n            low_indx = 0;\n\n            for (i = 0; i < BANDS; i++) {\n\n                if (workT[i] < lowest) {\n\n                    lowest   = workT[i];\n\n                    low_indx = i;\n\n                }\n\n            }\n\n            // if (lowest >= 1.e10)\n\n            //     break;\n\n            workT[low_indx] = lowest + 2.0;\n\n\n\n            if (!--chctx->bitsBandT[low_indx])\n\n                workT[low_indx] = 1.e20;\n\n\n\n            for (j = band_tab[low_indx]; j < band_tab[low_indx+1] && (freebits < summer); j++) {\n\n                if (chctx->CWlengthT[j] > 0) {\n\n                    chctx->CWlengthT[j]--;\n\n                    summer--;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 23266}
{"project": "FFmpeg", "commit_id": "ec2694d25905c217e5815947cda896aa25398388", "target": 0, "func": "static av_cold int g722_decode_init(AVCodecContext * avctx)\n\n{\n\n    G722Context *c = avctx->priv_data;\n\n\n\n    if (avctx->channels != 1) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Only mono tracks are allowed.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_S16;\n\n\n\n    c->band[0].scale_factor = 8;\n\n    c->band[1].scale_factor = 2;\n\n    c->prev_samples_pos = 22;\n\n\n\n    avcodec_get_frame_defaults(&c->frame);\n\n    avctx->coded_frame = &c->frame;\n\n\n\n    return 0;\n\n}\n", "idx": 23267}
{"project": "FFmpeg", "commit_id": "b3f9f7a33337e9b64e6044b0010e2722fa0b2f9c", "target": 0, "func": "static int handle_packet(MpegTSContext *ts, const uint8_t *packet)\n\n{\n\n    AVFormatContext *s = ts->stream;\n\n    MpegTSFilter *tss;\n\n    int len, pid, cc, cc_ok, afc, is_start;\n\n    const uint8_t *p, *p_end;\n\n    int64_t pos;\n\n\n\n    pid = AV_RB16(packet + 1) & 0x1fff;\n\n    if(pid && discard_pid(ts, pid))\n\n        return 0;\n\n    is_start = packet[1] & 0x40;\n\n    tss = ts->pids[pid];\n\n    if (ts->auto_guess && tss == NULL && is_start) {\n\n        add_pes_stream(ts, pid, -1, 0);\n\n        tss = ts->pids[pid];\n\n    }\n\n    if (!tss)\n\n        return 0;\n\n\n\n    /* continuity check (currently not used) */\n\n    cc = (packet[3] & 0xf);\n\n    cc_ok = (tss->last_cc < 0) || ((((tss->last_cc + 1) & 0x0f) == cc));\n\n    tss->last_cc = cc;\n\n\n\n    /* skip adaptation field */\n\n    afc = (packet[3] >> 4) & 3;\n\n    p = packet + 4;\n\n    if (afc == 0) /* reserved value */\n\n        return 0;\n\n    if (afc == 2) /* adaptation field only */\n\n        return 0;\n\n    if (afc == 3) {\n\n        /* skip adapation field */\n\n        p += p[0] + 1;\n\n    }\n\n    /* if past the end of packet, ignore */\n\n    p_end = packet + TS_PACKET_SIZE;\n\n    if (p >= p_end)\n\n        return 0;\n\n\n\n    pos = url_ftell(ts->stream->pb);\n\n    ts->pos47= pos % ts->raw_packet_size;\n\n\n\n    if (tss->type == MPEGTS_SECTION) {\n\n        if (is_start) {\n\n            /* pointer field present */\n\n            len = *p++;\n\n            if (p + len > p_end)\n\n                return 0;\n\n            if (len && cc_ok) {\n\n                /* write remaining section bytes */\n\n                write_section_data(s, tss,\n\n                                   p, len, 0);\n\n                /* check whether filter has been closed */\n\n                if (!ts->pids[pid])\n\n                    return 0;\n\n            }\n\n            p += len;\n\n            if (p < p_end) {\n\n                write_section_data(s, tss,\n\n                                   p, p_end - p, 1);\n\n            }\n\n        } else {\n\n            if (cc_ok) {\n\n                write_section_data(s, tss,\n\n                                   p, p_end - p, 0);\n\n            }\n\n        }\n\n    } else {\n\n        int ret;\n\n        // Note: The position here points actually behind the current packet.\n\n        if ((ret = tss->u.pes_filter.pes_cb(tss, p, p_end - p, is_start,\n\n                                            pos - ts->raw_packet_size)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23268}
{"project": "FFmpeg", "commit_id": "03cef34aa66662e2ab3681d290e7c5a6634f4058", "target": 0, "func": "static void buffer_release(void *opaque, uint8_t *data)\n\n{\n\n    *(uint8_t*)opaque = 0;\n\n}\n", "idx": 23269}
{"project": "FFmpeg", "commit_id": "63b737d4f9c118853a4f8d9af641335629bdf3ab", "target": 0, "func": "static void float_to_int16_3dnow(int16_t *dst, const float *src, int len){\n\n    // not bit-exact: pf2id uses different rounding than C and SSE\n\n    int i;\n\n    for(i=0; i<len; i+=4) {\n\n        asm volatile(\n\n            \"pf2id       %1, %%mm0 \\n\\t\"\n\n            \"pf2id       %2, %%mm1 \\n\\t\"\n\n            \"packssdw %%mm1, %%mm0 \\n\\t\"\n\n            \"movq     %%mm0, %0    \\n\\t\"\n\n            :\"=m\"(dst[i])\n\n            :\"m\"(src[i]), \"m\"(src[i+2])\n\n        );\n\n    }\n\n    asm volatile(\"femms\");\n\n}\n", "idx": 23270}
{"project": "FFmpeg", "commit_id": "1ec83d9a9e472f485897ac92bad9631d551a8c5b", "target": 0, "func": "static int add_shorts_metadata(const uint8_t **buf, int count, const char *name,\n\n                               const char *sep, TiffContext *s)\n\n{\n\n    char *ap;\n\n    int i;\n\n    int *sp = av_malloc(count * sizeof(int));\n\n    if (!sp)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for (i = 0; i < count; i++)\n\n        sp[i] = tget_short(buf, s->le);\n\n    ap = shorts2str(sp, count, sep);\n\n    av_freep(&sp);\n\n    if (!ap)\n\n        return AVERROR(ENOMEM);\n\n    av_dict_set(&s->picture.metadata, name, ap, AV_DICT_DONT_STRDUP_VAL);\n\n    return 0;\n\n}\n", "idx": 23271}
{"project": "FFmpeg", "commit_id": "15b219fae9da1691dfb264f51637805e1ca63d1a", "target": 0, "func": "int ff_mjpeg_decode_sos(MJpegDecodeContext *s,\n\n                        const uint8_t *mb_bitmask, const AVFrame *reference)\n\n{\n\n    int len, nb_components, i, h, v, predictor, point_transform;\n\n    int index, id;\n\n    const int block_size= s->lossless ? 1 : 8;\n\n    int ilv, prev_shift;\n\n\n\n    /* XXX: verify len field validity */\n\n    len = get_bits(&s->gb, 16);\n\n    nb_components = get_bits(&s->gb, 8);\n\n    if (nb_components == 0 || nb_components > MAX_COMPONENTS){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"decode_sos: nb_components (%d) unsupported\\n\", nb_components);\n\n        return -1;\n\n    }\n\n    if (len != 6+2*nb_components)\n\n    {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"decode_sos: invalid len (%d)\\n\", len);\n\n        return -1;\n\n    }\n\n    for(i=0;i<nb_components;i++) {\n\n        id = get_bits(&s->gb, 8) - 1;\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"component: %d\\n\", id);\n\n        /* find component index */\n\n        for(index=0;index<s->nb_components;index++)\n\n            if (id == s->component_id[index])\n\n                break;\n\n        if (index == s->nb_components)\n\n        {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"decode_sos: index(%d) out of components\\n\", index);\n\n            return -1;\n\n        }\n\n        /* Metasoft MJPEG codec has Cb and Cr swapped */\n\n        if (s->avctx->codec_tag == MKTAG('M', 'T', 'S', 'J')\n\n            && nb_components == 3 && s->nb_components == 3 && i)\n\n            index = 3 - i;\n\n\n\n        if(nb_components == 3 && s->nb_components == 3 && s->avctx->pix_fmt == PIX_FMT_GBR24P)\n\n            index = (i+2)%3;\n\n\n\n        s->comp_index[i] = index;\n\n\n\n        s->nb_blocks[i] = s->h_count[index] * s->v_count[index];\n\n        s->h_scount[i] = s->h_count[index];\n\n        s->v_scount[i] = s->v_count[index];\n\n\n\n        s->dc_index[i] = get_bits(&s->gb, 4);\n\n        s->ac_index[i] = get_bits(&s->gb, 4);\n\n\n\n        if (s->dc_index[i] <  0 || s->ac_index[i] < 0 ||\n\n            s->dc_index[i] >= 4 || s->ac_index[i] >= 4)\n\n            goto out_of_range;\n\n        if (!s->vlcs[0][s->dc_index[i]].table || !s->vlcs[1][s->ac_index[i]].table)\n\n            goto out_of_range;\n\n    }\n\n\n\n    predictor= get_bits(&s->gb, 8); /* JPEG Ss / lossless JPEG predictor /JPEG-LS NEAR */\n\n    ilv= get_bits(&s->gb, 8);    /* JPEG Se / JPEG-LS ILV */\n\n    if(s->avctx->codec_tag != AV_RL32(\"CJPG\")){\n\n        prev_shift = get_bits(&s->gb, 4); /* Ah */\n\n        point_transform= get_bits(&s->gb, 4); /* Al */\n\n    }else\n\n        prev_shift= point_transform= 0;\n\n\n\n    for(i=0;i<nb_components;i++)\n\n        s->last_dc[i] = 1024;\n\n\n\n    if (nb_components > 1) {\n\n        /* interleaved stream */\n\n        s->mb_width  = (s->width  + s->h_max * block_size - 1) / (s->h_max * block_size);\n\n        s->mb_height = (s->height + s->v_max * block_size - 1) / (s->v_max * block_size);\n\n    } else if(!s->ls) { /* skip this for JPEG-LS */\n\n        h = s->h_max / s->h_scount[0];\n\n        v = s->v_max / s->v_scount[0];\n\n        s->mb_width  = (s->width  + h * block_size - 1) / (h * block_size);\n\n        s->mb_height = (s->height + v * block_size - 1) / (v * block_size);\n\n        s->nb_blocks[0] = 1;\n\n        s->h_scount[0] = 1;\n\n        s->v_scount[0] = 1;\n\n    }\n\n\n\n    if(s->avctx->debug & FF_DEBUG_PICT_INFO)\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"%s %s p:%d >>:%d ilv:%d bits:%d skip:%d %s comp:%d\\n\", s->lossless ? \"lossless\" : \"sequential DCT\", s->rgb ? \"RGB\" : \"\",\n\n               predictor, point_transform, ilv, s->bits, s->mjpb_skiptosod,\n\n               s->pegasus_rct ? \"PRCT\" : (s->rct ? \"RCT\" : \"\"), nb_components);\n\n\n\n\n\n    /* mjpeg-b can have padding bytes between sos and image data, skip them */\n\n    for (i = s->mjpb_skiptosod; i > 0; i--)\n\n        skip_bits(&s->gb, 8);\n\n\n\n    if(s->lossless){\n\n        av_assert0(s->picture_ptr == &s->picture);\n\n        if(CONFIG_JPEGLS_DECODER && s->ls){\n\n//            for(){\n\n//            reset_ls_coding_parameters(s, 0);\n\n\n\n            if(ff_jpegls_decode_picture(s, predictor, point_transform, ilv) < 0)\n\n                return -1;\n\n        }else{\n\n            if(s->rgb){\n\n                if(ljpeg_decode_rgb_scan(s, nb_components, predictor, point_transform) < 0)\n\n                    return -1;\n\n            }else{\n\n                if(ljpeg_decode_yuv_scan(s, predictor, point_transform) < 0)\n\n                    return -1;\n\n            }\n\n        }\n\n    }else{\n\n        if(s->progressive && predictor) {\n\n            av_assert0(s->picture_ptr == &s->picture);\n\n            if(mjpeg_decode_scan_progressive_ac(s, predictor, ilv, prev_shift, point_transform) < 0)\n\n                return -1;\n\n        } else {\n\n            if(mjpeg_decode_scan(s, nb_components, prev_shift, point_transform,\n\n                                 mb_bitmask, reference) < 0)\n\n                return -1;\n\n        }\n\n    }\n\n    if (s->yuv421) {\n\n        uint8_t *line = s->picture_ptr->data[2];\n\n        for (i = 0; i < s->height / 2; i++) {\n\n            for (index = s->width - 1; index; index--)\n\n                line[index] = (line[index / 2] + line[(index + 1) / 2]) >> 1;\n\n            line += s->linesize[2];\n\n        }\n\n    } else if (s->yuv442) {\n\n        uint8_t *dst = &((uint8_t *)s->picture_ptr->data[2])[(s->height - 1) * s->linesize[2]];\n\n        for (i = s->height - 1; i; i--) {\n\n            uint8_t *src1 = &((uint8_t *)s->picture_ptr->data[2])[i / 2 * s->linesize[2]];\n\n            uint8_t *src2 = &((uint8_t *)s->picture_ptr->data[2])[(i + 1) / 2 * s->linesize[2]];\n\n            if (src1 == src2) {\n\n                memcpy(dst, src1, s->width);\n\n            } else {\n\n                for (index = 0; index < s->width; index++)\n\n                    dst[index] = (src1[index] + src2[index]) >> 1;\n\n            }\n\n            dst -= s->linesize[2];\n\n        }\n\n    }\n\n    emms_c();\n\n    return 0;\n\n out_of_range:\n\n    av_log(s->avctx, AV_LOG_ERROR, \"decode_sos: ac/dc index out of range\\n\");\n\n    return -1;\n\n}\n", "idx": 23272}
{"project": "FFmpeg", "commit_id": "e1d5bbeb39501a3271c6422390d13bf9391872d1", "target": 0, "func": "static int is_intra_more_likely(MpegEncContext *s){\n\n    int is_intra_likely, i, j, undamaged_count, skip_amount, mb_x, mb_y;\n\n\n\n    if (!s->last_picture_ptr || !s->last_picture_ptr->f.data[0]) return 1; //no previous frame available -> use spatial prediction\n\n\n\n    undamaged_count=0;\n\n    for(i=0; i<s->mb_num; i++){\n\n        const int mb_xy= s->mb_index2xy[i];\n\n        const int error= s->error_status_table[mb_xy];\n\n        if(!((error&DC_ERROR) && (error&MV_ERROR)))\n\n            undamaged_count++;\n\n    }\n\n\n\n    if(s->codec_id == CODEC_ID_H264){\n\n        H264Context *h= (void*)s;\n\n        if (h->ref_count[0] <= 0 || !h->ref_list[0][0].f.data[0])\n\n            return 1;\n\n    }\n\n\n\n    if(undamaged_count < 5) return 0; //almost all MBs damaged -> use temporal prediction\n\n\n\n    //prevent dsp.sad() check, that requires access to the image\n\n    if(CONFIG_MPEG_XVMC_DECODER && s->avctx->xvmc_acceleration && s->pict_type == AV_PICTURE_TYPE_I)\n\n        return 1;\n\n\n\n    skip_amount= FFMAX(undamaged_count/50, 1); //check only upto 50 MBs\n\n    is_intra_likely=0;\n\n\n\n    j=0;\n\n    for(mb_y= 0; mb_y<s->mb_height-1; mb_y++){\n\n        for(mb_x= 0; mb_x<s->mb_width; mb_x++){\n\n            int error;\n\n            const int mb_xy= mb_x + mb_y*s->mb_stride;\n\n\n\n            error= s->error_status_table[mb_xy];\n\n            if((error&DC_ERROR) && (error&MV_ERROR))\n\n                continue; //skip damaged\n\n\n\n            j++;\n\n            if((j%skip_amount) != 0) continue; //skip a few to speed things up\n\n\n\n            if(s->pict_type==AV_PICTURE_TYPE_I){\n\n                uint8_t *mb_ptr     = s->current_picture.f.data[0] + mb_x*16 + mb_y*16*s->linesize;\n\n                uint8_t *last_mb_ptr= s->last_picture.f.data   [0] + mb_x*16 + mb_y*16*s->linesize;\n\n\n\n                if (s->avctx->codec_id == CODEC_ID_H264) {\n\n                    // FIXME\n\n                } else {\n\n                    ff_thread_await_progress((AVFrame *) s->last_picture_ptr,\n\n                                             mb_y, 0);\n\n                }\n\n                is_intra_likely += s->dsp.sad[0](NULL, last_mb_ptr, mb_ptr                    , s->linesize, 16);\n\n                // FIXME need await_progress() here\n\n                is_intra_likely -= s->dsp.sad[0](NULL, last_mb_ptr, last_mb_ptr+s->linesize*16, s->linesize, 16);\n\n            }else{\n\n                if (IS_INTRA(s->current_picture.f.mb_type[mb_xy]))\n\n                   is_intra_likely++;\n\n                else\n\n                   is_intra_likely--;\n\n            }\n\n        }\n\n    }\n\n//printf(\"is_intra_likely: %d type:%d\\n\", is_intra_likely, s->pict_type);\n\n    return is_intra_likely > 0;\n\n}\n", "idx": 23273}
{"project": "FFmpeg", "commit_id": "84bc45880ae14277cb804569401ddd34274f4764", "target": 1, "func": "void ff_hevc_luma_mv_mvp_mode(HEVCContext *s, int x0, int y0, int nPbW,\n\n                              int nPbH, int log2_cb_size, int part_idx,\n\n                              int merge_idx, MvField *mv,\n\n                              int mvp_lx_flag, int LX)\n\n{\n\n    HEVCLocalContext *lc = s->HEVClc;\n\n    MvField *tab_mvf = s->ref->tab_mvf;\n\n    int isScaledFlag_L0 = 0;\n\n    int availableFlagLXA0 = 1;\n\n    int availableFlagLXB0 = 1;\n\n    int numMVPCandLX = 0;\n\n    int min_pu_width = s->sps->min_pu_width;\n\n\n\n    int xA0, yA0;\n\n    int is_available_a0;\n\n    int xA1, yA1;\n\n    int is_available_a1;\n\n    int xB0, yB0;\n\n    int is_available_b0;\n\n    int xB1, yB1;\n\n    int is_available_b1;\n\n    int xB2, yB2;\n\n    int is_available_b2;\n\n\n\n    Mv mvpcand_list[2] = { { 0 } };\n\n    Mv mxA;\n\n    Mv mxB;\n\n    int ref_idx_curr = 0;\n\n    int ref_idx = 0;\n\n    int pred_flag_index_l0;\n\n    int pred_flag_index_l1;\n\n\n\n    const int cand_bottom_left = lc->na.cand_bottom_left;\n\n    const int cand_left        = lc->na.cand_left;\n\n    const int cand_up_left     = lc->na.cand_up_left;\n\n    const int cand_up          = lc->na.cand_up;\n\n    const int cand_up_right    = lc->na.cand_up_right_sap;\n\n    ref_idx_curr       = LX;\n\n    ref_idx            = mv->ref_idx[LX];\n\n    pred_flag_index_l0 = LX;\n\n    pred_flag_index_l1 = !LX;\n\n\n\n    // left bottom spatial candidate\n\n    xA0 = x0 - 1;\n\n    yA0 = y0 + nPbH;\n\n\n\n    is_available_a0 = AVAILABLE(cand_bottom_left, A0) &&\n\n                      yA0 < s->sps->height &&\n\n                      PRED_BLOCK_AVAILABLE(A0);\n\n\n\n    //left spatial merge candidate\n\n    xA1    = x0 - 1;\n\n    yA1    = y0 + nPbH - 1;\n\n\n\n    is_available_a1 = AVAILABLE(cand_left, A1);\n\n    if (is_available_a0 || is_available_a1)\n\n        isScaledFlag_L0 = 1;\n\n\n\n    if (is_available_a0) {\n\n        if (MP_MX(A0, pred_flag_index_l0, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n        if (MP_MX(A0, pred_flag_index_l1, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n    }\n\n\n\n    if (is_available_a1) {\n\n        if (MP_MX(A1, pred_flag_index_l0, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n        if (MP_MX(A1, pred_flag_index_l1, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n    }\n\n\n\n    if (is_available_a0) {\n\n        if (MP_MX_LT(A0, pred_flag_index_l0, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n        if (MP_MX_LT(A0, pred_flag_index_l1, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n    }\n\n\n\n    if (is_available_a1) {\n\n        if (MP_MX_LT(A1, pred_flag_index_l0, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n        if (MP_MX_LT(A1, pred_flag_index_l1, mxA)) {\n\n            goto b_candidates;\n\n        }\n\n    }\n\n    availableFlagLXA0 = 0;\n\n\n\nb_candidates:\n\n    // B candidates\n\n    // above right spatial merge candidate\n\n    xB0    = x0 + nPbW;\n\n    yB0    = y0 - 1;\n\n\n\n    is_available_b0 =  AVAILABLE(cand_up_right, B0) &&\n\n                       xB0 < s->sps->width &&\n\n                       PRED_BLOCK_AVAILABLE(B0);\n\n\n\n    if (is_available_b0) {\n\n        if (MP_MX(B0, pred_flag_index_l0, mxB)) {\n\n            goto scalef;\n\n        }\n\n        if (MP_MX(B0, pred_flag_index_l1, mxB)) {\n\n            goto scalef;\n\n        }\n\n    }\n\n\n\n    // above spatial merge candidate\n\n    xB1    = x0 + nPbW - 1;\n\n    yB1    = y0 - 1;\n\n\n\n    is_available_b1 = AVAILABLE(cand_up, B1);\n\n\n\n    if (is_available_b1) {\n\n        if (MP_MX(B1, pred_flag_index_l0, mxB)) {\n\n            goto scalef;\n\n        }\n\n        if (MP_MX(B1, pred_flag_index_l1, mxB)) {\n\n            goto scalef;\n\n        }\n\n    }\n\n\n\n    // above left spatial merge candidate\n\n    xB2 = x0 - 1;\n\n    yB2 = y0 - 1;\n\n    is_available_b2 = AVAILABLE(cand_up_left, B2);\n\n\n\n    if (is_available_b2) {\n\n        if (MP_MX(B2, pred_flag_index_l0, mxB)) {\n\n            goto scalef;\n\n        }\n\n        if (MP_MX(B2, pred_flag_index_l1, mxB)) {\n\n            goto scalef;\n\n        }\n\n    }\n\n    availableFlagLXB0 = 0;\n\n\n\nscalef:\n\n    if (!isScaledFlag_L0) {\n\n        if (availableFlagLXB0) {\n\n            availableFlagLXA0 = 1;\n\n            mxA = mxB;\n\n        }\n\n        availableFlagLXB0 = 0;\n\n\n\n        // XB0 and L1\n\n        if (is_available_b0) {\n\n            availableFlagLXB0 = MP_MX_LT(B0, pred_flag_index_l0, mxB);\n\n            if (!availableFlagLXB0)\n\n                availableFlagLXB0 = MP_MX_LT(B0, pred_flag_index_l1, mxB);\n\n        }\n\n\n\n        if (is_available_b1 && !availableFlagLXB0) {\n\n            availableFlagLXB0 = MP_MX_LT(B1, pred_flag_index_l0, mxB);\n\n            if (!availableFlagLXB0)\n\n                availableFlagLXB0 = MP_MX_LT(B1, pred_flag_index_l1, mxB);\n\n        }\n\n\n\n        if (is_available_b2 && !availableFlagLXB0) {\n\n            availableFlagLXB0 = MP_MX_LT(B2, pred_flag_index_l0, mxB);\n\n            if (!availableFlagLXB0)\n\n                availableFlagLXB0 = MP_MX_LT(B2, pred_flag_index_l1, mxB);\n\n        }\n\n    }\n\n\n\n    if (availableFlagLXA0)\n\n        mvpcand_list[numMVPCandLX++] = mxA;\n\n\n\n    if (availableFlagLXB0 && (!availableFlagLXA0 || mxA.x != mxB.x || mxA.y != mxB.y))\n\n        mvpcand_list[numMVPCandLX++] = mxB;\n\n\n\n    //temporal motion vector prediction candidate\n\n    if (numMVPCandLX < 2 && s->sh.slice_temporal_mvp_enabled_flag &&\n\n        mvp_lx_flag == numMVPCandLX) {\n\n        Mv mv_col;\n\n        int available_col = temporal_luma_motion_vector(s, x0, y0, nPbW,\n\n                                                        nPbH, ref_idx,\n\n                                                        &mv_col, LX);\n\n        if (available_col)\n\n            mvpcand_list[numMVPCandLX++] = mv_col;\n\n    }\n\n\n\n    mv->mv[LX] = mvpcand_list[mvp_lx_flag];\n\n}\n", "idx": 23276}
{"project": "FFmpeg", "commit_id": "c3ab0004ae4dffc32494ae84dd15cfaa909a7884", "target": 1, "func": "static inline void RENAME(yuv2packedX)(SwsContext *c, const int16_t *lumFilter, const int16_t **lumSrc, int lumFilterSize,\n\n                                       const int16_t *chrFilter, const int16_t **chrSrc, int chrFilterSize,\n\n                                       const int16_t **alpSrc, uint8_t *dest, int dstW, int dstY)\n\n{\n\n#if COMPILE_TEMPLATE_MMX\n\n    x86_reg dummy=0;\n\n    if(!(c->flags & SWS_BITEXACT)) {\n\n        if (c->flags & SWS_ACCURATE_RND) {\n\n            switch(c->dstFormat) {\n\n            case PIX_FMT_RGB32:\n\n                if (CONFIG_SWSCALE_ALPHA && c->alpPixBuf) {\n\n                    YSCALEYUV2PACKEDX_ACCURATE\n\n                    YSCALEYUV2RGBX\n\n                    \"movq                      %%mm2, \"U_TEMP\"(%0)  \\n\\t\"\n\n                    \"movq                      %%mm4, \"V_TEMP\"(%0)  \\n\\t\"\n\n                    \"movq                      %%mm5, \"Y_TEMP\"(%0)  \\n\\t\"\n\n                    YSCALEYUV2PACKEDX_ACCURATE_YA(ALP_MMX_FILTER_OFFSET)\n\n                    \"movq               \"Y_TEMP\"(%0), %%mm5         \\n\\t\"\n\n                    \"psraw                        $3, %%mm1         \\n\\t\"\n\n                    \"psraw                        $3, %%mm7         \\n\\t\"\n\n                    \"packuswb                  %%mm7, %%mm1         \\n\\t\"\n\n                    WRITEBGR32(%4, %5, %%REGa, %%mm3, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm2, %%mm6)\n\n\n\n                    YSCALEYUV2PACKEDX_END\n\n                } else {\n\n                    YSCALEYUV2PACKEDX_ACCURATE\n\n                    YSCALEYUV2RGBX\n\n                    \"pcmpeqd %%mm7, %%mm7 \\n\\t\"\n\n                    WRITEBGR32(%4, %5, %%REGa, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)\n\n\n\n                    YSCALEYUV2PACKEDX_END\n\n                }\n\n                return;\n\n            case PIX_FMT_BGR24:\n\n                YSCALEYUV2PACKEDX_ACCURATE\n\n                YSCALEYUV2RGBX\n\n                \"pxor %%mm7, %%mm7 \\n\\t\"\n\n                \"lea (%%\"REG_a\", %%\"REG_a\", 2), %%\"REG_c\"\\n\\t\" //FIXME optimize\n\n                \"add %4, %%\"REG_c\"                        \\n\\t\"\n\n                WRITEBGR24(%%REGc, %5, %%REGa)\n\n\n\n\n\n                :: \"r\" (&c->redDither),\n\n                \"m\" (dummy), \"m\" (dummy), \"m\" (dummy),\n\n                \"r\" (dest), \"m\" (dstW)\n\n                : \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S\n\n                );\n\n                return;\n\n            case PIX_FMT_RGB555:\n\n                YSCALEYUV2PACKEDX_ACCURATE\n\n                YSCALEYUV2RGBX\n\n                \"pxor %%mm7, %%mm7 \\n\\t\"\n\n                /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n                \"paddusb \"BLUE_DITHER\"(%0), %%mm2\\n\\t\"\n\n                \"paddusb \"GREEN_DITHER\"(%0), %%mm4\\n\\t\"\n\n                \"paddusb \"RED_DITHER\"(%0), %%mm5\\n\\t\"\n\n#endif\n\n\n\n                WRITERGB15(%4, %5, %%REGa)\n\n                YSCALEYUV2PACKEDX_END\n\n                return;\n\n            case PIX_FMT_RGB565:\n\n                YSCALEYUV2PACKEDX_ACCURATE\n\n                YSCALEYUV2RGBX\n\n                \"pxor %%mm7, %%mm7 \\n\\t\"\n\n                /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n                \"paddusb \"BLUE_DITHER\"(%0), %%mm2\\n\\t\"\n\n                \"paddusb \"GREEN_DITHER\"(%0), %%mm4\\n\\t\"\n\n                \"paddusb \"RED_DITHER\"(%0), %%mm5\\n\\t\"\n\n#endif\n\n\n\n                WRITERGB16(%4, %5, %%REGa)\n\n                YSCALEYUV2PACKEDX_END\n\n                return;\n\n            case PIX_FMT_YUYV422:\n\n                YSCALEYUV2PACKEDX_ACCURATE\n\n                /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n\n\n                \"psraw $3, %%mm3    \\n\\t\"\n\n                \"psraw $3, %%mm4    \\n\\t\"\n\n                \"psraw $3, %%mm1    \\n\\t\"\n\n                \"psraw $3, %%mm7    \\n\\t\"\n\n                WRITEYUY2(%4, %5, %%REGa)\n\n                YSCALEYUV2PACKEDX_END\n\n                return;\n\n            }\n\n        } else {\n\n            switch(c->dstFormat) {\n\n            case PIX_FMT_RGB32:\n\n                if (CONFIG_SWSCALE_ALPHA && c->alpPixBuf) {\n\n                    YSCALEYUV2PACKEDX\n\n                    YSCALEYUV2RGBX\n\n                    YSCALEYUV2PACKEDX_YA(ALP_MMX_FILTER_OFFSET, %%mm0, %%mm3, %%mm6, %%mm1, %%mm7)\n\n                    \"psraw                        $3, %%mm1         \\n\\t\"\n\n                    \"psraw                        $3, %%mm7         \\n\\t\"\n\n                    \"packuswb                  %%mm7, %%mm1         \\n\\t\"\n\n                    WRITEBGR32(%4, %5, %%REGa, %%mm2, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm3, %%mm6)\n\n                    YSCALEYUV2PACKEDX_END\n\n                } else {\n\n                    YSCALEYUV2PACKEDX\n\n                    YSCALEYUV2RGBX\n\n                    \"pcmpeqd %%mm7, %%mm7 \\n\\t\"\n\n                    WRITEBGR32(%4, %5, %%REGa, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)\n\n                    YSCALEYUV2PACKEDX_END\n\n                }\n\n                return;\n\n            case PIX_FMT_BGR24:\n\n                YSCALEYUV2PACKEDX\n\n                YSCALEYUV2RGBX\n\n                \"pxor                    %%mm7, %%mm7       \\n\\t\"\n\n                \"lea (%%\"REG_a\", %%\"REG_a\", 2), %%\"REG_c\"   \\n\\t\" //FIXME optimize\n\n                \"add                        %4, %%\"REG_c\"   \\n\\t\"\n\n                WRITEBGR24(%%REGc, %5, %%REGa)\n\n\n\n                :: \"r\" (&c->redDither),\n\n                \"m\" (dummy), \"m\" (dummy), \"m\" (dummy),\n\n                \"r\" (dest),  \"m\" (dstW)\n\n                : \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S\n\n                );\n\n                return;\n\n            case PIX_FMT_RGB555:\n\n                YSCALEYUV2PACKEDX\n\n                YSCALEYUV2RGBX\n\n                \"pxor %%mm7, %%mm7 \\n\\t\"\n\n                /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n                \"paddusb \"BLUE_DITHER\"(%0), %%mm2  \\n\\t\"\n\n                \"paddusb \"GREEN_DITHER\"(%0), %%mm4  \\n\\t\"\n\n                \"paddusb \"RED_DITHER\"(%0), %%mm5  \\n\\t\"\n\n#endif\n\n\n\n                WRITERGB15(%4, %5, %%REGa)\n\n                YSCALEYUV2PACKEDX_END\n\n                return;\n\n            case PIX_FMT_RGB565:\n\n                YSCALEYUV2PACKEDX\n\n                YSCALEYUV2RGBX\n\n                \"pxor %%mm7, %%mm7 \\n\\t\"\n\n                /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n                \"paddusb \"BLUE_DITHER\"(%0), %%mm2  \\n\\t\"\n\n                \"paddusb \"GREEN_DITHER\"(%0), %%mm4  \\n\\t\"\n\n                \"paddusb \"RED_DITHER\"(%0), %%mm5  \\n\\t\"\n\n#endif\n\n\n\n                WRITERGB16(%4, %5, %%REGa)\n\n                YSCALEYUV2PACKEDX_END\n\n                return;\n\n            case PIX_FMT_YUYV422:\n\n                YSCALEYUV2PACKEDX\n\n                /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n\n\n                \"psraw $3, %%mm3    \\n\\t\"\n\n                \"psraw $3, %%mm4    \\n\\t\"\n\n                \"psraw $3, %%mm1    \\n\\t\"\n\n                \"psraw $3, %%mm7    \\n\\t\"\n\n                WRITEYUY2(%4, %5, %%REGa)\n\n                YSCALEYUV2PACKEDX_END\n\n                return;\n\n            }\n\n        }\n\n    }\n\n#endif /* COMPILE_TEMPLATE_MMX */\n\n#if COMPILE_TEMPLATE_ALTIVEC\n\n    /* The following list of supported dstFormat values should\n\n       match what's found in the body of ff_yuv2packedX_altivec() */\n\n    if (!(c->flags & SWS_BITEXACT) && !c->alpPixBuf &&\n\n         (c->dstFormat==PIX_FMT_ABGR  || c->dstFormat==PIX_FMT_BGRA  ||\n\n          c->dstFormat==PIX_FMT_BGR24 || c->dstFormat==PIX_FMT_RGB24 ||\n\n          c->dstFormat==PIX_FMT_RGBA  || c->dstFormat==PIX_FMT_ARGB))\n\n            ff_yuv2packedX_altivec(c, lumFilter, lumSrc, lumFilterSize,\n\n                                   chrFilter, chrSrc, chrFilterSize,\n\n                                   dest, dstW, dstY);\n\n    else\n\n#endif\n\n        yuv2packedXinC(c, lumFilter, lumSrc, lumFilterSize,\n\n                       chrFilter, chrSrc, chrFilterSize,\n\n                       alpSrc, dest, dstW, dstY);\n\n}\n", "idx": 23279}
{"project": "FFmpeg", "commit_id": "b12d92efd6c0d48665383a9baecc13e7ebbd8a22", "target": 1, "func": "static int vqa_decode_chunk(VqaContext *s)\n\n{\n\n    unsigned int chunk_type;\n\n    unsigned int chunk_size;\n\n    int byte_skip;\n\n    unsigned int index = 0;\n\n    int i;\n\n    unsigned char r, g, b;\n\n    int index_shift;\n\n    int res;\n\n\n\n    int cbf0_chunk = -1;\n\n    int cbfz_chunk = -1;\n\n    int cbp0_chunk = -1;\n\n    int cbpz_chunk = -1;\n\n    int cpl0_chunk = -1;\n\n    int cplz_chunk = -1;\n\n    int vptz_chunk = -1;\n\n\n\n    int x, y;\n\n    int lines = 0;\n\n    int pixel_ptr;\n\n    int vector_index = 0;\n\n    int lobyte = 0;\n\n    int hibyte = 0;\n\n    int lobytes = 0;\n\n    int hibytes = s->decode_buffer_size / 2;\n\n\n\n    /* first, traverse through the frame and find the subchunks */\n\n    while (bytestream2_get_bytes_left(&s->gb) >= 8) {\n\n\n\n        chunk_type = bytestream2_get_be32u(&s->gb);\n\n        index      = bytestream2_tell(&s->gb);\n\n        chunk_size = bytestream2_get_be32u(&s->gb);\n\n\n\n        switch (chunk_type) {\n\n\n\n        case CBF0_TAG:\n\n            cbf0_chunk = index;\n\n            break;\n\n\n\n        case CBFZ_TAG:\n\n            cbfz_chunk = index;\n\n            break;\n\n\n\n        case CBP0_TAG:\n\n            cbp0_chunk = index;\n\n            break;\n\n\n\n        case CBPZ_TAG:\n\n            cbpz_chunk = index;\n\n            break;\n\n\n\n        case CPL0_TAG:\n\n            cpl0_chunk = index;\n\n            break;\n\n\n\n        case CPLZ_TAG:\n\n            cplz_chunk = index;\n\n            break;\n\n\n\n        case VPTZ_TAG:\n\n            vptz_chunk = index;\n\n            break;\n\n\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Found unknown chunk type: %c%c%c%c (%08X)\\n\",\n\n            (chunk_type >> 24) & 0xFF,\n\n            (chunk_type >> 16) & 0xFF,\n\n            (chunk_type >>  8) & 0xFF,\n\n            (chunk_type >>  0) & 0xFF,\n\n            chunk_type);\n\n            break;\n\n        }\n\n\n\n        byte_skip = chunk_size & 0x01;\n\n        bytestream2_skip(&s->gb, chunk_size + byte_skip);\n\n    }\n\n\n\n    /* next, deal with the palette */\n\n    if ((cpl0_chunk != -1) && (cplz_chunk != -1)) {\n\n\n\n        /* a chunk should not have both chunk types */\n\n        av_log(s->avctx, AV_LOG_ERROR, \"problem: found both CPL0 and CPLZ chunks\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* decompress the palette chunk */\n\n    if (cplz_chunk != -1) {\n\n\n\n/* yet to be handled */\n\n\n\n    }\n\n\n\n    /* convert the RGB palette into the machine's endian format */\n\n    if (cpl0_chunk != -1) {\n\n\n\n        bytestream2_seek(&s->gb, cpl0_chunk, SEEK_SET);\n\n        chunk_size = bytestream2_get_be32(&s->gb);\n\n        /* sanity check the palette size */\n\n        if (chunk_size / 3 > 256 || chunk_size > bytestream2_get_bytes_left(&s->gb)) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"problem: found a palette chunk with %d colors\\n\",\n\n                chunk_size / 3);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        for (i = 0; i < chunk_size / 3; i++) {\n\n            /* scale by 4 to transform 6-bit palette -> 8-bit */\n\n            r = bytestream2_get_byteu(&s->gb) * 4;\n\n            g = bytestream2_get_byteu(&s->gb) * 4;\n\n            b = bytestream2_get_byteu(&s->gb) * 4;\n\n            s->palette[i] = 0xFF << 24 | r << 16 | g << 8 | b;\n\n            s->palette[i] |= s->palette[i] >> 6 & 0x30303;\n\n        }\n\n    }\n\n\n\n    /* next, look for a full codebook */\n\n    if ((cbf0_chunk != -1) && (cbfz_chunk != -1)) {\n\n\n\n        /* a chunk should not have both chunk types */\n\n        av_log(s->avctx, AV_LOG_ERROR, \"problem: found both CBF0 and CBFZ chunks\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* decompress the full codebook chunk */\n\n    if (cbfz_chunk != -1) {\n\n\n\n        bytestream2_seek(&s->gb, cbfz_chunk, SEEK_SET);\n\n        chunk_size = bytestream2_get_be32(&s->gb);\n\n        if ((res = decode_format80(s, chunk_size, s->codebook,\n\n                                   s->codebook_size, 0)) < 0)\n\n            return res;\n\n    }\n\n\n\n    /* copy a full codebook */\n\n    if (cbf0_chunk != -1) {\n\n\n\n        bytestream2_seek(&s->gb, cbf0_chunk, SEEK_SET);\n\n        chunk_size = bytestream2_get_be32(&s->gb);\n\n        /* sanity check the full codebook size */\n\n        if (chunk_size > MAX_CODEBOOK_SIZE) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"problem: CBF0 chunk too large (0x%X bytes)\\n\",\n\n                chunk_size);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        bytestream2_get_buffer(&s->gb, s->codebook, chunk_size);\n\n    }\n\n\n\n    /* decode the frame */\n\n    if (vptz_chunk == -1) {\n\n\n\n        /* something is wrong if there is no VPTZ chunk */\n\n        av_log(s->avctx, AV_LOG_ERROR, \"problem: no VPTZ chunk found\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    bytestream2_seek(&s->gb, vptz_chunk, SEEK_SET);\n\n    chunk_size = bytestream2_get_be32(&s->gb);\n\n    if ((res = decode_format80(s, chunk_size,\n\n                               s->decode_buffer, s->decode_buffer_size, 1)) < 0)\n\n        return res;\n\n\n\n    /* render the final PAL8 frame */\n\n    if (s->vector_height == 4)\n\n        index_shift = 4;\n\n    else\n\n        index_shift = 3;\n\n    for (y = 0; y < s->height; y += s->vector_height) {\n\n        for (x = 0; x < s->width; x += 4, lobytes++, hibytes++) {\n\n            pixel_ptr = y * s->frame.linesize[0] + x;\n\n\n\n            /* get the vector index, the method for which varies according to\n\n             * VQA file version */\n\n            switch (s->vqa_version) {\n\n\n\n            case 1:\n\n                lobyte = s->decode_buffer[lobytes * 2];\n\n                hibyte = s->decode_buffer[(lobytes * 2) + 1];\n\n                vector_index = ((hibyte << 8) | lobyte) >> 3;\n\n                vector_index <<= index_shift;\n\n                lines = s->vector_height;\n\n                /* uniform color fill - a quick hack */\n\n                if (hibyte == 0xFF) {\n\n                    while (lines--) {\n\n                        s->frame.data[0][pixel_ptr + 0] = 255 - lobyte;\n\n                        s->frame.data[0][pixel_ptr + 1] = 255 - lobyte;\n\n                        s->frame.data[0][pixel_ptr + 2] = 255 - lobyte;\n\n                        s->frame.data[0][pixel_ptr + 3] = 255 - lobyte;\n\n                        pixel_ptr += s->frame.linesize[0];\n\n                    }\n\n                    lines=0;\n\n                }\n\n                break;\n\n\n\n            case 2:\n\n                lobyte = s->decode_buffer[lobytes];\n\n                hibyte = s->decode_buffer[hibytes];\n\n                vector_index = (hibyte << 8) | lobyte;\n\n                vector_index <<= index_shift;\n\n                lines = s->vector_height;\n\n                break;\n\n\n\n            case 3:\n\n/* not implemented yet */\n\n                lines = 0;\n\n                break;\n\n            }\n\n\n\n            while (lines--) {\n\n                s->frame.data[0][pixel_ptr + 0] = s->codebook[vector_index++];\n\n                s->frame.data[0][pixel_ptr + 1] = s->codebook[vector_index++];\n\n                s->frame.data[0][pixel_ptr + 2] = s->codebook[vector_index++];\n\n                s->frame.data[0][pixel_ptr + 3] = s->codebook[vector_index++];\n\n                pixel_ptr += s->frame.linesize[0];\n\n            }\n\n        }\n\n    }\n\n\n\n    /* handle partial codebook */\n\n    if ((cbp0_chunk != -1) && (cbpz_chunk != -1)) {\n\n        /* a chunk should not have both chunk types */\n\n        av_log(s->avctx, AV_LOG_ERROR, \"problem: found both CBP0 and CBPZ chunks\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (cbp0_chunk != -1) {\n\n\n\n        bytestream2_seek(&s->gb, cbp0_chunk, SEEK_SET);\n\n        chunk_size = bytestream2_get_be32(&s->gb);\n\n\n\n        /* accumulate partial codebook */\n\n        bytestream2_get_buffer(&s->gb, &s->next_codebook_buffer[s->next_codebook_buffer_index],\n\n                               chunk_size);\n\n        s->next_codebook_buffer_index += chunk_size;\n\n\n\n        s->partial_countdown--;\n\n        if (s->partial_countdown <= 0) {\n\n\n\n            /* time to replace codebook */\n\n            memcpy(s->codebook, s->next_codebook_buffer,\n\n                s->next_codebook_buffer_index);\n\n\n\n            /* reset accounting */\n\n            s->next_codebook_buffer_index = 0;\n\n            s->partial_countdown = s->partial_count;\n\n        }\n\n    }\n\n\n\n    if (cbpz_chunk != -1) {\n\n\n\n        bytestream2_seek(&s->gb, cbpz_chunk, SEEK_SET);\n\n        chunk_size = bytestream2_get_be32(&s->gb);\n\n\n\n        /* accumulate partial codebook */\n\n        bytestream2_get_buffer(&s->gb, &s->next_codebook_buffer[s->next_codebook_buffer_index],\n\n                               chunk_size);\n\n        s->next_codebook_buffer_index += chunk_size;\n\n\n\n        s->partial_countdown--;\n\n        if (s->partial_countdown <= 0) {\n\n            GetByteContext gb;\n\n\n\n            bytestream2_init(&gb, s->next_codebook_buffer, s->next_codebook_buffer_index);\n\n            /* decompress codebook */\n\n            if ((res = decode_format80(s, s->next_codebook_buffer_index,\n\n                                       s->codebook, s->codebook_size, 0)) < 0)\n\n                return res;\n\n\n\n            /* reset accounting */\n\n            s->next_codebook_buffer_index = 0;\n\n            s->partial_countdown = s->partial_count;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23281}
{"project": "FFmpeg", "commit_id": "8fb8d539a4c594a58df226bc1bd7a4d149f39424", "target": 1, "func": "static int hls_read(URLContext *h, uint8_t *buf, int size)\n\n{\n\n    HLSContext *s = h->priv_data;\n\n    const char *url;\n\n    int ret;\n\n    int64_t reload_interval;\n\n\n\nstart:\n\n    if (s->seg_hd) {\n\n        ret = ffurl_read(s->seg_hd, buf, size);\n\n        if (ret > 0)\n\n            return ret;\n\n    }\n\n    if (s->seg_hd) {\n\n        ffurl_close(s->seg_hd);\n\n        s->seg_hd = NULL;\n\n        s->cur_seq_no++;\n\n    }\n\n    reload_interval = s->n_segments > 0 ?\n\n                      s->segments[s->n_segments - 1]->duration :\n\n                      s->target_duration;\n\n    reload_interval *= 1000000;\n\nretry:\n\n    if (!s->finished) {\n\n        int64_t now = av_gettime();\n\n        if (now - s->last_load_time >= reload_interval) {\n\n            if ((ret = parse_playlist(h, s->playlisturl)) < 0)\n\n                return ret;\n\n            /* If we need to reload the playlist again below (if\n\n             * there's still no more segments), switch to a reload\n\n             * interval of half the target duration. */\n\n            reload_interval = s->target_duration * 500000;\n\n        }\n\n    }\n\n    if (s->cur_seq_no < s->start_seq_no) {\n\n        av_log(h, AV_LOG_WARNING,\n\n               \"skipping %d segments ahead, expired from playlist\\n\",\n\n               s->start_seq_no - s->cur_seq_no);\n\n        s->cur_seq_no = s->start_seq_no;\n\n    }\n\n    if (s->cur_seq_no - s->start_seq_no >= s->n_segments) {\n\n        if (s->finished)\n\n            return AVERROR_EOF;\n\n        while (av_gettime() - s->last_load_time < reload_interval) {\n\n            if (ff_check_interrupt(&h->interrupt_callback))\n\n                return AVERROR_EXIT;\n\n            av_usleep(100*1000);\n\n        }\n\n        goto retry;\n\n    }\n\n    url = s->segments[s->cur_seq_no - s->start_seq_no]->url,\n\n    av_log(h, AV_LOG_DEBUG, \"opening %s\\n\", url);\n\n    ret = ffurl_open(&s->seg_hd, url, AVIO_FLAG_READ,\n\n                     &h->interrupt_callback, NULL);\n\n    if (ret < 0) {\n\n        if (ff_check_interrupt(&h->interrupt_callback))\n\n            return AVERROR_EXIT;\n\n        av_log(h, AV_LOG_WARNING, \"Unable to open %s\\n\", url);\n\n        s->cur_seq_no++;\n\n        goto retry;\n\n    }\n\n    goto start;\n\n}\n", "idx": 23282}
{"project": "FFmpeg", "commit_id": "cec939597722663f322941b4c12e00a583e63504", "target": 1, "func": "static inline void ff_h264_biweight_WxH_mmx2(uint8_t *dst, uint8_t *src, int stride, int log2_denom, int weightd, int weights, int offsetd, int offsets, int w, int h)\n\n{\n\n    int x, y;\n\n    int offset = ((offsets + offsetd + 1) | 1) << log2_denom;\n\n    asm volatile(\n\n        \"movd    %0, %%mm3        \\n\\t\"\n\n        \"movd    %1, %%mm4        \\n\\t\"\n\n        \"movd    %2, %%mm5        \\n\\t\"\n\n        \"movd    %3, %%mm6        \\n\\t\"\n\n        \"pshufw  $0, %%mm3, %%mm3 \\n\\t\"\n\n        \"pshufw  $0, %%mm4, %%mm4 \\n\\t\"\n\n        \"pshufw  $0, %%mm5, %%mm5 \\n\\t\"\n\n        \"pxor    %%mm7, %%mm7     \\n\\t\"\n\n        :: \"g\"(weightd), \"g\"(weights), \"g\"(offset), \"g\"(log2_denom+1)\n\n    );\n\n    for(y=0; y<h; y++){\n\n        for(x=0; x<w; x+=4){\n\n            asm volatile(\n\n                \"movd      %0,    %%mm0 \\n\\t\"\n\n                \"movd      %1,    %%mm1 \\n\\t\"\n\n                \"punpcklbw %%mm7, %%mm0 \\n\\t\"\n\n                \"punpcklbw %%mm7, %%mm1 \\n\\t\"\n\n                \"pmullw    %%mm3, %%mm0 \\n\\t\"\n\n                \"pmullw    %%mm4, %%mm1 \\n\\t\"\n\n                \"paddw     %%mm5, %%mm0 \\n\\t\"\n\n                \"paddw     %%mm1, %%mm0 \\n\\t\"\n\n                \"psraw     %%mm6, %%mm0 \\n\\t\"\n\n                \"packuswb  %%mm0, %%mm0 \\n\\t\"\n\n                \"movd      %%mm0, %0    \\n\\t\"\n\n                : \"+m\"(*(uint32_t*)(dst+x))\n\n                :  \"m\"(*(uint32_t*)(src+x))\n\n            );\n\n        }\n\n        src += stride;\n\n        dst += stride;\n\n    }\n\n}\n", "idx": 23283}
{"project": "FFmpeg", "commit_id": "41ee459e88093a0b7ae13b8539ed9ccd0ebd0f0b", "target": 1, "func": "static int dpx_probe(AVProbeData *p)\n\n{\n\n    const uint8_t *b = p->buf;\n\n\n\n    if (AV_RN32(b) == AV_RN32(\"SDPX\") || AV_RN32(b) == AV_RN32(\"XPDS\"))\n\n        return AVPROBE_SCORE_EXTENSION + 1;\n\n    return 0;\n\n}\n", "idx": 23284}
{"project": "FFmpeg", "commit_id": "b69c2e0e6dab87bb90fece1d0de47c28394aa8e6", "target": 1, "func": "static int yop_read_seek(AVFormatContext *s, int stream_index,\n\n                         int64_t timestamp, int flags)\n\n{\n\n    YopDecContext *yop = s->priv_data;\n\n    int64_t frame_pos, pos_min, pos_max;\n\n    int frame_count;\n\n\n\n    av_free_packet(&yop->video_packet);\n\n\n\n    if (!stream_index)\n\n        return -1;\n\n\n\n    pos_min        = s->data_offset;\n\n    pos_max        = avio_size(s->pb) - yop->frame_size;\n\n    frame_count    = (pos_max - pos_min) / yop->frame_size;\n\n\n\n    timestamp      = FFMAX(0, FFMIN(frame_count, timestamp));\n\n\n\n    frame_pos      = timestamp * yop->frame_size + pos_min;\n\n    yop->odd_frame = timestamp & 1;\n\n\n\n    avio_seek(s->pb, frame_pos, SEEK_SET);\n\n    return 0;\n\n}\n", "idx": 23285}
{"project": "FFmpeg", "commit_id": "158763312f97dd1cf635114c52c550800eda83d2", "target": 0, "func": "static av_cold int frei0r_init(AVFilterContext *ctx,\n\n                               const char *dl_name, int type)\n\n{\n\n    Frei0rContext *frei0r = ctx->priv;\n\n    f0r_init_f            f0r_init;\n\n    f0r_get_plugin_info_f f0r_get_plugin_info;\n\n    f0r_plugin_info_t *pi;\n\n    char *path;\n\n    int ret = 0;\n\n\n\n    /* see: http://frei0r.dyne.org/codedoc/html/group__pluglocations.html */\n\n    if ((path = av_strdup(getenv(\"FREI0R_PATH\")))) {\n\n#ifdef _WIN32\n\n        const char *separator = \";\";\n\n#else\n\n        const char *separator = \":\";\n\n#endif\n\n        char *p, *ptr = NULL;\n\n        for (p = path; p = av_strtok(p, separator, &ptr); p = NULL) {\n\n            /* add additional trailing slash in case it is missing */\n\n            char *p1 = av_asprintf(\"%s/\", p);\n\n            if (!p1) {\n\n                av_free(path);\n\n                return AVERROR(ENOMEM);\n\n            }\n\n            ret = load_path(ctx, &frei0r->dl_handle, p1, dl_name);\n\n            av_free(p1);\n\n            if (ret < 0) {\n\n                av_free(path);\n\n                return ret;\n\n            }\n\n            if (frei0r->dl_handle)\n\n                break;\n\n        }\n\n        av_free(path);\n\n    }\n\n    if (!frei0r->dl_handle && (path = getenv(\"HOME\"))) {\n\n        char *prefix = av_asprintf(\"%s/.frei0r-1/lib/\", path);\n\n        if (!prefix)\n\n            return AVERROR(ENOMEM);\n\n        ret = load_path(ctx, &frei0r->dl_handle, prefix, dl_name);\n\n        av_free(prefix);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n    if (!frei0r->dl_handle) {\n\n        ret = load_path(ctx, &frei0r->dl_handle, \"/usr/local/lib/frei0r-1/\", dl_name);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n    if (!frei0r->dl_handle) {\n\n        ret = load_path(ctx, &frei0r->dl_handle, \"/usr/lib/frei0r-1/\", dl_name);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n    if (!frei0r->dl_handle) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Could not find module '%s'\\n\", dl_name);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (!(f0r_init                = load_sym(ctx, \"f0r_init\"           )) ||\n\n        !(f0r_get_plugin_info     = load_sym(ctx, \"f0r_get_plugin_info\")) ||\n\n        !(frei0r->get_param_info  = load_sym(ctx, \"f0r_get_param_info\" )) ||\n\n        !(frei0r->get_param_value = load_sym(ctx, \"f0r_get_param_value\")) ||\n\n        !(frei0r->set_param_value = load_sym(ctx, \"f0r_set_param_value\")) ||\n\n        !(frei0r->update          = load_sym(ctx, \"f0r_update\"         )) ||\n\n        !(frei0r->construct       = load_sym(ctx, \"f0r_construct\"      )) ||\n\n        !(frei0r->destruct        = load_sym(ctx, \"f0r_destruct\"       )) ||\n\n        !(frei0r->deinit          = load_sym(ctx, \"f0r_deinit\"         )))\n\n        return AVERROR(EINVAL);\n\n\n\n    if (f0r_init() < 0) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Could not init the frei0r module\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    f0r_get_plugin_info(&frei0r->plugin_info);\n\n    pi = &frei0r->plugin_info;\n\n    if (pi->plugin_type != type) {\n\n        av_log(ctx, AV_LOG_ERROR,\n\n               \"Invalid type '%s' for the plugin\\n\",\n\n               pi->plugin_type == F0R_PLUGIN_TYPE_FILTER ? \"filter\" :\n\n               pi->plugin_type == F0R_PLUGIN_TYPE_SOURCE ? \"source\" :\n\n               pi->plugin_type == F0R_PLUGIN_TYPE_MIXER2 ? \"mixer2\" :\n\n               pi->plugin_type == F0R_PLUGIN_TYPE_MIXER3 ? \"mixer3\" : \"unknown\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    av_log(ctx, AV_LOG_VERBOSE,\n\n           \"name:%s author:'%s' explanation:'%s' color_model:%s \"\n\n           \"frei0r_version:%d version:%d.%d num_params:%d\\n\",\n\n           pi->name, pi->author, pi->explanation,\n\n           pi->color_model == F0R_COLOR_MODEL_BGRA8888 ? \"bgra8888\" :\n\n           pi->color_model == F0R_COLOR_MODEL_RGBA8888 ? \"rgba8888\" :\n\n           pi->color_model == F0R_COLOR_MODEL_PACKED32 ? \"packed32\" : \"unknown\",\n\n           pi->frei0r_version, pi->major_version, pi->minor_version, pi->num_params);\n\n\n\n    return 0;\n\n}\n", "idx": 23286}
{"project": "FFmpeg", "commit_id": "ded5957d75def70d2f1fc1c1eae079230004974b", "target": 0, "func": "static int film_read_packet(AVFormatContext *s,\n\n                            AVPacket *pkt)\n\n{\n\n    FilmDemuxContext *film = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    film_sample *sample;\n\n    int ret = 0;\n\n    int i;\n\n    int left, right;\n\n\n\n    if (film->current_sample >= film->sample_count)\n\n        return AVERROR(EIO);\n\n\n\n    sample = &film->sample_table[film->current_sample];\n\n\n\n    /* position the stream (will probably be there anyway) */\n\n    avio_seek(pb, sample->sample_offset, SEEK_SET);\n\n\n\n    /* do a special song and dance when loading FILM Cinepak chunks */\n\n    if ((sample->stream == film->video_stream_index) &&\n\n        (film->video_type == AV_CODEC_ID_CINEPAK)) {\n\n        pkt->pos= avio_tell(pb);\n\n        if (av_new_packet(pkt, sample->sample_size))\n\n            return AVERROR(ENOMEM);\n\n        avio_read(pb, pkt->data, sample->sample_size);\n\n    } else if ((sample->stream == film->audio_stream_index) &&\n\n        (film->audio_channels == 2) &&\n\n        (film->audio_type != AV_CODEC_ID_ADPCM_ADX)) {\n\n        /* stereo PCM needs to be interleaved */\n\n\n\n        if (av_new_packet(pkt, sample->sample_size))\n\n            return AVERROR(ENOMEM);\n\n\n\n        /* make sure the interleave buffer is large enough */\n\n        if (sample->sample_size > film->stereo_buffer_size) {\n\n            av_free(film->stereo_buffer);\n\n            film->stereo_buffer_size = sample->sample_size;\n\n            film->stereo_buffer = av_malloc(film->stereo_buffer_size);\n\n            if (!film->stereo_buffer) {\n\n                film->stereo_buffer_size = 0;\n\n                return AVERROR(ENOMEM);\n\n            }\n\n        }\n\n\n\n        pkt->pos= avio_tell(pb);\n\n        ret = avio_read(pb, film->stereo_buffer, sample->sample_size);\n\n        if (ret != sample->sample_size)\n\n            ret = AVERROR(EIO);\n\n\n\n        left = 0;\n\n        right = sample->sample_size / 2;\n\n        for (i = 0; i < sample->sample_size; ) {\n\n            if (film->audio_bits == 8) {\n\n                pkt->data[i++] = film->stereo_buffer[left++];\n\n                pkt->data[i++] = film->stereo_buffer[right++];\n\n            } else {\n\n                pkt->data[i++] = film->stereo_buffer[left++];\n\n                pkt->data[i++] = film->stereo_buffer[left++];\n\n                pkt->data[i++] = film->stereo_buffer[right++];\n\n                pkt->data[i++] = film->stereo_buffer[right++];\n\n            }\n\n        }\n\n    } else {\n\n        ret= av_get_packet(pb, pkt, sample->sample_size);\n\n        if (ret != sample->sample_size)\n\n            ret = AVERROR(EIO);\n\n    }\n\n\n\n    pkt->stream_index = sample->stream;\n\n    pkt->pts = sample->pts;\n\n\n\n    film->current_sample++;\n\n\n\n    return ret;\n\n}\n", "idx": 23287}
{"project": "FFmpeg", "commit_id": "c3ab0004ae4dffc32494ae84dd15cfaa909a7884", "target": 1, "func": "static inline void RENAME(hcscale_fast)(SwsContext *c, int16_t *dst,\n\n                                        int dstWidth, const uint8_t *src1,\n\n                                        const uint8_t *src2, int srcW, int xInc)\n\n{\n\n#if ARCH_X86\n\n#if COMPILE_TEMPLATE_MMX2\n\n    int32_t *filterPos = c->hChrFilterPos;\n\n    int16_t *filter    = c->hChrFilter;\n\n    int     canMMX2BeUsed  = c->canMMX2BeUsed;\n\n    void    *mmx2FilterCode= c->chrMmx2FilterCode;\n\n    int i;\n\n#if defined(PIC)\n\n    DECLARE_ALIGNED(8, uint64_t, ebxsave);\n\n#endif\n\n    if (canMMX2BeUsed) {\n\n        __asm__ volatile(\n\n#if defined(PIC)\n\n            \"mov          %%\"REG_b\", %6         \\n\\t\"\n\n#endif\n\n            \"pxor             %%mm7, %%mm7      \\n\\t\"\n\n            \"mov                 %0, %%\"REG_c\"  \\n\\t\"\n\n            \"mov                 %1, %%\"REG_D\"  \\n\\t\"\n\n            \"mov                 %2, %%\"REG_d\"  \\n\\t\"\n\n            \"mov                 %3, %%\"REG_b\"  \\n\\t\"\n\n            \"xor          %%\"REG_a\", %%\"REG_a\"  \\n\\t\" // i\n\n            PREFETCH\"   (%%\"REG_c\")             \\n\\t\"\n\n            PREFETCH\" 32(%%\"REG_c\")             \\n\\t\"\n\n            PREFETCH\" 64(%%\"REG_c\")             \\n\\t\"\n\n\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            \"xor          %%\"REG_a\", %%\"REG_a\"  \\n\\t\" // i\n\n            \"mov                 %5, %%\"REG_c\"  \\n\\t\" // src\n\n            \"mov                 %1, %%\"REG_D\"  \\n\\t\" // buf1\n\n            \"add              $\"AV_STRINGIFY(VOF)\", %%\"REG_D\"  \\n\\t\"\n\n            PREFETCH\"   (%%\"REG_c\")             \\n\\t\"\n\n            PREFETCH\" 32(%%\"REG_c\")             \\n\\t\"\n\n            PREFETCH\" 64(%%\"REG_c\")             \\n\\t\"\n\n\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n\n\n#if defined(PIC)\n\n            \"mov %6, %%\"REG_b\"    \\n\\t\"\n\n#endif\n\n            :: \"m\" (src1), \"m\" (dst), \"m\" (filter), \"m\" (filterPos),\n\n            \"m\" (mmx2FilterCode), \"m\" (src2)\n\n#if defined(PIC)\n\n            ,\"m\" (ebxsave)\n\n#endif\n\n            : \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S, \"%\"REG_D\n\n#if !defined(PIC)\n\n            ,\"%\"REG_b\n\n#endif\n\n        );\n\n        for (i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--) {\n\n            //printf(\"%d %d %d\\n\", dstWidth, i, srcW);\n\n            dst[i] = src1[srcW-1]*128;\n\n            dst[i+VOFW] = src2[srcW-1]*128;\n\n        }\n\n    } else {\n\n#endif /* COMPILE_TEMPLATE_MMX2 */\n\n        x86_reg dstWidth_reg = dstWidth;\n\n        x86_reg xInc_shr16 = (x86_reg) (xInc >> 16);\n\n        uint16_t xInc_mask = xInc & 0xffff;\n\n        __asm__ volatile(\n\n            \"xor %%\"REG_a\", %%\"REG_a\"               \\n\\t\" // i\n\n            \"xor %%\"REG_d\", %%\"REG_d\"               \\n\\t\" // xx\n\n            \"xorl    %%ecx, %%ecx                   \\n\\t\" // xalpha\n\n            ASMALIGN(4)\n\n            \"1:                                     \\n\\t\"\n\n            \"mov        %0, %%\"REG_S\"               \\n\\t\"\n\n            \"movzbl  (%%\"REG_S\", %%\"REG_d\"), %%edi  \\n\\t\" //src[xx]\n\n            \"movzbl 1(%%\"REG_S\", %%\"REG_d\"), %%esi  \\n\\t\" //src[xx+1]\n\n            FAST_BILINEAR_X86\n\n            \"movw     %%si, (%%\"REG_D\", %%\"REG_a\", 2)   \\n\\t\"\n\n\n\n            \"movzbl    (%5, %%\"REG_d\"), %%edi       \\n\\t\" //src[xx]\n\n            \"movzbl   1(%5, %%\"REG_d\"), %%esi       \\n\\t\" //src[xx+1]\n\n            FAST_BILINEAR_X86\n\n            \"movw     %%si, \"AV_STRINGIFY(VOF)\"(%%\"REG_D\", %%\"REG_a\", 2)   \\n\\t\"\n\n\n\n            \"addw       %4, %%cx                    \\n\\t\" //xalpha += xInc&0xFFFF\n\n            \"adc        %3, %%\"REG_d\"               \\n\\t\" //xx+= xInc>>16 + carry\n\n            \"add        $1, %%\"REG_a\"               \\n\\t\"\n\n            \"cmp        %2, %%\"REG_a\"               \\n\\t\"\n\n            \" jb        1b                          \\n\\t\"\n\n\n\n/* GCC 3.3 makes MPlayer crash on IA-32 machines when using \"g\" operand here,\n\nwhich is needed to support GCC 4.0. */\n\n#if ARCH_X86_64 && AV_GCC_VERSION_AT_LEAST(3,4)\n\n            :: \"m\" (src1), \"m\" (dst), \"g\" (dstWidth_reg), \"m\" (xInc_shr16), \"m\" (xInc_mask),\n\n#else\n\n            :: \"m\" (src1), \"m\" (dst), \"m\" (dstWidth_reg), \"m\" (xInc_shr16), \"m\" (xInc_mask),\n\n#endif\n\n            \"r\" (src2)\n\n            : \"%\"REG_a, \"%\"REG_d, \"%ecx\", \"%\"REG_D, \"%esi\"\n\n        );\n\n#if COMPILE_TEMPLATE_MMX2\n\n    } //if MMX2 can't be used\n\n#endif\n\n#else\n\n    int i;\n\n    unsigned int xpos=0;\n\n    for (i=0;i<dstWidth;i++) {\n\n        register unsigned int xx=xpos>>16;\n\n        register unsigned int xalpha=(xpos&0xFFFF)>>9;\n\n        dst[i]=(src1[xx]*(xalpha^127)+src1[xx+1]*xalpha);\n\n        dst[i+VOFW]=(src2[xx]*(xalpha^127)+src2[xx+1]*xalpha);\n\n        /* slower\n\n        dst[i]= (src1[xx]<<7) + (src1[xx+1] - src1[xx])*xalpha;\n\n        dst[i+VOFW]=(src2[xx]<<7) + (src2[xx+1] - src2[xx])*xalpha;\n\n        */\n\n        xpos+=xInc;\n\n    }\n\n#endif /* ARCH_X86 */\n\n}\n", "idx": 23293}
{"project": "FFmpeg", "commit_id": "2d09cdbaf2f449ba23d54e97e94bd97ca22208c6", "target": 1, "func": "static int decode_mb_info(IVI45DecContext *ctx, IVIBandDesc *band,\n                          IVITile *tile, AVCodecContext *avctx)\n{\n    int         x, y, mv_x, mv_y, mv_delta, offs, mb_offset,\n                mv_scale, blks_per_mb;\n    IVIMbInfo   *mb, *ref_mb;\n    int         row_offset = band->mb_size * band->pitch;\n    mb     = tile->mbs;\n    ref_mb = tile->ref_mbs;\n    offs   = tile->ypos * band->pitch + tile->xpos;\n    if (!ref_mb &&\n        ((band->qdelta_present && band->inherit_qdelta) || band->inherit_mv))\n    /* scale factor for motion vectors */\n    mv_scale = (ctx->planes[0].bands[0].mb_size >> 3) - (band->mb_size >> 3);\n    mv_x = mv_y = 0;\n    for (y = tile->ypos; y < (tile->ypos + tile->height); y += band->mb_size) {\n        mb_offset = offs;\n        for (x = tile->xpos; x < (tile->xpos + tile->width); x += band->mb_size) {\n            mb->xpos     = x;\n            mb->ypos     = y;\n            mb->buf_offs = mb_offset;\n            if (get_bits1(&ctx->gb)) {\n                if (ctx->frame_type == FRAMETYPE_INTRA) {\n                    av_log(avctx, AV_LOG_ERROR, \"Empty macroblock in an INTRA picture!\\n\");\n                    return -1;\n                mb->type = 1; /* empty macroblocks are always INTER */\n                mb->cbp  = 0; /* all blocks are empty */\n                mb->q_delta = 0;\n                if (!band->plane && !band->band_num && (ctx->frame_flags & 8)) {\n                    mb->q_delta = get_vlc2(&ctx->gb, ctx->mb_vlc.tab->table,\n                                           IVI_VLC_BITS, 1);\n                    mb->q_delta = IVI_TOSIGNED(mb->q_delta);\n                mb->mv_x = mb->mv_y = 0; /* no motion vector coded */\n                if (band->inherit_mv){\n                    /* motion vector inheritance */\n                    if (mv_scale) {\n                        mb->mv_x = ivi_scale_mv(ref_mb->mv_x, mv_scale);\n                        mb->mv_y = ivi_scale_mv(ref_mb->mv_y, mv_scale);\n                    } else {\n                        mb->mv_x = ref_mb->mv_x;\n                        mb->mv_y = ref_mb->mv_y;\n            } else {\n                if (band->inherit_mv) {\n                    mb->type = ref_mb->type; /* copy mb_type from corresponding reference mb */\n                } else if (ctx->frame_type == FRAMETYPE_INTRA) {\n                    mb->type = 0; /* mb_type is always INTRA for intra-frames */\n                } else {\n                    mb->type = get_bits1(&ctx->gb);\n                blks_per_mb = band->mb_size != band->blk_size ? 4 : 1;\n                mb->cbp = get_bits(&ctx->gb, blks_per_mb);\n                mb->q_delta = 0;\n                if (band->qdelta_present) {\n                    if (band->inherit_qdelta) {\n                        if (ref_mb) mb->q_delta = ref_mb->q_delta;\n                    } else if (mb->cbp || (!band->plane && !band->band_num &&\n                                           (ctx->frame_flags & 8))) {\n                        mb->q_delta = get_vlc2(&ctx->gb, ctx->mb_vlc.tab->table,\n                                               IVI_VLC_BITS, 1);\n                        mb->q_delta = IVI_TOSIGNED(mb->q_delta);\n                if (!mb->type) {\n                    mb->mv_x = mb->mv_y = 0; /* there is no motion vector in intra-macroblocks */\n                } else {\n                    if (band->inherit_mv){\n                        /* motion vector inheritance */\n                        if (mv_scale) {\n                            mb->mv_x = ivi_scale_mv(ref_mb->mv_x, mv_scale);\n                            mb->mv_y = ivi_scale_mv(ref_mb->mv_y, mv_scale);\n                        } else {\n                            mb->mv_x = ref_mb->mv_x;\n                            mb->mv_y = ref_mb->mv_y;\n                    } else {\n                        /* decode motion vector deltas */\n                        mv_delta = get_vlc2(&ctx->gb, ctx->mb_vlc.tab->table,\n                                            IVI_VLC_BITS, 1);\n                        mv_y += IVI_TOSIGNED(mv_delta);\n                        mv_delta = get_vlc2(&ctx->gb, ctx->mb_vlc.tab->table,\n                                            IVI_VLC_BITS, 1);\n                        mv_x += IVI_TOSIGNED(mv_delta);\n                        mb->mv_x = mv_x;\n                        mb->mv_y = mv_y;\n            mb++;\n            if (ref_mb)\n                ref_mb++;\n            mb_offset += band->mb_size;\n        offs += row_offset;\n    align_get_bits(&ctx->gb);\n    return 0;", "idx": 23294}
{"project": "FFmpeg", "commit_id": "180a0b1bcb522dab0ad828d8efb9673a6531d534", "target": 1, "func": "static void decode_nal_sei_frame_packing_arrangement(HEVCContext *s)\n\n{\n\n    GetBitContext *gb = &s->HEVClc->gb;\n\n    int cancel, type, quincunx, content;\n\n\n\n    get_ue_golomb(gb);                  // frame_packing_arrangement_id\n\n    cancel = get_bits1(gb);             // frame_packing_cancel_flag\n\n    if (cancel == 0) {\n\n        type     = get_bits(gb, 7);     // frame_packing_arrangement_type\n\n        quincunx = get_bits1(gb);       // quincunx_sampling_flag\n\n        content  = get_bits(gb, 6);     // content_interpretation_type\n\n\n\n        // the following skips spatial_flipping_flag frame0_flipped_flag\n\n        // field_views_flag current_frame_is_frame0_flag\n\n        // frame0_self_contained_flag frame1_self_contained_flag\n\n        skip_bits(gb, 6);\n\n\n\n        if (quincunx == 0 && type != 5)\n\n            skip_bits(gb, 16);  // frame[01]_grid_position_[xy]\n\n        skip_bits(gb, 8);       // frame_packing_arrangement_reserved_byte\n\n        skip_bits1(gb);         // frame_packing_arrangement_persistance_flag\n\n    }\n\n    skip_bits1(gb);             // upsampled_aspect_ratio_flag\n\n\n\n    s->sei_frame_packing_present      = (cancel == 0);\n\n    s->frame_packing_arrangement_type = type;\n\n    s->content_interpretation_type    = content;\n\n    s->quincunx_subsampling           = quincunx;\n\n}\n", "idx": 23295}
{"project": "FFmpeg", "commit_id": "042ef4b720f5d3321d9b7eeeb2067c671d5aeefd", "target": 1, "func": "static int decode_mb_cavlc(H264Context *h){\n\n    MpegEncContext * const s = &h->s;\n\n    const int mb_xy= s->mb_x + s->mb_y*s->mb_stride;\n\n    int partition_count;\n\n    unsigned int mb_type, cbp;\n\n    int dct8x8_allowed= h->pps.transform_8x8_mode;\n\n\n\n    s->dsp.clear_blocks(h->mb); //FIXME avoid if already clear (move after skip handlong?\n\n\n\n    tprintf(s->avctx, \"pic:%d mb:%d/%d\\n\", h->frame_num, s->mb_x, s->mb_y);\n\n    cbp = 0; /* avoid warning. FIXME: find a solution without slowing\n\n                down the code */\n\n    if(h->slice_type != I_TYPE && h->slice_type != SI_TYPE){\n\n        if(s->mb_skip_run==-1)\n\n            s->mb_skip_run= get_ue_golomb(&s->gb);\n\n\n\n        if (s->mb_skip_run--) {\n\n            if(FRAME_MBAFF && (s->mb_y&1) == 0){\n\n                if(s->mb_skip_run==0)\n\n                    h->mb_mbaff = h->mb_field_decoding_flag = get_bits1(&s->gb);\n\n                else\n\n                    predict_field_decoding_flag(h);\n\n            }\n\n            decode_mb_skip(h);\n\n            return 0;\n\n        }\n\n    }\n\n    if(FRAME_MBAFF){\n\n        if( (s->mb_y&1) == 0 )\n\n            h->mb_mbaff = h->mb_field_decoding_flag = get_bits1(&s->gb);\n\n    }else\n\n        h->mb_field_decoding_flag= (s->picture_structure!=PICT_FRAME);\n\n\n\n    h->prev_mb_skipped= 0;\n\n\n\n    mb_type= get_ue_golomb(&s->gb);\n\n    if(h->slice_type == B_TYPE){\n\n        if(mb_type < 23){\n\n            partition_count= b_mb_type_info[mb_type].partition_count;\n\n            mb_type=         b_mb_type_info[mb_type].type;\n\n        }else{\n\n            mb_type -= 23;\n\n            goto decode_intra_mb;\n\n        }\n\n    }else if(h->slice_type == P_TYPE /*|| h->slice_type == SP_TYPE */){\n\n        if(mb_type < 5){\n\n            partition_count= p_mb_type_info[mb_type].partition_count;\n\n            mb_type=         p_mb_type_info[mb_type].type;\n\n        }else{\n\n            mb_type -= 5;\n\n            goto decode_intra_mb;\n\n        }\n\n    }else{\n\n       assert(h->slice_type == I_TYPE);\n\ndecode_intra_mb:\n\n        if(mb_type > 25){\n\n            av_log(h->s.avctx, AV_LOG_ERROR, \"mb_type %d in %c slice too large at %d %d\\n\", mb_type, av_get_pict_type_char(h->slice_type), s->mb_x, s->mb_y);\n\n            return -1;\n\n        }\n\n        partition_count=0;\n\n        cbp= i_mb_type_info[mb_type].cbp;\n\n        h->intra16x16_pred_mode= i_mb_type_info[mb_type].pred_mode;\n\n        mb_type= i_mb_type_info[mb_type].type;\n\n    }\n\n\n\n    if(MB_FIELD)\n\n        mb_type |= MB_TYPE_INTERLACED;\n\n\n\n    h->slice_table[ mb_xy ]= h->slice_num;\n\n\n\n    if(IS_INTRA_PCM(mb_type)){\n\n        unsigned int x, y;\n\n\n\n        // We assume these blocks are very rare so we do not optimize it.\n\n        align_get_bits(&s->gb);\n\n\n\n        // The pixels are stored in the same order as levels in h->mb array.\n\n        for(y=0; y<16; y++){\n\n            const int index= 4*(y&3) + 32*((y>>2)&1) + 128*(y>>3);\n\n            for(x=0; x<16; x++){\n\n                tprintf(s->avctx, \"LUMA ICPM LEVEL (%3d)\\n\", show_bits(&s->gb, 8));\n\n                h->mb[index + (x&3) + 16*((x>>2)&1) + 64*(x>>3)]= get_bits(&s->gb, 8);\n\n            }\n\n        }\n\n        for(y=0; y<8; y++){\n\n            const int index= 256 + 4*(y&3) + 32*(y>>2);\n\n            for(x=0; x<8; x++){\n\n                tprintf(s->avctx, \"CHROMA U ICPM LEVEL (%3d)\\n\", show_bits(&s->gb, 8));\n\n                h->mb[index + (x&3) + 16*(x>>2)]= get_bits(&s->gb, 8);\n\n            }\n\n        }\n\n        for(y=0; y<8; y++){\n\n            const int index= 256 + 64 + 4*(y&3) + 32*(y>>2);\n\n            for(x=0; x<8; x++){\n\n                tprintf(s->avctx, \"CHROMA V ICPM LEVEL (%3d)\\n\", show_bits(&s->gb, 8));\n\n                h->mb[index + (x&3) + 16*(x>>2)]= get_bits(&s->gb, 8);\n\n            }\n\n        }\n\n\n\n        // In deblocking, the quantizer is 0\n\n        s->current_picture.qscale_table[mb_xy]= 0;\n\n        h->chroma_qp = get_chroma_qp(h->pps.chroma_qp_index_offset, 0);\n\n        // All coeffs are present\n\n        memset(h->non_zero_count[mb_xy], 16, 16);\n\n\n\n        s->current_picture.mb_type[mb_xy]= mb_type;\n\n        return 0;\n\n    }\n\n\n\n    if(MB_MBAFF){\n\n        h->ref_count[0] <<= 1;\n\n        h->ref_count[1] <<= 1;\n\n    }\n\n\n\n    fill_caches(h, mb_type, 0);\n\n\n\n    //mb_pred\n\n    if(IS_INTRA(mb_type)){\n\n            int pred_mode;\n\n//            init_top_left_availability(h);\n\n            if(IS_INTRA4x4(mb_type)){\n\n                int i;\n\n                int di = 1;\n\n                if(dct8x8_allowed && get_bits1(&s->gb)){\n\n                    mb_type |= MB_TYPE_8x8DCT;\n\n                    di = 4;\n\n                }\n\n\n\n//                fill_intra4x4_pred_table(h);\n\n                for(i=0; i<16; i+=di){\n\n                    int mode= pred_intra_mode(h, i);\n\n\n\n                    if(!get_bits1(&s->gb)){\n\n                        const int rem_mode= get_bits(&s->gb, 3);\n\n                        mode = rem_mode + (rem_mode >= mode);\n\n                    }\n\n\n\n                    if(di==4)\n\n                        fill_rectangle( &h->intra4x4_pred_mode_cache[ scan8[i] ], 2, 2, 8, mode, 1 );\n\n                    else\n\n                        h->intra4x4_pred_mode_cache[ scan8[i] ] = mode;\n\n                }\n\n                write_back_intra_pred_mode(h);\n\n                if( check_intra4x4_pred_mode(h) < 0)\n\n                    return -1;\n\n            }else{\n\n                h->intra16x16_pred_mode= check_intra_pred_mode(h, h->intra16x16_pred_mode);\n\n                if(h->intra16x16_pred_mode < 0)\n\n                    return -1;\n\n            }\n\n\n\n            pred_mode= check_intra_pred_mode(h, get_ue_golomb(&s->gb));\n\n            if(pred_mode < 0)\n\n                return -1;\n\n            h->chroma_pred_mode= pred_mode;\n\n    }else if(partition_count==4){\n\n        int i, j, sub_partition_count[4], list, ref[2][4];\n\n\n\n        if(h->slice_type == B_TYPE){\n\n            for(i=0; i<4; i++){\n\n                h->sub_mb_type[i]= get_ue_golomb(&s->gb);\n\n                if(h->sub_mb_type[i] >=13){\n\n                    av_log(h->s.avctx, AV_LOG_ERROR, \"B sub_mb_type %u out of range at %d %d\\n\", h->sub_mb_type[i], s->mb_x, s->mb_y);\n\n                    return -1;\n\n                }\n\n                sub_partition_count[i]= b_sub_mb_type_info[ h->sub_mb_type[i] ].partition_count;\n\n                h->sub_mb_type[i]=      b_sub_mb_type_info[ h->sub_mb_type[i] ].type;\n\n            }\n\n            if(   IS_DIRECT(h->sub_mb_type[0]) || IS_DIRECT(h->sub_mb_type[1])\n\n               || IS_DIRECT(h->sub_mb_type[2]) || IS_DIRECT(h->sub_mb_type[3])) {\n\n                pred_direct_motion(h, &mb_type);\n\n                h->ref_cache[0][scan8[4]] =\n\n                h->ref_cache[1][scan8[4]] =\n\n                h->ref_cache[0][scan8[12]] =\n\n                h->ref_cache[1][scan8[12]] = PART_NOT_AVAILABLE;\n\n            }\n\n        }else{\n\n            assert(h->slice_type == P_TYPE || h->slice_type == SP_TYPE); //FIXME SP correct ?\n\n            for(i=0; i<4; i++){\n\n                h->sub_mb_type[i]= get_ue_golomb(&s->gb);\n\n                if(h->sub_mb_type[i] >=4){\n\n                    av_log(h->s.avctx, AV_LOG_ERROR, \"P sub_mb_type %u out of range at %d %d\\n\", h->sub_mb_type[i], s->mb_x, s->mb_y);\n\n                    return -1;\n\n                }\n\n                sub_partition_count[i]= p_sub_mb_type_info[ h->sub_mb_type[i] ].partition_count;\n\n                h->sub_mb_type[i]=      p_sub_mb_type_info[ h->sub_mb_type[i] ].type;\n\n            }\n\n        }\n\n\n\n        for(list=0; list<h->list_count; list++){\n\n            int ref_count= IS_REF0(mb_type) ? 1 : h->ref_count[list];\n\n            for(i=0; i<4; i++){\n\n                if(IS_DIRECT(h->sub_mb_type[i])) continue;\n\n                if(IS_DIR(h->sub_mb_type[i], 0, list)){\n\n                    unsigned int tmp = get_te0_golomb(&s->gb, ref_count); //FIXME init to 0 before and skip?\n\n                    if(tmp>=ref_count){\n\n                        av_log(h->s.avctx, AV_LOG_ERROR, \"ref %u overflow\\n\", tmp);\n\n                        return -1;\n\n                    }\n\n                    ref[list][i]= tmp;\n\n                }else{\n\n                 //FIXME\n\n                    ref[list][i] = -1;\n\n                }\n\n            }\n\n        }\n\n\n\n        if(dct8x8_allowed)\n\n            dct8x8_allowed = get_dct8x8_allowed(h);\n\n\n\n        for(list=0; list<h->list_count; list++){\n\n            for(i=0; i<4; i++){\n\n                if(IS_DIRECT(h->sub_mb_type[i])) {\n\n                    h->ref_cache[list][ scan8[4*i] ] = h->ref_cache[list][ scan8[4*i]+1 ];\n\n                    continue;\n\n                }\n\n                h->ref_cache[list][ scan8[4*i]   ]=h->ref_cache[list][ scan8[4*i]+1 ]=\n\n                h->ref_cache[list][ scan8[4*i]+8 ]=h->ref_cache[list][ scan8[4*i]+9 ]= ref[list][i];\n\n\n\n                if(IS_DIR(h->sub_mb_type[i], 0, list)){\n\n                    const int sub_mb_type= h->sub_mb_type[i];\n\n                    const int block_width= (sub_mb_type & (MB_TYPE_16x16|MB_TYPE_16x8)) ? 2 : 1;\n\n                    for(j=0; j<sub_partition_count[i]; j++){\n\n                        int mx, my;\n\n                        const int index= 4*i + block_width*j;\n\n                        int16_t (* mv_cache)[2]= &h->mv_cache[list][ scan8[index] ];\n\n                        pred_motion(h, index, block_width, list, h->ref_cache[list][ scan8[index] ], &mx, &my);\n\n                        mx += get_se_golomb(&s->gb);\n\n                        my += get_se_golomb(&s->gb);\n\n                        tprintf(s->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        if(IS_SUB_8X8(sub_mb_type)){\n\n                            mv_cache[ 1 ][0]=\n\n                            mv_cache[ 8 ][0]= mv_cache[ 9 ][0]= mx;\n\n                            mv_cache[ 1 ][1]=\n\n                            mv_cache[ 8 ][1]= mv_cache[ 9 ][1]= my;\n\n                        }else if(IS_SUB_8X4(sub_mb_type)){\n\n                            mv_cache[ 1 ][0]= mx;\n\n                            mv_cache[ 1 ][1]= my;\n\n                        }else if(IS_SUB_4X8(sub_mb_type)){\n\n                            mv_cache[ 8 ][0]= mx;\n\n                            mv_cache[ 8 ][1]= my;\n\n                        }\n\n                        mv_cache[ 0 ][0]= mx;\n\n                        mv_cache[ 0 ][1]= my;\n\n                    }\n\n                }else{\n\n                    uint32_t *p= (uint32_t *)&h->mv_cache[list][ scan8[4*i] ][0];\n\n                    p[0] = p[1]=\n\n                    p[8] = p[9]= 0;\n\n                }\n\n            }\n\n        }\n\n    }else if(IS_DIRECT(mb_type)){\n\n        pred_direct_motion(h, &mb_type);\n\n        dct8x8_allowed &= h->sps.direct_8x8_inference_flag;\n\n    }else{\n\n        int list, mx, my, i;\n\n         //FIXME we should set ref_idx_l? to 0 if we use that later ...\n\n        if(IS_16X16(mb_type)){\n\n            for(list=0; list<h->list_count; list++){\n\n                    unsigned int val;\n\n                    if(IS_DIR(mb_type, 0, list)){\n\n                        val= get_te0_golomb(&s->gb, h->ref_count[list]);\n\n                        if(val >= h->ref_count[list]){\n\n                            av_log(h->s.avctx, AV_LOG_ERROR, \"ref %u overflow\\n\", val);\n\n                            return -1;\n\n                        }\n\n                    }else\n\n                        val= LIST_NOT_USED&0xFF;\n\n                    fill_rectangle(&h->ref_cache[list][ scan8[0] ], 4, 4, 8, val, 1);\n\n            }\n\n            for(list=0; list<h->list_count; list++){\n\n                unsigned int val;\n\n                if(IS_DIR(mb_type, 0, list)){\n\n                    pred_motion(h, 0, 4, list, h->ref_cache[list][ scan8[0] ], &mx, &my);\n\n                    mx += get_se_golomb(&s->gb);\n\n                    my += get_se_golomb(&s->gb);\n\n                    tprintf(s->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                    val= pack16to32(mx,my);\n\n                }else\n\n                    val=0;\n\n                fill_rectangle(h->mv_cache[list][ scan8[0] ], 4, 4, 8, val, 4);\n\n            }\n\n        }\n\n        else if(IS_16X8(mb_type)){\n\n            for(list=0; list<h->list_count; list++){\n\n                    for(i=0; i<2; i++){\n\n                        unsigned int val;\n\n                        if(IS_DIR(mb_type, i, list)){\n\n                            val= get_te0_golomb(&s->gb, h->ref_count[list]);\n\n                            if(val >= h->ref_count[list]){\n\n                                av_log(h->s.avctx, AV_LOG_ERROR, \"ref %u overflow\\n\", val);\n\n                                return -1;\n\n                            }\n\n                        }else\n\n                            val= LIST_NOT_USED&0xFF;\n\n                        fill_rectangle(&h->ref_cache[list][ scan8[0] + 16*i ], 4, 2, 8, val, 1);\n\n                    }\n\n            }\n\n            for(list=0; list<h->list_count; list++){\n\n                for(i=0; i<2; i++){\n\n                    unsigned int val;\n\n                    if(IS_DIR(mb_type, i, list)){\n\n                        pred_16x8_motion(h, 8*i, list, h->ref_cache[list][scan8[0] + 16*i], &mx, &my);\n\n                        mx += get_se_golomb(&s->gb);\n\n                        my += get_se_golomb(&s->gb);\n\n                        tprintf(s->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        val= pack16to32(mx,my);\n\n                    }else\n\n                        val=0;\n\n                    fill_rectangle(h->mv_cache[list][ scan8[0] + 16*i ], 4, 2, 8, val, 4);\n\n                }\n\n            }\n\n        }else{\n\n            assert(IS_8X16(mb_type));\n\n            for(list=0; list<h->list_count; list++){\n\n                    for(i=0; i<2; i++){\n\n                        unsigned int val;\n\n                        if(IS_DIR(mb_type, i, list)){ //FIXME optimize\n\n                            val= get_te0_golomb(&s->gb, h->ref_count[list]);\n\n                            if(val >= h->ref_count[list]){\n\n                                av_log(h->s.avctx, AV_LOG_ERROR, \"ref %u overflow\\n\", val);\n\n                                return -1;\n\n                            }\n\n                        }else\n\n                            val= LIST_NOT_USED&0xFF;\n\n                        fill_rectangle(&h->ref_cache[list][ scan8[0] + 2*i ], 2, 4, 8, val, 1);\n\n                    }\n\n            }\n\n            for(list=0; list<h->list_count; list++){\n\n                for(i=0; i<2; i++){\n\n                    unsigned int val;\n\n                    if(IS_DIR(mb_type, i, list)){\n\n                        pred_8x16_motion(h, i*4, list, h->ref_cache[list][ scan8[0] + 2*i ], &mx, &my);\n\n                        mx += get_se_golomb(&s->gb);\n\n                        my += get_se_golomb(&s->gb);\n\n                        tprintf(s->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        val= pack16to32(mx,my);\n\n                    }else\n\n                        val=0;\n\n                    fill_rectangle(h->mv_cache[list][ scan8[0] + 2*i ], 2, 4, 8, val, 4);\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    if(IS_INTER(mb_type))\n\n        write_back_motion(h, mb_type);\n\n\n\n    if(!IS_INTRA16x16(mb_type)){\n\n        cbp= get_ue_golomb(&s->gb);\n\n        if(cbp > 47){\n\n            av_log(h->s.avctx, AV_LOG_ERROR, \"cbp too large (%u) at %d %d\\n\", cbp, s->mb_x, s->mb_y);\n\n            return -1;\n\n        }\n\n\n\n        if(IS_INTRA4x4(mb_type))\n\n            cbp= golomb_to_intra4x4_cbp[cbp];\n\n        else\n\n            cbp= golomb_to_inter_cbp[cbp];\n\n    }\n\n    h->cbp = cbp;\n\n\n\n    if(dct8x8_allowed && (cbp&15) && !IS_INTRA(mb_type)){\n\n        if(get_bits1(&s->gb))\n\n            mb_type |= MB_TYPE_8x8DCT;\n\n    }\n\n    s->current_picture.mb_type[mb_xy]= mb_type;\n\n\n\n    if(cbp || IS_INTRA16x16(mb_type)){\n\n        int i8x8, i4x4, chroma_idx;\n\n        int chroma_qp, dquant;\n\n        GetBitContext *gb= IS_INTRA(mb_type) ? h->intra_gb_ptr : h->inter_gb_ptr;\n\n        const uint8_t *scan, *scan8x8, *dc_scan;\n\n\n\n//        fill_non_zero_count_cache(h);\n\n\n\n        if(IS_INTERLACED(mb_type)){\n\n            scan8x8= s->qscale ? h->field_scan8x8_cavlc : h->field_scan8x8_cavlc_q0;\n\n            scan= s->qscale ? h->field_scan : h->field_scan_q0;\n\n            dc_scan= luma_dc_field_scan;\n\n        }else{\n\n            scan8x8= s->qscale ? h->zigzag_scan8x8_cavlc : h->zigzag_scan8x8_cavlc_q0;\n\n            scan= s->qscale ? h->zigzag_scan : h->zigzag_scan_q0;\n\n            dc_scan= luma_dc_zigzag_scan;\n\n        }\n\n\n\n        dquant= get_se_golomb(&s->gb);\n\n\n\n        if( dquant > 25 || dquant < -26 ){\n\n            av_log(h->s.avctx, AV_LOG_ERROR, \"dquant out of range (%d) at %d %d\\n\", dquant, s->mb_x, s->mb_y);\n\n            return -1;\n\n        }\n\n\n\n        s->qscale += dquant;\n\n        if(((unsigned)s->qscale) > 51){\n\n            if(s->qscale<0) s->qscale+= 52;\n\n            else            s->qscale-= 52;\n\n        }\n\n\n\n        h->chroma_qp= chroma_qp= get_chroma_qp(h->pps.chroma_qp_index_offset, s->qscale);\n\n        if(IS_INTRA16x16(mb_type)){\n\n            if( decode_residual(h, h->intra_gb_ptr, h->mb, LUMA_DC_BLOCK_INDEX, dc_scan, h->dequant4_coeff[0][s->qscale], 16) < 0){\n\n                return -1; //FIXME continue if partitioned and other return -1 too\n\n            }\n\n\n\n            assert((cbp&15) == 0 || (cbp&15) == 15);\n\n\n\n            if(cbp&15){\n\n                for(i8x8=0; i8x8<4; i8x8++){\n\n                    for(i4x4=0; i4x4<4; i4x4++){\n\n                        const int index= i4x4 + 4*i8x8;\n\n                        if( decode_residual(h, h->intra_gb_ptr, h->mb + 16*index, index, scan + 1, h->dequant4_coeff[0][s->qscale], 15) < 0 ){\n\n                            return -1;\n\n                        }\n\n                    }\n\n                }\n\n            }else{\n\n                fill_rectangle(&h->non_zero_count_cache[scan8[0]], 4, 4, 8, 0, 1);\n\n            }\n\n        }else{\n\n            for(i8x8=0; i8x8<4; i8x8++){\n\n                if(cbp & (1<<i8x8)){\n\n                    if(IS_8x8DCT(mb_type)){\n\n                        DCTELEM *buf = &h->mb[64*i8x8];\n\n                        uint8_t *nnz;\n\n                        for(i4x4=0; i4x4<4; i4x4++){\n\n                            if( decode_residual(h, gb, buf, i4x4+4*i8x8, scan8x8+16*i4x4,\n\n                                                h->dequant8_coeff[IS_INTRA( mb_type ) ? 0:1][s->qscale], 16) <0 )\n\n                                return -1;\n\n                        }\n\n                        nnz= &h->non_zero_count_cache[ scan8[4*i8x8] ];\n\n                        nnz[0] += nnz[1] + nnz[8] + nnz[9];\n\n                    }else{\n\n                        for(i4x4=0; i4x4<4; i4x4++){\n\n                            const int index= i4x4 + 4*i8x8;\n\n\n\n                            if( decode_residual(h, gb, h->mb + 16*index, index, scan, h->dequant4_coeff[IS_INTRA( mb_type ) ? 0:3][s->qscale], 16) <0 ){\n\n                                return -1;\n\n                            }\n\n                        }\n\n                    }\n\n                }else{\n\n                    uint8_t * const nnz= &h->non_zero_count_cache[ scan8[4*i8x8] ];\n\n                    nnz[0] = nnz[1] = nnz[8] = nnz[9] = 0;\n\n                }\n\n            }\n\n        }\n\n\n\n        if(cbp&0x30){\n\n            for(chroma_idx=0; chroma_idx<2; chroma_idx++)\n\n                if( decode_residual(h, gb, h->mb + 256 + 16*4*chroma_idx, CHROMA_DC_BLOCK_INDEX, chroma_dc_scan, NULL, 4) < 0){\n\n                    return -1;\n\n                }\n\n        }\n\n\n\n        if(cbp&0x20){\n\n            for(chroma_idx=0; chroma_idx<2; chroma_idx++){\n\n                const uint32_t *qmul = h->dequant4_coeff[chroma_idx+1+(IS_INTRA( mb_type ) ? 0:3)][chroma_qp];\n\n                for(i4x4=0; i4x4<4; i4x4++){\n\n                    const int index= 16 + 4*chroma_idx + i4x4;\n\n                    if( decode_residual(h, gb, h->mb + 16*index, index, scan + 1, qmul, 15) < 0){\n\n                        return -1;\n\n                    }\n\n                }\n\n            }\n\n        }else{\n\n            uint8_t * const nnz= &h->non_zero_count_cache[0];\n\n            nnz[ scan8[16]+0 ] = nnz[ scan8[16]+1 ] =nnz[ scan8[16]+8 ] =nnz[ scan8[16]+9 ] =\n\n            nnz[ scan8[20]+0 ] = nnz[ scan8[20]+1 ] =nnz[ scan8[20]+8 ] =nnz[ scan8[20]+9 ] = 0;\n\n        }\n\n    }else{\n\n        uint8_t * const nnz= &h->non_zero_count_cache[0];\n\n        fill_rectangle(&nnz[scan8[0]], 4, 4, 8, 0, 1);\n\n        nnz[ scan8[16]+0 ] = nnz[ scan8[16]+1 ] =nnz[ scan8[16]+8 ] =nnz[ scan8[16]+9 ] =\n\n        nnz[ scan8[20]+0 ] = nnz[ scan8[20]+1 ] =nnz[ scan8[20]+8 ] =nnz[ scan8[20]+9 ] = 0;\n\n    }\n\n    s->current_picture.qscale_table[mb_xy]= s->qscale;\n\n    write_back_non_zero_count(h);\n\n\n\n    if(MB_MBAFF){\n\n        h->ref_count[0] >>= 1;\n\n        h->ref_count[1] >>= 1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23299}
{"project": "FFmpeg", "commit_id": "e977ca2645cc6b23589ddf97ab08861064ba8792", "target": 1, "func": "void avfilter_free(AVFilterContext *filter)\n\n{\n\n    int i;\n\n    AVFilterLink *link;\n\n\n\n    if (filter->filter->uninit)\n\n        filter->filter->uninit(filter);\n\n\n\n    for (i = 0; i < filter->input_count; i++) {\n\n        if ((link = filter->inputs[i])) {\n\n            if (link->src)\n\n                link->src->outputs[link->srcpad - link->src->output_pads] = NULL;\n\n            avfilter_formats_unref(&link->in_formats);\n\n            avfilter_formats_unref(&link->out_formats);\n\n        }\n\n        av_freep(&link);\n\n    }\n\n    for (i = 0; i < filter->output_count; i++) {\n\n        if ((link = filter->outputs[i])) {\n\n            if (link->dst)\n\n                link->dst->inputs[link->dstpad - link->dst->input_pads] = NULL;\n\n            avfilter_formats_unref(&link->in_formats);\n\n            avfilter_formats_unref(&link->out_formats);\n\n        }\n\n        av_freep(&link);\n\n    }\n\n\n\n    av_freep(&filter->name);\n\n    av_freep(&filter->input_pads);\n\n    av_freep(&filter->output_pads);\n\n    av_freep(&filter->inputs);\n\n    av_freep(&filter->outputs);\n\n    av_freep(&filter->priv);\n\n    av_free(filter);\n\n}\n", "idx": 23302}
{"project": "FFmpeg", "commit_id": "078d43e23a7a3d64aafee8a58b380d3e139b3020", "target": 1, "func": "static int mpegts_handle_packet(AVFormatContext *ctx, PayloadContext *data,\n\n                                AVStream *st, AVPacket *pkt, uint32_t *timestamp,\n\n                                const uint8_t *buf, int len, uint16_t seq,\n\n                                int flags)\n\n{\n\n    int ret;\n\n\n\n    // We don't want to use the RTP timestamps at all. If the mpegts demuxer\n\n    // doesn't set any pts/dts, the generic rtpdec code shouldn't try to\n\n    // fill it in either, since the mpegts and RTP timestamps are in totally\n\n    // different ranges.\n\n    *timestamp = RTP_NOTS_VALUE;\n\n\n\n    if (!data->ts)\n\n        return AVERROR(EINVAL);\n\n\n\n    if (!buf) {\n\n        if (data->read_buf_index >= data->read_buf_size)\n\n            return AVERROR(EAGAIN);\n\n        ret = ff_mpegts_parse_packet(data->ts, pkt, data->buf + data->read_buf_index,\n\n                                     data->read_buf_size - data->read_buf_index);\n\n        if (ret < 0)\n\n            return AVERROR(EAGAIN);\n\n        data->read_buf_index += ret;\n\n        if (data->read_buf_index < data->read_buf_size)\n\n            return 1;\n\n        else\n\n            return 0;\n\n    }\n\n\n\n    ret = ff_mpegts_parse_packet(data->ts, pkt, buf, len);\n\n    /* The only error that can be returned from ff_mpegts_parse_packet\n\n     * is \"no more data to return from the provided buffer\", so return\n\n     * AVERROR(EAGAIN) for all errors */\n\n    if (ret < 0)\n\n        return AVERROR(EAGAIN);\n\n    if (ret < len) {\n\n        data->read_buf_size = FFMIN(len - ret, sizeof(data->buf));\n\n        memcpy(data->buf, buf + ret, data->read_buf_size);\n\n        data->read_buf_index = 0;\n\n        return 1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 23305}
{"project": "FFmpeg", "commit_id": "83e34ae3c2b36e7b20169a8866e3f49294db1f5a", "target": 1, "func": "static inline int wv_unpack_stereo(WavpackFrameContext *s, GetBitContext *gb,\n\n                                   void *dst_l, void *dst_r, const int type)\n\n{\n\n    int i, j, count = 0;\n\n    int last, t;\n\n    int A, B, L, L2, R, R2;\n\n    int pos                 = s->pos;\n\n    uint32_t crc            = s->sc.crc;\n\n    uint32_t crc_extra_bits = s->extra_sc.crc;\n\n    int16_t *dst16_l        = dst_l;\n\n    int16_t *dst16_r        = dst_r;\n\n    int32_t *dst32_l        = dst_l;\n\n    int32_t *dst32_r        = dst_r;\n\n    float *dstfl_l          = dst_l;\n\n    float *dstfl_r          = dst_r;\n\n\n\n    s->one = s->zero = s->zeroes = 0;\n\n    do {\n\n        L = wv_get_value(s, gb, 0, &last);\n\n        if (last)\n\n            break;\n\n        R = wv_get_value(s, gb, 1, &last);\n\n        if (last)\n\n            break;\n\n        for (i = 0; i < s->terms; i++) {\n\n            t = s->decorr[i].value;\n\n            if (t > 0) {\n\n                if (t > 8) {\n\n                    if (t & 1) {\n\n                        A = 2U * s->decorr[i].samplesA[0] - s->decorr[i].samplesA[1];\n\n                        B = 2U * s->decorr[i].samplesB[0] - s->decorr[i].samplesB[1];\n\n                    } else {\n\n                        A = (int)(3U * s->decorr[i].samplesA[0] - s->decorr[i].samplesA[1]) >> 1;\n\n                        B = (int)(3U * s->decorr[i].samplesB[0] - s->decorr[i].samplesB[1]) >> 1;\n\n                    }\n\n                    s->decorr[i].samplesA[1] = s->decorr[i].samplesA[0];\n\n                    s->decorr[i].samplesB[1] = s->decorr[i].samplesB[0];\n\n                    j                        = 0;\n\n                } else {\n\n                    A = s->decorr[i].samplesA[pos];\n\n                    B = s->decorr[i].samplesB[pos];\n\n                    j = (pos + t) & 7;\n\n                }\n\n                if (type != AV_SAMPLE_FMT_S16P) {\n\n                    L2 = L + ((s->decorr[i].weightA * (int64_t)A + 512) >> 10);\n\n                    R2 = R + ((s->decorr[i].weightB * (int64_t)B + 512) >> 10);\n\n                } else {\n\n                    L2 = L + ((int)(s->decorr[i].weightA * (unsigned)A + 512) >> 10);\n\n                    R2 = R + ((int)(s->decorr[i].weightB * (unsigned)B + 512) >> 10);\n\n                }\n\n                if (A && L)\n\n                    s->decorr[i].weightA -= ((((L ^ A) >> 30) & 2) - 1) * s->decorr[i].delta;\n\n                if (B && R)\n\n                    s->decorr[i].weightB -= ((((R ^ B) >> 30) & 2) - 1) * s->decorr[i].delta;\n\n                s->decorr[i].samplesA[j] = L = L2;\n\n                s->decorr[i].samplesB[j] = R = R2;\n\n            } else if (t == -1) {\n\n                if (type != AV_SAMPLE_FMT_S16P)\n\n                    L2 = L + ((s->decorr[i].weightA * (int64_t)s->decorr[i].samplesA[0] + 512) >> 10);\n\n                else\n\n                    L2 = L + ((int)(s->decorr[i].weightA * (unsigned)s->decorr[i].samplesA[0] + 512) >> 10);\n\n                UPDATE_WEIGHT_CLIP(s->decorr[i].weightA, s->decorr[i].delta, s->decorr[i].samplesA[0], L);\n\n                L = L2;\n\n                if (type != AV_SAMPLE_FMT_S16P)\n\n                    R2 = R + ((s->decorr[i].weightB * (int64_t)L2 + 512) >> 10);\n\n                else\n\n                    R2 = R + ((int)(s->decorr[i].weightB * (unsigned)L2 + 512) >> 10);\n\n                UPDATE_WEIGHT_CLIP(s->decorr[i].weightB, s->decorr[i].delta, L2, R);\n\n                R                        = R2;\n\n                s->decorr[i].samplesA[0] = R;\n\n            } else {\n\n                if (type != AV_SAMPLE_FMT_S16P)\n\n                    R2 = R + ((s->decorr[i].weightB * (int64_t)s->decorr[i].samplesB[0] + 512) >> 10);\n\n                else\n\n                    R2 = R + ((int)(s->decorr[i].weightB * (unsigned)s->decorr[i].samplesB[0] + 512) >> 10);\n\n                UPDATE_WEIGHT_CLIP(s->decorr[i].weightB, s->decorr[i].delta, s->decorr[i].samplesB[0], R);\n\n                R = R2;\n\n\n\n                if (t == -3) {\n\n                    R2                       = s->decorr[i].samplesA[0];\n\n                    s->decorr[i].samplesA[0] = R;\n\n                }\n\n\n\n                if (type != AV_SAMPLE_FMT_S16P)\n\n                    L2 = L + ((s->decorr[i].weightA * (int64_t)R2 + 512) >> 10);\n\n                else\n\n                    L2 = L + ((int)(s->decorr[i].weightA * (unsigned)R2 + 512) >> 10);\n\n                UPDATE_WEIGHT_CLIP(s->decorr[i].weightA, s->decorr[i].delta, R2, L);\n\n                L                        = L2;\n\n                s->decorr[i].samplesB[0] = L;\n\n            }\n\n        }\n\n\n\n        if (type == AV_SAMPLE_FMT_S16P) {\n\n            if (FFABS(L) + (unsigned)FFABS(R) > (1<<19)) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"sample %d %d too large\\n\", L, R);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n\n\n        pos = (pos + 1) & 7;\n\n        if (s->joint)\n\n            L += (unsigned)(R -= (unsigned)(L >> 1));\n\n        crc = (crc * 3 + L) * 3 + R;\n\n\n\n        if (type == AV_SAMPLE_FMT_FLTP) {\n\n            *dstfl_l++ = wv_get_value_float(s, &crc_extra_bits, L);\n\n            *dstfl_r++ = wv_get_value_float(s, &crc_extra_bits, R);\n\n        } else if (type == AV_SAMPLE_FMT_S32P) {\n\n            *dst32_l++ = wv_get_value_integer(s, &crc_extra_bits, L);\n\n            *dst32_r++ = wv_get_value_integer(s, &crc_extra_bits, R);\n\n        } else {\n\n            *dst16_l++ = wv_get_value_integer(s, &crc_extra_bits, L);\n\n            *dst16_r++ = wv_get_value_integer(s, &crc_extra_bits, R);\n\n        }\n\n        count++;\n\n    } while (!last && count < s->samples);\n\n\n\n    wv_reset_saved_context(s);\n\n\n\n    if (last && count < s->samples) {\n\n        int size = av_get_bytes_per_sample(type);\n\n        memset((uint8_t*)dst_l + count*size, 0, (s->samples-count)*size);\n\n        memset((uint8_t*)dst_r + count*size, 0, (s->samples-count)*size);\n\n    }\n\n\n\n    if ((s->avctx->err_recognition & AV_EF_CRCCHECK) &&\n\n        wv_check_crc(s, crc, crc_extra_bits))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    return 0;\n\n}\n", "idx": 23308}
{"project": "FFmpeg", "commit_id": "e477f09d0b3619f3d29173b2cd593e17e2d1978e", "target": 1, "func": "static int decode_trns_chunk(AVCodecContext *avctx, PNGDecContext *s,\n\n                             uint32_t length)\n\n{\n\n    int v, i;\n\n\n\n    if (s->color_type == PNG_COLOR_TYPE_PALETTE) {\n\n        if (length > 256 || !(s->state & PNG_PLTE))\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        for (i = 0; i < length; i++) {\n\n            v = bytestream2_get_byte(&s->gb);\n\n            s->palette[i] = (s->palette[i] & 0x00ffffff) | (v << 24);\n\n        }\n\n    } else if (s->color_type == PNG_COLOR_TYPE_GRAY || s->color_type == PNG_COLOR_TYPE_RGB) {\n\n        if ((s->color_type == PNG_COLOR_TYPE_GRAY && length != 2) ||\n\n            (s->color_type == PNG_COLOR_TYPE_RGB && length != 6))\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        for (i = 0; i < length / 2; i++) {\n\n            /* only use the least significant bits */\n\n            v = av_mod_uintp2(bytestream2_get_be16(&s->gb), s->bit_depth);\n\n\n\n            if (s->bit_depth > 8)\n\n                AV_WB16(&s->transparent_color_be[2 * i], v);\n\n            else\n\n                s->transparent_color_be[i] = v;\n\n        }\n\n    } else {\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    bytestream2_skip(&s->gb, 4); /* crc */\n\n    s->has_trns = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 23309}
{"project": "FFmpeg", "commit_id": "c82b8ef0e4f226423ddd644bfe37e6a15d070924", "target": 1, "func": "static void compute_default_clut(AVSubtitleRect *rect, int w, int h)\n\n{\n\n    uint8_t list[256] = {0};\n\n    uint8_t list_inv[256];\n\n    int counttab[256] = {0};\n\n    int count, i, x, y;\n\n\n\n#define V(x,y) rect->data[0][(x) + (y)*rect->linesize[0]]\n\n    for (y = 0; y<h; y++) {\n\n        for (x = 0; x<w; x++) {\n\n            int v = V(x,y) + 1;\n\n            int vl = x     ? V(x-1,y) + 1 : 0;\n\n            int vr = x+1<w ? V(x+1,y) + 1 : 0;\n\n            int vt = y     ? V(x,y-1) + 1 : 0;\n\n            int vb = y+1<h ? V(x,y+1) + 1 : 0;\n\n            counttab[v-1] += !!((v!=vl) + (v!=vr) + (v!=vt) + (v!=vb));\n\n        }\n\n    }\n\n#define L(x,y) list[ rect->data[0][(x) + (y)*rect->linesize[0]] ]\n\n\n\n    for (i = 0; i<256; i++) {\n\n        int scoretab[256] = {0};\n\n        int bestscore = 0;\n\n        int bestv = 0;\n\n        for (y = 0; y<h; y++) {\n\n            for (x = 0; x<w; x++) {\n\n                int v = rect->data[0][x + y*rect->linesize[0]];\n\n                int l_m = list[v];\n\n                int l_l = x     ? L(x-1, y) : 1;\n\n                int l_r = x+1<w ? L(x+1, y) : 1;\n\n                int l_t = y     ? L(x, y-1) : 1;\n\n                int l_b = y+1<h ? L(x, y+1) : 1;\n\n                int score;\n\n                if (l_m)\n\n                    continue;\n\n                scoretab[v] += l_l + l_r + l_t + l_b;\n\n                score = 1024LL*scoretab[v] / counttab[v];\n\n                if (score > bestscore) {\n\n                    bestscore = score;\n\n                    bestv = v;\n\n                }\n\n            }\n\n        }\n\n        if (!bestscore)\n\n            break;\n\n        list    [ bestv ] = 1;\n\n        list_inv[     i ] = bestv;\n\n    }\n\n\n\n    count = i - 1;\n\n    for (i--; i>=0; i--) {\n\n        int v = i*255/count;\n\n        AV_WN32(rect->data[1] + 4*list_inv[i], RGBA(v/2,v,v/2,v));\n\n    }\n\n}\n", "idx": 23311}
{"project": "FFmpeg", "commit_id": "169c1cfa928040b83f2ac8386333ec5e5cff3df7", "target": 1, "func": "static int pvf_read_header(AVFormatContext *s)\n\n{\n\n    char buffer[32];\n\n    AVStream *st;\n\n    int bps, channels, sample_rate;\n\n\n\n    avio_skip(s->pb, 5);\n\n    ff_get_line(s->pb, buffer, sizeof(buffer));\n\n    if (sscanf(buffer, \"%d %d %d\",\n\n               &channels,\n\n               &sample_rate,\n\n               &bps) != 3)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (channels <= 0 || bps <= 0 || sample_rate <= 0)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    st->codecpar->codec_type  = AVMEDIA_TYPE_AUDIO;\n\n    st->codecpar->channels    = channels;\n\n    st->codecpar->sample_rate = sample_rate;\n\n    st->codecpar->codec_id    = ff_get_pcm_codec_id(bps, 0, 1, 0xFFFF);\n\n    st->codecpar->bits_per_coded_sample = bps;\n\n    st->codecpar->block_align = bps * st->codecpar->channels / 8;\n\n\n\n    avpriv_set_pts_info(st, 64, 1, st->codecpar->sample_rate);\n\n\n\n    return 0;\n\n}\n", "idx": 23313}
{"project": "FFmpeg", "commit_id": "0953736b7e97f6e121a0587a95434bf1857a27da", "target": 1, "func": "static inline int signed_shift(int i, int shift) {\n\n    if (shift > 0)\n\n        return i << shift;\n\n    return i >> -shift;\n\n}\n", "idx": 23316}
{"project": "FFmpeg", "commit_id": "fac1ccbda1bb8441c7329a3ac18fbf04886da983", "target": 1, "func": "static int doTest(uint8_t *ref[4], int refStride[4], int w, int h,\n\n                  enum AVPixelFormat srcFormat, enum AVPixelFormat dstFormat,\n\n                  int srcW, int srcH, int dstW, int dstH, int flags,\n\n                  struct Results *r)\n\n{\n\n    static enum AVPixelFormat cur_srcFormat;\n\n    static int cur_srcW, cur_srcH;\n\n    static uint8_t *src[4];\n\n    static int srcStride[4];\n\n    uint8_t *dst[4] = { 0 };\n\n    uint8_t *out[4] = { 0 };\n\n    int dstStride[4];\n\n    int i;\n\n    uint64_t ssdY, ssdU = 0, ssdV = 0, ssdA = 0;\n\n    struct SwsContext *dstContext = NULL, *outContext = NULL;\n\n    uint32_t crc = 0;\n\n    int res      = 0;\n\n\n\n    if (cur_srcFormat != srcFormat || cur_srcW != srcW || cur_srcH != srcH) {\n\n        struct SwsContext *srcContext = NULL;\n\n        int p;\n\n\n\n        for (p = 0; p < 4; p++)\n\n            av_freep(&src[p]);\n\n\n\n        av_image_fill_linesizes(srcStride, srcFormat, srcW);\n\n        for (p = 0; p < 4; p++) {\n\n            srcStride[p] = FFALIGN(srcStride[p], 16);\n\n            if (srcStride[p])\n\n                src[p] = av_mallocz(srcStride[p] * srcH + 16);\n\n            if (srcStride[p] && !src[p]) {\n\n                perror(\"Malloc\");\n\n                res = -1;\n\n                goto end;\n\n            }\n\n        }\n\n        srcContext = sws_getContext(w, h, AV_PIX_FMT_YUVA420P, srcW, srcH,\n\n                                    srcFormat, SWS_BILINEAR, NULL, NULL, NULL);\n\n        if (!srcContext) {\n\n            fprintf(stderr, \"Failed to get %s ---> %s\\n\",\n\n                    av_pix_fmt_descriptors[AV_PIX_FMT_YUVA420P].name,\n\n                    av_pix_fmt_descriptors[srcFormat].name);\n\n            res = -1;\n\n            goto end;\n\n        }\n\n        sws_scale(srcContext, ref, refStride, 0, h, src, srcStride);\n\n        sws_freeContext(srcContext);\n\n\n\n        cur_srcFormat = srcFormat;\n\n        cur_srcW      = srcW;\n\n        cur_srcH      = srcH;\n\n    }\n\n\n\n    av_image_fill_linesizes(dstStride, dstFormat, dstW);\n\n    for (i = 0; i < 4; i++) {\n\n        /* Image buffers passed into libswscale can be allocated any way you\n\n         * prefer, as long as they're aligned enough for the architecture, and\n\n         * they're freed appropriately (such as using av_free for buffers\n\n         * allocated with av_malloc). */\n\n        /* An extra 16 bytes is being allocated because some scalers may write\n\n         * out of bounds. */\n\n        dstStride[i] = FFALIGN(dstStride[i], 16);\n\n        if (dstStride[i])\n\n            dst[i] = av_mallocz(dstStride[i] * dstH + 16);\n\n        if (dstStride[i] && !dst[i]) {\n\n            perror(\"Malloc\");\n\n            res = -1;\n\n\n\n            goto end;\n\n        }\n\n    }\n\n\n\n    dstContext = sws_getContext(srcW, srcH, srcFormat, dstW, dstH, dstFormat,\n\n                                flags, NULL, NULL, NULL);\n\n    if (!dstContext) {\n\n        fprintf(stderr, \"Failed to get %s ---> %s\\n\",\n\n                av_pix_fmt_descriptors[srcFormat].name,\n\n                av_pix_fmt_descriptors[dstFormat].name);\n\n        res = -1;\n\n        goto end;\n\n    }\n\n\n\n    printf(\" %s %dx%d -> %s %3dx%3d flags=%2d\",\n\n           av_pix_fmt_descriptors[srcFormat].name, srcW, srcH,\n\n           av_pix_fmt_descriptors[dstFormat].name, dstW, dstH,\n\n           flags);\n\n    fflush(stdout);\n\n\n\n    sws_scale(dstContext, src, srcStride, 0, srcH, dst, dstStride);\n\n\n\n    for (i = 0; i < 4 && dstStride[i]; i++)\n\n        crc = av_crc(av_crc_get_table(AV_CRC_32_IEEE), crc, dst[i],\n\n                     dstStride[i] * dstH);\n\n\n\n    if (r && crc == r->crc) {\n\n        ssdY = r->ssdY;\n\n        ssdU = r->ssdU;\n\n        ssdV = r->ssdV;\n\n        ssdA = r->ssdA;\n\n    } else {\n\n        for (i = 0; i < 4; i++) {\n\n            refStride[i] = FFALIGN(refStride[i], 16);\n\n            if (refStride[i])\n\n                out[i] = av_mallocz(refStride[i] * h);\n\n            if (refStride[i] && !out[i]) {\n\n                perror(\"Malloc\");\n\n                res = -1;\n\n                goto end;\n\n            }\n\n        }\n\n        outContext = sws_getContext(dstW, dstH, dstFormat, w, h,\n\n                                    AV_PIX_FMT_YUVA420P, SWS_BILINEAR,\n\n                                    NULL, NULL, NULL);\n\n        if (!outContext) {\n\n            fprintf(stderr, \"Failed to get %s ---> %s\\n\",\n\n                    av_pix_fmt_descriptors[dstFormat].name,\n\n                    av_pix_fmt_descriptors[AV_PIX_FMT_YUVA420P].name);\n\n            res = -1;\n\n            goto end;\n\n        }\n\n        sws_scale(outContext, dst, dstStride, 0, dstH, out, refStride);\n\n\n\n        ssdY = getSSD(ref[0], out[0], refStride[0], refStride[0], w, h);\n\n        if (hasChroma(srcFormat) && hasChroma(dstFormat)) {\n\n            //FIXME check that output is really gray\n\n            ssdU = getSSD(ref[1], out[1], refStride[1], refStride[1],\n\n                          (w + 1) >> 1, (h + 1) >> 1);\n\n            ssdV = getSSD(ref[2], out[2], refStride[2], refStride[2],\n\n                          (w + 1) >> 1, (h + 1) >> 1);\n\n        }\n\n        if (isALPHA(srcFormat) && isALPHA(dstFormat))\n\n            ssdA = getSSD(ref[3], out[3], refStride[3], refStride[3], w, h);\n\n\n\n        ssdY /= w * h;\n\n        ssdU /= w * h / 4;\n\n        ssdV /= w * h / 4;\n\n        ssdA /= w * h;\n\n\n\n        sws_freeContext(outContext);\n\n\n\n        for (i = 0; i < 4; i++)\n\n            if (refStride[i])\n\n                av_free(out[i]);\n\n    }\n\n\n\n    printf(\" CRC=%08x SSD=%5\"PRId64 \",%5\"PRId64 \",%5\"PRId64 \",%5\"PRId64 \"\\n\",\n\n           crc, ssdY, ssdU, ssdV, ssdA);\n\n\n\nend:\n\n    sws_freeContext(dstContext);\n\n\n\n    for (i = 0; i < 4; i++)\n\n        if (dstStride[i])\n\n            av_free(dst[i]);\n\n\n\n    return res;\n\n}\n", "idx": 23318}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(yuv2yuv1)(int16_t *lumSrc, int16_t *chrSrc,\n\n\t\t\t\t    uint8_t *dest, uint8_t *uDest, uint8_t *vDest, int dstW, int chrDstW)\n\n{\n\n#ifdef HAVE_MMX\n\n\tif(uDest != NULL)\n\n\t{\n\n\t\tasm volatile(\n\n\t\t\t\tYSCALEYUV2YV121\n\n\t\t\t\t:: \"r\" (chrSrc + chrDstW), \"r\" (uDest + chrDstW),\n\n\t\t\t\t\"g\" ((long)-chrDstW)\n\n\t\t\t\t: \"%\"REG_a\n\n\t\t\t);\n\n\n\n\t\tasm volatile(\n\n\t\t\t\tYSCALEYUV2YV121\n\n\t\t\t\t:: \"r\" (chrSrc + 2048 + chrDstW), \"r\" (vDest + chrDstW),\n\n\t\t\t\t\"g\" ((long)-chrDstW)\n\n\t\t\t\t: \"%\"REG_a\n\n\t\t\t);\n\n\t}\n\n\n\n\tasm volatile(\n\n\t\tYSCALEYUV2YV121\n\n\t\t:: \"r\" (lumSrc + dstW), \"r\" (dest + dstW),\n\n\t\t\"g\" ((long)-dstW)\n\n\t\t: \"%\"REG_a\n\n\t);\n\n#else\n\n\tint i;\n\n\tfor(i=0; i<dstW; i++)\n\n\t{\n\n\t\tint val= lumSrc[i]>>7;\n\n\t\t\n\n\t\tif(val&256){\n\n\t\t\tif(val<0) val=0;\n\n\t\t\telse      val=255;\n\n\t\t}\n\n\n\n\t\tdest[i]= val;\n\n\t}\n\n\n\n\tif(uDest != NULL)\n\n\t\tfor(i=0; i<chrDstW; i++)\n\n\t\t{\n\n\t\t\tint u=chrSrc[i]>>7;\n\n\t\t\tint v=chrSrc[i + 2048]>>7;\n\n\n\n\t\t\tif((u|v)&256){\n\n\t\t\t\tif(u<0)         u=0;\n\n\t\t\t\telse if (u>255) u=255;\n\n\t\t\t\tif(v<0)         v=0;\n\n\t\t\t\telse if (v>255) v=255;\n\n\t\t\t}\n\n\n\n\t\t\tuDest[i]= u;\n\n\t\t\tvDest[i]= v;\n\n\t\t}\n\n#endif\n\n}\n", "idx": 23321}
{"project": "FFmpeg", "commit_id": "138902dfb60fbb87fb65a8c4800f8ac661394b72", "target": 1, "func": "static int read_dialogue(ASSContext *ass, AVBPrint *dst, const uint8_t *p,\n\n                         int64_t *start, int *duration)\n\n{\n\n    int pos;\n\n    int64_t end;\n\n    int hh1, mm1, ss1, ms1;\n\n    int hh2, mm2, ss2, ms2;\n\n\n\n    if (sscanf(p, \"Dialogue: %*[^,],%d:%d:%d%*c%d,%d:%d:%d%*c%d,%n\",\n\n               &hh1, &mm1, &ss1, &ms1,\n\n               &hh2, &mm2, &ss2, &ms2, &pos) >= 8) {\n\n\n\n        /* This is not part of the sscanf itself in order to handle an actual\n\n         * number (which would be the Layer) or the form \"Marked=N\" (which is\n\n         * the old SSA field, now replaced by Layer, and will be lead to Layer\n\n         * being 0 here). */\n\n        const int layer = atoi(p + 10);\n\n\n\n        end    = (hh2*3600LL + mm2*60LL + ss2) * 100LL + ms2;\n\n        *start = (hh1*3600LL + mm1*60LL + ss1) * 100LL + ms1;\n\n        *duration = end - *start;\n\n\n\n        av_bprint_clear(dst);\n\n        av_bprintf(dst, \"%u,%d,%s\", ass->readorder++, layer, p + pos);\n\n\n\n        /* right strip the buffer */\n\n        while (dst->len > 0 &&\n\n               dst->str[dst->len - 1] == '\\r' ||\n\n               dst->str[dst->len - 1] == '\\n')\n\n            dst->str[--dst->len] = 0;\n\n        return 0;\n\n    }\n\n    return -1;\n\n}\n", "idx": 23322}
{"project": "FFmpeg", "commit_id": "3016e919d4e1d90da98af19ce2a9d4979506eaf3", "target": 1, "func": "static inline int wv_get_value_integer(WavpackFrameContext *s, uint32_t *crc,\n\n                                       int S)\n\n{\n\n    unsigned bit;\n\n\n\n    if (s->extra_bits) {\n\n        S <<= s->extra_bits;\n\n\n\n        if (s->got_extra_bits &&\n\n            get_bits_left(&s->gb_extra_bits) >= s->extra_bits) {\n\n            S   |= get_bits_long(&s->gb_extra_bits, s->extra_bits);\n\n            *crc = *crc * 9 + (S & 0xffff) * 3 + ((unsigned)S >> 16);\n\n        }\n\n    }\n\n\n\n    bit = (S & s->and) | s->or;\n\n    bit = ((S + bit) << s->shift) - bit;\n\n\n\n    if (s->hybrid)\n\n        bit = av_clip(bit, s->hybrid_minclip, s->hybrid_maxclip);\n\n\n\n    return bit << s->post_shift;\n\n}\n", "idx": 23323}
{"project": "FFmpeg", "commit_id": "932e6a5a4c78250e3cab4f65215214fb0dbf51f7", "target": 1, "func": "static void quantize_bands(int (*out)[2], const float *in, const float *scaled,\n\n                           int size, float Q34, int is_signed, int maxval)\n\n{\n\n    int i;\n\n    double qc;\n\n    for (i = 0; i < size; i++) {\n\n        qc = scaled[i] * Q34;\n\n        out[i][0] = (int)FFMIN((int)qc,            maxval);\n\n        out[i][1] = (int)FFMIN((int)(qc + 0.4054), maxval);\n\n        if (is_signed && in[i] < 0.0f) {\n\n            out[i][0] = -out[i][0];\n\n            out[i][1] = -out[i][1];\n\n        }\n\n    }\n\n}\n", "idx": 23324}
{"project": "FFmpeg", "commit_id": "df3b17eba47e635a694acb18b74e389194355f45", "target": 1, "func": "av_cold int vaapi_device_init(const char *device)\n{\n    int err;\n    err = av_hwdevice_ctx_create(&hw_device_ctx, AV_HWDEVICE_TYPE_VAAPI,\n                                 device, NULL, 0);\n    if (err < 0) {\n        av_log(&vaapi_log, AV_LOG_ERROR, \"Failed to create a VAAPI device\\n\");\n        return err;\n    }\n    return 0;\n}", "idx": 23325}
{"project": "FFmpeg", "commit_id": "df037fe107ccfae4b26ee0e46b638b052f6e49f8", "target": 1, "func": "static int smvjpeg_decode_frame(AVCodecContext *avctx, void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    const AVPixFmtDescriptor *desc;\n\n    SMVJpegDecodeContext *s = avctx->priv_data;\n\n    AVFrame* mjpeg_data = s->picture[0];\n\n    int i, cur_frame = 0, ret = 0;\n\n\n\n    cur_frame = avpkt->pts % s->frames_per_jpeg;\n\n\n\n    /* Are we at the start of a block? */\n\n    if (!cur_frame) {\n\n        av_frame_unref(mjpeg_data);\n\n        ret = avcodec_decode_video2(s->avctx, mjpeg_data, &s->mjpeg_data_size, avpkt);\n\n        if (ret < 0) {\n\n            s->mjpeg_data_size = 0;\n\n            return ret;\n\n        }\n\n    } else if (!s->mjpeg_data_size)\n\n        return AVERROR(EINVAL);\n\n\n\n    desc = av_pix_fmt_desc_get(s->avctx->pix_fmt);\n\n    if (desc && mjpeg_data->height % (s->frames_per_jpeg << desc->log2_chroma_h)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid height\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /*use the last lot... */\n\n    *data_size = s->mjpeg_data_size;\n\n\n\n    avctx->pix_fmt = s->avctx->pix_fmt;\n\n\n\n    /* We shouldn't get here if frames_per_jpeg <= 0 because this was rejected\n\n       in init */\n\n    ret = ff_set_dimensions(avctx, mjpeg_data->width, mjpeg_data->height / s->frames_per_jpeg);\n\n    if (ret < 0) {\n\n        av_log(s, AV_LOG_ERROR, \"Failed to set dimensions\\n\");\n\n        return ret;\n\n    }\n\n\n\n    if (*data_size) {\n\n        s->picture[1]->extended_data = NULL;\n\n        s->picture[1]->width         = avctx->width;\n\n        s->picture[1]->height        = avctx->height;\n\n        s->picture[1]->format        = avctx->pix_fmt;\n\n        /* ff_init_buffer_info(avctx, &s->picture[1]); */\n\n        smv_img_pnt(s->picture[1]->data, mjpeg_data->data, mjpeg_data->linesize,\n\n                    avctx->pix_fmt, avctx->width, avctx->height, cur_frame);\n\n        for (i = 0; i < AV_NUM_DATA_POINTERS; i++)\n\n            s->picture[1]->linesize[i] = mjpeg_data->linesize[i];\n\n\n\n        ret = av_frame_ref(data, s->picture[1]);\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 23327}
{"project": "FFmpeg", "commit_id": "907783f221ad9594a528681e30777705f11bf0b5", "target": 0, "func": "static void rtsp_parse_rtp_info(RTSPState *rt, const char *p)\n\n{\n\n    int read = 0;\n\n    char key[20], value[1024], url[1024] = \"\";\n\n    uint32_t seq = 0, rtptime = 0;\n\n\n\n    for (;;) {\n\n        p += strspn(p, SPACE_CHARS);\n\n        if (!*p)\n\n            break;\n\n        get_word_sep(key, sizeof(key), \"=\", &p);\n\n        if (*p != '=')\n\n            break;\n\n        p++;\n\n        get_word_sep(value, sizeof(value), \";, \", &p);\n\n        read++;\n\n        if (!strcmp(key, \"url\"))\n\n            av_strlcpy(url, value, sizeof(url));\n\n        else if (!strcmp(key, \"seq\"))\n\n            seq = strtol(value, NULL, 10);\n\n        else if (!strcmp(key, \"rtptime\"))\n\n            rtptime = strtol(value, NULL, 10);\n\n        if (*p == ',') {\n\n            handle_rtp_info(rt, url, seq, rtptime);\n\n            url[0] = '\\0';\n\n            seq = rtptime = 0;\n\n            read = 0;\n\n        }\n\n        if (*p)\n\n            p++;\n\n    }\n\n    if (read > 0)\n\n        handle_rtp_info(rt, url, seq, rtptime);\n\n}\n", "idx": 23329}
{"project": "FFmpeg", "commit_id": "fd92dafaff8844b5fedf94679b93d953939a7f7b", "target": 0, "func": "static int bink_decode_plane(BinkContext *c, AVFrame *frame, BitstreamContext *bc,\n\n                             int plane_idx, int is_chroma)\n\n{\n\n    int blk, ret;\n\n    int i, j, bx, by;\n\n    uint8_t *dst, *prev, *ref_start, *ref_end;\n\n    int v, col[2];\n\n    const uint8_t *scan;\n\n    LOCAL_ALIGNED_16(int16_t, block, [64]);\n\n    LOCAL_ALIGNED_16(uint8_t, ublock, [64]);\n\n    LOCAL_ALIGNED_16(int32_t, dctblock, [64]);\n\n    int coordmap[64];\n\n\n\n    const int stride = frame->linesize[plane_idx];\n\n    int bw = is_chroma ? (c->avctx->width  + 15) >> 4 : (c->avctx->width  + 7) >> 3;\n\n    int bh = is_chroma ? (c->avctx->height + 15) >> 4 : (c->avctx->height + 7) >> 3;\n\n    int width = c->avctx->width >> is_chroma;\n\n\n\n    init_lengths(c, FFMAX(width, 8), bw);\n\n    for (i = 0; i < BINK_NB_SRC; i++)\n\n        read_bundle(bc, c, i);\n\n\n\n    ref_start = c->last->data[plane_idx] ? c->last->data[plane_idx]\n\n                                         : frame->data[plane_idx];\n\n    ref_end   = ref_start\n\n                + (bw - 1 + c->last->linesize[plane_idx] * (bh - 1)) * 8;\n\n\n\n    for (i = 0; i < 64; i++)\n\n        coordmap[i] = (i & 7) + (i >> 3) * stride;\n\n\n\n    for (by = 0; by < bh; by++) {\n\n        if ((ret = read_block_types(c->avctx, bc, &c->bundle[BINK_SRC_BLOCK_TYPES])) < 0)\n\n            return ret;\n\n        if ((ret = read_block_types(c->avctx, bc, &c->bundle[BINK_SRC_SUB_BLOCK_TYPES])) < 0)\n\n            return ret;\n\n        if ((ret = read_colors(bc, &c->bundle[BINK_SRC_COLORS], c)) < 0)\n\n            return ret;\n\n        if ((ret = read_patterns(c->avctx, bc, &c->bundle[BINK_SRC_PATTERN])) < 0)\n\n            return ret;\n\n        if ((ret = read_motion_values(c->avctx, bc, &c->bundle[BINK_SRC_X_OFF])) < 0)\n\n            return ret;\n\n        if ((ret = read_motion_values(c->avctx, bc, &c->bundle[BINK_SRC_Y_OFF])) < 0)\n\n            return ret;\n\n        if ((ret = read_dcs(c->avctx, bc, &c->bundle[BINK_SRC_INTRA_DC], DC_START_BITS, 0)) < 0)\n\n            return ret;\n\n        if ((ret = read_dcs(c->avctx, bc, &c->bundle[BINK_SRC_INTER_DC], DC_START_BITS, 1)) < 0)\n\n            return ret;\n\n        if ((ret = read_runs(c->avctx, bc, &c->bundle[BINK_SRC_RUN])) < 0)\n\n            return ret;\n\n\n\n        if (by == bh)\n\n            break;\n\n        dst  = frame->data[plane_idx]  + 8*by*stride;\n\n        prev = (c->last->data[plane_idx] ? c->last->data[plane_idx]\n\n                                         : frame->data[plane_idx]) + 8*by*stride;\n\n        for (bx = 0; bx < bw; bx++, dst += 8, prev += 8) {\n\n            blk = get_value(c, BINK_SRC_BLOCK_TYPES);\n\n            // 16x16 block type on odd line means part of the already decoded block, so skip it\n\n            if ((by & 1) && blk == SCALED_BLOCK) {\n\n                bx++;\n\n                dst  += 8;\n\n                prev += 8;\n\n                continue;\n\n            }\n\n            switch (blk) {\n\n            case SKIP_BLOCK:\n\n                c->hdsp.put_pixels_tab[1][0](dst, prev, stride, 8);\n\n                break;\n\n            case SCALED_BLOCK:\n\n                blk = get_value(c, BINK_SRC_SUB_BLOCK_TYPES);\n\n                switch (blk) {\n\n                case RUN_BLOCK:\n\n                    scan = bink_patterns[bitstream_read(bc, 4)];\n\n                    i = 0;\n\n                    do {\n\n                        int run = get_value(c, BINK_SRC_RUN) + 1;\n\n\n\n                        i += run;\n\n                        if (i > 64) {\n\n                            av_log(c->avctx, AV_LOG_ERROR, \"Run went out of bounds\\n\");\n\n                            return AVERROR_INVALIDDATA;\n\n                        }\n\n                        if (bitstream_read_bit(bc)) {\n\n                            v = get_value(c, BINK_SRC_COLORS);\n\n                            for (j = 0; j < run; j++)\n\n                                ublock[*scan++] = v;\n\n                        } else {\n\n                            for (j = 0; j < run; j++)\n\n                                ublock[*scan++] = get_value(c, BINK_SRC_COLORS);\n\n                        }\n\n                    } while (i < 63);\n\n                    if (i == 63)\n\n                        ublock[*scan++] = get_value(c, BINK_SRC_COLORS);\n\n                    break;\n\n                case INTRA_BLOCK:\n\n                    memset(dctblock, 0, sizeof(*dctblock) * 64);\n\n                    dctblock[0] = get_value(c, BINK_SRC_INTRA_DC);\n\n                    read_dct_coeffs(bc, dctblock, bink_scan, bink_intra_quant, -1);\n\n                    c->binkdsp.idct_put(ublock, 8, dctblock);\n\n                    break;\n\n                case FILL_BLOCK:\n\n                    v = get_value(c, BINK_SRC_COLORS);\n\n                    c->bdsp.fill_block_tab[0](dst, v, stride, 16);\n\n                    break;\n\n                case PATTERN_BLOCK:\n\n                    for (i = 0; i < 2; i++)\n\n                        col[i] = get_value(c, BINK_SRC_COLORS);\n\n                    for (j = 0; j < 8; j++) {\n\n                        v = get_value(c, BINK_SRC_PATTERN);\n\n                        for (i = 0; i < 8; i++, v >>= 1)\n\n                            ublock[i + j*8] = col[v & 1];\n\n                    }\n\n                    break;\n\n                case RAW_BLOCK:\n\n                    for (j = 0; j < 8; j++)\n\n                        for (i = 0; i < 8; i++)\n\n                            ublock[i + j*8] = get_value(c, BINK_SRC_COLORS);\n\n                    break;\n\n                default:\n\n                    av_log(c->avctx, AV_LOG_ERROR, \"Incorrect 16x16 block type %d\\n\", blk);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                if (blk != FILL_BLOCK)\n\n                c->binkdsp.scale_block(ublock, dst, stride);\n\n                bx++;\n\n                dst  += 8;\n\n                prev += 8;\n\n                break;\n\n            case MOTION_BLOCK:\n\n                ret = bink_put_pixels(c, dst, prev, stride,\n\n                                      ref_start, ref_end);\n\n                if (ret < 0)\n\n                    return ret;\n\n                break;\n\n            case RUN_BLOCK:\n\n                scan = bink_patterns[bitstream_read(bc, 4)];\n\n                i = 0;\n\n                do {\n\n                    int run = get_value(c, BINK_SRC_RUN) + 1;\n\n\n\n                    i += run;\n\n                    if (i > 64) {\n\n                        av_log(c->avctx, AV_LOG_ERROR, \"Run went out of bounds\\n\");\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                    if (bitstream_read_bit(bc)) {\n\n                        v = get_value(c, BINK_SRC_COLORS);\n\n                        for (j = 0; j < run; j++)\n\n                            dst[coordmap[*scan++]] = v;\n\n                    } else {\n\n                        for (j = 0; j < run; j++)\n\n                            dst[coordmap[*scan++]] = get_value(c, BINK_SRC_COLORS);\n\n                    }\n\n                } while (i < 63);\n\n                if (i == 63)\n\n                    dst[coordmap[*scan++]] = get_value(c, BINK_SRC_COLORS);\n\n                break;\n\n            case RESIDUE_BLOCK:\n\n                ret = bink_put_pixels(c, dst, prev, stride,\n\n                                      ref_start, ref_end);\n\n                if (ret < 0)\n\n                    return ret;\n\n                c->bdsp.clear_block(block);\n\n                v = bitstream_read(bc, 7);\n\n                read_residue(bc, block, v);\n\n                c->binkdsp.add_pixels8(dst, block, stride);\n\n                break;\n\n            case INTRA_BLOCK:\n\n                memset(dctblock, 0, sizeof(*dctblock) * 64);\n\n                dctblock[0] = get_value(c, BINK_SRC_INTRA_DC);\n\n                read_dct_coeffs(bc, dctblock, bink_scan, bink_intra_quant, -1);\n\n                c->binkdsp.idct_put(dst, stride, dctblock);\n\n                break;\n\n            case FILL_BLOCK:\n\n                v = get_value(c, BINK_SRC_COLORS);\n\n                c->bdsp.fill_block_tab[1](dst, v, stride, 8);\n\n                break;\n\n            case INTER_BLOCK:\n\n                ret = bink_put_pixels(c, dst, prev, stride,\n\n                                      ref_start, ref_end);\n\n                if (ret < 0)\n\n                    return ret;\n\n                memset(dctblock, 0, sizeof(*dctblock) * 64);\n\n                dctblock[0] = get_value(c, BINK_SRC_INTER_DC);\n\n                read_dct_coeffs(bc, dctblock, bink_scan, bink_inter_quant, -1);\n\n                c->binkdsp.idct_add(dst, stride, dctblock);\n\n                break;\n\n            case PATTERN_BLOCK:\n\n                for (i = 0; i < 2; i++)\n\n                    col[i] = get_value(c, BINK_SRC_COLORS);\n\n                for (i = 0; i < 8; i++) {\n\n                    v = get_value(c, BINK_SRC_PATTERN);\n\n                    for (j = 0; j < 8; j++, v >>= 1)\n\n                        dst[i*stride + j] = col[v & 1];\n\n                }\n\n                break;\n\n            case RAW_BLOCK:\n\n                for (i = 0; i < 8; i++)\n\n                    memcpy(dst + i*stride, c->bundle[BINK_SRC_COLORS].cur_ptr + i*8, 8);\n\n                c->bundle[BINK_SRC_COLORS].cur_ptr += 64;\n\n                break;\n\n            default:\n\n                av_log(c->avctx, AV_LOG_ERROR, \"Unknown block type %d\\n\", blk);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    }\n\n    if (bitstream_tell(bc) & 0x1F) // next plane data starts at 32-bit boundary\n\n        bitstream_skip(bc, 32 - (bitstream_tell(bc) & 0x1F));\n\n\n\n    return 0;\n\n}\n", "idx": 23330}
{"project": "FFmpeg", "commit_id": "0c22311b56e66115675c4a96e4c78547886a4171", "target": 0, "func": "static void opt_frame_pad_right(const char *arg)\n\n{\n\n    frame_padright = atoi(arg);\n\n    if (frame_padright < 0) {\n\n        fprintf(stderr, \"Incorrect right pad size\\n\");\n\n        av_exit(1);\n\n    }\n\n}\n", "idx": 23331}
{"project": "FFmpeg", "commit_id": "d1f558b3628d3ab99fd93a98b5758ef1be45a5da", "target": 0, "func": "static int dcadec_decode_frame(AVCodecContext *avctx, void *data,\n\n                               int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    DCAContext *s = avctx->priv_data;\n\n    AVFrame *frame = data;\n\n    uint8_t *input = avpkt->data;\n\n    int input_size = avpkt->size;\n\n    int i, ret, prev_packet = s->packet;\n\n\n\n    if (input_size < MIN_PACKET_SIZE || input_size > MAX_PACKET_SIZE) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid packet size\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    av_fast_malloc(&s->buffer, &s->buffer_size,\n\n                   FFALIGN(input_size, 4096) + DCA_BUFFER_PADDING_SIZE);\n\n    if (!s->buffer)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for (i = 0, ret = AVERROR_INVALIDDATA; i < input_size - MIN_PACKET_SIZE + 1 && ret < 0; i++)\n\n        ret = convert_bitstream(input + i, input_size - i, s->buffer, s->buffer_size);\n\n\n\n    if (ret < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Not a valid DCA frame\\n\");\n\n        return ret;\n\n    }\n\n\n\n    input      = s->buffer;\n\n    input_size = ret;\n\n\n\n    s->packet = 0;\n\n\n\n    // Parse backward compatible core sub-stream\n\n    if (AV_RB32(input) == DCA_SYNCWORD_CORE_BE) {\n\n        int frame_size;\n\n\n\n        if ((ret = ff_dca_core_parse(&s->core, input, input_size)) < 0)\n\n            return ret;\n\n\n\n        s->packet |= DCA_PACKET_CORE;\n\n\n\n        // EXXS data must be aligned on 4-byte boundary\n\n        frame_size = FFALIGN(s->core.frame_size, 4);\n\n        if (input_size - 4 > frame_size) {\n\n            input      += frame_size;\n\n            input_size -= frame_size;\n\n        }\n\n    }\n\n\n\n    if (!s->core_only) {\n\n        DCAExssAsset *asset = NULL;\n\n\n\n        // Parse extension sub-stream (EXSS)\n\n        if (AV_RB32(input) == DCA_SYNCWORD_SUBSTREAM) {\n\n            if ((ret = ff_dca_exss_parse(&s->exss, input, input_size)) < 0) {\n\n                if (avctx->err_recognition & AV_EF_EXPLODE)\n\n                    return ret;\n\n            } else {\n\n                s->packet |= DCA_PACKET_EXSS;\n\n                asset = &s->exss.assets[0];\n\n            }\n\n        }\n\n\n\n        // Parse XLL component in EXSS\n\n        if (asset && (asset->extension_mask & DCA_EXSS_XLL)) {\n\n            if ((ret = ff_dca_xll_parse(&s->xll, input, asset)) < 0) {\n\n                // Conceal XLL synchronization error\n\n                if (ret == AVERROR(EAGAIN)\n\n                    && (prev_packet & DCA_PACKET_XLL)\n\n                    && (s->packet & DCA_PACKET_CORE))\n\n                    s->packet |= DCA_PACKET_XLL | DCA_PACKET_RECOVERY;\n\n                else if (ret == AVERROR(ENOMEM) || (avctx->err_recognition & AV_EF_EXPLODE))\n\n                    return ret;\n\n            } else {\n\n                s->packet |= DCA_PACKET_XLL;\n\n            }\n\n        }\n\n\n\n        // Parse LBR component in EXSS\n\n        if (asset && (asset->extension_mask & DCA_EXSS_LBR)) {\n\n            if ((ret = ff_dca_lbr_parse(&s->lbr, input, asset)) < 0) {\n\n                if (ret == AVERROR(ENOMEM) || (avctx->err_recognition & AV_EF_EXPLODE))\n\n                    return ret;\n\n            } else {\n\n                s->packet |= DCA_PACKET_LBR;\n\n            }\n\n        }\n\n\n\n        // Parse core extensions in EXSS or backward compatible core sub-stream\n\n        if ((s->packet & DCA_PACKET_CORE)\n\n            && (ret = ff_dca_core_parse_exss(&s->core, input, asset)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    // Filter the frame\n\n    if (s->packet & DCA_PACKET_LBR) {\n\n        if ((ret = ff_dca_lbr_filter_frame(&s->lbr, frame)) < 0)\n\n            return ret;\n\n    } else if (s->packet & DCA_PACKET_XLL) {\n\n        if (s->packet & DCA_PACKET_CORE) {\n\n            int x96_synth = -1;\n\n\n\n            // Enable X96 synthesis if needed\n\n            if (s->xll.chset[0].freq == 96000 && s->core.sample_rate == 48000)\n\n                x96_synth = 1;\n\n\n\n            if ((ret = ff_dca_core_filter_fixed(&s->core, x96_synth)) < 0)\n\n                return ret;\n\n\n\n            // Force lossy downmixed output on the first core frame filtered.\n\n            // This prevents audible clicks when seeking and is consistent with\n\n            // what reference decoder does when there are multiple channel sets.\n\n            if (!(prev_packet & DCA_PACKET_RESIDUAL) && s->xll.nreschsets > 0\n\n                && s->xll.nchsets > 1) {\n\n                av_log(avctx, AV_LOG_VERBOSE, \"Forcing XLL recovery mode\\n\");\n\n                s->packet |= DCA_PACKET_RECOVERY;\n\n            }\n\n\n\n            // Set 'residual ok' flag for the next frame\n\n            s->packet |= DCA_PACKET_RESIDUAL;\n\n        }\n\n\n\n        if ((ret = ff_dca_xll_filter_frame(&s->xll, frame)) < 0) {\n\n            // Fall back to core unless hard error\n\n            if (!(s->packet & DCA_PACKET_CORE))\n\n                return ret;\n\n            if (ret != AVERROR_INVALIDDATA || (avctx->err_recognition & AV_EF_EXPLODE))\n\n                return ret;\n\n            if ((ret = ff_dca_core_filter_frame(&s->core, frame)) < 0)\n\n                return ret;\n\n        }\n\n    } else if (s->packet & DCA_PACKET_CORE) {\n\n        if ((ret = ff_dca_core_filter_frame(&s->core, frame)) < 0)\n\n            return ret;\n\n        if (s->core.filter_mode & DCA_FILTER_MODE_FIXED)\n\n            s->packet |= DCA_PACKET_RESIDUAL;\n\n    } else {\n\n        av_log(avctx, AV_LOG_ERROR, \"No valid DCA sub-stream found\\n\");\n\n        if (s->core_only)\n\n            av_log(avctx, AV_LOG_WARNING, \"Consider disabling 'core_only' option\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    *got_frame_ptr = 1;\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 23332}
{"project": "FFmpeg", "commit_id": "69e456d7fbc5fff88acf747d135bf15c8e511c59", "target": 0, "func": "static int iszero(const int16_t *c, int sz)\n\n{\n\n    int n;\n\n\n\n    for (n = 0; n < sz; n += 4)\n\n        if (AV_RN32A(&c[n]))\n\n            return 0;\n\n\n\n    return 1;\n\n}\n", "idx": 23333}
{"project": "FFmpeg", "commit_id": "121d3875b692c83866928e271c4b6d20d680d1a6", "target": 0, "func": "void avpriv_set_pts_info(AVStream *s, int pts_wrap_bits,\n\n                         unsigned int pts_num, unsigned int pts_den)\n\n{\n\n    AVRational new_tb;\n\n    if(av_reduce(&new_tb.num, &new_tb.den, pts_num, pts_den, INT_MAX)){\n\n        if(new_tb.num != pts_num)\n\n            av_log(NULL, AV_LOG_DEBUG, \"st:%d removing common factor %d from timebase\\n\", s->index, pts_num/new_tb.num);\n\n    }else\n\n        av_log(NULL, AV_LOG_WARNING, \"st:%d has too large timebase, reducing\\n\", s->index);\n\n\n\n    if(new_tb.num <= 0 || new_tb.den <= 0) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Ignoring attempt to set invalid timebase for st:%d\\n\", s->index);\n\n        return;\n\n    }\n\n    s->time_base = new_tb;\n\n    s->pts_wrap_bits = pts_wrap_bits;\n\n}\n", "idx": 23334}
{"project": "FFmpeg", "commit_id": "80bfce35ccd11458e97f68f417fc094c5347070c", "target": 1, "func": "static void RENAME(interleaveBytes)(const uint8_t *src1, const uint8_t *src2, uint8_t *dest,\n\n                                    int width, int height, int src1Stride,\n\n                                    int src2Stride, int dstStride)\n\n{\n\n    int h;\n\n\n\n    for (h=0; h < height; h++) {\n\n        int w;\n\n\n\n        if (width >= 16)\n\n#if COMPILE_TEMPLATE_SSE2\n\n        __asm__(\n\n            \"xor              %%\"REG_a\", %%\"REG_a\"  \\n\\t\"\n\n            \"1:                                     \\n\\t\"\n\n            PREFETCH\" 64(%1, %%\"REG_a\")             \\n\\t\"\n\n            PREFETCH\" 64(%2, %%\"REG_a\")             \\n\\t\"\n\n            \"movdqa     (%1, %%\"REG_a\"), %%xmm0     \\n\\t\"\n\n            \"movdqa     (%1, %%\"REG_a\"), %%xmm1     \\n\\t\"\n\n            \"movdqa     (%2, %%\"REG_a\"), %%xmm2     \\n\\t\"\n\n            \"punpcklbw           %%xmm2, %%xmm0     \\n\\t\"\n\n            \"punpckhbw           %%xmm2, %%xmm1     \\n\\t\"\n\n            \"movntdq             %%xmm0,   (%0, %%\"REG_a\", 2)   \\n\\t\"\n\n            \"movntdq             %%xmm1, 16(%0, %%\"REG_a\", 2)   \\n\\t\"\n\n            \"add                    $16, %%\"REG_a\"  \\n\\t\"\n\n            \"cmp                     %3, %%\"REG_a\"  \\n\\t\"\n\n            \" jb                     1b             \\n\\t\"\n\n            ::\"r\"(dest), \"r\"(src1), \"r\"(src2), \"r\" ((x86_reg)width-15)\n\n            : \"memory\", XMM_CLOBBERS(\"xmm0\", \"xmm1\", \"xmm2\",) \"%\"REG_a\n\n        );\n\n#else\n\n        __asm__(\n\n            \"xor %%\"REG_a\", %%\"REG_a\"               \\n\\t\"\n\n            \"1:                                     \\n\\t\"\n\n            PREFETCH\" 64(%1, %%\"REG_a\")             \\n\\t\"\n\n            PREFETCH\" 64(%2, %%\"REG_a\")             \\n\\t\"\n\n            \"movq       (%1, %%\"REG_a\"), %%mm0      \\n\\t\"\n\n            \"movq      8(%1, %%\"REG_a\"), %%mm2      \\n\\t\"\n\n            \"movq                 %%mm0, %%mm1      \\n\\t\"\n\n            \"movq                 %%mm2, %%mm3      \\n\\t\"\n\n            \"movq       (%2, %%\"REG_a\"), %%mm4      \\n\\t\"\n\n            \"movq      8(%2, %%\"REG_a\"), %%mm5      \\n\\t\"\n\n            \"punpcklbw            %%mm4, %%mm0      \\n\\t\"\n\n            \"punpckhbw            %%mm4, %%mm1      \\n\\t\"\n\n            \"punpcklbw            %%mm5, %%mm2      \\n\\t\"\n\n            \"punpckhbw            %%mm5, %%mm3      \\n\\t\"\n\n            MOVNTQ\"               %%mm0,   (%0, %%\"REG_a\", 2)   \\n\\t\"\n\n            MOVNTQ\"               %%mm1,  8(%0, %%\"REG_a\", 2)   \\n\\t\"\n\n            MOVNTQ\"               %%mm2, 16(%0, %%\"REG_a\", 2)   \\n\\t\"\n\n            MOVNTQ\"               %%mm3, 24(%0, %%\"REG_a\", 2)   \\n\\t\"\n\n            \"add                    $16, %%\"REG_a\"  \\n\\t\"\n\n            \"cmp                     %3, %%\"REG_a\"  \\n\\t\"\n\n            \" jb                     1b             \\n\\t\"\n\n            ::\"r\"(dest), \"r\"(src1), \"r\"(src2), \"r\" ((x86_reg)width-15)\n\n            : \"memory\", \"%\"REG_a\n\n        );\n\n#endif\n\n        for (w= (width&(~15)); w < width; w++) {\n\n            dest[2*w+0] = src1[w];\n\n            dest[2*w+1] = src2[w];\n\n        }\n\n        dest += dstStride;\n\n        src1 += src1Stride;\n\n        src2 += src2Stride;\n\n    }\n\n    __asm__(\n\n#if !COMPILE_TEMPLATE_SSE2\n\n            EMMS\"       \\n\\t\"\n\n#endif\n\n            SFENCE\"     \\n\\t\"\n\n            ::: \"memory\"\n\n            );\n\n}\n", "idx": 23340}
{"project": "FFmpeg", "commit_id": "7c10068da10aa288195f5eb5d7e34eb2d8ff7447", "target": 1, "func": "static int dvbsub_parse_page_segment(AVCodecContext *avctx,\n                                     const uint8_t *buf, int buf_size, AVSubtitle *sub, int *got_output)\n{\n    DVBSubContext *ctx = avctx->priv_data;\n    DVBSubRegionDisplay *display;\n    DVBSubRegionDisplay *tmp_display_list, **tmp_ptr;\n    const uint8_t *buf_end = buf + buf_size;\n    int region_id;\n    int page_state;\n    int timeout;\n    int version;\n    if (buf_size < 1)\n        return AVERROR_INVALIDDATA;\n    timeout = *buf++;\n    version = ((*buf)>>4) & 15;\n    page_state = ((*buf++) >> 2) & 3;\n    if (ctx->version == version) {\n        return 0;\n    ctx->time_out = timeout;\n    ctx->version = version;\n    ff_dlog(avctx, \"Page time out %ds, state %d\\n\", ctx->time_out, page_state);\n    if(ctx->compute_edt == 1)\n        save_subtitle_set(avctx, sub, got_output);\n    if (page_state == 1 || page_state == 2) {\n        delete_regions(ctx);\n        delete_objects(ctx);\n        delete_cluts(ctx);\n    tmp_display_list = ctx->display_list;\n    ctx->display_list = NULL;\n    while (buf + 5 < buf_end) {\n        region_id = *buf++;\n        buf += 1;\n        display = tmp_display_list;\n        tmp_ptr = &tmp_display_list;\n            tmp_ptr = &display->next;\n        if (!display) {\n            display = av_mallocz(sizeof(DVBSubRegionDisplay));\n            if (!display)\n                return AVERROR(ENOMEM);\n        display->region_id = region_id;\n        display->x_pos = AV_RB16(buf);\n        buf += 2;\n        display->y_pos = AV_RB16(buf);\n        buf += 2;\n        *tmp_ptr = display->next;\n        display->next = ctx->display_list;\n        ctx->display_list = display;\n        ff_dlog(avctx, \"Region %d, (%d,%d)\\n\", region_id, display->x_pos, display->y_pos);\n    while (tmp_display_list) {\n        display = tmp_display_list;\n        tmp_display_list = display->next;\n        av_freep(&display);\n    return 0;", "idx": 23341}
{"project": "FFmpeg", "commit_id": "f80224ed19a4c012549fd460d529c7c04e68cf21", "target": 1, "func": "static inline void ls_decode_line(JLSState *state, MJpegDecodeContext *s,\n                                  void *last, void *dst, int last2, int w,\n                                  int stride, int comp, int bits)\n{\n    int i, x = 0;\n    int Ra, Rb, Rc, Rd;\n    int D0, D1, D2;\n    while (x < w) {\n        int err, pred;\n        /* compute gradients */\n        Ra = x ? R(dst, x - stride) : R(last, x);\n        Rb = R(last, x);\n        Rc = x ? R(last, x - stride) : last2;\n        Rd = (x >= w - stride) ? R(last, x) : R(last, x + stride);\n        D0 = Rd - Rb;\n        D1 = Rb - Rc;\n        D2 = Rc - Ra;\n        /* run mode */\n        if ((FFABS(D0) <= state->near) &&\n            (FFABS(D1) <= state->near) &&\n            (FFABS(D2) <= state->near)) {\n            int r;\n            int RItype;\n            /* decode full runs while available */\n            while (get_bits1(&s->gb)) {\n                int r;\n                r = 1 << ff_log2_run[state->run_index[comp]];\n                if (x + r * stride > w)\n                    r = (w - x) / stride;\n                for (i = 0; i < r; i++) {\n                    W(dst, x, Ra);\n                    x += stride;\n                }\n                /* if EOL reached, we stop decoding */\n                if (r != 1 << ff_log2_run[state->run_index[comp]])\n                if (state->run_index[comp] < 31)\n                    state->run_index[comp]++;\n                if (x + stride > w)\n            }\n            /* decode aborted run */\n            r = ff_log2_run[state->run_index[comp]];\n            if (r)\n                r = get_bits_long(&s->gb, r);\n            if (x + r * stride > w) {\n                r = (w - x) / stride;\n            }\n            for (i = 0; i < r; i++) {\n                W(dst, x, Ra);\n                x += stride;\n            }\n            if (x >= w) {\n                av_log(NULL, AV_LOG_ERROR, \"run overflow\\n\");\n                av_assert0(x <= w);\n            }\n            /* decode run termination value */\n            Rb     = R(last, x);\n            RItype = (FFABS(Ra - Rb) <= state->near) ? 1 : 0;\n            err    = ls_get_code_runterm(&s->gb, state, RItype,\n                                         ff_log2_run[state->run_index[comp]]);\n            if (state->run_index[comp])\n                state->run_index[comp]--;\n            if (state->near && RItype) {\n                pred = Ra + err;\n            } else {\n                if (Rb < Ra)\n                    pred = Rb - err;\n                else\n                    pred = Rb + err;\n            }\n        } else { /* regular mode */\n            int context, sign;\n            context = ff_jpegls_quantize(state, D0) * 81 +\n                      ff_jpegls_quantize(state, D1) *  9 +\n                      ff_jpegls_quantize(state, D2);\n            pred    = mid_pred(Ra, Ra + Rb - Rc, Rb);\n            if (context < 0) {\n                context = -context;\n                sign    = 1;\n            } else {\n                sign = 0;\n            }\n            if (sign) {\n                pred = av_clip(pred - state->C[context], 0, state->maxval);\n                err  = -ls_get_code_regular(&s->gb, state, context);\n            } else {\n                pred = av_clip(pred + state->C[context], 0, state->maxval);\n                err  = ls_get_code_regular(&s->gb, state, context);\n            }\n            /* we have to do something more for near-lossless coding */\n            pred += err;\n        }\n        if (state->near) {\n            if (pred < -state->near)\n                pred += state->range * state->twonear;\n            else if (pred > state->maxval + state->near)\n                pred -= state->range * state->twonear;\n            pred = av_clip(pred, 0, state->maxval);\n        }\n        pred &= state->maxval;\n        W(dst, x, pred);\n        x += stride;\n    }\n}", "idx": 23342}
{"project": "FFmpeg", "commit_id": "5484170ac729d739b2747979408f47bd9aa31c7c", "target": 1, "func": "static int finish_frame(AVCodecContext *avctx, AVFrame *pict)\n\n{\n\n    RV34DecContext *r = avctx->priv_data;\n\n    MpegEncContext *s = &r->s;\n\n    int got_picture = 0;\n\n\n\n    ff_er_frame_end(s);\n\n    ff_MPV_frame_end(s);\n\n\n\n\n    if (HAVE_THREADS && (s->avctx->active_thread_type & FF_THREAD_FRAME))\n\n        ff_thread_report_progress(&s->current_picture_ptr->f, INT_MAX, 0);\n\n\n\n    if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n\n        *pict = s->current_picture_ptr->f;\n\n        got_picture = 1;\n\n    } else if (s->last_picture_ptr != NULL) {\n\n        *pict = s->last_picture_ptr->f;\n\n        got_picture = 1;\n\n    }\n\n    if (got_picture)\n\n        ff_print_debug_info(s, pict);\n\n\n\n    return got_picture;\n\n}", "idx": 23343}
{"project": "FFmpeg", "commit_id": "289520fd97395ffd5bf933ac80487e858bc4039d", "target": 0, "func": "static int load_matrix(MpegEncContext *s, uint16_t matrix0[64], uint16_t matrix1[64], int intra)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 64; i++) {\n\n        int j = s->dsp.idct_permutation[ff_zigzag_direct[i]];\n\n        int v = get_bits(&s->gb, 8);\n\n        if (v == 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"matrix damaged\\n\");\n\n            return -1;\n\n        }\n\n        if (intra && i == 0 && v != 8) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"intra matrix specifies invalid DC quantizer %d, ignoring\\n\", v);\n\n            v = 8; // needed by pink.mpg / issue1046\n\n        }\n\n        matrix0[j] = v;\n\n        if (matrix1)\n\n            matrix1[j] = v;\n\n    }\n\n    return 0;\n\n}\n", "idx": 23344}
{"project": "FFmpeg", "commit_id": "6029b8a6bbc8bbf7799108582e71078ec0bde1cf", "target": 0, "func": "static int s337m_probe(AVProbeData *p)\n\n{\n\n    uint64_t state = 0;\n\n    int markers[3] = { 0 };\n\n    int i, sum, max, data_type, data_size, offset;\n\n    uint8_t *buf;\n\n\n\n    for (buf = p->buf; buf < p->buf + p->buf_size; buf++) {\n\n        state = (state << 8) | *buf;\n\n        if (!IS_LE_MARKER(state))\n\n            continue;\n\n\n\n        if (IS_16LE_MARKER(state)) {\n\n            data_type = AV_RL16(buf + 1);\n\n            data_size = AV_RL16(buf + 3);\n\n            buf += 4;\n\n        } else {\n\n            data_type = AV_RL24(buf + 1);\n\n            data_size = AV_RL24(buf + 4);\n\n            buf += 6;\n\n        }\n\n\n\n        if (s337m_get_offset_and_codec(NULL, state, data_type, data_size, &offset, NULL))\n\n            continue;\n\n\n\n        i = IS_16LE_MARKER(state) ? 0 : IS_20LE_MARKER(state) ? 1 : 2;\n\n        markers[i]++;\n\n\n\n        buf  += offset;\n\n        state = 0;\n\n    }\n\n\n\n    sum = max = 0;\n\n    for (i = 0; i < FF_ARRAY_ELEMS(markers); i++) {\n\n        sum += markers[i];\n\n        if (markers[max] < markers[i])\n\n            max = i;\n\n    }\n\n\n\n    if (markers[max] > 3 && markers[max] * 4 > sum * 3)\n\n        return AVPROBE_SCORE_EXTENSION + 1;\n\n\n\n    return 0;\n\n}\n", "idx": 23345}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(yuv2nv12X)(SwsContext *c, const int16_t *lumFilter, const int16_t **lumSrc, int lumFilterSize,\n\n                                     const int16_t *chrFilter, const int16_t **chrSrc, int chrFilterSize,\n\n                                     uint8_t *dest, uint8_t *uDest, int dstW, int chrDstW, enum PixelFormat dstFormat)\n\n{\n\n    yuv2nv12XinC(lumFilter, lumSrc, lumFilterSize,\n\n                 chrFilter, chrSrc, chrFilterSize,\n\n                 dest, uDest, dstW, chrDstW, dstFormat);\n\n}\n", "idx": 23346}
{"project": "FFmpeg", "commit_id": "0d65e0f8cb0f924be95650f50f3d05d0b223aceb", "target": 1, "func": "int get_filtered_video_frame(AVFilterContext *ctx, AVFrame *frame,\n\n                             AVFilterBufferRef **picref_ptr, AVRational *tb)\n\n{\n\n    int ret;\n\n    AVFilterBufferRef *picref;\n\n\n\n\n    if ((ret = avfilter_request_frame(ctx->inputs[0])) < 0)\n\n        return ret;\n\n    if (!(picref = ctx->inputs[0]->cur_buf))\n\n        return AVERROR(ENOENT);\n\n    *picref_ptr = picref;\n\n    ctx->inputs[0]->cur_buf = NULL;\n\n    *tb = ctx->inputs[0]->time_base;\n\n\n\n    memcpy(frame->data,     picref->data,     sizeof(frame->data));\n\n    memcpy(frame->linesize, picref->linesize, sizeof(frame->linesize));\n\n    frame->pkt_pos          = picref->pos;\n\n    frame->interlaced_frame = picref->video->interlaced;\n\n    frame->top_field_first  = picref->video->top_field_first;\n\n    frame->key_frame        = picref->video->key_frame;\n\n    frame->pict_type        = picref->video->pict_type;\n\n    frame->sample_aspect_ratio = picref->video->sample_aspect_ratio;\n\n\n\n    return 1;\n\n}", "idx": 23348}
{"project": "FFmpeg", "commit_id": "3d9cb583c8f005a260d255853ef5f1c21e8599a0", "target": 1, "func": "static int hq_decode_block(HQContext *c, GetBitContext *gb, int16_t block[64],\n\n                           int qsel, int is_chroma, int is_hqa)\n\n{\n\n    const int32_t *q;\n\n    int val, pos = 1;\n\n\n\n    memset(block, 0, 64 * sizeof(*block));\n\n\n\n    if (!is_hqa) {\n\n        block[0] = get_sbits(gb, 9) * 64;\n\n        q = ff_hq_quants[qsel][is_chroma][get_bits(gb, 2)];\n\n    } else {\n\n        q = ff_hq_quants[qsel][is_chroma][get_bits(gb, 2)];\n\n        block[0] = get_sbits(gb, 9) * 64;\n\n    }\n\n\n\n    for (;;) {\n\n        val = get_vlc2(gb, c->hq_ac_vlc.table, 9, 2);\n\n        if (val < 0)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        pos += ff_hq_ac_skips[val];\n\n        if (pos >= 64)\n\n            break;\n\n        block[ff_zigzag_direct[pos]] = (ff_hq_ac_syms[val] * q[pos]) >> 12;\n\n        pos++;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23350}
{"project": "FFmpeg", "commit_id": "af19f78f2fe2b969104d4419efd25fdee90a2814", "target": 0, "func": "void dsputil_init_alpha(void)\n\n{\n\n    put_pixels_tab[0][0] = put_pixels16_axp_asm;\n\n    put_pixels_tab[0][1] = put_pixels16_x2_axp;\n\n    put_pixels_tab[0][2] = put_pixels16_y2_axp;\n\n    put_pixels_tab[0][3] = put_pixels16_xy2_axp;\n\n\n\n    put_no_rnd_pixels_tab[0][0] = put_pixels16_axp_asm;\n\n    put_no_rnd_pixels_tab[0][1] = put_no_rnd_pixels16_x2_axp;\n\n    put_no_rnd_pixels_tab[0][2] = put_no_rnd_pixels16_y2_axp;\n\n    put_no_rnd_pixels_tab[0][3] = put_no_rnd_pixels16_xy2_axp;\n\n\n\n    avg_pixels_tab[0][0] = avg_pixels16_axp;\n\n    avg_pixels_tab[0][1] = avg_pixels16_x2_axp;\n\n    avg_pixels_tab[0][2] = avg_pixels16_y2_axp;\n\n    avg_pixels_tab[0][3] = avg_pixels16_xy2_axp;\n\n\n\n    avg_no_rnd_pixels_tab[0][0] = avg_no_rnd_pixels16_axp;\n\n    avg_no_rnd_pixels_tab[0][1] = avg_no_rnd_pixels16_x2_axp;\n\n    avg_no_rnd_pixels_tab[0][2] = avg_no_rnd_pixels16_y2_axp;\n\n    avg_no_rnd_pixels_tab[0][3] = avg_no_rnd_pixels16_xy2_axp;\n\n\n\n    put_pixels_tab[1][0] = put_pixels_axp_asm;\n\n    put_pixels_tab[1][1] = put_pixels_x2_axp;\n\n    put_pixels_tab[1][2] = put_pixels_y2_axp;\n\n    put_pixels_tab[1][3] = put_pixels_xy2_axp;\n\n\n\n    put_no_rnd_pixels_tab[1][0] = put_pixels_axp_asm;\n\n    put_no_rnd_pixels_tab[1][1] = put_no_rnd_pixels_x2_axp;\n\n    put_no_rnd_pixels_tab[1][2] = put_no_rnd_pixels_y2_axp;\n\n    put_no_rnd_pixels_tab[1][3] = put_no_rnd_pixels_xy2_axp;\n\n\n\n    avg_pixels_tab[1][0] = avg_pixels_axp;\n\n    avg_pixels_tab[1][1] = avg_pixels_x2_axp;\n\n    avg_pixels_tab[1][2] = avg_pixels_y2_axp;\n\n    avg_pixels_tab[1][3] = avg_pixels_xy2_axp;\n\n\n\n    avg_no_rnd_pixels_tab[1][0] = avg_no_rnd_pixels_axp;\n\n    avg_no_rnd_pixels_tab[1][1] = avg_no_rnd_pixels_x2_axp;\n\n    avg_no_rnd_pixels_tab[1][2] = avg_no_rnd_pixels_y2_axp;\n\n    avg_no_rnd_pixels_tab[1][3] = avg_no_rnd_pixels_xy2_axp;\n\n\n\n    clear_blocks = clear_blocks_axp;\n\n\n\n    /* amask clears all bits that correspond to present features.  */\n\n    if (amask(AMASK_MVI) == 0) {\n\n        put_pixels_clamped = put_pixels_clamped_mvi_asm;\n\n        add_pixels_clamped = add_pixels_clamped_mvi_asm;\n\n\n\n        get_pixels       = get_pixels_mvi;\n\n        diff_pixels      = diff_pixels_mvi;\n\n        pix_abs8x8       = pix_abs8x8_mvi;\n\n        pix_abs16x16     = pix_abs16x16_mvi_asm;\n\n        pix_abs16x16_x2  = pix_abs16x16_x2_mvi;\n\n        pix_abs16x16_y2  = pix_abs16x16_y2_mvi;\n\n        pix_abs16x16_xy2 = pix_abs16x16_xy2_mvi;\n\n    }\n\n}\n", "idx": 23351}
{"project": "FFmpeg", "commit_id": "fc3a03fcf9cd7eafe7342e2508e6128888efa0bb", "target": 1, "func": "AVFrame *ff_framequeue_take(FFFrameQueue *fq)\n\n{\n\n    FFFrameBucket *b;\n\n\n\n    check_consistency(fq);\n\n    av_assert1(fq->queued);\n\n    b = bucket(fq, 0);\n\n    fq->queued--;\n\n    fq->tail++;\n\n    fq->tail &= fq->allocated - 1;\n\n    fq->total_frames_tail++;\n\n    fq->total_samples_tail += b->frame->nb_samples;\n\n\n    check_consistency(fq);\n\n    return b->frame;\n\n}", "idx": 23357}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static int copy_from(IpvideoContext *s, AVFrame *src, AVFrame *dst, int delta_x, int delta_y)\n\n{\n\n    int current_offset = s->pixel_ptr - dst->data[0];\n\n    int motion_offset = current_offset + delta_y * dst->linesize[0]\n\n                       + delta_x * (1 + s->is_16bpp);\n\n    if (motion_offset < 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \" Interplay video: motion offset < 0 (%d)\\n\", motion_offset);\n\n        return AVERROR_INVALIDDATA;\n\n    } else if (motion_offset > s->upper_motion_limit_offset) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \" Interplay video: motion offset above limit (%d >= %d)\\n\",\n\n            motion_offset, s->upper_motion_limit_offset);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (src->data[0] == NULL) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid decode type, corrupted header?\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    s->hdsp.put_pixels_tab[!s->is_16bpp][0](s->pixel_ptr, src->data[0] + motion_offset,\n\n                                            dst->linesize[0], 8);\n\n    return 0;\n\n}\n", "idx": 23361}
{"project": "FFmpeg", "commit_id": "fb9187129c3d07ac6d0f7deaa27f1248394d8f91", "target": 0, "func": "void av_log_format_line(void *ptr, int level, const char *fmt, va_list vl,\n\n                        char *line, int line_size, int *print_prefix)\n\n{\n\n    AVBPrint part[4];\n\n    format_line(ptr, level, fmt, vl, part, print_prefix, NULL);\n\n    snprintf(line, line_size, \"%s%s%s%s\", part[0].str, part[1].str, part[2].str, part[3].str);\n\n    av_bprint_finalize(part+3, NULL);\n\n}\n", "idx": 23372}
{"project": "FFmpeg", "commit_id": "83fd377c94d8fbffdb3e69fb3efe1976ff897a88", "target": 0, "func": "int ff_j2k_init_component(Jpeg2000Component *comp,\n\n                          Jpeg2000CodingStyle *codsty,\n\n                          Jpeg2000QuantStyle *qntsty,\n\n                          int cbps, int dx, int dy,\n\n                          AVCodecContext *avctx)\n\n{\n\n    uint8_t log2_band_prec_width, log2_band_prec_height;\n\n    int reslevelno, bandno, gbandno = 0, ret, i, j, csize = 1;\n\n\n\n    if (ret=ff_jpeg2000_dwt_init(&comp->dwt, comp->coord, codsty->nreslevels2decode-1, codsty->transform == FF_DWT53 ? FF_DWT53 : FF_DWT97_INT))\n\n        return ret;\n\n    for (i = 0; i < 2; i++)\n\n        csize *= comp->coord[i][1] - comp->coord[i][0];\n\n\n\n    comp->data = av_malloc_array(csize, sizeof(*comp->data));\n\n    if (!comp->data)\n\n        return AVERROR(ENOMEM);\n\n    comp->reslevel = av_malloc_array(codsty->nreslevels, sizeof(*comp->reslevel));\n\n    if (!comp->reslevel)\n\n        return AVERROR(ENOMEM);\n\n    /* LOOP on resolution levels */\n\n    for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) {\n\n        int declvl = codsty->nreslevels - reslevelno;    // N_L -r see  ISO/IEC 15444-1:2002 B.5\n\n        Jpeg2000ResLevel *reslevel = comp->reslevel + reslevelno;\n\n\n\n        /* Compute borders for each resolution level.\n\n         * Computation of trx_0, trx_1, try_0 and try_1.\n\n         * see ISO/IEC 15444-1:2002 eq. B.5 and B-14 */\n\n        for (i = 0; i < 2; i++)\n\n            for (j = 0; j < 2; j++)\n\n                reslevel->coord[i][j] =\n\n                    ff_jpeg2000_ceildivpow2(comp->coord_o[i][j], declvl - 1);\n\n        // update precincts size: 2^n value\n\n        reslevel->log2_prec_width  = codsty->log2_prec_widths[reslevelno];\n\n        reslevel->log2_prec_height = codsty->log2_prec_heights[reslevelno];\n\n\n\n        /* Number of bands for each resolution level */\n\n        if (reslevelno == 0)\n\n            reslevel->nbands = 1;\n\n        else\n\n            reslevel->nbands = 3;\n\n\n\n        /* Number of precincts wich span the tile for resolution level reslevelno\n\n         * see B.6 in ISO/IEC 15444-1:2002 eq. B-16\n\n         * num_precincts_x = |- trx_1 / 2 ^ log2_prec_width) -| - (trx_0 / 2 ^ log2_prec_width)\n\n         * num_precincts_y = |- try_1 / 2 ^ log2_prec_width) -| - (try_0 / 2 ^ log2_prec_width)\n\n         * for Dcinema profiles in JPEG 2000\n\n         * num_precincts_x = |- trx_1 / 2 ^ log2_prec_width) -|\n\n         * num_precincts_y = |- try_1 / 2 ^ log2_prec_width) -| */\n\n        if (reslevel->coord[0][1] == reslevel->coord[0][0])\n\n            reslevel->num_precincts_x = 0;\n\n        else\n\n            reslevel->num_precincts_x =\n\n                ff_jpeg2000_ceildivpow2(reslevel->coord[0][1],\n\n                                        reslevel->log2_prec_width) -\n\n                (reslevel->coord[0][0] >> reslevel->log2_prec_width);\n\n\n\n        if (reslevel->coord[1][1] == reslevel->coord[1][0])\n\n            reslevel->num_precincts_y = 0;\n\n        else\n\n            reslevel->num_precincts_y =\n\n                ff_jpeg2000_ceildivpow2(reslevel->coord[1][1],\n\n                                        reslevel->log2_prec_height) -\n\n                (reslevel->coord[1][0] >> reslevel->log2_prec_height);\n\n\n\n        reslevel->band = av_malloc_array(reslevel->nbands, sizeof(*reslevel->band));\n\n        if (!reslevel->band)\n\n            return AVERROR(ENOMEM);\n\n\n\n        for (bandno = 0; bandno < reslevel->nbands; bandno++, gbandno++) {\n\n            Jpeg2000Band *band = reslevel->band + bandno;\n\n            int cblkno, precno;\n\n            int nb_precincts;\n\n\n\n            /* TODO: Implementation of quantization step not finished,\n\n             * see ISO/IEC 15444-1:2002 E.1 and A.6.4. */\n\n            switch (qntsty->quantsty) {\n\n                uint8_t gain;\n\n                int numbps;\n\n            case JPEG2000_QSTY_NONE:\n\n                /* TODO: to verify. No quantization in this case */\n\n                band->f_stepsize = 1;\n\n                break;\n\n            case JPEG2000_QSTY_SI:\n\n                /*TODO: Compute formula to implement. */\n\n                numbps = cbps +\n\n                         lut_gain[codsty->transform][bandno + (reslevelno > 0)];\n\n                band->f_stepsize = SHL(2048 + qntsty->mant[gbandno],\n\n                                            2 + numbps - qntsty->expn[gbandno]);\n\n                break;\n\n            case JPEG2000_QSTY_SE:\n\n                /* Exponent quantization step.\n\n                 * Formula:\n\n                 * delta_b = 2 ^ (R_b - expn_b) * (1 + (mant_b / 2 ^ 11))\n\n                 * R_b = R_I + log2 (gain_b )\n\n                 * see ISO/IEC 15444-1:2002 E.1.1 eqn. E-3 and E-4 */\n\n                /* TODO/WARN: value of log2 (gain_b ) not taken into account\n\n                 * but it works (compared to OpenJPEG). Why?\n\n                 * Further investigation needed. */\n\n                gain      = cbps;\n\n                band->f_stepsize  = pow(2.0, gain - qntsty->expn[gbandno]);\n\n                band->f_stepsize *= (qntsty->mant[gbandno] / 2048.0 + 1.0);\n\n                break;\n\n            default:\n\n                band->f_stepsize = 0;\n\n                av_log(avctx, AV_LOG_ERROR, \"Unknown quantization format\\n\");\n\n                break;\n\n            }\n\n            /* FIXME: In openjepg code stespize = stepsize * 0.5. Why?\n\n             * If not set output of entropic decoder is not correct. */\n\n            if (!av_codec_is_encoder(avctx->codec))\n\n                band->f_stepsize *= 0.5;\n\n\n\n            band->i_stepsize = band->f_stepsize * (1 << 16);\n\n\n\n            /* computation of tbx_0, tbx_1, tby_0, tby_1\n\n             * see ISO/IEC 15444-1:2002 B.5 eq. B-15 and tbl B.1\n\n             * codeblock width and height is computed for\n\n             * DCI JPEG 2000 codeblock_width = codeblock_width = 32 = 2 ^ 5 */\n\n            if (reslevelno == 0) {\n\n                /* for reslevelno = 0, only one band, x0_b = y0_b = 0 */\n\n                for (i = 0; i < 2; i++)\n\n                    for (j = 0; j < 2; j++)\n\n                        band->coord[i][j] =\n\n                            ff_jpeg2000_ceildivpow2(comp->coord_o[i][j] - comp->coord_o[i][0],\n\n                                                    declvl - 1);\n\n                log2_band_prec_width  = reslevel->log2_prec_width;\n\n                log2_band_prec_height = reslevel->log2_prec_height;\n\n                /* see ISO/IEC 15444-1:2002 eq. B-17 and eq. B-15 */\n\n                band->log2_cblk_width  = FFMIN(codsty->log2_cblk_width,\n\n                                               reslevel->log2_prec_width);\n\n                band->log2_cblk_height = FFMIN(codsty->log2_cblk_height,\n\n                                               reslevel->log2_prec_height);\n\n            } else {\n\n                /* 3 bands x0_b = 1 y0_b = 0; x0_b = 0 y0_b = 1; x0_b = y0_b = 1 */\n\n                /* x0_b and y0_b are computed with ((bandno + 1 >> i) & 1) */\n\n                for (i = 0; i < 2; i++)\n\n                    for (j = 0; j < 2; j++)\n\n                        /* Formula example for tbx_0 = ceildiv((tcx_0 - 2 ^ (declvl - 1) * x0_b) / declvl) */\n\n                        band->coord[i][j] =\n\n                            ff_jpeg2000_ceildivpow2(comp->coord_o[i][j] - comp->coord_o[i][0] -\n\n                                                    (((bandno + 1 >> i) & 1) << declvl - 1),\n\n                                                    declvl);\n\n                /* TODO: Manage case of 3 band offsets here or\n\n                 * in coding/decoding function? */\n\n\n\n                /* see ISO/IEC 15444-1:2002 eq. B-17 and eq. B-15 */\n\n                band->log2_cblk_width  = FFMIN(codsty->log2_cblk_width,\n\n                                               reslevel->log2_prec_width - 1);\n\n                band->log2_cblk_height = FFMIN(codsty->log2_cblk_height,\n\n                                               reslevel->log2_prec_height - 1);\n\n\n\n                log2_band_prec_width  = reslevel->log2_prec_width  - 1;\n\n                log2_band_prec_height = reslevel->log2_prec_height - 1;\n\n            }\n\n\n\n            for (j = 0; j < 2; j++)\n\n                band->coord[0][j] = ff_jpeg2000_ceildiv(band->coord[0][j], dx);\n\n            for (j = 0; j < 2; j++)\n\n                band->coord[1][j] = ff_jpeg2000_ceildiv(band->coord[1][j], dy);\n\n\n\n            band->prec = av_malloc_array(reslevel->num_precincts_x *\n\n                                         reslevel->num_precincts_y,\n\n                                         sizeof(*band->prec));\n\n            if (!band->prec)\n\n                return AVERROR(ENOMEM);\n\n\n\n            nb_precincts = reslevel->num_precincts_x * reslevel->num_precincts_y;\n\n\n\n            for (precno = 0; precno < nb_precincts; precno++) {\n\n                Jpeg2000Prec *prec = band->prec + precno;\n\n\n\n                /* TODO: Explain formula for JPEG200 DCINEMA. */\n\n                /* TODO: Verify with previous count of codeblocks per band */\n\n\n\n                /* Compute P_x0 */\n\n                prec->coord[0][0] = (precno % reslevel->num_precincts_x) *\n\n                                    (1 << log2_band_prec_width);\n\n                prec->coord[0][0] = FFMAX(prec->coord[0][0], band->coord[0][0]);\n\n\n\n                /* Compute P_y0 */\n\n                prec->coord[1][0] = (precno / reslevel->num_precincts_x) *\n\n                                    (1 << log2_band_prec_height);\n\n                prec->coord[1][0] = FFMAX(prec->coord[1][0], band->coord[1][0]);\n\n\n\n                /* Compute P_x1 */\n\n                prec->coord[0][1] = prec->coord[0][0] +\n\n                                    (1 << log2_band_prec_width);\n\n                prec->coord[0][1] = FFMIN(prec->coord[0][1], band->coord[0][1]);\n\n\n\n                /* Compute P_y1 */\n\n                prec->coord[1][1] = prec->coord[1][0] +\n\n                                    (1 << log2_band_prec_height);\n\n                prec->coord[1][1] = FFMIN(prec->coord[1][1], band->coord[1][1]);\n\n\n\n                prec->nb_codeblocks_width =\n\n                    ff_jpeg2000_ceildivpow2(prec->coord[0][1] -\n\n                                            prec->coord[0][0],\n\n                                            band->log2_cblk_width);\n\n                prec->nb_codeblocks_height =\n\n                    ff_jpeg2000_ceildivpow2(prec->coord[1][1] -\n\n                                            prec->coord[1][0],\n\n                                            band->log2_cblk_height);\n\n\n\n                /* Tag trees initialization */\n\n                prec->cblkincl =\n\n                    ff_j2k_tag_tree_init(prec->nb_codeblocks_width,\n\n                                              prec->nb_codeblocks_height);\n\n                if (!prec->cblkincl)\n\n                    return AVERROR(ENOMEM);\n\n\n\n                prec->zerobits =\n\n                    ff_j2k_tag_tree_init(prec->nb_codeblocks_width,\n\n                                              prec->nb_codeblocks_height);\n\n                if (!prec->zerobits)\n\n                    return AVERROR(ENOMEM);\n\n\n\n                prec->cblk = av_malloc_array(prec->nb_codeblocks_width *\n\n                                             prec->nb_codeblocks_height,\n\n                                             sizeof(*prec->cblk));\n\n                if (!prec->cblk)\n\n                    return AVERROR(ENOMEM);\n\n                for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) {\n\n                    Jpeg2000Cblk *cblk = prec->cblk + cblkno;\n\n                    uint16_t Cx0, Cy0;\n\n\n\n                    /* Compute coordinates of codeblocks */\n\n                    /* Compute Cx0*/\n\n                    Cx0 = (prec->coord[0][0] >> band->log2_cblk_width) << band->log2_cblk_width;\n\n                    Cx0 = Cx0 + ((cblkno % prec->nb_codeblocks_width)  << band->log2_cblk_width);\n\n                    cblk->coord[0][0] = FFMAX(Cx0, prec->coord[0][0]);\n\n\n\n                    /* Compute Cy0*/\n\n                    Cy0 = (prec->coord[1][0] >> band->log2_cblk_height) << band->log2_cblk_height;\n\n                    Cy0 = Cy0 + ((cblkno / prec->nb_codeblocks_width)   << band->log2_cblk_height);\n\n                    cblk->coord[1][0] = FFMAX(Cy0, prec->coord[1][0]);\n\n\n\n                    /* Compute Cx1 */\n\n                    cblk->coord[0][1] = FFMIN(Cx0 + (1 << band->log2_cblk_width),\n\n                                              prec->coord[0][1]);\n\n\n\n                    /* Compute Cy1 */\n\n                    cblk->coord[1][1] = FFMIN(Cy0 + (1 << band->log2_cblk_height),\n\n                                              prec->coord[1][1]);\n\n\n\n                    if((bandno + !!reslevelno) & 1) {\n\n                        cblk->coord[0][0] += comp->reslevel[reslevelno-1].coord[0][1] - comp->reslevel[reslevelno-1].coord[0][0];\n\n                        cblk->coord[0][1] += comp->reslevel[reslevelno-1].coord[0][1] - comp->reslevel[reslevelno-1].coord[0][0];\n\n                    }\n\n                    if((bandno + !!reslevelno) & 2) {\n\n                        cblk->coord[1][0] += comp->reslevel[reslevelno-1].coord[1][1] - comp->reslevel[reslevelno-1].coord[1][0];\n\n                        cblk->coord[1][1] += comp->reslevel[reslevelno-1].coord[1][1] - comp->reslevel[reslevelno-1].coord[1][0];\n\n                    }\n\n\n\n                    cblk->zero      = 0;\n\n                    cblk->lblock    = 3;\n\n                    cblk->length    = 0;\n\n                    cblk->lengthinc = 0;\n\n                    cblk->npasses   = 0;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 23383}
{"project": "FFmpeg", "commit_id": "38beab19ab3b997bcbe2e95699d4952922f1f673", "target": 1, "func": "static int r3d_read_redv(AVFormatContext *s, AVPacket *pkt, Atom *atom)\n\n{\n\n    AVStream *st = s->streams[0];\n\n    int tmp, tmp2;\n\n    uint64_t pos = url_ftell(s->pb);\n\n    unsigned dts;\n\n\n\n    dts = get_be32(s->pb);\n\n\n\n    tmp = get_be32(s->pb);\n\n    dprintf(s, \"frame num %d\\n\", tmp);\n\n\n\n    tmp  = get_byte(s->pb); // major version\n\n    tmp2 = get_byte(s->pb); // minor version\n\n    dprintf(s, \"version %d.%d\\n\", tmp, tmp2);\n\n\n\n    tmp = get_be16(s->pb); // unknown\n\n    dprintf(s, \"unknown %d\\n\", tmp);\n\n\n\n    if (tmp > 4) {\n\n        tmp = get_be16(s->pb); // unknown\n\n        dprintf(s, \"unknown %d\\n\", tmp);\n\n\n\n        tmp = get_be16(s->pb); // unknown\n\n        dprintf(s, \"unknown %d\\n\", tmp);\n\n\n\n        tmp = get_be32(s->pb);\n\n        dprintf(s, \"width %d\\n\", tmp);\n\n        tmp = get_be32(s->pb);\n\n        dprintf(s, \"height %d\\n\", tmp);\n\n\n\n        tmp = get_be32(s->pb);\n\n        dprintf(s, \"metadata len %d\\n\", tmp);\n\n    }\n\n    tmp = atom->size - 8 - (url_ftell(s->pb) - pos);\n\n    if (tmp < 0)\n\n        return -1;\n\n\n\n    if (av_get_packet(s->pb, pkt, tmp) != tmp) {\n\n        av_log(s, AV_LOG_ERROR, \"error reading video packet\\n\");\n\n        return -1;\n\n    }\n\n\n\n    pkt->stream_index = 0;\n\n    pkt->dts = dts;\n\n    if (st->codec->time_base.den)\n\n        pkt->duration = (uint64_t)st->time_base.den*\n\n            st->codec->time_base.num/st->codec->time_base.den;\n\n    dprintf(s, \"pkt dts %lld duration %d\\n\", pkt->dts, pkt->duration);\n\n\n\n    return 0;\n\n}\n", "idx": 23384}
{"project": "FFmpeg", "commit_id": "6260ab60a80fd8baebf79f9ce9299b0db72333b5", "target": 0, "func": "static av_always_inline void blend_image_packed_rgb(AVFilterContext *ctx,\n\n                                   AVFrame *dst, const AVFrame *src,\n\n                                   int main_has_alpha, int x, int y,\n\n                                   int is_straight)\n\n{\n\n    OverlayContext *s = ctx->priv;\n\n    int i, imax, j, jmax;\n\n    const int src_w = src->width;\n\n    const int src_h = src->height;\n\n    const int dst_w = dst->width;\n\n    const int dst_h = dst->height;\n\n    uint8_t alpha;          ///< the amount of overlay to blend on to main\n\n    const int dr = s->main_rgba_map[R];\n\n    const int dg = s->main_rgba_map[G];\n\n    const int db = s->main_rgba_map[B];\n\n    const int da = s->main_rgba_map[A];\n\n    const int dstep = s->main_pix_step[0];\n\n    const int sr = s->overlay_rgba_map[R];\n\n    const int sg = s->overlay_rgba_map[G];\n\n    const int sb = s->overlay_rgba_map[B];\n\n    const int sa = s->overlay_rgba_map[A];\n\n    const int sstep = s->overlay_pix_step[0];\n\n    uint8_t *S, *sp, *d, *dp;\n\n\n\n    i = FFMAX(-y, 0);\n\n    sp = src->data[0] + i     * src->linesize[0];\n\n    dp = dst->data[0] + (y+i) * dst->linesize[0];\n\n\n\n    for (imax = FFMIN(-y + dst_h, src_h); i < imax; i++) {\n\n        j = FFMAX(-x, 0);\n\n        S = sp + j     * sstep;\n\n        d = dp + (x+j) * dstep;\n\n\n\n        for (jmax = FFMIN(-x + dst_w, src_w); j < jmax; j++) {\n\n            alpha = S[sa];\n\n\n\n            // if the main channel has an alpha channel, alpha has to be calculated\n\n            // to create an un-premultiplied (straight) alpha value\n\n            if (main_has_alpha && alpha != 0 && alpha != 255) {\n\n                uint8_t alpha_d = d[da];\n\n                alpha = UNPREMULTIPLY_ALPHA(alpha, alpha_d);\n\n            }\n\n\n\n            switch (alpha) {\n\n            case 0:\n\n                break;\n\n            case 255:\n\n                d[dr] = S[sr];\n\n                d[dg] = S[sg];\n\n                d[db] = S[sb];\n\n                break;\n\n            default:\n\n                // main_value = main_value * (1 - alpha) + overlay_value * alpha\n\n                // since alpha is in the range 0-255, the result must divided by 255\n\n                d[dr] = is_straight ? FAST_DIV255(d[dr] * (255 - alpha) + S[sr] * alpha) : FAST_DIV255(d[dr] * (255 - alpha) + S[sr]);\n\n                d[dg] = is_straight ? FAST_DIV255(d[dg] * (255 - alpha) + S[sg] * alpha) : FAST_DIV255(d[dr] * (255 - alpha) + S[sr]);\n\n                d[db] = is_straight ? FAST_DIV255(d[db] * (255 - alpha) + S[sb] * alpha) : FAST_DIV255(d[dr] * (255 - alpha) + S[sr]);\n\n            }\n\n            if (main_has_alpha) {\n\n                switch (alpha) {\n\n                case 0:\n\n                    break;\n\n                case 255:\n\n                    d[da] = S[sa];\n\n                    break;\n\n                default:\n\n                    // apply alpha compositing: main_alpha += (1-main_alpha) * overlay_alpha\n\n                    d[da] += FAST_DIV255((255 - d[da]) * S[sa]);\n\n                }\n\n            }\n\n            d += dstep;\n\n            S += sstep;\n\n        }\n\n        dp += dst->linesize[0];\n\n        sp += src->linesize[0];\n\n    }\n\n}\n", "idx": 23385}
{"project": "FFmpeg", "commit_id": "c9220d5b06536ac359166214b4131a1f15244617", "target": 1, "func": "static int decode_block_refinement(MJpegDecodeContext *s, int16_t *block,\n\n                                   uint8_t *last_nnz,\n\n                                   int ac_index, int16_t *quant_matrix,\n\n                                   int ss, int se, int Al, int *EOBRUN)\n\n{\n\n    int code, i = ss, j, sign, val, run;\n\n    int last    = FFMIN(se, *last_nnz);\n\n\n\n    OPEN_READER(re, &s->gb);\n\n    if (*EOBRUN) {\n\n        (*EOBRUN)--;\n\n    } else {\n\n        for (; ; i++) {\n\n            UPDATE_CACHE(re, &s->gb);\n\n            GET_VLC(code, re, &s->gb, s->vlcs[2][ac_index].table, 9, 2);\n\n\n\n            if (code & 0xF) {\n\n                run = ((unsigned) code) >> 4;\n\n                UPDATE_CACHE(re, &s->gb);\n\n                val = SHOW_UBITS(re, &s->gb, 1);\n\n                LAST_SKIP_BITS(re, &s->gb, 1);\n\n                ZERO_RUN;\n\n                j = s->scantable.permutated[i];\n\n                val--;\n\n                block[j] = ((quant_matrix[j]^val) - val) << Al;\n\n                if (i == se) {\n\n                    if (i > *last_nnz)\n\n                        *last_nnz = i;\n\n                    CLOSE_READER(re, &s->gb);\n\n                    return 0;\n\n                }\n\n            } else {\n\n                run = ((unsigned) code) >> 4;\n\n                if (run == 0xF) {\n\n                    ZERO_RUN;\n\n                } else {\n\n                    val = run;\n\n                    run = (1 << run);\n\n                    if (val) {\n\n                        UPDATE_CACHE(re, &s->gb);\n\n                        run += SHOW_UBITS(re, &s->gb, val);\n\n                        LAST_SKIP_BITS(re, &s->gb, val);\n\n                    }\n\n                    *EOBRUN = run - 1;\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n\n\n        if (i > *last_nnz)\n\n            *last_nnz = i;\n\n    }\n\n\n\n    for (; i <= last; i++) {\n\n        j = s->scantable.permutated[i];\n\n        if (block[j])\n\n            REFINE_BIT(j)\n\n    }\n\n    CLOSE_READER(re, &s->gb);\n\n\n\n    return 0;\n\n}\n", "idx": 23390}
{"project": "FFmpeg", "commit_id": "dce25564cc554cc85c8c28928b1b8d3f965c1b16", "target": 1, "func": "int ff_mov_lang_to_iso639(int code, char *to)\n\n{\n\n    int i;\n\n    /* is it the mangled iso code? */\n\n    /* see http://www.geocities.com/xhelmboyx/quicktime/formats/mp4-layout.txt */\n\n    if (code > 138) {\n\n        for (i = 2; i >= 0; i--) {\n\n            to[i] = 0x60 + (code & 0x1f);\n\n            code >>= 5;\n\n        }\n\n        return 1;\n\n    }\n\n    /* old fashion apple lang code */\n\n    if (code >= FF_ARRAY_ELEMS(mov_mdhd_language_map))\n\n        return 0;\n\n    if (!mov_mdhd_language_map[code])\n\n        return 0;\n\n    strncpy(to, mov_mdhd_language_map[code], 4);\n\n    return 1;\n\n}\n", "idx": 23391}
{"project": "FFmpeg", "commit_id": "e0c6cce44729d94e2a5507a4b6d031f23e8bd7b6", "target": 0, "func": "av_cold void ff_vp3dsp_init_x86(VP3DSPContext *c, int flags)\n\n{\n\n#if HAVE_YASM\n\n    int cpuflags = av_get_cpu_flags();\n\n\n\n#if ARCH_X86_32\n\n    if (HAVE_MMX && cpuflags & AV_CPU_FLAG_MMX) {\n\n        c->idct_put  = ff_vp3_idct_put_mmx;\n\n        c->idct_add  = ff_vp3_idct_add_mmx;\n\n        c->idct_perm = FF_PARTTRANS_IDCT_PERM;\n\n    }\n\n#endif\n\n\n\n    if (HAVE_MMXEXT && cpuflags & AV_CPU_FLAG_MMXEXT) {\n\n        c->idct_dc_add = ff_vp3_idct_dc_add_mmx2;\n\n\n\n        if (!(flags & CODEC_FLAG_BITEXACT)) {\n\n            c->v_loop_filter = ff_vp3_v_loop_filter_mmx2;\n\n            c->h_loop_filter = ff_vp3_h_loop_filter_mmx2;\n\n        }\n\n    }\n\n\n\n    if (cpuflags & AV_CPU_FLAG_SSE2) {\n\n        c->idct_put  = ff_vp3_idct_put_sse2;\n\n        c->idct_add  = ff_vp3_idct_add_sse2;\n\n        c->idct_perm = FF_TRANSPOSE_IDCT_PERM;\n\n    }\n\n#endif\n\n}\n", "idx": 23395}
{"project": "FFmpeg", "commit_id": "e5540b3fd30367ce3cc33b2f34a04b660dbc4b38", "target": 0, "func": "static int decode_hrd(VC9Context *v, GetBitContext *gb)\n\n{\n\n    int i, num;\n\n\n\n    num = get_bits(gb, 5);\n\n\n\n    if (v->hrd_rate || num != v->hrd_num_leaky_buckets)\n\n    {\n\n        av_freep(&v->hrd_rate);\n\n    }\n\n    if (!v->hrd_rate) v->hrd_rate = av_malloc(num);\n\n    if (!v->hrd_rate) return -1;\n\n\n\n    if (v->hrd_buffer || num != v->hrd_num_leaky_buckets)\n\n    {\n\n        av_freep(&v->hrd_buffer);\n\n    }\n\n    if (!v->hrd_buffer) v->hrd_buffer = av_malloc(num);\n\n    if (!v->hrd_buffer) return -1;\n\n\n\n    v->hrd_num_leaky_buckets = num;\n\n\n\n    //exponent in base-2 for rate\n\n    v->bit_rate_exponent = get_bits(gb, 4);\n\n    //exponent in base-2 for buffer_size\n\n    v->buffer_size_exponent = get_bits(gb, 4);\n\n\n\n    for (i=0; i<num; i++)\n\n    {\n\n        //mantissae, ordered (if not, use a function ?\n\n        v->hrd_rate[i] = get_bits(gb, 16);\n\n        if (i && v->hrd_rate[i-1]>=v->hrd_rate[i])\n\n        {\n\n            av_log(v, AV_LOG_ERROR, \"HDR Rates aren't strictly increasing:\"\n\n                   \"%i vs %i\\n\", v->hrd_rate[i-1], v->hrd_rate[i]);\n\n            return -1;\n\n        }\n\n        v->hrd_buffer[i] = get_bits(gb, 16);\n\n        if (i && v->hrd_buffer[i-1]<v->hrd_buffer[i])\n\n        {\n\n            av_log(v, AV_LOG_ERROR, \"HDR Buffers aren't decreasing:\"\n\n                   \"%i vs %i\\n\", v->hrd_buffer[i-1], v->hrd_buffer[i]);\n\n            return -1;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 23406}
{"project": "FFmpeg", "commit_id": "308429e124b97337a768839c1d5091900e974e7e", "target": 0, "func": "static int wav_write_trailer(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb  = s->pb;\n\n    WAVMuxContext    *wav = s->priv_data;\n\n    int64_t file_size, data_size;\n\n    int64_t number_of_samples = 0;\n\n    int rf64 = 0;\n\n\n\n    avio_flush(pb);\n\n\n\n    if (s->pb->seekable) {\n\n        if (wav->write_peak != 2) {\n\n            ff_end_tag(pb, wav->data);\n\n            avio_flush(pb);\n\n        }\n\n\n\n        if (wav->write_peak && wav->peak_output) {\n\n            peak_write_chunk(s);\n\n            avio_flush(pb);\n\n        }\n\n\n\n        /* update file size */\n\n        file_size = avio_tell(pb);\n\n        data_size = file_size - wav->data;\n\n        if (wav->rf64 == RF64_ALWAYS || (wav->rf64 == RF64_AUTO && file_size - 8 > UINT32_MAX)) {\n\n            rf64 = 1;\n\n        } else {\n\n            avio_seek(pb, 4, SEEK_SET);\n\n            avio_wl32(pb, (uint32_t)(file_size - 8));\n\n            avio_seek(pb, file_size, SEEK_SET);\n\n\n\n            avio_flush(pb);\n\n        }\n\n\n\n        number_of_samples = av_rescale(wav->maxpts - wav->minpts + wav->last_duration,\n\n                                       s->streams[0]->codec->sample_rate * (int64_t)s->streams[0]->time_base.num,\n\n                                       s->streams[0]->time_base.den);\n\n\n\n        if(s->streams[0]->codec->codec_tag != 0x01) {\n\n            /* Update num_samps in fact chunk */\n\n            avio_seek(pb, wav->fact_pos, SEEK_SET);\n\n            if (rf64 || (wav->rf64 == RF64_AUTO && number_of_samples > UINT32_MAX)) {\n\n                rf64 = 1;\n\n                avio_wl32(pb, -1);\n\n            } else {\n\n                avio_wl32(pb, number_of_samples);\n\n                avio_seek(pb, file_size, SEEK_SET);\n\n                avio_flush(pb);\n\n            }\n\n        }\n\n\n\n        if (rf64) {\n\n            /* overwrite RIFF with RF64 */\n\n            avio_seek(pb, 0, SEEK_SET);\n\n            ffio_wfourcc(pb, \"RF64\");\n\n            avio_wl32(pb, -1);\n\n\n\n            /* write ds64 chunk (overwrite JUNK if rf64 == RF64_AUTO) */\n\n            avio_seek(pb, wav->ds64 - 8, SEEK_SET);\n\n            ffio_wfourcc(pb, \"ds64\");\n\n            avio_wl32(pb, 28);                  /* ds64 chunk size */\n\n            avio_wl64(pb, file_size - 8);       /* RF64 chunk size */\n\n            avio_wl64(pb, data_size);           /* data chunk size */\n\n            avio_wl64(pb, number_of_samples);   /* fact chunk number of samples */\n\n            avio_wl32(pb, 0);                   /* number of table entries for non-'data' chunks */\n\n\n\n            /* write -1 in data chunk size */\n\n            avio_seek(pb, wav->data - 4, SEEK_SET);\n\n            avio_wl32(pb, -1);\n\n\n\n            avio_seek(pb, file_size, SEEK_SET);\n\n            avio_flush(pb);\n\n        }\n\n    }\n\n\n\n    if (wav->write_peak)\n\n        peak_free_buffers(s);\n\n\n\n    return 0;\n\n}\n", "idx": 23417}
{"project": "FFmpeg", "commit_id": "6f600ab35424823fb682b5669241edcc66590a8d", "target": 0, "func": "static av_cold int oggvorbis_encode_close(AVCodecContext *avccontext)\n\n{\n\n    OggVorbisContext *context = avccontext->priv_data;\n\n/*  ogg_packet op ; */\n\n\n\n    vorbis_analysis_wrote(&context->vd, 0);  /* notify vorbisenc this is EOF */\n\n\n\n    vorbis_block_clear(&context->vb);\n\n    vorbis_dsp_clear(&context->vd);\n\n    vorbis_info_clear(&context->vi);\n\n\n\n    av_freep(&avccontext->coded_frame);\n\n    av_freep(&avccontext->extradata);\n\n\n\n    return 0;\n\n}\n", "idx": 23424}
{"project": "FFmpeg", "commit_id": "b3f9f7a33337e9b64e6044b0010e2722fa0b2f9c", "target": 0, "func": "static PESContext *add_pes_stream(MpegTSContext *ts, int pid, int pcr_pid, int stream_type)\n\n{\n\n    MpegTSFilter *tss;\n\n    PESContext *pes;\n\n\n\n    /* if no pid found, then add a pid context */\n\n    pes = av_mallocz(sizeof(PESContext));\n\n    if (!pes)\n\n        return 0;\n\n    pes->ts = ts;\n\n    pes->stream = ts->stream;\n\n    pes->pid = pid;\n\n    pes->pcr_pid = pcr_pid;\n\n    pes->stream_type = stream_type;\n\n    pes->state = MPEGTS_SKIP;\n\n    pes->pts = AV_NOPTS_VALUE;\n\n    pes->dts = AV_NOPTS_VALUE;\n\n    tss = mpegts_open_pes_filter(ts, pid, mpegts_push_data, pes);\n\n    if (!tss) {\n\n        av_free(pes);\n\n        return 0;\n\n    }\n\n    return pes;\n\n}\n", "idx": 23425}
{"project": "FFmpeg", "commit_id": "3c77bb5f23b2e149495c814759beab7eedeede6c", "target": 0, "func": "av_cold int swr_init(struct SwrContext *s){\n\n    int ret;\n\n\n\n    clear_context(s);\n\n\n\n    if(s-> in_sample_fmt >= AV_SAMPLE_FMT_NB){\n\n        av_log(s, AV_LOG_ERROR, \"Requested input sample format %d is invalid\\n\", s->in_sample_fmt);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    if(s->out_sample_fmt >= AV_SAMPLE_FMT_NB){\n\n        av_log(s, AV_LOG_ERROR, \"Requested output sample format %d is invalid\\n\", s->out_sample_fmt);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    s->out.ch_count  = s-> user_out_ch_count;\n\n    s-> in.ch_count  = s->  user_in_ch_count;\n\n    s->used_ch_count = s->user_used_ch_count;\n\n\n\n    s-> in_ch_layout = s-> user_in_ch_layout;\n\n    s->out_ch_layout = s->user_out_ch_layout;\n\n\n\n    if(av_get_channel_layout_nb_channels(s-> in_ch_layout) > SWR_CH_MAX) {\n\n        av_log(s, AV_LOG_WARNING, \"Input channel layout 0x%\"PRIx64\" is invalid or unsupported.\\n\", s-> in_ch_layout);\n\n        s->in_ch_layout = 0;\n\n    }\n\n\n\n    if(av_get_channel_layout_nb_channels(s->out_ch_layout) > SWR_CH_MAX) {\n\n        av_log(s, AV_LOG_WARNING, \"Output channel layout 0x%\"PRIx64\" is invalid or unsupported.\\n\", s->out_ch_layout);\n\n        s->out_ch_layout = 0;\n\n    }\n\n\n\n    switch(s->engine){\n\n#if CONFIG_LIBSOXR\n\n        case SWR_ENGINE_SOXR: s->resampler = &swri_soxr_resampler; break;\n\n#endif\n\n        case SWR_ENGINE_SWR : s->resampler = &swri_resampler; break;\n\n        default:\n\n            av_log(s, AV_LOG_ERROR, \"Requested resampling engine is unavailable\\n\");\n\n            return AVERROR(EINVAL);\n\n    }\n\n\n\n    if(!s->used_ch_count)\n\n        s->used_ch_count= s->in.ch_count;\n\n\n\n    if(s->used_ch_count && s-> in_ch_layout && s->used_ch_count != av_get_channel_layout_nb_channels(s-> in_ch_layout)){\n\n        av_log(s, AV_LOG_WARNING, \"Input channel layout has a different number of channels than the number of used channels, ignoring layout\\n\");\n\n        s-> in_ch_layout= 0;\n\n    }\n\n\n\n    if(!s-> in_ch_layout)\n\n        s-> in_ch_layout= av_get_default_channel_layout(s->used_ch_count);\n\n    if(!s->out_ch_layout)\n\n        s->out_ch_layout= av_get_default_channel_layout(s->out.ch_count);\n\n\n\n    s->rematrix= s->out_ch_layout  !=s->in_ch_layout || s->rematrix_volume!=1.0 ||\n\n                 s->rematrix_custom;\n\n\n\n    if(s->int_sample_fmt == AV_SAMPLE_FMT_NONE){\n\n        if(av_get_planar_sample_fmt(s->in_sample_fmt) <= AV_SAMPLE_FMT_S16P){\n\n            s->int_sample_fmt= AV_SAMPLE_FMT_S16P;\n\n        }else if(   av_get_planar_sample_fmt(s-> in_sample_fmt) == AV_SAMPLE_FMT_S32P\n\n                 && av_get_planar_sample_fmt(s->out_sample_fmt) == AV_SAMPLE_FMT_S32P\n\n                 && !s->rematrix\n\n                 && s->engine != SWR_ENGINE_SOXR){\n\n            s->int_sample_fmt= AV_SAMPLE_FMT_S32P;\n\n        }else if(av_get_planar_sample_fmt(s->in_sample_fmt) <= AV_SAMPLE_FMT_FLTP){\n\n            s->int_sample_fmt= AV_SAMPLE_FMT_FLTP;\n\n        }else{\n\n            av_log(s, AV_LOG_DEBUG, \"Using double precision mode\\n\");\n\n            s->int_sample_fmt= AV_SAMPLE_FMT_DBLP;\n\n        }\n\n    }\n\n\n\n    if(   s->int_sample_fmt != AV_SAMPLE_FMT_S16P\n\n        &&s->int_sample_fmt != AV_SAMPLE_FMT_S32P\n\n        &&s->int_sample_fmt != AV_SAMPLE_FMT_FLTP\n\n        &&s->int_sample_fmt != AV_SAMPLE_FMT_DBLP){\n\n        av_log(s, AV_LOG_ERROR, \"Requested sample format %s is not supported internally, S16/S32/FLT/DBL is supported\\n\", av_get_sample_fmt_name(s->int_sample_fmt));\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    set_audiodata_fmt(&s-> in, s-> in_sample_fmt);\n\n    set_audiodata_fmt(&s->out, s->out_sample_fmt);\n\n\n\n    if (s->firstpts_in_samples != AV_NOPTS_VALUE) {\n\n        if (!s->async && s->min_compensation >= FLT_MAX/2)\n\n            s->async = 1;\n\n        s->firstpts =\n\n        s->outpts   = s->firstpts_in_samples * s->out_sample_rate;\n\n    } else\n\n        s->firstpts = AV_NOPTS_VALUE;\n\n\n\n    if (s->async) {\n\n        if (s->min_compensation >= FLT_MAX/2)\n\n            s->min_compensation = 0.001;\n\n        if (s->async > 1.0001) {\n\n            s->max_soft_compensation = s->async / (double) s->in_sample_rate;\n\n        }\n\n    }\n\n\n\n    if (s->out_sample_rate!=s->in_sample_rate || (s->flags & SWR_FLAG_RESAMPLE)){\n\n        s->resample = s->resampler->init(s->resample, s->out_sample_rate, s->in_sample_rate, s->filter_size, s->phase_shift, s->linear_interp, s->cutoff, s->int_sample_fmt, s->filter_type, s->kaiser_beta, s->precision, s->cheby);\n\n    }else\n\n        s->resampler->free(&s->resample);\n\n    if(    s->int_sample_fmt != AV_SAMPLE_FMT_S16P\n\n        && s->int_sample_fmt != AV_SAMPLE_FMT_S32P\n\n        && s->int_sample_fmt != AV_SAMPLE_FMT_FLTP\n\n        && s->int_sample_fmt != AV_SAMPLE_FMT_DBLP\n\n        && s->resample){\n\n        av_log(s, AV_LOG_ERROR, \"Resampling only supported with internal s16/s32/flt/dbl\\n\");\n\n        return -1;\n\n    }\n\n\n\n#define RSC 1 //FIXME finetune\n\n    if(!s-> in.ch_count)\n\n        s-> in.ch_count= av_get_channel_layout_nb_channels(s-> in_ch_layout);\n\n    if(!s->used_ch_count)\n\n        s->used_ch_count= s->in.ch_count;\n\n    if(!s->out.ch_count)\n\n        s->out.ch_count= av_get_channel_layout_nb_channels(s->out_ch_layout);\n\n\n\n    if(!s-> in.ch_count){\n\n        av_assert0(!s->in_ch_layout);\n\n        av_log(s, AV_LOG_ERROR, \"Input channel count and layout are unset\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if ((!s->out_ch_layout || !s->in_ch_layout) && s->used_ch_count != s->out.ch_count && !s->rematrix_custom) {\n\n        char l1[1024], l2[1024];\n\n        av_get_channel_layout_string(l1, sizeof(l1), s-> in.ch_count, s-> in_ch_layout);\n\n        av_get_channel_layout_string(l2, sizeof(l2), s->out.ch_count, s->out_ch_layout);\n\n        av_log(s, AV_LOG_ERROR, \"Rematrix is needed between %s and %s \"\n\n               \"but there is not enough information to do it\\n\", l1, l2);\n\n        return -1;\n\n    }\n\n\n\nav_assert0(s->used_ch_count);\n\nav_assert0(s->out.ch_count);\n\n    s->resample_first= RSC*s->out.ch_count/s->in.ch_count - RSC < s->out_sample_rate/(float)s-> in_sample_rate - 1.0;\n\n\n\n    s->in_buffer= s->in;\n\n    s->silence  = s->in;\n\n    s->drop_temp= s->out;\n\n\n\n    if(!s->resample && !s->rematrix && !s->channel_map && !s->dither.method){\n\n        s->full_convert = swri_audio_convert_alloc(s->out_sample_fmt,\n\n                                                   s-> in_sample_fmt, s-> in.ch_count, NULL, 0);\n\n        return 0;\n\n    }\n\n\n\n    s->in_convert = swri_audio_convert_alloc(s->int_sample_fmt,\n\n                                             s-> in_sample_fmt, s->used_ch_count, s->channel_map, 0);\n\n    s->out_convert= swri_audio_convert_alloc(s->out_sample_fmt,\n\n                                             s->int_sample_fmt, s->out.ch_count, NULL, 0);\n\n\n\n    if (!s->in_convert || !s->out_convert)\n\n        return AVERROR(ENOMEM);\n\n\n\n    s->postin= s->in;\n\n    s->preout= s->out;\n\n    s->midbuf= s->in;\n\n\n\n    if(s->channel_map){\n\n        s->postin.ch_count=\n\n        s->midbuf.ch_count= s->used_ch_count;\n\n        if(s->resample)\n\n            s->in_buffer.ch_count= s->used_ch_count;\n\n    }\n\n    if(!s->resample_first){\n\n        s->midbuf.ch_count= s->out.ch_count;\n\n        if(s->resample)\n\n            s->in_buffer.ch_count = s->out.ch_count;\n\n    }\n\n\n\n    set_audiodata_fmt(&s->postin, s->int_sample_fmt);\n\n    set_audiodata_fmt(&s->midbuf, s->int_sample_fmt);\n\n    set_audiodata_fmt(&s->preout, s->int_sample_fmt);\n\n\n\n    if(s->resample){\n\n        set_audiodata_fmt(&s->in_buffer, s->int_sample_fmt);\n\n    }\n\n\n\n    if ((ret = swri_dither_init(s, s->out_sample_fmt, s->int_sample_fmt)) < 0)\n\n        return ret;\n\n\n\n    if(s->rematrix || s->dither.method)\n\n        return swri_rematrix_init(s);\n\n\n\n    return 0;\n\n}\n", "idx": 23426}
{"project": "FFmpeg", "commit_id": "a7e6fbd90e62d3320b1e26d8209fc0f55ee5b0be", "target": 0, "func": "static int dxtory_decode_v2_565(AVCodecContext *avctx, AVFrame *pic,\n\n                                const uint8_t *src, int src_size, int is_565)\n\n{\n\n    GetByteContext gb;\n\n    GetBitContext  gb2;\n\n    int nslices, slice, slice_height;\n\n    uint32_t off, slice_size;\n\n    uint8_t *dst;\n\n    int ret;\n\n\n\n    bytestream2_init(&gb, src, src_size);\n\n    nslices = bytestream2_get_le16(&gb);\n\n    off = FFALIGN(nslices * 4 + 2, 16);\n\n    if (src_size < off) {\n\n        av_log(avctx, AV_LOG_ERROR, \"no slice data\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (!nslices || avctx->height % nslices) {\n\n        avpriv_request_sample(avctx, \"%d slices for %dx%d\", nslices,\n\n                              avctx->width, avctx->height);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    slice_height = avctx->height / nslices;\n\n    avctx->pix_fmt = AV_PIX_FMT_RGB24;\n\n    if ((ret = ff_get_buffer(avctx, pic, 0)) < 0)\n\n        return ret;\n\n\n\n    dst = pic->data[0];\n\n    for (slice = 0; slice < nslices; slice++) {\n\n        slice_size = bytestream2_get_le32(&gb);\n\n\n\n        ret = check_slice_size(avctx, src, src_size, slice_size, off);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        init_get_bits(&gb2, src + off + 16, (slice_size - 16) * 8);\n\n        dx2_decode_slice_565(&gb2, avctx->width, slice_height, dst,\n\n                             pic->linesize[0], is_565);\n\n\n\n        dst += pic->linesize[0] * slice_height;\n\n        off += slice_size;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23427}
{"project": "FFmpeg", "commit_id": "c341f734e5f9d6af4a8fdcceb6f5d12de6395c76", "target": 1, "func": "void mpeg_motion_internal(MpegEncContext *s,\n\n                 uint8_t *dest_y, uint8_t *dest_cb, uint8_t *dest_cr,\n\n                 int field_based, int bottom_field, int field_select,\n\n                 uint8_t **ref_picture, op_pixels_func (*pix_op)[4],\n\n                 int motion_x, int motion_y, int h, int is_mpeg12, int mb_y)\n\n{\n\n    uint8_t *ptr_y, *ptr_cb, *ptr_cr;\n\n    int dxy, uvdxy, mx, my, src_x, src_y,\n\n        uvsrc_x, uvsrc_y, v_edge_pos;\n\n    emuedge_linesize_type uvlinesize, linesize;\n\n\n\n#if 0\n\nif(s->quarter_sample)\n\n{\n\n    motion_x>>=1;\n\n    motion_y>>=1;\n\n}\n\n#endif\n\n\n\n    v_edge_pos = s->v_edge_pos >> field_based;\n\n    linesize   = s->current_picture.f.linesize[0] << field_based;\n\n    uvlinesize = s->current_picture.f.linesize[1] << field_based;\n\n\n\n    dxy = ((motion_y & 1) << 1) | (motion_x & 1);\n\n    src_x = s->mb_x* 16               + (motion_x >> 1);\n\n    src_y =(   mb_y<<(4-field_based)) + (motion_y >> 1);\n\n\n\n    if (!is_mpeg12 && s->out_format == FMT_H263) {\n\n        if((s->workaround_bugs & FF_BUG_HPEL_CHROMA) && field_based){\n\n            mx = (motion_x>>1)|(motion_x&1);\n\n            my = motion_y >>1;\n\n            uvdxy = ((my & 1) << 1) | (mx & 1);\n\n            uvsrc_x = s->mb_x* 8               + (mx >> 1);\n\n            uvsrc_y =(   mb_y<<(3-field_based))+ (my >> 1);\n\n        }else{\n\n            uvdxy = dxy | (motion_y & 2) | ((motion_x & 2) >> 1);\n\n            uvsrc_x = src_x>>1;\n\n            uvsrc_y = src_y>>1;\n\n        }\n\n    }else if(!is_mpeg12 && s->out_format == FMT_H261){//even chroma mv's are full pel in H261\n\n        mx = motion_x / 4;\n\n        my = motion_y / 4;\n\n        uvdxy = 0;\n\n        uvsrc_x = s->mb_x*8 + mx;\n\n        uvsrc_y =    mb_y*8 + my;\n\n    } else {\n\n        if(s->chroma_y_shift){\n\n            mx = motion_x / 2;\n\n            my = motion_y / 2;\n\n            uvdxy = ((my & 1) << 1) | (mx & 1);\n\n            uvsrc_x = s->mb_x* 8               + (mx >> 1);\n\n            uvsrc_y =(   mb_y<<(3-field_based))+ (my >> 1);\n\n        } else {\n\n            if(s->chroma_x_shift){\n\n            //Chroma422\n\n                mx = motion_x / 2;\n\n                uvdxy = ((motion_y & 1) << 1) | (mx & 1);\n\n                uvsrc_x = s->mb_x* 8           + (mx >> 1);\n\n                uvsrc_y = src_y;\n\n            } else {\n\n            //Chroma444\n\n                uvdxy = dxy;\n\n                uvsrc_x = src_x;\n\n                uvsrc_y = src_y;\n\n            }\n\n        }\n\n    }\n\n\n\n    ptr_y  = ref_picture[0] + src_y * linesize + src_x;\n\n    ptr_cb = ref_picture[1] + uvsrc_y * uvlinesize + uvsrc_x;\n\n    ptr_cr = ref_picture[2] + uvsrc_y * uvlinesize + uvsrc_x;\n\n\n\n    if(   (unsigned)src_x > FFMAX(s->h_edge_pos - (motion_x&1) - 16, 0)\n\n       || (unsigned)src_y > FFMAX(   v_edge_pos - (motion_y&1) - h , 0)){\n\n            if(is_mpeg12 || s->codec_id == AV_CODEC_ID_MPEG2VIDEO ||\n\n               s->codec_id == AV_CODEC_ID_MPEG1VIDEO){\n\n                av_log(s->avctx,AV_LOG_DEBUG,\n\n                        \"MPEG motion vector out of boundary (%d %d)\\n\", src_x, src_y);\n\n                return;\n\n            }\n\n            s->vdsp.emulated_edge_mc(s->edge_emu_buffer, ptr_y, s->linesize,\n\n                                17, 17+field_based,\n\n                                src_x, src_y<<field_based,\n\n                                s->h_edge_pos, s->v_edge_pos);\n\n            ptr_y = s->edge_emu_buffer;\n\n            if(!CONFIG_GRAY || !(s->flags&CODEC_FLAG_GRAY)){\n\n                uint8_t *uvbuf= s->edge_emu_buffer+18*s->linesize;\n\n                s->vdsp.emulated_edge_mc(uvbuf ,\n\n                                    ptr_cb, s->uvlinesize,\n\n                                    9, 9+field_based,\n\n                                    uvsrc_x, uvsrc_y<<field_based,\n\n                                    s->h_edge_pos>>1, s->v_edge_pos>>1);\n\n                s->vdsp.emulated_edge_mc(uvbuf+16,\n\n                                    ptr_cr, s->uvlinesize,\n\n                                    9, 9+field_based,\n\n                                    uvsrc_x, uvsrc_y<<field_based,\n\n                                    s->h_edge_pos>>1, s->v_edge_pos>>1);\n\n                ptr_cb= uvbuf;\n\n                ptr_cr= uvbuf+16;\n\n            }\n\n    }\n\n\n\n    if(bottom_field){ //FIXME use this for field pix too instead of the obnoxious hack which changes picture.data\n\n        dest_y += s->linesize;\n\n        dest_cb+= s->uvlinesize;\n\n        dest_cr+= s->uvlinesize;\n\n    }\n\n\n\n    if(field_select){\n\n        ptr_y += s->linesize;\n\n        ptr_cb+= s->uvlinesize;\n\n        ptr_cr+= s->uvlinesize;\n\n    }\n\n\n\n    pix_op[0][dxy](dest_y, ptr_y, linesize, h);\n\n\n\n    if(!CONFIG_GRAY || !(s->flags&CODEC_FLAG_GRAY)){\n\n        pix_op[s->chroma_x_shift][uvdxy]\n\n                (dest_cb, ptr_cb, uvlinesize, h >> s->chroma_y_shift);\n\n        pix_op[s->chroma_x_shift][uvdxy]\n\n                (dest_cr, ptr_cr, uvlinesize, h >> s->chroma_y_shift);\n\n    }\n\n    if(!is_mpeg12 && (CONFIG_H261_ENCODER || CONFIG_H261_DECODER) &&\n\n         s->out_format == FMT_H261){\n\n        ff_h261_loop_filter(s);\n\n    }\n\n}\n", "idx": 23429}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "void rgb16tobgr32(const uint8_t *src, uint8_t *dst, unsigned int src_size)\n\n{\n\n\tconst uint16_t *end;\n\n\tuint8_t *d = (uint8_t *)dst;\n\n\tconst uint16_t *s = (uint16_t *)src;\n\n\tend = s + src_size/2;\n\n\twhile(s < end)\n\n\t{\n\n\t\tregister uint16_t bgr;\n\n\t\tbgr = *s++;\n\n\t\t*d++ = (bgr&0xF800)>>8;\n\n\t\t*d++ = (bgr&0x7E0)>>3;\n\n\t\t*d++ = (bgr&0x1F)<<3;\n\n\t\t*d++ = 0;\n\n\t}\n\n}\n", "idx": 23431}
{"project": "FFmpeg", "commit_id": "c55e637072b694a1db40e21948d218bfa2e744bb", "target": 1, "func": "static int decode_audio_block(AC3DecodeContext *s, int blk)\n\n{\n\n    int fbw_channels = s->fbw_channels;\n\n    int channel_mode = s->channel_mode;\n\n    int i, bnd, seg, ch, ret;\n\n    int different_transforms;\n\n    int downmix_output;\n\n    int cpl_in_use;\n\n    GetBitContext *gbc = &s->gbc;\n\n    uint8_t bit_alloc_stages[AC3_MAX_CHANNELS] = { 0 };\n\n\n\n    /* block switch flags */\n\n    different_transforms = 0;\n\n    if (s->block_switch_syntax) {\n\n        for (ch = 1; ch <= fbw_channels; ch++) {\n\n            s->block_switch[ch] = get_bits1(gbc);\n\n            if (ch > 1 && s->block_switch[ch] != s->block_switch[1])\n\n                different_transforms = 1;\n\n        }\n\n    }\n\n\n\n    /* dithering flags */\n\n    if (s->dither_flag_syntax) {\n\n        for (ch = 1; ch <= fbw_channels; ch++) {\n\n            s->dither_flag[ch] = get_bits1(gbc);\n\n        }\n\n    }\n\n\n\n    /* dynamic range */\n\n    i = !s->channel_mode;\n\n    do {\n\n        if (get_bits1(gbc)) {\n\n            /* Allow asymmetric application of DRC when drc_scale > 1.\n\n               Amplification of quiet sounds is enhanced */\n\n            int range_bits = get_bits(gbc, 8);\n\n            INTFLOAT range = AC3_RANGE(range_bits);\n\n            if (range_bits <= 127 || s->drc_scale <= 1.0)\n\n                s->dynamic_range[i] = AC3_DYNAMIC_RANGE(range);\n\n            else\n\n                s->dynamic_range[i] = range;\n\n        } else if (blk == 0) {\n\n            s->dynamic_range[i] = AC3_DYNAMIC_RANGE1;\n\n        }\n\n    } while (i--);\n\n\n\n    /* spectral extension strategy */\n\n    if (s->eac3 && (!blk || get_bits1(gbc))) {\n\n        s->spx_in_use = get_bits1(gbc);\n\n        if (s->spx_in_use) {\n\n            if ((ret = spx_strategy(s, blk)) < 0)\n\n                return ret;\n\n        }\n\n    }\n\n    if (!s->eac3 || !s->spx_in_use) {\n\n        s->spx_in_use = 0;\n\n        for (ch = 1; ch <= fbw_channels; ch++) {\n\n            s->channel_uses_spx[ch] = 0;\n\n            s->first_spx_coords[ch] = 1;\n\n        }\n\n    }\n\n\n\n    /* spectral extension coordinates */\n\n    if (s->spx_in_use)\n\n        spx_coordinates(s);\n\n\n\n    /* coupling strategy */\n\n    if (s->eac3 ? s->cpl_strategy_exists[blk] : get_bits1(gbc)) {\n\n        if ((ret = coupling_strategy(s, blk, bit_alloc_stages)) < 0)\n\n            return ret;\n\n    } else if (!s->eac3) {\n\n        if (!blk) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"new coupling strategy must \"\n\n                   \"be present in block 0\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        } else {\n\n            s->cpl_in_use[blk] = s->cpl_in_use[blk-1];\n\n        }\n\n    }\n\n    cpl_in_use = s->cpl_in_use[blk];\n\n\n\n    /* coupling coordinates */\n\n    if (cpl_in_use) {\n\n        if ((ret = coupling_coordinates(s, blk)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    /* stereo rematrixing strategy and band structure */\n\n    if (channel_mode == AC3_CHMODE_STEREO) {\n\n        if ((s->eac3 && !blk) || get_bits1(gbc)) {\n\n            s->num_rematrixing_bands = 4;\n\n            if (cpl_in_use && s->start_freq[CPL_CH] <= 61) {\n\n                s->num_rematrixing_bands -= 1 + (s->start_freq[CPL_CH] == 37);\n\n            } else if (s->spx_in_use && s->spx_src_start_freq <= 61) {\n\n                s->num_rematrixing_bands--;\n\n            }\n\n            for (bnd = 0; bnd < s->num_rematrixing_bands; bnd++)\n\n                s->rematrixing_flags[bnd] = get_bits1(gbc);\n\n        } else if (!blk) {\n\n            av_log(s->avctx, AV_LOG_WARNING, \"Warning: \"\n\n                   \"new rematrixing strategy not present in block 0\\n\");\n\n            s->num_rematrixing_bands = 0;\n\n        }\n\n    }\n\n\n\n    /* exponent strategies for each channel */\n\n    for (ch = !cpl_in_use; ch <= s->channels; ch++) {\n\n        if (!s->eac3)\n\n            s->exp_strategy[blk][ch] = get_bits(gbc, 2 - (ch == s->lfe_ch));\n\n        if (s->exp_strategy[blk][ch] != EXP_REUSE)\n\n            bit_alloc_stages[ch] = 3;\n\n    }\n\n\n\n    /* channel bandwidth */\n\n    for (ch = 1; ch <= fbw_channels; ch++) {\n\n        s->start_freq[ch] = 0;\n\n        if (s->exp_strategy[blk][ch] != EXP_REUSE) {\n\n            int group_size;\n\n            int prev = s->end_freq[ch];\n\n            if (s->channel_in_cpl[ch])\n\n                s->end_freq[ch] = s->start_freq[CPL_CH];\n\n            else if (s->channel_uses_spx[ch])\n\n                s->end_freq[ch] = s->spx_src_start_freq;\n\n            else {\n\n                int bandwidth_code = get_bits(gbc, 6);\n\n                if (bandwidth_code > 60) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"bandwidth code = %d > 60\\n\", bandwidth_code);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                s->end_freq[ch] = bandwidth_code * 3 + 73;\n\n            }\n\n            group_size = 3 << (s->exp_strategy[blk][ch] - 1);\n\n            s->num_exp_groups[ch] = (s->end_freq[ch] + group_size-4) / group_size;\n\n            if (blk > 0 && s->end_freq[ch] != prev)\n\n                memset(bit_alloc_stages, 3, AC3_MAX_CHANNELS);\n\n        }\n\n    }\n\n    if (cpl_in_use && s->exp_strategy[blk][CPL_CH] != EXP_REUSE) {\n\n        s->num_exp_groups[CPL_CH] = (s->end_freq[CPL_CH] - s->start_freq[CPL_CH]) /\n\n                                    (3 << (s->exp_strategy[blk][CPL_CH] - 1));\n\n    }\n\n\n\n    /* decode exponents for each channel */\n\n    for (ch = !cpl_in_use; ch <= s->channels; ch++) {\n\n        if (s->exp_strategy[blk][ch] != EXP_REUSE) {\n\n            s->dexps[ch][0] = get_bits(gbc, 4) << !ch;\n\n            if (decode_exponents(s, gbc, s->exp_strategy[blk][ch],\n\n                                 s->num_exp_groups[ch], s->dexps[ch][0],\n\n                                 &s->dexps[ch][s->start_freq[ch]+!!ch])) {\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if (ch != CPL_CH && ch != s->lfe_ch)\n\n                skip_bits(gbc, 2); /* skip gainrng */\n\n        }\n\n    }\n\n\n\n    /* bit allocation information */\n\n    if (s->bit_allocation_syntax) {\n\n        if (get_bits1(gbc)) {\n\n            s->bit_alloc_params.slow_decay = ff_ac3_slow_decay_tab[get_bits(gbc, 2)] >> s->bit_alloc_params.sr_shift;\n\n            s->bit_alloc_params.fast_decay = ff_ac3_fast_decay_tab[get_bits(gbc, 2)] >> s->bit_alloc_params.sr_shift;\n\n            s->bit_alloc_params.slow_gain  = ff_ac3_slow_gain_tab[get_bits(gbc, 2)];\n\n            s->bit_alloc_params.db_per_bit = ff_ac3_db_per_bit_tab[get_bits(gbc, 2)];\n\n            s->bit_alloc_params.floor  = ff_ac3_floor_tab[get_bits(gbc, 3)];\n\n            for (ch = !cpl_in_use; ch <= s->channels; ch++)\n\n                bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n        } else if (!blk) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"new bit allocation info must \"\n\n                   \"be present in block 0\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    /* signal-to-noise ratio offsets and fast gains (signal-to-mask ratios) */\n\n    if (!s->eac3 || !blk) {\n\n        if (s->snr_offset_strategy && get_bits1(gbc)) {\n\n            int snr = 0;\n\n            int csnr;\n\n            csnr = (get_bits(gbc, 6) - 15) << 4;\n\n            for (i = ch = !cpl_in_use; ch <= s->channels; ch++) {\n\n                /* snr offset */\n\n                if (ch == i || s->snr_offset_strategy == 2)\n\n                    snr = (csnr + get_bits(gbc, 4)) << 2;\n\n                /* run at least last bit allocation stage if snr offset changes */\n\n                if (blk && s->snr_offset[ch] != snr) {\n\n                    bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 1);\n\n                }\n\n                s->snr_offset[ch] = snr;\n\n\n\n                /* fast gain (normal AC-3 only) */\n\n                if (!s->eac3) {\n\n                    int prev = s->fast_gain[ch];\n\n                    s->fast_gain[ch] = ff_ac3_fast_gain_tab[get_bits(gbc, 3)];\n\n                    /* run last 2 bit allocation stages if fast gain changes */\n\n                    if (blk && prev != s->fast_gain[ch])\n\n                        bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n                }\n\n            }\n\n        } else if (!s->eac3 && !blk) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"new snr offsets must be present in block 0\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    /* fast gain (E-AC-3 only) */\n\n    if (s->fast_gain_syntax && get_bits1(gbc)) {\n\n        for (ch = !cpl_in_use; ch <= s->channels; ch++) {\n\n            int prev = s->fast_gain[ch];\n\n            s->fast_gain[ch] = ff_ac3_fast_gain_tab[get_bits(gbc, 3)];\n\n            /* run last 2 bit allocation stages if fast gain changes */\n\n            if (blk && prev != s->fast_gain[ch])\n\n                bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n        }\n\n    } else if (s->eac3 && !blk) {\n\n        for (ch = !cpl_in_use; ch <= s->channels; ch++)\n\n            s->fast_gain[ch] = ff_ac3_fast_gain_tab[4];\n\n    }\n\n\n\n    /* E-AC-3 to AC-3 converter SNR offset */\n\n    if (s->frame_type == EAC3_FRAME_TYPE_INDEPENDENT && get_bits1(gbc)) {\n\n        skip_bits(gbc, 10); // skip converter snr offset\n\n    }\n\n\n\n    /* coupling leak information */\n\n    if (cpl_in_use) {\n\n        if (s->first_cpl_leak || get_bits1(gbc)) {\n\n            int fl = get_bits(gbc, 3);\n\n            int sl = get_bits(gbc, 3);\n\n            /* run last 2 bit allocation stages for coupling channel if\n\n               coupling leak changes */\n\n            if (blk && (fl != s->bit_alloc_params.cpl_fast_leak ||\n\n                sl != s->bit_alloc_params.cpl_slow_leak)) {\n\n                bit_alloc_stages[CPL_CH] = FFMAX(bit_alloc_stages[CPL_CH], 2);\n\n            }\n\n            s->bit_alloc_params.cpl_fast_leak = fl;\n\n            s->bit_alloc_params.cpl_slow_leak = sl;\n\n        } else if (!s->eac3 && !blk) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"new coupling leak info must \"\n\n                   \"be present in block 0\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        s->first_cpl_leak = 0;\n\n    }\n\n\n\n    /* delta bit allocation information */\n\n    if (s->dba_syntax && get_bits1(gbc)) {\n\n        /* delta bit allocation exists (strategy) */\n\n        for (ch = !cpl_in_use; ch <= fbw_channels; ch++) {\n\n            s->dba_mode[ch] = get_bits(gbc, 2);\n\n            if (s->dba_mode[ch] == DBA_RESERVED) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"delta bit allocation strategy reserved\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n        }\n\n        /* channel delta offset, len and bit allocation */\n\n        for (ch = !cpl_in_use; ch <= fbw_channels; ch++) {\n\n            if (s->dba_mode[ch] == DBA_NEW) {\n\n                s->dba_nsegs[ch] = get_bits(gbc, 3) + 1;\n\n                for (seg = 0; seg < s->dba_nsegs[ch]; seg++) {\n\n                    s->dba_offsets[ch][seg] = get_bits(gbc, 5);\n\n                    s->dba_lengths[ch][seg] = get_bits(gbc, 4);\n\n                    s->dba_values[ch][seg]  = get_bits(gbc, 3);\n\n                }\n\n                /* run last 2 bit allocation stages if new dba values */\n\n                bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n            }\n\n        }\n\n    } else if (blk == 0) {\n\n        for (ch = 0; ch <= s->channels; ch++) {\n\n            s->dba_mode[ch] = DBA_NONE;\n\n        }\n\n    }\n\n\n\n    /* Bit allocation */\n\n    for (ch = !cpl_in_use; ch <= s->channels; ch++) {\n\n        if (bit_alloc_stages[ch] > 2) {\n\n            /* Exponent mapping into PSD and PSD integration */\n\n            ff_ac3_bit_alloc_calc_psd(s->dexps[ch],\n\n                                      s->start_freq[ch], s->end_freq[ch],\n\n                                      s->psd[ch], s->band_psd[ch]);\n\n        }\n\n        if (bit_alloc_stages[ch] > 1) {\n\n            /* Compute excitation function, Compute masking curve, and\n\n               Apply delta bit allocation */\n\n            if (ff_ac3_bit_alloc_calc_mask(&s->bit_alloc_params, s->band_psd[ch],\n\n                                           s->start_freq[ch],  s->end_freq[ch],\n\n                                           s->fast_gain[ch],   (ch == s->lfe_ch),\n\n                                           s->dba_mode[ch],    s->dba_nsegs[ch],\n\n                                           s->dba_offsets[ch], s->dba_lengths[ch],\n\n                                           s->dba_values[ch],  s->mask[ch])) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"error in bit allocation\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n        if (bit_alloc_stages[ch] > 0) {\n\n            /* Compute bit allocation */\n\n            const uint8_t *bap_tab = s->channel_uses_aht[ch] ?\n\n                                     ff_eac3_hebap_tab : ff_ac3_bap_tab;\n\n            s->ac3dsp.bit_alloc_calc_bap(s->mask[ch], s->psd[ch],\n\n                                      s->start_freq[ch], s->end_freq[ch],\n\n                                      s->snr_offset[ch],\n\n                                      s->bit_alloc_params.floor,\n\n                                      bap_tab, s->bap[ch]);\n\n        }\n\n    }\n\n\n\n    /* unused dummy data */\n\n    if (s->skip_syntax && get_bits1(gbc)) {\n\n        int skipl = get_bits(gbc, 9);\n\n        skip_bits_long(gbc, 8 * skipl);\n\n    }\n\n\n\n    /* unpack the transform coefficients\n\n       this also uncouples channels if coupling is in use. */\n\n    decode_transform_coeffs(s, blk);\n\n\n\n    /* TODO: generate enhanced coupling coordinates and uncouple */\n\n\n\n    /* recover coefficients if rematrixing is in use */\n\n    if (s->channel_mode == AC3_CHMODE_STEREO)\n\n        do_rematrixing(s);\n\n\n\n    /* apply scaling to coefficients (headroom, dynrng) */\n\n    for (ch = 1; ch <= s->channels; ch++) {\n\n        int audio_channel = 0;\n\n        INTFLOAT gain;\n\n        if (s->channel_mode == AC3_CHMODE_DUALMONO)\n\n            audio_channel = 2-ch;\n\n        if (s->heavy_compression && s->compression_exists[audio_channel])\n\n            gain = s->heavy_dynamic_range[audio_channel];\n\n        else\n\n            gain = s->dynamic_range[audio_channel];\n\n\n\n#if USE_FIXED\n\n        scale_coefs(s->transform_coeffs[ch], s->fixed_coeffs[ch], gain, 256);\n\n#else\n\n        if (s->target_level != 0)\n\n          gain = gain * s->level_gain[audio_channel];\n\n        gain *= 1.0 / 4194304.0f;\n\n        s->fmt_conv.int32_to_float_fmul_scalar(s->transform_coeffs[ch],\n\n                                               s->fixed_coeffs[ch], gain, 256);\n\n#endif\n\n    }\n\n\n\n    /* apply spectral extension to high frequency bins */\n\n    if (CONFIG_EAC3_DECODER && s->spx_in_use) {\n\n        ff_eac3_apply_spectral_extension(s);\n\n    }\n\n\n\n    /* downmix and MDCT. order depends on whether block switching is used for\n\n       any channel in this block. this is because coefficients for the long\n\n       and short transforms cannot be mixed. */\n\n    downmix_output = s->channels != s->out_channels &&\n\n                     !((s->output_mode & AC3_OUTPUT_LFEON) &&\n\n                     s->fbw_channels == s->out_channels);\n\n    if (different_transforms) {\n\n        /* the delay samples have already been downmixed, so we upmix the delay\n\n           samples in order to reconstruct all channels before downmixing. */\n\n        if (s->downmixed) {\n\n            s->downmixed = 0;\n\n            ac3_upmix_delay(s);\n\n        }\n\n\n\n        do_imdct(s, s->channels);\n\n\n\n        if (downmix_output) {\n\n#if USE_FIXED\n\n            ac3_downmix_c_fixed16(s->outptr, s->downmix_coeffs,\n\n                              s->out_channels, s->fbw_channels, 256);\n\n#else\n\n            ff_ac3dsp_downmix(&s->ac3dsp, s->outptr, s->downmix_coeffs,\n\n                              s->out_channels, s->fbw_channels, 256);\n\n#endif\n\n        }\n\n    } else {\n\n        if (downmix_output) {\n\n            AC3_RENAME(ff_ac3dsp_downmix)(&s->ac3dsp, s->xcfptr + 1, s->downmix_coeffs,\n\n                                          s->out_channels, s->fbw_channels, 256);\n\n        }\n\n\n\n        if (downmix_output && !s->downmixed) {\n\n            s->downmixed = 1;\n\n            AC3_RENAME(ff_ac3dsp_downmix)(&s->ac3dsp, s->dlyptr, s->downmix_coeffs,\n\n                                          s->out_channels, s->fbw_channels, 128);\n\n        }\n\n\n\n        do_imdct(s, s->out_channels);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23432}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "static inline void RENAME(rgb32to16)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n\tconst uint8_t *s = src;\n\n\tconst uint8_t *end;\n\n#ifdef HAVE_MMX\n\n\tconst uint8_t *mm_end;\n\n#endif\n\n\tuint16_t *d = (uint16_t *)dst;\n\n\tend = s + src_size;\n\n#ifdef HAVE_MMX\n\n\tmm_end = end - 15;\n\n#if 1 //is faster only if multiplies are reasonable fast (FIXME figure out on which cpus this is faster, on Athlon its slightly faster)\n\n\tasm volatile(\n\n\t\t\"movq %3, %%mm5\t\t\t\\n\\t\"\n\n\t\t\"movq %4, %%mm6\t\t\t\\n\\t\"\n\n\t\t\"movq %5, %%mm7\t\t\t\\n\\t\"\n\n\t\t\"jmp 2f\t\t\t\t\\n\\t\"\n\n\t\tASMALIGN(4)\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\tPREFETCH\" 32(%1)\t\t\\n\\t\"\n\n\t\t\"movd\t(%1), %%mm0\t\t\\n\\t\"\n\n\t\t\"movd\t4(%1), %%mm3\t\t\\n\\t\"\n\n\t\t\"punpckldq 8(%1), %%mm0\t\t\\n\\t\"\n\n\t\t\"punpckldq 12(%1), %%mm3\t\\n\\t\"\n\n\t\t\"movq %%mm0, %%mm1\t\t\\n\\t\"\n\n\t\t\"movq %%mm3, %%mm4\t\t\\n\\t\"\n\n\t\t\"pand %%mm6, %%mm0\t\t\\n\\t\"\n\n\t\t\"pand %%mm6, %%mm3\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm7, %%mm3\t\t\\n\\t\"\n\n\t\t\"pand %%mm5, %%mm1\t\t\\n\\t\"\n\n\t\t\"pand %%mm5, %%mm4\t\t\\n\\t\"\n\n\t\t\"por %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\"por %%mm4, %%mm3\t\t\\n\\t\"\n\n\t\t\"psrld $5, %%mm0\t\t\\n\\t\"\n\n\t\t\"pslld $11, %%mm3\t\t\\n\\t\"\n\n\t\t\"por %%mm3, %%mm0\t\t\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, (%0)\t\t\\n\\t\"\n\n\t\t\"add $16, %1\t\t\t\\n\\t\"\n\n\t\t\"add $8, %0\t\t\t\\n\\t\"\n\n\t\t\"2:\t\t\t\t\\n\\t\"\n\n\t\t\"cmp %2, %1\t\t\t\\n\\t\"\n\n\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\t\t: \"+r\" (d), \"+r\"(s)\n\n\t\t: \"r\" (mm_end), \"m\" (mask3216g), \"m\" (mask3216br), \"m\" (mul3216)\n\n\t);\n\n#else\n\n\t__asm __volatile(PREFETCH\"\t%0\"::\"m\"(*src):\"memory\");\n\n\t__asm __volatile(\n\n\t    \"movq\t%0, %%mm7\\n\\t\"\n\n\t    \"movq\t%1, %%mm6\\n\\t\"\n\n\t    ::\"m\"(red_16mask),\"m\"(green_16mask));\n\n\twhile(s < mm_end)\n\n\t{\n\n\t    __asm __volatile(\n\n\t\tPREFETCH\" 32%1\\n\\t\"\n\n\t\t\"movd\t%1, %%mm0\\n\\t\"\n\n\t\t\"movd\t4%1, %%mm3\\n\\t\"\n\n\t\t\"punpckldq 8%1, %%mm0\\n\\t\"\n\n\t\t\"punpckldq 12%1, %%mm3\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm1\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm2\\n\\t\"\n\n\t\t\"movq\t%%mm3, %%mm4\\n\\t\"\n\n\t\t\"movq\t%%mm3, %%mm5\\n\\t\"\n\n\t\t\"psrlq\t$3, %%mm0\\n\\t\"\n\n\t\t\"psrlq\t$3, %%mm3\\n\\t\"\n\n\t\t\"pand\t%2, %%mm0\\n\\t\"\n\n\t\t\"pand\t%2, %%mm3\\n\\t\"\n\n\t\t\"psrlq\t$5, %%mm1\\n\\t\"\n\n\t\t\"psrlq\t$5, %%mm4\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm1\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm4\\n\\t\"\n\n\t\t\"psrlq\t$8, %%mm2\\n\\t\"\n\n\t\t\"psrlq\t$8, %%mm5\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm2\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm5\\n\\t\"\n\n\t\t\"por\t%%mm1, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm4, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm2, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm5, %%mm3\\n\\t\"\n\n\t\t\"psllq\t$16, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm3, %%mm0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\t:\"=m\"(*d):\"m\"(*s),\"m\"(blue_16mask):\"memory\");\n\n\t\td += 4;\n\n\t\ts += 16;\n\n\t}\n\n#endif\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\twhile(s < end)\n\n\t{\n\n\t\tregister int rgb = *(uint32_t*)s; s += 4;\n\n\t\t*d++ = ((rgb&0xFF)>>3) + ((rgb&0xFC00)>>5) + ((rgb&0xF80000)>>8);\n\n\t}\n\n}\n", "idx": 23433}
{"project": "FFmpeg", "commit_id": "26f2e2f3f73f0da088e6765291d0839ebb077b03", "target": 1, "func": "static void write_header(AVFormatContext *s)\n\n{\n\n    double min_buffer_time = 1.0;\n\n    avio_printf(s->pb, \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n\");\n\n    avio_printf(s->pb, \"<MPD\\n\");\n\n    avio_printf(s->pb, \"  xmlns:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\"\\n\");\n\n    avio_printf(s->pb, \"  xmlns=\\\"urn:mpeg:DASH:schema:MPD:2011\\\"\\n\");\n\n    avio_printf(s->pb, \"  xsi:schemaLocation=\\\"urn:mpeg:DASH:schema:MPD:2011\\\"\\n\");\n\n    avio_printf(s->pb, \"  type=\\\"static\\\"\\n\");\n\n    avio_printf(s->pb, \"  mediaPresentationDuration=\\\"PT%gS\\\"\\n\",\n\n                get_duration(s));\n\n    avio_printf(s->pb, \"  minBufferTime=\\\"PT%gS\\\"\\n\",\n\n                min_buffer_time);\n\n    avio_printf(s->pb, \"  profiles=\\\"urn:webm:dash:profile:webm-on-demand:2012\\\"\");\n\n    avio_printf(s->pb, \">\\n\");\n\n}\n", "idx": 23434}
{"project": "FFmpeg", "commit_id": "59c7615d58b5b7ea9caff2c8c774677973eb4f1c", "target": 1, "func": "static void print_formats(AVFilterContext *filter_ctx)\n\n{\n\n    int i, j;\n\n\n\n#define PRINT_FMTS(inout, outin, INOUT)                                 \\\n\n    for (i = 0; i < filter_ctx->nb_##inout##puts; i++) {                     \\\n\n        if (filter_ctx->inout##puts[i]->type == AVMEDIA_TYPE_VIDEO) {   \\\n\n            AVFilterFormats *fmts =                                     \\\n\n                filter_ctx->inout##puts[i]->outin##_formats;            \\\n\n            for (j = 0; j < fmts->nb_formats; j++)                    \\\n\n                if(av_get_pix_fmt_name(fmts->formats[j]))               \\\n\n                printf(#INOUT \"PUT[%d] %s: fmt:%s\\n\",                   \\\n\n                       i, filter_ctx->filter->inout##puts[i].name,      \\\n\n                       av_get_pix_fmt_name(fmts->formats[j]));          \\\n\n        } else if (filter_ctx->inout##puts[i]->type == AVMEDIA_TYPE_AUDIO) { \\\n\n            AVFilterFormats *fmts;                                      \\\n\n            AVFilterChannelLayouts *layouts;                            \\\n\n                                                                        \\\n\n            fmts = filter_ctx->inout##puts[i]->outin##_formats;         \\\n\n            for (j = 0; j < fmts->nb_formats; j++)                    \\\n\n                printf(#INOUT \"PUT[%d] %s: fmt:%s\\n\",                   \\\n\n                       i, filter_ctx->filter->inout##puts[i].name,      \\\n\n                       av_get_sample_fmt_name(fmts->formats[j]));       \\\n\n                                                                        \\\n\n            layouts = filter_ctx->inout##puts[i]->outin##_channel_layouts; \\\n\n            for (j = 0; j < layouts->nb_channel_layouts; j++) {                  \\\n\n                char buf[256];                                          \\\n\n                av_get_channel_layout_string(buf, sizeof(buf), -1,      \\\n\n                                             layouts->channel_layouts[j]);         \\\n\n                printf(#INOUT \"PUT[%d] %s: chlayout:%s\\n\",              \\\n\n                       i, filter_ctx->filter->inout##puts[i].name, buf); \\\n\n            }                                                           \\\n\n        }                                                               \\\n\n    }                                                                   \\\n\n\n\n    PRINT_FMTS(in,  out, IN);\n\n    PRINT_FMTS(out, in,  OUT);\n\n}\n", "idx": 23435}
{"project": "FFmpeg", "commit_id": "2b215b7f5af0ef9be79c697d8990e6958a134f98", "target": 1, "func": "static int hls_slice_data_wpp(HEVCContext *s, const uint8_t *nal, int length)\n{\n    HEVCLocalContext *lc = s->HEVClc;\n    int *ret = av_malloc_array(s->sh.num_entry_point_offsets + 1, sizeof(int));\n    int *arg = av_malloc_array(s->sh.num_entry_point_offsets + 1, sizeof(int));\n    int offset;\n    int startheader, cmpt = 0;\n    int i, j, res = 0;\n    if (!s->sList[1]) {\n        ff_alloc_entries(s->avctx, s->sh.num_entry_point_offsets + 1);\n        for (i = 1; i < s->threads_number; i++) {\n            s->sList[i] = av_malloc(sizeof(HEVCContext));\n            memcpy(s->sList[i], s, sizeof(HEVCContext));\n            s->HEVClcList[i] = av_mallocz(sizeof(HEVCLocalContext));\n            s->sList[i]->HEVClc = s->HEVClcList[i];\n    offset = (lc->gb.index >> 3);\n    for (j = 0, cmpt = 0, startheader = offset + s->sh.entry_point_offset[0]; j < s->skipped_bytes; j++) {\n        if (s->skipped_bytes_pos[j] >= offset && s->skipped_bytes_pos[j] < startheader) {\n            startheader--;\n            cmpt++;\n    for (i = 1; i < s->sh.num_entry_point_offsets; i++) {\n        offset += (s->sh.entry_point_offset[i - 1] - cmpt);\n        for (j = 0, cmpt = 0, startheader = offset\n             + s->sh.entry_point_offset[i]; j < s->skipped_bytes; j++) {\n            if (s->skipped_bytes_pos[j] >= offset && s->skipped_bytes_pos[j] < startheader) {\n                startheader--;\n                cmpt++;\n        s->sh.size[i - 1] = s->sh.entry_point_offset[i] - cmpt;\n        s->sh.offset[i - 1] = offset;\n    if (s->sh.num_entry_point_offsets != 0) {\n        offset += s->sh.entry_point_offset[s->sh.num_entry_point_offsets - 1] - cmpt;\n        s->sh.size[s->sh.num_entry_point_offsets - 1] = length - offset;\n        s->sh.offset[s->sh.num_entry_point_offsets - 1] = offset;\n    s->data = nal;\n    for (i = 1; i < s->threads_number; i++) {\n        s->sList[i]->HEVClc->first_qp_group = 1;\n        s->sList[i]->HEVClc->qp_y = s->sList[0]->HEVClc->qp_y;\n        memcpy(s->sList[i], s, sizeof(HEVCContext));\n        s->sList[i]->HEVClc = s->HEVClcList[i];\n    avpriv_atomic_int_set(&s->wpp_err, 0);\n    ff_reset_entries(s->avctx);\n    for (i = 0; i <= s->sh.num_entry_point_offsets; i++) {\n        arg[i] = i;\n        ret[i] = 0;\n    if (s->pps->entropy_coding_sync_enabled_flag)\n        s->avctx->execute2(s->avctx, (void *) hls_decode_entry_wpp, arg, ret, s->sh.num_entry_point_offsets + 1);\n    for (i = 0; i <= s->sh.num_entry_point_offsets; i++)\n        res += ret[i];\n    return res;", "idx": 23438}
{"project": "FFmpeg", "commit_id": "636ced8e1dc8248a1353b416240b93d70ad03edb", "target": 1, "func": "static void opt_input_file(void *optctx, const char *arg)\n\n{\n\n    if (input_filename) {\n\n        fprintf(stderr,\n\n                \"Argument '%s' provided as input filename, but '%s' was already specified.\\n\",\n\n                arg, input_filename);\n\n        exit(1);\n\n    }\n\n    if (!strcmp(arg, \"-\"))\n\n        arg = \"pipe:\";\n\n    input_filename = arg;\n\n}\n", "idx": 23440}
{"project": "FFmpeg", "commit_id": "5ffb5e7a2d69f5e4bece9829ede0432b4cbc0fe8", "target": 0, "func": "static void decode_p_block(FourXContext *f, uint16_t *dst, uint16_t *src,\n\n                           int log2w, int log2h, int stride)\n\n{\n\n    const int index = size2index[log2h][log2w];\n\n    const int h     = 1 << log2h;\n\n    int code        = get_vlc2(&f->gb,\n\n                               block_type_vlc[1 - (f->version > 1)][index].table,\n\n                               BLOCK_TYPE_VLC_BITS, 1);\n\n    uint16_t *start = (uint16_t *)f->last_picture.data[0];\n\n    uint16_t *end   = start + stride * (f->avctx->height - h + 1) - (1 << log2w);\n\n\n\n    av_assert2(code >= 0 && code <= 6);\n\n\n\n    if (code == 0) {\n\n        if (bytestream2_get_bytes_left(&f->g) < 1) {\n\n            av_log(f->avctx, AV_LOG_ERROR, \"bytestream overread\\n\");\n\n            return;\n\n        }\n\n        src += f->mv[bytestream2_get_byteu(&f->g)];\n\n        if (start > src || src > end) {\n\n            av_log(f->avctx, AV_LOG_ERROR, \"mv out of pic\\n\");\n\n            return;\n\n        }\n\n        mcdc(dst, src, log2w, h, stride, 1, 0);\n\n    } else if (code == 1) {\n\n        log2h--;\n\n        decode_p_block(f, dst, src, log2w, log2h, stride);\n\n        decode_p_block(f, dst + (stride << log2h),\n\n                          src + (stride << log2h), log2w, log2h, stride);\n\n    } else if (code == 2) {\n\n        log2w--;\n\n        decode_p_block(f, dst , src, log2w, log2h, stride);\n\n        decode_p_block(f, dst + (1 << log2w),\n\n                          src + (1 << log2w), log2w, log2h, stride);\n\n    } else if (code == 3 && f->version < 2) {\n\n        mcdc(dst, src, log2w, h, stride, 1, 0);\n\n    } else if (code == 4) {\n\n        if (bytestream2_get_bytes_left(&f->g) < 1) {\n\n            av_log(f->avctx, AV_LOG_ERROR, \"bytestream overread\\n\");\n\n            return;\n\n        }\n\n        src += f->mv[bytestream2_get_byteu(&f->g)];\n\n        if (start > src || src > end) {\n\n            av_log(f->avctx, AV_LOG_ERROR, \"mv out of pic\\n\");\n\n            return;\n\n        }\n\n        if (bytestream2_get_bytes_left(&f->g) < 2){\n\n            av_log(f->avctx, AV_LOG_ERROR, \"wordstream overread\\n\");\n\n            return;\n\n        }\n\n        mcdc(dst, src, log2w, h, stride, 1, bytestream2_get_le16u(&f->g2));\n\n    } else if (code == 5) {\n\n        if (bytestream2_get_bytes_left(&f->g) < 2) {\n\n            av_log(f->avctx, AV_LOG_ERROR, \"wordstream overread\\n\");\n\n            return;\n\n        }\n\n        mcdc(dst, src, log2w, h, stride, 0, bytestream2_get_le16u(&f->g2));\n\n    } else if (code == 6) {\n\n        if (bytestream2_get_bytes_left(&f->g) < 4) {\n\n            av_log(f->avctx, AV_LOG_ERROR, \"wordstream overread\\n\");\n\n            return;\n\n        }\n\n        if (log2w) {\n\n            dst[0]      = bytestream2_get_le16u(&f->g2);\n\n            dst[1]      = bytestream2_get_le16u(&f->g2);\n\n        } else {\n\n            dst[0]      = bytestream2_get_le16u(&f->g2);\n\n            dst[stride] = bytestream2_get_le16u(&f->g2);\n\n        }\n\n    }\n\n}\n", "idx": 23441}
{"project": "FFmpeg", "commit_id": "486637af8ef29ec215e0e0b7ecd3b5470f0e04e5", "target": 0, "func": "static void generate_coupling_coordinates(AC3DecodeContext * ctx)\n\n{\n\n    ac3_audio_block *ab = &ctx->audio_block;\n\n    uint8_t exp, mstrcplco;\n\n    int16_t mant;\n\n    uint32_t cplbndstrc = (1 << ab->ncplsubnd) >> 1;\n\n    int ch, bnd, sbnd;\n\n    float cplco;\n\n\n\n    if (ab->cplcoe)\n\n        for (ch = 0; ch < ctx->bsi.nfchans; ch++)\n\n            if (ab->cplcoe & (1 << ch)) {\n\n                mstrcplco = 3 * ab->mstrcplco[ch];\n\n                sbnd = ab->cplbegf;\n\n                for (bnd = 0; bnd < ab->ncplbnd; bnd++) {\n\n                    exp = ab->cplcoexp[ch][bnd];\n\n                    if (exp == 15)\n\n                        mant = ab->cplcomant[ch][bnd] <<= 14;\n\n                    else\n\n                        mant = (ab->cplcomant[ch][bnd] | 0x10) << 13;\n\n                    cplco = to_float(exp + mstrcplco, mant);\n\n                    if (ctx->bsi.acmod == 0x02 && (ab->flags & AC3_AB_PHSFLGINU) && ch == 1\n\n                            && (ab->phsflg & (1 << bnd)))\n\n                        cplco = -cplco; /* invert the right channel */\n\n                    ab->cplco[ch][sbnd++] = cplco;\n\n                    while (cplbndstrc & ab->cplbndstrc) {\n\n                        cplbndstrc >>= 1;\n\n                        ab->cplco[ch][sbnd++] = cplco;\n\n                    }\n\n                    cplbndstrc >>= 1;\n\n                }\n\n            }\n\n}\n", "idx": 23442}
{"project": "FFmpeg", "commit_id": "e2193b53eab9f207544a75ebaf51871b7a1a7931", "target": 0, "func": "static int update_streams_from_subdemuxer(AVFormatContext *s, struct playlist *pls)\n\n{\n\n    while (pls->n_main_streams < pls->ctx->nb_streams) {\n\n        int ist_idx = pls->n_main_streams;\n\n        AVStream *st = avformat_new_stream(s, NULL);\n\n        AVStream *ist = pls->ctx->streams[ist_idx];\n\n\n\n        if (!st)\n\n            return AVERROR(ENOMEM);\n\n\n\n        st->id = pls->index;\n\n        set_stream_info_from_input_stream(st, pls, ist);\n\n\n\n        dynarray_add(&pls->main_streams, &pls->n_main_streams, st);\n\n\n\n        add_stream_to_programs(s, pls, st);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23448}
{"project": "FFmpeg", "commit_id": "3f50965b28d0c4ef10dde0bf2f7a9f78fa36b378", "target": 0, "func": "static inline void h264_loop_filter_luma_c(uint8_t *pix, int xstride, int ystride, int alpha, int beta, int8_t *tc0)\n\n{\n\n    int i, d;\n\n    for( i = 0; i < 4; i++ ) {\n\n        if( tc0[i] < 0 ) {\n\n            pix += 4*ystride;\n\n            continue;\n\n        }\n\n        for( d = 0; d < 4; d++ ) {\n\n            const int p0 = pix[-1*xstride];\n\n            const int p1 = pix[-2*xstride];\n\n            const int p2 = pix[-3*xstride];\n\n            const int q0 = pix[0];\n\n            const int q1 = pix[1*xstride];\n\n            const int q2 = pix[2*xstride];\n\n\n\n            if( FFABS( p0 - q0 ) < alpha &&\n\n                FFABS( p1 - p0 ) < beta &&\n\n                FFABS( q1 - q0 ) < beta ) {\n\n\n\n                int tc = tc0[i];\n\n                int i_delta;\n\n\n\n                if( FFABS( p2 - p0 ) < beta ) {\n\n                    if(tc0[i])\n\n                    pix[-2*xstride] = p1 + av_clip( (( p2 + ( ( p0 + q0 + 1 ) >> 1 ) ) >> 1) - p1, -tc0[i], tc0[i] );\n\n                    tc++;\n\n                }\n\n                if( FFABS( q2 - q0 ) < beta ) {\n\n                    if(tc0[i])\n\n                    pix[   xstride] = q1 + av_clip( (( q2 + ( ( p0 + q0 + 1 ) >> 1 ) ) >> 1) - q1, -tc0[i], tc0[i] );\n\n                    tc++;\n\n                }\n\n\n\n                i_delta = av_clip( (((q0 - p0 ) << 2) + (p1 - q1) + 4) >> 3, -tc, tc );\n\n                pix[-xstride] = av_clip_uint8( p0 + i_delta );    /* p0' */\n\n                pix[0]        = av_clip_uint8( q0 - i_delta );    /* q0' */\n\n            }\n\n            pix += ystride;\n\n        }\n\n    }\n\n}\n", "idx": 23459}
{"project": "FFmpeg", "commit_id": "42fb414804419c3fc269c73ad049f218f8813ed0", "target": 0, "func": "static int mov_write_udta_tag(ByteIOContext *pb, MOVContext* mov,\n\n                              AVFormatContext *s)\n\n{\n\n    offset_t pos = url_ftell(pb);\n\n    int i;\n\n\n\n    put_be32(pb, 0); /* size */\n\n    put_tag(pb, \"udta\");\n\n\n\n    /* iTunes meta data */\n\n    mov_write_meta_tag(pb, mov, s);\n\n\n\n  if(mov->mode == MODE_MOV){ // the title field breaks gtkpod with mp4 and my suspicion is that stuff isnt valid in mp4\n\n    /* Requirements */\n\n    for (i=0; i<MAX_STREAMS; i++) {\n\n        if(mov->tracks[i].entry <= 0) continue;\n\n        if (mov->tracks[i].enc->codec_id == CODEC_ID_AAC ||\n\n            mov->tracks[i].enc->codec_id == CODEC_ID_MPEG4) {\n\n            mov_write_string_tag(pb, \"\\251req\", \"QuickTime 6.0 or greater\", 0);\n\n            break;\n\n        }\n\n    }\n\n\n\n    mov_write_string_tag(pb, \"\\251nam\", s->title         , 0);\n\n    mov_write_string_tag(pb, \"\\251aut\", s->author        , 0);\n\n    mov_write_string_tag(pb, \"\\251alb\", s->album         , 0);\n\n    mov_write_day_tag(pb, s->year, 0);\n\n    if(mov->tracks[0].enc && !(mov->tracks[0].enc->flags & CODEC_FLAG_BITEXACT))\n\n        mov_write_string_tag(pb, \"\\251enc\", LIBAVFORMAT_IDENT, 0);\n\n    mov_write_string_tag(pb, \"\\251des\", s->comment       , 0);\n\n    mov_write_string_tag(pb, \"\\251gen\", s->genre         , 0);\n\n  }\n\n\n\n    return updateSize(pb, pos);\n\n}\n", "idx": 23464}
{"project": "FFmpeg", "commit_id": "dde0af2df1caffb9e33855c08fc691dbbbbc72b3", "target": 0, "func": "static int vble_unpack(VBLEContext *ctx, GetBitContext *gb)\n\n{\n\n    int i;\n\n    static const uint8_t LUT[256] = {\n\n        8,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n        5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n        6,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n        5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n        7,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n        5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n        6,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n        5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n    };\n\n\n\n    /* Read all the lengths in first */\n\n    for (i = 0; i < ctx->size; i++) {\n\n        /* At most we need to read 9 bits total to get indices up to 8 */\n\n        int val = show_bits(gb, 8);\n\n\n\n        // read reverse unary\n\n        if (val) {\n\n            val = LUT[val];\n\n            skip_bits(gb, val + 1);\n\n            ctx->len[i] = val;\n\n        } else {\n\n            skip_bits(gb, 8);\n\n            if (!get_bits1(gb))\n\n                return -1;\n\n            ctx->len[i] = 8;\n\n        }\n\n    }\n\n\n\n    /* For any values that have length 0 */\n\n    memset(ctx->val, 0, ctx->size);\n\n\n\n    for (i = 0; i < ctx->size; i++) {\n\n        /* Check we have enough bits left */\n\n        if (get_bits_left(gb) < ctx->len[i])\n\n            return -1;\n\n\n\n        /* get_bits can't take a length of 0 */\n\n        if (ctx->len[i])\n\n            ctx->val[i] = (1 << ctx->len[i]) + get_bits(gb, ctx->len[i]) - 1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23465}
{"project": "FFmpeg", "commit_id": "7248797c03e8fcddc1f1ab5887d1e53cc691a2c2", "target": 0, "func": "static void selfTest(uint8_t *ref[4], int refStride[4], int w, int h)\n\n{\n\n    const int flags[] = { SWS_FAST_BILINEAR,\n\n                          SWS_BILINEAR, SWS_BICUBIC,\n\n                          SWS_X       , SWS_POINT  , SWS_AREA, 0 };\n\n    const int srcW = w;\n\n    const int srcH = h;\n\n    const int dstW[] = { srcW - srcW/3, srcW, srcW + srcW/3, 0 };\n\n    const int dstH[] = { srcH - srcH/3, srcH, srcH + srcH/3, 0 };\n\n    enum PixelFormat srcFormat, dstFormat;\n\n\n\n    for (srcFormat = 0; srcFormat < PIX_FMT_NB; srcFormat++) {\n\n        for (dstFormat = 0; dstFormat < PIX_FMT_NB; dstFormat++) {\n\n            int i, j, k;\n\n            int res = 0;\n\n\n\n            printf(\"%s -> %s\\n\",\n\n                   sws_format_name(srcFormat),\n\n                   sws_format_name(dstFormat));\n\n            fflush(stdout);\n\n\n\n            for (i = 0; dstW[i] && !res; i++)\n\n                for (j = 0; dstH[j] && !res; j++)\n\n                    for (k = 0; flags[k] && !res; k++)\n\n                        res = doTest(ref, refStride, w, h, srcFormat, dstFormat,\n\n                                     srcW, srcH, dstW[i], dstH[j], flags[k]);\n\n        }\n\n    }\n\n}\n", "idx": 23466}
{"project": "FFmpeg", "commit_id": "bcd7bf7eeb09a395cc01698842d1b8be9af483fc", "target": 0, "func": "static void avc_biwgt_4width_msa(uint8_t *src,\n\n                                 int32_t src_stride,\n\n                                 uint8_t *dst,\n\n                                 int32_t dst_stride,\n\n                                 int32_t height,\n\n                                 int32_t log2_denom,\n\n                                 int32_t src_weight,\n\n                                 int32_t dst_weight,\n\n                                 int32_t offset_in)\n\n{\n\n    if (2 == height) {\n\n        avc_biwgt_4x2_msa(src, src_stride, dst, dst_stride,\n\n                          log2_denom, src_weight, dst_weight,\n\n                          offset_in);\n\n    } else {\n\n        avc_biwgt_4x4multiple_msa(src, src_stride, dst, dst_stride,\n\n                                  height, log2_denom, src_weight,\n\n                                  dst_weight, offset_in);\n\n    }\n\n}\n", "idx": 23467}
{"project": "FFmpeg", "commit_id": "ff9db5cfd14558df9cfcc54d6c062bc34bf1f341", "target": 0, "func": "static inline int decode_vui_parameters(GetBitContext *gb, AVCodecContext *avctx,\n\n                                        SPS *sps)\n\n{\n\n    int aspect_ratio_info_present_flag;\n\n    unsigned int aspect_ratio_idc;\n\n\n\n    aspect_ratio_info_present_flag = get_bits1(gb);\n\n\n\n    if (aspect_ratio_info_present_flag) {\n\n        aspect_ratio_idc = get_bits(gb, 8);\n\n        if (aspect_ratio_idc == EXTENDED_SAR) {\n\n            sps->sar.num = get_bits(gb, 16);\n\n            sps->sar.den = get_bits(gb, 16);\n\n        } else if (aspect_ratio_idc < FF_ARRAY_ELEMS(pixel_aspect)) {\n\n            sps->sar = pixel_aspect[aspect_ratio_idc];\n\n        } else {\n\n            av_log(avctx, AV_LOG_ERROR, \"illegal aspect ratio\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    } else {\n\n        sps->sar.num =\n\n        sps->sar.den = 0;\n\n    }\n\n\n\n    if (get_bits1(gb))      /* overscan_info_present_flag */\n\n        get_bits1(gb);      /* overscan_appropriate_flag */\n\n\n\n    sps->video_signal_type_present_flag = get_bits1(gb);\n\n    if (sps->video_signal_type_present_flag) {\n\n        get_bits(gb, 3);                 /* video_format */\n\n        sps->full_range = get_bits1(gb); /* video_full_range_flag */\n\n\n\n        sps->colour_description_present_flag = get_bits1(gb);\n\n        if (sps->colour_description_present_flag) {\n\n            sps->color_primaries = get_bits(gb, 8); /* colour_primaries */\n\n            sps->color_trc       = get_bits(gb, 8); /* transfer_characteristics */\n\n            sps->colorspace      = get_bits(gb, 8); /* matrix_coefficients */\n\n            if (sps->color_primaries >= AVCOL_PRI_NB)\n\n                sps->color_primaries = AVCOL_PRI_UNSPECIFIED;\n\n            if (sps->color_trc >= AVCOL_TRC_NB)\n\n                sps->color_trc = AVCOL_TRC_UNSPECIFIED;\n\n            if (sps->colorspace >= AVCOL_SPC_NB)\n\n                sps->colorspace = AVCOL_SPC_UNSPECIFIED;\n\n        }\n\n    }\n\n\n\n    /* chroma_location_info_present_flag */\n\n    if (get_bits1(gb)) {\n\n        /* chroma_sample_location_type_top_field */\n\n        avctx->chroma_sample_location = get_ue_golomb(gb) + 1;\n\n        get_ue_golomb(gb);  /* chroma_sample_location_type_bottom_field */\n\n    }\n\n\n\n    sps->timing_info_present_flag = get_bits1(gb);\n\n    if (sps->timing_info_present_flag) {\n\n        sps->num_units_in_tick = get_bits_long(gb, 32);\n\n        sps->time_scale        = get_bits_long(gb, 32);\n\n        if (!sps->num_units_in_tick || !sps->time_scale) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"time_scale/num_units_in_tick invalid or unsupported (%\"PRIu32\"/%\"PRIu32\")\\n\",\n\n                   sps->time_scale, sps->num_units_in_tick);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        sps->fixed_frame_rate_flag = get_bits1(gb);\n\n    }\n\n\n\n    sps->nal_hrd_parameters_present_flag = get_bits1(gb);\n\n    if (sps->nal_hrd_parameters_present_flag)\n\n        if (decode_hrd_parameters(gb, avctx, sps) < 0)\n\n            return AVERROR_INVALIDDATA;\n\n    sps->vcl_hrd_parameters_present_flag = get_bits1(gb);\n\n    if (sps->vcl_hrd_parameters_present_flag)\n\n        if (decode_hrd_parameters(gb, avctx, sps) < 0)\n\n            return AVERROR_INVALIDDATA;\n\n    if (sps->nal_hrd_parameters_present_flag ||\n\n        sps->vcl_hrd_parameters_present_flag)\n\n        get_bits1(gb);     /* low_delay_hrd_flag */\n\n    sps->pic_struct_present_flag = get_bits1(gb);\n\n\n\n    sps->bitstream_restriction_flag = get_bits1(gb);\n\n    if (sps->bitstream_restriction_flag) {\n\n        get_bits1(gb);     /* motion_vectors_over_pic_boundaries_flag */\n\n        get_ue_golomb(gb); /* max_bytes_per_pic_denom */\n\n        get_ue_golomb(gb); /* max_bits_per_mb_denom */\n\n        get_ue_golomb(gb); /* log2_max_mv_length_horizontal */\n\n        get_ue_golomb(gb); /* log2_max_mv_length_vertical */\n\n        sps->num_reorder_frames = get_ue_golomb(gb);\n\n        get_ue_golomb(gb); /*max_dec_frame_buffering*/\n\n\n\n        if (get_bits_left(gb) < 0) {\n\n            sps->num_reorder_frames         = 0;\n\n            sps->bitstream_restriction_flag = 0;\n\n        }\n\n\n\n        if (sps->num_reorder_frames > 16U\n\n            /* max_dec_frame_buffering || max_dec_frame_buffering > 16 */) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Clipping illegal num_reorder_frames %d\\n\",\n\n                   sps->num_reorder_frames);\n\n            sps->num_reorder_frames = 16;\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n    if (get_bits_left(gb) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Overread VUI by %d bits\\n\", -get_bits_left(gb));\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23468}
{"project": "FFmpeg", "commit_id": "0cc5011f9a1b05132f9a20a71feb031f30a8a53b", "target": 0, "func": "static int buffer_needs_copy(PadContext *s, AVFrame *frame, AVBufferRef *buf)\n\n{\n\n    int planes[4] = { -1, -1, -1, -1}, *p = planes;\n\n    int i, j;\n\n\n\n    /* get all planes in this buffer */\n\n    for (i = 0; i < FF_ARRAY_ELEMS(planes) && frame->data[i]; i++) {\n\n        if (av_frame_get_plane_buffer(frame, i) == buf)\n\n            *p++ = i;\n\n    }\n\n\n\n    /* for each plane in this buffer, check that it can be padded without\n\n     * going over buffer bounds or other planes */\n\n    for (i = 0; i < FF_ARRAY_ELEMS(planes) && planes[i] >= 0; i++) {\n\n        int hsub = s->draw.hsub[planes[i]];\n\n        int vsub = s->draw.vsub[planes[i]];\n\n\n\n        uint8_t *start = frame->data[planes[i]];\n\n        uint8_t *end   = start + (frame->height >> vsub) *\n\n                                 frame->linesize[planes[i]];\n\n\n\n        /* amount of free space needed before the start and after the end\n\n         * of the plane */\n\n        ptrdiff_t req_start = (s->x >> hsub) * s->draw.pixelstep[planes[i]] +\n\n                              (s->y >> vsub) * frame->linesize[planes[i]];\n\n        ptrdiff_t req_end   = ((s->w - s->x - frame->width) >> hsub) *\n\n                              s->draw.pixelstep[planes[i]] +\n\n                              (s->y >> vsub) * frame->linesize[planes[i]];\n\n\n\n        if (frame->linesize[planes[i]] < (s->w >> hsub) * s->draw.pixelstep[planes[i]])\n\n            return 1;\n\n        if (start - buf->data < req_start ||\n\n            (buf->data + buf->size) - end < req_end)\n\n            return 1;\n\n\n\n        for (j = 0; j < FF_ARRAY_ELEMS(planes) && planes[j] >= 0; j++) {\n\n            int vsub1 = s->draw.vsub[planes[j]];\n\n            uint8_t *start1 = frame->data[planes[j]];\n\n            uint8_t *end1   = start1 + (frame->height >> vsub1) *\n\n                                       frame->linesize[planes[j]];\n\n            if (i == j)\n\n                continue;\n\n\n\n            if (FFSIGN(start - end1) != FFSIGN(start - end1 - req_start) ||\n\n                FFSIGN(end - start1) != FFSIGN(end - start1 + req_end))\n\n                return 1;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23469}
{"project": "FFmpeg", "commit_id": "2758cdedfb7ac61f8b5e4861f99218b6fd43491d", "target": 0, "func": "int ffurl_alloc(URLContext **puc, const char *filename, int flags,\n\n                const AVIOInterruptCB *int_cb)\n\n{\n\n    URLProtocol *up = NULL;\n\n    char proto_str[128], proto_nested[128], *ptr;\n\n    size_t proto_len = strspn(filename, URL_SCHEME_CHARS);\n\n\n\n    if (filename[proto_len] != ':' || is_dos_path(filename))\n\n        strcpy(proto_str, \"file\");\n\n    else\n\n        av_strlcpy(proto_str, filename,\n\n                   FFMIN(proto_len + 1, sizeof(proto_str)));\n\n\n\n    av_strlcpy(proto_nested, proto_str, sizeof(proto_nested));\n\n    if ((ptr = strchr(proto_nested, '+')))\n\n        *ptr = '\\0';\n\n\n\n    while (up = ffurl_protocol_next(up)) {\n\n        if (!strcmp(proto_str, up->name))\n\n            return url_alloc_for_protocol(puc, up, filename, flags, int_cb);\n\n        if (up->flags & URL_PROTOCOL_FLAG_NESTED_SCHEME &&\n\n            !strcmp(proto_nested, up->name))\n\n            return url_alloc_for_protocol(puc, up, filename, flags, int_cb);\n\n    }\n\n    *puc = NULL;\n\n    return AVERROR_PROTOCOL_NOT_FOUND;\n\n}\n", "idx": 23470}
{"project": "FFmpeg", "commit_id": "398f015f077c6a2406deffd9e37ff34b9c7bb3bc", "target": 0, "func": "static int transcode_subtitles(InputStream *ist, AVPacket *pkt, int *got_output)\n\n{\n\n    AVSubtitle subtitle;\n\n    int i, ret = avcodec_decode_subtitle2(ist->dec_ctx,\n\n                                          &subtitle, got_output, pkt);\n\n    if (ret < 0)\n\n        return ret;\n\n    if (!*got_output)\n\n        return ret;\n\n\n\n    ist->frames_decoded++;\n\n\n\n    for (i = 0; i < nb_output_streams; i++) {\n\n        OutputStream *ost = output_streams[i];\n\n\n\n        if (!check_output_constraints(ist, ost) || !ost->encoding_needed)\n\n            continue;\n\n\n\n        do_subtitle_out(output_files[ost->file_index]->ctx, ost, ist, &subtitle, pkt->pts);\n\n    }\n\n\n\n    avsubtitle_free(&subtitle);\n\n    return ret;\n\n}\n", "idx": 23471}
{"project": "FFmpeg", "commit_id": "44e2105189ac66637f34c764febc349238250b1d", "target": 1, "func": "static void decode_pitch_lag_high(int *lag_int, int *lag_frac, int pitch_index,\n\n                                  uint8_t *base_lag_int, int subframe)\n\n{\n\n    if (subframe == 0 || subframe == 2) {\n\n        if (pitch_index < 376) {\n\n            *lag_int  = (pitch_index + 137) >> 2;\n\n            *lag_frac = pitch_index - (*lag_int << 2) + 136;\n\n        } else if (pitch_index < 440) {\n\n            *lag_int  = (pitch_index + 257 - 376) >> 1;\n\n            *lag_frac = (pitch_index - (*lag_int << 1) + 256 - 376) << 1;\n\n            /* the actual resolution is 1/2 but expressed as 1/4 */\n\n        } else {\n\n            *lag_int  = pitch_index - 280;\n\n            *lag_frac = 0;\n\n        }\n\n        /* minimum lag for next subframe */\n\n        *base_lag_int = av_clip(*lag_int - 8 - (*lag_frac < 0),\n\n                                AMRWB_P_DELAY_MIN, AMRWB_P_DELAY_MAX - 15);\n\n        // XXX: the spec states clearly that *base_lag_int should be\n\n        // the nearest integer to *lag_int (minus 8), but the ref code\n\n        // actually always uses its floor, I'm following the latter\n\n    } else {\n\n        *lag_int  = (pitch_index + 1) >> 2;\n\n        *lag_frac = pitch_index - (*lag_int << 2);\n\n        *lag_int += *base_lag_int;\n\n    }\n\n}\n", "idx": 23477}
{"project": "FFmpeg", "commit_id": "31fe5d9825a050ca319ab9ddbe502d84ac3a576e", "target": 1, "func": "static int transcode(AVFormatContext **output_files,\n\n                     int nb_output_files,\n\n                     InputFile *input_files,\n\n                     int nb_input_files,\n\n                     StreamMap *stream_maps, int nb_stream_maps)\n\n{\n\n    int ret = 0, i, j, k, n, nb_ostreams = 0, step;\n\n\n\n    AVFormatContext *is, *os;\n\n    AVCodecContext *codec, *icodec;\n\n    OutputStream *ost, **ost_table = NULL;\n\n    InputStream *ist;\n\n    char error[1024];\n\n    int key;\n\n    int want_sdp = 1;\n\n    uint8_t no_packet[MAX_FILES]={0};\n\n    int no_packet_count=0;\n\n    int nb_frame_threshold[AVMEDIA_TYPE_NB]={0};\n\n    int nb_streams[AVMEDIA_TYPE_NB]={0};\n\n\n\n    if (rate_emu)\n\n        for (i = 0; i < nb_input_streams; i++)\n\n            input_streams[i].start = av_gettime();\n\n\n\n    /* output stream init */\n\n    nb_ostreams = 0;\n\n    for(i=0;i<nb_output_files;i++) {\n\n        os = output_files[i];\n\n        if (!os->nb_streams && !(os->oformat->flags & AVFMT_NOSTREAMS)) {\n\n            av_dump_format(output_files[i], i, output_files[i]->filename, 1);\n\n            fprintf(stderr, \"Output file #%d does not contain any stream\\n\", i);\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n        nb_ostreams += os->nb_streams;\n\n    }\n\n    if (nb_stream_maps > 0 && nb_stream_maps != nb_ostreams) {\n\n        fprintf(stderr, \"Number of stream maps must match number of output streams\\n\");\n\n        ret = AVERROR(EINVAL);\n\n        goto fail;\n\n    }\n\n\n\n    /* Sanity check the mapping args -- do the input files & streams exist? */\n\n    for(i=0;i<nb_stream_maps;i++) {\n\n        int fi = stream_maps[i].file_index;\n\n        int si = stream_maps[i].stream_index;\n\n\n\n        if (fi < 0 || fi > nb_input_files - 1 ||\n\n            si < 0 || si > input_files[fi].ctx->nb_streams - 1) {\n\n            fprintf(stderr,\"Could not find input stream #%d.%d\\n\", fi, si);\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n        fi = stream_maps[i].sync_file_index;\n\n        si = stream_maps[i].sync_stream_index;\n\n        if (fi < 0 || fi > nb_input_files - 1 ||\n\n            si < 0 || si > input_files[fi].ctx->nb_streams - 1) {\n\n            fprintf(stderr,\"Could not find sync stream #%d.%d\\n\", fi, si);\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n    ost_table = av_mallocz(sizeof(OutputStream *) * nb_ostreams);\n\n    if (!ost_table)\n\n        goto fail;\n\n\n\n    for(k=0;k<nb_output_files;k++) {\n\n        os = output_files[k];\n\n        for(i=0;i<os->nb_streams;i++,n++) {\n\n            nb_streams[os->streams[i]->codec->codec_type]++;\n\n        }\n\n    }\n\n    for(step=1<<30; step; step>>=1){\n\n        int found_streams[AVMEDIA_TYPE_NB]={0};\n\n        for(j=0; j<AVMEDIA_TYPE_NB; j++)\n\n            nb_frame_threshold[j] += step;\n\n\n\n        for(j=0; j<nb_input_streams; j++) {\n\n            int skip=0;\n\n            ist = &input_streams[j];\n\n            if(opt_programid){\n\n                int pi,si;\n\n                AVFormatContext *f= input_files[ ist->file_index ].ctx;\n\n                skip=1;\n\n                for(pi=0; pi<f->nb_programs; pi++){\n\n                    AVProgram *p= f->programs[pi];\n\n                    if(p->id == opt_programid)\n\n                        for(si=0; si<p->nb_stream_indexes; si++){\n\n                            if(f->streams[ p->stream_index[si] ] == ist->st)\n\n                                skip=0;\n\n                        }\n\n                }\n\n            }\n\n            if (ist->discard && ist->st->discard != AVDISCARD_ALL && !skip\n\n                && nb_frame_threshold[ist->st->codec->codec_type] <= ist->st->codec_info_nb_frames){\n\n                found_streams[ist->st->codec->codec_type]++;\n\n            }\n\n        }\n\n        for(j=0; j<AVMEDIA_TYPE_NB; j++)\n\n            if(found_streams[j] < nb_streams[j])\n\n                nb_frame_threshold[j] -= step;\n\n    }\n\n    n = 0;\n\n    for(k=0;k<nb_output_files;k++) {\n\n        os = output_files[k];\n\n        for(i=0;i<os->nb_streams;i++,n++) {\n\n            int found;\n\n            ost = ost_table[n] = output_streams_for_file[k][i];\n\n            if (nb_stream_maps > 0) {\n\n                ost->source_index = input_files[stream_maps[n].file_index].ist_index +\n\n                    stream_maps[n].stream_index;\n\n\n\n                /* Sanity check that the stream types match */\n\n                if (input_streams[ost->source_index].st->codec->codec_type != ost->st->codec->codec_type) {\n\n                    int i= ost->file_index;\n\n                    av_dump_format(output_files[i], i, output_files[i]->filename, 1);\n\n                    fprintf(stderr, \"Codec type mismatch for mapping #%d.%d -> #%d.%d\\n\",\n\n                        stream_maps[n].file_index, stream_maps[n].stream_index,\n\n                        ost->file_index, ost->index);\n\n                    ffmpeg_exit(1);\n\n                }\n\n\n\n            } else {\n\n                /* get corresponding input stream index : we select the first one with the right type */\n\n                found = 0;\n\n                for (j = 0; j < nb_input_streams; j++) {\n\n                    int skip=0;\n\n                    ist = &input_streams[j];\n\n                    if(opt_programid){\n\n                        int pi,si;\n\n                        AVFormatContext *f = input_files[ist->file_index].ctx;\n\n                        skip=1;\n\n                        for(pi=0; pi<f->nb_programs; pi++){\n\n                            AVProgram *p= f->programs[pi];\n\n                            if(p->id == opt_programid)\n\n                                for(si=0; si<p->nb_stream_indexes; si++){\n\n                                    if(f->streams[ p->stream_index[si] ] == ist->st)\n\n                                        skip=0;\n\n                                }\n\n                        }\n\n                    }\n\n                    if (ist->discard && ist->st->discard != AVDISCARD_ALL && !skip &&\n\n                        ist->st->codec->codec_type == ost->st->codec->codec_type &&\n\n                        nb_frame_threshold[ist->st->codec->codec_type] <= ist->st->codec_info_nb_frames) {\n\n                            ost->source_index = j;\n\n                            found = 1;\n\n                            break;\n\n                    }\n\n                }\n\n\n\n                if (!found) {\n\n                    if(! opt_programid) {\n\n                        /* try again and reuse existing stream */\n\n                        for (j = 0; j < nb_input_streams; j++) {\n\n                            ist = &input_streams[j];\n\n                            if (   ist->st->codec->codec_type == ost->st->codec->codec_type\n\n                                && ist->st->discard != AVDISCARD_ALL) {\n\n                                ost->source_index = j;\n\n                                found = 1;\n\n                            }\n\n                        }\n\n                    }\n\n                    if (!found) {\n\n                        int i= ost->file_index;\n\n                        av_dump_format(output_files[i], i, output_files[i]->filename, 1);\n\n                        fprintf(stderr, \"Could not find input stream matching output stream #%d.%d\\n\",\n\n                                ost->file_index, ost->index);\n\n                        ffmpeg_exit(1);\n\n                    }\n\n                }\n\n            }\n\n            ist = &input_streams[ost->source_index];\n\n            ist->discard = 0;\n\n            ost->sync_ist = (nb_stream_maps > 0) ?\n\n                &input_streams[input_files[stream_maps[n].sync_file_index].ist_index +\n\n                         stream_maps[n].sync_stream_index] : ist;\n\n        }\n\n    }\n\n\n\n    /* for each output stream, we compute the right encoding parameters */\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        ost = ost_table[i];\n\n        os = output_files[ost->file_index];\n\n        ist = &input_streams[ost->source_index];\n\n\n\n        codec = ost->st->codec;\n\n        icodec = ist->st->codec;\n\n\n\n        if (metadata_streams_autocopy)\n\n            av_dict_copy(&ost->st->metadata, ist->st->metadata,\n\n                         AV_DICT_DONT_OVERWRITE);\n\n\n\n        ost->st->disposition = ist->st->disposition;\n\n        codec->bits_per_raw_sample= icodec->bits_per_raw_sample;\n\n        codec->chroma_sample_location = icodec->chroma_sample_location;\n\n\n\n        if (ost->st->stream_copy) {\n\n            uint64_t extra_size = (uint64_t)icodec->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE;\n\n\n\n            if (extra_size > INT_MAX)\n\n                goto fail;\n\n\n\n            /* if stream_copy is selected, no need to decode or encode */\n\n            codec->codec_id = icodec->codec_id;\n\n            codec->codec_type = icodec->codec_type;\n\n\n\n            if(!codec->codec_tag){\n\n                if(   !os->oformat->codec_tag\n\n                   || av_codec_get_id (os->oformat->codec_tag, icodec->codec_tag) == codec->codec_id\n\n                   || av_codec_get_tag(os->oformat->codec_tag, icodec->codec_id) <= 0)\n\n                    codec->codec_tag = icodec->codec_tag;\n\n            }\n\n\n\n            codec->bit_rate = icodec->bit_rate;\n\n            codec->rc_max_rate    = icodec->rc_max_rate;\n\n            codec->rc_buffer_size = icodec->rc_buffer_size;\n\n            codec->extradata= av_mallocz(extra_size);\n\n            if (!codec->extradata)\n\n                goto fail;\n\n            memcpy(codec->extradata, icodec->extradata, icodec->extradata_size);\n\n            codec->extradata_size= icodec->extradata_size;\n\n\n\n            codec->time_base = ist->st->time_base;\n\n            if(!strcmp(os->oformat->name, \"avi\")) {\n\n                if(!copy_tb && av_q2d(icodec->time_base)*icodec->ticks_per_frame > 2*av_q2d(ist->st->time_base) && av_q2d(ist->st->time_base) < 1.0/500){\n\n                    codec->time_base = icodec->time_base;\n\n                    codec->time_base.num *= icodec->ticks_per_frame;\n\n                    codec->time_base.den *= 2;\n\n                }\n\n            } else if(!(os->oformat->flags & AVFMT_VARIABLE_FPS)) {\n\n                if(!copy_tb && av_q2d(icodec->time_base)*icodec->ticks_per_frame > av_q2d(ist->st->time_base) && av_q2d(ist->st->time_base) < 1.0/500){\n\n                    codec->time_base = icodec->time_base;\n\n                    codec->time_base.num *= icodec->ticks_per_frame;\n\n                }\n\n            }\n\n            av_reduce(&codec->time_base.num, &codec->time_base.den,\n\n                        codec->time_base.num, codec->time_base.den, INT_MAX);\n\n\n\n            switch(codec->codec_type) {\n\n            case AVMEDIA_TYPE_AUDIO:\n\n                if(audio_volume != 256) {\n\n                    fprintf(stderr,\"-acodec copy and -vol are incompatible (frames are not decoded)\\n\");\n\n                    ffmpeg_exit(1);\n\n                }\n\n                codec->channel_layout = icodec->channel_layout;\n\n                codec->sample_rate = icodec->sample_rate;\n\n                codec->channels = icodec->channels;\n\n                codec->frame_size = icodec->frame_size;\n\n                codec->audio_service_type = icodec->audio_service_type;\n\n                codec->block_align= icodec->block_align;\n\n                if(codec->block_align == 1 && codec->codec_id == CODEC_ID_MP3)\n\n                    codec->block_align= 0;\n\n                if(codec->codec_id == CODEC_ID_AC3)\n\n                    codec->block_align= 0;\n\n                break;\n\n            case AVMEDIA_TYPE_VIDEO:\n\n                codec->pix_fmt = icodec->pix_fmt;\n\n                codec->width = icodec->width;\n\n                codec->height = icodec->height;\n\n                codec->has_b_frames = icodec->has_b_frames;\n\n                if (!codec->sample_aspect_ratio.num) {\n\n                    codec->sample_aspect_ratio =\n\n                    ost->st->sample_aspect_ratio =\n\n                        ist->st->sample_aspect_ratio.num ? ist->st->sample_aspect_ratio :\n\n                        ist->st->codec->sample_aspect_ratio.num ?\n\n                        ist->st->codec->sample_aspect_ratio : (AVRational){0, 1};\n\n                }\n\n                break;\n\n            case AVMEDIA_TYPE_SUBTITLE:\n\n                codec->width = icodec->width;\n\n                codec->height = icodec->height;\n\n                break;\n\n            case AVMEDIA_TYPE_DATA:\n\n                break;\n\n            default:\n\n                abort();\n\n            }\n\n        } else {\n\n            if (!ost->enc)\n\n                ost->enc = avcodec_find_encoder(ost->st->codec->codec_id);\n\n            switch(codec->codec_type) {\n\n            case AVMEDIA_TYPE_AUDIO:\n\n                ost->fifo= av_fifo_alloc(1024);\n\n                if(!ost->fifo)\n\n                    goto fail;\n\n                ost->reformat_pair = MAKE_SFMT_PAIR(AV_SAMPLE_FMT_NONE,AV_SAMPLE_FMT_NONE);\n\n                if (!codec->sample_rate) {\n\n                    codec->sample_rate = icodec->sample_rate;\n\n                }\n\n                choose_sample_rate(ost->st, ost->enc);\n\n                codec->time_base = (AVRational){1, codec->sample_rate};\n\n                if (codec->sample_fmt == AV_SAMPLE_FMT_NONE)\n\n                    codec->sample_fmt = icodec->sample_fmt;\n\n                choose_sample_fmt(ost->st, ost->enc);\n\n                if (!codec->channels) {\n\n                    codec->channels = icodec->channels;\n\n                    codec->channel_layout = icodec->channel_layout;\n\n                }\n\n                if (av_get_channel_layout_nb_channels(codec->channel_layout) != codec->channels)\n\n                    codec->channel_layout = 0;\n\n                ost->audio_resample = codec->sample_rate != icodec->sample_rate || audio_sync_method > 1;\n\n                icodec->request_channels = codec->channels;\n\n                ist->decoding_needed = 1;\n\n                ost->encoding_needed = 1;\n\n                ost->resample_sample_fmt  = icodec->sample_fmt;\n\n                ost->resample_sample_rate = icodec->sample_rate;\n\n                ost->resample_channels    = icodec->channels;\n\n                break;\n\n            case AVMEDIA_TYPE_VIDEO:\n\n                if (codec->pix_fmt == PIX_FMT_NONE)\n\n                    codec->pix_fmt = icodec->pix_fmt;\n\n                choose_pixel_fmt(ost->st, ost->enc);\n\n\n\n                if (ost->st->codec->pix_fmt == PIX_FMT_NONE) {\n\n                    fprintf(stderr, \"Video pixel format is unknown, stream cannot be encoded\\n\");\n\n                    ffmpeg_exit(1);\n\n                }\n\n\n\n                if (!codec->width || !codec->height) {\n\n                    codec->width  = icodec->width;\n\n                    codec->height = icodec->height;\n\n                }\n\n\n\n                ost->video_resample = codec->width   != icodec->width  ||\n\n                                      codec->height  != icodec->height ||\n\n                                      codec->pix_fmt != icodec->pix_fmt;\n\n                if (ost->video_resample) {\n\n                    codec->bits_per_raw_sample= frame_bits_per_raw_sample;\n\n                }\n\n\n\n                ost->resample_height = icodec->height;\n\n                ost->resample_width  = icodec->width;\n\n                ost->resample_pix_fmt= icodec->pix_fmt;\n\n                ost->encoding_needed = 1;\n\n                ist->decoding_needed = 1;\n\n\n\n                if (!ost->frame_rate.num)\n\n                    ost->frame_rate = ist->st->r_frame_rate.num ? ist->st->r_frame_rate : (AVRational){25,1};\n\n                if (ost->enc && ost->enc->supported_framerates && !force_fps) {\n\n                    int idx = av_find_nearest_q_idx(ost->frame_rate, ost->enc->supported_framerates);\n\n                    ost->frame_rate = ost->enc->supported_framerates[idx];\n\n                }\n\n                codec->time_base = (AVRational){ost->frame_rate.den, ost->frame_rate.num};\n\n                if(   av_q2d(codec->time_base) < 0.001 && video_sync_method\n\n                   && (video_sync_method==1 || (video_sync_method<0 && !(os->oformat->flags & AVFMT_VARIABLE_FPS)))){\n\n                    av_log(os, AV_LOG_WARNING, \"Frame rate very high for a muxer not effciciently supporting it.\\n\"\n\n                                               \"Please consider specifiying a lower framerate, a different muxer or -vsync 2\\n\");\n\n                }\n\n\n\n#if CONFIG_AVFILTER\n\n                if (configure_video_filters(ist, ost)) {\n\n                    fprintf(stderr, \"Error opening filters!\\n\");\n\n                    exit(1);\n\n                }\n\n#endif\n\n                break;\n\n            case AVMEDIA_TYPE_SUBTITLE:\n\n                ost->encoding_needed = 1;\n\n                ist->decoding_needed = 1;\n\n                break;\n\n            default:\n\n                abort();\n\n                break;\n\n            }\n\n            /* two pass mode */\n\n            if (ost->encoding_needed && codec->codec_id != CODEC_ID_H264 &&\n\n                (codec->flags & (CODEC_FLAG_PASS1 | CODEC_FLAG_PASS2))) {\n\n                char logfilename[1024];\n\n                FILE *f;\n\n\n\n                snprintf(logfilename, sizeof(logfilename), \"%s-%d.log\",\n\n                         pass_logfilename_prefix ? pass_logfilename_prefix : DEFAULT_PASS_LOGFILENAME_PREFIX,\n\n                         i);\n\n                if (codec->flags & CODEC_FLAG_PASS1) {\n\n                    f = fopen(logfilename, \"wb\");\n\n                    if (!f) {\n\n                        fprintf(stderr, \"Cannot write log file '%s' for pass-1 encoding: %s\\n\", logfilename, strerror(errno));\n\n                        ffmpeg_exit(1);\n\n                    }\n\n                    ost->logfile = f;\n\n                } else {\n\n                    char  *logbuffer;\n\n                    size_t logbuffer_size;\n\n                    if (read_file(logfilename, &logbuffer, &logbuffer_size) < 0) {\n\n                        fprintf(stderr, \"Error reading log file '%s' for pass-2 encoding\\n\", logfilename);\n\n                        ffmpeg_exit(1);\n\n                    }\n\n                    codec->stats_in = logbuffer;\n\n                }\n\n            }\n\n        }\n\n        if(codec->codec_type == AVMEDIA_TYPE_VIDEO){\n\n            /* maximum video buffer size is 6-bytes per pixel, plus DPX header size */\n\n            int size= codec->width * codec->height;\n\n            bit_buffer_size= FFMAX(bit_buffer_size, 6*size + 1664);\n\n        }\n\n    }\n\n\n\n    if (!bit_buffer)\n\n        bit_buffer = av_malloc(bit_buffer_size);\n\n    if (!bit_buffer) {\n\n        fprintf(stderr, \"Cannot allocate %d bytes output buffer\\n\",\n\n                bit_buffer_size);\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    /* open each encoder */\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        ost = ost_table[i];\n\n        if (ost->encoding_needed) {\n\n            AVCodec *codec = ost->enc;\n\n            AVCodecContext *dec = input_streams[ost->source_index].st->codec;\n\n            if (!codec) {\n\n                snprintf(error, sizeof(error), \"Encoder (codec id %d) not found for output stream #%d.%d\",\n\n                         ost->st->codec->codec_id, ost->file_index, ost->index);\n\n                ret = AVERROR(EINVAL);\n\n                goto dump_format;\n\n            }\n\n            if (dec->subtitle_header) {\n\n                ost->st->codec->subtitle_header = av_malloc(dec->subtitle_header_size);\n\n                if (!ost->st->codec->subtitle_header) {\n\n                    ret = AVERROR(ENOMEM);\n\n                    goto dump_format;\n\n                }\n\n                memcpy(ost->st->codec->subtitle_header, dec->subtitle_header, dec->subtitle_header_size);\n\n                ost->st->codec->subtitle_header_size = dec->subtitle_header_size;\n\n            }\n\n            if (avcodec_open2(ost->st->codec, codec, &ost->opts) < 0) {\n\n                snprintf(error, sizeof(error), \"Error while opening encoder for output stream #%d.%d - maybe incorrect parameters such as bit_rate, rate, width or height\",\n\n                        ost->file_index, ost->index);\n\n                ret = AVERROR(EINVAL);\n\n                goto dump_format;\n\n            }\n\n            assert_codec_experimental(ost->st->codec, 1);\n\n            assert_avoptions(ost->opts);\n\n            if (ost->st->codec->bit_rate && ost->st->codec->bit_rate < 1000)\n\n                av_log(NULL, AV_LOG_WARNING, \"The bitrate parameter is set too low.\"\n\n                                             \"It takes bits/s as argument, not kbits/s\\n\");\n\n            extra_size += ost->st->codec->extradata_size;\n\n        }\n\n    }\n\n\n\n    /* open each decoder */\n\n    for (i = 0; i < nb_input_streams; i++) {\n\n        ist = &input_streams[i];\n\n        if (ist->decoding_needed) {\n\n            AVCodec *codec = ist->dec;\n\n            if (!codec)\n\n                codec = avcodec_find_decoder(ist->st->codec->codec_id);\n\n            if (!codec) {\n\n                snprintf(error, sizeof(error), \"Decoder (codec id %d) not found for input stream #%d.%d\",\n\n                        ist->st->codec->codec_id, ist->file_index, ist->st->index);\n\n                ret = AVERROR(EINVAL);\n\n                goto dump_format;\n\n            }\n\n            if (avcodec_open2(ist->st->codec, codec, &ist->opts) < 0) {\n\n                snprintf(error, sizeof(error), \"Error while opening decoder for input stream #%d.%d\",\n\n                        ist->file_index, ist->st->index);\n\n                ret = AVERROR(EINVAL);\n\n                goto dump_format;\n\n            }\n\n            assert_codec_experimental(ist->st->codec, 0);\n\n            assert_avoptions(ost->opts);\n\n            //if (ist->st->codec->codec_type == AVMEDIA_TYPE_VIDEO)\n\n            //    ist->st->codec->flags |= CODEC_FLAG_REPEAT_FIELD;\n\n        }\n\n    }\n\n\n\n    /* init pts */\n\n    for (i = 0; i < nb_input_streams; i++) {\n\n        AVStream *st;\n\n        ist = &input_streams[i];\n\n        st= ist->st;\n\n        ist->pts = st->avg_frame_rate.num ? - st->codec->has_b_frames*AV_TIME_BASE / av_q2d(st->avg_frame_rate) : 0;\n\n        ist->next_pts = AV_NOPTS_VALUE;\n\n        ist->is_start = 1;\n\n    }\n\n\n\n    /* set meta data information from input file if required */\n\n    for (i=0;i<nb_meta_data_maps;i++) {\n\n        AVFormatContext *files[2];\n\n        AVDictionary    **meta[2];\n\n        int j;\n\n\n\n#define METADATA_CHECK_INDEX(index, nb_elems, desc)\\\n\n        if ((index) < 0 || (index) >= (nb_elems)) {\\\n\n            snprintf(error, sizeof(error), \"Invalid %s index %d while processing metadata maps\\n\",\\\n\n                     (desc), (index));\\\n\n            ret = AVERROR(EINVAL);\\\n\n            goto dump_format;\\\n\n        }\n\n\n\n        int out_file_index = meta_data_maps[i][0].file;\n\n        int in_file_index = meta_data_maps[i][1].file;\n\n        if (in_file_index < 0 || out_file_index < 0)\n\n            continue;\n\n        METADATA_CHECK_INDEX(out_file_index, nb_output_files, \"output file\")\n\n        METADATA_CHECK_INDEX(in_file_index, nb_input_files, \"input file\")\n\n\n\n        files[0] = output_files[out_file_index];\n\n        files[1] = input_files[in_file_index].ctx;\n\n\n\n        for (j = 0; j < 2; j++) {\n\n            MetadataMap *map = &meta_data_maps[i][j];\n\n\n\n            switch (map->type) {\n\n            case 'g':\n\n                meta[j] = &files[j]->metadata;\n\n                break;\n\n            case 's':\n\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_streams, \"stream\")\n\n                meta[j] = &files[j]->streams[map->index]->metadata;\n\n                break;\n\n            case 'c':\n\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_chapters, \"chapter\")\n\n                meta[j] = &files[j]->chapters[map->index]->metadata;\n\n                break;\n\n            case 'p':\n\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_programs, \"program\")\n\n                meta[j] = &files[j]->programs[map->index]->metadata;\n\n                break;\n\n            }\n\n        }\n\n\n\n        av_dict_copy(meta[0], *meta[1], AV_DICT_DONT_OVERWRITE);\n\n    }\n\n\n\n    /* copy global metadata by default */\n\n    if (metadata_global_autocopy) {\n\n\n\n        for (i = 0; i < nb_output_files; i++)\n\n            av_dict_copy(&output_files[i]->metadata, input_files[0].ctx->metadata,\n\n                         AV_DICT_DONT_OVERWRITE);\n\n    }\n\n\n\n    /* copy chapters according to chapter maps */\n\n    for (i = 0; i < nb_chapter_maps; i++) {\n\n        int infile  = chapter_maps[i].in_file;\n\n        int outfile = chapter_maps[i].out_file;\n\n\n\n        if (infile < 0 || outfile < 0)\n\n            continue;\n\n        if (infile >= nb_input_files) {\n\n            snprintf(error, sizeof(error), \"Invalid input file index %d in chapter mapping.\\n\", infile);\n\n            ret = AVERROR(EINVAL);\n\n            goto dump_format;\n\n        }\n\n        if (outfile >= nb_output_files) {\n\n            snprintf(error, sizeof(error), \"Invalid output file index %d in chapter mapping.\\n\",outfile);\n\n            ret = AVERROR(EINVAL);\n\n            goto dump_format;\n\n        }\n\n        copy_chapters(infile, outfile);\n\n    }\n\n\n\n    /* copy chapters from the first input file that has them*/\n\n    if (!nb_chapter_maps)\n\n        for (i = 0; i < nb_input_files; i++) {\n\n            if (!input_files[i].ctx->nb_chapters)\n\n                continue;\n\n\n\n            for (j = 0; j < nb_output_files; j++)\n\n                if ((ret = copy_chapters(i, j)) < 0)\n\n                    goto dump_format;\n\n            break;\n\n        }\n\n\n\n    /* open files and write file headers */\n\n    for(i=0;i<nb_output_files;i++) {\n\n        os = output_files[i];\n\n        if (avformat_write_header(os, &output_opts[i]) < 0) {\n\n            snprintf(error, sizeof(error), \"Could not write header for output file #%d (incorrect codec parameters ?)\", i);\n\n            ret = AVERROR(EINVAL);\n\n            goto dump_format;\n\n        }\n\n//        assert_avoptions(output_opts[i]);\n\n        if (strcmp(output_files[i]->oformat->name, \"rtp\")) {\n\n            want_sdp = 0;\n\n        }\n\n    }\n\n\n\n dump_format:\n\n    /* dump the file output parameters - cannot be done before in case\n\n       of stream copy */\n\n    for(i=0;i<nb_output_files;i++) {\n\n        av_dump_format(output_files[i], i, output_files[i]->filename, 1);\n\n    }\n\n\n\n    /* dump the stream mapping */\n\n    if (verbose >= 0) {\n\n        fprintf(stderr, \"Stream mapping:\\n\");\n\n        for(i=0;i<nb_ostreams;i++) {\n\n            ost = ost_table[i];\n\n            fprintf(stderr, \"  Stream #%d.%d -> #%d.%d\",\n\n                    input_streams[ost->source_index].file_index,\n\n                    input_streams[ost->source_index].st->index,\n\n                    ost->file_index,\n\n                    ost->index);\n\n            if (ost->sync_ist != &input_streams[ost->source_index])\n\n                fprintf(stderr, \" [sync #%d.%d]\",\n\n                        ost->sync_ist->file_index,\n\n                        ost->sync_ist->st->index);\n\n            fprintf(stderr, \"\\n\");\n\n        }\n\n    }\n\n\n\n    if (ret) {\n\n        fprintf(stderr, \"%s\\n\", error);\n\n        goto fail;\n\n    }\n\n\n\n    if (want_sdp) {\n\n        print_sdp(output_files, nb_output_files);\n\n    }\n\n\n\n    if (!using_stdin) {\n\n        if(verbose >= 0)\n\n            fprintf(stderr, \"Press [q] to stop, [?] for help\\n\");\n\n        avio_set_interrupt_cb(decode_interrupt_cb);\n\n    }\n\n    term_init();\n\n\n\n    timer_start = av_gettime();\n\n\n\n    for(; received_sigterm == 0;) {\n\n        int file_index, ist_index;\n\n        AVPacket pkt;\n\n        double ipts_min;\n\n        double opts_min;\n\n\n\n    redo:\n\n        ipts_min= 1e100;\n\n        opts_min= 1e100;\n\n        /* if 'q' pressed, exits */\n\n        if (!using_stdin) {\n\n            if (q_pressed)\n\n                break;\n\n            /* read_key() returns 0 on EOF */\n\n            key = read_key();\n\n            if (key == 'q')\n\n                break;\n\n            if (key == '+') verbose++;\n\n            if (key == '-') verbose--;\n\n            if (key == 's') qp_hist     ^= 1;\n\n            if (key == 'h'){\n\n                if (do_hex_dump){\n\n                    do_hex_dump = do_pkt_dump = 0;\n\n                } else if(do_pkt_dump){\n\n                    do_hex_dump = 1;\n\n                } else\n\n                    do_pkt_dump = 1;\n\n                av_log_set_level(AV_LOG_DEBUG);\n\n            }\n\n            if (key == 'd' || key == 'D'){\n\n                int debug=0;\n\n                if(key == 'D') {\n\n                    debug = input_streams[0].st->codec->debug<<1;\n\n                    if(!debug) debug = 1;\n\n                    while(debug & (FF_DEBUG_DCT_COEFF|FF_DEBUG_VIS_QP|FF_DEBUG_VIS_MB_TYPE)) //unsupported, would just crash\n\n                        debug += debug;\n\n                }else\n\n                    scanf(\"%d\", &debug);\n\n                for(i=0;i<nb_input_streams;i++) {\n\n                    input_streams[i].st->codec->debug = debug;\n\n                }\n\n                for(i=0;i<nb_ostreams;i++) {\n\n                    ost = ost_table[i];\n\n                    ost->st->codec->debug = debug;\n\n                }\n\n                if(debug) av_log_set_level(AV_LOG_DEBUG);\n\n                fprintf(stderr,\"debug=%d\\n\", debug);\n\n            }\n\n            if (key == '?'){\n\n                fprintf(stderr, \"key    function\\n\"\n\n                                \"?      show this help\\n\"\n\n                                \"+      increase verbosity\\n\"\n\n                                \"-      decrease verbosity\\n\"\n\n                                \"D      cycle through available debug modes\\n\"\n\n                                \"h      dump packets/hex press to cycle through the 3 states\\n\"\n\n                                \"q      quit\\n\"\n\n                                \"s      Show QP histogram\\n\"\n\n                );\n\n            }\n\n        }\n\n\n\n        /* select the stream that we must read now by looking at the\n\n           smallest output pts */\n\n        file_index = -1;\n\n        for(i=0;i<nb_ostreams;i++) {\n\n            double ipts, opts;\n\n            ost = ost_table[i];\n\n            os = output_files[ost->file_index];\n\n            ist = &input_streams[ost->source_index];\n\n            if(ist->is_past_recording_time || no_packet[ist->file_index])\n\n                continue;\n\n                opts = ost->st->pts.val * av_q2d(ost->st->time_base);\n\n            ipts = (double)ist->pts;\n\n            if (!input_files[ist->file_index].eof_reached){\n\n                if(ipts < ipts_min) {\n\n                    ipts_min = ipts;\n\n                    if(input_sync ) file_index = ist->file_index;\n\n                }\n\n                if(opts < opts_min) {\n\n                    opts_min = opts;\n\n                    if(!input_sync) file_index = ist->file_index;\n\n                }\n\n            }\n\n            if(ost->frame_number >= max_frames[ost->st->codec->codec_type]){\n\n                file_index= -1;\n\n                break;\n\n            }\n\n        }\n\n        /* if none, if is finished */\n\n        if (file_index < 0) {\n\n            if(no_packet_count){\n\n                no_packet_count=0;\n\n                memset(no_packet, 0, sizeof(no_packet));\n\n                usleep(10000);\n\n                continue;\n\n            }\n\n            break;\n\n        }\n\n\n\n        /* finish if limit size exhausted */\n\n        if (limit_filesize != 0 && limit_filesize <= avio_tell(output_files[0]->pb))\n\n            break;\n\n\n\n        /* read a frame from it and output it in the fifo */\n\n        is = input_files[file_index].ctx;\n\n        ret= av_read_frame(is, &pkt);\n\n        if(ret == AVERROR(EAGAIN)){\n\n            no_packet[file_index]=1;\n\n            no_packet_count++;\n\n            continue;\n\n        }\n\n        if (ret < 0) {\n\n            input_files[file_index].eof_reached = 1;\n\n            if (opt_shortest)\n\n                break;\n\n            else\n\n                continue;\n\n        }\n\n\n\n        no_packet_count=0;\n\n        memset(no_packet, 0, sizeof(no_packet));\n\n\n\n        if (do_pkt_dump) {\n\n            av_pkt_dump_log2(NULL, AV_LOG_DEBUG, &pkt, do_hex_dump,\n\n                             is->streams[pkt.stream_index]);\n\n        }\n\n        /* the following test is needed in case new streams appear\n\n           dynamically in stream : we ignore them */\n\n        if (pkt.stream_index >= input_files[file_index].ctx->nb_streams)\n\n            goto discard_packet;\n\n        ist_index = input_files[file_index].ist_index + pkt.stream_index;\n\n        ist = &input_streams[ist_index];\n\n        if (ist->discard)\n\n            goto discard_packet;\n\n\n\n        if (pkt.dts != AV_NOPTS_VALUE)\n\n            pkt.dts += av_rescale_q(input_files[ist->file_index].ts_offset, AV_TIME_BASE_Q, ist->st->time_base);\n\n        if (pkt.pts != AV_NOPTS_VALUE)\n\n            pkt.pts += av_rescale_q(input_files[ist->file_index].ts_offset, AV_TIME_BASE_Q, ist->st->time_base);\n\n\n\n        if (ist->ts_scale) {\n\n            if(pkt.pts != AV_NOPTS_VALUE)\n\n                pkt.pts *= ist->ts_scale;\n\n            if(pkt.dts != AV_NOPTS_VALUE)\n\n                pkt.dts *= ist->ts_scale;\n\n        }\n\n\n\n//        fprintf(stderr, \"next:%\"PRId64\" dts:%\"PRId64\" off:%\"PRId64\" %d\\n\", ist->next_pts, pkt.dts, input_files[ist->file_index].ts_offset, ist->st->codec->codec_type);\n\n        if (pkt.dts != AV_NOPTS_VALUE && ist->next_pts != AV_NOPTS_VALUE\n\n            && (is->iformat->flags & AVFMT_TS_DISCONT)) {\n\n            int64_t pkt_dts= av_rescale_q(pkt.dts, ist->st->time_base, AV_TIME_BASE_Q);\n\n            int64_t delta= pkt_dts - ist->next_pts;\n\n            if((FFABS(delta) > 1LL*dts_delta_threshold*AV_TIME_BASE || pkt_dts+1<ist->pts)&& !copy_ts){\n\n                input_files[ist->file_index].ts_offset -= delta;\n\n                if (verbose > 2)\n\n                    fprintf(stderr, \"timestamp discontinuity %\"PRId64\", new offset= %\"PRId64\"\\n\",\n\n                            delta, input_files[ist->file_index].ts_offset);\n\n                pkt.dts-= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);\n\n                if(pkt.pts != AV_NOPTS_VALUE)\n\n                    pkt.pts-= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);\n\n            }\n\n        }\n\n\n\n        /* finish if recording time exhausted */\n\n        if (recording_time != INT64_MAX &&\n\n            (pkt.pts != AV_NOPTS_VALUE ?\n\n                av_compare_ts(pkt.pts, ist->st->time_base, recording_time + start_time, (AVRational){1, 1000000})\n\n                    :\n\n                av_compare_ts(ist->pts, AV_TIME_BASE_Q, recording_time + start_time, (AVRational){1, 1000000})\n\n            )>= 0) {\n\n            ist->is_past_recording_time = 1;\n\n            goto discard_packet;\n\n        }\n\n\n\n        //fprintf(stderr,\"read #%d.%d size=%d\\n\", ist->file_index, ist->st->index, pkt.size);\n\n        if (output_packet(ist, ist_index, ost_table, nb_ostreams, &pkt) < 0) {\n\n\n\n            if (verbose >= 0)\n\n                fprintf(stderr, \"Error while decoding stream #%d.%d\\n\",\n\n                        ist->file_index, ist->st->index);\n\n            if (exit_on_error)\n\n                ffmpeg_exit(1);\n\n            av_free_packet(&pkt);\n\n            goto redo;\n\n        }\n\n\n\n    discard_packet:\n\n        av_free_packet(&pkt);\n\n\n\n        /* dump report by using the output first video and audio streams */\n\n        print_report(output_files, ost_table, nb_ostreams, 0);\n\n    }\n\n\n\n    /* at the end of stream, we must flush the decoder buffers */\n\n    for (i = 0; i < nb_input_streams; i++) {\n\n        ist = &input_streams[i];\n\n        if (ist->decoding_needed) {\n\n            output_packet(ist, i, ost_table, nb_ostreams, NULL);\n\n        }\n\n    }\n\n\n\n    term_exit();\n\n\n\n    /* write the trailer if needed and close file */\n\n    for(i=0;i<nb_output_files;i++) {\n\n        os = output_files[i];\n\n        av_write_trailer(os);\n\n    }\n\n\n\n    /* dump report by using the first video and audio streams */\n\n    print_report(output_files, ost_table, nb_ostreams, 1);\n\n\n\n    /* close each encoder */\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        ost = ost_table[i];\n\n        if (ost->encoding_needed) {\n\n            av_freep(&ost->st->codec->stats_in);\n\n            avcodec_close(ost->st->codec);\n\n        }\n\n#if CONFIG_AVFILTER\n\n        avfilter_graph_free(&ost->graph);\n\n#endif\n\n    }\n\n\n\n    /* close each decoder */\n\n    for (i = 0; i < nb_input_streams; i++) {\n\n        ist = &input_streams[i];\n\n        if (ist->decoding_needed) {\n\n            avcodec_close(ist->st->codec);\n\n        }\n\n    }\n\n\n\n    /* finished ! */\n\n    ret = 0;\n\n\n\n fail:\n\n    av_freep(&bit_buffer);\n\n\n\n    if (ost_table) {\n\n        for(i=0;i<nb_ostreams;i++) {\n\n            ost = ost_table[i];\n\n            if (ost) {\n\n                if (ost->st->stream_copy)\n\n                    av_freep(&ost->st->codec->extradata);\n\n                if (ost->logfile) {\n\n                    fclose(ost->logfile);\n\n                    ost->logfile = NULL;\n\n                }\n\n                av_fifo_free(ost->fifo); /* works even if fifo is not\n\n                                             initialized but set to zero */\n\n                av_freep(&ost->st->codec->subtitle_header);\n\n                av_free(ost->resample_frame.data[0]);\n\n                av_free(ost->forced_kf_pts);\n\n                if (ost->video_resample)\n\n                    sws_freeContext(ost->img_resample_ctx);\n\n                if (ost->resample)\n\n                    audio_resample_close(ost->resample);\n\n                if (ost->reformat_ctx)\n\n                    av_audio_convert_free(ost->reformat_ctx);\n\n                av_dict_free(&ost->opts);\n\n                av_free(ost);\n\n            }\n\n        }\n\n        av_free(ost_table);\n\n    }\n\n    return ret;\n\n}\n", "idx": 23480}
{"project": "FFmpeg", "commit_id": "6d695d7acc4cb1da84eb73710e05a4c090e5ab31", "target": 1, "func": "static int amv_encode_picture(AVCodecContext *avctx, AVPacket *pkt,\n\n                              const AVFrame *pic_arg, int *got_packet)\n\n\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    AVFrame *pic;\n\n    int i, ret;\n\n    int chroma_h_shift, chroma_v_shift;\n\n\n\n    av_pix_fmt_get_chroma_sub_sample(avctx->pix_fmt, &chroma_h_shift, &chroma_v_shift);\n\n\n\n    //CODEC_FLAG_EMU_EDGE have to be cleared\n\n    if(s->avctx->flags & CODEC_FLAG_EMU_EDGE)\n\n        return AVERROR(EINVAL);\n\n\n\n    if (avctx->height & 15) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Height must be a multiple of 16, also note, \"\n\n               \"if you have a AMV sample thats mod 16 != 0, please contact us\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    pic = av_frame_clone(pic_arg);\n\n    if (!pic)\n\n        return AVERROR(ENOMEM);\n\n    //picture should be flipped upside-down\n\n    for(i=0; i < 3; i++) {\n\n        int vsample = i ? 2 >> chroma_v_shift : 2;\n\n        pic->data[i] += (pic->linesize[i] * (vsample * (8 * s->mb_height -((s->height/V_MAX)&7)) - 1 ));\n\n        pic->linesize[i] *= -1;\n\n    }\n\n    ret = ff_MPV_encode_picture(avctx, pkt, pic, got_packet);\n\n    av_frame_free(&pic);\n\n    return ret;\n\n}\n", "idx": 23482}
{"project": "FFmpeg", "commit_id": "0d21a84605bad4e75dacb8196e5859902ed36f01", "target": 0, "func": "static inline void halfpel_motion_search4(MpegEncContext * s,\n\n\t\t\t\t  int *mx_ptr, int *my_ptr, int dmin,\n\n\t\t\t\t  int xmin, int ymin, int xmax, int ymax,\n\n                                  int pred_x, int pred_y, int block_x, int block_y,\n\n                                  uint8_t *ref_picture)\n\n{\n\n    UINT16 *mv_penalty= s->mv_penalty[s->f_code] + MAX_MV; // f_code of the prev frame\n\n    const int quant= s->qscale;\n\n    int pen_x, pen_y;\n\n    int mx, my, mx1, my1, d, xx, yy, dminh;\n\n    UINT8 *pix, *ptr;\n\n\n\n    xx = 8 * block_x;\n\n    yy = 8 * block_y;\n\n    pix =  s->new_picture[0] + (yy * s->linesize) + xx;\n\n    \n\n    mx = *mx_ptr;\n\n    my = *my_ptr;\n\n    ptr = ref_picture + ((yy+my) * s->linesize) + xx + mx;\n\n\n\n    dminh = dmin;\n\n\n\n    if (mx > xmin && mx < xmax && \n\n        my > ymin && my < ymax) {\n\n\n\n        mx= mx1= 2*mx;\n\n        my= my1= 2*my;\n\n        if(dmin < Z_THRESHOLD && mx==0 && my==0){\n\n            *mx_ptr = 0;\n\n            *my_ptr = 0;\n\n            return;\n\n        }\n\n        \n\n        pen_x= pred_x + mx;\n\n        pen_y= pred_y + my;\n\n\n\n        ptr-= s->linesize;\n\n        CHECK_HALF_MV4(xy2, -1, -1)\n\n        CHECK_HALF_MV4(y2 ,  0, -1)\n\n        CHECK_HALF_MV4(xy2, +1, -1)\n\n        \n\n        ptr+= s->linesize;\n\n        CHECK_HALF_MV4(x2 , -1,  0)\n\n        CHECK_HALF_MV4(x2 , +1,  0)\n\n        CHECK_HALF_MV4(xy2, -1, +1)\n\n        CHECK_HALF_MV4(y2 ,  0, +1)\n\n        CHECK_HALF_MV4(xy2, +1, +1)\n\n\n\n    }else{\n\n        mx*=2;\n\n        my*=2;\n\n    }\n\n\n\n    *mx_ptr = mx;\n\n    *my_ptr = my;\n\n}\n", "idx": 23487}
{"project": "FFmpeg", "commit_id": "1d16a1cf99488f16492b1bb48e023f4da8377e07", "target": 0, "func": "static void ff_h264_idct8_add4_mmx(uint8_t *dst, const int *block_offset, DCTELEM *block, int stride, const uint8_t nnzc[6*8]){\n\n    int i;\n\n    for(i=0; i<16; i+=4){\n\n        if(nnzc[ scan8[i] ])\n\n            ff_h264_idct8_add_mmx(dst + block_offset[i], block + i*16, stride);\n\n    }\n\n}\n", "idx": 23488}
{"project": "FFmpeg", "commit_id": "1303d62d8416fa315a0cc7bbbe35cfdab787ea92", "target": 0, "func": "static int mpegts_raw_read_packet(AVFormatContext *s,\n\n                                  AVPacket *pkt)\n\n{\n\n    MpegTSContext *ts = s->priv_data;\n\n    int ret, i;\n\n    int64_t pcr_h, next_pcr_h, pos;\n\n    int pcr_l, next_pcr_l;\n\n    uint8_t pcr_buf[12];\n\n\n\n    if (av_new_packet(pkt, TS_PACKET_SIZE) < 0)\n\n        return AVERROR(ENOMEM);\n\n    pkt->pos= url_ftell(s->pb);\n\n    ret = read_packet(s->pb, pkt->data, ts->raw_packet_size);\n\n    if (ret < 0) {\n\n        av_free_packet(pkt);\n\n        return ret;\n\n    }\n\n    if (ts->mpeg2ts_compute_pcr) {\n\n        /* compute exact PCR for each packet */\n\n        if (parse_pcr(&pcr_h, &pcr_l, pkt->data) == 0) {\n\n            /* we read the next PCR (XXX: optimize it by using a bigger buffer */\n\n            pos = url_ftell(s->pb);\n\n            for(i = 0; i < MAX_PACKET_READAHEAD; i++) {\n\n                url_fseek(s->pb, pos + i * ts->raw_packet_size, SEEK_SET);\n\n                get_buffer(s->pb, pcr_buf, 12);\n\n                if (parse_pcr(&next_pcr_h, &next_pcr_l, pcr_buf) == 0) {\n\n                    /* XXX: not precise enough */\n\n                    ts->pcr_incr = ((next_pcr_h - pcr_h) * 300 + (next_pcr_l - pcr_l)) /\n\n                        (i + 1);\n\n                    break;\n\n                }\n\n            }\n\n            url_fseek(s->pb, pos, SEEK_SET);\n\n            /* no next PCR found: we use previous increment */\n\n            ts->cur_pcr = pcr_h * 300 + pcr_l;\n\n        }\n\n        pkt->pts = ts->cur_pcr;\n\n        pkt->duration = ts->pcr_incr;\n\n        ts->cur_pcr += ts->pcr_incr;\n\n    }\n\n    pkt->stream_index = 0;\n\n    return 0;\n\n}\n", "idx": 23499}
{"project": "FFmpeg", "commit_id": "1dba8371d93cf1c83bcd5c432d921905206a60f3", "target": 0, "func": "int avio_open2(AVIOContext **s, const char *filename, int flags,\n\n               const AVIOInterruptCB *int_cb, AVDictionary **options)\n\n{\n\n    URLContext *h;\n\n    int err;\n\n\n\n    err = ffurl_open(&h, filename, flags, int_cb, options);\n\n    if (err < 0)\n\n        return err;\n\n    err = ffio_fdopen(s, h);\n\n    if (err < 0) {\n\n        ffurl_close(h);\n\n        return err;\n\n    }\n\n    return 0;\n\n}\n", "idx": 23506}
{"project": "FFmpeg", "commit_id": "aac46e088d67a390489af686b846dea4987d8ffb", "target": 0, "func": "static void sbr_hf_inverse_filter(float (*alpha0)[2], float (*alpha1)[2],\n\n                                  const float X_low[32][40][2], int k0)\n\n{\n\n    int k;\n\n    for (k = 0; k < k0; k++) {\n\n        float phi[3][2][2], dk;\n\n\n\n        autocorrelate(X_low[k], phi, 0);\n\n        autocorrelate(X_low[k], phi, 1);\n\n        autocorrelate(X_low[k], phi, 2);\n\n\n\n        dk =  phi[2][1][0] * phi[1][0][0] -\n\n             (phi[1][1][0] * phi[1][1][0] + phi[1][1][1] * phi[1][1][1]) / 1.000001f;\n\n\n\n        if (!dk) {\n\n            alpha1[k][0] = 0;\n\n            alpha1[k][1] = 0;\n\n        } else {\n\n            float temp_real, temp_im;\n\n            temp_real = phi[0][0][0] * phi[1][1][0] -\n\n                        phi[0][0][1] * phi[1][1][1] -\n\n                        phi[0][1][0] * phi[1][0][0];\n\n            temp_im   = phi[0][0][0] * phi[1][1][1] +\n\n                        phi[0][0][1] * phi[1][1][0] -\n\n                        phi[0][1][1] * phi[1][0][0];\n\n\n\n            alpha1[k][0] = temp_real / dk;\n\n            alpha1[k][1] = temp_im   / dk;\n\n        }\n\n\n\n        if (!phi[1][0][0]) {\n\n            alpha0[k][0] = 0;\n\n            alpha0[k][1] = 0;\n\n        } else {\n\n            float temp_real, temp_im;\n\n            temp_real = phi[0][0][0] + alpha1[k][0] * phi[1][1][0] +\n\n                                       alpha1[k][1] * phi[1][1][1];\n\n            temp_im   = phi[0][0][1] + alpha1[k][1] * phi[1][1][0] -\n\n                                       alpha1[k][0] * phi[1][1][1];\n\n\n\n            alpha0[k][0] = -temp_real / phi[1][0][0];\n\n            alpha0[k][1] = -temp_im   / phi[1][0][0];\n\n        }\n\n\n\n        if (alpha1[k][0] * alpha1[k][0] + alpha1[k][1] * alpha1[k][1] >= 16.0f ||\n\n           alpha0[k][0] * alpha0[k][0] + alpha0[k][1] * alpha0[k][1] >= 16.0f) {\n\n            alpha1[k][0] = 0;\n\n            alpha1[k][1] = 0;\n\n            alpha0[k][0] = 0;\n\n            alpha0[k][1] = 0;\n\n        }\n\n    }\n\n}\n", "idx": 23507}
{"project": "FFmpeg", "commit_id": "83548fe894cdb455cc127f754d09905b6d23c173", "target": 0, "func": "static int avi_write_trailer(AVFormatContext *s)\n\n{\n\n    AVIContext *avi = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int res = 0;\n\n    int i, j, n, nb_frames;\n\n    int64_t file_size;\n\n\n\n    if (pb->seekable) {\n\n        if (avi->riff_id == 1) {\n\n            ff_end_tag(pb, avi->movi_list);\n\n            res = avi_write_idx1(s);\n\n            ff_end_tag(pb, avi->riff_start);\n\n        } else {\n\n            avi_write_ix(s);\n\n            ff_end_tag(pb, avi->movi_list);\n\n            ff_end_tag(pb, avi->riff_start);\n\n\n\n            file_size = avio_tell(pb);\n\n            avio_seek(pb, avi->odml_list - 8, SEEK_SET);\n\n            ffio_wfourcc(pb, \"LIST\"); /* Making this AVI OpenDML one */\n\n            avio_skip(pb, 16);\n\n\n\n            for (n = nb_frames = 0; n < s->nb_streams; n++) {\n\n                AVCodecParameters *par = s->streams[n]->codecpar;\n\n                AVIStream *avist       = s->streams[n]->priv_data;\n\n\n\n                if (par->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n                    if (nb_frames < avist->packet_count)\n\n                        nb_frames = avist->packet_count;\n\n                } else {\n\n                    if (par->codec_id == AV_CODEC_ID_MP2 ||\n\n                        par->codec_id == AV_CODEC_ID_MP3)\n\n                        nb_frames += avist->packet_count;\n\n                }\n\n            }\n\n            avio_wl32(pb, nb_frames);\n\n            avio_seek(pb, file_size, SEEK_SET);\n\n\n\n            avi_write_counters(s, avi->riff_id);\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVIStream *avist = s->streams[i]->priv_data;\n\n        for (j = 0; j < avist->indexes.ents_allocated / AVI_INDEX_CLUSTER_SIZE; j++)\n\n            av_free(avist->indexes.cluster[j]);\n\n        av_freep(&avist->indexes.cluster);\n\n        avist->indexes.ents_allocated = avist->indexes.entry = 0;\n\n    }\n\n\n\n    return res;\n\n}\n", "idx": 23508}
{"project": "FFmpeg", "commit_id": "3cec81f4d4f26b62bc2d22bb450bbf51ec3a7f09", "target": 0, "func": "static int mov_read_udta_string(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    char tmp_key[5];\n\n    char str[1024], key2[32], language[4] = {0};\n\n    const char *key = NULL;\n\n    uint16_t langcode = 0;\n\n    uint32_t data_type = 0, str_size;\n\n    int (*parse)(MOVContext*, AVIOContext*, unsigned, const char*) = NULL;\n\n\n\n    switch (atom.type) {\n\n    case MKTAG(0xa9,'n','a','m'): key = \"title\";     break;\n\n    case MKTAG(0xa9,'a','u','t'):\n\n    case MKTAG(0xa9,'A','R','T'): key = \"artist\";    break;\n\n    case MKTAG( 'a','A','R','T'): key = \"album_artist\";    break;\n\n    case MKTAG(0xa9,'w','r','t'): key = \"composer\";  break;\n\n    case MKTAG( 'c','p','r','t'):\n\n    case MKTAG(0xa9,'c','p','y'): key = \"copyright\"; break;\n\n    case MKTAG(0xa9,'c','m','t'):\n\n    case MKTAG(0xa9,'i','n','f'): key = \"comment\";   break;\n\n    case MKTAG(0xa9,'a','l','b'): key = \"album\";     break;\n\n    case MKTAG(0xa9,'d','a','y'): key = \"date\";      break;\n\n    case MKTAG(0xa9,'g','e','n'): key = \"genre\";     break;\n\n    case MKTAG( 'g','n','r','e'): key = \"genre\";\n\n        parse = mov_metadata_gnre; break;\n\n    case MKTAG(0xa9,'t','o','o'):\n\n    case MKTAG(0xa9,'s','w','r'): key = \"encoder\";   break;\n\n    case MKTAG(0xa9,'e','n','c'): key = \"encoder\";   break;\n\n    case MKTAG(0xa9,'x','y','z'): key = \"location\";  break;\n\n    case MKTAG( 'd','e','s','c'): key = \"description\";break;\n\n    case MKTAG( 'l','d','e','s'): key = \"synopsis\";  break;\n\n    case MKTAG( 't','v','s','h'): key = \"show\";      break;\n\n    case MKTAG( 't','v','e','n'): key = \"episode_id\";break;\n\n    case MKTAG( 't','v','n','n'): key = \"network\";   break;\n\n    case MKTAG( 't','r','k','n'): key = \"track\";\n\n        parse = mov_metadata_track_or_disc_number; break;\n\n    case MKTAG( 'd','i','s','k'): key = \"disc\";\n\n        parse = mov_metadata_track_or_disc_number; break;\n\n    case MKTAG( 't','v','e','s'): key = \"episode_sort\";\n\n        parse = mov_metadata_int8_bypass_padding; break;\n\n    case MKTAG( 't','v','s','n'): key = \"season_number\";\n\n        parse = mov_metadata_int8_bypass_padding; break;\n\n    case MKTAG( 's','t','i','k'): key = \"media_type\";\n\n        parse = mov_metadata_int8_no_padding; break;\n\n    case MKTAG( 'h','d','v','d'): key = \"hd_video\";\n\n        parse = mov_metadata_int8_no_padding; break;\n\n    case MKTAG( 'p','g','a','p'): key = \"gapless_playback\";\n\n        parse = mov_metadata_int8_no_padding; break;\n\n    case MKTAG( 'l','o','c','i'):\n\n        return mov_metadata_loci(c, pb, atom.size);\n\n    }\n\n\n\n    if (c->itunes_metadata && atom.size > 8) {\n\n        int data_size = avio_rb32(pb);\n\n        int tag = avio_rl32(pb);\n\n        if (tag == MKTAG('d','a','t','a')) {\n\n            data_type = avio_rb32(pb); // type\n\n            avio_rb32(pb); // unknown\n\n            str_size = data_size - 16;\n\n            atom.size -= 16;\n\n\n\n            if (atom.type == MKTAG('c', 'o', 'v', 'r')) {\n\n                int ret = mov_read_covr(c, pb, data_type, str_size);\n\n                if (ret < 0) {\n\n                    av_log(c->fc, AV_LOG_ERROR, \"Error parsing cover art.\\n\");\n\n                    return ret;\n\n                }\n\n            }\n\n        } else return 0;\n\n    } else if (atom.size > 4 && key && !c->itunes_metadata) {\n\n        str_size = avio_rb16(pb); // string length\n\n        langcode = avio_rb16(pb);\n\n        ff_mov_lang_to_iso639(langcode, language);\n\n        atom.size -= 4;\n\n    } else\n\n        str_size = atom.size;\n\n\n\n    if (c->export_all && !key) {\n\n        snprintf(tmp_key, 5, \"%.4s\", (char*)&atom.type);\n\n        key = tmp_key;\n\n    }\n\n\n\n    if (!key)\n\n        return 0;\n\n    if (atom.size < 0)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    str_size = FFMIN3(sizeof(str)-1, str_size, atom.size);\n\n\n\n    if (parse)\n\n        parse(c, pb, str_size, key);\n\n    else {\n\n        if (data_type == 3 || (data_type == 0 && (langcode < 0x400 || langcode == 0x7fff))) { // MAC Encoded\n\n            mov_read_mac_string(c, pb, str_size, str, sizeof(str));\n\n        } else {\n\n            avio_read(pb, str, str_size);\n\n            str[str_size] = 0;\n\n        }\n\n        c->fc->event_flags |= AVFMT_EVENT_FLAG_METADATA_UPDATED;\n\n        av_dict_set(&c->fc->metadata, key, str, 0);\n\n        if (*language && strcmp(language, \"und\")) {\n\n            snprintf(key2, sizeof(key2), \"%s-%s\", key, language);\n\n            av_dict_set(&c->fc->metadata, key2, str, 0);\n\n        }\n\n    }\n\n    av_dlog(c->fc, \"lang \\\"%3s\\\" \", language);\n\n    av_dlog(c->fc, \"tag \\\"%s\\\" value \\\"%s\\\" atom \\\"%.4s\\\" %d %\"PRId64\"\\n\",\n\n            key, str, (char*)&atom.type, str_size, atom.size);\n\n\n\n    return 0;\n\n}\n", "idx": 23509}
{"project": "FFmpeg", "commit_id": "0ccabeeaef77e240f2a44f78271a8914a23e239b", "target": 0, "func": "static AVFilterBufferRef *get_video_buffer(AVFilterLink *link, int perms,\n\n                                        int w, int h)\n\n{\n\n    FlipContext *flip = link->dst->priv;\n\n    int i;\n\n\n\n    AVFilterBufferRef *picref = avfilter_get_video_buffer(link->dst->outputs[0],\n\n                                                       perms, w, h);\n\n\n\n    for (i = 0; i < 4; i ++) {\n\n        int vsub = i == 1 || i == 2 ? flip->vsub : 0;\n\n\n\n        if (picref->data[i]) {\n\n            picref->data[i] += ((h >> vsub)-1) * picref->linesize[i];\n\n            picref->linesize[i] = -picref->linesize[i];\n\n        }\n\n    }\n\n\n\n    return picref;\n\n}\n", "idx": 23515}
{"project": "FFmpeg", "commit_id": "753074721bd414874d18c372c491bdc6323fa3bf", "target": 0, "func": "static int set_pix_fmt(AVCodecContext *avctx, vpx_codec_caps_t codec_caps,\n\n                       struct vpx_codec_enc_cfg *enccfg, vpx_codec_flags_t *flags,\n\n                       vpx_img_fmt_t *img_fmt)\n\n{\n\n    VPxContext av_unused *ctx = avctx->priv_data;\n\n#ifdef VPX_IMG_FMT_HIGHBITDEPTH\n\n    enccfg->g_bit_depth = enccfg->g_input_bit_depth = 8;\n\n#endif\n\n    switch (avctx->pix_fmt) {\n\n    case AV_PIX_FMT_YUV420P:\n\n    case AV_PIX_FMT_YUVA420P:\n\n        enccfg->g_profile = 0;\n\n        *img_fmt = VPX_IMG_FMT_I420;\n\n        return 0;\n\n    case AV_PIX_FMT_YUV422P:\n\n        enccfg->g_profile = 1;\n\n        *img_fmt = VPX_IMG_FMT_I422;\n\n        return 0;\n\n#if VPX_IMAGE_ABI_VERSION >= 3\n\n    case AV_PIX_FMT_YUV440P:\n\n        enccfg->g_profile = 1;\n\n        *img_fmt = VPX_IMG_FMT_I440;\n\n        return 0;\n\n    case AV_PIX_FMT_GBRP:\n\n        ctx->vpx_cs = VPX_CS_SRGB;\n\n#endif\n\n    case AV_PIX_FMT_YUV444P:\n\n        enccfg->g_profile = 1;\n\n        *img_fmt = VPX_IMG_FMT_I444;\n\n        return 0;\n\n#ifdef VPX_IMG_FMT_HIGHBITDEPTH\n\n    case AV_PIX_FMT_YUV420P10:\n\n    case AV_PIX_FMT_YUV420P12:\n\n        if (codec_caps & VPX_CODEC_CAP_HIGHBITDEPTH) {\n\n            enccfg->g_bit_depth = enccfg->g_input_bit_depth =\n\n                avctx->pix_fmt == AV_PIX_FMT_YUV420P10 ? 10 : 12;\n\n            enccfg->g_profile = 2;\n\n            *img_fmt = VPX_IMG_FMT_I42016;\n\n            *flags |= VPX_CODEC_USE_HIGHBITDEPTH;\n\n            return 0;\n\n        }\n\n        break;\n\n    case AV_PIX_FMT_YUV422P10:\n\n    case AV_PIX_FMT_YUV422P12:\n\n        if (codec_caps & VPX_CODEC_CAP_HIGHBITDEPTH) {\n\n            enccfg->g_bit_depth = enccfg->g_input_bit_depth =\n\n                avctx->pix_fmt == AV_PIX_FMT_YUV422P10 ? 10 : 12;\n\n            enccfg->g_profile = 3;\n\n            *img_fmt = VPX_IMG_FMT_I42216;\n\n            *flags |= VPX_CODEC_USE_HIGHBITDEPTH;\n\n            return 0;\n\n        }\n\n        break;\n\n#if VPX_IMAGE_ABI_VERSION >= 3\n\n    case AV_PIX_FMT_YUV440P10:\n\n    case AV_PIX_FMT_YUV440P12:\n\n        if (codec_caps & VPX_CODEC_CAP_HIGHBITDEPTH) {\n\n            enccfg->g_bit_depth = enccfg->g_input_bit_depth =\n\n                avctx->pix_fmt == AV_PIX_FMT_YUV440P10 ? 10 : 12;\n\n            enccfg->g_profile = 3;\n\n            *img_fmt = VPX_IMG_FMT_I44016;\n\n            *flags |= VPX_CODEC_USE_HIGHBITDEPTH;\n\n            return 0;\n\n        }\n\n        break;\n\n    case AV_PIX_FMT_GBRP10:\n\n    case AV_PIX_FMT_GBRP12:\n\n        ctx->vpx_cs = VPX_CS_SRGB;\n\n#endif\n\n    case AV_PIX_FMT_YUV444P10:\n\n    case AV_PIX_FMT_YUV444P12:\n\n        if (codec_caps & VPX_CODEC_CAP_HIGHBITDEPTH) {\n\n            enccfg->g_bit_depth = enccfg->g_input_bit_depth =\n\n                avctx->pix_fmt == AV_PIX_FMT_YUV444P10 ||\n\n                avctx->pix_fmt == AV_PIX_FMT_GBRP10 ? 10 : 12;\n\n            enccfg->g_profile = 3;\n\n            *img_fmt = VPX_IMG_FMT_I44416;\n\n            *flags |= VPX_CODEC_USE_HIGHBITDEPTH;\n\n            return 0;\n\n        }\n\n        break;\n\n#endif\n\n    default:\n\n        break;\n\n    }\n\n    av_log(avctx, AV_LOG_ERROR, \"Unsupported pixel format.\\n\");\n\n    return AVERROR_INVALIDDATA;\n\n}\n", "idx": 23526}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(rgb24to16)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n    const uint8_t *s = src;\n\n    const uint8_t *end;\n\n#if COMPILE_TEMPLATE_MMX\n\n    const uint8_t *mm_end;\n\n#endif\n\n    uint16_t *d = (uint16_t *)dst;\n\n    end = s + src_size;\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*src):\"memory\");\n\n    __asm__ volatile(\n\n        \"movq         %0, %%mm7     \\n\\t\"\n\n        \"movq         %1, %%mm6     \\n\\t\"\n\n        ::\"m\"(red_16mask),\"m\"(green_16mask));\n\n    mm_end = end - 15;\n\n    while (s < mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"    32%1           \\n\\t\"\n\n            \"movd          %1, %%mm0    \\n\\t\"\n\n            \"movd         3%1, %%mm3    \\n\\t\"\n\n            \"punpckldq    6%1, %%mm0    \\n\\t\"\n\n            \"punpckldq    9%1, %%mm3    \\n\\t\"\n\n            \"movq       %%mm0, %%mm1    \\n\\t\"\n\n            \"movq       %%mm0, %%mm2    \\n\\t\"\n\n            \"movq       %%mm3, %%mm4    \\n\\t\"\n\n            \"movq       %%mm3, %%mm5    \\n\\t\"\n\n            \"psllq         $8, %%mm0    \\n\\t\"\n\n            \"psllq         $8, %%mm3    \\n\\t\"\n\n            \"pand       %%mm7, %%mm0    \\n\\t\"\n\n            \"pand       %%mm7, %%mm3    \\n\\t\"\n\n            \"psrlq         $5, %%mm1    \\n\\t\"\n\n            \"psrlq         $5, %%mm4    \\n\\t\"\n\n            \"pand       %%mm6, %%mm1    \\n\\t\"\n\n            \"pand       %%mm6, %%mm4    \\n\\t\"\n\n            \"psrlq        $19, %%mm2    \\n\\t\"\n\n            \"psrlq        $19, %%mm5    \\n\\t\"\n\n            \"pand          %2, %%mm2    \\n\\t\"\n\n            \"pand          %2, %%mm5    \\n\\t\"\n\n            \"por        %%mm1, %%mm0    \\n\\t\"\n\n            \"por        %%mm4, %%mm3    \\n\\t\"\n\n            \"por        %%mm2, %%mm0    \\n\\t\"\n\n            \"por        %%mm5, %%mm3    \\n\\t\"\n\n            \"psllq        $16, %%mm3    \\n\\t\"\n\n            \"por        %%mm3, %%mm0    \\n\\t\"\n\n            MOVNTQ\"     %%mm0, %0       \\n\\t\"\n\n            :\"=m\"(*d):\"m\"(*s),\"m\"(blue_16mask):\"memory\");\n\n        d += 4;\n\n        s += 12;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n#endif\n\n    while (s < end) {\n\n        const int r = *s++;\n\n        const int g = *s++;\n\n        const int b = *s++;\n\n        *d++ = (b>>3) | ((g&0xFC)<<3) | ((r&0xF8)<<8);\n\n    }\n\n}\n", "idx": 23537}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(yuv2packed2)(SwsContext *c, const uint16_t *buf0, const uint16_t *buf1, const uint16_t *uvbuf0, const uint16_t *uvbuf1,\n\n                          const uint16_t *abuf0, const uint16_t *abuf1, uint8_t *dest, int dstW, int yalpha, int uvalpha, int y)\n\n{\n\n    int  yalpha1=4095- yalpha;\n\n    int uvalpha1=4095-uvalpha;\n\n    int i;\n\n\n\n#if COMPILE_TEMPLATE_MMX\n\n    if(!(c->flags & SWS_BITEXACT)) {\n\n        switch(c->dstFormat) {\n\n        //Note 8280 == DSTW_OFFSET but the preprocessor can't handle that there :(\n\n        case PIX_FMT_RGB32:\n\n            if (CONFIG_SWSCALE_ALPHA && c->alpPixBuf) {\n\n#if ARCH_X86_64\n\n                __asm__ volatile(\n\n                    YSCALEYUV2RGB(%%r8, %5)\n\n                    YSCALEYUV2RGB_YA(%%r8, %5, %6, %7)\n\n                    \"psraw                  $3, %%mm1       \\n\\t\" /* abuf0[eax] - abuf1[eax] >>7*/\n\n                    \"psraw                  $3, %%mm7       \\n\\t\" /* abuf0[eax] - abuf1[eax] >>7*/\n\n                    \"packuswb            %%mm7, %%mm1       \\n\\t\"\n\n                    WRITEBGR32(%4, 8280(%5), %%r8, %%mm2, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm3, %%mm6)\n\n\n\n                    :: \"c\" (buf0), \"d\" (buf1), \"S\" (uvbuf0), \"D\" (uvbuf1), \"r\" (dest),\n\n                    \"a\" (&c->redDither)\n\n                    ,\"r\" (abuf0), \"r\" (abuf1)\n\n                    : \"%r8\"\n\n                );\n\n#else\n\n                c->u_temp=(intptr_t)abuf0;\n\n                c->v_temp=(intptr_t)abuf1;\n\n                __asm__ volatile(\n\n                    \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n                    \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n                    \"push %%\"REG_BP\"                        \\n\\t\"\n\n                    YSCALEYUV2RGB(%%REGBP, %5)\n\n                    \"push                   %0              \\n\\t\"\n\n                    \"push                   %1              \\n\\t\"\n\n                    \"mov          \"U_TEMP\"(%5), %0          \\n\\t\"\n\n                    \"mov          \"V_TEMP\"(%5), %1          \\n\\t\"\n\n                    YSCALEYUV2RGB_YA(%%REGBP, %5, %0, %1)\n\n                    \"psraw                  $3, %%mm1       \\n\\t\" /* abuf0[eax] - abuf1[eax] >>7*/\n\n                    \"psraw                  $3, %%mm7       \\n\\t\" /* abuf0[eax] - abuf1[eax] >>7*/\n\n                    \"packuswb            %%mm7, %%mm1       \\n\\t\"\n\n                    \"pop                    %1              \\n\\t\"\n\n                    \"pop                    %0              \\n\\t\"\n\n                    WRITEBGR32(%%REGb, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm3, %%mm6)\n\n                    \"pop %%\"REG_BP\"                         \\n\\t\"\n\n                    \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n\n\n                    :: \"c\" (buf0), \"d\" (buf1), \"S\" (uvbuf0), \"D\" (uvbuf1), \"m\" (dest),\n\n                    \"a\" (&c->redDither)\n\n                );\n\n#endif\n\n            } else {\n\n                __asm__ volatile(\n\n                    \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n                    \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n                    \"push %%\"REG_BP\"                        \\n\\t\"\n\n                    YSCALEYUV2RGB(%%REGBP, %5)\n\n                    \"pcmpeqd %%mm7, %%mm7                   \\n\\t\"\n\n                    WRITEBGR32(%%REGb, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)\n\n                    \"pop %%\"REG_BP\"                         \\n\\t\"\n\n                    \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n\n\n                    :: \"c\" (buf0), \"d\" (buf1), \"S\" (uvbuf0), \"D\" (uvbuf1), \"m\" (dest),\n\n                    \"a\" (&c->redDither)\n\n                );\n\n            }\n\n            return;\n\n        case PIX_FMT_BGR24:\n\n            __asm__ volatile(\n\n                \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n                \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n                \"push %%\"REG_BP\"                        \\n\\t\"\n\n                YSCALEYUV2RGB(%%REGBP, %5)\n\n                \"pxor    %%mm7, %%mm7                   \\n\\t\"\n\n                WRITEBGR24(%%REGb, 8280(%5), %%REGBP)\n\n                \"pop %%\"REG_BP\"                         \\n\\t\"\n\n                \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n                :: \"c\" (buf0), \"d\" (buf1), \"S\" (uvbuf0), \"D\" (uvbuf1), \"m\" (dest),\n\n                \"a\" (&c->redDither)\n\n            );\n\n            return;\n\n        case PIX_FMT_RGB555:\n\n            __asm__ volatile(\n\n                \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n                \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n                \"push %%\"REG_BP\"                        \\n\\t\"\n\n                YSCALEYUV2RGB(%%REGBP, %5)\n\n                \"pxor    %%mm7, %%mm7                   \\n\\t\"\n\n                /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n                \"paddusb \"BLUE_DITHER\"(%5), %%mm2      \\n\\t\"\n\n                \"paddusb \"GREEN_DITHER\"(%5), %%mm4      \\n\\t\"\n\n                \"paddusb \"RED_DITHER\"(%5), %%mm5      \\n\\t\"\n\n#endif\n\n\n\n                WRITERGB15(%%REGb, 8280(%5), %%REGBP)\n\n                \"pop %%\"REG_BP\"                         \\n\\t\"\n\n                \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n\n\n                :: \"c\" (buf0), \"d\" (buf1), \"S\" (uvbuf0), \"D\" (uvbuf1), \"m\" (dest),\n\n                \"a\" (&c->redDither)\n\n            );\n\n            return;\n\n        case PIX_FMT_RGB565:\n\n            __asm__ volatile(\n\n                \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n                \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n                \"push %%\"REG_BP\"                        \\n\\t\"\n\n                YSCALEYUV2RGB(%%REGBP, %5)\n\n                \"pxor    %%mm7, %%mm7                   \\n\\t\"\n\n                /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n                \"paddusb \"BLUE_DITHER\"(%5), %%mm2      \\n\\t\"\n\n                \"paddusb \"GREEN_DITHER\"(%5), %%mm4      \\n\\t\"\n\n                \"paddusb \"RED_DITHER\"(%5), %%mm5      \\n\\t\"\n\n#endif\n\n\n\n                WRITERGB16(%%REGb, 8280(%5), %%REGBP)\n\n                \"pop %%\"REG_BP\"                         \\n\\t\"\n\n                \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n                :: \"c\" (buf0), \"d\" (buf1), \"S\" (uvbuf0), \"D\" (uvbuf1), \"m\" (dest),\n\n                \"a\" (&c->redDither)\n\n            );\n\n            return;\n\n        case PIX_FMT_YUYV422:\n\n            __asm__ volatile(\n\n                \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n                \"mov %4, %%\"REG_b\"                        \\n\\t\"\n\n                \"push %%\"REG_BP\"                        \\n\\t\"\n\n                YSCALEYUV2PACKED(%%REGBP, %5)\n\n                WRITEYUY2(%%REGb, 8280(%5), %%REGBP)\n\n                \"pop %%\"REG_BP\"                         \\n\\t\"\n\n                \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n                :: \"c\" (buf0), \"d\" (buf1), \"S\" (uvbuf0), \"D\" (uvbuf1), \"m\" (dest),\n\n                \"a\" (&c->redDither)\n\n            );\n\n            return;\n\n        default: break;\n\n        }\n\n    }\n\n#endif //COMPILE_TEMPLATE_MMX\n\n    YSCALE_YUV_2_ANYRGB_C(YSCALE_YUV_2_RGB2_C, YSCALE_YUV_2_PACKED2_C(void,0), YSCALE_YUV_2_GRAY16_2_C, YSCALE_YUV_2_MONO2_C)\n\n}\n", "idx": 23548}
{"project": "FFmpeg", "commit_id": "e45a2872fafe631c14aee9f79d0963d68c4fc1fd", "target": 0, "func": "void put_no_rnd_pixels16_xy2_altivec(uint8_t * block, const uint8_t * pixels, int line_size, int h)\n\n{\n\nPOWERPC_TBL_DECLARE(altivec_put_no_rnd_pixels16_xy2_num, 1);\n\n#ifdef ALTIVEC_USE_REFERENCE_C_CODE\n\n    int j;\n\nPOWERPC_TBL_START_COUNT(altivec_put_no_rnd_pixels16_xy2_num, 1);\n\n      for (j = 0; j < 4; j++) {\n\n      int i;\n\n      const uint32_t a = (((const struct unaligned_32 *) (pixels))->l);\n\n      const uint32_t b =\n\n        (((const struct unaligned_32 *) (pixels + 1))->l);\n\n      uint32_t l0 =\n\n        (a & 0x03030303UL) + (b & 0x03030303UL) + 0x01010101UL;\n\n      uint32_t h0 =\n\n        ((a & 0xFCFCFCFCUL) >> 2) + ((b & 0xFCFCFCFCUL) >> 2);\n\n      uint32_t l1, h1;\n\n      pixels += line_size;\n\n      for (i = 0; i < h; i += 2) {\n\n        uint32_t a = (((const struct unaligned_32 *) (pixels))->l);\n\n        uint32_t b = (((const struct unaligned_32 *) (pixels + 1))->l);\n\n        l1 = (a & 0x03030303UL) + (b & 0x03030303UL);\n\n        h1 = ((a & 0xFCFCFCFCUL) >> 2) + ((b & 0xFCFCFCFCUL) >> 2);\n\n        *((uint32_t *) block) =\n\n          h0 + h1 + (((l0 + l1) >> 2) & 0x0F0F0F0FUL);\n\n        pixels += line_size;\n\n        block += line_size;\n\n        a = (((const struct unaligned_32 *) (pixels))->l);\n\n        b = (((const struct unaligned_32 *) (pixels + 1))->l);\n\n        l0 = (a & 0x03030303UL) + (b & 0x03030303UL) + 0x01010101UL;\n\n        h0 = ((a & 0xFCFCFCFCUL) >> 2) + ((b & 0xFCFCFCFCUL) >> 2);\n\n        *((uint32_t *) block) =\n\n          h0 + h1 + (((l0 + l1) >> 2) & 0x0F0F0F0FUL);\n\n        pixels += line_size;\n\n        block += line_size;\n\n      } pixels += 4 - line_size * (h + 1);\n\n      block += 4 - line_size * h;\n\n    }\n\n\n\nPOWERPC_TBL_STOP_COUNT(altivec_put_no_rnd_pixels16_xy2_num, 1);\n\n\n\n#else /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n   register int i;\n\n   register vector unsigned char\n\n     pixelsv1, pixelsv2, pixelsv3, pixelsv4;\n\n   register vector unsigned char\n\n     blockv, temp1, temp2;\n\n   register vector unsigned short\n\n     pixelssum1, pixelssum2, temp3,\n\n     pixelssum3, pixelssum4, temp4;\n\n   register const vector unsigned char vczero = (const vector unsigned char)vec_splat_u8(0);\n\n   register const vector unsigned short vcone = (const vector unsigned short)vec_splat_u16(1);\n\n   register const vector unsigned short vctwo = (const vector unsigned short)vec_splat_u16(2);\n\n\n\nPOWERPC_TBL_START_COUNT(altivec_put_no_rnd_pixels16_xy2_num, 1);\n\n \n\n   temp1 = vec_ld(0, pixels);\n\n   temp2 = vec_ld(16, pixels);\n\n   pixelsv1 = vec_perm(temp1, temp2, vec_lvsl(0, pixels));\n\n   if ((((unsigned long)pixels) & 0x0000000F) ==  0x0000000F)\n\n   {\n\n     pixelsv2 = temp2;\n\n   }\n\n   else\n\n   {\n\n     pixelsv2 = vec_perm(temp1, temp2, vec_lvsl(1, pixels));\n\n   }\n\n   pixelsv3 = vec_mergel(vczero, pixelsv1);\n\n   pixelsv4 = vec_mergel(vczero, pixelsv2);\n\n   pixelsv1 = vec_mergeh(vczero, pixelsv1);\n\n   pixelsv2 = vec_mergeh(vczero, pixelsv2);\n\n   pixelssum3 = vec_add((vector unsigned short)pixelsv3,\n\n                        (vector unsigned short)pixelsv4);\n\n   pixelssum3 = vec_add(pixelssum3, vcone);\n\n   pixelssum1 = vec_add((vector unsigned short)pixelsv1,\n\n                        (vector unsigned short)pixelsv2);\n\n   pixelssum1 = vec_add(pixelssum1, vcone);\n\n   \n\n   for (i = 0; i < h ; i++) {\n\n     blockv = vec_ld(0, block);\n\n\n\n     temp1 = vec_ld(line_size, pixels);\n\n     temp2 = vec_ld(line_size + 16, pixels);\n\n     pixelsv1 = vec_perm(temp1, temp2, vec_lvsl(line_size, pixels));\n\n     if (((((unsigned long)pixels) + line_size) & 0x0000000F) ==  0x0000000F)\n\n     {\n\n       pixelsv2 = temp2;\n\n     }\n\n     else\n\n     {\n\n       pixelsv2 = vec_perm(temp1, temp2, vec_lvsl(line_size + 1, pixels));\n\n     }\n\n\n\n     pixelsv3 = vec_mergel(vczero, pixelsv1);\n\n     pixelsv4 = vec_mergel(vczero, pixelsv2);\n\n     pixelsv1 = vec_mergeh(vczero, pixelsv1);\n\n     pixelsv2 = vec_mergeh(vczero, pixelsv2);\n\n     \n\n     pixelssum4 = vec_add((vector unsigned short)pixelsv3,\n\n                          (vector unsigned short)pixelsv4);\n\n     pixelssum2 = vec_add((vector unsigned short)pixelsv1,\n\n                          (vector unsigned short)pixelsv2);\n\n     temp4 = vec_add(pixelssum3, pixelssum4);\n\n     temp4 = vec_sra(temp4, vctwo);\n\n     temp3 = vec_add(pixelssum1, pixelssum2);\n\n     temp3 = vec_sra(temp3, vctwo);\n\n\n\n     pixelssum3 = vec_add(pixelssum4, vcone);\n\n     pixelssum1 = vec_add(pixelssum2, vcone);\n\n\n\n     blockv = vec_packsu(temp3, temp4);\n\n     \n\n     vec_st(blockv, 0, block);\n\n     \n\n     block += line_size;\n\n     pixels += line_size;\n\n   }\n\n   \n\nPOWERPC_TBL_STOP_COUNT(altivec_put_no_rnd_pixels16_xy2_num, 1);\n\n#endif /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n}\n", "idx": 23556}
{"project": "FFmpeg", "commit_id": "3547f8e8f8418af0c578eba0de62ecba08e460c2", "target": 0, "func": "static inline void rv34_mc(RV34DecContext *r, const int block_type,\n\n                          const int xoff, const int yoff, int mv_off,\n\n                          const int width, const int height, int dir,\n\n                          const int thirdpel, int weighted,\n\n                          qpel_mc_func (*qpel_mc)[16],\n\n                          h264_chroma_mc_func (*chroma_mc))\n\n{\n\n    MpegEncContext *s = &r->s;\n\n    uint8_t *Y, *U, *V, *srcY, *srcU, *srcV;\n\n    int dxy, mx, my, umx, umy, lx, ly, uvmx, uvmy, src_x, src_y, uvsrc_x, uvsrc_y;\n\n    int mv_pos = s->mb_x * 2 + s->mb_y * 2 * s->b8_stride + mv_off;\n\n    int is16x16 = 1;\n\n\n\n    if(thirdpel){\n\n        int chroma_mx, chroma_my;\n\n        mx = (s->current_picture_ptr->f.motion_val[dir][mv_pos][0] + (3 << 24)) / 3 - (1 << 24);\n\n        my = (s->current_picture_ptr->f.motion_val[dir][mv_pos][1] + (3 << 24)) / 3 - (1 << 24);\n\n        lx = (s->current_picture_ptr->f.motion_val[dir][mv_pos][0] + (3 << 24)) % 3;\n\n        ly = (s->current_picture_ptr->f.motion_val[dir][mv_pos][1] + (3 << 24)) % 3;\n\n        chroma_mx = s->current_picture_ptr->f.motion_val[dir][mv_pos][0] / 2;\n\n        chroma_my = s->current_picture_ptr->f.motion_val[dir][mv_pos][1] / 2;\n\n        umx = (chroma_mx + (3 << 24)) / 3 - (1 << 24);\n\n        umy = (chroma_my + (3 << 24)) / 3 - (1 << 24);\n\n        uvmx = chroma_coeffs[(chroma_mx + (3 << 24)) % 3];\n\n        uvmy = chroma_coeffs[(chroma_my + (3 << 24)) % 3];\n\n    }else{\n\n        int cx, cy;\n\n        mx = s->current_picture_ptr->f.motion_val[dir][mv_pos][0] >> 2;\n\n        my = s->current_picture_ptr->f.motion_val[dir][mv_pos][1] >> 2;\n\n        lx = s->current_picture_ptr->f.motion_val[dir][mv_pos][0] & 3;\n\n        ly = s->current_picture_ptr->f.motion_val[dir][mv_pos][1] & 3;\n\n        cx = s->current_picture_ptr->f.motion_val[dir][mv_pos][0] / 2;\n\n        cy = s->current_picture_ptr->f.motion_val[dir][mv_pos][1] / 2;\n\n        umx = cx >> 2;\n\n        umy = cy >> 2;\n\n        uvmx = (cx & 3) << 1;\n\n        uvmy = (cy & 3) << 1;\n\n        //due to some flaw RV40 uses the same MC compensation routine for H2V2 and H3V3\n\n        if(uvmx == 6 && uvmy == 6)\n\n            uvmx = uvmy = 4;\n\n    }\n\n\n\n    if (HAVE_THREADS && (s->avctx->active_thread_type & FF_THREAD_FRAME)) {\n\n        /* wait for the referenced mb row to be finished */\n\n        int mb_row = FFMIN(s->mb_height - 1, s->mb_y + ((yoff + my + 21) >> 4));\n\n        AVFrame *f = dir ? &s->next_picture_ptr->f : &s->last_picture_ptr->f;\n\n        ff_thread_await_progress(f, mb_row, 0);\n\n    }\n\n\n\n    dxy = ly*4 + lx;\n\n    srcY = dir ? s->next_picture_ptr->f.data[0] : s->last_picture_ptr->f.data[0];\n\n    srcU = dir ? s->next_picture_ptr->f.data[1] : s->last_picture_ptr->f.data[1];\n\n    srcV = dir ? s->next_picture_ptr->f.data[2] : s->last_picture_ptr->f.data[2];\n\n    src_x = s->mb_x * 16 + xoff + mx;\n\n    src_y = s->mb_y * 16 + yoff + my;\n\n    uvsrc_x = s->mb_x * 8 + (xoff >> 1) + umx;\n\n    uvsrc_y = s->mb_y * 8 + (yoff >> 1) + umy;\n\n    srcY += src_y * s->linesize + src_x;\n\n    srcU += uvsrc_y * s->uvlinesize + uvsrc_x;\n\n    srcV += uvsrc_y * s->uvlinesize + uvsrc_x;\n\n    if(s->h_edge_pos - (width << 3) < 6 || s->v_edge_pos - (height << 3) < 6 ||\n\n       (unsigned)(src_x - !!lx*2) > s->h_edge_pos - !!lx*2 - (width <<3) - 4 ||\n\n       (unsigned)(src_y - !!ly*2) > s->v_edge_pos - !!ly*2 - (height<<3) - 4) {\n\n        uint8_t *uvbuf = s->edge_emu_buffer + 22 * s->linesize;\n\n\n\n        srcY -= 2 + 2*s->linesize;\n\n        s->dsp.emulated_edge_mc(s->edge_emu_buffer, srcY, s->linesize, (width<<3)+6, (height<<3)+6,\n\n                            src_x - 2, src_y - 2, s->h_edge_pos, s->v_edge_pos);\n\n        srcY = s->edge_emu_buffer + 2 + 2*s->linesize;\n\n        s->dsp.emulated_edge_mc(uvbuf     , srcU, s->uvlinesize, (width<<2)+1, (height<<2)+1,\n\n                            uvsrc_x, uvsrc_y, s->h_edge_pos >> 1, s->v_edge_pos >> 1);\n\n        s->dsp.emulated_edge_mc(uvbuf + 16, srcV, s->uvlinesize, (width<<2)+1, (height<<2)+1,\n\n                            uvsrc_x, uvsrc_y, s->h_edge_pos >> 1, s->v_edge_pos >> 1);\n\n        srcU = uvbuf;\n\n        srcV = uvbuf + 16;\n\n    }\n\n    if(!weighted){\n\n        Y = s->dest[0] + xoff      + yoff     *s->linesize;\n\n        U = s->dest[1] + (xoff>>1) + (yoff>>1)*s->uvlinesize;\n\n        V = s->dest[2] + (xoff>>1) + (yoff>>1)*s->uvlinesize;\n\n    }else{\n\n        Y = r->tmp_b_block_y [dir]     +  xoff     +  yoff    *s->linesize;\n\n        U = r->tmp_b_block_uv[dir*2]   + (xoff>>1) + (yoff>>1)*s->uvlinesize;\n\n        V = r->tmp_b_block_uv[dir*2+1] + (xoff>>1) + (yoff>>1)*s->uvlinesize;\n\n    }\n\n\n\n    if(block_type == RV34_MB_P_16x8){\n\n        qpel_mc[1][dxy](Y, srcY, s->linesize);\n\n        Y    += 8;\n\n        srcY += 8;\n\n    }else if(block_type == RV34_MB_P_8x16){\n\n        qpel_mc[1][dxy](Y, srcY, s->linesize);\n\n        Y    += 8 * s->linesize;\n\n        srcY += 8 * s->linesize;\n\n    }\n\n    is16x16 = (block_type != RV34_MB_P_8x8) && (block_type != RV34_MB_P_16x8) && (block_type != RV34_MB_P_8x16);\n\n    qpel_mc[!is16x16][dxy](Y, srcY, s->linesize);\n\n    chroma_mc[2-width]   (U, srcU, s->uvlinesize, height*4, uvmx, uvmy);\n\n    chroma_mc[2-width]   (V, srcV, s->uvlinesize, height*4, uvmx, uvmy);\n\n}\n", "idx": 23557}
{"project": "FFmpeg", "commit_id": "ff35c7cdfac3a4affa9e98a806281da99f66787f", "target": 0, "func": "static int ftp_retrieve(FTPContext *s)\n\n{\n\n    char command[CONTROL_BUFFER_SIZE];\n\n    const int retr_codes[] = {150, 550, 0}; /* 550 is incorrect code */\n\n\n\n    snprintf(command, sizeof(command), \"RETR %s\\r\\n\", s->path);\n\n    if (ftp_send_command(s, command, retr_codes, NULL) != 150)\n\n        return AVERROR(EIO);\n\n\n\n    s->state = DOWNLOADING;\n\n\n\n    return 0;\n\n}\n", "idx": 23558}
{"project": "FFmpeg", "commit_id": "e45a2872fafe631c14aee9f79d0963d68c4fc1fd", "target": 0, "func": "void dct_unquantize_h263_altivec(MpegEncContext *s, \n\n                                 DCTELEM *block, int n, int qscale)\n\n{\n\nPOWERPC_TBL_DECLARE(altivec_dct_unquantize_h263_num, 1);\n\n    int i, level, qmul, qadd;\n\n    int nCoeffs;\n\n    \n\n    assert(s->block_last_index[n]>=0);\n\n\n\nPOWERPC_TBL_START_COUNT(altivec_dct_unquantize_h263_num, 1);\n\n    \n\n    qadd = (qscale - 1) | 1;\n\n    qmul = qscale << 1;\n\n    \n\n    if (s->mb_intra) {\n\n        if (!s->h263_aic) {\n\n            if (n < 4) \n\n                block[0] = block[0] * s->y_dc_scale;\n\n            else\n\n                block[0] = block[0] * s->c_dc_scale;\n\n        }else\n\n            qadd = 0;\n\n        i = 1;\n\n        nCoeffs= 63; //does not allways use zigzag table \n\n    } else {\n\n        i = 0;\n\n        nCoeffs= s->intra_scantable.raster_end[ s->block_last_index[n] ];\n\n    }\n\n\n\n#ifdef ALTIVEC_USE_REFERENCE_C_CODE\n\n    for(;i<=nCoeffs;i++) {\n\n        level = block[i];\n\n        if (level) {\n\n            if (level < 0) {\n\n                level = level * qmul - qadd;\n\n            } else {\n\n                level = level * qmul + qadd;\n\n            }\n\n            block[i] = level;\n\n        }\n\n    }\n\n#else /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n    {\n\n      register const vector short vczero = (const vector short)vec_splat_s16(0);\n\n      short __attribute__ ((aligned(16))) qmul8[] =\n\n          {\n\n            qmul, qmul, qmul, qmul,\n\n            qmul, qmul, qmul, qmul\n\n          };\n\n      short __attribute__ ((aligned(16))) qadd8[] =\n\n          {\n\n            qadd, qadd, qadd, qadd,\n\n            qadd, qadd, qadd, qadd\n\n          };\n\n      short __attribute__ ((aligned(16))) nqadd8[] =\n\n          {\n\n            -qadd, -qadd, -qadd, -qadd,\n\n            -qadd, -qadd, -qadd, -qadd\n\n          };\n\n      register vector short blockv, qmulv, qaddv, nqaddv, temp1;\n\n      register vector bool short blockv_null, blockv_neg;\n\n      register short backup_0 = block[0];\n\n      register int j = 0;\n\n      \n\n      qmulv = vec_ld(0, qmul8);\n\n      qaddv = vec_ld(0, qadd8);\n\n      nqaddv = vec_ld(0, nqadd8);\n\n\n\n#if 0 // block *is* 16 bytes-aligned, it seems.\n\n      // first make sure block[j] is 16 bytes-aligned\n\n      for(j = 0; (j <= nCoeffs) && ((((unsigned long)block) + (j << 1)) & 0x0000000F) ; j++) {\n\n        level = block[j];\n\n        if (level) {\n\n          if (level < 0) {\n\n                level = level * qmul - qadd;\n\n            } else {\n\n                level = level * qmul + qadd;\n\n            }\n\n            block[j] = level;\n\n        }\n\n      }\n\n#endif\n\n      \n\n      // vectorize all the 16 bytes-aligned blocks\n\n      // of 8 elements\n\n      for(; (j + 7) <= nCoeffs ; j+=8)\n\n      {\n\n        blockv = vec_ld(j << 1, block);\n\n        blockv_neg = vec_cmplt(blockv, vczero);\n\n        blockv_null = vec_cmpeq(blockv, vczero);\n\n        // choose between +qadd or -qadd as the third operand\n\n        temp1 = vec_sel(qaddv, nqaddv, blockv_neg);\n\n        // multiply & add (block{i,i+7} * qmul [+-] qadd)\n\n        temp1 = vec_mladd(blockv, qmulv, temp1);\n\n        // put 0 where block[{i,i+7} used to have 0\n\n        blockv = vec_sel(temp1, blockv, blockv_null);\n\n        vec_st(blockv, j << 1, block);\n\n      }\n\n\n\n      // if nCoeffs isn't a multiple of 8, finish the job\n\n      // using good old scalar units.\n\n      // (we could do it using a truncated vector,\n\n      // but I'm not sure it's worth the hassle)\n\n      for(; j <= nCoeffs ; j++) {\n\n        level = block[j];\n\n        if (level) {\n\n          if (level < 0) {\n\n                level = level * qmul - qadd;\n\n            } else {\n\n                level = level * qmul + qadd;\n\n            }\n\n            block[j] = level;\n\n        }\n\n      }\n\n      \n\n      if (i == 1)\n\n      { // cheat. this avoid special-casing the first iteration\n\n        block[0] = backup_0;\n\n      }\n\n    }\n\n#endif /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n\n\nPOWERPC_TBL_STOP_COUNT(altivec_dct_unquantize_h263_num, nCoeffs == 63);\n\n}\n", "idx": 23559}
{"project": "FFmpeg", "commit_id": "70143a3954e1c4412efb2bf1a3a818adea2d3abf", "target": 0, "func": "static int dxva2_get_buffer(AVCodecContext *s, AVFrame *frame, int flags)\n\n{\n\n    InputStream  *ist = s->opaque;\n\n    DXVA2Context *ctx = ist->hwaccel_ctx;\n\n\n\n    return av_hwframe_get_buffer(ctx->hw_frames_ctx, frame, 0);\n\n}\n", "idx": 23560}
{"project": "FFmpeg", "commit_id": "e0c6cce44729d94e2a5507a4b6d031f23e8bd7b6", "target": 0, "func": "DECL_IMDCT_BLOCKS(sse,sse)\n\nDECL_IMDCT_BLOCKS(sse2,sse)\n\nDECL_IMDCT_BLOCKS(sse3,sse)\n\nDECL_IMDCT_BLOCKS(ssse3,sse)\n\nDECL_IMDCT_BLOCKS(avx,avx)\n\n#endif /* HAVE_YASM */\n\n\n\nvoid ff_mpadsp_init_mmx(MPADSPContext *s)\n\n{\n\n    int mm_flags = av_get_cpu_flags();\n\n\n\n    int i, j;\n\n    for (j = 0; j < 4; j++) {\n\n        for (i = 0; i < 40; i ++) {\n\n            mdct_win_sse[0][j][4*i    ] = ff_mdct_win_float[j    ][i];\n\n            mdct_win_sse[0][j][4*i + 1] = ff_mdct_win_float[j + 4][i];\n\n            mdct_win_sse[0][j][4*i + 2] = ff_mdct_win_float[j    ][i];\n\n            mdct_win_sse[0][j][4*i + 3] = ff_mdct_win_float[j + 4][i];\n\n            mdct_win_sse[1][j][4*i    ] = ff_mdct_win_float[0    ][i];\n\n            mdct_win_sse[1][j][4*i + 1] = ff_mdct_win_float[4    ][i];\n\n            mdct_win_sse[1][j][4*i + 2] = ff_mdct_win_float[j    ][i];\n\n            mdct_win_sse[1][j][4*i + 3] = ff_mdct_win_float[j + 4][i];\n\n        }\n\n    }\n\n\n\n#if HAVE_SSE2_INLINE\n\n    if (mm_flags & AV_CPU_FLAG_SSE2) {\n\n        s->apply_window_float = apply_window_mp3;\n\n    }\n\n#endif /* HAVE_SSE2_INLINE */\n\n\n\n#if HAVE_YASM\n\n    if (mm_flags & AV_CPU_FLAG_AVX && HAVE_AVX) {\n\n        s->imdct36_blocks_float = imdct36_blocks_avx;\n\n#if HAVE_SSE\n\n    } else if (mm_flags & AV_CPU_FLAG_SSSE3) {\n\n        s->imdct36_blocks_float = imdct36_blocks_ssse3;\n\n    } else if (mm_flags & AV_CPU_FLAG_SSE3) {\n\n        s->imdct36_blocks_float = imdct36_blocks_sse3;\n\n    } else if (mm_flags & AV_CPU_FLAG_SSE2) {\n\n        s->imdct36_blocks_float = imdct36_blocks_sse2;\n\n    } else if (mm_flags & AV_CPU_FLAG_SSE) {\n\n        s->imdct36_blocks_float = imdct36_blocks_sse;\n\n#endif /* HAVE_SSE */\n\n    }\n\n#endif /* HAVE_YASM */\n\n}\n", "idx": 23561}
{"project": "FFmpeg", "commit_id": "57877f2b449f265ae1dd070b46aaadff4f0b3e34", "target": 0, "func": "static inline int sub_left_prediction(HYuvContext *s, uint8_t *dst,\n\n                                      const uint8_t *src, int w, int left)\n\n{\n\n    int i;\n\n    if (s->bps <= 8) {\n\n        if (w < 32) {\n\n            for (i = 0; i < w; i++) {\n\n                const int temp = src[i];\n\n                dst[i] = temp - left;\n\n                left   = temp;\n\n            }\n\n            return left;\n\n        } else {\n\n            for (i = 0; i < 32; i++) {\n\n                const int temp = src[i];\n\n                dst[i] = temp - left;\n\n                left   = temp;\n\n            }\n\n            s->llvidencdsp.diff_bytes(dst + 32, src + 32, src + 31, w - 32);\n\n            return src[w-1];\n\n        }\n\n    } else {\n\n        const uint16_t *src16 = (const uint16_t *)src;\n\n        uint16_t       *dst16 = (      uint16_t *)dst;\n\n        if (w < 32) {\n\n            for (i = 0; i < w; i++) {\n\n                const int temp = src16[i];\n\n                dst16[i] = temp - left;\n\n                left   = temp;\n\n            }\n\n            return left;\n\n        } else {\n\n            for (i = 0; i < 16; i++) {\n\n                const int temp = src16[i];\n\n                dst16[i] = temp - left;\n\n                left   = temp;\n\n            }\n\n            s->hencdsp.diff_int16(dst16 + 16, src16 + 16, src16 + 15, s->n - 1, w - 16);\n\n            return src16[w-1];\n\n        }\n\n    }\n\n}\n", "idx": 23562}
{"project": "FFmpeg", "commit_id": "0c5f839693da2276c2da23400f67a67be4ea0af1", "target": 1, "func": "int ffurl_register_protocol(URLProtocol *protocol, int size)\n\n{\n\n    URLProtocol **p;\n\n    if (size < sizeof(URLProtocol)) {\n\n        URLProtocol *temp = av_mallocz(sizeof(URLProtocol));\n\n        memcpy(temp, protocol, size);\n\n        protocol = temp;\n\n    }\n\n    p = &first_protocol;\n\n    while (*p != NULL)\n\n        p = &(*p)->next;\n\n    *p             = protocol;\n\n    protocol->next = NULL;\n\n    return 0;\n\n}\n", "idx": 23566}
{"project": "FFmpeg", "commit_id": "3ab9a2a5577d445252724af4067d2a7c8a378efa", "target": 1, "func": "static void rv34_idct_add_c(uint8_t *dst, int stride, DCTELEM *block){\n\n    int      temp[16];\n\n    uint8_t *cm = ff_cropTbl + MAX_NEG_CROP;\n\n    int      i;\n\n\n\n    rv34_row_transform(temp, block);\n\n    memset(block, 0, 16*sizeof(DCTELEM));\n\n\n\n    for(i = 0; i < 4; i++){\n\n        const int z0 = 13*(temp[4*0+i] +    temp[4*2+i]) + 0x200;\n\n        const int z1 = 13*(temp[4*0+i] -    temp[4*2+i]) + 0x200;\n\n        const int z2 =  7* temp[4*1+i] - 17*temp[4*3+i];\n\n        const int z3 = 17* temp[4*1+i] +  7*temp[4*3+i];\n\n\n\n        dst[0] = cm[ dst[0] + ( (z0 + z3) >> 10 ) ];\n\n        dst[1] = cm[ dst[1] + ( (z1 + z2) >> 10 ) ];\n\n        dst[2] = cm[ dst[2] + ( (z1 - z2) >> 10 ) ];\n\n        dst[3] = cm[ dst[3] + ( (z0 - z3) >> 10 ) ];\n\n\n\n        dst  += stride;\n\n    }\n\n}\n", "idx": 23568}
{"project": "FFmpeg", "commit_id": "67e285ceca1cb602a5ab87010b30d904527924fe", "target": 1, "func": "int av_reallocp(void *ptr, size_t size)\n\n{\n\n    void **ptrptr = ptr;\n\n    void *ret;\n\n\n\n\n\n\n\n    ret = av_realloc(*ptrptr, size);\n\n\n\n    if (!ret) {\n\n\n        return AVERROR(ENOMEM);\n\n\n\n\n    *ptrptr = ret;\n\n", "idx": 23570}
{"project": "FFmpeg", "commit_id": "a8469223f6bb756a44f6579439fcae24ccc739b1", "target": 1, "func": "static int alac_decode_frame(AVCodecContext *avctx, void *data,\n\n                             int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    const uint8_t *inbuffer = avpkt->data;\n\n    int input_buffer_size = avpkt->size;\n\n    ALACContext *alac = avctx->priv_data;\n\n\n\n    int channels;\n\n    unsigned int outputsamples;\n\n    int hassize;\n\n    unsigned int readsamplesize;\n\n    int isnotcompressed;\n\n    uint8_t interlacing_shift;\n\n    uint8_t interlacing_leftweight;\n\n    int i, ch, ret;\n\n\n\n    init_get_bits(&alac->gb, inbuffer, input_buffer_size * 8);\n\n\n\n    channels = get_bits(&alac->gb, 3) + 1;\n\n    if (channels != avctx->channels) {\n\n        av_log(avctx, AV_LOG_ERROR, \"frame header channel count mismatch\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* 2^result = something to do with output waiting.\n\n     * perhaps matters if we read > 1 frame in a pass?\n\n     */\n\n    skip_bits(&alac->gb, 4);\n\n\n\n    skip_bits(&alac->gb, 12); /* unknown, skip 12 bits */\n\n\n\n    /* the output sample size is stored soon */\n\n    hassize = get_bits1(&alac->gb);\n\n\n\n    alac->extra_bits = get_bits(&alac->gb, 2) << 3;\n\n\n\n    /* whether the frame is compressed */\n\n    isnotcompressed = get_bits1(&alac->gb);\n\n\n\n    if (hassize) {\n\n        /* now read the number of samples as a 32bit integer */\n\n        outputsamples = get_bits_long(&alac->gb, 32);\n\n        if(outputsamples > alac->setinfo_max_samples_per_frame){\n\n            av_log(avctx, AV_LOG_ERROR, \"outputsamples %d > %d\\n\", outputsamples, alac->setinfo_max_samples_per_frame);\n\n            return -1;\n\n        }\n\n    } else\n\n        outputsamples = alac->setinfo_max_samples_per_frame;\n\n\n\n    /* get output buffer */\n\n    if (outputsamples > INT32_MAX) {\n\n        av_log(avctx, AV_LOG_ERROR, \"unsupported block size: %u\\n\", outputsamples);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    alac->frame.nb_samples = outputsamples;\n\n    if ((ret = avctx->get_buffer(avctx, &alac->frame)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n\n\n    readsamplesize = alac->setinfo_sample_size - alac->extra_bits + channels - 1;\n\n    if (readsamplesize > MIN_CACHE_BITS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"readsamplesize too big (%d)\\n\", readsamplesize);\n\n        return -1;\n\n    }\n\n\n\n    if (!isnotcompressed) {\n\n        /* so it is compressed */\n\n        int16_t predictor_coef_table[MAX_CHANNELS][32];\n\n        int predictor_coef_num[MAX_CHANNELS];\n\n        int prediction_type[MAX_CHANNELS];\n\n        int prediction_quantitization[MAX_CHANNELS];\n\n        int ricemodifier[MAX_CHANNELS];\n\n\n\n        interlacing_shift = get_bits(&alac->gb, 8);\n\n        interlacing_leftweight = get_bits(&alac->gb, 8);\n\n\n\n        for (ch = 0; ch < channels; ch++) {\n\n            prediction_type[ch] = get_bits(&alac->gb, 4);\n\n            prediction_quantitization[ch] = get_bits(&alac->gb, 4);\n\n\n\n            ricemodifier[ch] = get_bits(&alac->gb, 3);\n\n            predictor_coef_num[ch] = get_bits(&alac->gb, 5);\n\n\n\n            /* read the predictor table */\n\n            for (i = 0; i < predictor_coef_num[ch]; i++)\n\n                predictor_coef_table[ch][i] = (int16_t)get_bits(&alac->gb, 16);\n\n        }\n\n\n\n        if (alac->extra_bits) {\n\n            for (i = 0; i < outputsamples; i++) {\n\n                for (ch = 0; ch < channels; ch++)\n\n                    alac->extra_bits_buffer[ch][i] = get_bits(&alac->gb, alac->extra_bits);\n\n            }\n\n        }\n\n        for (ch = 0; ch < channels; ch++) {\n\n            bastardized_rice_decompress(alac,\n\n                                        alac->predicterror_buffer[ch],\n\n                                        outputsamples,\n\n                                        readsamplesize,\n\n                                        alac->setinfo_rice_initialhistory,\n\n                                        alac->setinfo_rice_kmodifier,\n\n                                        ricemodifier[ch] * alac->setinfo_rice_historymult / 4,\n\n                                        (1 << alac->setinfo_rice_kmodifier) - 1);\n\n\n\n            if (prediction_type[ch] == 0) {\n\n                /* adaptive fir */\n\n                predictor_decompress_fir_adapt(alac->predicterror_buffer[ch],\n\n                                               alac->outputsamples_buffer[ch],\n\n                                               outputsamples,\n\n                                               readsamplesize,\n\n                                               predictor_coef_table[ch],\n\n                                               predictor_coef_num[ch],\n\n                                               prediction_quantitization[ch]);\n\n            } else {\n\n                av_log(avctx, AV_LOG_ERROR, \"FIXME: unhandled prediction type: %i\\n\", prediction_type[ch]);\n\n                /* I think the only other prediction type (or perhaps this is\n\n                 * just a boolean?) runs adaptive fir twice.. like:\n\n                 * predictor_decompress_fir_adapt(predictor_error, tempout, ...)\n\n                 * predictor_decompress_fir_adapt(predictor_error, outputsamples ...)\n\n                 * little strange..\n\n                 */\n\n            }\n\n        }\n\n    } else {\n\n        /* not compressed, easy case */\n\n        for (i = 0; i < outputsamples; i++) {\n\n            for (ch = 0; ch < channels; ch++) {\n\n                alac->outputsamples_buffer[ch][i] = get_sbits_long(&alac->gb,\n\n                                                                   alac->setinfo_sample_size);\n\n            }\n\n        }\n\n        alac->extra_bits = 0;\n\n        interlacing_shift = 0;\n\n        interlacing_leftweight = 0;\n\n    }\n\n    if (get_bits(&alac->gb, 3) != 7)\n\n        av_log(avctx, AV_LOG_ERROR, \"Error : Wrong End Of Frame\\n\");\n\n\n\n    if (channels == 2 && interlacing_leftweight) {\n\n        decorrelate_stereo(alac->outputsamples_buffer, outputsamples,\n\n                           interlacing_shift, interlacing_leftweight);\n\n    }\n\n\n\n    if (alac->extra_bits) {\n\n        append_extra_bits(alac->outputsamples_buffer, alac->extra_bits_buffer,\n\n                          alac->extra_bits, alac->numchannels, outputsamples);\n\n    }\n\n\n\n    switch(alac->setinfo_sample_size) {\n\n    case 16:\n\n        if (channels == 2) {\n\n            interleave_stereo_16(alac->outputsamples_buffer,\n\n                                 (int16_t *)alac->frame.data[0], outputsamples);\n\n        } else {\n\n            int16_t *outbuffer = (int16_t *)alac->frame.data[0];\n\n            for (i = 0; i < outputsamples; i++) {\n\n                outbuffer[i] = alac->outputsamples_buffer[0][i];\n\n            }\n\n        }\n\n        break;\n\n    case 24:\n\n        if (channels == 2) {\n\n            interleave_stereo_24(alac->outputsamples_buffer,\n\n                                 (int32_t *)alac->frame.data[0], outputsamples);\n\n        } else {\n\n            int32_t *outbuffer = (int32_t *)alac->frame.data[0];\n\n            for (i = 0; i < outputsamples; i++)\n\n                outbuffer[i] = alac->outputsamples_buffer[0][i] << 8;\n\n        }\n\n        break;\n\n    }\n\n\n\n    if (input_buffer_size * 8 - get_bits_count(&alac->gb) > 8)\n\n        av_log(avctx, AV_LOG_ERROR, \"Error : %d bits left\\n\", input_buffer_size * 8 - get_bits_count(&alac->gb));\n\n\n\n    *got_frame_ptr   = 1;\n\n    *(AVFrame *)data = alac->frame;\n\n\n\n    return input_buffer_size;\n\n}\n", "idx": 23571}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int avi_probe(AVProbeData *p)\n\n{\n\n    /* check file header */\n\n    if (p->buf_size <= 32)\n\n        return 0;\n\n    if (p->buf[0] == 'R' && p->buf[1] == 'I' &&\n\n        p->buf[2] == 'F' && p->buf[3] == 'F' &&\n\n        p->buf[8] == 'A' && p->buf[9] == 'V' &&\n\n        p->buf[10] == 'I' && (p->buf[11] == ' ' || p->buf[11] == 0x19))\n\n        return AVPROBE_SCORE_MAX;\n\n    else\n\n        return 0;\n\n}\n", "idx": 23572}
{"project": "FFmpeg", "commit_id": "9f0a705d46547ca0c3edab21f24cdb0fb3237185", "target": 0, "func": "static int decode_user_data(MpegEncContext *s, GetBitContext *gb){\n\n    char buf[256];\n\n    int i;\n\n    int e;\n\n    int ver = 0, build = 0, ver2 = 0, ver3 = 0;\n\n    char last;\n\n\n\n    for(i=0; i<255 && get_bits_count(gb) < gb->size_in_bits; i++){\n\n        if(show_bits(gb, 23) == 0) break;\n\n        buf[i]= get_bits(gb, 8);\n\n    }\n\n    buf[i]=0;\n\n\n\n    /* divx detection */\n\n    e=sscanf(buf, \"DivX%dBuild%d%c\", &ver, &build, &last);\n\n    if(e<2)\n\n        e=sscanf(buf, \"DivX%db%d%c\", &ver, &build, &last);\n\n    if(e>=2){\n\n        s->divx_version= ver;\n\n        s->divx_build= build;\n\n        s->divx_packed= e==3 && last=='p';\n\n        if(s->divx_packed)\n\n            av_log(s->avctx, AV_LOG_WARNING, \"Invalid and inefficient vfw-avi packed B frames detected\\n\");\n\n    }\n\n\n\n    /* ffmpeg detection */\n\n    e=sscanf(buf, \"FFmpe%*[^b]b%d\", &build)+3;\n\n    if(e!=4)\n\n        e=sscanf(buf, \"FFmpeg v%d.%d.%d / libavcodec build: %d\", &ver, &ver2, &ver3, &build);\n\n    if(e!=4){\n\n        e=sscanf(buf, \"Lavc%d.%d.%d\", &ver, &ver2, &ver3)+1;\n\n        if (e>1)\n\n            build= (ver<<16) + (ver2<<8) + ver3;\n\n    }\n\n    if(e!=4){\n\n        if(strcmp(buf, \"ffmpeg\")==0){\n\n            s->lavc_build= 4600;\n\n        }\n\n    }\n\n    if(e==4){\n\n        s->lavc_build= build;\n\n    }\n\n\n\n    /* Xvid detection */\n\n    e=sscanf(buf, \"XviD%d\", &build);\n\n    if(e==1){\n\n        s->xvid_build= build;\n\n    }\n\n\n\n//printf(\"User Data: %s\\n\", buf);\n\n    return 0;\n\n}\n", "idx": 23573}
{"project": "FFmpeg", "commit_id": "13a099799e89a76eb921ca452e1b04a7a28a9855", "target": 0, "func": "static void RENAME(yuv2yuv1_ar)(SwsContext *c, const int16_t *lumSrc,\n\n                                const int16_t *chrUSrc, const int16_t *chrVSrc,\n\n                                const int16_t *alpSrc,\n\n                                uint8_t *dest, uint8_t *uDest, uint8_t *vDest,\n\n                                uint8_t *aDest, int dstW, int chrDstW)\n\n{\n\n    int p= 4;\n\n    const int16_t *src[4]= { alpSrc + dstW, lumSrc + dstW, chrUSrc + chrDstW, chrVSrc + chrDstW };\n\n    uint8_t *dst[4]= { aDest, dest, uDest, vDest };\n\n    x86_reg counter[4]= { dstW, dstW, chrDstW, chrDstW };\n\n\n\n    while (p--) {\n\n        if (dst[p]) {\n\n            __asm__ volatile(\n\n                \"mov %2, %%\"REG_a\"                    \\n\\t\"\n\n                \"pcmpeqw %%mm7, %%mm7                 \\n\\t\"\n\n                \"psrlw                 $15, %%mm7     \\n\\t\"\n\n                \"psllw                  $6, %%mm7     \\n\\t\"\n\n                \".p2align                4            \\n\\t\" /* FIXME Unroll? */\n\n                \"1:                                   \\n\\t\"\n\n                \"movq  (%0, %%\"REG_a\", 2), %%mm0      \\n\\t\"\n\n                \"movq 8(%0, %%\"REG_a\", 2), %%mm1      \\n\\t\"\n\n                \"paddsw             %%mm7, %%mm0      \\n\\t\"\n\n                \"paddsw             %%mm7, %%mm1      \\n\\t\"\n\n                \"psraw                 $7, %%mm0      \\n\\t\"\n\n                \"psraw                 $7, %%mm1      \\n\\t\"\n\n                \"packuswb           %%mm1, %%mm0      \\n\\t\"\n\n                MOVNTQ(%%mm0, (%1, %%REGa))\n\n                \"add                   $8, %%\"REG_a\"  \\n\\t\"\n\n                \"jnc                   1b             \\n\\t\"\n\n                :: \"r\" (src[p]), \"r\" (dst[p] + counter[p]),\n\n                   \"g\" (-counter[p])\n\n                : \"%\"REG_a\n\n            );\n\n        }\n\n    }\n\n}\n", "idx": 23574}
{"project": "FFmpeg", "commit_id": "7546964f96168cd6ac819ef4c3212ee586619f1a", "target": 0, "func": "static int nvdec_h264_decode_init(AVCodecContext *avctx)\n\n{\n\n    const H264Context *h = avctx->priv_data;\n\n    const SPS       *sps = h->ps.sps;\n\n    return ff_nvdec_decode_init(avctx, sps->ref_frame_count + sps->num_reorder_frames);\n\n}\n", "idx": 23575}
{"project": "FFmpeg", "commit_id": "ca32f7f2083f9ededd1d9964ed065e0ad07a01e0", "target": 0, "func": "void ff_h264_idct8_add_c(uint8_t *dst, DCTELEM *block, int stride){\n\n    int i;\n\n    uint8_t *cm = ff_cropTbl + MAX_NEG_CROP;\n\n\n\n    block[0] += 32;\n\n\n\n    for( i = 0; i < 8; i++ )\n\n    {\n\n        const int a0 =  block[0+i*8] + block[4+i*8];\n\n        const int a2 =  block[0+i*8] - block[4+i*8];\n\n        const int a4 = (block[2+i*8]>>1) - block[6+i*8];\n\n        const int a6 = (block[6+i*8]>>1) + block[2+i*8];\n\n\n\n        const int b0 = a0 + a6;\n\n        const int b2 = a2 + a4;\n\n        const int b4 = a2 - a4;\n\n        const int b6 = a0 - a6;\n\n\n\n        const int a1 = -block[3+i*8] + block[5+i*8] - block[7+i*8] - (block[7+i*8]>>1);\n\n        const int a3 =  block[1+i*8] + block[7+i*8] - block[3+i*8] - (block[3+i*8]>>1);\n\n        const int a5 = -block[1+i*8] + block[7+i*8] + block[5+i*8] + (block[5+i*8]>>1);\n\n        const int a7 =  block[3+i*8] + block[5+i*8] + block[1+i*8] + (block[1+i*8]>>1);\n\n\n\n        const int b1 = (a7>>2) + a1;\n\n        const int b3 =  a3 + (a5>>2);\n\n        const int b5 = (a3>>2) - a5;\n\n        const int b7 =  a7 - (a1>>2);\n\n\n\n        block[0+i*8] = b0 + b7;\n\n        block[7+i*8] = b0 - b7;\n\n        block[1+i*8] = b2 + b5;\n\n        block[6+i*8] = b2 - b5;\n\n        block[2+i*8] = b4 + b3;\n\n        block[5+i*8] = b4 - b3;\n\n        block[3+i*8] = b6 + b1;\n\n        block[4+i*8] = b6 - b1;\n\n    }\n\n    for( i = 0; i < 8; i++ )\n\n    {\n\n        const int a0 =  block[i+0*8] + block[i+4*8];\n\n        const int a2 =  block[i+0*8] - block[i+4*8];\n\n        const int a4 = (block[i+2*8]>>1) - block[i+6*8];\n\n        const int a6 = (block[i+6*8]>>1) + block[i+2*8];\n\n\n\n        const int b0 = a0 + a6;\n\n        const int b2 = a2 + a4;\n\n        const int b4 = a2 - a4;\n\n        const int b6 = a0 - a6;\n\n\n\n        const int a1 = -block[i+3*8] + block[i+5*8] - block[i+7*8] - (block[i+7*8]>>1);\n\n        const int a3 =  block[i+1*8] + block[i+7*8] - block[i+3*8] - (block[i+3*8]>>1);\n\n        const int a5 = -block[i+1*8] + block[i+7*8] + block[i+5*8] + (block[i+5*8]>>1);\n\n        const int a7 =  block[i+3*8] + block[i+5*8] + block[i+1*8] + (block[i+1*8]>>1);\n\n\n\n        const int b1 = (a7>>2) + a1;\n\n        const int b3 =  a3 + (a5>>2);\n\n        const int b5 = (a3>>2) - a5;\n\n        const int b7 =  a7 - (a1>>2);\n\n\n\n        dst[i + 0*stride] = cm[ dst[i + 0*stride] + ((b0 + b7) >> 6) ];\n\n        dst[i + 1*stride] = cm[ dst[i + 1*stride] + ((b2 + b5) >> 6) ];\n\n        dst[i + 2*stride] = cm[ dst[i + 2*stride] + ((b4 + b3) >> 6) ];\n\n        dst[i + 3*stride] = cm[ dst[i + 3*stride] + ((b6 + b1) >> 6) ];\n\n        dst[i + 4*stride] = cm[ dst[i + 4*stride] + ((b6 - b1) >> 6) ];\n\n        dst[i + 5*stride] = cm[ dst[i + 5*stride] + ((b4 - b3) >> 6) ];\n\n        dst[i + 6*stride] = cm[ dst[i + 6*stride] + ((b2 - b5) >> 6) ];\n\n        dst[i + 7*stride] = cm[ dst[i + 7*stride] + ((b0 - b7) >> 6) ];\n\n    }\n\n}\n", "idx": 23576}
{"project": "FFmpeg", "commit_id": "662234a9a22f1cd0f0ac83b8bb1ffadedca90c0a", "target": 0, "func": "void ff_put_h264_qpel8_mc02_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_vt_8w_msa(src - (stride * 2), stride, dst, stride, 8);\n\n}\n", "idx": 23577}
{"project": "FFmpeg", "commit_id": "f5a9c35f886508b851011b7dd4ec18cc67b57d37", "target": 0, "func": "static int read_pakt_chunk(AVFormatContext *s, int64_t size)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st      = s->streams[0];\n\n    CaffContext *caf  = s->priv_data;\n\n    int64_t pos = 0, ccount;\n\n    int num_packets, i;\n\n\n\n    ccount = avio_tell(pb);\n\n\n\n    num_packets = avio_rb64(pb);\n\n    if (num_packets < 0 || INT32_MAX / sizeof(AVIndexEntry) < num_packets)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    st->nb_frames  = avio_rb64(pb); /* valid frames */\n\n    st->nb_frames += avio_rb32(pb); /* priming frames */\n\n    st->nb_frames += avio_rb32(pb); /* remainder frames */\n\n\n\n    st->duration = 0;\n\n    for (i = 0; i < num_packets; i++) {\n\n        av_add_index_entry(s->streams[0], pos, st->duration, 0, 0, AVINDEX_KEYFRAME);\n\n        pos += caf->bytes_per_packet ? caf->bytes_per_packet : ff_mp4_read_descr_len(pb);\n\n        st->duration += caf->frames_per_packet ? caf->frames_per_packet : ff_mp4_read_descr_len(pb);\n\n    }\n\n\n\n    if (avio_tell(pb) - ccount != size) {\n\n        av_log(s, AV_LOG_ERROR, \"error reading packet table\\n\");\n\n        return -1;\n\n    }\n\n\n\n    caf->num_bytes = pos;\n\n    return 0;\n\n}\n", "idx": 23578}
{"project": "FFmpeg", "commit_id": "7b5ff7d57355dc608f0fd86e3ab32a2fda65e752", "target": 1, "func": "static void vp8_decode_mb_row_no_filter(AVCodecContext *avctx, void *tdata,\n\n                                        int jobnr, int threadnr)\n\n{\n\n    decode_mb_row_no_filter(avctx, tdata, jobnr, threadnr, 0);\n\n}\n", "idx": 23579}
{"project": "FFmpeg", "commit_id": "e5755893786ecab2e6f0414d1b2983dcaa3d237e", "target": 1, "func": "static void mxf_free_metadataset(MXFMetadataSet **ctx, int freectx)\n\n{\n\n    MXFIndexTableSegment *seg;\n\n    switch ((*ctx)->type) {\n\n    case Descriptor:\n\n        av_freep(&((MXFDescriptor *)*ctx)->extradata);\n\n        break;\n\n    case MultipleDescriptor:\n\n        av_freep(&((MXFDescriptor *)*ctx)->sub_descriptors_refs);\n\n        break;\n\n    case Sequence:\n\n        av_freep(&((MXFSequence *)*ctx)->structural_components_refs);\n\n        break;\n\n    case EssenceGroup:\n\n        av_freep(&((MXFEssenceGroup *)*ctx)->structural_components_refs);\n\n        break;\n\n    case SourcePackage:\n\n    case MaterialPackage:\n\n        av_freep(&((MXFPackage *)*ctx)->tracks_refs);\n\n        av_freep(&((MXFPackage *)*ctx)->name);\n\n\n        break;\n\n    case TaggedValue:\n\n        av_freep(&((MXFTaggedValue *)*ctx)->name);\n\n        av_freep(&((MXFTaggedValue *)*ctx)->value);\n\n        break;\n\n    case IndexTableSegment:\n\n        seg = (MXFIndexTableSegment *)*ctx;\n\n        av_freep(&seg->temporal_offset_entries);\n\n        av_freep(&seg->flag_entries);\n\n        av_freep(&seg->stream_offset_entries);\n\n    default:\n\n        break;\n\n    }\n\n    if (freectx)\n\n    av_freep(ctx);\n\n}", "idx": 23580}
{"project": "FFmpeg", "commit_id": "4a7876c6e4e62e94d51e364ba99aae4da7671238", "target": 1, "func": "static av_cold int qdm2_decode_init(AVCodecContext *avctx)\n\n{\n\n    QDM2Context *s = avctx->priv_data;\n\n    uint8_t *extradata;\n\n    int extradata_size;\n\n    int tmp_val, tmp, size;\n\n\n\n    /* extradata parsing\n\n\n\n    Structure:\n\n    wave {\n\n        frma (QDM2)\n\n        QDCA\n\n        QDCP\n\n    }\n\n\n\n    32  size (including this field)\n\n    32  tag (=frma)\n\n    32  type (=QDM2 or QDMC)\n\n\n\n    32  size (including this field, in bytes)\n\n    32  tag (=QDCA) // maybe mandatory parameters\n\n    32  unknown (=1)\n\n    32  channels (=2)\n\n    32  samplerate (=44100)\n\n    32  bitrate (=96000)\n\n    32  block size (=4096)\n\n    32  frame size (=256) (for one channel)\n\n    32  packet size (=1300)\n\n\n\n    32  size (including this field, in bytes)\n\n    32  tag (=QDCP) // maybe some tuneable parameters\n\n    32  float1 (=1.0)\n\n    32  zero ?\n\n    32  float2 (=1.0)\n\n    32  float3 (=1.0)\n\n    32  unknown (27)\n\n    32  unknown (8)\n\n    32  zero ?\n\n    */\n\n\n\n    if (!avctx->extradata || (avctx->extradata_size < 48)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"extradata missing or truncated\\n\");\n\n        return -1;\n\n    }\n\n\n\n    extradata = avctx->extradata;\n\n    extradata_size = avctx->extradata_size;\n\n\n\n    while (extradata_size > 7) {\n\n        if (!memcmp(extradata, \"frmaQDM\", 7))\n\n            break;\n\n        extradata++;\n\n        extradata_size--;\n\n    }\n\n\n\n    if (extradata_size < 12) {\n\n        av_log(avctx, AV_LOG_ERROR, \"not enough extradata (%i)\\n\",\n\n               extradata_size);\n\n        return -1;\n\n    }\n\n\n\n    if (memcmp(extradata, \"frmaQDM\", 7)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid headers, QDM? not found\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (extradata[7] == 'C') {\n\n//        s->is_qdmc = 1;\n\n        av_log(avctx, AV_LOG_ERROR, \"stream is QDMC version 1, which is not supported\\n\");\n\n        return -1;\n\n    }\n\n\n\n    extradata += 8;\n\n    extradata_size -= 8;\n\n\n\n    size = AV_RB32(extradata);\n\n\n\n    if(size > extradata_size){\n\n        av_log(avctx, AV_LOG_ERROR, \"extradata size too small, %i < %i\\n\",\n\n               extradata_size, size);\n\n        return -1;\n\n    }\n\n\n\n    extradata += 4;\n\n    av_log(avctx, AV_LOG_DEBUG, \"size: %d\\n\", size);\n\n    if (AV_RB32(extradata) != MKBETAG('Q','D','C','A')) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid extradata, expecting QDCA\\n\");\n\n        return -1;\n\n    }\n\n\n\n    extradata += 8;\n\n\n\n    avctx->channels = s->nb_channels = s->channels = AV_RB32(extradata);\n\n    extradata += 4;\n\n    if (s->channels > MPA_MAX_CHANNELS)\n\n\n\n\n    avctx->sample_rate = AV_RB32(extradata);\n\n    extradata += 4;\n\n\n\n    avctx->bit_rate = AV_RB32(extradata);\n\n    extradata += 4;\n\n\n\n    s->group_size = AV_RB32(extradata);\n\n    extradata += 4;\n\n\n\n    s->fft_size = AV_RB32(extradata);\n\n    extradata += 4;\n\n\n\n    s->checksum_size = AV_RB32(extradata);\n\n\n\n    s->fft_order = av_log2(s->fft_size) + 1;\n\n    s->fft_frame_size = 2 * s->fft_size; // complex has two floats\n\n\n\n    // something like max decodable tones\n\n    s->group_order = av_log2(s->group_size) + 1;\n\n    s->frame_size = s->group_size / 16; // 16 iterations per super block\n\n\n\n\n\n    s->sub_sampling = s->fft_order - 7;\n\n    s->frequency_range = 255 / (1 << (2 - s->sub_sampling));\n\n\n\n    switch ((s->sub_sampling * 2 + s->channels - 1)) {\n\n        case 0: tmp = 40; break;\n\n        case 1: tmp = 48; break;\n\n        case 2: tmp = 56; break;\n\n        case 3: tmp = 72; break;\n\n        case 4: tmp = 80; break;\n\n        case 5: tmp = 100;break;\n\n        default: tmp=s->sub_sampling; break;\n\n    }\n\n    tmp_val = 0;\n\n    if ((tmp * 1000) < avctx->bit_rate)  tmp_val = 1;\n\n    if ((tmp * 1440) < avctx->bit_rate)  tmp_val = 2;\n\n    if ((tmp * 1760) < avctx->bit_rate)  tmp_val = 3;\n\n    if ((tmp * 2240) < avctx->bit_rate)  tmp_val = 4;\n\n    s->cm_table_select = tmp_val;\n\n\n\n    if (s->sub_sampling == 0)\n\n        tmp = 7999;\n\n    else\n\n        tmp = ((-(s->sub_sampling -1)) & 8000) + 20000;\n\n    /*\n\n    0: 7999 -> 0\n\n    1: 20000 -> 2\n\n    2: 28000 -> 2\n\n    */\n\n    if (tmp < 8000)\n\n        s->coeff_per_sb_select = 0;\n\n    else if (tmp <= 16000)\n\n        s->coeff_per_sb_select = 1;\n\n    else\n\n        s->coeff_per_sb_select = 2;\n\n\n\n    // Fail on unknown fft order\n\n    if ((s->fft_order < 7) || (s->fft_order > 9)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown FFT order (%d), contact the developers!\\n\", s->fft_order);\n\n        return -1;\n\n    }\n\n\n\n    ff_rdft_init(&s->rdft_ctx, s->fft_order, IDFT_C2R);\n\n    ff_mpadsp_init(&s->mpadsp);\n\n\n\n    qdm2_init(s);\n\n\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_S16;\n\n\n\n//    dump_context(s);\n\n    return 0;\n\n}", "idx": 23581}
{"project": "FFmpeg", "commit_id": "b9029997d4694b6533556480fe0ab1f3f9779a56", "target": 0, "func": "static int roq_decode_end(AVCodecContext *avctx)\n\n{\n\n    RoqContext *s = avctx->priv_data;\n\n\n\n    /* release the last frame */\n\n    avctx->release_buffer(avctx, &s->last_frame);\n\n\n\n    return 0;\n\n}\n", "idx": 23584}
{"project": "FFmpeg", "commit_id": "a9decf004189b86e110ccb70f728409db330a6c2", "target": 0, "func": "static int vfw_read_header(AVFormatContext *s, AVFormatParameters *ap)\n\n{\n\n    struct vfw_ctx *ctx = s->priv_data;\n\n    AVCodecContext *codec;\n\n    AVStream *st;\n\n    int devnum;\n\n    int bisize;\n\n    BITMAPINFO *bi;\n\n    CAPTUREPARMS cparms;\n\n    DWORD biCompression;\n\n    WORD biBitCount;\n\n    int width;\n\n    int height;\n\n    int ret;\n\n\n\n    if(!ap->time_base.den) {\n\n        av_log(s, AV_LOG_ERROR, \"A time base must be specified.\\n\");\n\n        return AVERROR_IO;\n\n    }\n\n\n\n    ctx->s = s;\n\n\n\n    ctx->hwnd = capCreateCaptureWindow(NULL, 0, 0, 0, 0, 0, HWND_MESSAGE, 0);\n\n    if(!ctx->hwnd) {\n\n        av_log(s, AV_LOG_ERROR, \"Could not create capture window.\\n\");\n\n        return AVERROR_IO;\n\n    }\n\n\n\n    /* If atoi fails, devnum==0 and the default device is used */\n\n    devnum = atoi(s->filename);\n\n\n\n    ret = SendMessage(ctx->hwnd, WM_CAP_DRIVER_CONNECT, devnum, 0);\n\n    if(!ret) {\n\n        av_log(s, AV_LOG_ERROR, \"Could not connect to device.\\n\");\n\n        DestroyWindow(ctx->hwnd);\n\n        return AVERROR(ENODEV);\n\n    }\n\n\n\n    SendMessage(ctx->hwnd, WM_CAP_SET_OVERLAY, 0, 0);\n\n    SendMessage(ctx->hwnd, WM_CAP_SET_PREVIEW, 0, 0);\n\n\n\n    ret = SendMessage(ctx->hwnd, WM_CAP_SET_CALLBACK_VIDEOSTREAM, 0,\n\n                      (LPARAM) videostream_cb);\n\n    if(!ret) {\n\n        av_log(s, AV_LOG_ERROR, \"Could not set video stream callback.\\n\");\n\n        goto fail_io;\n\n    }\n\n\n\n    SetWindowLongPtr(ctx->hwnd, GWLP_USERDATA, (LONG_PTR) ctx);\n\n\n\n    st = av_new_stream(s, 0);\n\n    if(!st) {\n\n        vfw_read_close(s);\n\n        return AVERROR_NOMEM;\n\n    }\n\n\n\n    /* Set video format */\n\n    bisize = SendMessage(ctx->hwnd, WM_CAP_GET_VIDEOFORMAT, 0, 0);\n\n    if(!bisize)\n\n        goto fail_io;\n\n    bi = av_malloc(bisize);\n\n    if(!bi) {\n\n        vfw_read_close(s);\n\n        return AVERROR_NOMEM;\n\n    }\n\n    ret = SendMessage(ctx->hwnd, WM_CAP_GET_VIDEOFORMAT, bisize, (LPARAM) bi);\n\n    if(!ret)\n\n        goto fail_bi;\n\n\n\n    dump_bih(s, &bi->bmiHeader);\n\n\n\n    width  = ap->width  ? ap->width  : bi->bmiHeader.biWidth ;\n\n    height = ap->height ? ap->height : bi->bmiHeader.biHeight;\n\n    bi->bmiHeader.biWidth  = width ;\n\n    bi->bmiHeader.biHeight = height;\n\n\n\n#if 0\n\n    /* For testing yet unsupported compressions\n\n     * Copy these values from user-supplied verbose information */\n\n    bi->bmiHeader.biWidth       = 320;\n\n    bi->bmiHeader.biHeight      = 240;\n\n    bi->bmiHeader.biPlanes      = 1;\n\n    bi->bmiHeader.biBitCount    = 12;\n\n    bi->bmiHeader.biCompression = MKTAG('I','4','2','0');\n\n    bi->bmiHeader.biSizeImage   = 115200;\n\n    dump_bih(s, &bi->bmiHeader);\n\n#endif\n\n\n\n    ret = SendMessage(ctx->hwnd, WM_CAP_SET_VIDEOFORMAT, bisize, (LPARAM) bi);\n\n    if(!ret) {\n\n        av_log(s, AV_LOG_ERROR, \"Could not set Video Format.\\n\");\n\n        goto fail_bi;\n\n    }\n\n\n\n    biCompression = bi->bmiHeader.biCompression;\n\n    biBitCount = bi->bmiHeader.biBitCount;\n\n\n\n    av_free(bi);\n\n\n\n    /* Set sequence setup */\n\n    ret = SendMessage(ctx->hwnd, WM_CAP_GET_SEQUENCE_SETUP, sizeof(cparms),\n\n                      (LPARAM) &cparms);\n\n    if(!ret)\n\n        goto fail_io;\n\n\n\n    dump_captureparms(s, &cparms);\n\n\n\n    cparms.fYield = 1; // Spawn a background thread\n\n    cparms.dwRequestMicroSecPerFrame =\n\n                               (ap->time_base.num*1000000) / ap->time_base.den;\n\n    cparms.fAbortLeftMouse = 0;\n\n    cparms.fAbortRightMouse = 0;\n\n    cparms.fCaptureAudio = 0;\n\n    cparms.vKeyAbort = 0;\n\n\n\n    ret = SendMessage(ctx->hwnd, WM_CAP_SET_SEQUENCE_SETUP, sizeof(cparms),\n\n                      (LPARAM) &cparms);\n\n    if(!ret)\n\n        goto fail_io;\n\n\n\n    codec = st->codec;\n\n    codec->time_base = ap->time_base;\n\n    codec->codec_type = CODEC_TYPE_VIDEO;\n\n    codec->width = width;\n\n    codec->height = height;\n\n    codec->pix_fmt = vfw_pixfmt(biCompression, biBitCount);\n\n    if(codec->pix_fmt == PIX_FMT_NONE) {\n\n        codec->codec_id = vfw_codecid(biCompression);\n\n        if(codec->codec_id == CODEC_ID_NONE) {\n\n            av_log(s, AV_LOG_ERROR, \"Unknown compression type. \"\n\n                             \"Please report verbose (-v 9) debug information.\\n\");\n\n            vfw_read_close(s);\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n        codec->bits_per_coded_sample = biBitCount;\n\n    } else {\n\n        codec->codec_id = CODEC_ID_RAWVIDEO;\n\n        if(biCompression == BI_RGB)\n\n            codec->bits_per_coded_sample = biBitCount;\n\n    }\n\n\n\n    av_set_pts_info(st, 32, 1, 1000);\n\n\n\n    ctx->mutex = CreateMutex(NULL, 0, NULL);\n\n    if(!ctx->mutex) {\n\n        av_log(s, AV_LOG_ERROR, \"Could not create Mutex.\\n\" );\n\n        goto fail_io;\n\n    }\n\n    ctx->event = CreateEvent(NULL, 1, 0, NULL);\n\n    if(!ctx->event) {\n\n        av_log(s, AV_LOG_ERROR, \"Could not create Event.\\n\" );\n\n        goto fail_io;\n\n    }\n\n\n\n    ret = SendMessage(ctx->hwnd, WM_CAP_SEQUENCE_NOFILE, 0, 0);\n\n    if(!ret) {\n\n        av_log(s, AV_LOG_ERROR, \"Could not start capture sequence.\\n\" );\n\n        goto fail_io;\n\n    }\n\n\n\n    return 0;\n\n\n\nfail_bi:\n\n    av_free(bi);\n\n\n\nfail_io:\n\n    vfw_read_close(s);\n\n    return AVERROR_IO;\n\n}\n", "idx": 23595}
{"project": "FFmpeg", "commit_id": "61d43a265176e8e724301b7721affbe9f61729d5", "target": 0, "func": "static int lag_decode_arith_plane(LagarithContext *l, uint8_t *dst,\n\n                                  int width, int height, int stride,\n\n                                  const uint8_t *src, int src_size)\n\n{\n\n    int i = 0;\n\n    int read = 0;\n\n    uint32_t length;\n\n    uint32_t offset = 1;\n\n    int esc_count;\n\n    GetBitContext gb;\n\n    lag_rac rac;\n\n    const uint8_t *src_end = src + src_size;\n\n\n\n    rac.avctx = l->avctx;\n\n    l->zeros = 0;\n\n\n\n    if(src_size < 2)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    esc_count = src[0];\n\n    if (esc_count < 4) {\n\n        length = width * height;\n\n        if(src_size < 5)\n\n            return AVERROR_INVALIDDATA;\n\n        if (esc_count && AV_RL32(src + 1) < length) {\n\n            length = AV_RL32(src + 1);\n\n            offset += 4;\n\n        }\n\n\n\n        init_get_bits8(&gb, src + offset, src_size - offset);\n\n\n\n        if (lag_read_prob_header(&rac, &gb) < 0)\n\n            return -1;\n\n\n\n        ff_lag_rac_init(&rac, &gb, length - stride);\n\n\n\n        for (i = 0; i < height; i++)\n\n            read += lag_decode_line(l, &rac, dst + (i * stride), width,\n\n                                    stride, esc_count);\n\n\n\n        if (read > length)\n\n            av_log(l->avctx, AV_LOG_WARNING,\n\n                   \"Output more bytes than length (%d of %d)\\n\", read,\n\n                   length);\n\n    } else if (esc_count < 8) {\n\n        esc_count -= 4;\n\n        src ++;\n\n        src_size --;\n\n        if (esc_count > 0) {\n\n            /* Zero run coding only, no range coding. */\n\n            for (i = 0; i < height; i++) {\n\n                int res = lag_decode_zero_run_line(l, dst + (i * stride), src,\n\n                                                   src_end, width, esc_count);\n\n                if (res < 0)\n\n                    return res;\n\n                src += res;\n\n            }\n\n        } else {\n\n            if (src_size < width * height)\n\n                return AVERROR_INVALIDDATA; // buffer not big enough\n\n            /* Plane is stored uncompressed */\n\n            for (i = 0; i < height; i++) {\n\n                memcpy(dst + (i * stride), src, width);\n\n                src += width;\n\n            }\n\n        }\n\n    } else if (esc_count == 0xff) {\n\n        /* Plane is a solid run of given value */\n\n        for (i = 0; i < height; i++)\n\n            memset(dst + i * stride, src[1], width);\n\n        /* Do not apply prediction.\n\n           Note: memset to 0 above, setting first value to src[1]\n\n           and applying prediction gives the same result. */\n\n        return 0;\n\n    } else {\n\n        av_log(l->avctx, AV_LOG_ERROR,\n\n               \"Invalid zero run escape code! (%#x)\\n\", esc_count);\n\n        return -1;\n\n    }\n\n\n\n    if (l->avctx->pix_fmt != AV_PIX_FMT_YUV422P) {\n\n        for (i = 0; i < height; i++) {\n\n            lag_pred_line(l, dst, width, stride, i);\n\n            dst += stride;\n\n        }\n\n    } else {\n\n        for (i = 0; i < height; i++) {\n\n            lag_pred_line_yuy2(l, dst, width, stride, i,\n\n                               width == l->avctx->width);\n\n            dst += stride;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23613}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int decode_wmv9(AVCodecContext *avctx, const uint8_t *buf, int buf_size,\n\n                       int x, int y, int w, int h, int wmv9_mask)\n\n{\n\n    MSS2Context *ctx  = avctx->priv_data;\n\n    MSS12Context *c   = &ctx->c;\n\n    VC1Context *v     = avctx->priv_data;\n\n    MpegEncContext *s = &v->s;\n\n    AVFrame *f;\n\n    int ret;\n\n\n\n    ff_mpeg_flush(avctx);\n\n\n\n    init_get_bits(&s->gb, buf, buf_size * 8);\n\n\n\n    s->loop_filter = avctx->skip_loop_filter < AVDISCARD_ALL;\n\n\n\n    if (ff_vc1_parse_frame_header(v, &s->gb) < 0) {\n\n        av_log(v->s.avctx, AV_LOG_ERROR, \"header error\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->pict_type != AV_PICTURE_TYPE_I) {\n\n        av_log(v->s.avctx, AV_LOG_ERROR, \"expected I-frame\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    avctx->pix_fmt = AV_PIX_FMT_YUV420P;\n\n\n\n    if ((ret = ff_MPV_frame_start(s, avctx)) < 0) {\n\n        av_log(v->s.avctx, AV_LOG_ERROR, \"ff_MPV_frame_start error\\n\");\n\n        avctx->pix_fmt = AV_PIX_FMT_RGB24;\n\n        return ret;\n\n    }\n\n\n\n    ff_mpeg_er_frame_start(s);\n\n\n\n    v->bits = buf_size * 8;\n\n\n\n    v->end_mb_x = (w + 15) >> 4;\n\n    s->end_mb_y = (h + 15) >> 4;\n\n    if (v->respic & 1)\n\n        v->end_mb_x = v->end_mb_x + 1 >> 1;\n\n    if (v->respic & 2)\n\n        s->end_mb_y = s->end_mb_y + 1 >> 1;\n\n\n\n    ff_vc1_decode_blocks(v);\n\n\n\n    ff_er_frame_end(&s->er);\n\n\n\n    ff_MPV_frame_end(s);\n\n\n\n    f = &s->current_picture.f;\n\n\n\n    if (v->respic == 3) {\n\n        ctx->dsp.upsample_plane(f->data[0], f->linesize[0], w,      h);\n\n        ctx->dsp.upsample_plane(f->data[1], f->linesize[1], w >> 1, h >> 1);\n\n        ctx->dsp.upsample_plane(f->data[2], f->linesize[2], w >> 1, h >> 1);\n\n    } else if (v->respic)\n\n        avpriv_request_sample(v->s.avctx,\n\n                              \"Asymmetric WMV9 rectangle subsampling\");\n\n\n\n    av_assert0(f->linesize[1] == f->linesize[2]);\n\n\n\n    if (wmv9_mask != -1)\n\n        ctx->dsp.mss2_blit_wmv9_masked(c->rgb_pic + y * c->rgb_stride + x * 3,\n\n                                       c->rgb_stride, wmv9_mask,\n\n                                       c->pal_pic + y * c->pal_stride + x,\n\n                                       c->pal_stride,\n\n                                       f->data[0], f->linesize[0],\n\n                                       f->data[1], f->data[2], f->linesize[1],\n\n                                       w, h);\n\n    else\n\n        ctx->dsp.mss2_blit_wmv9(c->rgb_pic + y * c->rgb_stride + x * 3,\n\n                                c->rgb_stride,\n\n                                f->data[0], f->linesize[0],\n\n                                f->data[1], f->data[2], f->linesize[1],\n\n                                w, h);\n\n\n\n    avctx->pix_fmt = AV_PIX_FMT_RGB24;\n\n\n\n    return 0;\n\n}\n", "idx": 23625}
{"project": "FFmpeg", "commit_id": "3ab9a2a5577d445252724af4067d2a7c8a378efa", "target": 1, "func": "static void rv40_h_weak_loop_filter(uint8_t *src, const int stride,\n\n                                    const int filter_p1, const int filter_q1,\n\n                                    const int alpha, const int beta,\n\n                                    const int lim_p0q0, const int lim_q1,\n\n                                    const int lim_p1)\n\n{\n\n    rv40_weak_loop_filter(src, stride, 1, filter_p1, filter_q1,\n\n                          alpha, beta, lim_p0q0, lim_q1, lim_p1);\n\n}\n", "idx": 23627}
{"project": "FFmpeg", "commit_id": "9487fb4dea3498eb4711eb023f43199f68701b1e", "target": 1, "func": "yuv2rgb_1_c_template(SwsContext *c, const int16_t *buf0,\n                     const int16_t *ubuf[2], const int16_t *vbuf[2],\n                     const int16_t *abuf0, uint8_t *dest, int dstW,\n                     int uvalpha, int y, enum PixelFormat target,\n                     int hasAlpha)\n{\n    const int16_t *ubuf0 = ubuf[0], *vbuf0 = vbuf[0];\n    int i;\n    if (uvalpha < 2048) {\n        for (i = 0; i < (dstW >> 1); i++) {\n            int Y1 = buf0[i * 2]     >> 7;\n            int Y2 = buf0[i * 2 + 1] >> 7;\n            int U  = ubuf0[i]        >> 7;\n            int V  = vbuf0[i]        >> 7;\n            int A1, A2;\n            const void *r =  c->table_rV[V],\n                       *g = (c->table_gU[U] + c->table_gV[V]),\n                       *b =  c->table_bU[U];\n            if (hasAlpha) {\n                A1 = abuf0[i * 2    ] >> 7;\n                A2 = abuf0[i * 2 + 1] >> 7;\n            }\n            yuv2rgb_write(dest, i, Y1, Y2, hasAlpha ? A1 : 0, hasAlpha ? A2 : 0,\n                          r, g, b, y, target, hasAlpha);\n        }\n    } else {\n        const int16_t *ubuf1 = ubuf[1], *vbuf1 = vbuf[1];\n        for (i = 0; i < (dstW >> 1); i++) {\n            int Y1 =  buf0[i * 2]          >> 7;\n            int Y2 =  buf0[i * 2 + 1]      >> 7;\n            int U  = (ubuf0[i] + ubuf1[i]) >> 8;\n            int V  = (vbuf0[i] + vbuf1[i]) >> 8;\n            int A1, A2;\n            const void *r =  c->table_rV[V],\n                       *g = (c->table_gU[U] + c->table_gV[V]),\n                       *b =  c->table_bU[U];\n            if (hasAlpha) {\n                A1 = abuf0[i * 2    ] >> 7;\n                A2 = abuf0[i * 2 + 1] >> 7;\n            }\n            yuv2rgb_write(dest, i, Y1, Y2, hasAlpha ? A1 : 0, hasAlpha ? A2 : 0,\n                          r, g, b, y, target, hasAlpha);\n        }\n    }\n}", "idx": 23628}
{"project": "FFmpeg", "commit_id": "8348bd198ff8ef2ad366ac7ad959193ef845d468", "target": 0, "func": "static AVStream * parse_media_type(AVFormatContext *s, AVStream *st, int sid,\n\n                                   ff_asf_guid mediatype, ff_asf_guid subtype,\n\n                                   ff_asf_guid formattype, int size)\n\n{\n\n    WtvContext *wtv = s->priv_data;\n\n    AVIOContext *pb = wtv->pb;\n\n    if (!ff_guidcmp(subtype, ff_mediasubtype_cpfilters_processed) &&\n\n        !ff_guidcmp(formattype, ff_format_cpfilters_processed)) {\n\n        ff_asf_guid actual_subtype;\n\n        ff_asf_guid actual_formattype;\n\n\n\n        if (size < 32) {\n\n            av_log(s, AV_LOG_WARNING, \"format buffer size underflow\\n\");\n\n            avio_skip(pb, size);\n\n            return NULL;\n\n        }\n\n\n\n        avio_skip(pb, size - 32);\n\n        ff_get_guid(pb, &actual_subtype);\n\n        ff_get_guid(pb, &actual_formattype);\n\n        avio_seek(pb, -size, SEEK_CUR);\n\n\n\n        st = parse_media_type(s, st, sid, mediatype, actual_subtype, actual_formattype, size - 32);\n\n        avio_skip(pb, 32);\n\n        return st;\n\n    } else if (!ff_guidcmp(mediatype, ff_mediatype_audio)) {\n\n        st = new_stream(s, st, sid, AVMEDIA_TYPE_AUDIO);\n\n        if (!st)\n\n            return NULL;\n\n        if (!ff_guidcmp(formattype, ff_format_waveformatex)) {\n\n            int ret = ff_get_wav_header(pb, st->codec, size);\n\n            if (ret < 0)\n\n                return NULL;\n\n        } else {\n\n            if (ff_guidcmp(formattype, ff_format_none))\n\n                av_log(s, AV_LOG_WARNING, \"unknown formattype:\"FF_PRI_GUID\"\\n\", FF_ARG_GUID(formattype));\n\n            avio_skip(pb, size);\n\n        }\n\n\n\n        if (!memcmp(subtype + 4, (const uint8_t[]){FF_MEDIASUBTYPE_BASE_GUID}, 12)) {\n\n            st->codec->codec_id = ff_wav_codec_get_id(AV_RL32(subtype), st->codec->bits_per_coded_sample);\n\n        } else if (!ff_guidcmp(subtype, mediasubtype_mpeg1payload)) {\n\n            if (st->codec->extradata && st->codec->extradata_size >= 22)\n\n                parse_mpeg1waveformatex(st);\n\n            else\n\n                av_log(s, AV_LOG_WARNING, \"MPEG1WAVEFORMATEX underflow\\n\");\n\n        } else {\n\n            st->codec->codec_id = ff_codec_guid_get_id(ff_codec_wav_guids, subtype);\n\n            if (st->codec->codec_id == AV_CODEC_ID_NONE)\n\n                av_log(s, AV_LOG_WARNING, \"unknown subtype:\"FF_PRI_GUID\"\\n\", FF_ARG_GUID(subtype));\n\n        }\n\n        return st;\n\n    } else if (!ff_guidcmp(mediatype, ff_mediatype_video)) {\n\n        st = new_stream(s, st, sid, AVMEDIA_TYPE_VIDEO);\n\n        if (!st)\n\n            return NULL;\n\n        if (!ff_guidcmp(formattype, ff_format_videoinfo2)) {\n\n            int consumed = parse_videoinfoheader2(s, st);\n\n            avio_skip(pb, FFMAX(size - consumed, 0));\n\n        } else if (!ff_guidcmp(formattype, ff_format_mpeg2_video)) {\n\n            int consumed = parse_videoinfoheader2(s, st);\n\n            int count;\n\n            avio_skip(pb, 4);\n\n            count = avio_rl32(pb);\n\n            avio_skip(pb, 12);\n\n            if (count && ff_get_extradata(st->codec, pb, count) < 0) {\n\n               ff_free_stream(s, st);\n\n               return NULL;\n\n            }\n\n            consumed += 20 + count;\n\n            avio_skip(pb, FFMAX(size - consumed, 0));\n\n        } else {\n\n            if (ff_guidcmp(formattype, ff_format_none))\n\n                av_log(s, AV_LOG_WARNING, \"unknown formattype:\"FF_PRI_GUID\"\\n\", FF_ARG_GUID(formattype));\n\n            avio_skip(pb, size);\n\n        }\n\n\n\n        if (!memcmp(subtype + 4, (const uint8_t[]){FF_MEDIASUBTYPE_BASE_GUID}, 12)) {\n\n            st->codec->codec_id = ff_codec_get_id(ff_codec_bmp_tags, AV_RL32(subtype));\n\n        } else {\n\n            st->codec->codec_id = ff_codec_guid_get_id(ff_video_guids, subtype);\n\n        }\n\n        if (st->codec->codec_id == AV_CODEC_ID_NONE)\n\n            av_log(s, AV_LOG_WARNING, \"unknown subtype:\"FF_PRI_GUID\"\\n\", FF_ARG_GUID(subtype));\n\n        return st;\n\n    } else if (!ff_guidcmp(mediatype, mediatype_mpeg2_pes) &&\n\n               !ff_guidcmp(subtype, mediasubtype_dvb_subtitle)) {\n\n        st = new_stream(s, st, sid, AVMEDIA_TYPE_SUBTITLE);\n\n        if (!st)\n\n            return NULL;\n\n        if (ff_guidcmp(formattype, ff_format_none))\n\n            av_log(s, AV_LOG_WARNING, \"unknown formattype:\"FF_PRI_GUID\"\\n\", FF_ARG_GUID(formattype));\n\n        avio_skip(pb, size);\n\n        st->codec->codec_id = AV_CODEC_ID_DVB_SUBTITLE;\n\n        return st;\n\n    } else if (!ff_guidcmp(mediatype, mediatype_mstvcaption) &&\n\n               (!ff_guidcmp(subtype, mediasubtype_teletext) || !ff_guidcmp(subtype, mediasubtype_dtvccdata))) {\n\n        st = new_stream(s, st, sid, AVMEDIA_TYPE_SUBTITLE);\n\n        if (!st)\n\n            return NULL;\n\n        if (ff_guidcmp(formattype, ff_format_none))\n\n            av_log(s, AV_LOG_WARNING, \"unknown formattype:\"FF_PRI_GUID\"\\n\", FF_ARG_GUID(formattype));\n\n        avio_skip(pb, size);\n\n        st->codec->codec_id = !ff_guidcmp(subtype, mediasubtype_teletext) ? AV_CODEC_ID_DVB_TELETEXT : AV_CODEC_ID_EIA_608;\n\n        return st;\n\n    } else if (!ff_guidcmp(mediatype, mediatype_mpeg2_sections) &&\n\n               !ff_guidcmp(subtype, mediasubtype_mpeg2_sections)) {\n\n        if (ff_guidcmp(formattype, ff_format_none))\n\n            av_log(s, AV_LOG_WARNING, \"unknown formattype:\"FF_PRI_GUID\"\\n\", FF_ARG_GUID(formattype));\n\n        avio_skip(pb, size);\n\n        return NULL;\n\n    }\n\n\n\n    av_log(s, AV_LOG_WARNING, \"unknown media type, mediatype:\"FF_PRI_GUID\n\n                              \", subtype:\"FF_PRI_GUID\", formattype:\"FF_PRI_GUID\"\\n\",\n\n                              FF_ARG_GUID(mediatype), FF_ARG_GUID(subtype), FF_ARG_GUID(formattype));\n\n    avio_skip(pb, size);\n\n    return NULL;\n\n}\n", "idx": 23630}
{"project": "FFmpeg", "commit_id": "d6737539e77e78fca9a04914d51996cfd1ccc55c", "target": 0, "func": "static void intra_predict_dc_4blk_8x8_msa(uint8_t *src, int32_t stride)\n\n{\n\n    uint8_t lp_cnt;\n\n    uint32_t src0, src1, src3, src2 = 0;\n\n    uint32_t out0, out1, out2, out3;\n\n    v16u8 src_top;\n\n    v8u16 add;\n\n    v4u32 sum;\n\n\n\n    src_top = LD_UB(src - stride);\n\n    add = __msa_hadd_u_h((v16u8) src_top, (v16u8) src_top);\n\n    sum = __msa_hadd_u_w(add, add);\n\n    src0 = __msa_copy_u_w((v4i32) sum, 0);\n\n    src1 = __msa_copy_u_w((v4i32) sum, 1);\n\n\n\n    for (lp_cnt = 0; lp_cnt < 4; lp_cnt++) {\n\n        src0 += src[lp_cnt * stride - 1];\n\n        src2 += src[(4 + lp_cnt) * stride - 1];\n\n    }\n\n\n\n    src0 = (src0 + 4) >> 3;\n\n    src3 = (src1 + src2 + 4) >> 3;\n\n    src1 = (src1 + 2) >> 2;\n\n    src2 = (src2 + 2) >> 2;\n\n    out0 = src0 * 0x01010101;\n\n    out1 = src1 * 0x01010101;\n\n    out2 = src2 * 0x01010101;\n\n    out3 = src3 * 0x01010101;\n\n\n\n    for (lp_cnt = 4; lp_cnt--;) {\n\n        SW(out0, src);\n\n        SW(out1, (src + 4));\n\n        SW(out2, (src + 4 * stride));\n\n        SW(out3, (src + 4 * stride + 4));\n\n        src += stride;\n\n    }\n\n}\n", "idx": 23631}
{"project": "FFmpeg", "commit_id": "357282c6f3c990833d0508c234ac4522d536c4ac", "target": 1, "func": "static int init_poc(H264Context *h){\n\n    MpegEncContext * const s = &h->s;\n\n    const int max_frame_num= 1<<h->sps.log2_max_frame_num;\n\n    int field_poc[2];\n\n\n\n    h->frame_num_offset= h->prev_frame_num_offset;\n\n    if(h->frame_num < h->prev_frame_num)\n\n        h->frame_num_offset += max_frame_num;\n\n\n\n    if(h->sps.poc_type==0){\n\n        const int max_poc_lsb= 1<<h->sps.log2_max_poc_lsb;\n\n\n\n        if     (h->poc_lsb < h->prev_poc_lsb && h->prev_poc_lsb - h->poc_lsb >= max_poc_lsb/2)\n\n            h->poc_msb = h->prev_poc_msb + max_poc_lsb;\n\n        else if(h->poc_lsb > h->prev_poc_lsb && h->prev_poc_lsb - h->poc_lsb < -max_poc_lsb/2)\n\n            h->poc_msb = h->prev_poc_msb - max_poc_lsb;\n\n        else\n\n            h->poc_msb = h->prev_poc_msb;\n\n//printf(\"poc: %d %d\\n\", h->poc_msb, h->poc_lsb);\n\n        field_poc[0] =\n\n        field_poc[1] = h->poc_msb + h->poc_lsb;\n\n        if(s->picture_structure == PICT_FRAME)\n\n            field_poc[1] += h->delta_poc_bottom;\n\n    }else if(h->sps.poc_type==1){\n\n        int abs_frame_num, expected_delta_per_poc_cycle, expectedpoc;\n\n        int i;\n\n\n\n        if(h->sps.poc_cycle_length != 0)\n\n            abs_frame_num = h->frame_num_offset + h->frame_num;\n\n        else\n\n            abs_frame_num = 0;\n\n\n\n        if(h->nal_ref_idc==0 && abs_frame_num > 0)\n\n            abs_frame_num--;\n\n\n\n        expected_delta_per_poc_cycle = 0;\n\n        for(i=0; i < h->sps.poc_cycle_length; i++)\n\n            expected_delta_per_poc_cycle += h->sps.offset_for_ref_frame[ i ]; //FIXME integrate during sps parse\n\n\n\n        if(abs_frame_num > 0){\n\n            int poc_cycle_cnt          = (abs_frame_num - 1) / h->sps.poc_cycle_length;\n\n            int frame_num_in_poc_cycle = (abs_frame_num - 1) % h->sps.poc_cycle_length;\n\n\n\n            expectedpoc = poc_cycle_cnt * expected_delta_per_poc_cycle;\n\n            for(i = 0; i <= frame_num_in_poc_cycle; i++)\n\n                expectedpoc = expectedpoc + h->sps.offset_for_ref_frame[ i ];\n\n        } else\n\n            expectedpoc = 0;\n\n\n\n        if(h->nal_ref_idc == 0)\n\n            expectedpoc = expectedpoc + h->sps.offset_for_non_ref_pic;\n\n\n\n        field_poc[0] = expectedpoc + h->delta_poc[0];\n\n        field_poc[1] = field_poc[0] + h->sps.offset_for_top_to_bottom_field;\n\n\n\n        if(s->picture_structure == PICT_FRAME)\n\n            field_poc[1] += h->delta_poc[1];\n\n    }else{\n\n        int poc= 2*(h->frame_num_offset + h->frame_num);\n\n\n\n        if(!h->nal_ref_idc)\n\n            poc--;\n\n\n\n        field_poc[0]= poc;\n\n        field_poc[1]= poc;\n\n    }\n\n\n\n    if(s->picture_structure != PICT_BOTTOM_FIELD) {\n\n        s->current_picture_ptr->field_poc[0]= field_poc[0];\n\n        s->current_picture_ptr->poc = field_poc[0];\n\n    }\n\n    if(s->picture_structure != PICT_TOP_FIELD) {\n\n        s->current_picture_ptr->field_poc[1]= field_poc[1];\n\n        s->current_picture_ptr->poc = field_poc[1];\n\n    }\n\n    if(!FIELD_PICTURE || !s->first_field) {\n\n        Picture *cur = s->current_picture_ptr;\n\n        cur->poc= FFMIN(cur->field_poc[0], cur->field_poc[1]);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23632}
{"project": "FFmpeg", "commit_id": "5e268633d17ccfe99955af95f5b60fc4f983a7b2", "target": 1, "func": "static int avui_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n\n                             const AVFrame *pic, int *got_packet)\n\n{\n\n    uint8_t *dst, *src = pic->data[0];\n\n    int i, j, skip, ret, size, interlaced;\n\n\n\n    interlaced = avctx->field_order > AV_FIELD_PROGRESSIVE;\n\n\n\n    if (avctx->height == 486) {\n\n        skip = 10;\n\n    } else {\n\n        skip = 16;\n\n    }\n\n    size = 2 * avctx->width * (avctx->height + skip) + 8 * interlaced;\n\n    if ((ret = ff_alloc_packet2(avctx, pkt, size)) < 0)\n\n        return ret;\n\n    dst = pkt->data;\n\n    if (!(avctx->extradata = av_mallocz(24 + FF_INPUT_BUFFER_PADDING_SIZE)))\n\n        return AVERROR(ENOMEM);\n\n    avctx->extradata_size = 24;\n\n    memcpy(avctx->extradata, \"\\0\\0\\0\\x18\"\"APRGAPRG0001\", 16);\n\n    if (interlaced) {\n\n        avctx->extradata[19] = 2;\n\n    } else {\n\n        avctx->extradata[19] = 1;\n\n        dst += avctx->width * skip;\n\n    }\n\n\n\n    avctx->coded_frame->reference = 0;\n\n    avctx->coded_frame->key_frame = 1;\n\n    avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    for (i = 0; i <= interlaced; i++) {\n\n        if (interlaced && avctx->height == 486) {\n\n            src = pic->data[0] + (1 - i) * pic->linesize[0];\n\n        } else {\n\n            src = pic->data[0] + i * pic->linesize[0];\n\n        }\n\n        dst += avctx->width * skip + 4 * i;\n\n        for (j = 0; j < avctx->height; j += interlaced + 1) {\n\n            memcpy(dst, src, avctx->width * 2);\n\n            src += (interlaced + 1) * pic->linesize[0];\n\n            dst += avctx->width * 2;\n\n        }\n\n    }\n\n\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n\n    *got_packet = 1;\n\n    return 0;\n\n}\n", "idx": 23635}
{"project": "FFmpeg", "commit_id": "3ca5df36a50e3ffd3b24734725bf545617a627a8", "target": 1, "func": "static int decode_subframe(WmallDecodeCtx *s)\n\n{\n\n    int offset        = s->samples_per_frame;\n\n    int subframe_len  = s->samples_per_frame;\n\n    int total_samples = s->samples_per_frame * s->num_channels;\n\n    int i, j, rawpcm_tile, padding_zeroes, res;\n\n\n\n    s->subframe_offset = get_bits_count(&s->gb);\n\n\n\n    /* reset channel context and find the next block offset and size\n\n        == the next block of the channel with the smallest number of\n\n        decoded samples */\n\n    for (i = 0; i < s->num_channels; i++) {\n\n        if (offset > s->channel[i].decoded_samples) {\n\n            offset = s->channel[i].decoded_samples;\n\n            subframe_len =\n\n                s->channel[i].subframe_len[s->channel[i].cur_subframe];\n\n        }\n\n    }\n\n\n\n    /* get a list of all channels that contain the estimated block */\n\n    s->channels_for_cur_subframe = 0;\n\n    for (i = 0; i < s->num_channels; i++) {\n\n        const int cur_subframe = s->channel[i].cur_subframe;\n\n        /* subtract already processed samples */\n\n        total_samples -= s->channel[i].decoded_samples;\n\n\n\n        /* and count if there are multiple subframes that match our profile */\n\n        if (offset == s->channel[i].decoded_samples &&\n\n            subframe_len == s->channel[i].subframe_len[cur_subframe]) {\n\n            total_samples -= s->channel[i].subframe_len[cur_subframe];\n\n            s->channel[i].decoded_samples +=\n\n                s->channel[i].subframe_len[cur_subframe];\n\n            s->channel_indexes_for_cur_subframe[s->channels_for_cur_subframe] = i;\n\n            ++s->channels_for_cur_subframe;\n\n        }\n\n    }\n\n\n\n    /* check if the frame will be complete after processing the\n\n        estimated block */\n\n    if (!total_samples)\n\n        s->parsed_all_subframes = 1;\n\n\n\n\n\n    s->seekable_tile = get_bits1(&s->gb);\n\n    if (s->seekable_tile) {\n\n        clear_codec_buffers(s);\n\n\n\n        s->do_arith_coding    = get_bits1(&s->gb);\n\n        if (s->do_arith_coding) {\n\n            avpriv_request_sample(s->avctx, \"Arithmetic coding\");\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n        s->do_ac_filter       = get_bits1(&s->gb);\n\n        s->do_inter_ch_decorr = get_bits1(&s->gb);\n\n        s->do_mclms           = get_bits1(&s->gb);\n\n\n\n        if (s->do_ac_filter)\n\n            decode_ac_filter(s);\n\n\n\n        if (s->do_mclms)\n\n            decode_mclms(s);\n\n\n\n        if ((res = decode_cdlms(s)) < 0)\n\n            return res;\n\n        s->movave_scaling = get_bits(&s->gb, 3);\n\n        s->quant_stepsize = get_bits(&s->gb, 8) + 1;\n\n\n\n        reset_codec(s);\n\n    } else if (!s->cdlms[0][0].order) {\n\n        av_log(s->avctx, AV_LOG_DEBUG,\n\n               \"Waiting for seekable tile\\n\");\n\n        s->frame.nb_samples = 0;\n\n        return -1;\n\n    }\n\n\n\n    rawpcm_tile = get_bits1(&s->gb);\n\n\n\n    for (i = 0; i < s->num_channels; i++)\n\n        s->is_channel_coded[i] = 1;\n\n\n\n    if (!rawpcm_tile) {\n\n        for (i = 0; i < s->num_channels; i++)\n\n            s->is_channel_coded[i] = get_bits1(&s->gb);\n\n\n\n        if (s->bV3RTM) {\n\n            // LPC\n\n            s->do_lpc = get_bits1(&s->gb);\n\n            if (s->do_lpc) {\n\n                decode_lpc(s);\n\n                avpriv_request_sample(s->avctx, \"Expect wrong output since \"\n\n                                      \"inverse LPC filter\");\n\n            }\n\n        } else\n\n            s->do_lpc = 0;\n\n    }\n\n\n\n\n\n    if (get_bits1(&s->gb))\n\n        padding_zeroes = get_bits(&s->gb, 5);\n\n    else\n\n        padding_zeroes = 0;\n\n\n\n    if (rawpcm_tile) {\n\n        int bits = s->bits_per_sample - padding_zeroes;\n\n        if (bits <= 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Invalid number of padding bits in raw PCM tile\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        av_dlog(s->avctx, \"RAWPCM %d bits per sample. \"\n\n                \"total %d bits, remain=%d\\n\", bits,\n\n                bits * s->num_channels * subframe_len, get_bits_count(&s->gb));\n\n        for (i = 0; i < s->num_channels; i++)\n\n            for (j = 0; j < subframe_len; j++)\n\n                s->channel_coeffs[i][j] = get_sbits(&s->gb, bits);\n\n    } else {\n\n        for (i = 0; i < s->num_channels; i++)\n\n            if (s->is_channel_coded[i]) {\n\n                decode_channel_residues(s, i, subframe_len);\n\n                if (s->seekable_tile)\n\n                    use_high_update_speed(s, i);\n\n                else\n\n                    use_normal_update_speed(s, i);\n\n                revert_cdlms(s, i, 0, subframe_len);\n\n            } else {\n\n                memset(s->channel_residues[i], 0, sizeof(**s->channel_residues) * subframe_len);\n\n            }\n\n    }\n\n    if (s->do_mclms)\n\n        revert_mclms(s, subframe_len);\n\n    if (s->do_inter_ch_decorr)\n\n        revert_inter_ch_decorr(s, subframe_len);\n\n    if (s->do_ac_filter)\n\n        revert_acfilter(s, subframe_len);\n\n\n\n    /* Dequantize */\n\n    if (s->quant_stepsize != 1)\n\n        for (i = 0; i < s->num_channels; i++)\n\n            for (j = 0; j < subframe_len; j++)\n\n                s->channel_residues[i][j] *= s->quant_stepsize;\n\n\n\n    /* Write to proper output buffer depending on bit-depth */\n\n    for (i = 0; i < s->channels_for_cur_subframe; i++) {\n\n        int c = s->channel_indexes_for_cur_subframe[i];\n\n        int subframe_len = s->channel[c].subframe_len[s->channel[c].cur_subframe];\n\n\n\n        for (j = 0; j < subframe_len; j++) {\n\n            if (s->bits_per_sample == 16) {\n\n                *s->samples_16[c]++ = (int16_t) s->channel_residues[c][j] << padding_zeroes;\n\n            } else {\n\n                *s->samples_32[c]++ = s->channel_residues[c][j] << padding_zeroes;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* handled one subframe */\n\n    for (i = 0; i < s->channels_for_cur_subframe; i++) {\n\n        int c = s->channel_indexes_for_cur_subframe[i];\n\n        if (s->channel[c].cur_subframe >= s->channel[c].num_subframes) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"broken subframe\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        ++s->channel[c].cur_subframe;\n\n    }\n\n    return 0;\n\n}\n", "idx": 23636}
{"project": "FFmpeg", "commit_id": "1b9ca38d9d06d319fffd61d27e4eb385d6572ba8", "target": 1, "func": "int av_resample(AVResampleContext *c, short *dst, short *src, int *consumed, int src_size, int dst_size, int update_ctx){\n\n    int dst_index, i;\n\n    int index= c->index;\n\n    int frac= c->frac;\n\n    int dst_incr_frac= c->dst_incr % c->src_incr;\n\n    int dst_incr=      c->dst_incr / c->src_incr;\n\n    int compensation_distance= c->compensation_distance;\n\n\n\n  if(compensation_distance == 0 && c->filter_length == 1 && c->phase_shift==0){\n\n        int64_t index2= ((int64_t)index)<<32;\n\n        int64_t incr= (1LL<<32) * c->dst_incr / c->src_incr;\n\n        dst_size= FFMIN(dst_size, (src_size-1-index) * (int64_t)c->src_incr / c->dst_incr);\n\n\n\n        for(dst_index=0; dst_index < dst_size; dst_index++){\n\n            dst[dst_index] = src[index2>>32];\n\n            index2 += incr;\n\n        }\n\n        frac += dst_index * dst_incr_frac;\n\n        index += dst_index * dst_incr;\n\n        index += frac / c->src_incr;\n\n        frac %= c->src_incr;\n\n  }else{\n\n    for(dst_index=0; dst_index < dst_size; dst_index++){\n\n        FELEM *filter= c->filter_bank + c->filter_length*(index & c->phase_mask);\n\n        int sample_index= index >> c->phase_shift;\n\n        FELEM2 val=0;\n\n\n\n        if(sample_index < 0){\n\n            for(i=0; i<c->filter_length; i++)\n\n                val += src[FFABS(sample_index + i) % src_size] * filter[i];\n\n        }else if(sample_index + c->filter_length > src_size){\n\n            break;\n\n        }else if(c->linear){\n\n            FELEM2 v2=0;\n\n            for(i=0; i<c->filter_length; i++){\n\n                val += src[sample_index + i] * (FELEM2)filter[i];\n\n                v2  += src[sample_index + i] * (FELEM2)filter[i + c->filter_length];\n\n            }\n\n            val+=(v2-val)*(FELEML)frac / c->src_incr;\n\n        }else{\n\n            for(i=0; i<c->filter_length; i++){\n\n                val += src[sample_index + i] * (FELEM2)filter[i];\n\n            }\n\n        }\n\n\n\n#ifdef CONFIG_RESAMPLE_AUDIOPHILE_KIDDY_MODE\n\n        dst[dst_index] = av_clip_int16(lrintf(val));\n\n#else\n\n        val = (val + (1<<(FILTER_SHIFT-1)))>>FILTER_SHIFT;\n\n        dst[dst_index] = (unsigned)(val + 32768) > 65535 ? (val>>31) ^ 32767 : val;\n\n#endif\n\n\n\n        frac += dst_incr_frac;\n\n        index += dst_incr;\n\n        if(frac >= c->src_incr){\n\n            frac -= c->src_incr;\n\n            index++;\n\n        }\n\n\n\n        if(dst_index + 1 == compensation_distance){\n\n            compensation_distance= 0;\n\n            dst_incr_frac= c->ideal_dst_incr % c->src_incr;\n\n            dst_incr=      c->ideal_dst_incr / c->src_incr;\n\n        }\n\n    }\n\n  }\n\n    *consumed= FFMAX(index, 0) >> c->phase_shift;\n\n    if(index>=0) index &= c->phase_mask;\n\n\n\n    if(compensation_distance){\n\n        compensation_distance -= dst_index;\n\n        assert(compensation_distance > 0);\n\n    }\n\n    if(update_ctx){\n\n        c->frac= frac;\n\n        c->index= index;\n\n        c->dst_incr= dst_incr_frac + c->src_incr*dst_incr;\n\n        c->compensation_distance= compensation_distance;\n\n    }\n\n#if 0\n\n    if(update_ctx && !c->compensation_distance){\n\n#undef rand\n\n        av_resample_compensate(c, rand() % (8000*2) - 8000, 8000*2);\n\nav_log(NULL, AV_LOG_DEBUG, \"%d %d %d\\n\", c->dst_incr, c->ideal_dst_incr, c->compensation_distance);\n\n    }\n\n#endif\n\n\n\n    return dst_index;\n\n}\n", "idx": 23639}
{"project": "FFmpeg", "commit_id": "2caf19e90f270abe1e80a3e85acaf0eb5c9d0aac", "target": 1, "func": "static void FUNCC(pred4x4_128_dc)(uint8_t *_src, const uint8_t *topright, int _stride){\n\n    pixel *src = (pixel*)_src;\n\n    int stride = _stride/sizeof(pixel);\n\n    ((pixel4*)(src+0*stride))[0]=\n\n    ((pixel4*)(src+1*stride))[0]=\n\n    ((pixel4*)(src+2*stride))[0]=\n\n    ((pixel4*)(src+3*stride))[0]= PIXEL_SPLAT_X4(1<<(BIT_DEPTH-1));\n\n}\n", "idx": 23640}
{"project": "FFmpeg", "commit_id": "1bab6f852c7ca433285d19f65c701885fa69cc57", "target": 1, "func": "static void RENAME(yuv2rgb565_1)(SwsContext *c, const int16_t *buf0,\n\n                                 const int16_t *ubuf[2], const int16_t *bguf[2],\n\n                                 const int16_t *abuf0, uint8_t *dest,\n\n                                 int dstW, int uvalpha, int y)\n\n{\n\n    const int16_t *ubuf0 = ubuf[0], *ubuf1 = ubuf[1];\n\n    const int16_t *buf1= buf0; //FIXME needed for RGB1/BGR1\n\n\n\n    if (uvalpha < 2048) { // note this is not correct (shifts chrominance by 0.5 pixels) but it is a bit faster\n\n        __asm__ volatile(\n\n            \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n            \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n            \"push %%\"REG_BP\"                        \\n\\t\"\n\n            YSCALEYUV2RGB1(%%REGBP, %5)\n\n            \"pxor    %%mm7, %%mm7                   \\n\\t\"\n\n            /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n            \"paddusb \"BLUE_DITHER\"(%5), %%mm2      \\n\\t\"\n\n            \"paddusb \"GREEN_DITHER\"(%5), %%mm4      \\n\\t\"\n\n            \"paddusb \"RED_DITHER\"(%5), %%mm5      \\n\\t\"\n\n#endif\n\n            WRITERGB16(%%REGb, 8280(%5), %%REGBP)\n\n            \"pop %%\"REG_BP\"                         \\n\\t\"\n\n            \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n            :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n               \"a\" (&c->redDither)\n\n        );\n\n    } else {\n\n        __asm__ volatile(\n\n            \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n            \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n            \"push %%\"REG_BP\"                        \\n\\t\"\n\n            YSCALEYUV2RGB1b(%%REGBP, %5)\n\n            \"pxor    %%mm7, %%mm7                   \\n\\t\"\n\n            /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n            \"paddusb \"BLUE_DITHER\"(%5), %%mm2      \\n\\t\"\n\n            \"paddusb \"GREEN_DITHER\"(%5), %%mm4      \\n\\t\"\n\n            \"paddusb \"RED_DITHER\"(%5), %%mm5      \\n\\t\"\n\n#endif\n\n            WRITERGB16(%%REGb, 8280(%5), %%REGBP)\n\n            \"pop %%\"REG_BP\"                         \\n\\t\"\n\n            \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n            :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n               \"a\" (&c->redDither)\n\n        );\n\n    }\n\n}\n", "idx": 23643}
{"project": "FFmpeg", "commit_id": "46e407554968e7258c874f4caf517172ffa285cf", "target": 1, "func": "int ff_dirac_golomb_read_16bit(DiracGolombLUT *lut_ctx, const uint8_t *buf,\n                               int bytes, uint8_t *_dst, int coeffs)\n{\n    int i, b, c_idx = 0;\n    int16_t *dst = (int16_t *)_dst;\n    DiracGolombLUT *future[4], *l = &lut_ctx[2*LUT_SIZE + buf[0]];\n    INIT_RESIDUE(res);\n    for (b = 1; b <= bytes; b++) {\n        future[0] = &lut_ctx[buf[b]];\n        future[1] = future[0] + 1*LUT_SIZE;\n        future[2] = future[0] + 2*LUT_SIZE;\n        future[3] = future[0] + 3*LUT_SIZE;\n        if ((c_idx + 1) > coeffs)\n            return c_idx;\n        if (res_bits && l->sign) {\n            int32_t coeff = 1;\n            APPEND_RESIDUE(res, l->preamble);\n            for (i = 0; i < (res_bits >> 1) - 1; i++) {\n                coeff <<= 1;\n                coeff |= (res >> (RSIZE_BITS - 2*i - 2)) & 1;\n            }\n            dst[c_idx++] = l->sign * (coeff - 1);\n        }\n        for (i = 0; i < LUT_BITS; i++)\n            dst[c_idx + i] = l->ready[i];\n        c_idx += l->ready_num;\n        APPEND_RESIDUE(res, l->leftover);\n        l = future[l->need_s ? 3 : !res_bits ? 2 : res_bits & 1];\n    }\n    return c_idx;\n}", "idx": 23644}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "void ff_add_pixels_clamped_c(const DCTELEM *block, uint8_t *restrict pixels,\n\n                             int line_size)\n\n{\n\n    int i;\n\n    uint8_t *cm = ff_cropTbl + MAX_NEG_CROP;\n\n\n\n    /* read the pixels */\n\n    for(i=0;i<8;i++) {\n\n        pixels[0] = cm[pixels[0] + block[0]];\n\n        pixels[1] = cm[pixels[1] + block[1]];\n\n        pixels[2] = cm[pixels[2] + block[2]];\n\n        pixels[3] = cm[pixels[3] + block[3]];\n\n        pixels[4] = cm[pixels[4] + block[4]];\n\n        pixels[5] = cm[pixels[5] + block[5]];\n\n        pixels[6] = cm[pixels[6] + block[6]];\n\n        pixels[7] = cm[pixels[7] + block[7]];\n\n        pixels += line_size;\n\n        block += 8;\n\n    }\n\n}\n", "idx": 23647}
{"project": "FFmpeg", "commit_id": "a38469e1da7b4829a2fba4279d8420a33f96832e", "target": 0, "func": "void show_help(void)\n\n{\n\n    const OptionDef *po;\n\n    int i, expert;\n\n\n\n    printf(\"ffmpeg version \" FFMPEG_VERSION \", Copyright (c) 2000,2001 Gerard Lantau\\n\"\n\n           \"usage: ffmpeg [[options] -i input_file]... {[options] outfile}...\\n\"\n\n           \"Hyper fast MPEG1/MPEG4/H263/RV and AC3/MPEG audio encoder\\n\"\n\n           \"\\n\"\n\n           \"Main options are:\\n\");\n\n    for(i=0;i<2;i++) {\n\n        if (i == 1)\n\n            printf(\"\\nAdvanced options are:\\n\");\n\n        for(po = options; po->name != NULL; po++) {\n\n            char buf[64];\n\n            expert = (po->flags & OPT_EXPERT) != 0;\n\n            if (expert == i) {\n\n                strcpy(buf, po->name);\n\n                if (po->flags & HAS_ARG) {\n\n                    strcat(buf, \" \");\n\n                    strcat(buf, po->argname);\n\n                }\n\n                printf(\"-%-17s  %s\\n\", buf, po->help);\n\n            }\n\n        }\n\n    }\n\n\n\n    exit(1);\n\n}\n", "idx": 23651}
{"project": "FFmpeg", "commit_id": "229843aa359ae0c9519977d7fa952688db63f559", "target": 0, "func": "static int ftp_shutdown(URLContext *h, int flags)\n\n{\n\n    FTPContext *s = h->priv_data;\n\n\n\n    av_dlog(h, \"ftp protocol shutdown\\n\");\n\n\n\n    if (s->conn_data)\n\n        return ffurl_shutdown(s->conn_data, flags);\n\n\n\n    return AVERROR(EIO);\n\n}\n", "idx": 23652}
{"project": "FFmpeg", "commit_id": "3b199d29cd597a3518136d78860e172060b9e83d", "target": 0, "func": "static av_cold int smc_decode_init(AVCodecContext *avctx)\n\n{\n\n    SmcContext *s = avctx->priv_data;\n\n\n\n    s->avctx = avctx;\n\n    avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n\n\n    s->frame.data[0] = NULL;\n\n\n\n    return 0;\n\n}\n", "idx": 23653}
{"project": "FFmpeg", "commit_id": "e3d2500fe498289a878b956f6efb4995438c9515", "target": 1, "func": "static inline void RENAME(yuv2yuvX)(int16_t *lumFilter, int16_t **lumSrc, int lumFilterSize,\n\n\t\t\t\t    int16_t *chrFilter, int16_t **chrSrc, int chrFilterSize,\n\n\t\t\t\t    uint8_t *dest, uint8_t *uDest, uint8_t *vDest, int dstW,\n\n\t\t\t\t    int16_t * lumMmxFilter, int16_t * chrMmxFilter)\n\n{\n\n#ifdef HAVE_MMX\n\n\tif(uDest != NULL)\n\n\t{\n\n\t\tasm volatile(\n\n\t\t\t\tYSCALEYUV2YV12X(0)\n\n\t\t\t\t:: \"m\" (-chrFilterSize), \"r\" (chrSrc+chrFilterSize),\n\n\t\t\t\t\"r\" (chrMmxFilter+chrFilterSize*4), \"r\" (uDest), \"m\" (dstW>>1)\n\n\t\t\t\t: \"%eax\", \"%edx\", \"%esi\"\n\n\t\t\t);\n\n\n\n\t\tasm volatile(\n\n\t\t\t\tYSCALEYUV2YV12X(4096)\n\n\t\t\t\t:: \"m\" (-chrFilterSize), \"r\" (chrSrc+chrFilterSize),\n\n\t\t\t\t\"r\" (chrMmxFilter+chrFilterSize*4), \"r\" (vDest), \"m\" (dstW>>1)\n\n\t\t\t\t: \"%eax\", \"%edx\", \"%esi\"\n\n\t\t\t);\n\n\t}\n\n\n\n\tasm volatile(\n\n\t\t\tYSCALEYUV2YV12X(0)\n\n\t\t\t:: \"m\" (-lumFilterSize), \"r\" (lumSrc+lumFilterSize),\n\n\t\t\t   \"r\" (lumMmxFilter+lumFilterSize*4), \"r\" (dest), \"m\" (dstW)\n\n\t\t\t: \"%eax\", \"%edx\", \"%esi\"\n\n\t\t);\n\n#else\n\n\t//FIXME Optimize (just quickly writen not opti..)\n\n\tint i;\n\n\tfor(i=0; i<dstW; i++)\n\n\t{\n\n\t\tint val=0;\n\n\t\tint j;\n\n\t\tfor(j=0; j<lumFilterSize; j++)\n\n\t\t\tval += lumSrc[j][i] * lumFilter[j];\n\n\n\n\t\tdest[i]= MIN(MAX(val>>19, 0), 255);\n\n\t}\n\n\n\n\tif(uDest != NULL)\n\n\t\tfor(i=0; i<(dstW>>1); i++)\n\n\t\t{\n\n\t\t\tint u=0;\n\n\t\t\tint v=0;\n\n\t\t\tint j;\n\n\t\t\tfor(j=0; j<lumFilterSize; j++)\n\n\t\t\t{\n\n\t\t\t\tu += chrSrc[j][i] * chrFilter[j];\n\n\t\t\t\tv += chrSrc[j][i + 2048] * chrFilter[j];\n\n\t\t\t}\n\n\n\n\t\t\tuDest[i]= MIN(MAX(u>>19, 0), 255);\n\n\t\t\tvDest[i]= MIN(MAX(v>>19, 0), 255);\n\n\t\t}\n\n#endif\n\n}\n", "idx": 23654}
{"project": "FFmpeg", "commit_id": "341f01290c2353669ed2263f56e1a9f4c67cc597", "target": 1, "func": "static int huff_build12(VLC *vlc, uint8_t *len)\n\n{\n\n    HuffEntry he[4096];\n\n    uint32_t codes[4096];\n\n    uint8_t bits[4096];\n\n    uint16_t syms[4096];\n\n    uint32_t code;\n\n    int i;\n\n\n\n    for (i = 0; i < 4096; i++) {\n\n        he[i].sym = 4095 - i;\n\n        he[i].len = len[i];\n\n        if (len[i] == 0)\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n    AV_QSORT(he, 4096, HuffEntry, huff_cmp_len12);\n\n\n\n    code = 1;\n\n    for (i = 4095; i >= 0; i--) {\n\n        codes[i] = code >> (32 - he[i].len);\n\n        bits[i]  = he[i].len;\n\n        syms[i]  = he[i].sym;\n\n        code += 0x80000000u >> (he[i].len - 1);\n\n    }\n\n\n\n    ff_free_vlc(vlc);\n\n    return ff_init_vlc_sparse(vlc, FFMIN(he[4095].len, 14), 4096,\n\n                              bits,  sizeof(*bits),  sizeof(*bits),\n\n                              codes, sizeof(*codes), sizeof(*codes),\n\n                              syms,  sizeof(*syms),  sizeof(*syms), 0);\n\n}\n", "idx": 23664}
{"project": "FFmpeg", "commit_id": "290e7eb77bee5a54182fb3d5fb122c1e117190da", "target": 1, "func": "void ff_set_fixed_vector(float *out, const AMRFixed *in, float scale, int size)\n\n{\n\n    int i;\n\n\n\n    for (i=0; i < in->n; i++) {\n\n        int x   = in->x[i], repeats = !((in->no_repeat_mask >> i) & 1);\n\n        float y = in->y[i] * scale;\n\n\n\n\n        do {\n\n            out[x] += y;\n\n            y *= in->pitch_fac;\n\n            x += in->pitch_lag;\n\n        } while (x < size && repeats);\n\n    }\n\n}", "idx": 23665}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static int do_bit_allocation(AC3DecodeContext *ctx, int flags)\n\n{\n\n    ac3_audio_block *ab = &ctx->audio_block;\n\n    int i, snroffst = 0;\n\n\n\n    if (!flags) /* bit allocation is not required */\n\n        return 0;\n\n\n\n    if (ab->flags & AC3_AB_SNROFFSTE) { /* check whether snroffsts are zero */\n\n        snroffst += ab->csnroffst;\n\n        if (ab->flags & AC3_AB_CPLINU)\n\n            snroffst += ab->cplfsnroffst;\n\n        for (i = 0; i < ctx->bsi.nfchans; i++)\n\n            snroffst += ab->fsnroffst[i];\n\n        if (ctx->bsi.flags & AC3_BSI_LFEON)\n\n            snroffst += ab->lfefsnroffst;\n\n        if (!snroffst) {\n\n            memset(ab->cplbap, 0, sizeof (ab->cplbap));\n\n            for (i = 0; i < ctx->bsi.nfchans; i++)\n\n                memset(ab->bap[i], 0, sizeof (ab->bap[i]));\n\n            memset(ab->lfebap, 0, sizeof (ab->lfebap));\n\n\n\n            return 0;\n\n        }\n\n    }\n\n\n\n    /* perform bit allocation */\n\n    if ((ab->flags & AC3_AB_CPLINU) && (flags & 64))\n\n        if (_do_bit_allocation(ctx, 5))\n\n            return -1;\n\n    for (i = 0; i < ctx->bsi.nfchans; i++)\n\n        if (flags & (1 << i))\n\n            if (_do_bit_allocation(ctx, i))\n\n                return -1;\n\n    if ((ctx->bsi.flags & AC3_BSI_LFEON) && (flags & 32))\n\n        if (_do_bit_allocation(ctx, 6))\n\n            return -1;\n\n\n\n    return 0;\n\n}\n", "idx": 23668}
{"project": "FFmpeg", "commit_id": "65d999d6cfc4190f26156a0878d1599d9085c7e9", "target": 0, "func": "int avcodec_default_get_buffer(AVCodecContext *s, AVFrame *pic){\n\n    int i;\n\n    int w= s->width;\n\n    int h= s->height;\n\n    InternalBuffer *buf;\n\n    int *picture_number;\n\n\n\n    assert(pic->data[0]==NULL);\n\n    assert(INTERNAL_BUFFER_SIZE > s->internal_buffer_count);\n\n\n\n    if(avcodec_check_dimensions(s,w,h))\n\n        return -1;\n\n\n\n    if(s->internal_buffer==NULL){\n\n        s->internal_buffer= av_mallocz(INTERNAL_BUFFER_SIZE*sizeof(InternalBuffer));\n\n    }\n\n#if 0\n\n    s->internal_buffer= av_fast_realloc(\n\n        s->internal_buffer,\n\n        &s->internal_buffer_size,\n\n        sizeof(InternalBuffer)*FFMAX(99,  s->internal_buffer_count+1)/*FIXME*/\n\n        );\n\n#endif\n\n\n\n    buf= &((InternalBuffer*)s->internal_buffer)[s->internal_buffer_count];\n\n    picture_number= &(((InternalBuffer*)s->internal_buffer)[INTERNAL_BUFFER_SIZE-1]).last_pic_num; //FIXME ugly hack\n\n    (*picture_number)++;\n\n\n\n    if(buf->base[0]){\n\n        pic->age= *picture_number - buf->last_pic_num;\n\n        buf->last_pic_num= *picture_number;\n\n    }else{\n\n        int h_chroma_shift, v_chroma_shift;\n\n        int pixel_size, size[3];\n\n        AVPicture picture;\n\n\n\n        avcodec_get_chroma_sub_sample(s->pix_fmt, &h_chroma_shift, &v_chroma_shift);\n\n\n\n        avcodec_align_dimensions(s, &w, &h);\n\n\n\n        if(!(s->flags&CODEC_FLAG_EMU_EDGE)){\n\n            w+= EDGE_WIDTH*2;\n\n            h+= EDGE_WIDTH*2;\n\n        }\n\n        avpicture_fill(&picture, NULL, s->pix_fmt, w, h);\n\n        pixel_size= picture.linesize[0]*8 / w;\n\n//av_log(NULL, AV_LOG_ERROR, \"%d %d %d %d\\n\", (int)picture.data[1], w, h, s->pix_fmt);\n\n        assert(pixel_size>=1);\n\n            //FIXME next ensures that linesize= 2^x uvlinesize, thats needed because some MC code assumes it\n\n        if(pixel_size == 3*8)\n\n            w= ALIGN(w, STRIDE_ALIGN<<h_chroma_shift);\n\n        else\n\n            w= ALIGN(pixel_size*w, STRIDE_ALIGN<<(h_chroma_shift+3)) / pixel_size;\n\n        size[1] = avpicture_fill(&picture, NULL, s->pix_fmt, w, h);\n\n        size[0] = picture.linesize[0] * h;\n\n        size[1] -= size[0];\n\n        if(picture.data[2])\n\n            size[1]= size[2]= size[1]/2;\n\n        else\n\n            size[2]= 0;\n\n\n\n        buf->last_pic_num= -256*256*256*64;\n\n        memset(buf->base, 0, sizeof(buf->base));\n\n        memset(buf->data, 0, sizeof(buf->data));\n\n\n\n        for(i=0; i<3 && size[i]; i++){\n\n            const int h_shift= i==0 ? 0 : h_chroma_shift;\n\n            const int v_shift= i==0 ? 0 : v_chroma_shift;\n\n\n\n            buf->linesize[i]= picture.linesize[i];\n\n\n\n            buf->base[i]= av_malloc(size[i]+16); //FIXME 16\n\n            if(buf->base[i]==NULL) return -1;\n\n            memset(buf->base[i], 128, size[i]);\n\n\n\n            // no edge if EDEG EMU or not planar YUV, we check for PAL8 redundantly to protect against a exploitable bug regression ...\n\n            if((s->flags&CODEC_FLAG_EMU_EDGE) || (s->pix_fmt == PIX_FMT_PAL8) || !size[2])\n\n                buf->data[i] = buf->base[i];\n\n            else\n\n                buf->data[i] = buf->base[i] + ALIGN((buf->linesize[i]*EDGE_WIDTH>>v_shift) + (EDGE_WIDTH>>h_shift), STRIDE_ALIGN);\n\n        }\n\n        pic->age= 256*256*256*64;\n\n    }\n\n    pic->type= FF_BUFFER_TYPE_INTERNAL;\n\n\n\n    for(i=0; i<4; i++){\n\n        pic->base[i]= buf->base[i];\n\n        pic->data[i]= buf->data[i];\n\n        pic->linesize[i]= buf->linesize[i];\n\n    }\n\n    s->internal_buffer_count++;\n\n\n\n    return 0;\n\n}\n", "idx": 23669}
{"project": "FFmpeg", "commit_id": "fe53fa253f4a54f715249f0d88f7320ae0f65df5", "target": 1, "func": "matroska_add_stream (MatroskaDemuxContext *matroska)\n\n{\n\n    int res = 0;\n\n    uint32_t id;\n\n    MatroskaTrack *track;\n\n\n\n    av_log(matroska->ctx, AV_LOG_DEBUG, \"parsing track, adding stream..,\\n\");\n\n\n\n    /* Allocate a generic track. As soon as we know its type we'll realloc. */\n\n    track = av_mallocz(MAX_TRACK_SIZE);\n\n    matroska->num_tracks++;\n\n    strcpy(track->language, \"eng\");\n\n\n\n    /* start with the master */\n\n    if ((res = ebml_read_master(matroska, &id)) < 0)\n\n        return res;\n\n\n\n    /* try reading the trackentry headers */\n\n    while (res == 0) {\n\n        if (!(id = ebml_peek_id(matroska, &matroska->level_up))) {\n\n            res = AVERROR(EIO);\n\n            break;\n\n        } else if (matroska->level_up > 0) {\n\n            matroska->level_up--;\n\n            break;\n\n        }\n\n\n\n        switch (id) {\n\n            /* track number (unique stream ID) */\n\n            case MATROSKA_ID_TRACKNUMBER: {\n\n                uint64_t num;\n\n                if ((res = ebml_read_uint(matroska, &id, &num)) < 0)\n\n                    break;\n\n                track->num = num;\n\n                break;\n\n            }\n\n\n\n            /* track UID (unique identifier) */\n\n            case MATROSKA_ID_TRACKUID: {\n\n                uint64_t num;\n\n                if ((res = ebml_read_uint(matroska, &id, &num)) < 0)\n\n                    break;\n\n                track->uid = num;\n\n                break;\n\n            }\n\n\n\n            /* track type (video, audio, combined, subtitle, etc.) */\n\n            case MATROSKA_ID_TRACKTYPE: {\n\n                uint64_t num;\n\n                if ((res = ebml_read_uint(matroska, &id, &num)) < 0)\n\n                    break;\n\n                if (track->type && track->type != num) {\n\n                    av_log(matroska->ctx, AV_LOG_INFO,\n\n                           \"More than one tracktype in an entry - skip\\n\");\n\n                    break;\n\n                }\n\n                track->type = num;\n\n\n\n                switch (track->type) {\n\n                    case MATROSKA_TRACK_TYPE_VIDEO:\n\n                    case MATROSKA_TRACK_TYPE_AUDIO:\n\n                    case MATROSKA_TRACK_TYPE_SUBTITLE:\n\n                        break;\n\n                    case MATROSKA_TRACK_TYPE_COMPLEX:\n\n                    case MATROSKA_TRACK_TYPE_LOGO:\n\n                    case MATROSKA_TRACK_TYPE_CONTROL:\n\n                    default:\n\n                        av_log(matroska->ctx, AV_LOG_INFO,\n\n                               \"Unknown or unsupported track type 0x%x\\n\",\n\n                               track->type);\n\n                        track->type = MATROSKA_TRACK_TYPE_NONE;\n\n                        break;\n\n                }\n\n                matroska->tracks[matroska->num_tracks - 1] = track;\n\n                break;\n\n            }\n\n\n\n            /* tracktype specific stuff for video */\n\n            case MATROSKA_ID_TRACKVIDEO: {\n\n                MatroskaVideoTrack *videotrack;\n\n                if (!track->type)\n\n                    track->type = MATROSKA_TRACK_TYPE_VIDEO;\n\n                if (track->type != MATROSKA_TRACK_TYPE_VIDEO) {\n\n                    av_log(matroska->ctx, AV_LOG_INFO,\n\n                           \"video data in non-video track - ignoring\\n\");\n\n                    res = AVERROR_INVALIDDATA;\n\n                    break;\n\n                } else if ((res = ebml_read_master(matroska, &id)) < 0)\n\n                    break;\n\n                videotrack = (MatroskaVideoTrack *)track;\n\n\n\n                while (res == 0) {\n\n                    if (!(id = ebml_peek_id(matroska, &matroska->level_up))) {\n\n                        res = AVERROR(EIO);\n\n                        break;\n\n                    } else if (matroska->level_up > 0) {\n\n                        matroska->level_up--;\n\n                        break;\n\n                    }\n\n\n\n                    switch (id) {\n\n                        /* fixme, this should be one-up, but I get it here */\n\n                        case MATROSKA_ID_TRACKDEFAULTDURATION: {\n\n                            uint64_t num;\n\n                            if ((res = ebml_read_uint (matroska, &id,\n\n                                                       &num)) < 0)\n\n                                break;\n\n                            track->default_duration = num;\n\n                            break;\n\n                        }\n\n\n\n                        /* video framerate */\n\n                        case MATROSKA_ID_VIDEOFRAMERATE: {\n\n                            double num;\n\n                            if ((res = ebml_read_float(matroska, &id,\n\n                                                       &num)) < 0)\n\n                                break;\n\n                            if (!track->default_duration)\n\n                                track->default_duration = 1000000000/num;\n\n                            break;\n\n                        }\n\n\n\n                        /* width of the size to display the video at */\n\n                        case MATROSKA_ID_VIDEODISPLAYWIDTH: {\n\n                            uint64_t num;\n\n                            if ((res = ebml_read_uint(matroska, &id,\n\n                                                      &num)) < 0)\n\n                                break;\n\n                            videotrack->display_width = num;\n\n                            break;\n\n                        }\n\n\n\n                        /* height of the size to display the video at */\n\n                        case MATROSKA_ID_VIDEODISPLAYHEIGHT: {\n\n                            uint64_t num;\n\n                            if ((res = ebml_read_uint(matroska, &id,\n\n                                                      &num)) < 0)\n\n                                break;\n\n                            videotrack->display_height = num;\n\n                            break;\n\n                        }\n\n\n\n                        /* width of the video in the file */\n\n                        case MATROSKA_ID_VIDEOPIXELWIDTH: {\n\n                            uint64_t num;\n\n                            if ((res = ebml_read_uint(matroska, &id,\n\n                                                      &num)) < 0)\n\n                                break;\n\n                            videotrack->pixel_width = num;\n\n                            break;\n\n                        }\n\n\n\n                        /* height of the video in the file */\n\n                        case MATROSKA_ID_VIDEOPIXELHEIGHT: {\n\n                            uint64_t num;\n\n                            if ((res = ebml_read_uint(matroska, &id,\n\n                                                      &num)) < 0)\n\n                                break;\n\n                            videotrack->pixel_height = num;\n\n                            break;\n\n                        }\n\n\n\n                        /* whether the video is interlaced */\n\n                        case MATROSKA_ID_VIDEOFLAGINTERLACED: {\n\n                            uint64_t num;\n\n                            if ((res = ebml_read_uint(matroska, &id,\n\n                                                      &num)) < 0)\n\n                                break;\n\n                            if (num)\n\n                                track->flags |=\n\n                                    MATROSKA_VIDEOTRACK_INTERLACED;\n\n                            else\n\n                                track->flags &=\n\n                                    ~MATROSKA_VIDEOTRACK_INTERLACED;\n\n                            break;\n\n                        }\n\n\n\n                        /* stereo mode (whether the video has two streams,\n\n                         * where one is for the left eye and the other for\n\n                         * the right eye, which creates a 3D-like\n\n                         * effect) */\n\n                        case MATROSKA_ID_VIDEOSTEREOMODE: {\n\n                            uint64_t num;\n\n                            if ((res = ebml_read_uint(matroska, &id,\n\n                                                      &num)) < 0)\n\n                                break;\n\n                            if (num != MATROSKA_EYE_MODE_MONO &&\n\n                                num != MATROSKA_EYE_MODE_LEFT &&\n\n                                num != MATROSKA_EYE_MODE_RIGHT &&\n\n                                num != MATROSKA_EYE_MODE_BOTH) {\n\n                                av_log(matroska->ctx, AV_LOG_INFO,\n\n                                       \"Ignoring unknown eye mode 0x%x\\n\",\n\n                                       (uint32_t) num);\n\n                                break;\n\n                            }\n\n                            videotrack->eye_mode = num;\n\n                            break;\n\n                        }\n\n\n\n                        /* aspect ratio behaviour */\n\n                        case MATROSKA_ID_VIDEOASPECTRATIO: {\n\n                            uint64_t num;\n\n                            if ((res = ebml_read_uint(matroska, &id,\n\n                                                      &num)) < 0)\n\n                                break;\n\n                            if (num != MATROSKA_ASPECT_RATIO_MODE_FREE &&\n\n                                num != MATROSKA_ASPECT_RATIO_MODE_KEEP &&\n\n                                num != MATROSKA_ASPECT_RATIO_MODE_FIXED) {\n\n                                av_log(matroska->ctx, AV_LOG_INFO,\n\n                                       \"Ignoring unknown aspect ratio 0x%x\\n\",\n\n                                       (uint32_t) num);\n\n                                break;\n\n                            }\n\n                            videotrack->ar_mode = num;\n\n                            break;\n\n                        }\n\n\n\n                        /* colorspace (only matters for raw video)\n\n                         * fourcc */\n\n                        case MATROSKA_ID_VIDEOCOLORSPACE: {\n\n                            uint64_t num;\n\n                            if ((res = ebml_read_uint(matroska, &id,\n\n                                                      &num)) < 0)\n\n                                break;\n\n                            videotrack->fourcc = num;\n\n                            break;\n\n                        }\n\n\n\n                        default:\n\n                            av_log(matroska->ctx, AV_LOG_INFO,\n\n                                   \"Unknown video track header entry \"\n\n                                   \"0x%x - ignoring\\n\", id);\n\n                            /* pass-through */\n\n\n\n                        case EBML_ID_VOID:\n\n                            res = ebml_read_skip(matroska);\n\n                            break;\n\n                    }\n\n\n\n                    if (matroska->level_up) {\n\n                        matroska->level_up--;\n\n                        break;\n\n                    }\n\n                }\n\n                break;\n\n            }\n\n\n\n            /* tracktype specific stuff for audio */\n\n            case MATROSKA_ID_TRACKAUDIO: {\n\n                MatroskaAudioTrack *audiotrack;\n\n                if (!track->type)\n\n                    track->type = MATROSKA_TRACK_TYPE_AUDIO;\n\n                if (track->type != MATROSKA_TRACK_TYPE_AUDIO) {\n\n                    av_log(matroska->ctx, AV_LOG_INFO,\n\n                           \"audio data in non-audio track - ignoring\\n\");\n\n                    res = AVERROR_INVALIDDATA;\n\n                    break;\n\n                } else if ((res = ebml_read_master(matroska, &id)) < 0)\n\n                    break;\n\n                audiotrack = (MatroskaAudioTrack *)track;\n\n                audiotrack->channels = 1;\n\n                audiotrack->samplerate = 8000;\n\n\n\n                while (res == 0) {\n\n                    if (!(id = ebml_peek_id(matroska, &matroska->level_up))) {\n\n                        res = AVERROR(EIO);\n\n                        break;\n\n                    } else if (matroska->level_up > 0) {\n\n                        matroska->level_up--;\n\n                        break;\n\n                    }\n\n\n\n                    switch (id) {\n\n                        /* samplerate */\n\n                        case MATROSKA_ID_AUDIOSAMPLINGFREQ: {\n\n                            double num;\n\n                            if ((res = ebml_read_float(matroska, &id,\n\n                                                       &num)) < 0)\n\n                                break;\n\n                            audiotrack->internal_samplerate =\n\n                            audiotrack->samplerate = num;\n\n                            break;\n\n                        }\n\n\n\n                        case MATROSKA_ID_AUDIOOUTSAMPLINGFREQ: {\n\n                            double num;\n\n                            if ((res = ebml_read_float(matroska, &id,\n\n                                                       &num)) < 0)\n\n                                break;\n\n                            audiotrack->samplerate = num;\n\n                            break;\n\n                        }\n\n\n\n                            /* bitdepth */\n\n                        case MATROSKA_ID_AUDIOBITDEPTH: {\n\n                            uint64_t num;\n\n                            if ((res = ebml_read_uint(matroska, &id,\n\n                                                      &num)) < 0)\n\n                                break;\n\n                            audiotrack->bitdepth = num;\n\n                            break;\n\n                        }\n\n\n\n                            /* channels */\n\n                        case MATROSKA_ID_AUDIOCHANNELS: {\n\n                            uint64_t num;\n\n                            if ((res = ebml_read_uint(matroska, &id,\n\n                                                      &num)) < 0)\n\n                                break;\n\n                            audiotrack->channels = num;\n\n                            break;\n\n                        }\n\n\n\n                        default:\n\n                            av_log(matroska->ctx, AV_LOG_INFO,\n\n                                   \"Unknown audio track header entry \"\n\n                                   \"0x%x - ignoring\\n\", id);\n\n                            /* pass-through */\n\n\n\n                        case EBML_ID_VOID:\n\n                            res = ebml_read_skip(matroska);\n\n                            break;\n\n                    }\n\n\n\n                    if (matroska->level_up) {\n\n                        matroska->level_up--;\n\n                        break;\n\n                    }\n\n                }\n\n                break;\n\n            }\n\n\n\n                /* codec identifier */\n\n            case MATROSKA_ID_CODECID: {\n\n                char *text;\n\n                if ((res = ebml_read_ascii(matroska, &id, &text)) < 0)\n\n                    break;\n\n                track->codec_id = text;\n\n                break;\n\n            }\n\n\n\n                /* codec private data */\n\n            case MATROSKA_ID_CODECPRIVATE: {\n\n                uint8_t *data;\n\n                int size;\n\n                if ((res = ebml_read_binary(matroska, &id, &data, &size) < 0))\n\n                    break;\n\n                track->codec_priv = data;\n\n                track->codec_priv_size = size;\n\n                break;\n\n            }\n\n\n\n                /* name of the codec */\n\n            case MATROSKA_ID_CODECNAME: {\n\n                char *text;\n\n                if ((res = ebml_read_utf8(matroska, &id, &text)) < 0)\n\n                    break;\n\n                track->codec_name = text;\n\n                break;\n\n            }\n\n\n\n                /* name of this track */\n\n            case MATROSKA_ID_TRACKNAME: {\n\n                char *text;\n\n                if ((res = ebml_read_utf8(matroska, &id, &text)) < 0)\n\n                    break;\n\n                track->name = text;\n\n                break;\n\n            }\n\n\n\n                /* language (matters for audio/subtitles, mostly) */\n\n            case MATROSKA_ID_TRACKLANGUAGE: {\n\n                char *text, *end;\n\n                if ((res = ebml_read_utf8(matroska, &id, &text)) < 0)\n\n                    break;\n\n                if ((end = strchr(text, '-')))\n\n                    *end = '\\0';\n\n                if (strlen(text) == 3)\n\n                    strcpy(track->language, text);\n\n                av_free(text);\n\n                break;\n\n            }\n\n\n\n                /* whether this is actually used */\n\n            case MATROSKA_ID_TRACKFLAGENABLED: {\n\n                uint64_t num;\n\n                if ((res = ebml_read_uint(matroska, &id, &num)) < 0)\n\n                    break;\n\n                if (num)\n\n                    track->flags |= MATROSKA_TRACK_ENABLED;\n\n                else\n\n                    track->flags &= ~MATROSKA_TRACK_ENABLED;\n\n                break;\n\n            }\n\n\n\n                /* whether it's the default for this track type */\n\n            case MATROSKA_ID_TRACKFLAGDEFAULT: {\n\n                uint64_t num;\n\n                if ((res = ebml_read_uint(matroska, &id, &num)) < 0)\n\n                    break;\n\n                if (num)\n\n                    track->flags |= MATROSKA_TRACK_DEFAULT;\n\n                else\n\n                    track->flags &= ~MATROSKA_TRACK_DEFAULT;\n\n                break;\n\n            }\n\n\n\n                /* lacing (like MPEG, where blocks don't end/start on frame\n\n                 * boundaries) */\n\n            case MATROSKA_ID_TRACKFLAGLACING: {\n\n                uint64_t num;\n\n                if ((res = ebml_read_uint(matroska, &id, &num)) < 0)\n\n                    break;\n\n                if (num)\n\n                    track->flags |= MATROSKA_TRACK_LACING;\n\n                else\n\n                    track->flags &= ~MATROSKA_TRACK_LACING;\n\n                break;\n\n            }\n\n\n\n                /* default length (in time) of one data block in this track */\n\n            case MATROSKA_ID_TRACKDEFAULTDURATION: {\n\n                uint64_t num;\n\n                if ((res = ebml_read_uint(matroska, &id, &num)) < 0)\n\n                    break;\n\n                track->default_duration = num;\n\n                break;\n\n            }\n\n\n\n            case MATROSKA_ID_TRACKCONTENTENCODINGS: {\n\n                if ((res = ebml_read_master(matroska, &id)) < 0)\n\n                    break;\n\n\n\n                while (res == 0) {\n\n                    if (!(id = ebml_peek_id(matroska, &matroska->level_up))) {\n\n                        res = AVERROR(EIO);\n\n                        break;\n\n                    } else if (matroska->level_up > 0) {\n\n                        matroska->level_up--;\n\n                        break;\n\n                    }\n\n\n\n                    switch (id) {\n\n                        case MATROSKA_ID_TRACKCONTENTENCODING: {\n\n                            int encoding_scope = 1;\n\n                            if ((res = ebml_read_master(matroska, &id)) < 0)\n\n                                break;\n\n\n\n                            while (res == 0) {\n\n                                if (!(id = ebml_peek_id(matroska, &matroska->level_up))) {\n\n                                    res = AVERROR(EIO);\n\n                                    break;\n\n                                } else if (matroska->level_up > 0) {\n\n                                    matroska->level_up--;\n\n                                    break;\n\n                                }\n\n\n\n                                switch (id) {\n\n                                    case MATROSKA_ID_ENCODINGSCOPE: {\n\n                                        uint64_t num;\n\n                                        if ((res = ebml_read_uint(matroska, &id, &num)) < 0)\n\n                                            break;\n\n                                        encoding_scope = num;\n\n                                        break;\n\n                                    }\n\n\n\n                                    case MATROSKA_ID_ENCODINGTYPE: {\n\n                                        uint64_t num;\n\n                                        if ((res = ebml_read_uint(matroska, &id, &num)) < 0)\n\n                                            break;\n\n                                        if (num)\n\n                                            av_log(matroska->ctx, AV_LOG_ERROR,\n\n                                                   \"Unsupported encoding type\");\n\n                                        break;\n\n                                    }\n\n\n\n                                    case MATROSKA_ID_ENCODINGCOMPRESSION: {\n\n                                        if ((res = ebml_read_master(matroska, &id)) < 0)\n\n                                            break;\n\n\n\n                                        while (res == 0) {\n\n                                            if (!(id = ebml_peek_id(matroska, &matroska->level_up))) {\n\n                                                res = AVERROR(EIO);\n\n                                                break;\n\n                                            } else if (matroska->level_up > 0) {\n\n                                                matroska->level_up--;\n\n                                                break;\n\n                                            }\n\n\n\n                                            switch (id) {\n\n                                                case MATROSKA_ID_ENCODINGCOMPALGO: {\n\n                                                    uint64_t num;\n\n                                                    if ((res = ebml_read_uint(matroska, &id, &num)) < 0)\n\n                                                        break;\n\n                                                    if (num != MATROSKA_TRACK_ENCODING_COMP_HEADERSTRIP &&\n\n#ifdef CONFIG_ZLIB\n\n                                                        num != MATROSKA_TRACK_ENCODING_COMP_ZLIB &&\n\n#endif\n\n#ifdef CONFIG_BZLIB\n\n                                                        num != MATROSKA_TRACK_ENCODING_COMP_BZLIB &&\n\n#endif\n\n                                                        num != MATROSKA_TRACK_ENCODING_COMP_LZO)\n\n                                                        av_log(matroska->ctx, AV_LOG_ERROR,\n\n                                                               \"Unsupported compression algo\\n\");\n\n                                                    track->encoding_algo = num;\n\n                                                    break;\n\n                                                }\n\n\n\n                                                case MATROSKA_ID_ENCODINGCOMPSETTINGS: {\n\n                                                    uint8_t *data;\n\n                                                    int size;\n\n                                                    if ((res = ebml_read_binary(matroska, &id, &data, &size) < 0))\n\n                                                        break;\n\n                                                    track->encoding_settings = data;\n\n                                                    track->encoding_settings_len = size;\n\n                                                    break;\n\n                                                }\n\n\n\n                                                default:\n\n                                                    av_log(matroska->ctx, AV_LOG_INFO,\n\n                                                           \"Unknown compression header entry \"\n\n                                                           \"0x%x - ignoring\\n\", id);\n\n                                                    /* pass-through */\n\n\n\n                                                case EBML_ID_VOID:\n\n                                                    res = ebml_read_skip(matroska);\n\n                                                    break;\n\n                                            }\n\n\n\n                                            if (matroska->level_up) {\n\n                                                matroska->level_up--;\n\n                                                break;\n\n                                            }\n\n                                        }\n\n                                        break;\n\n                                    }\n\n\n\n                                    default:\n\n                                        av_log(matroska->ctx, AV_LOG_INFO,\n\n                                               \"Unknown content encoding header entry \"\n\n                                               \"0x%x - ignoring\\n\", id);\n\n                                        /* pass-through */\n\n\n\n                                    case EBML_ID_VOID:\n\n                                        res = ebml_read_skip(matroska);\n\n                                        break;\n\n                                }\n\n\n\n                                if (matroska->level_up) {\n\n                                    matroska->level_up--;\n\n                                    break;\n\n                                }\n\n                            }\n\n\n\n                            track->encoding_scope = encoding_scope;\n\n                            break;\n\n                        }\n\n\n\n                        default:\n\n                            av_log(matroska->ctx, AV_LOG_INFO,\n\n                                   \"Unknown content encodings header entry \"\n\n                                   \"0x%x - ignoring\\n\", id);\n\n                            /* pass-through */\n\n\n\n                        case EBML_ID_VOID:\n\n                            res = ebml_read_skip(matroska);\n\n                            break;\n\n                    }\n\n\n\n                    if (matroska->level_up) {\n\n                        matroska->level_up--;\n\n                        break;\n\n                    }\n\n                }\n\n                break;\n\n            }\n\n\n\n            case MATROSKA_ID_TRACKTIMECODESCALE: {\n\n                double num;\n\n                if ((res = ebml_read_float(matroska, &id, &num)) < 0)\n\n                    break;\n\n                track->time_scale = num;\n\n                break;\n\n            }\n\n\n\n            default:\n\n                av_log(matroska->ctx, AV_LOG_INFO,\n\n                       \"Unknown track header entry 0x%x - ignoring\\n\", id);\n\n                /* pass-through */\n\n\n\n            case EBML_ID_VOID:\n\n            /* we ignore these because they're nothing useful. */\n\n            case MATROSKA_ID_TRACKFLAGFORCED:\n\n            case MATROSKA_ID_CODECDECODEALL:\n\n            case MATROSKA_ID_CODECINFOURL:\n\n            case MATROSKA_ID_CODECDOWNLOADURL:\n\n            case MATROSKA_ID_TRACKMINCACHE:\n\n            case MATROSKA_ID_TRACKMAXCACHE:\n\n                res = ebml_read_skip(matroska);\n\n                break;\n\n        }\n\n\n\n        if (matroska->level_up) {\n\n            matroska->level_up--;\n\n            break;\n\n        }\n\n    }\n\n\n\n    return res;\n\n}\n", "idx": 23672}
{"project": "FFmpeg", "commit_id": "28bf81c90d36a55cf76e2be913c5215ebebf61f2", "target": 1, "func": "inline static void RENAME(hcscale)(uint16_t *dst, int dstWidth,\n\n\t\t\t\tuint8_t *src1, uint8_t *src2, int srcW, int xInc)\n\n{\n\n#ifdef HAVE_MMX\n\n\t// use the new MMX scaler if th mmx2 cant be used (its faster than the x86asm one)\n\n    if(sws_flags != SWS_FAST_BILINEAR || (!canMMX2BeUsed))\n\n#else\n\n    if(sws_flags != SWS_FAST_BILINEAR)\n\n#endif\n\n    {\n\n    \tRENAME(hScale)(dst     , dstWidth, src1, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n    \tRENAME(hScale)(dst+2048, dstWidth, src2, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n    }\n\n    else // Fast Bilinear upscale / crap downscale\n\n    {\n\n#ifdef ARCH_X86\n\n#ifdef HAVE_MMX2\n\n\tint i;\n\n\tif(canMMX2BeUsed)\n\n\t{\n\n\t\tasm volatile(\n\n\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\"pxor %%mm2, %%mm2\t\t\\n\\t\" // 2*xalpha\n\n\t\t\"movd %5, %%mm6\t\t\t\\n\\t\" // xInc&0xFFFF\n\n\t\t\"punpcklwd %%mm6, %%mm6\t\t\\n\\t\"\n\n\t\t\"punpcklwd %%mm6, %%mm6\t\t\\n\\t\"\n\n\t\t\"movq %%mm6, %%mm2\t\t\\n\\t\"\n\n\t\t\"psllq $16, %%mm2\t\t\\n\\t\"\n\n\t\t\"paddw %%mm6, %%mm2\t\t\\n\\t\"\n\n\t\t\"psllq $16, %%mm2\t\t\\n\\t\"\n\n\t\t\"paddw %%mm6, %%mm2\t\t\\n\\t\"\n\n\t\t\"psllq $16, %%mm2\t\t\\n\\t\" //0,t,2t,3t\t\tt=xInc&0xFFFF\n\n\t\t\"movq %%mm2, \"MANGLE(temp0)\"\t\\n\\t\"\n\n\t\t\"movd %4, %%mm6\t\t\t\\n\\t\" //(xInc*4)&0xFFFF\n\n\t\t\"punpcklwd %%mm6, %%mm6\t\t\\n\\t\"\n\n\t\t\"punpcklwd %%mm6, %%mm6\t\t\\n\\t\"\n\n\t\t\"xorl %%eax, %%eax\t\t\\n\\t\" // i\n\n\t\t\"movl %0, %%esi\t\t\t\\n\\t\" // src\n\n\t\t\"movl %1, %%edi\t\t\t\\n\\t\" // buf1\n\n\t\t\"movl %3, %%edx\t\t\t\\n\\t\" // (xInc*4)>>16\n\n\t\t\"xorl %%ecx, %%ecx\t\t\\n\\t\"\n\n\t\t\"xorl %%ebx, %%ebx\t\t\\n\\t\"\n\n\t\t\"movw %4, %%bx\t\t\t\\n\\t\" // (xInc*4)&0xFFFF\n\n\n\n#define FUNNYUVCODE \\\n\n\t\t\tPREFETCH\" 1024(%%esi)\t\t\\n\\t\"\\\n\n\t\t\tPREFETCH\" 1056(%%esi)\t\t\\n\\t\"\\\n\n\t\t\tPREFETCH\" 1088(%%esi)\t\t\\n\\t\"\\\n\n\t\t\t\"call \"MANGLE(funnyUVCode)\"\t\\n\\t\"\\\n\n\t\t\t\"movq \"MANGLE(temp0)\", %%mm2\t\\n\\t\"\\\n\n\t\t\t\"xorl %%ecx, %%ecx\t\t\\n\\t\"\n\n\n\nFUNNYUVCODE\n\nFUNNYUVCODE\n\nFUNNYUVCODE\n\nFUNNYUVCODE\n\n\n\nFUNNYUVCODE\n\nFUNNYUVCODE\n\nFUNNYUVCODE\n\nFUNNYUVCODE\n\n\t\t\"xorl %%eax, %%eax\t\t\\n\\t\" // i\n\n\t\t\"movl %6, %%esi\t\t\t\\n\\t\" // src\n\n\t\t\"movl %1, %%edi\t\t\t\\n\\t\" // buf1\n\n\t\t\"addl $4096, %%edi\t\t\\n\\t\"\n\n\n\nFUNNYUVCODE\n\nFUNNYUVCODE\n\nFUNNYUVCODE\n\nFUNNYUVCODE\n\n\n\nFUNNYUVCODE\n\nFUNNYUVCODE\n\nFUNNYUVCODE\n\nFUNNYUVCODE\n\n\n\n\t\t:: \"m\" (src1), \"m\" (dst), \"m\" (dstWidth), \"m\" ((xInc*4)>>16),\n\n\t\t  \"m\" ((xInc*4)&0xFFFF), \"m\" (xInc&0xFFFF), \"m\" (src2)\n\n\t\t: \"%eax\", \"%ebx\", \"%ecx\", \"%edx\", \"%esi\", \"%edi\"\n\n\t);\n\n\t\tfor(i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--)\n\n\t\t{\n\n//\t\t\tprintf(\"%d %d %d\\n\", dstWidth, i, srcW);\n\n\t\t\tdst[i] = src1[srcW-1]*128;\n\n\t\t\tdst[i+2048] = src2[srcW-1]*128;\n\n\t\t}\n\n\t}\n\n\telse\n\n\t{\n\n#endif\n\n\tasm volatile(\n\n\t\t\"xorl %%eax, %%eax\t\t\\n\\t\" // i\n\n\t\t\"xorl %%ebx, %%ebx\t\t\\n\\t\" // xx\n\n\t\t\"xorl %%ecx, %%ecx\t\t\\n\\t\" // 2*xalpha\n\n\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\"movl %0, %%esi\t\t\t\\n\\t\"\n\n\t\t\"movzbl  (%%esi, %%ebx), %%edi\t\\n\\t\" //src[xx]\n\n\t\t\"movzbl 1(%%esi, %%ebx), %%esi\t\\n\\t\" //src[xx+1]\n\n\t\t\"subl %%edi, %%esi\t\t\\n\\t\" //src[xx+1] - src[xx]\n\n\t\t\"imull %%ecx, %%esi\t\t\\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n\t\t\"shll $16, %%edi\t\t\\n\\t\"\n\n\t\t\"addl %%edi, %%esi\t\t\\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n\t\t\"movl %1, %%edi\t\t\t\\n\\t\"\n\n\t\t\"shrl $9, %%esi\t\t\t\\n\\t\"\n\n\t\t\"movw %%si, (%%edi, %%eax, 2)\t\\n\\t\"\n\n\n\n\t\t\"movzbl  (%5, %%ebx), %%edi\t\\n\\t\" //src[xx]\n\n\t\t\"movzbl 1(%5, %%ebx), %%esi\t\\n\\t\" //src[xx+1]\n\n\t\t\"subl %%edi, %%esi\t\t\\n\\t\" //src[xx+1] - src[xx]\n\n\t\t\"imull %%ecx, %%esi\t\t\\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n\t\t\"shll $16, %%edi\t\t\\n\\t\"\n\n\t\t\"addl %%edi, %%esi\t\t\\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n\t\t\"movl %1, %%edi\t\t\t\\n\\t\"\n\n\t\t\"shrl $9, %%esi\t\t\t\\n\\t\"\n\n\t\t\"movw %%si, 4096(%%edi, %%eax, 2)\\n\\t\"\n\n\n\n\t\t\"addw %4, %%cx\t\t\t\\n\\t\" //2*xalpha += xInc&0xFF\n\n\t\t\"adcl %3, %%ebx\t\t\t\\n\\t\" //xx+= xInc>>8 + carry\n\n\t\t\"addl $1, %%eax\t\t\t\\n\\t\"\n\n\t\t\"cmpl %2, %%eax\t\t\t\\n\\t\"\n\n\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\n\n\t\t:: \"m\" (src1), \"m\" (dst), \"m\" (dstWidth), \"m\" (xInc>>16), \"m\" (xInc&0xFFFF),\n\n\t\t\"r\" (src2)\n\n\t\t: \"%eax\", \"%ebx\", \"%ecx\", \"%edi\", \"%esi\"\n\n\t\t);\n\n#ifdef HAVE_MMX2\n\n\t} //if MMX2 cant be used\n\n#endif\n\n#else\n\n\tint i;\n\n\tunsigned int xpos=0;\n\n\tfor(i=0;i<dstWidth;i++)\n\n\t{\n\n\t\tregister unsigned int xx=xpos>>16;\n\n\t\tregister unsigned int xalpha=(xpos&0xFFFF)>>9;\n\n\t\tdst[i]=(src1[xx]*(xalpha^127)+src1[xx+1]*xalpha);\n\n\t\tdst[i+2048]=(src2[xx]*(xalpha^127)+src2[xx+1]*xalpha);\n\n/* slower\n\n\t  dst[i]= (src1[xx]<<7) + (src1[xx+1] - src1[xx])*xalpha;\n\n\t  dst[i+2048]=(src2[xx]<<7) + (src2[xx+1] - src2[xx])*xalpha;\n\n*/\n\n\t\txpos+=xInc;\n\n\t}\n\n#endif\n\n   }\n\n}\n", "idx": 23676}
{"project": "FFmpeg", "commit_id": "850c6db97d1f78e7607952ab8b854a93a185319e", "target": 0, "func": "static int decode_plane10(UtvideoContext *c, int plane_no,\n\n                          uint16_t *dst, int step, ptrdiff_t stride,\n\n                          int width, int height,\n\n                          const uint8_t *src, const uint8_t *huff,\n\n                          int use_pred)\n\n{\n\n    int i, j, slice, pix, ret;\n\n    int sstart, send;\n\n    VLC vlc;\n\n    GetBitContext gb;\n\n    int prev, fsym;\n\n\n\n    if ((ret = build_huff10(huff, &vlc, &fsym)) < 0) {\n\n        av_log(c->avctx, AV_LOG_ERROR, \"Cannot build Huffman codes\\n\");\n\n        return ret;\n\n    }\n\n    if (fsym >= 0) { // build_huff reported a symbol to fill slices with\n\n        send = 0;\n\n        for (slice = 0; slice < c->slices; slice++) {\n\n            uint16_t *dest;\n\n\n\n            sstart = send;\n\n            send   = (height * (slice + 1) / c->slices);\n\n            dest   = dst + sstart * stride;\n\n\n\n            prev = 0x200;\n\n            for (j = sstart; j < send; j++) {\n\n                for (i = 0; i < width * step; i += step) {\n\n                    pix = fsym;\n\n                    if (use_pred) {\n\n                        prev += pix;\n\n                        prev &= 0x3FF;\n\n                        pix   = prev;\n\n                    }\n\n                    dest[i] = pix;\n\n                }\n\n                dest += stride;\n\n            }\n\n        }\n\n        return 0;\n\n    }\n\n\n\n    send = 0;\n\n    for (slice = 0; slice < c->slices; slice++) {\n\n        uint16_t *dest;\n\n        int slice_data_start, slice_data_end, slice_size;\n\n\n\n        sstart = send;\n\n        send   = (height * (slice + 1) / c->slices);\n\n        dest   = dst + sstart * stride;\n\n\n\n        // slice offset and size validation was done earlier\n\n        slice_data_start = slice ? AV_RL32(src + slice * 4 - 4) : 0;\n\n        slice_data_end   = AV_RL32(src + slice * 4);\n\n        slice_size       = slice_data_end - slice_data_start;\n\n\n\n        if (!slice_size) {\n\n            av_log(c->avctx, AV_LOG_ERROR, \"Plane has more than one symbol \"\n\n                   \"yet a slice has a length of zero.\\n\");\n\n            goto fail;\n\n        }\n\n\n\n        memset(c->slice_bits + slice_size, 0, AV_INPUT_BUFFER_PADDING_SIZE);\n\n        c->bdsp.bswap_buf((uint32_t *) c->slice_bits,\n\n                          (uint32_t *)(src + slice_data_start + c->slices * 4),\n\n                          (slice_data_end - slice_data_start + 3) >> 2);\n\n        init_get_bits(&gb, c->slice_bits, slice_size * 8);\n\n\n\n        prev = 0x200;\n\n        for (j = sstart; j < send; j++) {\n\n            for (i = 0; i < width * step; i += step) {\n\n                pix = get_vlc2(&gb, vlc.table, VLC_BITS, 3);\n\n                if (pix < 0) {\n\n                    av_log(c->avctx, AV_LOG_ERROR, \"Decoding error\\n\");\n\n                    goto fail;\n\n                }\n\n                if (use_pred) {\n\n                    prev += pix;\n\n                    prev &= 0x3FF;\n\n                    pix   = prev;\n\n                }\n\n                dest[i] = pix;\n\n            }\n\n            dest += stride;\n\n            if (get_bits_left(&gb) < 0) {\n\n                av_log(c->avctx, AV_LOG_ERROR,\n\n                        \"Slice decoding ran out of bits\\n\");\n\n                goto fail;\n\n            }\n\n        }\n\n        if (get_bits_left(&gb) > 32)\n\n            av_log(c->avctx, AV_LOG_WARNING,\n\n                   \"%d bits left after decoding slice\\n\", get_bits_left(&gb));\n\n    }\n\n\n\n    ff_free_vlc(&vlc);\n\n\n\n    return 0;\n\nfail:\n\n    ff_free_vlc(&vlc);\n\n    return AVERROR_INVALIDDATA;\n\n}\n", "idx": 23678}
{"project": "FFmpeg", "commit_id": "6d702dc072ffc255cd0f709132e55661698313e7", "target": 0, "func": "static int encode_slice(AVCodecContext *avctx, const AVFrame *pic,\n\n                        PutBitContext *pb,\n\n                        int sizes[4], int x, int y, int quant,\n\n                        int mbs_per_slice)\n\n{\n\n    ProresContext *ctx = avctx->priv_data;\n\n    int i, xp, yp;\n\n    int total_size = 0;\n\n    const uint16_t *src;\n\n    int slice_width_factor = av_log2(mbs_per_slice);\n\n    int num_cblocks, pwidth;\n\n    int plane_factor, is_chroma;\n\n\n\n    for (i = 0; i < ctx->num_planes; i++) {\n\n        is_chroma    = (i == 1 || i == 2);\n\n        plane_factor = slice_width_factor + 2;\n\n        if (is_chroma)\n\n            plane_factor += ctx->chroma_factor - 3;\n\n        if (!is_chroma || ctx->chroma_factor == CFACTOR_Y444) {\n\n            xp          = x << 4;\n\n            yp          = y << 4;\n\n            num_cblocks = 4;\n\n            pwidth      = avctx->width;\n\n        } else {\n\n            xp          = x << 3;\n\n            yp          = y << 4;\n\n            num_cblocks = 2;\n\n            pwidth      = avctx->width >> 1;\n\n        }\n\n        src = (const uint16_t*)(pic->data[i] + yp * pic->linesize[i]) + xp;\n\n\n\n        get_slice_data(ctx, src, pic->linesize[i], xp, yp,\n\n                       pwidth, avctx->height, ctx->blocks[0],\n\n                       mbs_per_slice, num_cblocks);\n\n        sizes[i] = encode_slice_plane(ctx, pb, src, pic->linesize[i],\n\n                                      mbs_per_slice, ctx->blocks[0],\n\n                                      num_cblocks, plane_factor,\n\n                                      ctx->quants[quant]);\n\n        total_size += sizes[i];\n\n    }\n\n    return total_size;\n\n}\n", "idx": 23679}
{"project": "FFmpeg", "commit_id": "a147c1b2b125c26cd2c5105a7f274a597de37731", "target": 0, "func": "static int ogg_write_header(AVFormatContext *s)\n\n{\n\n    OGGStreamContext *oggstream;\n\n    int i, j;\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVStream *st = s->streams[i];\n\n        unsigned serial_num = i;\n\n\n\n        if (st->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            if (st->codec->codec_id == AV_CODEC_ID_OPUS)\n\n                /* Opus requires a fixed 48kHz clock */\n\n                avpriv_set_pts_info(st, 64, 1, 48000);\n\n            else\n\n                avpriv_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n        } else if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO)\n\n            avpriv_set_pts_info(st, 64, st->codec->time_base.num, st->codec->time_base.den);\n\n        if (st->codec->codec_id != AV_CODEC_ID_VORBIS &&\n\n            st->codec->codec_id != AV_CODEC_ID_THEORA &&\n\n            st->codec->codec_id != AV_CODEC_ID_SPEEX  &&\n\n            st->codec->codec_id != AV_CODEC_ID_FLAC   &&\n\n            st->codec->codec_id != AV_CODEC_ID_OPUS) {\n\n            av_log(s, AV_LOG_ERROR, \"Unsupported codec id in stream %d\\n\", i);\n\n            return -1;\n\n        }\n\n\n\n        if (!st->codec->extradata || !st->codec->extradata_size) {\n\n            av_log(s, AV_LOG_ERROR, \"No extradata present\\n\");\n\n            return -1;\n\n        }\n\n        oggstream = av_mallocz(sizeof(*oggstream));\n\n        oggstream->page.stream_index = i;\n\n\n\n        if (!(st->codec->flags & CODEC_FLAG_BITEXACT))\n\n            do {\n\n                serial_num = av_get_random_seed();\n\n                for (j = 0; j < i; j++) {\n\n                    OGGStreamContext *sc = s->streams[j]->priv_data;\n\n                    if (serial_num == sc->serial_num)\n\n                        break;\n\n                }\n\n            } while (j < i);\n\n        oggstream->serial_num = serial_num;\n\n\n\n        st->priv_data = oggstream;\n\n        if (st->codec->codec_id == AV_CODEC_ID_FLAC) {\n\n            int err = ogg_build_flac_headers(st->codec, oggstream,\n\n                                             st->codec->flags & CODEC_FLAG_BITEXACT,\n\n                                             &s->metadata);\n\n            if (err) {\n\n                av_log(s, AV_LOG_ERROR, \"Error writing FLAC headers\\n\");\n\n                av_freep(&st->priv_data);\n\n                return err;\n\n            }\n\n        } else if (st->codec->codec_id == AV_CODEC_ID_SPEEX) {\n\n            int err = ogg_build_speex_headers(st->codec, oggstream,\n\n                                              st->codec->flags & CODEC_FLAG_BITEXACT,\n\n                                              &s->metadata);\n\n            if (err) {\n\n                av_log(s, AV_LOG_ERROR, \"Error writing Speex headers\\n\");\n\n                av_freep(&st->priv_data);\n\n                return err;\n\n            }\n\n        } else if (st->codec->codec_id == AV_CODEC_ID_OPUS) {\n\n            int err = ogg_build_opus_headers(st->codec, oggstream,\n\n                                             st->codec->flags & CODEC_FLAG_BITEXACT,\n\n                                             &s->metadata);\n\n            if (err) {\n\n                av_log(s, AV_LOG_ERROR, \"Error writing Opus headers\\n\");\n\n                av_freep(&st->priv_data);\n\n                return err;\n\n            }\n\n        } else {\n\n            uint8_t *p;\n\n            const char *cstr = st->codec->codec_id == AV_CODEC_ID_VORBIS ? \"vorbis\" : \"theora\";\n\n            int header_type = st->codec->codec_id == AV_CODEC_ID_VORBIS ? 3 : 0x81;\n\n            int framing_bit = st->codec->codec_id == AV_CODEC_ID_VORBIS ? 1 : 0;\n\n\n\n            if (avpriv_split_xiph_headers(st->codec->extradata, st->codec->extradata_size,\n\n                                      st->codec->codec_id == AV_CODEC_ID_VORBIS ? 30 : 42,\n\n                                      oggstream->header, oggstream->header_len) < 0) {\n\n                av_log(s, AV_LOG_ERROR, \"Extradata corrupted\\n\");\n\n                av_freep(&st->priv_data);\n\n                return -1;\n\n            }\n\n\n\n            p = ogg_write_vorbiscomment(7, st->codec->flags & CODEC_FLAG_BITEXACT,\n\n                                        &oggstream->header_len[1], &s->metadata,\n\n                                        framing_bit);\n\n            oggstream->header[1] = p;\n\n            if (!p)\n\n                return AVERROR(ENOMEM);\n\n\n\n            bytestream_put_byte(&p, header_type);\n\n            bytestream_put_buffer(&p, cstr, 6);\n\n\n\n            if (st->codec->codec_id == AV_CODEC_ID_THEORA) {\n\n                /** KFGSHIFT is the width of the less significant section of the granule position\n\n                    The less significant section is the frame count since the last keyframe */\n\n                oggstream->kfgshift = ((oggstream->header[0][40]&3)<<3)|(oggstream->header[0][41]>>5);\n\n                oggstream->vrev = oggstream->header[0][9];\n\n                av_log(s, AV_LOG_DEBUG, \"theora kfgshift %d, vrev %d\\n\",\n\n                       oggstream->kfgshift, oggstream->vrev);\n\n            }\n\n        }\n\n    }\n\n\n\n    for (j = 0; j < s->nb_streams; j++) {\n\n        OGGStreamContext *oggstream = s->streams[j]->priv_data;\n\n        ogg_buffer_data(s, s->streams[j], oggstream->header[0],\n\n                        oggstream->header_len[0], 0, 1);\n\n        oggstream->page.flags |= 2; // bos\n\n        ogg_buffer_page(s, oggstream);\n\n    }\n\n    for (j = 0; j < s->nb_streams; j++) {\n\n        AVStream *st = s->streams[j];\n\n        OGGStreamContext *oggstream = st->priv_data;\n\n        for (i = 1; i < 3; i++) {\n\n            if (oggstream && oggstream->header_len[i])\n\n                ogg_buffer_data(s, st, oggstream->header[i],\n\n                                oggstream->header_len[i], 0, 1);\n\n        }\n\n        ogg_buffer_page(s, oggstream);\n\n    }\n\n    return 0;\n\n}\n", "idx": 23681}
{"project": "FFmpeg", "commit_id": "94bb1ce882a12b6d7a1fa32715a68121b39ee838", "target": 0, "func": "static int revert_channel_correlation(ALSDecContext *ctx, ALSBlockData *bd,\n\n                                       ALSChannelData **cd, int *reverted,\n\n                                       unsigned int offset, int c)\n\n{\n\n    ALSChannelData *ch = cd[c];\n\n    unsigned int   dep = 0;\n\n    unsigned int channels = ctx->avctx->channels;\n\n\n\n    if (reverted[c])\n\n        return 0;\n\n\n\n    reverted[c] = 1;\n\n\n\n    while (dep < channels && !ch[dep].stop_flag) {\n\n        revert_channel_correlation(ctx, bd, cd, reverted, offset,\n\n                                   ch[dep].master_channel);\n\n\n\n        dep++;\n\n    }\n\n\n\n    if (dep == channels) {\n\n        av_log(ctx->avctx, AV_LOG_WARNING, \"Invalid channel correlation!\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    bd->const_block = ctx->const_block + c;\n\n    bd->shift_lsbs  = ctx->shift_lsbs + c;\n\n    bd->opt_order   = ctx->opt_order + c;\n\n    bd->store_prev_samples = ctx->store_prev_samples + c;\n\n    bd->use_ltp     = ctx->use_ltp + c;\n\n    bd->ltp_lag     = ctx->ltp_lag + c;\n\n    bd->ltp_gain    = ctx->ltp_gain[c];\n\n    bd->lpc_cof     = ctx->lpc_cof[c];\n\n    bd->quant_cof   = ctx->quant_cof[c];\n\n    bd->raw_samples = ctx->raw_samples[c] + offset;\n\n\n\n    dep = 0;\n\n    while (!ch[dep].stop_flag) {\n\n        unsigned int smp;\n\n        unsigned int begin = 1;\n\n        unsigned int end   = bd->block_length - 1;\n\n        int64_t y;\n\n        int32_t *master = ctx->raw_samples[ch[dep].master_channel] + offset;\n\n\n\n        if (ch[dep].time_diff_flag) {\n\n            int t = ch[dep].time_diff_index;\n\n\n\n            if (ch[dep].time_diff_sign) {\n\n                t      = -t;\n\n                begin -= t;\n\n            } else {\n\n                end   -= t;\n\n            }\n\n\n\n            for (smp = begin; smp < end; smp++) {\n\n                y  = (1 << 6) +\n\n                     MUL64(ch[dep].weighting[0], master[smp - 1    ]) +\n\n                     MUL64(ch[dep].weighting[1], master[smp        ]) +\n\n                     MUL64(ch[dep].weighting[2], master[smp + 1    ]) +\n\n                     MUL64(ch[dep].weighting[3], master[smp - 1 + t]) +\n\n                     MUL64(ch[dep].weighting[4], master[smp     + t]) +\n\n                     MUL64(ch[dep].weighting[5], master[smp + 1 + t]);\n\n\n\n                bd->raw_samples[smp] += y >> 7;\n\n            }\n\n        } else {\n\n            for (smp = begin; smp < end; smp++) {\n\n                y  = (1 << 6) +\n\n                     MUL64(ch[dep].weighting[0], master[smp - 1]) +\n\n                     MUL64(ch[dep].weighting[1], master[smp    ]) +\n\n                     MUL64(ch[dep].weighting[2], master[smp + 1]);\n\n\n\n                bd->raw_samples[smp] += y >> 7;\n\n            }\n\n        }\n\n\n\n        dep++;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23692}
{"project": "FFmpeg", "commit_id": "29fb49194bedc74ac9be0b49b6b42dcfeb6222d9", "target": 0, "func": "int av_get_cpu_flags(void)\n\n{\n\n    if (checked)\n\n        return flags;\n\n\n\n    if (ARCH_AARCH64)\n\n        flags = ff_get_cpu_flags_aarch64();\n\n    if (ARCH_ARM)\n\n        flags = ff_get_cpu_flags_arm();\n\n    if (ARCH_PPC)\n\n        flags = ff_get_cpu_flags_ppc();\n\n    if (ARCH_X86)\n\n        flags = ff_get_cpu_flags_x86();\n\n\n\n    checked = 1;\n\n    return flags;\n\n}\n", "idx": 23693}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static inline void downmix_3f_1r_to_mono(float *samples)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        samples[i] += (samples[i + 256] + samples[i + 512] + samples[i + 768]);\n\n        samples[i + 256] = samples[i + 512] = samples[i + 768] = 0;\n\n    }\n\n}\n", "idx": 23704}
{"project": "FFmpeg", "commit_id": "c341f734e5f9d6af4a8fdcceb6f5d12de6395c76", "target": 1, "func": "void ff_snow_pred_block(SnowContext *s, uint8_t *dst, uint8_t *tmp, int stride, int sx, int sy, int b_w, int b_h, BlockNode *block, int plane_index, int w, int h){\n\n    if(block->type & BLOCK_INTRA){\n\n        int x, y;\n\n        const unsigned color  = block->color[plane_index];\n\n        const unsigned color4 = color*0x01010101;\n\n        if(b_w==32){\n\n            for(y=0; y < b_h; y++){\n\n                *(uint32_t*)&dst[0 + y*stride]= color4;\n\n                *(uint32_t*)&dst[4 + y*stride]= color4;\n\n                *(uint32_t*)&dst[8 + y*stride]= color4;\n\n                *(uint32_t*)&dst[12+ y*stride]= color4;\n\n                *(uint32_t*)&dst[16+ y*stride]= color4;\n\n                *(uint32_t*)&dst[20+ y*stride]= color4;\n\n                *(uint32_t*)&dst[24+ y*stride]= color4;\n\n                *(uint32_t*)&dst[28+ y*stride]= color4;\n\n            }\n\n        }else if(b_w==16){\n\n            for(y=0; y < b_h; y++){\n\n                *(uint32_t*)&dst[0 + y*stride]= color4;\n\n                *(uint32_t*)&dst[4 + y*stride]= color4;\n\n                *(uint32_t*)&dst[8 + y*stride]= color4;\n\n                *(uint32_t*)&dst[12+ y*stride]= color4;\n\n            }\n\n        }else if(b_w==8){\n\n            for(y=0; y < b_h; y++){\n\n                *(uint32_t*)&dst[0 + y*stride]= color4;\n\n                *(uint32_t*)&dst[4 + y*stride]= color4;\n\n            }\n\n        }else if(b_w==4){\n\n            for(y=0; y < b_h; y++){\n\n                *(uint32_t*)&dst[0 + y*stride]= color4;\n\n            }\n\n        }else{\n\n            for(y=0; y < b_h; y++){\n\n                for(x=0; x < b_w; x++){\n\n                    dst[x + y*stride]= color;\n\n                }\n\n            }\n\n        }\n\n    }else{\n\n        uint8_t *src= s->last_picture[block->ref]->data[plane_index];\n\n        const int scale= plane_index ?  (2*s->mv_scale)>>s->chroma_h_shift : 2*s->mv_scale;\n\n        int mx= block->mx*scale;\n\n        int my= block->my*scale;\n\n        const int dx= mx&15;\n\n        const int dy= my&15;\n\n        const int tab_index= 3 - (b_w>>2) + (b_w>>4);\n\n        sx += (mx>>4) - (HTAPS_MAX/2-1);\n\n        sy += (my>>4) - (HTAPS_MAX/2-1);\n\n        src += sx + sy*stride;\n\n        if(   (unsigned)sx >= FFMAX(w - b_w - (HTAPS_MAX-2), 0)\n\n           || (unsigned)sy >= FFMAX(h - b_h - (HTAPS_MAX-2), 0)){\n\n            s->vdsp.emulated_edge_mc(tmp + MB_SIZE, src, stride, b_w+HTAPS_MAX-1, b_h+HTAPS_MAX-1, sx, sy, w, h);\n\n            src= tmp + MB_SIZE;\n\n        }\n\n\n\n        av_assert2(s->chroma_h_shift == s->chroma_v_shift); // only one mv_scale\n\n\n\n        av_assert2(b_w>1 && b_h>1);\n\n        av_assert2((tab_index>=0 && tab_index<4) || b_w==32);\n\n        if((dx&3) || (dy&3) || !(b_w == b_h || 2*b_w == b_h || b_w == 2*b_h) || (b_w&(b_w-1)) || !s->plane[plane_index].fast_mc )\n\n            mc_block(&s->plane[plane_index], dst, src, stride, b_w, b_h, dx, dy);\n\n        else if(b_w==32){\n\n            int y;\n\n            for(y=0; y<b_h; y+=16){\n\n                s->h264qpel.put_h264_qpel_pixels_tab[0][dy+(dx>>2)](dst + y*stride, src + 3 + (y+3)*stride,stride);\n\n                s->h264qpel.put_h264_qpel_pixels_tab[0][dy+(dx>>2)](dst + 16 + y*stride, src + 19 + (y+3)*stride,stride);\n\n            }\n\n        }else if(b_w==b_h)\n\n            s->h264qpel.put_h264_qpel_pixels_tab[tab_index  ][dy+(dx>>2)](dst,src + 3 + 3*stride,stride);\n\n        else if(b_w==2*b_h){\n\n            s->h264qpel.put_h264_qpel_pixels_tab[tab_index+1][dy+(dx>>2)](dst    ,src + 3       + 3*stride,stride);\n\n            s->h264qpel.put_h264_qpel_pixels_tab[tab_index+1][dy+(dx>>2)](dst+b_h,src + 3 + b_h + 3*stride,stride);\n\n        }else{\n\n            av_assert2(2*b_w==b_h);\n\n            s->h264qpel.put_h264_qpel_pixels_tab[tab_index  ][dy+(dx>>2)](dst           ,src + 3 + 3*stride           ,stride);\n\n            s->h264qpel.put_h264_qpel_pixels_tab[tab_index  ][dy+(dx>>2)](dst+b_w*stride,src + 3 + 3*stride+b_w*stride,stride);\n\n        }\n\n    }\n\n}\n", "idx": 23711}
{"project": "FFmpeg", "commit_id": "f738140807f504c9af7850042067777832f05e88", "target": 1, "func": "static int decode_pic_timing(HEVCSEIContext *s, GetBitContext *gb, const HEVCParamSets *ps,\n\n                             void *logctx)\n\n{\n\n    HEVCSEIPictureTiming *h = &s->picture_timing;\n\n    HEVCSPS *sps;\n\n\n\n    if (!ps->sps_list[s->active_seq_parameter_set_id])\n\n        return(AVERROR(ENOMEM));\n\n    sps = (HEVCSPS*)ps->sps_list[s->active_seq_parameter_set_id]->data;\n\n\n\n    if (sps->vui.frame_field_info_present_flag) {\n\n        int pic_struct = get_bits(gb, 4);\n\n        h->picture_struct = AV_PICTURE_STRUCTURE_UNKNOWN;\n\n        if (pic_struct == 2) {\n\n            av_log(logctx, AV_LOG_DEBUG, \"BOTTOM Field\\n\");\n\n            h->picture_struct = AV_PICTURE_STRUCTURE_BOTTOM_FIELD;\n\n        } else if (pic_struct == 1) {\n\n            av_log(logctx, AV_LOG_DEBUG, \"TOP Field\\n\");\n\n            h->picture_struct = AV_PICTURE_STRUCTURE_TOP_FIELD;\n\n        }\n\n        get_bits(gb, 2);                   // source_scan_type\n\n        get_bits(gb, 1);                   // duplicate_flag\n\n    }\n\n    return 1;\n\n}\n", "idx": 23713}
{"project": "FFmpeg", "commit_id": "cd1047f3911fa0d34c86f470537f343d23c8b956", "target": 0, "func": "static int qsv_decode_init(AVCodecContext *avctx, QSVContext *q)\n\n{\n\n    const AVPixFmtDescriptor *desc;\n\n    mfxSession session = NULL;\n\n    int iopattern = 0;\n\n    mfxVideoParam param = { { 0 } };\n\n    int frame_width  = avctx->coded_width;\n\n    int frame_height = avctx->coded_height;\n\n    int ret;\n\n\n\n    desc = av_pix_fmt_desc_get(avctx->sw_pix_fmt);\n\n    if (!desc)\n\n        return AVERROR_BUG;\n\n\n\n    if (!q->async_fifo) {\n\n        q->async_fifo = av_fifo_alloc((1 + q->async_depth) *\n\n                                      (sizeof(mfxSyncPoint*) + sizeof(QSVFrame*)));\n\n        if (!q->async_fifo)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    if (avctx->pix_fmt == AV_PIX_FMT_QSV && avctx->hwaccel_context) {\n\n        AVQSVContext *user_ctx = avctx->hwaccel_context;\n\n        session           = user_ctx->session;\n\n        iopattern         = user_ctx->iopattern;\n\n        q->ext_buffers    = user_ctx->ext_buffers;\n\n        q->nb_ext_buffers = user_ctx->nb_ext_buffers;\n\n    }\n\n\n\n    if (avctx->hw_frames_ctx) {\n\n        AVHWFramesContext    *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n\n        AVQSVFramesContext *frames_hwctx = frames_ctx->hwctx;\n\n\n\n        if (!iopattern) {\n\n            if (frames_hwctx->frame_type & MFX_MEMTYPE_OPAQUE_FRAME)\n\n                iopattern = MFX_IOPATTERN_OUT_OPAQUE_MEMORY;\n\n            else if (frames_hwctx->frame_type & MFX_MEMTYPE_VIDEO_MEMORY_DECODER_TARGET)\n\n                iopattern = MFX_IOPATTERN_OUT_VIDEO_MEMORY;\n\n        }\n\n\n\n        frame_width  = frames_hwctx->surfaces[0].Info.Width;\n\n        frame_height = frames_hwctx->surfaces[0].Info.Height;\n\n    }\n\n\n\n    if (!iopattern)\n\n        iopattern = MFX_IOPATTERN_OUT_SYSTEM_MEMORY;\n\n    q->iopattern = iopattern;\n\n\n\n    ret = qsv_init_session(avctx, q, session, avctx->hw_frames_ctx);\n\n    if (ret < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error initializing an MFX session\\n\");\n\n        return ret;\n\n    }\n\n\n\n    ret = ff_qsv_codec_id_to_mfx(avctx->codec_id);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    param.mfx.CodecId      = ret;\n\n    param.mfx.CodecProfile = avctx->profile;\n\n    param.mfx.CodecLevel   = avctx->level;\n\n\n\n    param.mfx.FrameInfo.BitDepthLuma   = desc->comp[0].depth;\n\n    param.mfx.FrameInfo.BitDepthChroma = desc->comp[0].depth;\n\n    param.mfx.FrameInfo.Shift          = desc->comp[0].depth > 8;\n\n    param.mfx.FrameInfo.FourCC         = q->fourcc;\n\n    param.mfx.FrameInfo.Width          = frame_width;\n\n    param.mfx.FrameInfo.Height         = frame_height;\n\n    param.mfx.FrameInfo.ChromaFormat   = MFX_CHROMAFORMAT_YUV420;\n\n\n\n    param.IOPattern   = q->iopattern;\n\n    param.AsyncDepth  = q->async_depth;\n\n    param.ExtParam    = q->ext_buffers;\n\n    param.NumExtParam = q->nb_ext_buffers;\n\n\n\n    ret = MFXVideoDECODE_Init(q->session, &param);\n\n    if (ret < 0)\n\n        return ff_qsv_print_error(avctx, ret,\n\n                                  \"Error initializing the MFX video decoder\");\n\n\n\n    q->frame_info = param.mfx.FrameInfo;\n\n\n\n    return 0;\n\n}\n", "idx": 23714}
{"project": "FFmpeg", "commit_id": "6892d145a0c80249bd61ee7dd31ec851c5076bcd", "target": 1, "func": "static int film_read_header(AVFormatContext *s)\n\n{\n\n    FilmDemuxContext *film = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st;\n\n    unsigned char scratch[256];\n\n    int i;\n\n    unsigned int data_offset;\n\n    unsigned int audio_frame_counter;\n\n\n\n    film->sample_table = NULL;\n\n    film->stereo_buffer = NULL;\n\n    film->stereo_buffer_size = 0;\n\n\n\n    /* load the main FILM header */\n\n    if (avio_read(pb, scratch, 16) != 16)\n\n        return AVERROR(EIO);\n\n    data_offset = AV_RB32(&scratch[4]);\n\n    film->version = AV_RB32(&scratch[8]);\n\n\n\n    /* load the FDSC chunk */\n\n    if (film->version == 0) {\n\n        /* special case for Lemmings .film files; 20-byte header */\n\n        if (avio_read(pb, scratch, 20) != 20)\n\n            return AVERROR(EIO);\n\n        /* make some assumptions about the audio parameters */\n\n        film->audio_type = AV_CODEC_ID_PCM_S8;\n\n        film->audio_samplerate = 22050;\n\n        film->audio_channels = 1;\n\n        film->audio_bits = 8;\n\n    } else {\n\n        /* normal Saturn .cpk files; 32-byte header */\n\n        if (avio_read(pb, scratch, 32) != 32)\n\n            return AVERROR(EIO);\n\n        film->audio_samplerate = AV_RB16(&scratch[24]);\n\n        film->audio_channels = scratch[21];\n\n        if (!film->audio_channels || film->audio_channels > 2) {\n\n            av_log(s, AV_LOG_ERROR,\n\n                   \"Invalid number of channels: %d\\n\", film->audio_channels);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        film->audio_bits = scratch[22];\n\n        if (scratch[23] == 2)\n\n            film->audio_type = AV_CODEC_ID_ADPCM_ADX;\n\n        else if (film->audio_channels > 0) {\n\n            if (film->audio_bits == 8)\n\n                film->audio_type = AV_CODEC_ID_PCM_S8;\n\n            else if (film->audio_bits == 16)\n\n                film->audio_type = AV_CODEC_ID_PCM_S16BE;\n\n            else\n\n                film->audio_type = AV_CODEC_ID_NONE;\n\n        } else\n\n            film->audio_type = AV_CODEC_ID_NONE;\n\n    }\n\n\n\n    if (AV_RB32(&scratch[0]) != FDSC_TAG)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (AV_RB32(&scratch[8]) == CVID_TAG) {\n\n        film->video_type = AV_CODEC_ID_CINEPAK;\n\n    } else if (AV_RB32(&scratch[8]) == RAW_TAG) {\n\n        film->video_type = AV_CODEC_ID_RAWVIDEO;\n\n    } else {\n\n        film->video_type = AV_CODEC_ID_NONE;\n\n    }\n\n\n\n    /* initialize the decoder streams */\n\n    if (film->video_type) {\n\n        st = avformat_new_stream(s, NULL);\n\n        if (!st)\n\n            return AVERROR(ENOMEM);\n\n        film->video_stream_index = st->index;\n\n        st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n        st->codec->codec_id = film->video_type;\n\n        st->codec->codec_tag = 0;  /* no fourcc */\n\n        st->codec->width = AV_RB32(&scratch[16]);\n\n        st->codec->height = AV_RB32(&scratch[12]);\n\n\n\n        if (film->video_type == AV_CODEC_ID_RAWVIDEO) {\n\n            if (scratch[20] == 24) {\n\n                st->codec->pix_fmt = AV_PIX_FMT_RGB24;\n\n            } else {\n\n                av_log(s, AV_LOG_ERROR, \"raw video is using unhandled %dbpp\\n\", scratch[20]);\n\n                return -1;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (film->audio_type) {\n\n        st = avformat_new_stream(s, NULL);\n\n        if (!st)\n\n            return AVERROR(ENOMEM);\n\n        film->audio_stream_index = st->index;\n\n        st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n        st->codec->codec_id = film->audio_type;\n\n        st->codec->codec_tag = 1;\n\n        st->codec->channels = film->audio_channels;\n\n        st->codec->sample_rate = film->audio_samplerate;\n\n\n\n        if (film->audio_type == AV_CODEC_ID_ADPCM_ADX) {\n\n            st->codec->bits_per_coded_sample = 18 * 8 / 32;\n\n            st->codec->block_align = st->codec->channels * 18;\n\n            st->need_parsing = AVSTREAM_PARSE_FULL;\n\n        } else {\n\n            st->codec->bits_per_coded_sample = film->audio_bits;\n\n            st->codec->block_align = st->codec->channels *\n\n                st->codec->bits_per_coded_sample / 8;\n\n        }\n\n\n\n        st->codec->bit_rate = st->codec->channels * st->codec->sample_rate *\n\n            st->codec->bits_per_coded_sample;\n\n    }\n\n\n\n    /* load the sample table */\n\n    if (avio_read(pb, scratch, 16) != 16)\n\n        return AVERROR(EIO);\n\n    if (AV_RB32(&scratch[0]) != STAB_TAG)\n\n        return AVERROR_INVALIDDATA;\n\n    film->base_clock = AV_RB32(&scratch[8]);\n\n    film->sample_count = AV_RB32(&scratch[12]);\n\n    if(film->sample_count >= UINT_MAX / sizeof(film_sample))\n\n        return -1;\n\n    film->sample_table = av_malloc(film->sample_count * sizeof(film_sample));\n\n    if (!film->sample_table)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        st = s->streams[i];\n\n        if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO)\n\n            avpriv_set_pts_info(st, 33, 1, film->base_clock);\n\n        else\n\n            avpriv_set_pts_info(st, 64, 1, film->audio_samplerate);\n\n    }\n\n\n\n    audio_frame_counter = 0;\n\n    for (i = 0; i < film->sample_count; i++) {\n\n        /* load the next sample record and transfer it to an internal struct */\n\n        if (avio_read(pb, scratch, 16) != 16) {\n\n            av_free(film->sample_table);\n\n            return AVERROR(EIO);\n\n        }\n\n        film->sample_table[i].sample_offset =\n\n            data_offset + AV_RB32(&scratch[0]);\n\n        film->sample_table[i].sample_size = AV_RB32(&scratch[4]);\n\n        if (film->sample_table[i].sample_size > INT_MAX / 4)\n\n            return AVERROR_INVALIDDATA;\n\n        if (AV_RB32(&scratch[8]) == 0xFFFFFFFF) {\n\n            film->sample_table[i].stream = film->audio_stream_index;\n\n            film->sample_table[i].pts = audio_frame_counter;\n\n\n\n            if (film->audio_type == AV_CODEC_ID_ADPCM_ADX)\n\n                audio_frame_counter += (film->sample_table[i].sample_size * 32 /\n\n                    (18 * film->audio_channels));\n\n            else if (film->audio_type != AV_CODEC_ID_NONE)\n\n                audio_frame_counter += (film->sample_table[i].sample_size /\n\n                    (film->audio_channels * film->audio_bits / 8));\n\n        } else {\n\n            film->sample_table[i].stream = film->video_stream_index;\n\n            film->sample_table[i].pts = AV_RB32(&scratch[8]) & 0x7FFFFFFF;\n\n            film->sample_table[i].keyframe = (scratch[8] & 0x80) ? 0 : 1;\n\n        }\n\n    }\n\n\n\n    film->current_sample = 0;\n\n\n\n    return 0;\n\n}\n", "idx": 23715}
{"project": "FFmpeg", "commit_id": "5b4da8a38a5ed211df9504c85ce401c30af86b97", "target": 0, "func": "static int encode_q_branch(SnowContext *s, int level, int x, int y){\n\n    uint8_t p_buffer[1024];\n\n    uint8_t i_buffer[1024];\n\n    uint8_t p_state[sizeof(s->block_state)];\n\n    uint8_t i_state[sizeof(s->block_state)];\n\n    RangeCoder pc, ic;\n\n    uint8_t *pbbak= s->c.bytestream;\n\n    uint8_t *pbbak_start= s->c.bytestream_start;\n\n    int score, score2, iscore, i_len, p_len, block_s, sum, base_bits;\n\n    const int w= s->b_width  << s->block_max_depth;\n\n    const int h= s->b_height << s->block_max_depth;\n\n    const int rem_depth= s->block_max_depth - level;\n\n    const int index= (x + y*w) << rem_depth;\n\n    const int block_w= 1<<(LOG2_MB_SIZE - level);\n\n    int trx= (x+1)<<rem_depth;\n\n    int try= (y+1)<<rem_depth;\n\n    const BlockNode *left  = x ? &s->block[index-1] : &null_block;\n\n    const BlockNode *top   = y ? &s->block[index-w] : &null_block;\n\n    const BlockNode *right = trx<w ? &s->block[index+1] : &null_block;\n\n    const BlockNode *bottom= try<h ? &s->block[index+w] : &null_block;\n\n    const BlockNode *tl    = y && x ? &s->block[index-w-1] : left;\n\n    const BlockNode *tr    = y && trx<w && ((x&1)==0 || level==0) ? &s->block[index-w+(1<<rem_depth)] : tl; //FIXME use lt\n\n    int pl = left->color[0];\n\n    int pcb= left->color[1];\n\n    int pcr= left->color[2];\n\n    int pmx, pmy;\n\n    int mx=0, my=0;\n\n    int l,cr,cb;\n\n    const int stride= s->current_picture->linesize[0];\n\n    const int uvstride= s->current_picture->linesize[1];\n\n    uint8_t *current_data[3]= { s->input_picture->data[0] + (x + y*  stride)*block_w,\n\n                                s->input_picture->data[1] + ((x*block_w)>>s->chroma_h_shift) + ((y*uvstride*block_w)>>s->chroma_v_shift),\n\n                                s->input_picture->data[2] + ((x*block_w)>>s->chroma_h_shift) + ((y*uvstride*block_w)>>s->chroma_v_shift)};\n\n    int P[10][2];\n\n    int16_t last_mv[3][2];\n\n    int qpel= !!(s->avctx->flags & AV_CODEC_FLAG_QPEL); //unused\n\n    const int shift= 1+qpel;\n\n    MotionEstContext *c= &s->m.me;\n\n    int ref_context= av_log2(2*left->ref) + av_log2(2*top->ref);\n\n    int mx_context= av_log2(2*FFABS(left->mx - top->mx));\n\n    int my_context= av_log2(2*FFABS(left->my - top->my));\n\n    int s_context= 2*left->level + 2*top->level + tl->level + tr->level;\n\n    int ref, best_ref, ref_score, ref_mx, ref_my;\n\n\n\n    av_assert0(sizeof(s->block_state) >= 256);\n\n    if(s->keyframe){\n\n        set_blocks(s, level, x, y, pl, pcb, pcr, 0, 0, 0, BLOCK_INTRA);\n\n        return 0;\n\n    }\n\n\n\n//    clip predictors / edge ?\n\n\n\n    P_LEFT[0]= left->mx;\n\n    P_LEFT[1]= left->my;\n\n    P_TOP [0]= top->mx;\n\n    P_TOP [1]= top->my;\n\n    P_TOPRIGHT[0]= tr->mx;\n\n    P_TOPRIGHT[1]= tr->my;\n\n\n\n    last_mv[0][0]= s->block[index].mx;\n\n    last_mv[0][1]= s->block[index].my;\n\n    last_mv[1][0]= right->mx;\n\n    last_mv[1][1]= right->my;\n\n    last_mv[2][0]= bottom->mx;\n\n    last_mv[2][1]= bottom->my;\n\n\n\n    s->m.mb_stride=2;\n\n    s->m.mb_x=\n\n    s->m.mb_y= 0;\n\n    c->skip= 0;\n\n\n\n    av_assert1(c->  stride ==   stride);\n\n    av_assert1(c->uvstride == uvstride);\n\n\n\n    c->penalty_factor    = get_penalty_factor(s->lambda, s->lambda2, c->avctx->me_cmp);\n\n    c->sub_penalty_factor= get_penalty_factor(s->lambda, s->lambda2, c->avctx->me_sub_cmp);\n\n    c->mb_penalty_factor = get_penalty_factor(s->lambda, s->lambda2, c->avctx->mb_cmp);\n\n    c->current_mv_penalty= c->mv_penalty[s->m.f_code=1] + MAX_MV;\n\n\n\n    c->xmin = - x*block_w - 16+3;\n\n    c->ymin = - y*block_w - 16+3;\n\n    c->xmax = - (x+1)*block_w + (w<<(LOG2_MB_SIZE - s->block_max_depth)) + 16-3;\n\n    c->ymax = - (y+1)*block_w + (h<<(LOG2_MB_SIZE - s->block_max_depth)) + 16-3;\n\n\n\n    if(P_LEFT[0]     > (c->xmax<<shift)) P_LEFT[0]    = (c->xmax<<shift);\n\n    if(P_LEFT[1]     > (c->ymax<<shift)) P_LEFT[1]    = (c->ymax<<shift);\n\n    if(P_TOP[0]      > (c->xmax<<shift)) P_TOP[0]     = (c->xmax<<shift);\n\n    if(P_TOP[1]      > (c->ymax<<shift)) P_TOP[1]     = (c->ymax<<shift);\n\n    if(P_TOPRIGHT[0] < (c->xmin<<shift)) P_TOPRIGHT[0]= (c->xmin<<shift);\n\n    if(P_TOPRIGHT[0] > (c->xmax<<shift)) P_TOPRIGHT[0]= (c->xmax<<shift); //due to pmx no clip\n\n    if(P_TOPRIGHT[1] > (c->ymax<<shift)) P_TOPRIGHT[1]= (c->ymax<<shift);\n\n\n\n    P_MEDIAN[0]= mid_pred(P_LEFT[0], P_TOP[0], P_TOPRIGHT[0]);\n\n    P_MEDIAN[1]= mid_pred(P_LEFT[1], P_TOP[1], P_TOPRIGHT[1]);\n\n\n\n    if (!y) {\n\n        c->pred_x= P_LEFT[0];\n\n        c->pred_y= P_LEFT[1];\n\n    } else {\n\n        c->pred_x = P_MEDIAN[0];\n\n        c->pred_y = P_MEDIAN[1];\n\n    }\n\n\n\n    score= INT_MAX;\n\n    best_ref= 0;\n\n    for(ref=0; ref<s->ref_frames; ref++){\n\n        init_ref(c, current_data, s->last_picture[ref]->data, NULL, block_w*x, block_w*y, 0);\n\n\n\n        ref_score= ff_epzs_motion_search(&s->m, &ref_mx, &ref_my, P, 0, /*ref_index*/ 0, last_mv,\n\n                                         (1<<16)>>shift, level-LOG2_MB_SIZE+4, block_w);\n\n\n\n        av_assert2(ref_mx >= c->xmin);\n\n        av_assert2(ref_mx <= c->xmax);\n\n        av_assert2(ref_my >= c->ymin);\n\n        av_assert2(ref_my <= c->ymax);\n\n\n\n        ref_score= c->sub_motion_search(&s->m, &ref_mx, &ref_my, ref_score, 0, 0, level-LOG2_MB_SIZE+4, block_w);\n\n        ref_score= ff_get_mb_score(&s->m, ref_mx, ref_my, 0, 0, level-LOG2_MB_SIZE+4, block_w, 0);\n\n        ref_score+= 2*av_log2(2*ref)*c->penalty_factor;\n\n        if(s->ref_mvs[ref]){\n\n            s->ref_mvs[ref][index][0]= ref_mx;\n\n            s->ref_mvs[ref][index][1]= ref_my;\n\n            s->ref_scores[ref][index]= ref_score;\n\n        }\n\n        if(score > ref_score){\n\n            score= ref_score;\n\n            best_ref= ref;\n\n            mx= ref_mx;\n\n            my= ref_my;\n\n        }\n\n    }\n\n    //FIXME if mb_cmp != SSE then intra cannot be compared currently and mb_penalty vs. lambda2\n\n\n\n  //  subpel search\n\n    base_bits= get_rac_count(&s->c) - 8*(s->c.bytestream - s->c.bytestream_start);\n\n    pc= s->c;\n\n    pc.bytestream_start=\n\n    pc.bytestream= p_buffer; //FIXME end/start? and at the other stoo\n\n    memcpy(p_state, s->block_state, sizeof(s->block_state));\n\n\n\n    if(level!=s->block_max_depth)\n\n        put_rac(&pc, &p_state[4 + s_context], 1);\n\n    put_rac(&pc, &p_state[1 + left->type + top->type], 0);\n\n    if(s->ref_frames > 1)\n\n        put_symbol(&pc, &p_state[128 + 1024 + 32*ref_context], best_ref, 0);\n\n    pred_mv(s, &pmx, &pmy, best_ref, left, top, tr);\n\n    put_symbol(&pc, &p_state[128 + 32*(mx_context + 16*!!best_ref)], mx - pmx, 1);\n\n    put_symbol(&pc, &p_state[128 + 32*(my_context + 16*!!best_ref)], my - pmy, 1);\n\n    p_len= pc.bytestream - pc.bytestream_start;\n\n    score += (s->lambda2*(get_rac_count(&pc)-base_bits))>>FF_LAMBDA_SHIFT;\n\n\n\n    block_s= block_w*block_w;\n\n    sum = pix_sum(current_data[0], stride, block_w, block_w);\n\n    l= (sum + block_s/2)/block_s;\n\n    iscore = pix_norm1(current_data[0], stride, block_w) - 2*l*sum + l*l*block_s;\n\n\n\n    if (s->nb_planes > 2) {\n\n        block_s= block_w*block_w>>(s->chroma_h_shift + s->chroma_v_shift);\n\n        sum = pix_sum(current_data[1], uvstride, block_w>>s->chroma_h_shift, block_w>>s->chroma_v_shift);\n\n        cb= (sum + block_s/2)/block_s;\n\n    //    iscore += pix_norm1(&current_mb[1][0], uvstride, block_w>>1) - 2*cb*sum + cb*cb*block_s;\n\n        sum = pix_sum(current_data[2], uvstride, block_w>>s->chroma_h_shift, block_w>>s->chroma_v_shift);\n\n        cr= (sum + block_s/2)/block_s;\n\n    //    iscore += pix_norm1(&current_mb[2][0], uvstride, block_w>>1) - 2*cr*sum + cr*cr*block_s;\n\n    }else\n\n        cb = cr = 0;\n\n\n\n    ic= s->c;\n\n    ic.bytestream_start=\n\n    ic.bytestream= i_buffer; //FIXME end/start? and at the other stoo\n\n    memcpy(i_state, s->block_state, sizeof(s->block_state));\n\n    if(level!=s->block_max_depth)\n\n        put_rac(&ic, &i_state[4 + s_context], 1);\n\n    put_rac(&ic, &i_state[1 + left->type + top->type], 1);\n\n    put_symbol(&ic, &i_state[32],  l-pl , 1);\n\n    if (s->nb_planes > 2) {\n\n        put_symbol(&ic, &i_state[64], cb-pcb, 1);\n\n        put_symbol(&ic, &i_state[96], cr-pcr, 1);\n\n    }\n\n    i_len= ic.bytestream - ic.bytestream_start;\n\n    iscore += (s->lambda2*(get_rac_count(&ic)-base_bits))>>FF_LAMBDA_SHIFT;\n\n\n\n    av_assert1(iscore < 255*255*256 + s->lambda2*10);\n\n    av_assert1(iscore >= 0);\n\n    av_assert1(l>=0 && l<=255);\n\n    av_assert1(pl>=0 && pl<=255);\n\n\n\n    if(level==0){\n\n        int varc= iscore >> 8;\n\n        int vard= score >> 8;\n\n        if (vard <= 64 || vard < varc)\n\n            c->scene_change_score+= ff_sqrt(vard) - ff_sqrt(varc);\n\n        else\n\n            c->scene_change_score+= s->m.qscale;\n\n    }\n\n\n\n    if(level!=s->block_max_depth){\n\n        put_rac(&s->c, &s->block_state[4 + s_context], 0);\n\n        score2 = encode_q_branch(s, level+1, 2*x+0, 2*y+0);\n\n        score2+= encode_q_branch(s, level+1, 2*x+1, 2*y+0);\n\n        score2+= encode_q_branch(s, level+1, 2*x+0, 2*y+1);\n\n        score2+= encode_q_branch(s, level+1, 2*x+1, 2*y+1);\n\n        score2+= s->lambda2>>FF_LAMBDA_SHIFT; //FIXME exact split overhead\n\n\n\n        if(score2 < score && score2 < iscore)\n\n            return score2;\n\n    }\n\n\n\n    if(iscore < score){\n\n        pred_mv(s, &pmx, &pmy, 0, left, top, tr);\n\n        memcpy(pbbak, i_buffer, i_len);\n\n        s->c= ic;\n\n        s->c.bytestream_start= pbbak_start;\n\n        s->c.bytestream= pbbak + i_len;\n\n        set_blocks(s, level, x, y, l, cb, cr, pmx, pmy, 0, BLOCK_INTRA);\n\n        memcpy(s->block_state, i_state, sizeof(s->block_state));\n\n        return iscore;\n\n    }else{\n\n        memcpy(pbbak, p_buffer, p_len);\n\n        s->c= pc;\n\n        s->c.bytestream_start= pbbak_start;\n\n        s->c.bytestream= pbbak + p_len;\n\n        set_blocks(s, level, x, y, pl, pcb, pcr, mx, my, best_ref, 0);\n\n        memcpy(s->block_state, p_state, sizeof(s->block_state));\n\n        return score;\n\n    }\n\n}\n", "idx": 23717}
{"project": "FFmpeg", "commit_id": "851ded8918c977d8160c6617b69604f758cabf50", "target": 0, "func": "static inline int decode_cabac_mb_transform_size( H264Context *h ) {\n\n    return get_cabac( &h->cabac, &h->cabac_state[399 + h->neighbor_transform_size] );\n\n}\n", "idx": 23718}
{"project": "FFmpeg", "commit_id": "0574780d7a196f87ddd89d6362f4c47f3532b4c4", "target": 1, "func": "static av_always_inline void filter_mb_dir(const H264Context *h, H264SliceContext *sl,\n\n                                           int mb_x, int mb_y,\n\n                                           uint8_t *img_y, uint8_t *img_cb, uint8_t *img_cr,\n\n                                           unsigned int linesize, unsigned int uvlinesize,\n\n                                           int mb_xy, int mb_type, int mvy_limit,\n\n                                           int first_vertical_edge_done, int a, int b,\n\n                                           int chroma, int dir)\n\n{\n\n    int edge;\n\n    int chroma_qp_avg[2];\n\n    int chroma444 = CHROMA444(h);\n\n    int chroma422 = CHROMA422(h);\n\n    const int mbm_xy = dir == 0 ? mb_xy -1 : sl->top_mb_xy;\n\n    const int mbm_type = dir == 0 ? sl->left_type[LTOP] : sl->top_type;\n\n\n\n    // how often to recheck mv-based bS when iterating between edges\n\n    static const uint8_t mask_edge_tab[2][8]={{0,3,3,3,1,1,1,1},\n\n                                              {0,3,1,1,3,3,3,3}};\n\n    const int mask_edge = mask_edge_tab[dir][(mb_type>>3)&7];\n\n    const int edges = mask_edge== 3 && !(sl->cbp&15) ? 1 : 4;\n\n\n\n    // how often to recheck mv-based bS when iterating along each edge\n\n    const int mask_par0 = mb_type & (MB_TYPE_16x16 | (MB_TYPE_8x16 >> dir));\n\n\n\n    if(mbm_type && !first_vertical_edge_done){\n\n\n\n        if (FRAME_MBAFF(h) && (dir == 1) && ((mb_y&1) == 0)\n\n            && IS_INTERLACED(mbm_type&~mb_type)\n\n            ) {\n\n            // This is a special case in the norm where the filtering must\n\n            // be done twice (one each of the field) even if we are in a\n\n            // frame macroblock.\n\n            //\n\n            unsigned int tmp_linesize   = 2 *   linesize;\n\n            unsigned int tmp_uvlinesize = 2 * uvlinesize;\n\n            int mbn_xy = mb_xy - 2 * h->mb_stride;\n\n            int j;\n\n\n\n            for(j=0; j<2; j++, mbn_xy += h->mb_stride){\n\n                DECLARE_ALIGNED(8, int16_t, bS)[4];\n\n                int qp;\n\n                if (IS_INTRA(mb_type | h->cur_pic.mb_type[mbn_xy])) {\n\n                    AV_WN64A(bS, 0x0003000300030003ULL);\n\n                } else {\n\n                    if (!CABAC(h) && IS_8x8DCT(h->cur_pic.mb_type[mbn_xy])) {\n\n                        bS[0]= 1+((h->cbp_table[mbn_xy] & 0x4000) || sl->non_zero_count_cache[scan8[0]+0]);\n\n                        bS[1]= 1+((h->cbp_table[mbn_xy] & 0x4000) || sl->non_zero_count_cache[scan8[0]+1]);\n\n                        bS[2]= 1+((h->cbp_table[mbn_xy] & 0x8000) || sl->non_zero_count_cache[scan8[0]+2]);\n\n                        bS[3]= 1+((h->cbp_table[mbn_xy] & 0x8000) || sl->non_zero_count_cache[scan8[0]+3]);\n\n                    }else{\n\n                    const uint8_t *mbn_nnz = h->non_zero_count[mbn_xy] + 3*4;\n\n                    int i;\n\n                    for( i = 0; i < 4; i++ ) {\n\n                        bS[i] = 1 + !!(sl->non_zero_count_cache[scan8[0]+i] | mbn_nnz[i]);\n\n                    }\n\n                    }\n\n                }\n\n                // Do not use s->qscale as luma quantizer because it has not the same\n\n                // value in IPCM macroblocks.\n\n                qp = (h->cur_pic.qscale_table[mb_xy] + h->cur_pic.qscale_table[mbn_xy] + 1) >> 1;\n\n                ff_tlog(h->avctx, \"filter mb:%d/%d dir:%d edge:%d, QPy:%d ls:%d uvls:%d\", mb_x, mb_y, dir, edge, qp, tmp_linesize, tmp_uvlinesize);\n\n                { int i; for (i = 0; i < 4; i++) ff_tlog(h->avctx, \" bS[%d]:%d\", i, bS[i]); ff_tlog(h->avctx, \"\\n\"); }\n\n                filter_mb_edgeh( &img_y[j*linesize], tmp_linesize, bS, qp, a, b, h, 0 );\n\n                chroma_qp_avg[0] = (sl->chroma_qp[0] + get_chroma_qp(h->ps.pps, 0, h->cur_pic.qscale_table[mbn_xy]) + 1) >> 1;\n\n                chroma_qp_avg[1] = (sl->chroma_qp[1] + get_chroma_qp(h->ps.pps, 1, h->cur_pic.qscale_table[mbn_xy]) + 1) >> 1;\n\n                if (chroma) {\n\n                    if (chroma444) {\n\n                        filter_mb_edgeh (&img_cb[j*uvlinesize], tmp_uvlinesize, bS, chroma_qp_avg[0], a, b, h, 0);\n\n                        filter_mb_edgeh (&img_cr[j*uvlinesize], tmp_uvlinesize, bS, chroma_qp_avg[1], a, b, h, 0);\n\n                    } else {\n\n                        filter_mb_edgech(&img_cb[j*uvlinesize], tmp_uvlinesize, bS, chroma_qp_avg[0], a, b, h, 0);\n\n                        filter_mb_edgech(&img_cr[j*uvlinesize], tmp_uvlinesize, bS, chroma_qp_avg[1], a, b, h, 0);\n\n                    }\n\n                }\n\n            }\n\n        }else{\n\n            DECLARE_ALIGNED(8, int16_t, bS)[4];\n\n            int qp;\n\n\n\n            if( IS_INTRA(mb_type|mbm_type)) {\n\n                AV_WN64A(bS, 0x0003000300030003ULL);\n\n                if (   (!IS_INTERLACED(mb_type|mbm_type))\n\n                    || ((FRAME_MBAFF(h) || (h->picture_structure != PICT_FRAME)) && (dir == 0))\n\n                )\n\n                    AV_WN64A(bS, 0x0004000400040004ULL);\n\n            } else {\n\n                int i;\n\n                int mv_done;\n\n\n\n                if( dir && FRAME_MBAFF(h) && IS_INTERLACED(mb_type ^ mbm_type)) {\n\n                    AV_WN64A(bS, 0x0001000100010001ULL);\n\n                    mv_done = 1;\n\n                }\n\n                else if( mask_par0 && ((mbm_type & (MB_TYPE_16x16 | (MB_TYPE_8x16 >> dir)))) ) {\n\n                    int b_idx= 8 + 4;\n\n                    int bn_idx= b_idx - (dir ? 8:1);\n\n\n\n                    bS[0] = bS[1] = bS[2] = bS[3] = check_mv(sl, 8 + 4, bn_idx, mvy_limit);\n\n                    mv_done = 1;\n\n                }\n\n                else\n\n                    mv_done = 0;\n\n\n\n                for( i = 0; i < 4; i++ ) {\n\n                    int x = dir == 0 ? 0 : i;\n\n                    int y = dir == 0 ? i    : 0;\n\n                    int b_idx= 8 + 4 + x + 8*y;\n\n                    int bn_idx= b_idx - (dir ? 8:1);\n\n\n\n                    if (sl->non_zero_count_cache[b_idx] |\n\n                        sl->non_zero_count_cache[bn_idx]) {\n\n                        bS[i] = 2;\n\n                    }\n\n                    else if(!mv_done)\n\n                    {\n\n                        bS[i] = check_mv(sl, b_idx, bn_idx, mvy_limit);\n\n                    }\n\n                }\n\n            }\n\n\n\n            /* Filter edge */\n\n            // Do not use s->qscale as luma quantizer because it has not the same\n\n            // value in IPCM macroblocks.\n\n            if(bS[0]+bS[1]+bS[2]+bS[3]){\n\n                qp = (h->cur_pic.qscale_table[mb_xy] + h->cur_pic.qscale_table[mbm_xy] + 1) >> 1;\n\n                ff_tlog(h->avctx, \"filter mb:%d/%d dir:%d edge:%d, QPy:%d ls:%d uvls:%d\", mb_x, mb_y, dir, edge, qp, linesize, uvlinesize);\n\n                chroma_qp_avg[0] = (sl->chroma_qp[0] + get_chroma_qp(h->ps.pps, 0, h->cur_pic.qscale_table[mbm_xy]) + 1) >> 1;\n\n                chroma_qp_avg[1] = (sl->chroma_qp[1] + get_chroma_qp(h->ps.pps, 1, h->cur_pic.qscale_table[mbm_xy]) + 1) >> 1;\n\n                if( dir == 0 ) {\n\n                    filter_mb_edgev( &img_y[0], linesize, bS, qp, a, b, h, 1 );\n\n                    if (chroma) {\n\n                        if (chroma444) {\n\n                            filter_mb_edgev ( &img_cb[0], uvlinesize, bS, chroma_qp_avg[0], a, b, h, 1);\n\n                            filter_mb_edgev ( &img_cr[0], uvlinesize, bS, chroma_qp_avg[1], a, b, h, 1);\n\n                        } else {\n\n                            filter_mb_edgecv( &img_cb[0], uvlinesize, bS, chroma_qp_avg[0], a, b, h, 1);\n\n                            filter_mb_edgecv( &img_cr[0], uvlinesize, bS, chroma_qp_avg[1], a, b, h, 1);\n\n                        }\n\n                    }\n\n                } else {\n\n                    filter_mb_edgeh( &img_y[0], linesize, bS, qp, a, b, h, 1 );\n\n                    if (chroma) {\n\n                        if (chroma444) {\n\n                            filter_mb_edgeh ( &img_cb[0], uvlinesize, bS, chroma_qp_avg[0], a, b, h, 1);\n\n                            filter_mb_edgeh ( &img_cr[0], uvlinesize, bS, chroma_qp_avg[1], a, b, h, 1);\n\n                        } else {\n\n                            filter_mb_edgech( &img_cb[0], uvlinesize, bS, chroma_qp_avg[0], a, b, h, 1);\n\n                            filter_mb_edgech( &img_cr[0], uvlinesize, bS, chroma_qp_avg[1], a, b, h, 1);\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    /* Calculate bS */\n\n    for( edge = 1; edge < edges; edge++ ) {\n\n        DECLARE_ALIGNED(8, int16_t, bS)[4];\n\n        int qp;\n\n        const int deblock_edge = !IS_8x8DCT(mb_type & (edge<<24)); // (edge&1) && IS_8x8DCT(mb_type)\n\n\n\n        if (!deblock_edge && (!chroma422 || dir == 0))\n\n            continue;\n\n\n\n        if( IS_INTRA(mb_type)) {\n\n            AV_WN64A(bS, 0x0003000300030003ULL);\n\n        } else {\n\n            int i;\n\n            int mv_done;\n\n\n\n            if( edge & mask_edge ) {\n\n                AV_ZERO64(bS);\n\n                mv_done = 1;\n\n            }\n\n            else if( mask_par0 ) {\n\n                int b_idx= 8 + 4 + edge * (dir ? 8:1);\n\n                int bn_idx= b_idx - (dir ? 8:1);\n\n\n\n                bS[0] = bS[1] = bS[2] = bS[3] = check_mv(sl, b_idx, bn_idx, mvy_limit);\n\n                mv_done = 1;\n\n            }\n\n            else\n\n                mv_done = 0;\n\n\n\n            for( i = 0; i < 4; i++ ) {\n\n                int x = dir == 0 ? edge : i;\n\n                int y = dir == 0 ? i    : edge;\n\n                int b_idx= 8 + 4 + x + 8*y;\n\n                int bn_idx= b_idx - (dir ? 8:1);\n\n\n\n                if (sl->non_zero_count_cache[b_idx] |\n\n                    sl->non_zero_count_cache[bn_idx]) {\n\n                    bS[i] = 2;\n\n                }\n\n                else if(!mv_done)\n\n                {\n\n                    bS[i] = check_mv(sl, b_idx, bn_idx, mvy_limit);\n\n                }\n\n            }\n\n\n\n            if(bS[0]+bS[1]+bS[2]+bS[3] == 0)\n\n                continue;\n\n        }\n\n\n\n        /* Filter edge */\n\n        // Do not use s->qscale as luma quantizer because it has not the same\n\n        // value in IPCM macroblocks.\n\n        qp = h->cur_pic.qscale_table[mb_xy];\n\n        ff_tlog(h->avctx, \"filter mb:%d/%d dir:%d edge:%d, QPy:%d ls:%d uvls:%d\", mb_x, mb_y, dir, edge, qp, linesize, uvlinesize);\n\n        if( dir == 0 ) {\n\n            filter_mb_edgev( &img_y[4*edge << h->pixel_shift], linesize, bS, qp, a, b, h, 0 );\n\n            if (chroma) {\n\n                if (chroma444) {\n\n                    filter_mb_edgev ( &img_cb[4*edge << h->pixel_shift], uvlinesize, bS, sl->chroma_qp[0], a, b, h, 0);\n\n                    filter_mb_edgev ( &img_cr[4*edge << h->pixel_shift], uvlinesize, bS, sl->chroma_qp[1], a, b, h, 0);\n\n                } else if( (edge&1) == 0 ) {\n\n                    filter_mb_edgecv( &img_cb[2*edge << h->pixel_shift], uvlinesize, bS, sl->chroma_qp[0], a, b, h, 0);\n\n                    filter_mb_edgecv( &img_cr[2*edge << h->pixel_shift], uvlinesize, bS, sl->chroma_qp[1], a, b, h, 0);\n\n                }\n\n            }\n\n        } else {\n\n            if (chroma422) {\n\n                if (deblock_edge)\n\n                    filter_mb_edgeh(&img_y[4*edge*linesize], linesize, bS, qp, a, b, h, 0);\n\n                if (chroma) {\n\n                    filter_mb_edgech(&img_cb[4*edge*uvlinesize], uvlinesize, bS, sl->chroma_qp[0], a, b, h, 0);\n\n                    filter_mb_edgech(&img_cr[4*edge*uvlinesize], uvlinesize, bS, sl->chroma_qp[1], a, b, h, 0);\n\n                }\n\n            } else {\n\n                filter_mb_edgeh(&img_y[4*edge*linesize], linesize, bS, qp, a, b, h, 0);\n\n                if (chroma) {\n\n                    if (chroma444) {\n\n                        filter_mb_edgeh (&img_cb[4*edge*uvlinesize], uvlinesize, bS, sl->chroma_qp[0], a, b, h, 0);\n\n                        filter_mb_edgeh (&img_cr[4*edge*uvlinesize], uvlinesize, bS, sl->chroma_qp[1], a, b, h, 0);\n\n                    } else if ((edge&1) == 0) {\n\n                        filter_mb_edgech(&img_cb[2*edge*uvlinesize], uvlinesize, bS, sl->chroma_qp[0], a, b, h, 0);\n\n                        filter_mb_edgech(&img_cr[2*edge*uvlinesize], uvlinesize, bS, sl->chroma_qp[1], a, b, h, 0);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 23719}
{"project": "FFmpeg", "commit_id": "71a3dff9d56b9ddf3aa8179bc4aed9724724068e", "target": 0, "func": "int ff_h263_decode_frame(AVCodecContext *avctx,\n\n                             void *data, int *data_size,\n\n                             const uint8_t *buf, int buf_size)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int ret;\n\n    AVFrame *pict = data;\n\n\n\n#ifdef PRINT_FRAME_TIME\n\nuint64_t time= rdtsc();\n\n#endif\n\n#ifdef DEBUG\n\n    av_log(avctx, AV_LOG_DEBUG, \"*****frame %d size=%d\\n\", avctx->frame_number, buf_size);\n\n    if(buf_size>0)\n\n        av_log(avctx, AV_LOG_DEBUG, \"bytes=%x %x %x %x\\n\", buf[0], buf[1], buf[2], buf[3]);\n\n#endif\n\n    s->flags= avctx->flags;\n\n    s->flags2= avctx->flags2;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0) {\n\n        /* special case for last picture */\n\n        if (s->low_delay==0 && s->next_picture_ptr) {\n\n            *pict= *(AVFrame*)s->next_picture_ptr;\n\n            s->next_picture_ptr= NULL;\n\n\n\n            *data_size = sizeof(AVFrame);\n\n        }\n\n\n\n        return 0;\n\n    }\n\n\n\n    if(s->flags&CODEC_FLAG_TRUNCATED){\n\n        int next;\n\n\n\n        if(CONFIG_MPEG4_DECODER && s->codec_id==CODEC_ID_MPEG4){\n\n            next= ff_mpeg4_find_frame_end(&s->parse_context, buf, buf_size);\n\n        }else if(CONFIG_H263_DECODER && s->codec_id==CODEC_ID_H263){\n\n            next= ff_h263_find_frame_end(&s->parse_context, buf, buf_size);\n\n        }else{\n\n            av_log(s->avctx, AV_LOG_ERROR, \"this codec does not support truncated bitstreams\\n\");\n\n            return -1;\n\n        }\n\n\n\n        if( ff_combine_frame(&s->parse_context, next, (const uint8_t **)&buf, &buf_size) < 0 )\n\n            return buf_size;\n\n    }\n\n\n\n\n\nretry:\n\n\n\n    if(s->bitstream_buffer_size && (s->divx_packed || buf_size<20)){ //divx 5.01+/xvid frame reorder\n\n        init_get_bits(&s->gb, s->bitstream_buffer, s->bitstream_buffer_size*8);\n\n    }else\n\n        init_get_bits(&s->gb, buf, buf_size*8);\n\n    s->bitstream_buffer_size=0;\n\n\n\n    if (!s->context_initialized) {\n\n        if (MPV_common_init(s) < 0) //we need the idct permutaton for reading a custom matrix\n\n            return -1;\n\n    }\n\n\n\n    /* We need to set current_picture_ptr before reading the header,\n\n     * otherwise we cannot store anyting in there */\n\n    if(s->current_picture_ptr==NULL || s->current_picture_ptr->data[0]){\n\n        int i= ff_find_unused_picture(s, 0);\n\n        s->current_picture_ptr= &s->picture[i];\n\n    }\n\n\n\n    /* let's go :-) */\n\n    if (CONFIG_WMV2_DECODER && s->msmpeg4_version==5) {\n\n        ret= ff_wmv2_decode_picture_header(s);\n\n    } else if (CONFIG_MSMPEG4_DECODER && s->msmpeg4_version) {\n\n        ret = msmpeg4_decode_picture_header(s);\n\n    } else if (s->h263_pred) {\n\n        if(s->avctx->extradata_size && s->picture_number==0){\n\n            GetBitContext gb;\n\n\n\n            init_get_bits(&gb, s->avctx->extradata, s->avctx->extradata_size*8);\n\n            ret = ff_mpeg4_decode_picture_header(s, &gb);\n\n        }\n\n        ret = ff_mpeg4_decode_picture_header(s, &s->gb);\n\n    } else if (s->codec_id == CODEC_ID_H263I) {\n\n        ret = intel_h263_decode_picture_header(s);\n\n    } else if (s->h263_flv) {\n\n        ret = flv_h263_decode_picture_header(s);\n\n    } else {\n\n        ret = h263_decode_picture_header(s);\n\n    }\n\n\n\n    if(ret==FRAME_SKIPPED) return get_consumed_bytes(s, buf_size);\n\n\n\n    /* skip if the header was thrashed */\n\n    if (ret < 0){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"header damaged\\n\");\n\n        return -1;\n\n    }\n\n\n\n    avctx->has_b_frames= !s->low_delay;\n\n\n\n    if(s->xvid_build==0 && s->divx_version==0 && s->lavc_build==0){\n\n        if(s->stream_codec_tag == AV_RL32(\"XVID\") ||\n\n           s->codec_tag == AV_RL32(\"XVID\") || s->codec_tag == AV_RL32(\"XVIX\") ||\n\n           s->codec_tag == AV_RL32(\"RMP4\"))\n\n            s->xvid_build= -1;\n\n#if 0\n\n        if(s->codec_tag == AV_RL32(\"DIVX\") && s->vo_type==0 && s->vol_control_parameters==1\n\n           && s->padding_bug_score > 0 && s->low_delay) // XVID with modified fourcc\n\n            s->xvid_build= -1;\n\n#endif\n\n    }\n\n\n\n    if(s->xvid_build==0 && s->divx_version==0 && s->lavc_build==0){\n\n        if(s->codec_tag == AV_RL32(\"DIVX\") && s->vo_type==0 && s->vol_control_parameters==0)\n\n            s->divx_version= 400; //divx 4\n\n    }\n\n\n\n    if(s->xvid_build && s->divx_version){\n\n        s->divx_version=\n\n        s->divx_build= 0;\n\n    }\n\n\n\n    if(s->workaround_bugs&FF_BUG_AUTODETECT){\n\n        if(s->codec_tag == AV_RL32(\"XVIX\"))\n\n            s->workaround_bugs|= FF_BUG_XVID_ILACE;\n\n\n\n        if(s->codec_tag == AV_RL32(\"UMP4\")){\n\n            s->workaround_bugs|= FF_BUG_UMP4;\n\n        }\n\n\n\n        if(s->divx_version>=500 && s->divx_build<1814){\n\n            s->workaround_bugs|= FF_BUG_QPEL_CHROMA;\n\n        }\n\n\n\n        if(s->divx_version>502 && s->divx_build<1814){\n\n            s->workaround_bugs|= FF_BUG_QPEL_CHROMA2;\n\n        }\n\n\n\n        if(s->xvid_build && s->xvid_build<=3)\n\n            s->padding_bug_score= 256*256*256*64;\n\n\n\n        if(s->xvid_build && s->xvid_build<=1)\n\n            s->workaround_bugs|= FF_BUG_QPEL_CHROMA;\n\n\n\n        if(s->xvid_build && s->xvid_build<=12)\n\n            s->workaround_bugs|= FF_BUG_EDGE;\n\n\n\n        if(s->xvid_build && s->xvid_build<=32)\n\n            s->workaround_bugs|= FF_BUG_DC_CLIP;\n\n\n\n#define SET_QPEL_FUNC(postfix1, postfix2) \\\n\n    s->dsp.put_ ## postfix1 = ff_put_ ## postfix2;\\\n\n    s->dsp.put_no_rnd_ ## postfix1 = ff_put_no_rnd_ ## postfix2;\\\n\n    s->dsp.avg_ ## postfix1 = ff_avg_ ## postfix2;\n\n\n\n        if(s->lavc_build && s->lavc_build<4653)\n\n            s->workaround_bugs|= FF_BUG_STD_QPEL;\n\n\n\n        if(s->lavc_build && s->lavc_build<4655)\n\n            s->workaround_bugs|= FF_BUG_DIRECT_BLOCKSIZE;\n\n\n\n        if(s->lavc_build && s->lavc_build<4670){\n\n            s->workaround_bugs|= FF_BUG_EDGE;\n\n        }\n\n\n\n        if(s->lavc_build && s->lavc_build<=4712)\n\n            s->workaround_bugs|= FF_BUG_DC_CLIP;\n\n\n\n        if(s->divx_version)\n\n            s->workaround_bugs|= FF_BUG_DIRECT_BLOCKSIZE;\n\n//printf(\"padding_bug_score: %d\\n\", s->padding_bug_score);\n\n        if(s->divx_version==501 && s->divx_build==20020416)\n\n            s->padding_bug_score= 256*256*256*64;\n\n\n\n        if(s->divx_version && s->divx_version<500){\n\n            s->workaround_bugs|= FF_BUG_EDGE;\n\n        }\n\n\n\n        if(s->divx_version)\n\n            s->workaround_bugs|= FF_BUG_HPEL_CHROMA;\n\n#if 0\n\n        if(s->divx_version==500)\n\n            s->padding_bug_score= 256*256*256*64;\n\n\n\n        /* very ugly XVID padding bug detection FIXME/XXX solve this differently\n\n         * Let us hope this at least works.\n\n         */\n\n        if(   s->resync_marker==0 && s->data_partitioning==0 && s->divx_version==0\n\n           && s->codec_id==CODEC_ID_MPEG4 && s->vo_type==0)\n\n            s->workaround_bugs|= FF_BUG_NO_PADDING;\n\n\n\n        if(s->lavc_build && s->lavc_build<4609) //FIXME not sure about the version num but a 4609 file seems ok\n\n            s->workaround_bugs|= FF_BUG_NO_PADDING;\n\n#endif\n\n    }\n\n\n\n    if(s->workaround_bugs& FF_BUG_STD_QPEL){\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][ 5], qpel16_mc11_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][ 7], qpel16_mc31_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][ 9], qpel16_mc12_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][11], qpel16_mc32_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][13], qpel16_mc13_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[0][15], qpel16_mc33_old_c)\n\n\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][ 5], qpel8_mc11_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][ 7], qpel8_mc31_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][ 9], qpel8_mc12_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][11], qpel8_mc32_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][13], qpel8_mc13_old_c)\n\n        SET_QPEL_FUNC(qpel_pixels_tab[1][15], qpel8_mc33_old_c)\n\n    }\n\n\n\n    if(avctx->debug & FF_DEBUG_BUGS)\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"bugs: %X lavc_build:%d xvid_build:%d divx_version:%d divx_build:%d %s\\n\",\n\n               s->workaround_bugs, s->lavc_build, s->xvid_build, s->divx_version, s->divx_build,\n\n               s->divx_packed ? \"p\" : \"\");\n\n\n\n#if 0 // dump bits per frame / qp / complexity\n\n{\n\n    static FILE *f=NULL;\n\n    if(!f) f=fopen(\"rate_qp_cplx.txt\", \"w\");\n\n    fprintf(f, \"%d %d %f\\n\", buf_size, s->qscale, buf_size*(double)s->qscale);\n\n}\n\n#endif\n\n\n\n#if HAVE_MMX\n\n    if(s->codec_id == CODEC_ID_MPEG4 && s->xvid_build && avctx->idct_algo == FF_IDCT_AUTO && (mm_flags & FF_MM_MMX)){\n\n        avctx->idct_algo= FF_IDCT_XVIDMMX;\n\n        avctx->coded_width= 0; // force reinit\n\n//        dsputil_init(&s->dsp, avctx);\n\n        s->picture_number=0;\n\n    }\n\n#endif\n\n\n\n        /* After H263 & mpeg4 header decode we have the height, width,*/\n\n        /* and other parameters. So then we could init the picture   */\n\n        /* FIXME: By the way H263 decoder is evolving it should have */\n\n        /* an H263EncContext                                         */\n\n\n\n    if (   s->width  != avctx->coded_width\n\n        || s->height != avctx->coded_height) {\n\n        /* H.263 could change picture size any time */\n\n        ParseContext pc= s->parse_context; //FIXME move these demuxng hack to avformat\n\n        s->parse_context.buffer=0;\n\n        MPV_common_end(s);\n\n        s->parse_context= pc;\n\n    }\n\n    if (!s->context_initialized) {\n\n        avcodec_set_dimensions(avctx, s->width, s->height);\n\n\n\n        goto retry;\n\n    }\n\n\n\n    if((s->codec_id==CODEC_ID_H263 || s->codec_id==CODEC_ID_H263P))\n\n        s->gob_index = ff_h263_get_gob_height(s);\n\n\n\n    // for hurry_up==5\n\n    s->current_picture.pict_type= s->pict_type;\n\n    s->current_picture.key_frame= s->pict_type == FF_I_TYPE;\n\n\n\n    /* skip B-frames if we don't have reference frames */\n\n    if(s->last_picture_ptr==NULL && (s->pict_type==FF_B_TYPE || s->dropable)) return get_consumed_bytes(s, buf_size);\n\n    /* skip b frames if we are in a hurry */\n\n    if(avctx->hurry_up && s->pict_type==FF_B_TYPE) return get_consumed_bytes(s, buf_size);\n\n    if(   (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type==FF_B_TYPE)\n\n       || (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type!=FF_I_TYPE)\n\n       ||  avctx->skip_frame >= AVDISCARD_ALL)\n\n        return get_consumed_bytes(s, buf_size);\n\n    /* skip everything if we are in a hurry>=5 */\n\n    if(avctx->hurry_up>=5) return get_consumed_bytes(s, buf_size);\n\n\n\n    if(s->next_p_frame_damaged){\n\n        if(s->pict_type==FF_B_TYPE)\n\n            return get_consumed_bytes(s, buf_size);\n\n        else\n\n            s->next_p_frame_damaged=0;\n\n    }\n\n\n\n    if((s->avctx->flags2 & CODEC_FLAG2_FAST) && s->pict_type==FF_B_TYPE){\n\n        s->me.qpel_put= s->dsp.put_2tap_qpel_pixels_tab;\n\n        s->me.qpel_avg= s->dsp.avg_2tap_qpel_pixels_tab;\n\n    }else if((!s->no_rounding) || s->pict_type==FF_B_TYPE){\n\n        s->me.qpel_put= s->dsp.put_qpel_pixels_tab;\n\n        s->me.qpel_avg= s->dsp.avg_qpel_pixels_tab;\n\n    }else{\n\n        s->me.qpel_put= s->dsp.put_no_rnd_qpel_pixels_tab;\n\n        s->me.qpel_avg= s->dsp.avg_qpel_pixels_tab;\n\n    }\n\n\n\n    if(MPV_frame_start(s, avctx) < 0)\n\n        return -1;\n\n\n\n#ifdef DEBUG\n\n    av_log(avctx, AV_LOG_DEBUG, \"qscale=%d\\n\", s->qscale);\n\n#endif\n\n\n\n    ff_er_frame_start(s);\n\n\n\n    //the second part of the wmv2 header contains the MB skip bits which are stored in current_picture->mb_type\n\n    //which is not available before MPV_frame_start()\n\n    if (CONFIG_WMV2_DECODER && s->msmpeg4_version==5){\n\n        ret = ff_wmv2_decode_secondary_picture_header(s);\n\n        if(ret<0) return ret;\n\n        if(ret==1) goto intrax8_decoded;\n\n    }\n\n\n\n    /* decode each macroblock */\n\n    s->mb_x=0;\n\n    s->mb_y=0;\n\n\n\n    decode_slice(s);\n\n    while(s->mb_y<s->mb_height){\n\n        if(s->msmpeg4_version){\n\n            if(s->slice_height==0 || s->mb_x!=0 || (s->mb_y%s->slice_height)!=0 || get_bits_count(&s->gb) > s->gb.size_in_bits)\n\n                break;\n\n        }else{\n\n            if(ff_h263_resync(s)<0)\n\n                break;\n\n        }\n\n\n\n        if(s->msmpeg4_version<4 && s->h263_pred)\n\n            ff_mpeg4_clean_buffers(s);\n\n\n\n        decode_slice(s);\n\n    }\n\n\n\n    if (s->h263_msmpeg4 && s->msmpeg4_version<4 && s->pict_type==FF_I_TYPE)\n\n        if(!CONFIG_MSMPEG4_DECODER || msmpeg4_decode_ext_header(s, buf_size) < 0){\n\n            s->error_status_table[s->mb_num-1]= AC_ERROR|DC_ERROR|MV_ERROR;\n\n        }\n\n\n\n    /* divx 5.01+ bistream reorder stuff */\n\n    if(s->codec_id==CODEC_ID_MPEG4 && s->bitstream_buffer_size==0 && s->divx_packed){\n\n        int current_pos= get_bits_count(&s->gb)>>3;\n\n        int startcode_found=0;\n\n\n\n        if(buf_size - current_pos > 5){\n\n            int i;\n\n            for(i=current_pos; i<buf_size-3; i++){\n\n                if(buf[i]==0 && buf[i+1]==0 && buf[i+2]==1 && buf[i+3]==0xB6){\n\n                    startcode_found=1;\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n        if(s->gb.buffer == s->bitstream_buffer && buf_size>20){ //xvid style\n\n            startcode_found=1;\n\n            current_pos=0;\n\n        }\n\n\n\n        if(startcode_found){\n\n            s->bitstream_buffer= av_fast_realloc(\n\n                s->bitstream_buffer,\n\n                &s->allocated_bitstream_buffer_size,\n\n                buf_size - current_pos + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            memcpy(s->bitstream_buffer, buf + current_pos, buf_size - current_pos);\n\n            s->bitstream_buffer_size= buf_size - current_pos;\n\n        }\n\n    }\n\n\n\nintrax8_decoded:\n\n    ff_er_frame_end(s);\n\n\n\n    MPV_frame_end(s);\n\n\n\nassert(s->current_picture.pict_type == s->current_picture_ptr->pict_type);\n\nassert(s->current_picture.pict_type == s->pict_type);\n\n    if (s->pict_type == FF_B_TYPE || s->low_delay) {\n\n        *pict= *(AVFrame*)s->current_picture_ptr;\n\n    } else if (s->last_picture_ptr != NULL) {\n\n        *pict= *(AVFrame*)s->last_picture_ptr;\n\n    }\n\n\n\n    if(s->last_picture_ptr || s->low_delay){\n\n        *data_size = sizeof(AVFrame);\n\n        ff_print_debug_info(s, pict);\n\n    }\n\n\n\n    /* Return the Picture timestamp as the frame number */\n\n    /* we subtract 1 because it is added on utils.c     */\n\n    avctx->frame_number = s->picture_number - 1;\n\n\n\n#ifdef PRINT_FRAME_TIME\n\nav_log(avctx, AV_LOG_DEBUG, \"%\"PRId64\"\\n\", rdtsc()-time);\n\n#endif\n\n\n\n    return get_consumed_bytes(s, buf_size);\n\n}\n", "idx": 23720}
{"project": "FFmpeg", "commit_id": "386d60f9783ac094dae6c3c9210e0469f98c9147", "target": 1, "func": "static av_always_inline int lcg_random(int previous_val)\n\n{\n\n    return previous_val * 1664525 + 1013904223;\n\n}\n", "idx": 23722}
{"project": "FFmpeg", "commit_id": "f9d7e9feec2a0fd7f7930d01876a70a9b8a4a3b9", "target": 1, "func": "static int open_slave(AVFormatContext *avf, char *slave, TeeSlave *tee_slave)\n\n{\n\n    int i, ret;\n\n    AVDictionary *options = NULL;\n\n    AVDictionaryEntry *entry;\n\n    char *filename;\n\n    char *format = NULL, *select = NULL;\n\n    AVFormatContext *avf2 = NULL;\n\n    AVStream *st, *st2;\n\n    int stream_count;\n\n    int fullret;\n\n    char *subselect = NULL, *next_subselect = NULL, *first_subselect = NULL, *tmp_select = NULL;\n\n\n\n    if ((ret = parse_slave_options(avf, slave, &options, &filename)) < 0)\n\n        return ret;\n\n\n\n#define STEAL_OPTION(option, field) do {                                \\\n\n        if ((entry = av_dict_get(options, option, NULL, 0))) {          \\\n\n            field = entry->value;                                       \\\n\n            entry->value = NULL; /* prevent it from being freed */      \\\n\n            av_dict_set(&options, option, NULL, 0);                     \\\n\n        }                                                               \\\n\n    } while (0)\n\n\n\n    STEAL_OPTION(\"f\", format);\n\n    STEAL_OPTION(\"select\", select);\n\n\n\n    ret = avformat_alloc_output_context2(&avf2, NULL, format, filename);\n\n    if (ret < 0)\n\n        goto end;\n\n    av_dict_copy(&avf2->metadata, avf->metadata, 0);\n\n    avf2->opaque   = avf->opaque;\n\n    avf2->io_open  = avf->io_open;\n\n    avf2->io_close = avf->io_close;\n\n\n\n    tee_slave->stream_map = av_calloc(avf->nb_streams, sizeof(*tee_slave->stream_map));\n\n    if (!tee_slave->stream_map) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto end;\n\n    }\n\n\n\n    stream_count = 0;\n\n    for (i = 0; i < avf->nb_streams; i++) {\n\n        st = avf->streams[i];\n\n        if (select) {\n\n            tmp_select = av_strdup(select);  // av_strtok is destructive so we regenerate it in each loop\n\n            if (!tmp_select) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto end;\n\n            }\n\n            fullret = 0;\n\n            first_subselect = tmp_select;\n\n            next_subselect = NULL;\n\n            while (subselect = av_strtok(first_subselect, slave_select_sep, &next_subselect)) {\n\n                first_subselect = NULL;\n\n\n\n                ret = avformat_match_stream_specifier(avf, avf->streams[i], subselect);\n\n                if (ret < 0) {\n\n                    av_log(avf, AV_LOG_ERROR,\n\n                           \"Invalid stream specifier '%s' for output '%s'\\n\",\n\n                           subselect, slave);\n\n                    goto end;\n\n                }\n\n                if (ret != 0) {\n\n                    fullret = 1; // match\n\n                    break;\n\n                }\n\n            }\n\n            av_freep(&tmp_select);\n\n\n\n            if (fullret == 0) { /* no match */\n\n                tee_slave->stream_map[i] = -1;\n\n                continue;\n\n            }\n\n        }\n\n        tee_slave->stream_map[i] = stream_count++;\n\n\n\n        if (!(st2 = avformat_new_stream(avf2, NULL))) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto end;\n\n        }\n\n        st2->id = st->id;\n\n        st2->r_frame_rate        = st->r_frame_rate;\n\n        st2->time_base           = st->time_base;\n\n        st2->start_time          = st->start_time;\n\n        st2->duration            = st->duration;\n\n        st2->nb_frames           = st->nb_frames;\n\n        st2->disposition         = st->disposition;\n\n        st2->sample_aspect_ratio = st->sample_aspect_ratio;\n\n        st2->avg_frame_rate      = st->avg_frame_rate;\n\n        av_dict_copy(&st2->metadata, st->metadata, 0);\n\n        if ((ret = avcodec_parameters_copy(st2->codecpar, st->codecpar)) < 0)\n\n            goto end;\n\n    }\n\n\n\n    if (!(avf2->oformat->flags & AVFMT_NOFILE)) {\n\n        if ((ret = avf2->io_open(avf2, &avf2->pb, filename, AVIO_FLAG_WRITE, NULL)) < 0) {\n\n            av_log(avf, AV_LOG_ERROR, \"Slave '%s': error opening: %s\\n\",\n\n                   slave, av_err2str(ret));\n\n            goto end;\n\n        }\n\n    }\n\n\n\n    if ((ret = avformat_write_header(avf2, &options)) < 0) {\n\n        av_log(avf, AV_LOG_ERROR, \"Slave '%s': error writing header: %s\\n\",\n\n               slave, av_err2str(ret));\n\n        goto end;\n\n    }\n\n\n\n    tee_slave->avf = avf2;\n\n    tee_slave->bsfs = av_calloc(avf2->nb_streams, sizeof(TeeSlave));\n\n    if (!tee_slave->bsfs) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto end;\n\n    }\n\n\n\n    entry = NULL;\n\n    while (entry = av_dict_get(options, \"bsfs\", NULL, AV_DICT_IGNORE_SUFFIX)) {\n\n        const char *spec = entry->key + strlen(\"bsfs\");\n\n        if (*spec) {\n\n            if (strspn(spec, slave_bsfs_spec_sep) != 1) {\n\n                av_log(avf, AV_LOG_ERROR,\n\n                       \"Specifier separator in '%s' is '%c', but only characters '%s' \"\n\n                       \"are allowed\\n\", entry->key, *spec, slave_bsfs_spec_sep);\n\n                return AVERROR(EINVAL);\n\n            }\n\n            spec++; /* consume separator */\n\n        }\n\n\n\n        for (i = 0; i < avf2->nb_streams; i++) {\n\n            ret = avformat_match_stream_specifier(avf2, avf2->streams[i], spec);\n\n            if (ret < 0) {\n\n                av_log(avf, AV_LOG_ERROR,\n\n                       \"Invalid stream specifier '%s' in bsfs option '%s' for slave \"\n\n                       \"output '%s'\\n\", spec, entry->key, filename);\n\n                goto end;\n\n            }\n\n\n\n            if (ret > 0) {\n\n                av_log(avf, AV_LOG_DEBUG, \"spec:%s bsfs:%s matches stream %d of slave \"\n\n                       \"output '%s'\\n\", spec, entry->value, i, filename);\n\n                if (tee_slave->bsfs[i]) {\n\n                    av_log(avf, AV_LOG_WARNING,\n\n                           \"Duplicate bsfs specification associated to stream %d of slave \"\n\n                           \"output '%s', filters will be ignored\\n\", i, filename);\n\n                    continue;\n\n                }\n\n                ret = parse_bsfs(avf, entry->value, &tee_slave->bsfs[i]);\n\n                if (ret < 0) {\n\n                    av_log(avf, AV_LOG_ERROR,\n\n                           \"Error parsing bitstream filter sequence '%s' associated to \"\n\n                           \"stream %d of slave output '%s'\\n\", entry->value, i, filename);\n\n                    goto end;\n\n                }\n\n            }\n\n        }\n\n\n\n        av_dict_set(&options, entry->key, NULL, 0);\n\n    }\n\n\n\n    if (options) {\n\n        entry = NULL;\n\n        while ((entry = av_dict_get(options, \"\", entry, AV_DICT_IGNORE_SUFFIX)))\n\n            av_log(avf2, AV_LOG_ERROR, \"Unknown option '%s'\\n\", entry->key);\n\n        ret = AVERROR_OPTION_NOT_FOUND;\n\n        goto end;\n\n    }\n\n\n\nend:\n\n    av_free(format);\n\n    av_free(select);\n\n    av_dict_free(&options);\n\n    av_freep(&tmp_select);\n\n    return ret;\n\n}\n", "idx": 23725}
{"project": "FFmpeg", "commit_id": "1891dfe0130991ee138d01f2877678de717b9e23", "target": 1, "func": "static av_cold int cuvid_decode_init(AVCodecContext *avctx)\n\n{\n\n    CuvidContext *ctx = avctx->priv_data;\n\n    AVCUDADeviceContext *device_hwctx;\n\n    AVHWDeviceContext *device_ctx;\n\n    AVHWFramesContext *hwframe_ctx;\n\n    CUVIDPARSERPARAMS cuparseinfo;\n\n    CUVIDEOFORMATEX cuparse_ext;\n\n    CUVIDSOURCEDATAPACKET seq_pkt;\n\n    CUdevice device;\n\n    CUcontext cuda_ctx = NULL;\n\n    CUcontext dummy;\n\n    const AVBitStreamFilter *bsf;\n\n    int ret = 0;\n\n\n\n    enum AVPixelFormat pix_fmts[3] = { AV_PIX_FMT_CUDA,\n\n                                       AV_PIX_FMT_NV12,\n\n                                       AV_PIX_FMT_NONE };\n\n\n\n    ret = ff_get_format(avctx, pix_fmts);\n\n    if (ret < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"ff_get_format failed: %d\\n\", ret);\n\n        return ret;\n\n    }\n\n\n\n    ctx->frame_queue = av_fifo_alloc(MAX_FRAME_COUNT * sizeof(CUVIDPARSERDISPINFO));\n\n    if (!ctx->frame_queue) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto error;\n\n    }\n\n\n\n    avctx->pix_fmt = ret;\n\n\n\n    if (avctx->hw_frames_ctx) {\n\n        ctx->hwframe = av_buffer_ref(avctx->hw_frames_ctx);\n\n        if (!ctx->hwframe) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto error;\n\n        }\n\n\n\n        hwframe_ctx = (AVHWFramesContext*)ctx->hwframe->data;\n\n\n\n        ctx->hwdevice = av_buffer_ref(hwframe_ctx->device_ref);\n\n        if (!ctx->hwdevice) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto error;\n\n        }\n\n\n\n        device_ctx = hwframe_ctx->device_ctx;\n\n        device_hwctx = device_ctx->hwctx;\n\n        cuda_ctx = device_hwctx->cuda_ctx;\n\n    } else {\n\n        ctx->hwdevice = av_hwdevice_ctx_alloc(AV_HWDEVICE_TYPE_CUDA);\n\n        if (!ctx->hwdevice) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Error allocating hwdevice\\n\");\n\n            ret = AVERROR(ENOMEM);\n\n            goto error;\n\n        }\n\n\n\n        ret = CHECK_CU(cuInit(0));\n\n        if (ret < 0)\n\n            goto error;\n\n\n\n        ret = CHECK_CU(cuDeviceGet(&device, 0));\n\n        if (ret < 0)\n\n            goto error;\n\n\n\n        ret = CHECK_CU(cuCtxCreate(&cuda_ctx, CU_CTX_SCHED_BLOCKING_SYNC, device));\n\n        if (ret < 0)\n\n            goto error;\n\n\n\n        device_ctx = (AVHWDeviceContext*)ctx->hwdevice->data;\n\n        device_ctx->free = cuvid_ctx_free;\n\n\n\n        device_hwctx = device_ctx->hwctx;\n\n        device_hwctx->cuda_ctx = cuda_ctx;\n\n\n\n        ret = CHECK_CU(cuCtxPopCurrent(&dummy));\n\n        if (ret < 0)\n\n            goto error;\n\n\n\n        ret = av_hwdevice_ctx_init(ctx->hwdevice);\n\n        if (ret < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"av_hwdevice_ctx_init failed\\n\");\n\n            goto error;\n\n        }\n\n\n\n        ctx->hwframe = av_hwframe_ctx_alloc(ctx->hwdevice);\n\n        if (!ctx->hwframe) {\n\n            av_log(avctx, AV_LOG_ERROR, \"av_hwframe_ctx_alloc failed\\n\");\n\n            ret = AVERROR(ENOMEM);\n\n            goto error;\n\n        }\n\n    }\n\n\n\n    memset(&cuparseinfo, 0, sizeof(cuparseinfo));\n\n    memset(&cuparse_ext, 0, sizeof(cuparse_ext));\n\n    memset(&seq_pkt, 0, sizeof(seq_pkt));\n\n\n\n    cuparseinfo.pExtVideoInfo = &cuparse_ext;\n\n\n\n    switch (avctx->codec->id) {\n\n\n\n\n\n\n#if CONFIG_H264_CUVID_DECODER\n\n    case AV_CODEC_ID_H264:\n\n        cuparseinfo.CodecType = cudaVideoCodec_H264;\n\n\n\n#if CONFIG_HEVC_CUVID_DECODER\n\n    case AV_CODEC_ID_HEVC:\n\n        cuparseinfo.CodecType = cudaVideoCodec_HEVC;\n\n\n\n#if CONFIG_MJPEG_CUVID_DECODER\n\n    case AV_CODEC_ID_MJPEG:\n\n        cuparseinfo.CodecType = cudaVideoCodec_JPEG;\n\n\n\n#if CONFIG_MPEG1_CUVID_DECODER\n\n    case AV_CODEC_ID_MPEG1VIDEO:\n\n        cuparseinfo.CodecType = cudaVideoCodec_MPEG1;\n\n\n\n#if CONFIG_MPEG2_CUVID_DECODER\n\n    case AV_CODEC_ID_MPEG2VIDEO:\n\n        cuparseinfo.CodecType = cudaVideoCodec_MPEG2;\n\n\n\n#if CONFIG_MPEG4_CUVID_DECODER\n\n    case AV_CODEC_ID_MPEG4:\n\n\n\n\n#if CONFIG_VP8_CUVID_DECODER\n\n    case AV_CODEC_ID_VP8:\n\n        cuparseinfo.CodecType = cudaVideoCodec_VP8;\n\n\n\n#if CONFIG_VP9_CUVID_DECODER\n\n    case AV_CODEC_ID_VP9:\n\n        cuparseinfo.CodecType = cudaVideoCodec_VP9;\n\n\n\n#if CONFIG_VC1_CUVID_DECODER\n\n    case AV_CODEC_ID_VC1:\n\n        cuparseinfo.CodecType = cudaVideoCodec_VC1;\n\n\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid CUVID codec!\\n\");\n\n        return AVERROR_BUG;\n\n    }\n\n\n\n    if (avctx->codec->id == AV_CODEC_ID_H264 || avctx->codec->id == AV_CODEC_ID_HEVC) {\n\n        if (avctx->codec->id == AV_CODEC_ID_H264)\n\n            bsf = av_bsf_get_by_name(\"h264_mp4toannexb\");\n\n        else\n\n            bsf = av_bsf_get_by_name(\"hevc_mp4toannexb\");\n\n\n\n        if (!bsf) {\n\n            ret = AVERROR_BSF_NOT_FOUND;\n\n            goto error;\n\n        }\n\n        if (ret = av_bsf_alloc(bsf, &ctx->bsf)) {\n\n            goto error;\n\n        }\n\n        if (((ret = avcodec_parameters_from_context(ctx->bsf->par_in, avctx)) < 0) || ((ret = av_bsf_init(ctx->bsf)) < 0)) {\n\n            av_bsf_free(&ctx->bsf);\n\n            goto error;\n\n        }\n\n\n\n        cuparse_ext.format.seqhdr_data_length = ctx->bsf->par_out->extradata_size;\n\n        memcpy(cuparse_ext.raw_seqhdr_data,\n\n               ctx->bsf->par_out->extradata,\n\n               FFMIN(sizeof(cuparse_ext.raw_seqhdr_data), ctx->bsf->par_out->extradata_size));\n\n    } else if (avctx->extradata_size > 0) {\n\n        cuparse_ext.format.seqhdr_data_length = avctx->extradata_size;\n\n        memcpy(cuparse_ext.raw_seqhdr_data,\n\n               avctx->extradata,\n\n               FFMIN(sizeof(cuparse_ext.raw_seqhdr_data), avctx->extradata_size));\n\n    }\n\n\n\n    cuparseinfo.ulMaxNumDecodeSurfaces = MAX_FRAME_COUNT;\n\n    cuparseinfo.ulMaxDisplayDelay = 4;\n\n    cuparseinfo.pUserData = avctx;\n\n    cuparseinfo.pfnSequenceCallback = cuvid_handle_video_sequence;\n\n    cuparseinfo.pfnDecodePicture = cuvid_handle_picture_decode;\n\n    cuparseinfo.pfnDisplayPicture = cuvid_handle_picture_display;\n\n\n\n    ret = CHECK_CU(cuCtxPushCurrent(cuda_ctx));\n\n    if (ret < 0)\n\n        goto error;\n\n\n\n    ret = cuvid_test_dummy_decoder(avctx, &cuparseinfo);\n\n    if (ret < 0)\n\n        goto error;\n\n\n\n    ret = CHECK_CU(cuvidCreateVideoParser(&ctx->cuparser, &cuparseinfo));\n\n    if (ret < 0)\n\n        goto error;\n\n\n\n    seq_pkt.payload = cuparse_ext.raw_seqhdr_data;\n\n    seq_pkt.payload_size = cuparse_ext.format.seqhdr_data_length;\n\n\n\n    if (seq_pkt.payload && seq_pkt.payload_size) {\n\n        ret = CHECK_CU(cuvidParseVideoData(ctx->cuparser, &seq_pkt));\n\n        if (ret < 0)\n\n            goto error;\n\n    }\n\n\n\n    ret = CHECK_CU(cuCtxPopCurrent(&dummy));\n\n    if (ret < 0)\n\n        goto error;\n\n\n\n    return 0;\n\n\n\nerror:\n\n    cuvid_decode_end(avctx);\n\n    return ret;\n\n}", "idx": 23730}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "static void fill_scaling_lists(const AVCodecContext *avctx, AVDXVAContext *ctx, const H264Context *h, DXVA_Qmatrix_H264 *qm)\n\n{\n\n    unsigned i, j;\n\n    memset(qm, 0, sizeof(*qm));\n\n    if (DXVA_CONTEXT_WORKAROUND(avctx, ctx) & FF_DXVA2_WORKAROUND_SCALING_LIST_ZIGZAG) {\n\n        for (i = 0; i < 6; i++)\n\n            for (j = 0; j < 16; j++)\n\n                qm->bScalingLists4x4[i][j] = h->pps.scaling_matrix4[i][j];\n\n\n\n        for (i = 0; i < 64; i++) {\n\n            qm->bScalingLists8x8[0][i] = h->pps.scaling_matrix8[0][i];\n\n            qm->bScalingLists8x8[1][i] = h->pps.scaling_matrix8[3][i];\n\n        }\n\n    } else {\n\n        for (i = 0; i < 6; i++)\n\n            for (j = 0; j < 16; j++)\n\n                qm->bScalingLists4x4[i][j] = h->pps.scaling_matrix4[i][ff_zigzag_scan[j]];\n\n\n\n        for (i = 0; i < 64; i++) {\n\n            qm->bScalingLists8x8[0][i] = h->pps.scaling_matrix8[0][ff_zigzag_direct[i]];\n\n            qm->bScalingLists8x8[1][i] = h->pps.scaling_matrix8[3][ff_zigzag_direct[i]];\n\n        }\n\n    }\n\n}\n", "idx": 23731}
{"project": "FFmpeg", "commit_id": "ebba2b3e2a551ce638d17332761431ba748f178f", "target": 0, "func": "static int tcp_wait_fd(int fd, int write)\n\n{\n\n    int ev = write ? POLLOUT : POLLIN;\n\n    struct pollfd p = { .fd = fd, .events = ev, .revents = 0 };\n\n    int ret;\n\n\n\n    ret = poll(&p, 1, 100);\n\n    return ret < 0 ? ff_neterrno() : p.revents & ev ? 0 : AVERROR(EAGAIN);\n\n}\n", "idx": 23732}
{"project": "FFmpeg", "commit_id": "77015443a84bb5dbed38eafc2ea26a2bf2641ed6", "target": 0, "func": "static int file_check(URLContext *h, int mask)\n\n{\n\n#if HAVE_ACCESS && defined(R_OK)\n\n    int ret = 0;\n\n    if (access(h->filename, F_OK) < 0)\n\n        return AVERROR(errno);\n\n    if (mask&AVIO_FLAG_READ)\n\n        if (access(h->filename, R_OK) >= 0)\n\n            ret |= AVIO_FLAG_READ;\n\n    if (mask&AVIO_FLAG_WRITE)\n\n        if (access(h->filename, W_OK) >= 0)\n\n            ret |= AVIO_FLAG_WRITE;\n\n#else\n\n    struct stat st;\n\n    int ret = stat(h->filename, &st);\n\n    if (ret < 0)\n\n        return AVERROR(errno);\n\n\n\n    ret |= st.st_mode&S_IRUSR ? mask&AVIO_FLAG_READ  : 0;\n\n    ret |= st.st_mode&S_IWUSR ? mask&AVIO_FLAG_WRITE : 0;\n\n#endif\n\n    return ret;\n\n}\n", "idx": 23734}
{"project": "FFmpeg", "commit_id": "332f9ac4e31ce5e6d0c42ac9e0229d7d1b2b4d60", "target": 0, "func": "static int rv10_decode_packet(AVCodecContext *avctx, \n\n                             uint8_t *buf, int buf_size)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int i, mb_count, mb_pos, left;\n\n\n\n    init_get_bits(&s->gb, buf, buf_size*8);\n\n#if 0\n\n    for(i=0; i<buf_size*8 && i<100; i++)\n\n        printf(\"%d\", get_bits1(&s->gb));\n\n    printf(\"\\n\");\n\n    return 0;\n\n#endif\n\n    if(s->codec_id ==CODEC_ID_RV10)\n\n        mb_count = rv10_decode_picture_header(s);\n\n    else\n\n        mb_count = rv20_decode_picture_header(s);\n\n    if (mb_count < 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"HEADER ERROR\\n\");\n\n        return -1;\n\n    }\n\n    \n\n    if (s->mb_x >= s->mb_width ||\n\n        s->mb_y >= s->mb_height) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"POS ERROR %d %d\\n\", s->mb_x, s->mb_y);\n\n        return -1;\n\n    }\n\n    mb_pos = s->mb_y * s->mb_width + s->mb_x;\n\n    left = s->mb_width * s->mb_height - mb_pos;\n\n    if (mb_count > left) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"COUNT ERROR\\n\");\n\n        return -1;\n\n    }\n\n//if(s->pict_type == P_TYPE) return 0;\n\n\n\n    if (s->mb_x == 0 && s->mb_y == 0) {\n\n        if(MPV_frame_start(s, avctx) < 0)\n\n            return -1;\n\n    }\n\n\n\n#ifdef DEBUG\n\n    printf(\"qscale=%d\\n\", s->qscale);\n\n#endif\n\n\n\n    /* default quantization values */\n\n    if(s->codec_id== CODEC_ID_RV10){\n\n        if(s->mb_y==0) s->first_slice_line=1;\n\n    }else{\n\n        s->first_slice_line=1;    \n\n        s->resync_mb_x= s->mb_x;\n\n        s->resync_mb_y= s->mb_y;\n\n    }\n\n    if(s->h263_aic){\n\n        s->y_dc_scale_table= \n\n        s->c_dc_scale_table= ff_aic_dc_scale_table;\n\n    }else{\n\n        s->y_dc_scale_table=\n\n        s->c_dc_scale_table= ff_mpeg1_dc_scale_table;\n\n    }\n\n    s->y_dc_scale= s->y_dc_scale_table[ s->qscale ];\n\n    s->c_dc_scale= s->c_dc_scale_table[ s->qscale ];\n\n    \n\n    s->rv10_first_dc_coded[0] = 0;\n\n    s->rv10_first_dc_coded[1] = 0;\n\n    s->rv10_first_dc_coded[2] = 0;\n\n\n\n    s->block_wrap[0]=\n\n    s->block_wrap[1]=\n\n    s->block_wrap[2]=\n\n    s->block_wrap[3]= s->mb_width*2 + 2;\n\n    s->block_wrap[4]=\n\n    s->block_wrap[5]= s->mb_width + 2;\n\n    ff_init_block_index(s);\n\n    /* decode each macroblock */\n\n    for(i=0;i<mb_count;i++) {\n\n        int ret;\n\n        ff_update_block_index(s);\n\n#ifdef DEBUG\n\n        printf(\"**mb x=%d y=%d\\n\", s->mb_x, s->mb_y);\n\n#endif\n\n        \n\n\ts->dsp.clear_blocks(s->block[0]);\n\n        s->mv_dir = MV_DIR_FORWARD;\n\n        s->mv_type = MV_TYPE_16X16; \n\n        ret=ff_h263_decode_mb(s, s->block);\n\n\n\n        if (ret == SLICE_ERROR) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"ERROR at MB %d %d\\n\", s->mb_x, s->mb_y);\n\n            return -1;\n\n        }\n\n        ff_h263_update_motion_val(s);\n\n        MPV_decode_mb(s, s->block);\n\n        if (++s->mb_x == s->mb_width) {\n\n            s->mb_x = 0;\n\n            s->mb_y++;\n\n            ff_init_block_index(s);\n\n        }\n\n        if(s->mb_x == s->resync_mb_x)\n\n            s->first_slice_line=0;\n\n        if(ret == SLICE_END) break;\n\n    }\n\n\n\n    return buf_size;\n\n}\n", "idx": 23745}
{"project": "FFmpeg", "commit_id": "8b31c086b6065084644b86a63c9171f3094cf6ad", "target": 0, "func": "static int decode_tag(AVCodecContext * avctx,\n\n                      void *data, int *data_size,\n\n                      AVPacket *avpkt) {\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    NellyMoserDecodeContext *s = avctx->priv_data;\n\n    int blocks, i;\n\n    int16_t* samples;\n\n    *data_size = 0;\n\n    samples = (int16_t*)data;\n\n\n\n    if (buf_size < avctx->block_align)\n\n        return buf_size;\n\n\n\n    if (buf_size % 64) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Tag size %d.\\n\", buf_size);\n\n        return buf_size;\n\n    }\n\n    blocks = buf_size / 64;\n\n    /* Normal numbers of blocks for sample rates:\n\n     *  8000 Hz - 1\n\n     * 11025 Hz - 2\n\n     * 16000 Hz - 3\n\n     * 22050 Hz - 4\n\n     * 44100 Hz - 8\n\n     */\n\n\n\n    for (i=0 ; i<blocks ; i++) {\n\n        nelly_decode_block(s, &buf[i*NELLY_BLOCK_LEN], s->float_buf);\n\n        s->fmt_conv.float_to_int16(&samples[i*NELLY_SAMPLES], s->float_buf, NELLY_SAMPLES);\n\n        *data_size += NELLY_SAMPLES*sizeof(int16_t);\n\n    }\n\n\n\n    return buf_size;\n\n}\n", "idx": 23756}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static void RENAME(extract_even)(const uint8_t *src, uint8_t *dst, x86_reg count)\n\n{\n\n    dst +=   count;\n\n    src += 2*count;\n\n    count= - count;\n\n\n\n#if COMPILE_TEMPLATE_MMX\n\n    if(count <= -16) {\n\n        count += 15;\n\n        __asm__ volatile(\n\n            \"pcmpeqw       %%mm7, %%mm7        \\n\\t\"\n\n            \"psrlw            $8, %%mm7        \\n\\t\"\n\n            \"1:                                \\n\\t\"\n\n            \"movq -30(%1, %0, 2), %%mm0        \\n\\t\"\n\n            \"movq -22(%1, %0, 2), %%mm1        \\n\\t\"\n\n            \"movq -14(%1, %0, 2), %%mm2        \\n\\t\"\n\n            \"movq  -6(%1, %0, 2), %%mm3        \\n\\t\"\n\n            \"pand          %%mm7, %%mm0        \\n\\t\"\n\n            \"pand          %%mm7, %%mm1        \\n\\t\"\n\n            \"pand          %%mm7, %%mm2        \\n\\t\"\n\n            \"pand          %%mm7, %%mm3        \\n\\t\"\n\n            \"packuswb      %%mm1, %%mm0        \\n\\t\"\n\n            \"packuswb      %%mm3, %%mm2        \\n\\t\"\n\n            MOVNTQ\"        %%mm0,-15(%2, %0)   \\n\\t\"\n\n            MOVNTQ\"        %%mm2,- 7(%2, %0)   \\n\\t\"\n\n            \"add             $16, %0           \\n\\t\"\n\n            \" js 1b                            \\n\\t\"\n\n            : \"+r\"(count)\n\n            : \"r\"(src), \"r\"(dst)\n\n        );\n\n        count -= 15;\n\n    }\n\n#endif\n\n    while(count<0) {\n\n        dst[count]= src[2*count];\n\n        count++;\n\n    }\n\n}\n", "idx": 23759}
{"project": "FFmpeg", "commit_id": "d6737539e77e78fca9a04914d51996cfd1ccc55c", "target": 0, "func": "static void intra_predict_horiz_16x16_msa(uint8_t *src, int32_t src_stride,\n\n                                          uint8_t *dst, int32_t dst_stride)\n\n{\n\n    uint32_t row;\n\n    uint8_t inp0, inp1, inp2, inp3;\n\n    v16u8 src0, src1, src2, src3;\n\n\n\n    for (row = 4; row--;) {\n\n        inp0 = src[0];\n\n        src += src_stride;\n\n        inp1 = src[0];\n\n        src += src_stride;\n\n        inp2 = src[0];\n\n        src += src_stride;\n\n        inp3 = src[0];\n\n        src += src_stride;\n\n\n\n        src0 = (v16u8) __msa_fill_b(inp0);\n\n        src1 = (v16u8) __msa_fill_b(inp1);\n\n        src2 = (v16u8) __msa_fill_b(inp2);\n\n        src3 = (v16u8) __msa_fill_b(inp3);\n\n\n\n        ST_UB4(src0, src1, src2, src3, dst, dst_stride);\n\n        dst += (4 * dst_stride);\n\n    }\n\n}\n", "idx": 23760}
{"project": "FFmpeg", "commit_id": "5705dc527687fd84d94c934169b6bd753459744f", "target": 1, "func": "int av_image_check_sar(unsigned int w, unsigned int h, AVRational sar)\n\n{\n\n    int64_t scaled_dim;\n\n\n\n    if (!sar.den)\n\n        return AVERROR(EINVAL);\n\n\n\n    if (!sar.num || sar.num == sar.den)\n\n        return 0;\n\n\n\n    if (sar.num < sar.den)\n\n        scaled_dim = av_rescale_rnd(w, sar.num, sar.den, AV_ROUND_ZERO);\n\n    else\n\n        scaled_dim = av_rescale_rnd(h, sar.den, sar.num, AV_ROUND_ZERO);\n\n\n\n    if (scaled_dim > 0)\n\n        return 0;\n\n\n\n    return AVERROR(EINVAL);\n\n}\n", "idx": 23762}
{"project": "FFmpeg", "commit_id": "d94c577d3c61e428cfcbcd3dc3a80bd848077eae", "target": 0, "func": "int read_file(const char *filename, char **bufptr, size_t *size)\n\n{\n\n    FILE *f = fopen(filename, \"rb\");\n\n\n\n    if (!f) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Cannot read file '%s': %s\\n\", filename, strerror(errno));\n\n        return AVERROR(errno);\n\n    }\n\n    fseek(f, 0, SEEK_END);\n\n    *size = ftell(f);\n\n    fseek(f, 0, SEEK_SET);\n\n    *bufptr = av_malloc(*size + 1);\n\n    if (!*bufptr) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Could not allocate file buffer\\n\");\n\n        fclose(f);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    fread(*bufptr, 1, *size, f);\n\n    (*bufptr)[*size++] = '\\0';\n\n\n\n    fclose(f);\n\n    return 0;\n\n}\n", "idx": 23764}
{"project": "FFmpeg", "commit_id": "9d73e302537144877ca9d5b648b21aca28b78f4f", "target": 1, "func": "int64_t ff_gen_search(AVFormatContext *s, int stream_index, int64_t target_ts,\n\n                      int64_t pos_min, int64_t pos_max, int64_t pos_limit,\n\n                      int64_t ts_min, int64_t ts_max, int flags, int64_t *ts_ret,\n\n                      int64_t (*read_timestamp)(struct AVFormatContext *, int , int64_t *, int64_t ))\n\n{\n\n    int64_t pos, ts;\n\n    int64_t start_pos, filesize;\n\n    int no_change;\n\n\n\n    av_dlog(s, \"gen_seek: %d %s\\n\", stream_index, av_ts2str(target_ts));\n\n\n\n    if(ts_min == AV_NOPTS_VALUE){\n\n        pos_min = s->data_offset;\n\n        ts_min = ff_read_timestamp(s, stream_index, &pos_min, INT64_MAX, read_timestamp);\n\n        if (ts_min == AV_NOPTS_VALUE)\n\n            return -1;\n\n    }\n\n\n\n    if(ts_min >= target_ts){\n\n        *ts_ret= ts_min;\n\n        return pos_min;\n\n    }\n\n\n\n    if(ts_max == AV_NOPTS_VALUE){\n\n        int step= 1024;\n\n        filesize = avio_size(s->pb);\n\n        pos_max = filesize - 1;\n\n        do{\n\n            pos_max = FFMAX(0, pos_max - step);\n\n            ts_max = ff_read_timestamp(s, stream_index, &pos_max, pos_max + step, read_timestamp);\n\n            step += step;\n\n        }while(ts_max == AV_NOPTS_VALUE && pos_max > 0);\n\n        if (ts_max == AV_NOPTS_VALUE)\n\n            return -1;\n\n\n\n        for(;;){\n\n            int64_t tmp_pos= pos_max + 1;\n\n            int64_t tmp_ts= ff_read_timestamp(s, stream_index, &tmp_pos, INT64_MAX, read_timestamp);\n\n            if(tmp_ts == AV_NOPTS_VALUE)\n\n                break;\n\n            ts_max= tmp_ts;\n\n            pos_max= tmp_pos;\n\n            if(tmp_pos >= filesize)\n\n                break;\n\n        }\n\n        pos_limit= pos_max;\n\n    }\n\n\n\n    if(ts_max <= target_ts){\n\n        *ts_ret= ts_max;\n\n        return pos_max;\n\n    }\n\n\n\n    if(ts_min > ts_max){\n\n        return -1;\n\n    }else if(ts_min == ts_max){\n\n        pos_limit= pos_min;\n\n    }\n\n\n\n    no_change=0;\n\n    while (pos_min < pos_limit) {\n\n        av_dlog(s, \"pos_min=0x%\"PRIx64\" pos_max=0x%\"PRIx64\" dts_min=%s dts_max=%s\\n\",\n\n                pos_min, pos_max, av_ts2str(ts_min), av_ts2str(ts_max));\n\n        assert(pos_limit <= pos_max);\n\n\n\n        if(no_change==0){\n\n            int64_t approximate_keyframe_distance= pos_max - pos_limit;\n\n            // interpolate position (better than dichotomy)\n\n            pos = av_rescale(target_ts - ts_min, pos_max - pos_min, ts_max - ts_min)\n\n                + pos_min - approximate_keyframe_distance;\n\n        }else if(no_change==1){\n\n            // bisection, if interpolation failed to change min or max pos last time\n\n            pos = (pos_min + pos_limit)>>1;\n\n        }else{\n\n            /* linear search if bisection failed, can only happen if there\n\n               are very few or no keyframes between min/max */\n\n            pos=pos_min;\n\n        }\n\n        if(pos <= pos_min)\n\n            pos= pos_min + 1;\n\n        else if(pos > pos_limit)\n\n            pos= pos_limit;\n\n        start_pos= pos;\n\n\n\n        ts = ff_read_timestamp(s, stream_index, &pos, INT64_MAX, read_timestamp); //may pass pos_limit instead of -1\n\n        if(pos == pos_max)\n\n            no_change++;\n\n        else\n\n            no_change=0;\n\n        av_dlog(s, \"%\"PRId64\" %\"PRId64\" %\"PRId64\" / %s %s %s target:%s limit:%\"PRId64\" start:%\"PRId64\" noc:%d\\n\",\n\n                pos_min, pos, pos_max,\n\n                av_ts2str(ts_min), av_ts2str(ts), av_ts2str(ts_max), av_ts2str(target_ts),\n\n                pos_limit, start_pos, no_change);\n\n        if(ts == AV_NOPTS_VALUE){\n\n            av_log(s, AV_LOG_ERROR, \"read_timestamp() failed in the middle\\n\");\n\n            return -1;\n\n        }\n\n        assert(ts != AV_NOPTS_VALUE);\n\n        if (target_ts <= ts) {\n\n            pos_limit = start_pos - 1;\n\n            pos_max = pos;\n\n            ts_max = ts;\n\n        }\n\n        if (target_ts >= ts) {\n\n            pos_min = pos;\n\n            ts_min = ts;\n\n        }\n\n    }\n\n\n\n    pos = (flags & AVSEEK_FLAG_BACKWARD) ? pos_min : pos_max;\n\n    ts  = (flags & AVSEEK_FLAG_BACKWARD) ?  ts_min :  ts_max;\n\n#if 0\n\n    pos_min = pos;\n\n    ts_min = ff_read_timestamp(s, stream_index, &pos_min, INT64_MAX, read_timestamp);\n\n    pos_min++;\n\n    ts_max = ff_read_timestamp(s, stream_index, &pos_min, INT64_MAX, read_timestamp);\n\n    av_dlog(s, \"pos=0x%\"PRIx64\" %s<=%s<=%s\\n\",\n\n            pos, av_ts2str(ts_min), av_ts2str(target_ts), av_ts2str(ts_max));\n\n#endif\n\n    *ts_ret= ts;\n\n    return pos;\n\n}\n", "idx": 23765}
{"project": "FFmpeg", "commit_id": "6179dc8aa7e5fc5358b9614306f93f1adadf22a4", "target": 1, "func": "static inline int get_amv(Mpeg4DecContext *ctx, int n)\n\n{\n\n    MpegEncContext *s = &ctx->m;\n\n    int x, y, mb_v, sum, dx, dy, shift;\n\n    int len     = 1 << (s->f_code + 4);\n\n    const int a = s->sprite_warping_accuracy;\n\n\n\n    if (s->workaround_bugs & FF_BUG_AMV)\n\n        len >>= s->quarter_sample;\n\n\n\n    if (s->real_sprite_warping_points == 1) {\n\n        if (ctx->divx_version == 500 && ctx->divx_build == 413)\n\n            sum = s->sprite_offset[0][n] / (1 << (a - s->quarter_sample));\n\n        else\n\n            sum = RSHIFT(s->sprite_offset[0][n] << s->quarter_sample, a);\n\n    } else {\n\n        dx    = s->sprite_delta[n][0];\n\n        dy    = s->sprite_delta[n][1];\n\n        shift = ctx->sprite_shift[0];\n\n        if (n)\n\n            dy -= 1 << (shift + a + 1);\n\n        else\n\n            dx -= 1 << (shift + a + 1);\n\n        mb_v = s->sprite_offset[0][n] + dx * s->mb_x * 16 + dy * s->mb_y * 16;\n\n\n\n        sum = 0;\n\n        for (y = 0; y < 16; y++) {\n\n            int v;\n\n\n\n            v = mb_v + dy * y;\n\n            // FIXME optimize\n\n            for (x = 0; x < 16; x++) {\n\n                sum += v >> shift;\n\n                v   += dx;\n\n            }\n\n        }\n\n        sum = RSHIFT(sum, a + 8 - s->quarter_sample);\n\n    }\n\n\n\n    if (sum < -len)\n\n        sum = -len;\n\n    else if (sum >= len)\n\n        sum = len - 1;\n\n\n\n    return sum;\n\n}\n", "idx": 23767}
{"project": "FFmpeg", "commit_id": "ba47d519e537299179d20b9a599c5824589a3f7a", "target": 1, "func": "static void decode_gray_bitstream(HYuvContext *s, int count)\n\n{\n\n    int i;\n\n    OPEN_READER(re, &s->gb);\n\n    count /= 2;\n\n\n\n    if (count >= (get_bits_left(&s->gb)) / (32 * 2)) {\n\n        for (i = 0; i < count && get_bits_left(&s->gb) > 0; i++) {\n\n            READ_2PIX(s->temp[0][2 * i], s->temp[0][2 * i + 1], 0);\n\n        }\n\n    } else {\n\n        for (i = 0; i < count; i++) {\n\n            READ_2PIX(s->temp[0][2 * i], s->temp[0][2 * i + 1], 0);\n\n        }\n\n    }\n\n    CLOSE_READER(re, &s->gb);\n\n}\n", "idx": 23769}
{"project": "FFmpeg", "commit_id": "be8d812c9635f31f69c30dff9ebf565a07a7dab7", "target": 1, "func": "static void ready_codebook(vorbis_enc_codebook *cb)\n\n{\n\n    int i;\n\n\n\n    ff_vorbis_len2vlc(cb->lens, cb->codewords, cb->nentries);\n\n\n\n    if (!cb->lookup) {\n\n        cb->pow2 = cb->dimentions = NULL;\n\n    } else {\n\n        int vals = cb_lookup_vals(cb->lookup, cb->ndimentions, cb->nentries);\n\n        cb->dimentions = av_malloc(sizeof(float) * cb->nentries * cb->ndimentions);\n\n        cb->pow2 = av_mallocz(sizeof(float) * cb->nentries);\n\n        for (i = 0; i < cb->nentries; i++) {\n\n            float last = 0;\n\n            int j;\n\n            int div = 1;\n\n            for (j = 0; j < cb->ndimentions; j++) {\n\n                int off;\n\n                if (cb->lookup == 1)\n\n                    off = (i / div) % vals; // lookup type 1\n\n                else\n\n                    off = i * cb->ndimentions + j; // lookup type 2\n\n\n\n                cb->dimentions[i * cb->ndimentions + j] = last + cb->min + cb->quantlist[off] * cb->delta;\n\n                if (cb->seq_p)\n\n                    last = cb->dimentions[i * cb->ndimentions + j];\n\n                cb->pow2[i] += cb->dimentions[i * cb->ndimentions + j] * cb->dimentions[i * cb->ndimentions + j];\n\n                div *= vals;\n\n            }\n\n            cb->pow2[i] /= 2.;\n\n        }\n\n    }\n\n}\n", "idx": 23775}
{"project": "FFmpeg", "commit_id": "6b6b84ae1625ce1e38ff5f1b4c0bf03450066e66", "target": 1, "func": "static int adx_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    int buf_size        = avpkt->size;\n\n    ADXContext *c       = avctx->priv_data;\n\n    int16_t *samples;\n\n    const uint8_t *buf  = avpkt->data;\n\n    int num_blocks, ch, ret;\n\n\n\n    if (c->eof) {\n\n        *got_frame_ptr = 0;\n\n        return buf_size;\n\n    }\n\n\n\n    if(AV_RB16(buf) == 0x8000){\n\n        int header_size;\n\n        if ((ret = avpriv_adx_decode_header(avctx, buf,\n\n                                            buf_size, &header_size,\n\n                                            c->coeff)) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"error parsing ADX header\\n\");\n\n\n        }\n\n        c->channels = avctx->channels;\n\n        if(buf_size < header_size)\n\n\n        buf += header_size;\n\n        buf_size -= header_size;\n\n    }\n\n\n\n\n\n    /* calculate number of blocks in the packet */\n\n    num_blocks = buf_size / (BLOCK_SIZE * c->channels);\n\n\n\n    /* if the packet is not an even multiple of BLOCK_SIZE, check for an EOF\n\n       packet */\n\n    if (!num_blocks || buf_size % (BLOCK_SIZE * avctx->channels)) {\n\n        if (buf_size >= 4 && (AV_RB16(buf) & 0x8000)) {\n\n            c->eof = 1;\n\n            *got_frame_ptr = 0;\n\n            return avpkt->size;\n\n        }\n\n\n    }\n\n\n\n    /* get output buffer */\n\n    c->frame.nb_samples = num_blocks * BLOCK_SAMPLES;\n\n    if ((ret = avctx->get_buffer(avctx, &c->frame)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n    samples = (int16_t *)c->frame.data[0];\n\n\n\n    while (num_blocks--) {\n\n        for (ch = 0; ch < c->channels; ch++) {\n\n            if (adx_decode(c, samples + ch, buf, ch)) {\n\n                c->eof = 1;\n\n                buf = avpkt->data + avpkt->size;\n\n                break;\n\n            }\n\n            buf_size -= BLOCK_SIZE;\n\n            buf      += BLOCK_SIZE;\n\n        }\n\n        samples += BLOCK_SAMPLES * c->channels;\n\n    }\n\n\n\n    *got_frame_ptr   = 1;\n\n    *(AVFrame *)data = c->frame;\n\n\n\n    return buf - avpkt->data;\n\n}", "idx": 23776}
{"project": "FFmpeg", "commit_id": "4ddb3a6df0f6ad053c8455e074c1e6688b051272", "target": 1, "func": "static int gif_read_image(GifState *s, AVFrame *frame)\n\n{\n\n    int left, top, width, height, bits_per_pixel, code_size, flags;\n\n    int is_interleaved, has_local_palette, y, pass, y1, linesize, pal_size;\n\n    uint32_t *ptr, *pal, *px, *pr, *ptr1;\n\n    int ret;\n\n    uint8_t *idx;\n\n\n\n    /* At least 9 bytes of Image Descriptor. */\n\n    if (bytestream2_get_bytes_left(&s->gb) < 9)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    left   = bytestream2_get_le16u(&s->gb);\n\n    top    = bytestream2_get_le16u(&s->gb);\n\n    width  = bytestream2_get_le16u(&s->gb);\n\n    height = bytestream2_get_le16u(&s->gb);\n\n    flags  = bytestream2_get_byteu(&s->gb);\n\n    is_interleaved = flags & 0x40;\n\n    has_local_palette = flags & 0x80;\n\n    bits_per_pixel = (flags & 0x07) + 1;\n\n\n\n    av_dlog(s->avctx, \"image x=%d y=%d w=%d h=%d\\n\", left, top, width, height);\n\n\n\n    if (has_local_palette) {\n\n        pal_size = 1 << bits_per_pixel;\n\n\n\n        if (bytestream2_get_bytes_left(&s->gb) < pal_size * 3)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        gif_read_palette(s, s->local_palette, pal_size);\n\n        pal = s->local_palette;\n\n    } else {\n\n        if (!s->has_global_palette) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"picture doesn't have either global or local palette.\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        pal = s->global_palette;\n\n    }\n\n\n\n    if (s->keyframe) {\n\n        if (s->transparent_color_index == -1 && s->has_global_palette) {\n\n            /* transparency wasn't set before the first frame, fill with background color */\n\n            gif_fill(frame, s->bg_color);\n\n        } else {\n\n            /* otherwise fill with transparent color.\n\n             * this is necessary since by default picture filled with 0x80808080. */\n\n            gif_fill(frame, s->trans_color);\n\n        }\n\n    }\n\n\n\n    /* verify that all the image is inside the screen dimensions */\n\n    if (left + width > s->screen_width ||\n\n        top + height > s->screen_height) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"image is outside the screen dimensions.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (width <= 0 || height <= 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid image dimensions.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* process disposal method */\n\n    if (s->gce_prev_disposal == GCE_DISPOSAL_BACKGROUND) {\n\n        gif_fill_rect(frame, s->stored_bg_color, s->gce_l, s->gce_t, s->gce_w, s->gce_h);\n\n    } else if (s->gce_prev_disposal == GCE_DISPOSAL_RESTORE) {\n\n        gif_copy_img_rect(s->stored_img, (uint32_t *)frame->data[0],\n\n            frame->linesize[0] / sizeof(uint32_t), s->gce_l, s->gce_t, s->gce_w, s->gce_h);\n\n    }\n\n\n\n    s->gce_prev_disposal = s->gce_disposal;\n\n\n\n    if (s->gce_disposal != GCE_DISPOSAL_NONE) {\n\n        s->gce_l = left;  s->gce_t = top;\n\n        s->gce_w = width; s->gce_h = height;\n\n\n\n        if (s->gce_disposal == GCE_DISPOSAL_BACKGROUND) {\n\n            if (s->transparent_color_index >= 0)\n\n                s->stored_bg_color = s->trans_color;\n\n            else\n\n                s->stored_bg_color = s->bg_color;\n\n        } else if (s->gce_disposal == GCE_DISPOSAL_RESTORE) {\n\n            av_fast_malloc(&s->stored_img, &s->stored_img_size, frame->linesize[0] * frame->height);\n\n            if (!s->stored_img)\n\n                return AVERROR(ENOMEM);\n\n\n\n            gif_copy_img_rect((uint32_t *)frame->data[0], s->stored_img,\n\n                frame->linesize[0] / sizeof(uint32_t), left, top, width, height);\n\n        }\n\n    }\n\n\n\n    /* Expect at least 2 bytes: 1 for lzw code size and 1 for block size. */\n\n    if (bytestream2_get_bytes_left(&s->gb) < 2)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    /* now get the image data */\n\n    code_size = bytestream2_get_byteu(&s->gb);\n\n    if ((ret = ff_lzw_decode_init(s->lzw, code_size, s->gb.buffer,\n\n                                  bytestream2_get_bytes_left(&s->gb), FF_LZW_GIF)) < 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"LZW init failed\\n\");\n\n        return ret;\n\n    }\n\n\n\n    /* read all the image */\n\n    linesize = frame->linesize[0] / sizeof(uint32_t);\n\n    ptr1 = (uint32_t *)frame->data[0] + top * linesize + left;\n\n    ptr = ptr1;\n\n    pass = 0;\n\n    y1 = 0;\n\n    for (y = 0; y < height; y++) {\n\n        int count = ff_lzw_decode(s->lzw, s->idx_line, width);\n\n        if (count != width) {\n\n            if (count)\n\n                av_log(s->avctx, AV_LOG_ERROR, \"LZW decode failed\\n\");\n\n            goto decode_tail;\n\n        }\n\n\n\n        pr = ptr + width;\n\n\n\n        for (px = ptr, idx = s->idx_line; px < pr; px++, idx++) {\n\n            if (*idx != s->transparent_color_index)\n\n                *px = pal[*idx];\n\n        }\n\n\n\n        if (is_interleaved) {\n\n            switch(pass) {\n\n            default:\n\n            case 0:\n\n            case 1:\n\n                y1 += 8;\n\n                ptr += linesize * 8;\n\n                if (y1 >= height) {\n\n                    y1 = pass ? 2 : 4;\n\n                    ptr = ptr1 + linesize * y1;\n\n                    pass++;\n\n                }\n\n                break;\n\n            case 2:\n\n                y1 += 4;\n\n                ptr += linesize * 4;\n\n                if (y1 >= height) {\n\n                    y1 = 1;\n\n                    ptr = ptr1 + linesize;\n\n                    pass++;\n\n                }\n\n                break;\n\n            case 3:\n\n                y1 += 2;\n\n                ptr += linesize * 2;\n\n                break;\n\n            }\n\n        } else {\n\n            ptr += linesize;\n\n        }\n\n    }\n\n\n\n decode_tail:\n\n    /* read the garbage data until end marker is found */\n\n    ff_lzw_decode_tail(s->lzw);\n\n\n\n    /* Graphic Control Extension's scope is single frame.\n\n     * Remove its influence. */\n\n    s->transparent_color_index = -1;\n\n    s->gce_disposal = GCE_DISPOSAL_NONE;\n\n\n\n    return 0;\n\n}\n", "idx": 23780}
{"project": "FFmpeg", "commit_id": "e32bbd411242658717b0dd637dd85da4c8b40437", "target": 1, "func": "static int decode_slice_thread(AVCodecContext *avctx, void *arg, int jobnr, int threadnr)\n\n{\n\n    ProresContext *ctx = avctx->priv_data;\n\n    SliceContext *slice = &ctx->slices[jobnr];\n\n    const uint8_t *buf = slice->data;\n\n    AVFrame *pic = ctx->frame;\n\n    int i, hdr_size, qscale, log2_chroma_blocks_per_mb;\n\n    int luma_stride, chroma_stride;\n\n    int y_data_size, u_data_size, v_data_size, a_data_size;\n\n    uint8_t *dest_y, *dest_u, *dest_v, *dest_a;\n\n    int16_t qmat_luma_scaled[64];\n\n    int16_t qmat_chroma_scaled[64];\n\n    int mb_x_shift;\n\n\n\n    slice->ret = -1;\n\n    //av_log(avctx, AV_LOG_INFO, \"slice %d mb width %d mb x %d y %d\\n\",\n\n    //       jobnr, slice->mb_count, slice->mb_x, slice->mb_y);\n\n\n\n    // slice header\n\n    hdr_size = buf[0] >> 3;\n\n    qscale = av_clip(buf[1], 1, 224);\n\n    qscale = qscale > 128 ? qscale - 96 << 2: qscale;\n\n    y_data_size = AV_RB16(buf + 2);\n\n    u_data_size = AV_RB16(buf + 4);\n\n    v_data_size = slice->data_size - y_data_size - u_data_size - hdr_size;\n\n    if (hdr_size > 7) v_data_size = AV_RB16(buf + 6);\n\n    a_data_size = slice->data_size - y_data_size - u_data_size -\n\n                  v_data_size - hdr_size;\n\n\n\n    if (y_data_size < 0 || u_data_size < 0 || v_data_size < 0\n\n        || hdr_size+y_data_size+u_data_size+v_data_size > slice->data_size){\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid plane data size\\n\");\n\n        return -1;\n\n    }\n\n\n\n    buf += hdr_size;\n\n\n\n    for (i = 0; i < 64; i++) {\n\n        qmat_luma_scaled  [i] = ctx->qmat_luma  [i] * qscale;\n\n        qmat_chroma_scaled[i] = ctx->qmat_chroma[i] * qscale;\n\n    }\n\n\n\n    if (ctx->frame_type == 0) {\n\n        luma_stride   = pic->linesize[0];\n\n        chroma_stride = pic->linesize[1];\n\n    } else {\n\n        luma_stride   = pic->linesize[0] << 1;\n\n        chroma_stride = pic->linesize[1] << 1;\n\n    }\n\n\n\n    if (avctx->pix_fmt == AV_PIX_FMT_YUV444P10 || avctx->pix_fmt == AV_PIX_FMT_YUVA444P10) {\n\n        mb_x_shift = 5;\n\n        log2_chroma_blocks_per_mb = 2;\n\n    } else {\n\n        mb_x_shift = 4;\n\n        log2_chroma_blocks_per_mb = 1;\n\n    }\n\n\n\n    dest_y = pic->data[0] + (slice->mb_y << 4) * luma_stride + (slice->mb_x << 5);\n\n    dest_u = pic->data[1] + (slice->mb_y << 4) * chroma_stride + (slice->mb_x << mb_x_shift);\n\n    dest_v = pic->data[2] + (slice->mb_y << 4) * chroma_stride + (slice->mb_x << mb_x_shift);\n\n    dest_a = pic->data[3] + (slice->mb_y << 4) * luma_stride + (slice->mb_x << 5);\n\n\n\n    if (ctx->frame_type && ctx->first_field ^ ctx->frame->top_field_first) {\n\n        dest_y += pic->linesize[0];\n\n        dest_u += pic->linesize[1];\n\n        dest_v += pic->linesize[2];\n\n        dest_a += pic->linesize[3];\n\n    }\n\n\n\n    decode_slice_luma(avctx, slice, (uint16_t*)dest_y, luma_stride,\n\n                      buf, y_data_size, qmat_luma_scaled);\n\n\n\n    if (!(avctx->flags & CODEC_FLAG_GRAY)) {\n\n        decode_slice_chroma(avctx, slice, (uint16_t*)dest_u, chroma_stride,\n\n                            buf + y_data_size, u_data_size,\n\n                            qmat_chroma_scaled, log2_chroma_blocks_per_mb);\n\n        decode_slice_chroma(avctx, slice, (uint16_t*)dest_v, chroma_stride,\n\n                            buf + y_data_size + u_data_size, v_data_size,\n\n                            qmat_chroma_scaled, log2_chroma_blocks_per_mb);\n\n    }\n\n    /* decode alpha plane if available */\n\n    if (ctx->alpha_info && dest_a && a_data_size)\n\n        decode_slice_alpha(ctx, (uint16_t*)dest_a, luma_stride,\n\n                           buf + y_data_size + u_data_size + v_data_size,\n\n                           a_data_size, slice->mb_count);\n\n\n\n    slice->ret = 0;\n\n    return 0;\n\n}\n", "idx": 23781}
{"project": "FFmpeg", "commit_id": "c82bf15dca00f67a701d126e47ea9075fc9459cb", "target": 1, "func": "static void flush_buffered(AVFormatContext *s1, int last)\n\n{\n\n    RTPMuxContext *s = s1->priv_data;\n\n    if (s->buf_ptr != s->buf) {\n\n        // If only sending one single NAL unit, skip the aggregation framing\n\n        if (s->buffered_nals == 1)\n\n            ff_rtp_send_data(s1, s->buf + 4, s->buf_ptr - s->buf - 4, last);\n\n        else\n\n            ff_rtp_send_data(s1, s->buf, s->buf_ptr - s->buf, last);\n\n    }\n\n    s->buf_ptr = s->buf;\n\n    s->buffered_nals = 0;\n\n}\n", "idx": 23783}
{"project": "FFmpeg", "commit_id": "67020711b7d45afa073ef671f755765035a64373", "target": 1, "func": "static int vp8_lossy_decode_frame(AVCodecContext *avctx, AVFrame *p,\n                                  int *got_frame, uint8_t *data_start,\n                                  unsigned int data_size)\n{\n    WebPContext *s = avctx->priv_data;\n    AVPacket pkt;\n    int ret;\n    if (!s->initialized) {\n        ff_vp8_decode_init(avctx);\n        s->initialized = 1;\n    }\n    avctx->pix_fmt = s->has_alpha ? AV_PIX_FMT_YUVA420P : AV_PIX_FMT_YUV420P;\n    s->lossless = 0;\n    if (data_size > INT_MAX) {\n        av_log(avctx, AV_LOG_ERROR, \"unsupported chunk size\\n\");\n        return AVERROR_PATCHWELCOME;\n    }\n    av_init_packet(&pkt);\n    pkt.data = data_start;\n    pkt.size = data_size;\n    ret = ff_vp8_decode_frame(avctx, p, got_frame, &pkt);\n    if (ret < 0)\n        return ret;\n    update_canvas_size(avctx, avctx->width, avctx->height);\n    if (s->has_alpha) {\n        ret = vp8_lossy_decode_alpha(avctx, p, s->alpha_data,\n                                     s->alpha_data_size);\n        if (ret < 0)\n            return ret;\n    }\n    return ret;\n}", "idx": 23784}
{"project": "FFmpeg", "commit_id": "8cd1c0febe88b757e915e9af15559575c21ca728", "target": 1, "func": "static int pcx_decode_frame(AVCodecContext *avctx, void *data, int *data_size,\n\n                            AVPacket *avpkt) {\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    PCXContext * const s = avctx->priv_data;\n\n    AVFrame *picture = data;\n\n    AVFrame * const p = &s->picture;\n\n    int compressed, xmin, ymin, xmax, ymax;\n\n    unsigned int w, h, bits_per_pixel, bytes_per_line, nplanes, stride, y, x,\n\n                 bytes_per_scanline;\n\n    uint8_t *ptr;\n\n    uint8_t const *bufstart = buf;\n\n    uint8_t *scanline;\n\n    int ret = -1;\n\n\n\n    if (buf[0] != 0x0a || buf[1] > 5) {\n\n        av_log(avctx, AV_LOG_ERROR, \"this is not PCX encoded data\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    compressed = buf[2];\n\n    xmin = AV_RL16(buf+ 4);\n\n    ymin = AV_RL16(buf+ 6);\n\n    xmax = AV_RL16(buf+ 8);\n\n    ymax = AV_RL16(buf+10);\n\n\n\n    if (xmax < xmin || ymax < ymin) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid image dimensions\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    w = xmax - xmin + 1;\n\n    h = ymax - ymin + 1;\n\n\n\n    bits_per_pixel     = buf[3];\n\n    bytes_per_line     = AV_RL16(buf+66);\n\n    nplanes            = buf[65];\n\n    bytes_per_scanline = nplanes * bytes_per_line;\n\n\n\n    if (bytes_per_scanline < w * bits_per_pixel * nplanes / 8) {\n\n        av_log(avctx, AV_LOG_ERROR, \"PCX data is corrupted\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    switch ((nplanes<<8) + bits_per_pixel) {\n\n        case 0x0308:\n\n            avctx->pix_fmt = AV_PIX_FMT_RGB24;\n\n            break;\n\n        case 0x0108:\n\n        case 0x0104:\n\n        case 0x0102:\n\n        case 0x0101:\n\n        case 0x0401:\n\n        case 0x0301:\n\n        case 0x0201:\n\n            avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n            break;\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid PCX file\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    buf += 128;\n\n\n\n    if (p->data[0])\n\n        avctx->release_buffer(avctx, p);\n\n\n\n    if (av_image_check_size(w, h, 0, avctx))\n\n        return AVERROR_INVALIDDATA;\n\n    if (w != avctx->width || h != avctx->height)\n\n        avcodec_set_dimensions(avctx, w, h);\n\n    if ((ret = avctx->get_buffer(avctx, p)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n\n\n    p->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    ptr    = p->data[0];\n\n    stride = p->linesize[0];\n\n\n\n    scanline = av_malloc(bytes_per_scanline);\n\n    if (!scanline)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if (nplanes == 3 && bits_per_pixel == 8) {\n\n        for (y=0; y<h; y++) {\n\n            buf = pcx_rle_decode(buf, scanline, bytes_per_scanline, compressed);\n\n\n\n            for (x=0; x<w; x++) {\n\n                ptr[3*x  ] = scanline[x                    ];\n\n                ptr[3*x+1] = scanline[x+ bytes_per_line    ];\n\n                ptr[3*x+2] = scanline[x+(bytes_per_line<<1)];\n\n            }\n\n\n\n            ptr += stride;\n\n        }\n\n\n\n    } else if (nplanes == 1 && bits_per_pixel == 8) {\n\n        const uint8_t *palstart = bufstart + buf_size - 769;\n\n\n\n        for (y=0; y<h; y++, ptr+=stride) {\n\n            buf = pcx_rle_decode(buf, scanline, bytes_per_scanline, compressed);\n\n            memcpy(ptr, scanline, w);\n\n        }\n\n\n\n        if (buf != palstart) {\n\n            av_log(avctx, AV_LOG_WARNING, \"image data possibly corrupted\\n\");\n\n            buf = palstart;\n\n        }\n\n        if (*buf++ != 12) {\n\n            av_log(avctx, AV_LOG_ERROR, \"expected palette after image data\\n\");\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto end;\n\n        }\n\n\n\n    } else if (nplanes == 1) {   /* all packed formats, max. 16 colors */\n\n        GetBitContext s;\n\n\n\n        for (y=0; y<h; y++) {\n\n            init_get_bits(&s, scanline, bytes_per_scanline<<3);\n\n\n\n            buf = pcx_rle_decode(buf, scanline, bytes_per_scanline, compressed);\n\n\n\n            for (x=0; x<w; x++)\n\n                ptr[x] = get_bits(&s, bits_per_pixel);\n\n            ptr += stride;\n\n        }\n\n\n\n    } else {    /* planar, 4, 8 or 16 colors */\n\n        int i;\n\n\n\n        for (y=0; y<h; y++) {\n\n            buf = pcx_rle_decode(buf, scanline, bytes_per_scanline, compressed);\n\n\n\n            for (x=0; x<w; x++) {\n\n                int m = 0x80 >> (x&7), v = 0;\n\n                for (i=nplanes - 1; i>=0; i--) {\n\n                    v <<= 1;\n\n                    v  += !!(scanline[i*bytes_per_line + (x>>3)] & m);\n\n                }\n\n                ptr[x] = v;\n\n            }\n\n            ptr += stride;\n\n        }\n\n    }\n\n\n\n    if (nplanes == 1 && bits_per_pixel == 8) {\n\n        pcx_palette(&buf, (uint32_t *) p->data[1], 256);\n\n    } else if (bits_per_pixel * nplanes == 1) {\n\n        AV_WN32A(p->data[1]  , 0xFF000000);\n\n        AV_WN32A(p->data[1]+4, 0xFFFFFFFF);\n\n    } else if (bits_per_pixel < 8) {\n\n        const uint8_t *palette = bufstart+16;\n\n        pcx_palette(&palette, (uint32_t *) p->data[1], 16);\n\n    }\n\n\n\n    *picture = s->picture;\n\n    *data_size = sizeof(AVFrame);\n\n\n\n    ret = buf - bufstart;\n\nend:\n\n    av_free(scanline);\n\n    return ret;\n\n}\n", "idx": 23786}
{"project": "FFmpeg", "commit_id": "a0c624e299730c8c5800375c2f5f3c6c200053ff", "target": 1, "func": "static int v4l2_send_frame(AVCodecContext *avctx, const AVFrame *frame)\n\n{\n\n    V4L2m2mContext *s = avctx->priv_data;\n\n    V4L2Context *const output = &s->output;\n\n\n\n    return ff_v4l2_context_enqueue_frame(output, frame);\n\n}\n", "idx": 23791}
{"project": "FFmpeg", "commit_id": "9ac831c2c02e6e1c9c322b8bb77881c1dbac6f08", "target": 0, "func": "static int vp8_decode_frame(AVCodecContext *avctx, void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    VP8Context *s = avctx->priv_data;\n\n    int ret, mb_x, mb_y, i, y, referenced;\n\n    enum AVDiscard skip_thresh;\n\n    AVFrame *curframe;\n\n\n\n    if ((ret = decode_frame_header(s, avpkt->data, avpkt->size)) < 0)\n\n        return ret;\n\n\n\n    referenced = s->update_last || s->update_golden == VP56_FRAME_CURRENT\n\n                                || s->update_altref == VP56_FRAME_CURRENT;\n\n\n\n    skip_thresh = !referenced ? AVDISCARD_NONREF :\n\n                    !s->keyframe ? AVDISCARD_NONKEY : AVDISCARD_ALL;\n\n\n\n    if (avctx->skip_frame >= skip_thresh) {\n\n        s->invisible = 1;\n\n        goto skip_decode;\n\n    }\n\n\n\n    for (i = 0; i < 4; i++)\n\n        if (&s->frames[i] != s->framep[VP56_FRAME_PREVIOUS] &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN] &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN2]) {\n\n            curframe = s->framep[VP56_FRAME_CURRENT] = &s->frames[i];\n\n            break;\n\n        }\n\n    if (curframe->data[0])\n\n        avctx->release_buffer(avctx, curframe);\n\n\n\n    curframe->key_frame = s->keyframe;\n\n    curframe->pict_type = s->keyframe ? FF_I_TYPE : FF_P_TYPE;\n\n    curframe->reference = referenced ? 3 : 0;\n\n    if ((ret = avctx->get_buffer(avctx, curframe))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed!\\n\");\n\n        return ret;\n\n    }\n\n\n\n    // Given that arithmetic probabilities are updated every frame, it's quite likely\n\n    // that the values we have on a random interframe are complete junk if we didn't\n\n    // start decode on a keyframe. So just don't display anything rather than junk.\n\n    if (!s->keyframe && (!s->framep[VP56_FRAME_PREVIOUS] ||\n\n                         !s->framep[VP56_FRAME_GOLDEN] ||\n\n                         !s->framep[VP56_FRAME_GOLDEN2])) {\n\n        av_log(avctx, AV_LOG_WARNING, \"Discarding interframe without a prior keyframe!\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    s->linesize   = curframe->linesize[0];\n\n    s->uvlinesize = curframe->linesize[1];\n\n\n\n    if (!s->edge_emu_buffer)\n\n        s->edge_emu_buffer = av_malloc(21*s->linesize);\n\n\n\n    memset(s->top_nnz, 0, s->mb_width*sizeof(*s->top_nnz));\n\n\n\n    // top edge of 127 for intra prediction\n\n    if (!(avctx->flags & CODEC_FLAG_EMU_EDGE)) {\n\n        memset(curframe->data[0] - s->linesize  -1, 127, s->linesize  +1);\n\n        memset(curframe->data[1] - s->uvlinesize-1, 127, s->uvlinesize+1);\n\n        memset(curframe->data[2] - s->uvlinesize-1, 127, s->uvlinesize+1);\n\n    }\n\n\n\n    for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n\n        VP56RangeCoder *c = &s->coeff_partition[mb_y & (s->num_coeff_partitions-1)];\n\n        VP8Macroblock *mb = s->macroblocks + mb_y*s->mb_stride;\n\n        uint8_t *intra4x4 = s->intra4x4_pred_mode + 4*mb_y*s->b4_stride;\n\n        uint8_t *dst[3] = {\n\n            curframe->data[0] + 16*mb_y*s->linesize,\n\n            curframe->data[1] +  8*mb_y*s->uvlinesize,\n\n            curframe->data[2] +  8*mb_y*s->uvlinesize\n\n        };\n\n\n\n        memset(s->left_nnz, 0, sizeof(s->left_nnz));\n\n\n\n        // left edge of 129 for intra prediction\n\n        if (!(avctx->flags & CODEC_FLAG_EMU_EDGE))\n\n            for (i = 0; i < 3; i++)\n\n                for (y = 0; y < 16>>!!i; y++)\n\n                    dst[i][y*curframe->linesize[i]-1] = 129;\n\n\n\n        for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n            decode_mb_mode(s, mb, mb_x, mb_y, intra4x4 + 4*mb_x);\n\n\n\n            if (!mb->skip)\n\n                decode_mb_coeffs(s, c, mb, s->top_nnz[mb_x], s->left_nnz);\n\n            else {\n\n                AV_ZERO128(s->non_zero_count_cache);    // luma\n\n                AV_ZERO64(s->non_zero_count_cache[4]);  // chroma\n\n            }\n\n\n\n            if (mb->mode <= MODE_I4x4) {\n\n                intra_predict(s, dst, mb, intra4x4 + 4*mb_x, mb_x, mb_y);\n\n                memset(mb->bmv, 0, sizeof(mb->bmv));\n\n            } else {\n\n                inter_predict(s, dst, mb, mb_x, mb_y);\n\n            }\n\n\n\n            if (!mb->skip) {\n\n                idct_mb(s, dst[0], dst[1], dst[2], mb);\n\n            } else {\n\n                AV_ZERO64(s->left_nnz);\n\n                AV_WN64(s->top_nnz[mb_x], 0);   // array of 9, so unaligned\n\n\n\n                // Reset DC block predictors if they would exist if the mb had coefficients\n\n                if (mb->mode != MODE_I4x4 && mb->mode != VP8_MVMODE_SPLIT) {\n\n                    s->left_nnz[8]      = 0;\n\n                    s->top_nnz[mb_x][8] = 0;\n\n                }\n\n            }\n\n\n\n            dst[0] += 16;\n\n            dst[1] += 8;\n\n            dst[2] += 8;\n\n            mb++;\n\n        }\n\n        if (mb_y && s->filter.level && avctx->skip_loop_filter < skip_thresh) {\n\n            if (s->filter.simple)\n\n                filter_mb_row_simple(s, mb_y-1);\n\n            else\n\n                filter_mb_row(s, mb_y-1);\n\n        }\n\n    }\n\n    if (s->filter.level && avctx->skip_loop_filter < skip_thresh) {\n\n        if (s->filter.simple)\n\n            filter_mb_row_simple(s, mb_y-1);\n\n        else\n\n            filter_mb_row(s, mb_y-1);\n\n    }\n\n\n\nskip_decode:\n\n    // if future frames don't use the updated probabilities,\n\n    // reset them to the values we saved\n\n    if (!s->update_probabilities)\n\n        s->prob[0] = s->prob[1];\n\n\n\n    // check if golden and altref are swapped\n\n    if (s->update_altref == VP56_FRAME_GOLDEN &&\n\n        s->update_golden == VP56_FRAME_GOLDEN2)\n\n        FFSWAP(AVFrame *, s->framep[VP56_FRAME_GOLDEN], s->framep[VP56_FRAME_GOLDEN2]);\n\n    else {\n\n        if (s->update_altref != VP56_FRAME_NONE)\n\n            s->framep[VP56_FRAME_GOLDEN2] = s->framep[s->update_altref];\n\n\n\n        if (s->update_golden != VP56_FRAME_NONE)\n\n            s->framep[VP56_FRAME_GOLDEN] = s->framep[s->update_golden];\n\n    }\n\n\n\n    if (s->update_last) // move cur->prev\n\n        s->framep[VP56_FRAME_PREVIOUS] = s->framep[VP56_FRAME_CURRENT];\n\n\n\n    // release no longer referenced frames\n\n    for (i = 0; i < 4; i++)\n\n        if (s->frames[i].data[0] &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_CURRENT] &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_PREVIOUS] &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN] &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN2])\n\n            avctx->release_buffer(avctx, &s->frames[i]);\n\n\n\n    if (!s->invisible) {\n\n        *(AVFrame*)data = *s->framep[VP56_FRAME_CURRENT];\n\n        *data_size = sizeof(AVFrame);\n\n    }\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 23792}
{"project": "FFmpeg", "commit_id": "eb7802afefb7af4da50bc56818cdab9da07de7d0", "target": 0, "func": "void ff_init_vscale_pfn(SwsContext *c,\n\n    yuv2planar1_fn yuv2plane1,\n\n    yuv2planarX_fn yuv2planeX,\n\n    yuv2interleavedX_fn yuv2nv12cX,\n\n    yuv2packed1_fn yuv2packed1,\n\n    yuv2packed2_fn yuv2packed2,\n\n    yuv2packedX_fn yuv2packedX,\n\n    yuv2anyX_fn yuv2anyX, int use_mmx)\n\n{\n\n    VScalerContext *lumCtx = NULL;\n\n    VScalerContext *chrCtx = NULL;\n\n    int idx = c->numDesc - (c->is_internal_gamma ? 2 : 1); //FIXME avoid hardcoding indexes\n\n\n\n    if (isPlanarYUV(c->dstFormat) || (isGray(c->dstFormat) && !isALPHA(c->dstFormat))) {\n\n        if (!isGray(c->dstFormat)) {\n\n            chrCtx = c->desc[idx].instance;\n\n\n\n            chrCtx->filter[0] = use_mmx ? (int16_t*)c->chrMmxFilter : c->vChrFilter;\n\n            chrCtx->filter_size = c->vChrFilterSize;\n\n            chrCtx->filter_pos = c->vChrFilterPos;\n\n            chrCtx->isMMX = use_mmx;\n\n\n\n            --idx;\n\n            if (yuv2nv12cX)               chrCtx->pfn = yuv2nv12cX;\n\n            else if (c->vChrFilterSize == 1) chrCtx->pfn = yuv2plane1;\n\n            else                             chrCtx->pfn = yuv2planeX;\n\n        }\n\n\n\n        lumCtx = c->desc[idx].instance;\n\n\n\n        lumCtx->filter[0] = use_mmx ? (int16_t*)c->lumMmxFilter : c->vLumFilter;\n\n        lumCtx->filter[1] = use_mmx ? (int16_t*)c->alpMmxFilter : c->vLumFilter;\n\n        lumCtx->filter_size = c->vLumFilterSize;\n\n        lumCtx->filter_pos = c->vLumFilterPos;\n\n        lumCtx->isMMX = use_mmx;\n\n\n\n        if (c->vLumFilterSize == 1) lumCtx->pfn = yuv2plane1;\n\n        else                        lumCtx->pfn = yuv2planeX;\n\n\n\n    } else {\n\n        lumCtx = c->desc[idx].instance;\n\n        chrCtx = &lumCtx[1];\n\n\n\n        lumCtx->filter[0] = c->vLumFilter;\n\n        lumCtx->filter_size = c->vLumFilterSize;\n\n        lumCtx->filter_pos = c->vLumFilterPos;\n\n\n\n        chrCtx->filter[0] = c->vChrFilter;\n\n        chrCtx->filter_size = c->vChrFilterSize;\n\n        chrCtx->filter_pos = c->vChrFilterPos;\n\n\n\n        lumCtx->isMMX = use_mmx;\n\n        chrCtx->isMMX = use_mmx;\n\n\n\n        if (yuv2packedX) {\n\n            if (c->yuv2packed1 && c->vLumFilterSize == 1 && c->vChrFilterSize <= 2)\n\n                lumCtx->pfn = yuv2packed1;\n\n            else if (c->yuv2packed2 && c->vLumFilterSize == 2 && c->vChrFilterSize == 2)\n\n                lumCtx->pfn = yuv2packed2;\n\n            else\n\n                lumCtx->pfn = yuv2packedX;\n\n        } else\n\n            lumCtx->pfn = yuv2anyX;\n\n    }\n\n}\n", "idx": 23793}
{"project": "FFmpeg", "commit_id": "07a47ae2a3f7bcfea25828628e8b1df44dd5a1cd", "target": 0, "func": "static int flv_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    int ret, i, type, size, pts, flags, is_audio, next, pos;\n\n    AVStream *st = NULL;\n\n\n\n for(;;){\n\n    pos = url_ftell(s->pb);\n\n    url_fskip(s->pb, 4); /* size of previous packet */\n\n    type = get_byte(s->pb);\n\n    size = get_be24(s->pb);\n\n    pts = get_be24(s->pb);\n\n    pts |= get_byte(s->pb) << 24;\n\n//    av_log(s, AV_LOG_DEBUG, \"type:%d, size:%d, pts:%d\\n\", type, size, pts);\n\n    if (url_feof(s->pb))\n\n        return AVERROR(EIO);\n\n    url_fskip(s->pb, 3); /* stream id, always 0 */\n\n    flags = 0;\n\n\n\n    if(size == 0)\n\n        continue;\n\n\n\n    next= size + url_ftell(s->pb);\n\n\n\n    if (type == FLV_TAG_TYPE_AUDIO) {\n\n        is_audio=1;\n\n        flags = get_byte(s->pb);\n\n    } else if (type == FLV_TAG_TYPE_VIDEO) {\n\n        is_audio=0;\n\n        flags = get_byte(s->pb);\n\n    } else {\n\n        if (type == FLV_TAG_TYPE_META && size > 13+1+4)\n\n            flv_read_metabody(s, next);\n\n        else /* skip packet */\n\n            av_log(s, AV_LOG_ERROR, \"skipping flv packet: type %d, size %d, flags %d\\n\", type, size, flags);\n\n        url_fseek(s->pb, next, SEEK_SET);\n\n        continue;\n\n    }\n\n\n\n    /* now find stream */\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        st = s->streams[i];\n\n        if (st->id == is_audio)\n\n            break;\n\n    }\n\n    if(i == s->nb_streams){\n\n        av_log(NULL, AV_LOG_ERROR, \"invalid stream\\n\");\n\n        st= create_stream(s, is_audio);\n\n        s->ctx_flags &= ~AVFMTCTX_NOHEADER;\n\n    }\n\n//    av_log(NULL, AV_LOG_DEBUG, \"%d %X %d \\n\", is_audio, flags, st->discard);\n\n    if(  (st->discard >= AVDISCARD_NONKEY && !((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_KEY ||         is_audio))\n\n       ||(st->discard >= AVDISCARD_BIDIR  &&  ((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_DISP_INTER && !is_audio))\n\n       || st->discard >= AVDISCARD_ALL\n\n       ){\n\n        url_fseek(s->pb, next, SEEK_SET);\n\n        continue;\n\n    }\n\n    if ((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_KEY)\n\n        av_add_index_entry(st, pos, pts, size, 0, AVINDEX_KEYFRAME);\n\n    break;\n\n }\n\n\n\n    // if not streamed and no duration from metadata then seek to end to find the duration from the timestamps\n\n    if(!url_is_streamed(s->pb) && s->duration==AV_NOPTS_VALUE){\n\n        int size;\n\n        const int pos= url_ftell(s->pb);\n\n        const int fsize= url_fsize(s->pb);\n\n        url_fseek(s->pb, fsize-4, SEEK_SET);\n\n        size= get_be32(s->pb);\n\n        url_fseek(s->pb, fsize-3-size, SEEK_SET);\n\n        if(size == get_be24(s->pb) + 11){\n\n            s->duration= get_be24(s->pb) * (int64_t)AV_TIME_BASE / 1000;\n\n        }\n\n        url_fseek(s->pb, pos, SEEK_SET);\n\n    }\n\n\n\n    if(is_audio){\n\n        if(!st->codec->sample_rate || !st->codec->bits_per_sample || (!st->codec->codec_id && !st->codec->codec_tag)) {\n\n            st->codec->channels = (flags & FLV_AUDIO_CHANNEL_MASK) == FLV_STEREO ? 2 : 1;\n\n            if((flags & FLV_AUDIO_CODECID_MASK) == FLV_CODECID_NELLYMOSER_8HZ_MONO)\n\n                st->codec->sample_rate= 8000;\n\n            else\n\n                st->codec->sample_rate = (44100 << ((flags & FLV_AUDIO_SAMPLERATE_MASK) >> FLV_AUDIO_SAMPLERATE_OFFSET) >> 3);\n\n            st->codec->bits_per_sample = (flags & FLV_AUDIO_SAMPLESIZE_MASK) ? 16 : 8;\n\n            flv_set_audio_codec(s, st, flags & FLV_AUDIO_CODECID_MASK);\n\n        }\n\n    }else{\n\n        size -= flv_set_video_codec(s, st, flags & FLV_VIDEO_CODECID_MASK);\n\n    }\n\n\n\n    ret= av_get_packet(s->pb, pkt, size - 1);\n\n    if (ret <= 0) {\n\n        return AVERROR(EIO);\n\n    }\n\n    /* note: we need to modify the packet size here to handle the last\n\n       packet */\n\n    pkt->size = ret;\n\n    pkt->pts = pts;\n\n    pkt->stream_index = st->index;\n\n\n\n    if (is_audio || ((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_KEY))\n\n        pkt->flags |= PKT_FLAG_KEY;\n\n\n\n    return ret;\n\n}\n", "idx": 23794}
{"project": "FFmpeg", "commit_id": "19fe8b4100dfe0323e351e474c54293bb4ae576e", "target": 0, "func": "static inline void fill_caches(H264Context *h, int mb_type, int for_deblock){\n\n    MpegEncContext * const s = &h->s;\n\n    const int mb_xy= s->mb_x + s->mb_y*s->mb_stride;\n\n    int topleft_xy, top_xy, topright_xy, left_xy[2];\n\n    int topleft_type, top_type, topright_type, left_type[2];\n\n    int left_block[4];\n\n    int i;\n\n\n\n    //wow what a mess, why didnt they simplify the interlacing&intra stuff, i cant imagine that these complex rules are worth it \n\n    \n\n    if(h->sps.mb_aff){\n\n    //FIXME\n\n        topleft_xy = 0; /* avoid warning */\n\n        top_xy = 0; /* avoid warning */\n\n        topright_xy = 0; /* avoid warning */\n\n    }else{\n\n        topleft_xy = mb_xy-1 - s->mb_stride;\n\n        top_xy     = mb_xy   - s->mb_stride;\n\n        topright_xy= mb_xy+1 - s->mb_stride;\n\n        left_xy[0]   = mb_xy-1;\n\n        left_xy[1]   = mb_xy-1;\n\n        left_block[0]= 0;\n\n        left_block[1]= 1;\n\n        left_block[2]= 2;\n\n        left_block[3]= 3;\n\n    }\n\n\n\n    if(for_deblock){\n\n        topleft_type = h->slice_table[topleft_xy ] < 255 ? s->current_picture.mb_type[topleft_xy] : 0;\n\n        top_type     = h->slice_table[top_xy     ] < 255 ? s->current_picture.mb_type[top_xy]     : 0;\n\n        topright_type= h->slice_table[topright_xy] < 255 ? s->current_picture.mb_type[topright_xy]: 0;\n\n        left_type[0] = h->slice_table[left_xy[0] ] < 255 ? s->current_picture.mb_type[left_xy[0]] : 0;\n\n        left_type[1] = h->slice_table[left_xy[1] ] < 255 ? s->current_picture.mb_type[left_xy[1]] : 0;\n\n    }else{\n\n        topleft_type = h->slice_table[topleft_xy ] == h->slice_num ? s->current_picture.mb_type[topleft_xy] : 0;\n\n        top_type     = h->slice_table[top_xy     ] == h->slice_num ? s->current_picture.mb_type[top_xy]     : 0;\n\n        topright_type= h->slice_table[topright_xy] == h->slice_num ? s->current_picture.mb_type[topright_xy]: 0;\n\n        left_type[0] = h->slice_table[left_xy[0] ] == h->slice_num ? s->current_picture.mb_type[left_xy[0]] : 0;\n\n        left_type[1] = h->slice_table[left_xy[1] ] == h->slice_num ? s->current_picture.mb_type[left_xy[1]] : 0;\n\n    }\n\n\n\n    if(IS_INTRA(mb_type)){\n\n        h->topleft_samples_available= \n\n        h->top_samples_available= \n\n        h->left_samples_available= 0xFFFF;\n\n        h->topright_samples_available= 0xEEEA;\n\n\n\n        if(!IS_INTRA(top_type) && (top_type==0 || h->pps.constrained_intra_pred)){\n\n            h->topleft_samples_available= 0xB3FF;\n\n            h->top_samples_available= 0x33FF;\n\n            h->topright_samples_available= 0x26EA;\n\n        }\n\n        for(i=0; i<2; i++){\n\n            if(!IS_INTRA(left_type[i]) && (left_type[i]==0 || h->pps.constrained_intra_pred)){\n\n                h->topleft_samples_available&= 0xDF5F;\n\n                h->left_samples_available&= 0x5F5F;\n\n            }\n\n        }\n\n        \n\n        if(!IS_INTRA(topleft_type) && (topleft_type==0 || h->pps.constrained_intra_pred))\n\n            h->topleft_samples_available&= 0x7FFF;\n\n        \n\n        if(!IS_INTRA(topright_type) && (topright_type==0 || h->pps.constrained_intra_pred))\n\n            h->topright_samples_available&= 0xFBFF;\n\n    \n\n        if(IS_INTRA4x4(mb_type)){\n\n            if(IS_INTRA4x4(top_type)){\n\n                h->intra4x4_pred_mode_cache[4+8*0]= h->intra4x4_pred_mode[top_xy][4];\n\n                h->intra4x4_pred_mode_cache[5+8*0]= h->intra4x4_pred_mode[top_xy][5];\n\n                h->intra4x4_pred_mode_cache[6+8*0]= h->intra4x4_pred_mode[top_xy][6];\n\n                h->intra4x4_pred_mode_cache[7+8*0]= h->intra4x4_pred_mode[top_xy][3];\n\n            }else{\n\n                int pred;\n\n                if(!top_type || (IS_INTER(top_type) && h->pps.constrained_intra_pred))\n\n                    pred= -1;\n\n                else{\n\n                    pred= 2;\n\n                }\n\n                h->intra4x4_pred_mode_cache[4+8*0]=\n\n                h->intra4x4_pred_mode_cache[5+8*0]=\n\n                h->intra4x4_pred_mode_cache[6+8*0]=\n\n                h->intra4x4_pred_mode_cache[7+8*0]= pred;\n\n            }\n\n            for(i=0; i<2; i++){\n\n                if(IS_INTRA4x4(left_type[i])){\n\n                    h->intra4x4_pred_mode_cache[3+8*1 + 2*8*i]= h->intra4x4_pred_mode[left_xy[i]][left_block[0+2*i]];\n\n                    h->intra4x4_pred_mode_cache[3+8*2 + 2*8*i]= h->intra4x4_pred_mode[left_xy[i]][left_block[1+2*i]];\n\n                }else{\n\n                    int pred;\n\n                    if(!left_type[i] || (IS_INTER(left_type[i]) && h->pps.constrained_intra_pred))\n\n                        pred= -1;\n\n                    else{\n\n                        pred= 2;\n\n                    }\n\n                    h->intra4x4_pred_mode_cache[3+8*1 + 2*8*i]=\n\n                    h->intra4x4_pred_mode_cache[3+8*2 + 2*8*i]= pred;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    \n\n    \n\n/*\n\n0 . T T. T T T T \n\n1 L . .L . . . . \n\n2 L . .L . . . . \n\n3 . T TL . . . . \n\n4 L . .L . . . . \n\n5 L . .. . . . . \n\n*/\n\n//FIXME constraint_intra_pred & partitioning & nnz (lets hope this is just a typo in the spec)\n\n    if(top_type){\n\n        h->non_zero_count_cache[4+8*0]= h->non_zero_count[top_xy][0];\n\n        h->non_zero_count_cache[5+8*0]= h->non_zero_count[top_xy][1];\n\n        h->non_zero_count_cache[6+8*0]= h->non_zero_count[top_xy][2];\n\n        h->non_zero_count_cache[7+8*0]= h->non_zero_count[top_xy][3];\n\n    \n\n        h->non_zero_count_cache[1+8*0]= h->non_zero_count[top_xy][7];\n\n        h->non_zero_count_cache[2+8*0]= h->non_zero_count[top_xy][8];\n\n    \n\n        h->non_zero_count_cache[1+8*3]= h->non_zero_count[top_xy][10];\n\n        h->non_zero_count_cache[2+8*3]= h->non_zero_count[top_xy][11];\n\n        \n\n        h->top_cbp= h->cbp_table[top_xy];\n\n    }else{\n\n        h->non_zero_count_cache[4+8*0]=      \n\n        h->non_zero_count_cache[5+8*0]=\n\n        h->non_zero_count_cache[6+8*0]=\n\n        h->non_zero_count_cache[7+8*0]=\n\n    \n\n        h->non_zero_count_cache[1+8*0]=\n\n        h->non_zero_count_cache[2+8*0]=\n\n    \n\n        h->non_zero_count_cache[1+8*3]=\n\n        h->non_zero_count_cache[2+8*3]= h->pps.cabac && !IS_INTRA(mb_type) ? 0 : 64;\n\n        \n\n        if(IS_INTRA(mb_type)) h->top_cbp= 0x1C0;\n\n        else                  h->top_cbp= 0;\n\n    }\n\n    \n\n    if(left_type[0]){\n\n        h->non_zero_count_cache[3+8*1]= h->non_zero_count[left_xy[0]][6];\n\n        h->non_zero_count_cache[3+8*2]= h->non_zero_count[left_xy[0]][5];\n\n        h->non_zero_count_cache[0+8*1]= h->non_zero_count[left_xy[0]][9]; //FIXME left_block\n\n        h->non_zero_count_cache[0+8*4]= h->non_zero_count[left_xy[0]][12];\n\n        h->left_cbp= h->cbp_table[left_xy[0]]; //FIXME interlacing\n\n    }else{\n\n        h->non_zero_count_cache[3+8*1]= \n\n        h->non_zero_count_cache[3+8*2]= \n\n        h->non_zero_count_cache[0+8*1]= \n\n        h->non_zero_count_cache[0+8*4]= h->pps.cabac && !IS_INTRA(mb_type) ? 0 : 64;\n\n        \n\n        if(IS_INTRA(mb_type)) h->left_cbp= 0x1C0;//FIXME interlacing\n\n        else                  h->left_cbp= 0;\n\n    }\n\n    \n\n    if(left_type[1]){\n\n        h->non_zero_count_cache[3+8*3]= h->non_zero_count[left_xy[1]][4];\n\n        h->non_zero_count_cache[3+8*4]= h->non_zero_count[left_xy[1]][3];\n\n        h->non_zero_count_cache[0+8*2]= h->non_zero_count[left_xy[1]][8];\n\n        h->non_zero_count_cache[0+8*5]= h->non_zero_count[left_xy[1]][11];\n\n    }else{\n\n        h->non_zero_count_cache[3+8*3]= \n\n        h->non_zero_count_cache[3+8*4]= \n\n        h->non_zero_count_cache[0+8*2]= \n\n        h->non_zero_count_cache[0+8*5]= h->pps.cabac && !IS_INTRA(mb_type) ? 0 : 64;\n\n    }\n\n    \n\n#if 1\n\n    //FIXME direct mb can skip much of this\n\n    if(IS_INTER(mb_type) || (IS_DIRECT(mb_type) && h->direct_spatial_mv_pred)){\n\n        int list;\n\n        for(list=0; list<2; list++){\n\n            if((!IS_8X8(mb_type)) && !USES_LIST(mb_type, list) && !IS_DIRECT(mb_type)){\n\n                /*if(!h->mv_cache_clean[list]){\n\n                    memset(h->mv_cache [list],  0, 8*5*2*sizeof(int16_t)); //FIXME clean only input? clean at all?\n\n                    memset(h->ref_cache[list], PART_NOT_AVAILABLE, 8*5*sizeof(int8_t));\n\n                    h->mv_cache_clean[list]= 1;\n\n                }*/\n\n                continue;\n\n            }\n\n            h->mv_cache_clean[list]= 0;\n\n            \n\n            if(IS_INTER(topleft_type)){\n\n                const int b_xy = h->mb2b_xy[topleft_xy] + 3 + 3*h->b_stride;\n\n                const int b8_xy= h->mb2b8_xy[topleft_xy] + 1 + h->b8_stride;\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] - 1 - 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy];\n\n                h->ref_cache[list][scan8[0] - 1 - 1*8]= s->current_picture.ref_index[list][b8_xy];\n\n            }else{\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] - 1 - 1*8]= 0;\n\n                h->ref_cache[list][scan8[0] - 1 - 1*8]= topleft_type ? LIST_NOT_USED : PART_NOT_AVAILABLE;\n\n            }\n\n            \n\n            if(IS_INTER(top_type)){\n\n                const int b_xy= h->mb2b_xy[top_xy] + 3*h->b_stride;\n\n                const int b8_xy= h->mb2b8_xy[top_xy] + h->b8_stride;\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] + 0 - 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + 0];\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] + 1 - 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + 1];\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] + 2 - 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + 2];\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] + 3 - 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + 3];\n\n                h->ref_cache[list][scan8[0] + 0 - 1*8]=\n\n                h->ref_cache[list][scan8[0] + 1 - 1*8]= s->current_picture.ref_index[list][b8_xy + 0];\n\n                h->ref_cache[list][scan8[0] + 2 - 1*8]=\n\n                h->ref_cache[list][scan8[0] + 3 - 1*8]= s->current_picture.ref_index[list][b8_xy + 1];\n\n            }else{\n\n                *(uint32_t*)h->mv_cache [list][scan8[0] + 0 - 1*8]= \n\n                *(uint32_t*)h->mv_cache [list][scan8[0] + 1 - 1*8]= \n\n                *(uint32_t*)h->mv_cache [list][scan8[0] + 2 - 1*8]= \n\n                *(uint32_t*)h->mv_cache [list][scan8[0] + 3 - 1*8]= 0;\n\n                *(uint32_t*)&h->ref_cache[list][scan8[0] + 0 - 1*8]= ((top_type ? LIST_NOT_USED : PART_NOT_AVAILABLE)&0xFF)*0x01010101;\n\n            }\n\n\n\n            if(IS_INTER(topright_type)){\n\n                const int b_xy= h->mb2b_xy[topright_xy] + 3*h->b_stride;\n\n                const int b8_xy= h->mb2b8_xy[topright_xy] + h->b8_stride;\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] + 4 - 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy];\n\n                h->ref_cache[list][scan8[0] + 4 - 1*8]= s->current_picture.ref_index[list][b8_xy];\n\n            }else{\n\n                *(uint32_t*)h->mv_cache [list][scan8[0] + 4 - 1*8]= 0;\n\n                h->ref_cache[list][scan8[0] + 4 - 1*8]= topright_type ? LIST_NOT_USED : PART_NOT_AVAILABLE;\n\n            }\n\n            \n\n            //FIXME unify cleanup or sth\n\n            if(IS_INTER(left_type[0])){\n\n                const int b_xy= h->mb2b_xy[left_xy[0]] + 3;\n\n                const int b8_xy= h->mb2b8_xy[left_xy[0]] + 1;\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] - 1 + 0*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + h->b_stride*left_block[0]];\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] - 1 + 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + h->b_stride*left_block[1]];\n\n                h->ref_cache[list][scan8[0] - 1 + 0*8]= \n\n                h->ref_cache[list][scan8[0] - 1 + 1*8]= s->current_picture.ref_index[list][b8_xy + h->b8_stride*(left_block[0]>>1)];\n\n            }else{\n\n                *(uint32_t*)h->mv_cache [list][scan8[0] - 1 + 0*8]=\n\n                *(uint32_t*)h->mv_cache [list][scan8[0] - 1 + 1*8]= 0;\n\n                h->ref_cache[list][scan8[0] - 1 + 0*8]=\n\n                h->ref_cache[list][scan8[0] - 1 + 1*8]= left_type[0] ? LIST_NOT_USED : PART_NOT_AVAILABLE;\n\n            }\n\n            \n\n            if(IS_INTER(left_type[1])){\n\n                const int b_xy= h->mb2b_xy[left_xy[1]] + 3;\n\n                const int b8_xy= h->mb2b8_xy[left_xy[1]] + 1;\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] - 1 + 2*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + h->b_stride*left_block[2]];\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] - 1 + 3*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + h->b_stride*left_block[3]];\n\n                h->ref_cache[list][scan8[0] - 1 + 2*8]= \n\n                h->ref_cache[list][scan8[0] - 1 + 3*8]= s->current_picture.ref_index[list][b8_xy + h->b8_stride*(left_block[2]>>1)];\n\n            }else{\n\n                *(uint32_t*)h->mv_cache [list][scan8[0] - 1 + 2*8]=\n\n                *(uint32_t*)h->mv_cache [list][scan8[0] - 1 + 3*8]= 0;\n\n                h->ref_cache[list][scan8[0] - 1 + 2*8]=\n\n                h->ref_cache[list][scan8[0] - 1 + 3*8]= left_type[0] ? LIST_NOT_USED : PART_NOT_AVAILABLE;\n\n            }\n\n\n\n            if(for_deblock)\n\n                continue;\n\n\n\n            h->ref_cache[list][scan8[5 ]+1] = \n\n            h->ref_cache[list][scan8[7 ]+1] = \n\n            h->ref_cache[list][scan8[13]+1] =  //FIXME remove past 3 (init somewher else)\n\n            h->ref_cache[list][scan8[4 ]] = \n\n            h->ref_cache[list][scan8[12]] = PART_NOT_AVAILABLE;\n\n            *(uint32_t*)h->mv_cache [list][scan8[5 ]+1]=\n\n            *(uint32_t*)h->mv_cache [list][scan8[7 ]+1]=\n\n            *(uint32_t*)h->mv_cache [list][scan8[13]+1]= //FIXME remove past 3 (init somewher else)\n\n            *(uint32_t*)h->mv_cache [list][scan8[4 ]]=\n\n            *(uint32_t*)h->mv_cache [list][scan8[12]]= 0;\n\n\n\n            if( h->pps.cabac ) {\n\n                /* XXX beurk, Load mvd */\n\n                if(IS_INTER(topleft_type)){\n\n                    const int b_xy = h->mb2b_xy[topleft_xy] + 3 + 3*h->b_stride;\n\n                    *(uint32_t*)h->mvd_cache[list][scan8[0] - 1 - 1*8]= *(uint32_t*)h->mvd_table[list][b_xy];\n\n                }else{\n\n                    *(uint32_t*)h->mvd_cache[list][scan8[0] - 1 - 1*8]= 0;\n\n                }\n\n\n\n                if(IS_INTER(top_type)){\n\n                    const int b_xy= h->mb2b_xy[top_xy] + 3*h->b_stride;\n\n                    *(uint32_t*)h->mvd_cache[list][scan8[0] + 0 - 1*8]= *(uint32_t*)h->mvd_table[list][b_xy + 0];\n\n                    *(uint32_t*)h->mvd_cache[list][scan8[0] + 1 - 1*8]= *(uint32_t*)h->mvd_table[list][b_xy + 1];\n\n                    *(uint32_t*)h->mvd_cache[list][scan8[0] + 2 - 1*8]= *(uint32_t*)h->mvd_table[list][b_xy + 2];\n\n                    *(uint32_t*)h->mvd_cache[list][scan8[0] + 3 - 1*8]= *(uint32_t*)h->mvd_table[list][b_xy + 3];\n\n                }else{\n\n                    *(uint32_t*)h->mvd_cache [list][scan8[0] + 0 - 1*8]= \n\n                    *(uint32_t*)h->mvd_cache [list][scan8[0] + 1 - 1*8]= \n\n                    *(uint32_t*)h->mvd_cache [list][scan8[0] + 2 - 1*8]= \n\n                    *(uint32_t*)h->mvd_cache [list][scan8[0] + 3 - 1*8]= 0;\n\n                }\n\n                if(IS_INTER(left_type[0])){\n\n                    const int b_xy= h->mb2b_xy[left_xy[0]] + 3;\n\n                    *(uint32_t*)h->mvd_cache[list][scan8[0] - 1 + 0*8]= *(uint32_t*)h->mvd_table[list][b_xy + h->b_stride*left_block[0]];\n\n                    *(uint32_t*)h->mvd_cache[list][scan8[0] - 1 + 1*8]= *(uint32_t*)h->mvd_table[list][b_xy + h->b_stride*left_block[1]];\n\n                }else{\n\n                    *(uint32_t*)h->mvd_cache [list][scan8[0] - 1 + 0*8]=\n\n                    *(uint32_t*)h->mvd_cache [list][scan8[0] - 1 + 1*8]= 0;\n\n                }\n\n                if(IS_INTER(left_type[1])){\n\n                    const int b_xy= h->mb2b_xy[left_xy[1]] + 3;\n\n                    *(uint32_t*)h->mvd_cache[list][scan8[0] - 1 + 2*8]= *(uint32_t*)h->mvd_table[list][b_xy + h->b_stride*left_block[2]];\n\n                    *(uint32_t*)h->mvd_cache[list][scan8[0] - 1 + 3*8]= *(uint32_t*)h->mvd_table[list][b_xy + h->b_stride*left_block[3]];\n\n                }else{\n\n                    *(uint32_t*)h->mvd_cache [list][scan8[0] - 1 + 2*8]=\n\n                    *(uint32_t*)h->mvd_cache [list][scan8[0] - 1 + 3*8]= 0;\n\n                }\n\n                *(uint32_t*)h->mvd_cache [list][scan8[5 ]+1]=\n\n                *(uint32_t*)h->mvd_cache [list][scan8[7 ]+1]=\n\n                *(uint32_t*)h->mvd_cache [list][scan8[13]+1]= //FIXME remove past 3 (init somewher else)\n\n                *(uint32_t*)h->mvd_cache [list][scan8[4 ]]=\n\n                *(uint32_t*)h->mvd_cache [list][scan8[12]]= 0;\n\n\n\n                if(h->slice_type == B_TYPE){\n\n                    fill_rectangle(&h->direct_cache[scan8[0]], 4, 4, 8, 0, 1);\n\n\n\n                    if(IS_DIRECT(top_type)){\n\n                        *(uint32_t*)&h->direct_cache[scan8[0] - 1*8]= 0x01010101;\n\n                    }else if(IS_8X8(top_type)){\n\n                        int b8_xy = h->mb2b8_xy[top_xy] + h->b8_stride;\n\n                        h->direct_cache[scan8[0] + 0 - 1*8]= h->direct_table[b8_xy];\n\n                        h->direct_cache[scan8[0] + 2 - 1*8]= h->direct_table[b8_xy + 1];\n\n                    }else{\n\n                        *(uint32_t*)&h->direct_cache[scan8[0] - 1*8]= 0;\n\n                    }\n\n                    \n\n                    //FIXME interlacing\n\n                    if(IS_DIRECT(left_type[0])){\n\n                        h->direct_cache[scan8[0] - 1 + 0*8]=\n\n                        h->direct_cache[scan8[0] - 1 + 2*8]= 1;\n\n                    }else if(IS_8X8(left_type[0])){\n\n                        int b8_xy = h->mb2b8_xy[left_xy[0]] + 1;\n\n                        h->direct_cache[scan8[0] - 1 + 0*8]= h->direct_table[b8_xy];\n\n                        h->direct_cache[scan8[0] - 1 + 2*8]= h->direct_table[b8_xy + h->b8_stride];\n\n                    }else{\n\n                        h->direct_cache[scan8[0] - 1 + 0*8]=\n\n                        h->direct_cache[scan8[0] - 1 + 2*8]= 0;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n#endif\n\n}\n", "idx": 23795}
{"project": "FFmpeg", "commit_id": "9ac831c2c02e6e1c9c322b8bb77881c1dbac6f08", "target": 0, "func": "static int update_dimensions(VP8Context *s, int width, int height)\n\n{\n\n    int i;\n\n\n\n    if (avcodec_check_dimensions(s->avctx, width, height))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    vp8_decode_flush(s->avctx);\n\n\n\n    avcodec_set_dimensions(s->avctx, width, height);\n\n\n\n    s->mb_width  = (s->avctx->coded_width +15) / 16;\n\n    s->mb_height = (s->avctx->coded_height+15) / 16;\n\n\n\n    // we allocate a border around the top/left of intra4x4 modes\n\n    // this is 4 blocks for intra4x4 to keep 4-byte alignment for fill_rectangle\n\n    s->mb_stride = s->mb_width+1;\n\n    s->b4_stride = 4*s->mb_stride;\n\n\n\n    s->macroblocks_base        = av_mallocz(s->mb_stride*(s->mb_height+1)*sizeof(*s->macroblocks));\n\n    s->intra4x4_pred_mode_base = av_mallocz(s->b4_stride*(4*s->mb_height+1));\n\n    s->top_nnz                 = av_mallocz(s->mb_width*sizeof(*s->top_nnz));\n\n\n\n    if (!s->macroblocks_base || !s->intra4x4_pred_mode_base || !s->top_nnz)\n\n        return AVERROR(ENOMEM);\n\n\n\n    s->macroblocks        = s->macroblocks_base        + 1 + s->mb_stride;\n\n    s->intra4x4_pred_mode = s->intra4x4_pred_mode_base + 4 + s->b4_stride;\n\n\n\n    memset(s->intra4x4_pred_mode_base, DC_PRED, s->b4_stride);\n\n    for (i = 0; i < 4*s->mb_height; i++)\n\n        s->intra4x4_pred_mode[i*s->b4_stride-1] = DC_PRED;\n\n\n\n    return 0;\n\n}\n", "idx": 23796}
{"project": "FFmpeg", "commit_id": "8fa18e042ad2c078f759692f1db5629d16d70595", "target": 0, "func": "static int http_connect(URLContext *h, const char *path, const char *local_path,\n\n                        const char *hoststr, const char *auth,\n\n                        const char *proxyauth, int *new_location)\n\n{\n\n    HTTPContext *s = h->priv_data;\n\n    int post, err;\n\n    char headers[HTTP_HEADERS_SIZE] = \"\";\n\n    char *authstr = NULL, *proxyauthstr = NULL;\n\n    uint64_t off = s->off;\n\n    int len = 0;\n\n    const char *method;\n\n    int send_expect_100 = 0;\n\n\n\n    /* send http header */\n\n    post = h->flags & AVIO_FLAG_WRITE;\n\n\n\n    if (s->post_data) {\n\n        /* force POST method and disable chunked encoding when\n\n         * custom HTTP post data is set */\n\n        post            = 1;\n\n        s->chunked_post = 0;\n\n    }\n\n\n\n    if (s->method)\n\n        method = s->method;\n\n    else\n\n        method = post ? \"POST\" : \"GET\";\n\n\n\n    authstr      = ff_http_auth_create_response(&s->auth_state, auth,\n\n                                                local_path, method);\n\n    proxyauthstr = ff_http_auth_create_response(&s->proxy_auth_state, proxyauth,\n\n                                                local_path, method);\n\n    if (post && !s->post_data) {\n\n        send_expect_100 = s->send_expect_100;\n\n        /* The user has supplied authentication but we don't know the auth type,\n\n         * send Expect: 100-continue to get the 401 response including the\n\n         * WWW-Authenticate header, or an 100 continue if no auth actually\n\n         * is needed. */\n\n        if (auth && *auth &&\n\n            s->auth_state.auth_type == HTTP_AUTH_NONE &&\n\n            s->http_code != 401)\n\n            send_expect_100 = 1;\n\n    }\n\n\n\n#if FF_API_HTTP_USER_AGENT\n\n    if (strcmp(s->user_agent_deprecated, DEFAULT_USER_AGENT)) {\n\n        av_log(s, AV_LOG_WARNING, \"the user-agent option is deprecated, please use user_agent option\\n\");\n\n        s->user_agent = av_strdup(s->user_agent_deprecated);\n\n    }\n\n#endif\n\n    /* set default headers if needed */\n\n    if (!has_header(s->headers, \"\\r\\nUser-Agent: \"))\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"User-Agent: %s\\r\\n\", s->user_agent);\n\n    if (!has_header(s->headers, \"\\r\\nAccept: \"))\n\n        len += av_strlcpy(headers + len, \"Accept: */*\\r\\n\",\n\n                          sizeof(headers) - len);\n\n    // Note: we send this on purpose even when s->off is 0 when we're probing,\n\n    // since it allows us to detect more reliably if a (non-conforming)\n\n    // server supports seeking by analysing the reply headers.\n\n    if (!has_header(s->headers, \"\\r\\nRange: \") && !post && (s->off > 0 || s->end_off || s->seekable == -1)) {\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"Range: bytes=%\"PRIu64\"-\", s->off);\n\n        if (s->end_off)\n\n            len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                               \"%\"PRId64, s->end_off - 1);\n\n        len += av_strlcpy(headers + len, \"\\r\\n\",\n\n                          sizeof(headers) - len);\n\n    }\n\n    if (send_expect_100 && !has_header(s->headers, \"\\r\\nExpect: \"))\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"Expect: 100-continue\\r\\n\");\n\n\n\n    if (!has_header(s->headers, \"\\r\\nConnection: \")) {\n\n        if (s->multiple_requests)\n\n            len += av_strlcpy(headers + len, \"Connection: keep-alive\\r\\n\",\n\n                              sizeof(headers) - len);\n\n        else\n\n            len += av_strlcpy(headers + len, \"Connection: close\\r\\n\",\n\n                              sizeof(headers) - len);\n\n    }\n\n\n\n    if (!has_header(s->headers, \"\\r\\nHost: \"))\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"Host: %s\\r\\n\", hoststr);\n\n    if (!has_header(s->headers, \"\\r\\nContent-Length: \") && s->post_data)\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"Content-Length: %d\\r\\n\", s->post_datalen);\n\n\n\n    if (!has_header(s->headers, \"\\r\\nContent-Type: \") && s->content_type)\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"Content-Type: %s\\r\\n\", s->content_type);\n\n    if (!has_header(s->headers, \"\\r\\nCookie: \") && s->cookies) {\n\n        char *cookies = NULL;\n\n        if (!get_cookies(s, &cookies, path, hoststr) && cookies) {\n\n            len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                               \"Cookie: %s\\r\\n\", cookies);\n\n            av_free(cookies);\n\n        }\n\n    }\n\n    if (!has_header(s->headers, \"\\r\\nIcy-MetaData: \") && s->icy)\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"Icy-MetaData: %d\\r\\n\", 1);\n\n\n\n    /* now add in custom headers */\n\n    if (s->headers)\n\n        av_strlcpy(headers + len, s->headers, sizeof(headers) - len);\n\n\n\n    snprintf(s->buffer, sizeof(s->buffer),\n\n             \"%s %s HTTP/1.1\\r\\n\"\n\n             \"%s\"\n\n             \"%s\"\n\n             \"%s\"\n\n             \"%s%s\"\n\n             \"\\r\\n\",\n\n             method,\n\n             path,\n\n             post && s->chunked_post ? \"Transfer-Encoding: chunked\\r\\n\" : \"\",\n\n             headers,\n\n             authstr ? authstr : \"\",\n\n             proxyauthstr ? \"Proxy-\" : \"\", proxyauthstr ? proxyauthstr : \"\");\n\n\n\n    av_log(h, AV_LOG_DEBUG, \"request: %s\\n\", s->buffer);\n\n\n\n    if ((err = ffurl_write(s->hd, s->buffer, strlen(s->buffer))) < 0)\n\n        goto done;\n\n\n\n    if (s->post_data)\n\n        if ((err = ffurl_write(s->hd, s->post_data, s->post_datalen)) < 0)\n\n            goto done;\n\n\n\n    /* init input buffer */\n\n    s->buf_ptr          = s->buffer;\n\n    s->buf_end          = s->buffer;\n\n    s->line_count       = 0;\n\n    s->off              = 0;\n\n    s->icy_data_read    = 0;\n\n    s->filesize         = UINT64_MAX;\n\n    s->willclose        = 0;\n\n    s->end_chunked_post = 0;\n\n    s->end_header       = 0;\n\n    if (post && !s->post_data && !send_expect_100) {\n\n        /* Pretend that it did work. We didn't read any header yet, since\n\n         * we've still to send the POST data, but the code calling this\n\n         * function will check http_code after we return. */\n\n        s->http_code = 200;\n\n        err = 0;\n\n        goto done;\n\n    }\n\n\n\n    /* wait for header */\n\n    err = http_read_header(h, new_location);\n\n    if (err < 0)\n\n        goto done;\n\n\n\n    if (*new_location)\n\n        s->off = off;\n\n\n\n    err = (off == s->off) ? 0 : -1;\n\ndone:\n\n    av_freep(&authstr);\n\n    av_freep(&proxyauthstr);\n\n    return err;\n\n}\n", "idx": 23797}
{"project": "FFmpeg", "commit_id": "9a6c528e08c42f43216fed9d6abd9e545db88d13", "target": 0, "func": "static void predictor_decompress_fir_adapt(int32_t *error_buffer,\n\n                                           int32_t *buffer_out,\n\n                                           int output_size,\n\n                                           int readsamplesize,\n\n                                           int16_t *predictor_coef_table,\n\n                                           int predictor_coef_num,\n\n                                           int predictor_quantitization)\n\n{\n\n    int i;\n\n\n\n    /* first sample always copies */\n\n    *buffer_out = *error_buffer;\n\n\n\n    if (!predictor_coef_num) {\n\n        if (output_size <= 1)\n\n            return;\n\n\n\n        memcpy(&buffer_out[1], &error_buffer[1],\n\n               (output_size - 1) * sizeof(*buffer_out));\n\n        return;\n\n    }\n\n\n\n    if (predictor_coef_num == 31) {\n\n        /* simple 1st-order prediction */\n\n        if (output_size <= 1)\n\n            return;\n\n        for (i = 1; i < output_size; i++) {\n\n            buffer_out[i] = sign_extend(buffer_out[i - 1] + error_buffer[i],\n\n                                        readsamplesize);\n\n        }\n\n        return;\n\n    }\n\n\n\n    /* read warm-up samples */\n\n    for (i = 0; i < predictor_coef_num; i++) {\n\n        buffer_out[i + 1] = sign_extend(buffer_out[i] + error_buffer[i + 1],\n\n                                        readsamplesize);\n\n    }\n\n\n\n    /* NOTE: 4 and 8 are very common cases that could be optimized. */\n\n\n\n    /* general case */\n\n    for (i = predictor_coef_num; i < output_size - 1; i++) {\n\n        int j;\n\n        int val = 0;\n\n        int error_val = error_buffer[i + 1];\n\n        int error_sign;\n\n        int d = buffer_out[i - predictor_coef_num];\n\n\n\n        for (j = 0; j < predictor_coef_num; j++) {\n\n            val += (buffer_out[i - j] - d) *\n\n                   predictor_coef_table[j];\n\n        }\n\n\n\n        val = (val + (1 << (predictor_quantitization - 1))) >>\n\n              predictor_quantitization;\n\n        val += d + error_val;\n\n\n\n        buffer_out[i + 1] = sign_extend(val, readsamplesize);\n\n\n\n        /* adapt LPC coefficients */\n\n        error_sign = sign_only(error_val);\n\n        if (error_sign) {\n\n            for (j = predictor_coef_num - 1; j >= 0 && error_val * error_sign > 0; j--) {\n\n                int sign;\n\n                val  = d - buffer_out[i - j];\n\n                sign = sign_only(val) * error_sign;\n\n                predictor_coef_table[j] -= sign;\n\n                val *= sign;\n\n                error_val -= ((val >> predictor_quantitization) *\n\n                              (predictor_coef_num - j));\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 23798}
{"project": "FFmpeg", "commit_id": "fc49f22c3b735db5aaac5f98e40b7124a2be13b8", "target": 1, "func": "static int alloc_audio_output_buf(AVCodecContext *dec, AVCodecContext *enc,\n\n                                  int nb_samples, int *buf_linesize)\n\n{\n\n    int64_t audio_buf_samples;\n\n    int audio_buf_size;\n\n\n\n    /* calculate required number of samples to allocate */\n\n    audio_buf_samples = ((int64_t)nb_samples * enc->sample_rate + dec->sample_rate) /\n\n                        dec->sample_rate;\n\n    audio_buf_samples = 4 * audio_buf_samples + 10000; // safety factors for resampling\n\n    audio_buf_samples = FFMAX(audio_buf_samples, enc->frame_size);\n\n    if (audio_buf_samples > INT_MAX)\n\n        return AVERROR(EINVAL);\n\n\n\n    audio_buf_size = av_samples_get_buffer_size(buf_linesize, enc->channels,\n\n                                                audio_buf_samples,\n\n                                                enc->sample_fmt, 0);\n\n    if (audio_buf_size < 0)\n\n        return audio_buf_size;\n\n\n\n    av_fast_malloc(&audio_buf, &allocated_audio_buf_size, audio_buf_size);\n\n    if (!audio_buf)\n\n        return AVERROR(ENOMEM);\n\n\n\n    return 0;\n\n}\n", "idx": 23799}
{"project": "FFmpeg", "commit_id": "6f7f2396049575fcf2054b4dafa19ca01381638e", "target": 1, "func": "static int nut_write_header(AVFormatContext * avf) {\n\n    NUTContext * priv = avf->priv_data;\n\n    AVIOContext * bc = avf->pb;\n\n    nut_muxer_opts_tt mopts = {\n\n        .output = {\n\n            .priv = bc,\n\n            .write = av_write,\n\n        },\n\n        .alloc = { av_malloc, av_realloc, av_free },\n\n        .write_index = 1,\n\n        .realtime_stream = 0,\n\n        .max_distance = 32768,\n\n        .fti = NULL,\n\n    };\n\n    nut_stream_header_tt * s;\n\n    int i;\n\n\n\n    priv->s = s = av_mallocz((avf->nb_streams + 1) * sizeof*s);\n\n\n\n\n\n    for (i = 0; i < avf->nb_streams; i++) {\n\n        AVCodecContext * codec = avf->streams[i]->codec;\n\n        int j;\n\n        int fourcc = 0;\n\n        int num, denom, ssize;\n\n\n\n        s[i].type = codec->codec_type == AVMEDIA_TYPE_VIDEO ? NUT_VIDEO_CLASS : NUT_AUDIO_CLASS;\n\n\n\n        if (codec->codec_tag) fourcc = codec->codec_tag;\n\n        else fourcc = ff_codec_get_tag(nut_tags, codec->codec_id);\n\n\n\n        if (!fourcc) {\n\n            if (codec->codec_type == AVMEDIA_TYPE_VIDEO) fourcc = ff_codec_get_tag(ff_codec_bmp_tags, codec->codec_id);\n\n            if (codec->codec_type == AVMEDIA_TYPE_AUDIO) fourcc = ff_codec_get_tag(ff_codec_wav_tags, codec->codec_id);\n\n        }\n\n\n\n        s[i].fourcc_len = 4;\n\n        s[i].fourcc = av_malloc(s[i].fourcc_len);\n\n        for (j = 0; j < s[i].fourcc_len; j++) s[i].fourcc[j] = (fourcc >> (j*8)) & 0xFF;\n\n\n\n        ff_parse_specific_params(codec, &num, &ssize, &denom);\n\n        avpriv_set_pts_info(avf->streams[i], 60, denom, num);\n\n\n\n        s[i].time_base.num = denom;\n\n        s[i].time_base.den = num;\n\n\n\n        s[i].fixed_fps = 0;\n\n        s[i].decode_delay = codec->has_b_frames;\n\n        s[i].codec_specific_len = codec->extradata_size;\n\n        s[i].codec_specific = codec->extradata;\n\n\n\n        if (codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            s[i].width = codec->width;\n\n            s[i].height = codec->height;\n\n            s[i].sample_width = 0;\n\n            s[i].sample_height = 0;\n\n            s[i].colorspace_type = 0;\n\n        } else {\n\n            s[i].samplerate_num = codec->sample_rate;\n\n            s[i].samplerate_denom = 1;\n\n            s[i].channel_count = codec->channels;\n\n        }\n\n    }\n\n\n\n    s[avf->nb_streams].type = -1;\n\n    priv->nut = nut_muxer_init(&mopts, s, NULL);\n\n\n\n    return 0;\n\n}", "idx": 23801}
{"project": "FFmpeg", "commit_id": "20da77449d4427a7152b80e4f9acce6a8c93ee7d", "target": 0, "func": "static inline int RENAME(yuv420_rgb16)(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,\n\n             int srcSliceH, uint8_t* dst[], int dstStride[]){\n\n    int y, h_size;\n\n\n\n    if(c->srcFormat == PIX_FMT_YUV422P){\n\n\tsrcStride[1] *= 2;\n\n\tsrcStride[2] *= 2;\n\n    }\n\n\n\n    h_size= (c->dstW+7)&~7;\n\n    if(h_size*2 > dstStride[0]) h_size-=8;\n\n    \n\n    __asm__ __volatile__ (\"pxor %mm4, %mm4;\" /* zero mm4 */ );\n\n//printf(\"%X %X %X %X %X %X %X %X %X %X\\n\", (int)&c->redDither, (int)&b5Dither, (int)src[0], (int)src[1], (int)src[2], (int)dst[0],\n\n//srcStride[0],srcStride[1],srcStride[2],dstStride[0]);\n\n    for (y= 0; y<srcSliceH; y++ ) {\n\n\tuint8_t *_image = dst[0] + (y+srcSliceY)*dstStride[0];\n\n\tuint8_t *_py = src[0] + y*srcStride[0];\n\n\tuint8_t *_pu = src[1] + (y>>1)*srcStride[1];\n\n\tuint8_t *_pv = src[2] + (y>>1)*srcStride[2];\n\n\tlong index= -h_size/2;\n\n\n\n\tb5Dither= dither8[y&1];\n\n\tg6Dither= dither4[y&1];\n\n\tg5Dither= dither8[y&1];\n\n\tr5Dither= dither8[(y+1)&1];\n\n\t    /* this mmx assembly code deals with SINGLE scan line at a time, it convert 8\n\n\t       pixels in each iteration */\n\n\t    __asm__ __volatile__ (\n\n\t/* load data for start of next scan line */\n\n\t\t     \"movd (%2, %0), %%mm0;\" /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */\n\n\t\t     \"movd (%3, %0), %%mm1;\" /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */\n\n\t\t     \"movq (%5, %0, 2), %%mm6;\" /* Load 8  Y Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 */\n\n//\t\t    \".balign 16\t\t\t\\n\\t\"\n\n\t\t    \"1:\t\t\t\t\\n\\t\"\n\n/* no speed diference on my p3@500 with prefetch,\n\n * if it is faster for anyone with -benchmark then tell me\n\n\t\t\tPREFETCH\" 64(%0) \\n\\t\"\n\n\t\t\tPREFETCH\" 64(%1) \\n\\t\"\n\n\t\t\tPREFETCH\" 64(%2) \\n\\t\"\n\n*/\n\nYUV2RGB\n\n\n\n#ifdef DITHER1XBPP\n\n\t\t\t\"paddusb \"MANGLE(b5Dither)\", %%mm0;\"\n\n\t\t\t\"paddusb \"MANGLE(g6Dither)\", %%mm2;\"\n\n\t\t\t\"paddusb \"MANGLE(r5Dither)\", %%mm1;\"\n\n#endif\n\n\t\t     /* mask unneeded bits off */\n\n\t\t     \"pand \"MANGLE(mmx_redmask)\", %%mm0;\" /* b7b6b5b4 b3_0_0_0 b7b6b5b4 b3_0_0_0 */\n\n\t\t     \"pand \"MANGLE(mmx_grnmask)\", %%mm2;\" /* g7g6g5g4 g3g2_0_0 g7g6g5g4 g3g2_0_0 */\n\n\t\t     \"pand \"MANGLE(mmx_redmask)\", %%mm1;\" /* r7r6r5r4 r3_0_0_0 r7r6r5r4 r3_0_0_0 */\n\n\n\n\t\t     \"psrlw $3,%%mm0;\" /* 0_0_0_b7 b6b5b4b3 0_0_0_b7 b6b5b4b3 */\n\n\t\t     \"pxor %%mm4, %%mm4;\" /* zero mm4 */\n\n\n\n\t\t     \"movq %%mm0, %%mm5;\" /* Copy B7-B0 */\n\n\t\t     \"movq %%mm2, %%mm7;\" /* Copy G7-G0 */\n\n\n\n\t\t     /* convert rgb24 plane to rgb16 pack for pixel 0-3 */\n\n\t\t     \"punpcklbw %%mm4, %%mm2;\" /* 0_0_0_0 0_0_0_0 g7g6g5g4 g3g2_0_0 */\n\n\t\t     \"punpcklbw %%mm1, %%mm0;\" /* r7r6r5r4 r3_0_0_0 0_0_0_b7 b6b5b4b3 */\n\n\n\n\t\t     \"psllw $3, %%mm2;\" /* 0_0_0_0 0_g7g6g5 g4g3g2_0 0_0_0_0 */\n\n\t\t     \"por %%mm2, %%mm0;\" /* r7r6r5r4 r3g7g6g5 g4g3g2b7 b6b5b4b3 */\n\n\n\n\t\t     \"movq 8 (%5, %0, 2), %%mm6;\" /* Load 8 Y Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 */\n\n\t\t     MOVNTQ \" %%mm0, (%1);\" /* store pixel 0-3 */\n\n\n\n\t\t     /* convert rgb24 plane to rgb16 pack for pixel 0-3 */\n\n\t\t     \"punpckhbw %%mm4, %%mm7;\" /* 0_0_0_0 0_0_0_0 g7g6g5g4 g3g2_0_0 */\n\n\t\t     \"punpckhbw %%mm1, %%mm5;\" /* r7r6r5r4 r3_0_0_0 0_0_0_b7 b6b5b4b3 */\n\n\n\n\t\t     \"psllw $3, %%mm7;\" /* 0_0_0_0 0_g7g6g5 g4g3g2_0 0_0_0_0 */\n\n\t\t     \"movd 4 (%2, %0), %%mm0;\" /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */\n\n\n\n\t\t     \"por %%mm7, %%mm5;\" /* r7r6r5r4 r3g7g6g5 g4g3g2b7 b6b5b4b3 */\n\n\t\t     \"movd 4 (%3, %0), %%mm1;\" /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */\n\n\n\n\t\t     MOVNTQ \" %%mm5, 8 (%1);\" /* store pixel 4-7 */\n\n\t\t     \n\n\t\t     \"add $16, %1\t\t\t\\n\\t\"\n\n\t\t     \"add $4, %0\t\t\t\\n\\t\"\n\n\t\t     \" js 1b\t\t\t\t\\n\\t\"\n\n\t\t     \n\n\t\t     : \"+r\" (index), \"+r\" (_image)\n\n\t\t     : \"r\" (_pu - index), \"r\" (_pv - index), \"r\"(&c->redDither), \"r\" (_py - 2*index)\n\n\t\t     );\n\n    }\n\n\n\n    __asm__ __volatile__ (EMMS);\n\n    \n\n    return srcSliceH;\n\n}\n", "idx": 23802}
{"project": "FFmpeg", "commit_id": "3d828c9fd51aa8c348ff11241e212e5834b4f806", "target": 0, "func": "size_t av_cpu_max_align(void)\n\n{\n\n    int flags = av_get_cpu_flags();\n\n\n\n    if (flags & AV_CPU_FLAG_AVX)\n\n        return 32;\n\n    if (flags & (AV_CPU_FLAG_ALTIVEC | AV_CPU_FLAG_SSE | AV_CPU_FLAG_NEON))\n\n        return 16;\n\n\n\n    return 8;\n\n}\n", "idx": 23821}
{"project": "FFmpeg", "commit_id": "ed16c2dbf47cdd7c48825b4da6e7036698e5dde1", "target": 0, "func": "static void h261_loop_filter_c(uint8_t *src, int stride){\n\n    int x,y,xy,yz;\n\n    int temp[64];\n\n\n\n    for(x=0; x<8; x++){\n\n        temp[x      ] = 4*src[x           ];\n\n        temp[x + 7*8] = 4*src[x + 7*stride];\n\n    }\n\n    for(y=1; y<7; y++){\n\n        for(x=0; x<8; x++){\n\n            xy = y * stride + x;\n\n            yz = y * 8 + x;\n\n            temp[yz] = src[xy - stride] + 2*src[xy] + src[xy + stride];\n\n        }\n\n    }\n\n\n\n    for(y=0; y<8; y++){\n\n        src[  y*stride] = (temp[  y*8] + 2)>>2;\n\n        src[7+y*stride] = (temp[7+y*8] + 2)>>2;\n\n        for(x=1; x<7; x++){\n\n            xy = y * stride + x;\n\n            yz = y * 8 + x;\n\n            src[xy] = (temp[yz-1] + 2*temp[yz] + temp[yz+1] + 8)>>4;\n\n        }\n\n    }\n\n}\n", "idx": 23832}
{"project": "FFmpeg", "commit_id": "354b757300186ed7a7e36682e8faf5cdc4ad63c1", "target": 0, "func": "int ff_rtsp_connect(AVFormatContext *s)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    char host[1024], path[1024], tcpname[1024], cmd[2048], auth[128];\n\n    char *option_list, *option, *filename;\n\n    int port, err, tcp_fd;\n\n    RTSPMessageHeader reply1 = {}, *reply = &reply1;\n\n    int lower_transport_mask = 0;\n\n    char real_challenge[64];\n\n    struct sockaddr_storage peer;\n\n    socklen_t peer_len = sizeof(peer);\n\n\n\n    if (!ff_network_init())\n\n        return AVERROR(EIO);\n\nredirect:\n\n    rt->control_transport = RTSP_MODE_PLAIN;\n\n    /* extract hostname and port */\n\n    av_url_split(NULL, 0, auth, sizeof(auth),\n\n                 host, sizeof(host), &port, path, sizeof(path), s->filename);\n\n    if (*auth) {\n\n        av_strlcpy(rt->auth, auth, sizeof(rt->auth));\n\n    }\n\n    if (port < 0)\n\n        port = RTSP_DEFAULT_PORT;\n\n\n\n    /* search for options */\n\n    option_list = strrchr(path, '?');\n\n    if (option_list) {\n\n        /* Strip out the RTSP specific options, write out the rest of\n\n         * the options back into the same string. */\n\n        filename = option_list;\n\n        while (option_list) {\n\n            /* move the option pointer */\n\n            option = ++option_list;\n\n            option_list = strchr(option_list, '&');\n\n            if (option_list)\n\n                *option_list = 0;\n\n\n\n            /* handle the options */\n\n            if (!strcmp(option, \"udp\")) {\n\n                lower_transport_mask |= (1<< RTSP_LOWER_TRANSPORT_UDP);\n\n            } else if (!strcmp(option, \"multicast\")) {\n\n                lower_transport_mask |= (1<< RTSP_LOWER_TRANSPORT_UDP_MULTICAST);\n\n            } else if (!strcmp(option, \"tcp\")) {\n\n                lower_transport_mask |= (1<< RTSP_LOWER_TRANSPORT_TCP);\n\n            } else if(!strcmp(option, \"http\")) {\n\n                lower_transport_mask |= (1<< RTSP_LOWER_TRANSPORT_TCP);\n\n                rt->control_transport = RTSP_MODE_TUNNEL;\n\n            } else {\n\n                /* Write options back into the buffer, using memmove instead\n\n                 * of strcpy since the strings may overlap. */\n\n                int len = strlen(option);\n\n                memmove(++filename, option, len);\n\n                filename += len;\n\n                if (option_list) *filename = '&';\n\n            }\n\n        }\n\n        *filename = 0;\n\n    }\n\n\n\n    if (!lower_transport_mask)\n\n        lower_transport_mask = (1 << RTSP_LOWER_TRANSPORT_NB) - 1;\n\n\n\n    if (s->oformat) {\n\n        /* Only UDP or TCP - UDP multicast isn't supported. */\n\n        lower_transport_mask &= (1 << RTSP_LOWER_TRANSPORT_UDP) |\n\n                                (1 << RTSP_LOWER_TRANSPORT_TCP);\n\n        if (!lower_transport_mask || rt->control_transport == RTSP_MODE_TUNNEL) {\n\n            av_log(s, AV_LOG_ERROR, \"Unsupported lower transport method, \"\n\n                                    \"only UDP and TCP are supported for output.\\n\");\n\n            err = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n    /* Construct the URI used in request; this is similar to s->filename,\n\n     * but with authentication credentials removed and RTSP specific options\n\n     * stripped out. */\n\n    ff_url_join(rt->control_uri, sizeof(rt->control_uri), \"rtsp\", NULL,\n\n                host, port, \"%s\", path);\n\n\n\n    if (rt->control_transport == RTSP_MODE_TUNNEL) {\n\n        /* set up initial handshake for tunneling */\n\n        char httpname[1024];\n\n        char sessioncookie[17];\n\n        char headers[1024];\n\n\n\n        ff_url_join(httpname, sizeof(httpname), \"http\", auth, host, port, \"%s\", path);\n\n        snprintf(sessioncookie, sizeof(sessioncookie), \"%08x%08x\",\n\n                 av_get_random_seed(), av_get_random_seed());\n\n\n\n        /* GET requests */\n\n        if (url_alloc(&rt->rtsp_hd, httpname, URL_RDONLY) < 0) {\n\n            err = AVERROR(EIO);\n\n            goto fail;\n\n        }\n\n\n\n        /* generate GET headers */\n\n        snprintf(headers, sizeof(headers),\n\n                 \"x-sessioncookie: %s\\r\\n\"\n\n                 \"Accept: application/x-rtsp-tunnelled\\r\\n\"\n\n                 \"Pragma: no-cache\\r\\n\"\n\n                 \"Cache-Control: no-cache\\r\\n\",\n\n                 sessioncookie);\n\n        ff_http_set_headers(rt->rtsp_hd, headers);\n\n\n\n        /* complete the connection */\n\n        if (url_connect(rt->rtsp_hd)) {\n\n            err = AVERROR(EIO);\n\n            goto fail;\n\n        }\n\n\n\n        /* POST requests */\n\n        if (url_alloc(&rt->rtsp_hd_out, httpname, URL_WRONLY) < 0 ) {\n\n            err = AVERROR(EIO);\n\n            goto fail;\n\n        }\n\n\n\n        /* generate POST headers */\n\n        snprintf(headers, sizeof(headers),\n\n                 \"x-sessioncookie: %s\\r\\n\"\n\n                 \"Content-Type: application/x-rtsp-tunnelled\\r\\n\"\n\n                 \"Pragma: no-cache\\r\\n\"\n\n                 \"Cache-Control: no-cache\\r\\n\"\n\n                 \"Content-Length: 32767\\r\\n\"\n\n                 \"Expires: Sun, 9 Jan 1972 00:00:00 GMT\\r\\n\",\n\n                 sessioncookie);\n\n        ff_http_set_headers(rt->rtsp_hd_out, headers);\n\n        ff_http_set_chunked_transfer_encoding(rt->rtsp_hd_out, 0);\n\n\n\n        /* Initialize the authentication state for the POST session. The HTTP\n\n         * protocol implementation doesn't properly handle multi-pass\n\n         * authentication for POST requests, since it would require one of\n\n         * the following:\n\n         * - implementing Expect: 100-continue, which many HTTP servers\n\n         *   don't support anyway, even less the RTSP servers that do HTTP\n\n         *   tunneling\n\n         * - sending the whole POST data until getting a 401 reply specifying\n\n         *   what authentication method to use, then resending all that data\n\n         * - waiting for potential 401 replies directly after sending the\n\n         *   POST header (waiting for some unspecified time)\n\n         * Therefore, we copy the full auth state, which works for both basic\n\n         * and digest. (For digest, we would have to synchronize the nonce\n\n         * count variable between the two sessions, if we'd do more requests\n\n         * with the original session, though.)\n\n         */\n\n        ff_http_init_auth_state(rt->rtsp_hd_out, rt->rtsp_hd);\n\n\n\n        /* complete the connection */\n\n        if (url_connect(rt->rtsp_hd_out)) {\n\n            err = AVERROR(EIO);\n\n            goto fail;\n\n        }\n\n    } else {\n\n        /* open the tcp connection */\n\n        ff_url_join(tcpname, sizeof(tcpname), \"tcp\", NULL, host, port, NULL);\n\n        if (url_open(&rt->rtsp_hd, tcpname, URL_RDWR) < 0) {\n\n            err = AVERROR(EIO);\n\n            goto fail;\n\n        }\n\n        rt->rtsp_hd_out = rt->rtsp_hd;\n\n    }\n\n    rt->seq = 0;\n\n\n\n    tcp_fd = url_get_file_handle(rt->rtsp_hd);\n\n    if (!getpeername(tcp_fd, (struct sockaddr*) &peer, &peer_len)) {\n\n        getnameinfo((struct sockaddr*) &peer, peer_len, host, sizeof(host),\n\n                    NULL, 0, NI_NUMERICHOST);\n\n    }\n\n\n\n    /* request options supported by the server; this also detects server\n\n     * type */\n\n    for (rt->server_type = RTSP_SERVER_RTP;;) {\n\n        cmd[0] = 0;\n\n        if (rt->server_type == RTSP_SERVER_REAL)\n\n            av_strlcat(cmd,\n\n                       /**\n\n                        * The following entries are required for proper\n\n                        * streaming from a Realmedia server. They are\n\n                        * interdependent in some way although we currently\n\n                        * don't quite understand how. Values were copied\n\n                        * from mplayer SVN r23589.\n\n                        * @param CompanyID is a 16-byte ID in base64\n\n                        * @param ClientChallenge is a 16-byte ID in hex\n\n                        */\n\n                       \"ClientChallenge: 9e26d33f2984236010ef6253fb1887f7\\r\\n\"\n\n                       \"PlayerStarttime: [28/03/2003:22:50:23 00:00]\\r\\n\"\n\n                       \"CompanyID: KnKV4M4I/B2FjJ1TToLycw==\\r\\n\"\n\n                       \"GUID: 00000000-0000-0000-0000-000000000000\\r\\n\",\n\n                       sizeof(cmd));\n\n        ff_rtsp_send_cmd(s, \"OPTIONS\", rt->control_uri, cmd, reply, NULL);\n\n        if (reply->status_code != RTSP_STATUS_OK) {\n\n            err = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n\n\n        /* detect server type if not standard-compliant RTP */\n\n        if (rt->server_type != RTSP_SERVER_REAL && reply->real_challenge[0]) {\n\n            rt->server_type = RTSP_SERVER_REAL;\n\n            continue;\n\n        } else if (!strncasecmp(reply->server, \"WMServer/\", 9)) {\n\n            rt->server_type = RTSP_SERVER_WMS;\n\n        } else if (rt->server_type == RTSP_SERVER_REAL)\n\n            strcpy(real_challenge, reply->real_challenge);\n\n        break;\n\n    }\n\n\n\n    if (s->iformat)\n\n        err = rtsp_setup_input_streams(s, reply);\n\n    else\n\n        err = rtsp_setup_output_streams(s, host);\n\n    if (err)\n\n        goto fail;\n\n\n\n    do {\n\n        int lower_transport = ff_log2_tab[lower_transport_mask &\n\n                                  ~(lower_transport_mask - 1)];\n\n\n\n        err = make_setup_request(s, host, port, lower_transport,\n\n                                 rt->server_type == RTSP_SERVER_REAL ?\n\n                                     real_challenge : NULL);\n\n        if (err < 0)\n\n            goto fail;\n\n        lower_transport_mask &= ~(1 << lower_transport);\n\n        if (lower_transport_mask == 0 && err == 1) {\n\n            err = FF_NETERROR(EPROTONOSUPPORT);\n\n            goto fail;\n\n        }\n\n    } while (err);\n\n\n\n    rt->state = RTSP_STATE_IDLE;\n\n    rt->seek_timestamp = 0; /* default is to start stream at position zero */\n\n    return 0;\n\n fail:\n\n    ff_rtsp_close_streams(s);\n\n    ff_rtsp_close_connections(s);\n\n    if (reply->status_code >=300 && reply->status_code < 400 && s->iformat) {\n\n        av_strlcpy(s->filename, reply->location, sizeof(s->filename));\n\n        av_log(s, AV_LOG_INFO, \"Status %d: Redirecting to %s\\n\",\n\n               reply->status_code,\n\n               s->filename);\n\n        goto redirect;\n\n    }\n\n    ff_network_close();\n\n    return err;\n\n}\n", "idx": 23833}
{"project": "FFmpeg", "commit_id": "b1e2192007d7026049237c9ab11e05ae71bf4f42", "target": 1, "func": "static int ipvideo_decode_frame(AVCodecContext *avctx,\n\n                                void *data, int *got_frame,\n\n                                AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    IpvideoContext *s = avctx->priv_data;\n\n    AVFrame *frame = data;\n\n    int ret;\n\n\n\n    if (buf_size < 2)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    /* decoding map contains 4 bits of information per 8x8 block */\n\n    s->decoding_map_size = AV_RL16(avpkt->data);\n\n\n\n    /* compressed buffer needs to be large enough to at least hold an entire\n\n     * decoding map */\n\n    if (buf_size < s->decoding_map_size + 2)\n\n        return buf_size;\n\n\n\n    if (av_packet_get_side_data(avpkt, AV_PKT_DATA_PARAM_CHANGE, NULL)) {\n\n        av_frame_unref(s->last_frame);\n\n        av_frame_unref(s->second_last_frame);\n\n    }\n\n\n\n    s->decoding_map = buf + 2;\n\n    bytestream2_init(&s->stream_ptr, buf + 2 + s->decoding_map_size,\n\n                     buf_size - s->decoding_map_size);\n\n\n\n    if ((ret = ff_get_buffer(avctx, frame, AV_GET_BUFFER_FLAG_REF)) < 0)\n\n        return ret;\n\n\n\n    if (!s->is_16bpp) {\n\n        int size;\n\n        const uint8_t *pal = av_packet_get_side_data(avpkt, AV_PKT_DATA_PALETTE, &size);\n\n        if (pal && size == AVPALETTE_SIZE) {\n\n            frame->palette_has_changed = 1;\n\n            memcpy(s->pal, pal, AVPALETTE_SIZE);\n\n        } else if (pal) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Palette size %d is wrong\\n\", size);\n\n        }\n\n    }\n\n\n\n    ipvideo_decode_opcodes(s, frame);\n\n\n\n    *got_frame = 1;\n\n\n\n    /* shuffle frames */\n\n    av_frame_unref(s->second_last_frame);\n\n    FFSWAP(AVFrame*, s->second_last_frame, s->last_frame);\n\n    if ((ret = av_frame_ref(s->last_frame, frame)) < 0)\n\n        return ret;\n\n\n\n    /* report that the buffer was completely consumed */\n\n    return buf_size;\n\n}\n", "idx": 23835}
{"project": "FFmpeg", "commit_id": "19f6fd199e46c5a56f09a768ece4246b48bd86dd", "target": 0, "func": "static int process_ipmovie_chunk(IPMVEContext *s, AVIOContext *pb,\n\n    AVPacket *pkt)\n\n{\n\n    unsigned char chunk_preamble[CHUNK_PREAMBLE_SIZE];\n\n    int chunk_type;\n\n    int chunk_size;\n\n    unsigned char opcode_preamble[OPCODE_PREAMBLE_SIZE];\n\n    unsigned char opcode_type;\n\n    unsigned char opcode_version;\n\n    int opcode_size;\n\n    unsigned char scratch[1024];\n\n    int i, j;\n\n    int first_color, last_color;\n\n    int audio_flags;\n\n    unsigned char r, g, b;\n\n    unsigned int width, height;\n\n\n\n    /* see if there are any pending packets */\n\n    chunk_type = load_ipmovie_packet(s, pb, pkt);\n\n    if (chunk_type != CHUNK_DONE)\n\n        return chunk_type;\n\n\n\n    /* read the next chunk, wherever the file happens to be pointing */\n\n    if (avio_feof(pb))\n\n        return CHUNK_EOF;\n\n    if (avio_read(pb, chunk_preamble, CHUNK_PREAMBLE_SIZE) !=\n\n        CHUNK_PREAMBLE_SIZE)\n\n        return CHUNK_BAD;\n\n    chunk_size = AV_RL16(&chunk_preamble[0]);\n\n    chunk_type = AV_RL16(&chunk_preamble[2]);\n\n\n\n    av_log(s->avf, AV_LOG_TRACE, \"chunk type 0x%04X, 0x%04X bytes: \", chunk_type, chunk_size);\n\n\n\n    switch (chunk_type) {\n\n\n\n    case CHUNK_INIT_AUDIO:\n\n        av_log(s->avf, AV_LOG_TRACE, \"initialize audio\\n\");\n\n        break;\n\n\n\n    case CHUNK_AUDIO_ONLY:\n\n        av_log(s->avf, AV_LOG_TRACE, \"audio only\\n\");\n\n        break;\n\n\n\n    case CHUNK_INIT_VIDEO:\n\n        av_log(s->avf, AV_LOG_TRACE, \"initialize video\\n\");\n\n        break;\n\n\n\n    case CHUNK_VIDEO:\n\n        av_log(s->avf, AV_LOG_TRACE, \"video (and audio)\\n\");\n\n        break;\n\n\n\n    case CHUNK_SHUTDOWN:\n\n        av_log(s->avf, AV_LOG_TRACE, \"shutdown\\n\");\n\n        break;\n\n\n\n    case CHUNK_END:\n\n        av_log(s->avf, AV_LOG_TRACE, \"end\\n\");\n\n        break;\n\n\n\n    default:\n\n        av_log(s->avf, AV_LOG_TRACE, \"invalid chunk\\n\");\n\n        chunk_type = CHUNK_BAD;\n\n        break;\n\n\n\n    }\n\n\n\n    while ((chunk_size > 0) && (chunk_type != CHUNK_BAD)) {\n\n\n\n        /* read the next chunk, wherever the file happens to be pointing */\n\n        if (avio_feof(pb)) {\n\n            chunk_type = CHUNK_EOF;\n\n            break;\n\n        }\n\n        if (avio_read(pb, opcode_preamble, CHUNK_PREAMBLE_SIZE) !=\n\n            CHUNK_PREAMBLE_SIZE) {\n\n            chunk_type = CHUNK_BAD;\n\n            break;\n\n        }\n\n\n\n        opcode_size = AV_RL16(&opcode_preamble[0]);\n\n        opcode_type = opcode_preamble[2];\n\n        opcode_version = opcode_preamble[3];\n\n\n\n        chunk_size -= OPCODE_PREAMBLE_SIZE;\n\n        chunk_size -= opcode_size;\n\n        if (chunk_size < 0) {\n\n            av_log(s->avf, AV_LOG_TRACE, \"chunk_size countdown just went negative\\n\");\n\n            chunk_type = CHUNK_BAD;\n\n            break;\n\n        }\n\n\n\n        av_log(s->avf, AV_LOG_TRACE, \"  opcode type %02X, version %d, 0x%04X bytes: \",\n\n                opcode_type, opcode_version, opcode_size);\n\n        switch (opcode_type) {\n\n\n\n        case OPCODE_END_OF_STREAM:\n\n            av_log(s->avf, AV_LOG_TRACE, \"end of stream\\n\");\n\n            avio_skip(pb, opcode_size);\n\n            break;\n\n\n\n        case OPCODE_END_OF_CHUNK:\n\n            av_log(s->avf, AV_LOG_TRACE, \"end of chunk\\n\");\n\n            avio_skip(pb, opcode_size);\n\n            break;\n\n\n\n        case OPCODE_CREATE_TIMER:\n\n            av_log(s->avf, AV_LOG_TRACE, \"create timer\\n\");\n\n            if ((opcode_version > 0) || (opcode_size != 6)) {\n\n                av_log(s->avf, AV_LOG_TRACE, \"bad create_timer opcode\\n\");\n\n                chunk_type = CHUNK_BAD;\n\n                break;\n\n            }\n\n            if (avio_read(pb, scratch, opcode_size) !=\n\n                opcode_size) {\n\n                chunk_type = CHUNK_BAD;\n\n                break;\n\n            }\n\n            s->frame_pts_inc = ((uint64_t)AV_RL32(&scratch[0])) * AV_RL16(&scratch[4]);\n\n            break;\n\n\n\n        case OPCODE_INIT_AUDIO_BUFFERS:\n\n            av_log(s->avf, AV_LOG_TRACE, \"initialize audio buffers\\n\");\n\n            if (opcode_version > 1 || opcode_size > 10 || opcode_size < 6) {\n\n                av_log(s->avf, AV_LOG_TRACE, \"bad init_audio_buffers opcode\\n\");\n\n                chunk_type = CHUNK_BAD;\n\n                break;\n\n            }\n\n            if (avio_read(pb, scratch, opcode_size) !=\n\n                opcode_size) {\n\n                chunk_type = CHUNK_BAD;\n\n                break;\n\n            }\n\n            s->audio_sample_rate = AV_RL16(&scratch[4]);\n\n            audio_flags = AV_RL16(&scratch[2]);\n\n            /* bit 0 of the flags: 0 = mono, 1 = stereo */\n\n            s->audio_channels = (audio_flags & 1) + 1;\n\n            /* bit 1 of the flags: 0 = 8 bit, 1 = 16 bit */\n\n            s->audio_bits = (((audio_flags >> 1) & 1) + 1) * 8;\n\n            /* bit 2 indicates compressed audio in version 1 opcode */\n\n            if ((opcode_version == 1) && (audio_flags & 0x4))\n\n                s->audio_type = AV_CODEC_ID_INTERPLAY_DPCM;\n\n            else if (s->audio_bits == 16)\n\n                s->audio_type = AV_CODEC_ID_PCM_S16LE;\n\n            else\n\n                s->audio_type = AV_CODEC_ID_PCM_U8;\n\n            av_log(s->avf, AV_LOG_TRACE, \"audio: %d bits, %d Hz, %s, %s format\\n\",\n\n                    s->audio_bits, s->audio_sample_rate,\n\n                    (s->audio_channels == 2) ? \"stereo\" : \"mono\",\n\n                    (s->audio_type == AV_CODEC_ID_INTERPLAY_DPCM) ?\n\n                    \"Interplay audio\" : \"PCM\");\n\n            break;\n\n\n\n        case OPCODE_START_STOP_AUDIO:\n\n            av_log(s->avf, AV_LOG_TRACE, \"start/stop audio\\n\");\n\n            avio_skip(pb, opcode_size);\n\n            break;\n\n\n\n        case OPCODE_INIT_VIDEO_BUFFERS:\n\n            av_log(s->avf, AV_LOG_TRACE, \"initialize video buffers\\n\");\n\n            if ((opcode_version > 2) || (opcode_size > 8) || opcode_size < 4\n\n                || opcode_version == 2 && opcode_size < 8\n\n            ) {\n\n                av_log(s->avf, AV_LOG_TRACE, \"bad init_video_buffers opcode\\n\");\n\n                chunk_type = CHUNK_BAD;\n\n                break;\n\n            }\n\n            if (avio_read(pb, scratch, opcode_size) !=\n\n                opcode_size) {\n\n                chunk_type = CHUNK_BAD;\n\n                break;\n\n            }\n\n            width  = AV_RL16(&scratch[0]) * 8;\n\n            height = AV_RL16(&scratch[2]) * 8;\n\n            if (width != s->video_width) {\n\n                s->video_width = width;\n\n                s->changed++;\n\n            }\n\n            if (height != s->video_height) {\n\n                s->video_height = height;\n\n                s->changed++;\n\n            }\n\n            if (opcode_version < 2 || !AV_RL16(&scratch[6])) {\n\n                s->video_bpp = 8;\n\n            } else {\n\n                s->video_bpp = 16;\n\n            }\n\n            av_log(s->avf, AV_LOG_TRACE, \"video resolution: %d x %d\\n\",\n\n                    s->video_width, s->video_height);\n\n            break;\n\n\n\n        case OPCODE_UNKNOWN_06:\n\n        case OPCODE_UNKNOWN_0E:\n\n        case OPCODE_UNKNOWN_10:\n\n        case OPCODE_UNKNOWN_12:\n\n        case OPCODE_UNKNOWN_13:\n\n        case OPCODE_UNKNOWN_14:\n\n        case OPCODE_UNKNOWN_15:\n\n            av_log(s->avf, AV_LOG_TRACE, \"unknown (but documented) opcode %02X\\n\", opcode_type);\n\n            avio_skip(pb, opcode_size);\n\n            break;\n\n\n\n        case OPCODE_SEND_BUFFER:\n\n            av_log(s->avf, AV_LOG_TRACE, \"send buffer\\n\");\n\n            avio_skip(pb, opcode_size);\n\n            s->send_buffer = 1;\n\n            break;\n\n\n\n        case OPCODE_AUDIO_FRAME:\n\n            av_log(s->avf, AV_LOG_TRACE, \"audio frame\\n\");\n\n\n\n            /* log position and move on for now */\n\n            s->audio_chunk_offset = avio_tell(pb);\n\n            s->audio_chunk_size = opcode_size;\n\n            avio_skip(pb, opcode_size);\n\n            break;\n\n\n\n        case OPCODE_SILENCE_FRAME:\n\n            av_log(s->avf, AV_LOG_TRACE, \"silence frame\\n\");\n\n            avio_skip(pb, opcode_size);\n\n            break;\n\n\n\n        case OPCODE_INIT_VIDEO_MODE:\n\n            av_log(s->avf, AV_LOG_TRACE, \"initialize video mode\\n\");\n\n            avio_skip(pb, opcode_size);\n\n            break;\n\n\n\n        case OPCODE_CREATE_GRADIENT:\n\n            av_log(s->avf, AV_LOG_TRACE, \"create gradient\\n\");\n\n            avio_skip(pb, opcode_size);\n\n            break;\n\n\n\n        case OPCODE_SET_PALETTE:\n\n            av_log(s->avf, AV_LOG_TRACE, \"set palette\\n\");\n\n            /* check for the logical maximum palette size\n\n             * (3 * 256 + 4 bytes) */\n\n            if (opcode_size > 0x304 || opcode_size < 4) {\n\n                av_log(s->avf, AV_LOG_TRACE, \"demux_ipmovie: set_palette opcode with invalid size\\n\");\n\n                chunk_type = CHUNK_BAD;\n\n                break;\n\n            }\n\n            if (avio_read(pb, scratch, opcode_size) != opcode_size) {\n\n                chunk_type = CHUNK_BAD;\n\n                break;\n\n            }\n\n\n\n            /* load the palette into internal data structure */\n\n            first_color = AV_RL16(&scratch[0]);\n\n            last_color = first_color + AV_RL16(&scratch[2]) - 1;\n\n            /* sanity check (since they are 16 bit values) */\n\n            if (   (first_color > 0xFF) || (last_color > 0xFF)\n\n                || (last_color - first_color + 1)*3 + 4 > opcode_size) {\n\n                av_log(s->avf, AV_LOG_TRACE, \"demux_ipmovie: set_palette indexes out of range (%d -> %d)\\n\",\n\n                    first_color, last_color);\n\n                chunk_type = CHUNK_BAD;\n\n                break;\n\n            }\n\n            j = 4;  /* offset of first palette data */\n\n            for (i = first_color; i <= last_color; i++) {\n\n                /* the palette is stored as a 6-bit VGA palette, thus each\n\n                 * component is shifted up to a 8-bit range */\n\n                r = scratch[j++] * 4;\n\n                g = scratch[j++] * 4;\n\n                b = scratch[j++] * 4;\n\n                s->palette[i] = (0xFFU << 24) | (r << 16) | (g << 8) | (b);\n\n                s->palette[i] |= s->palette[i] >> 6 & 0x30303;\n\n            }\n\n            s->has_palette = 1;\n\n            break;\n\n\n\n        case OPCODE_SET_PALETTE_COMPRESSED:\n\n            av_log(s->avf, AV_LOG_TRACE, \"set palette compressed\\n\");\n\n            avio_skip(pb, opcode_size);\n\n            break;\n\n\n\n        case OPCODE_SET_DECODING_MAP:\n\n            av_log(s->avf, AV_LOG_TRACE, \"set decoding map\\n\");\n\n\n\n            /* log position and move on for now */\n\n            s->decode_map_chunk_offset = avio_tell(pb);\n\n            s->decode_map_chunk_size = opcode_size;\n\n            avio_skip(pb, opcode_size);\n\n            break;\n\n\n\n        case OPCODE_VIDEO_DATA_11:\n\n            av_log(s->avf, AV_LOG_TRACE, \"set video data\\n\");\n\n            s->frame_format = 0x11;\n\n\n\n            /* log position and move on for now */\n\n            s->video_chunk_offset = avio_tell(pb);\n\n            s->video_chunk_size = opcode_size;\n\n            avio_skip(pb, opcode_size);\n\n            break;\n\n\n\n        default:\n\n            av_log(s->avf, AV_LOG_TRACE, \"*** unknown opcode type\\n\");\n\n            chunk_type = CHUNK_BAD;\n\n            break;\n\n\n\n        }\n\n    }\n\n\n\n    if (s->avf->nb_streams == 1 && s->audio_type)\n\n        init_audio(s->avf);\n\n\n\n    /* make a note of where the stream is sitting */\n\n    s->next_chunk_offset = avio_tell(pb);\n\n\n\n    /* dispatch the first of any pending packets */\n\n    if ((chunk_type == CHUNK_VIDEO) || (chunk_type == CHUNK_AUDIO_ONLY))\n\n        chunk_type = load_ipmovie_packet(s, pb, pkt);\n\n\n\n    return chunk_type;\n\n}\n", "idx": 23836}
{"project": "FFmpeg", "commit_id": "7efabffc2899b76688a40b4bd7c63370eb2d8ca8", "target": 1, "func": "static OutputStream *new_video_stream(OptionsContext *o, AVFormatContext *oc, int source_index)\n\n{\n\n    AVStream *st;\n\n    OutputStream *ost;\n\n    AVCodecContext *video_enc;\n\n    char *frame_rate = NULL, *frame_aspect_ratio = NULL;\n\n\n\n    ost = new_output_stream(o, oc, AVMEDIA_TYPE_VIDEO, source_index);\n\n    st  = ost->st;\n\n    video_enc = ost->enc_ctx;\n\n\n\n    MATCH_PER_STREAM_OPT(frame_rates, str, frame_rate, oc, st);\n\n    if (frame_rate && av_parse_video_rate(&ost->frame_rate, frame_rate) < 0) {\n\n        av_log(NULL, AV_LOG_FATAL, \"Invalid framerate value: %s\\n\", frame_rate);\n\n        exit_program(1);\n\n    }\n\n    if (frame_rate && video_sync_method == VSYNC_PASSTHROUGH)\n\n        av_log(NULL, AV_LOG_ERROR, \"Using -vsync 0 and -r can produce invalid output files\\n\");\n\n\n\n    MATCH_PER_STREAM_OPT(frame_aspect_ratios, str, frame_aspect_ratio, oc, st);\n\n    if (frame_aspect_ratio) {\n\n        AVRational q;\n\n        if (av_parse_ratio(&q, frame_aspect_ratio, 255, 0, NULL) < 0 ||\n\n            q.num <= 0 || q.den <= 0) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Invalid aspect ratio: %s\\n\", frame_aspect_ratio);\n\n            exit_program(1);\n\n        }\n\n        ost->frame_aspect_ratio = q;\n\n    }\n\n\n\n    MATCH_PER_STREAM_OPT(filter_scripts, str, ost->filters_script, oc, st);\n\n    MATCH_PER_STREAM_OPT(filters,        str, ost->filters,        oc, st);\n\n\n\n    if (!ost->stream_copy) {\n\n        const char *p = NULL;\n\n        char *frame_size = NULL;\n\n        char *frame_pix_fmt = NULL;\n\n        char *intra_matrix = NULL, *inter_matrix = NULL;\n\n        char *chroma_intra_matrix = NULL;\n\n        int do_pass = 0;\n\n        int i;\n\n\n\n        MATCH_PER_STREAM_OPT(frame_sizes, str, frame_size, oc, st);\n\n        if (frame_size && av_parse_video_size(&video_enc->width, &video_enc->height, frame_size) < 0) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Invalid frame size: %s.\\n\", frame_size);\n\n            exit_program(1);\n\n        }\n\n\n\n        video_enc->bits_per_raw_sample = frame_bits_per_raw_sample;\n\n        MATCH_PER_STREAM_OPT(frame_pix_fmts, str, frame_pix_fmt, oc, st);\n\n        if (frame_pix_fmt && *frame_pix_fmt == '+') {\n\n            ost->keep_pix_fmt = 1;\n\n            if (!*++frame_pix_fmt)\n\n                frame_pix_fmt = NULL;\n\n        }\n\n        if (frame_pix_fmt && (video_enc->pix_fmt = av_get_pix_fmt(frame_pix_fmt)) == AV_PIX_FMT_NONE) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Unknown pixel format requested: %s.\\n\", frame_pix_fmt);\n\n            exit_program(1);\n\n        }\n\n        st->sample_aspect_ratio = video_enc->sample_aspect_ratio;\n\n\n\n        if (intra_only)\n\n            video_enc->gop_size = 0;\n\n        MATCH_PER_STREAM_OPT(intra_matrices, str, intra_matrix, oc, st);\n\n        if (intra_matrix) {\n\n            if (!(video_enc->intra_matrix = av_mallocz(sizeof(*video_enc->intra_matrix) * 64))) {\n\n                av_log(NULL, AV_LOG_FATAL, \"Could not allocate memory for intra matrix.\\n\");\n\n                exit_program(1);\n\n            }\n\n            parse_matrix_coeffs(video_enc->intra_matrix, intra_matrix);\n\n        }\n\n        MATCH_PER_STREAM_OPT(chroma_intra_matrices, str, chroma_intra_matrix, oc, st);\n\n        if (chroma_intra_matrix) {\n\n            uint16_t *p = av_mallocz(sizeof(*video_enc->chroma_intra_matrix) * 64);\n\n            if (!p) {\n\n                av_log(NULL, AV_LOG_FATAL, \"Could not allocate memory for intra matrix.\\n\");\n\n                exit_program(1);\n\n            }\n\n            av_codec_set_chroma_intra_matrix(video_enc, p);\n\n            parse_matrix_coeffs(p, chroma_intra_matrix);\n\n        }\n\n        MATCH_PER_STREAM_OPT(inter_matrices, str, inter_matrix, oc, st);\n\n        if (inter_matrix) {\n\n            if (!(video_enc->inter_matrix = av_mallocz(sizeof(*video_enc->inter_matrix) * 64))) {\n\n                av_log(NULL, AV_LOG_FATAL, \"Could not allocate memory for inter matrix.\\n\");\n\n                exit_program(1);\n\n            }\n\n            parse_matrix_coeffs(video_enc->inter_matrix, inter_matrix);\n\n        }\n\n\n\n        MATCH_PER_STREAM_OPT(rc_overrides, str, p, oc, st);\n\n        for (i = 0; p; i++) {\n\n            int start, end, q;\n\n            int e = sscanf(p, \"%d,%d,%d\", &start, &end, &q);\n\n            if (e != 3) {\n\n                av_log(NULL, AV_LOG_FATAL, \"error parsing rc_override\\n\");\n\n                exit_program(1);\n\n            }\n\n            /* FIXME realloc failure */\n\n            video_enc->rc_override =\n\n                av_realloc_array(video_enc->rc_override,\n\n                                 i + 1, sizeof(RcOverride));\n\n            video_enc->rc_override[i].start_frame = start;\n\n            video_enc->rc_override[i].end_frame   = end;\n\n            if (q > 0) {\n\n                video_enc->rc_override[i].qscale         = q;\n\n                video_enc->rc_override[i].quality_factor = 1.0;\n\n            }\n\n            else {\n\n                video_enc->rc_override[i].qscale         = 0;\n\n                video_enc->rc_override[i].quality_factor = -q/100.0;\n\n            }\n\n            p = strchr(p, '/');\n\n            if (p) p++;\n\n        }\n\n        video_enc->rc_override_count = i;\n\n\n\n        if (do_psnr)\n\n            video_enc->flags|= CODEC_FLAG_PSNR;\n\n\n\n        /* two pass mode */\n\n        MATCH_PER_STREAM_OPT(pass, i, do_pass, oc, st);\n\n        if (do_pass) {\n\n            if (do_pass & 1) {\n\n                video_enc->flags |= CODEC_FLAG_PASS1;\n\n                av_dict_set(&ost->encoder_opts, \"flags\", \"+pass1\", AV_DICT_APPEND);\n\n            }\n\n            if (do_pass & 2) {\n\n                video_enc->flags |= CODEC_FLAG_PASS2;\n\n                av_dict_set(&ost->encoder_opts, \"flags\", \"+pass2\", AV_DICT_APPEND);\n\n            }\n\n        }\n\n\n\n        MATCH_PER_STREAM_OPT(passlogfiles, str, ost->logfile_prefix, oc, st);\n\n        if (ost->logfile_prefix &&\n\n            !(ost->logfile_prefix = av_strdup(ost->logfile_prefix)))\n\n            exit_program(1);\n\n\n\n        MATCH_PER_STREAM_OPT(forced_key_frames, str, ost->forced_keyframes, oc, st);\n\n        if (ost->forced_keyframes)\n\n            ost->forced_keyframes = av_strdup(ost->forced_keyframes);\n\n\n\n        MATCH_PER_STREAM_OPT(force_fps, i, ost->force_fps, oc, st);\n\n\n\n        ost->top_field_first = -1;\n\n        MATCH_PER_STREAM_OPT(top_field_first, i, ost->top_field_first, oc, st);\n\n\n\n\n\n        ost->avfilter = get_ost_filters(o, oc, ost);\n\n        if (!ost->avfilter)\n\n            exit_program(1);\n\n    } else {\n\n        MATCH_PER_STREAM_OPT(copy_initial_nonkeyframes, i, ost->copy_initial_nonkeyframes, oc ,st);\n\n    }\n\n\n\n    if (ost->stream_copy)\n\n        check_streamcopy_filters(o, oc, ost, AVMEDIA_TYPE_VIDEO);\n\n\n\n    return ost;\n\n}\n", "idx": 23837}
{"project": "FFmpeg", "commit_id": "a04c2c707de2ce850f79870e84ac9d7ec7aa9143", "target": 1, "func": "int av_lockmgr_register(int (*cb)(void **mutex, enum AVLockOp op))\n\n{\n\n    if (lockmgr_cb) {\n\n        // There is no good way to rollback a failure to destroy the\n\n        // mutex, so we ignore failures.\n\n        lockmgr_cb(&codec_mutex,    AV_LOCK_DESTROY);\n\n        lockmgr_cb(&avformat_mutex, AV_LOCK_DESTROY);\n\n        lockmgr_cb     = NULL;\n\n        codec_mutex    = NULL;\n\n        avformat_mutex = NULL;\n\n    }\n\n\n\n    if (cb) {\n\n        void *new_codec_mutex    = NULL;\n\n        void *new_avformat_mutex = NULL;\n\n        int err;\n\n        if (err = cb(&new_codec_mutex, AV_LOCK_CREATE)) {\n\n            return err > 0 ? AVERROR_UNKNOWN : err;\n\n        }\n\n        if (err = cb(&new_avformat_mutex, AV_LOCK_CREATE)) {\n\n            // Ignore failures to destroy the newly created mutex.\n\n            cb(&new_codec_mutex, AV_LOCK_DESTROY);\n\n            return err > 0 ? AVERROR_UNKNOWN : err;\n\n        }\n\n        lockmgr_cb     = cb;\n\n        codec_mutex    = new_codec_mutex;\n\n        avformat_mutex = new_avformat_mutex;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23843}
{"project": "FFmpeg", "commit_id": "b15818642b4e8c4ea61bf93bc6920e71a834a535", "target": 1, "func": "static void compute_stereo(MPADecodeContext *s, GranuleDef *g0, GranuleDef *g1)\n\n{\n\n    int i, j, k, l;\n\n    int sf_max, sf, len, non_zero_found;\n\n    INTFLOAT (*is_tab)[16], *tab0, *tab1, tmp0, tmp1, v1, v2;\n\n    int non_zero_found_short[3];\n\n\n\n    /* intensity stereo */\n\n    if (s->mode_ext & MODE_EXT_I_STEREO) {\n\n        if (!s->lsf) {\n\n            is_tab = is_table;\n\n            sf_max = 7;\n\n        } else {\n\n            is_tab = is_table_lsf[g1->scalefac_compress & 1];\n\n            sf_max = 16;\n\n        }\n\n\n\n        tab0 = g0->sb_hybrid + 576;\n\n        tab1 = g1->sb_hybrid + 576;\n\n\n\n        non_zero_found_short[0] = 0;\n\n        non_zero_found_short[1] = 0;\n\n        non_zero_found_short[2] = 0;\n\n        k = (13 - g1->short_start) * 3 + g1->long_end - 3;\n\n        for (i = 12; i >= g1->short_start; i--) {\n\n            /* for last band, use previous scale factor */\n\n            if (i != 11)\n\n                k -= 3;\n\n            len = band_size_short[s->sample_rate_index][i];\n\n            for (l = 2; l >= 0; l--) {\n\n                tab0 -= len;\n\n                tab1 -= len;\n\n                if (!non_zero_found_short[l]) {\n\n                    /* test if non zero band. if so, stop doing i-stereo */\n\n                    for (j = 0; j < len; j++) {\n\n                        if (tab1[j] != 0) {\n\n                            non_zero_found_short[l] = 1;\n\n                            goto found1;\n\n                        }\n\n                    }\n\n                    sf = g1->scale_factors[k + l];\n\n                    if (sf >= sf_max)\n\n                        goto found1;\n\n\n\n                    v1 = is_tab[0][sf];\n\n                    v2 = is_tab[1][sf];\n\n                    for (j = 0; j < len; j++) {\n\n                        tmp0    = tab0[j];\n\n                        tab0[j] = MULLx(tmp0, v1, FRAC_BITS);\n\n                        tab1[j] = MULLx(tmp0, v2, FRAC_BITS);\n\n                    }\n\n                } else {\n\nfound1:\n\n                    if (s->mode_ext & MODE_EXT_MS_STEREO) {\n\n                        /* lower part of the spectrum : do ms stereo\n\n                           if enabled */\n\n                        for (j = 0; j < len; j++) {\n\n                            tmp0    = tab0[j];\n\n                            tmp1    = tab1[j];\n\n                            tab0[j] = MULLx(tmp0 + tmp1, ISQRT2, FRAC_BITS);\n\n                            tab1[j] = MULLx(tmp0 - tmp1, ISQRT2, FRAC_BITS);\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n\n\n        non_zero_found = non_zero_found_short[0] |\n\n                         non_zero_found_short[1] |\n\n                         non_zero_found_short[2];\n\n\n\n        for (i = g1->long_end - 1;i >= 0;i--) {\n\n            len   = band_size_long[s->sample_rate_index][i];\n\n            tab0 -= len;\n\n            tab1 -= len;\n\n            /* test if non zero band. if so, stop doing i-stereo */\n\n            if (!non_zero_found) {\n\n                for (j = 0; j < len; j++) {\n\n                    if (tab1[j] != 0) {\n\n                        non_zero_found = 1;\n\n                        goto found2;\n\n                    }\n\n                }\n\n                /* for last band, use previous scale factor */\n\n                k  = (i == 21) ? 20 : i;\n\n                sf = g1->scale_factors[k];\n\n                if (sf >= sf_max)\n\n                    goto found2;\n\n                v1 = is_tab[0][sf];\n\n                v2 = is_tab[1][sf];\n\n                for (j = 0; j < len; j++) {\n\n                    tmp0    = tab0[j];\n\n                    tab0[j] = MULLx(tmp0, v1, FRAC_BITS);\n\n                    tab1[j] = MULLx(tmp0, v2, FRAC_BITS);\n\n                }\n\n            } else {\n\nfound2:\n\n                if (s->mode_ext & MODE_EXT_MS_STEREO) {\n\n                    /* lower part of the spectrum : do ms stereo\n\n                       if enabled */\n\n                    for (j = 0; j < len; j++) {\n\n                        tmp0    = tab0[j];\n\n                        tmp1    = tab1[j];\n\n                        tab0[j] = MULLx(tmp0 + tmp1, ISQRT2, FRAC_BITS);\n\n                        tab1[j] = MULLx(tmp0 - tmp1, ISQRT2, FRAC_BITS);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    } else if (s->mode_ext & MODE_EXT_MS_STEREO) {\n\n        /* ms stereo ONLY */\n\n        /* NOTE: the 1/sqrt(2) normalization factor is included in the\n\n           global gain */\n\n#if USE_FLOATS\n\n       s->fdsp->butterflies_float(g0->sb_hybrid, g1->sb_hybrid, 576);\n\n#else\n\n        tab0 = g0->sb_hybrid;\n\n        tab1 = g1->sb_hybrid;\n\n        for (i = 0; i < 576; i++) {\n\n            tmp0    = tab0[i];\n\n            tmp1    = tab1[i];\n\n            tab0[i] = tmp0 + tmp1;\n\n            tab1[i] = tmp0 - tmp1;\n\n        }\n\n#endif\n\n    }\n\n}\n", "idx": 23844}
{"project": "FFmpeg", "commit_id": "f1e173049ecc9de03817385ba8962d14cba779db", "target": 0, "func": "static void dequantization_int(int x, int y, Jpeg2000Cblk *cblk,\n\n                               Jpeg2000Component *comp,\n\n                               Jpeg2000T1Context *t1, Jpeg2000Band *band)\n\n{\n\n    int i, j;\n\n    int w = cblk->coord[0][1] - cblk->coord[0][0];\n\n    for (j = 0; j < (cblk->coord[1][1] - cblk->coord[1][0]); ++j) {\n\n        int32_t *datap = &comp->i_data[(comp->coord[0][1] - comp->coord[0][0]) * (y + j) + x];\n\n        int *src = t1->data[j];\n\n        if (band->i_stepsize == 16384) {\n\n            for (i = 0; i < w; ++i)\n\n                datap[i] = src[i] / 2;\n\n        } else {\n\n            // This should be VERY uncommon\n\n            for (i = 0; i < w; ++i)\n\n                datap[i] = (src[i] * (int64_t)band->i_stepsize) / 32768;\n\n        }\n\n    }\n\n}\n", "idx": 23854}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int gxf_probe(AVProbeData *p) {\n\n    static const uint8_t startcode[] = {0, 0, 0, 0, 1, 0xbc}; // start with map packet\n\n    static const uint8_t endcode[] = {0, 0, 0, 0, 0xe1, 0xe2};\n\n    if (p->buf_size < 16)\n\n        return 0;\n\n    if (!memcmp(p->buf, startcode, sizeof(startcode)) &&\n\n        !memcmp(&p->buf[16 - sizeof(endcode)], endcode, sizeof(endcode)))\n\n        return AVPROBE_SCORE_MAX;\n\n    return 0;\n\n}\n", "idx": 23865}
{"project": "FFmpeg", "commit_id": "80a5d05108cb218e8cd2e25c6621a3bfef0a832e", "target": 0, "func": "static int vaapi_encode_h265_init_sequence_params(AVCodecContext *avctx)\n\n{\n\n    VAAPIEncodeContext                 *ctx = avctx->priv_data;\n\n    VAEncSequenceParameterBufferHEVC  *vseq = ctx->codec_sequence_params;\n\n    VAEncPictureParameterBufferHEVC   *vpic = ctx->codec_picture_params;\n\n    VAAPIEncodeH265Context            *priv = ctx->priv_data;\n\n    VAAPIEncodeH265MiscSequenceParams *mseq = &priv->misc_sequence_params;\n\n    int i;\n\n\n\n    {\n\n        // general_profile_space == 0.\n\n        vseq->general_profile_idc = 1; // Main profile (ctx->codec_profile?)\n\n        vseq->general_tier_flag = 0;\n\n\n\n        vseq->general_level_idc = avctx->level * 3;\n\n\n\n        vseq->intra_period = 0;\n\n        vseq->intra_idr_period = 0;\n\n        vseq->ip_period = 0;\n\n\n\n        vseq->pic_width_in_luma_samples  = ctx->aligned_width;\n\n        vseq->pic_height_in_luma_samples = ctx->aligned_height;\n\n\n\n        vseq->seq_fields.bits.chroma_format_idc = 1; // 4:2:0.\n\n        vseq->seq_fields.bits.separate_colour_plane_flag = 0;\n\n        vseq->seq_fields.bits.bit_depth_luma_minus8 = 0; // 8-bit luma.\n\n        vseq->seq_fields.bits.bit_depth_chroma_minus8 = 0; // 8-bit chroma.\n\n        // Other misc flags all zero.\n\n\n\n        // These have to come from the capabilities of the encoder.  We have\n\n        // no way to query it, so just hardcode ones which worked for me...\n\n        // CTB size from 8x8 to 32x32.\n\n        vseq->log2_min_luma_coding_block_size_minus3 = 0;\n\n        vseq->log2_diff_max_min_luma_coding_block_size = 2;\n\n        // Transform size from 4x4 to 32x32.\n\n        vseq->log2_min_transform_block_size_minus2 = 0;\n\n        vseq->log2_diff_max_min_transform_block_size = 3;\n\n        // Full transform hierarchy allowed (2-5).\n\n        vseq->max_transform_hierarchy_depth_inter = 3;\n\n        vseq->max_transform_hierarchy_depth_intra = 3;\n\n\n\n        vseq->vui_parameters_present_flag = 0;\n\n\n\n        vseq->bits_per_second = avctx->bit_rate;\n\n        if (avctx->framerate.num > 0 && avctx->framerate.den > 0) {\n\n            vseq->vui_num_units_in_tick = avctx->framerate.num;\n\n            vseq->vui_time_scale        = avctx->framerate.den;\n\n        } else {\n\n            vseq->vui_num_units_in_tick = avctx->time_base.num;\n\n            vseq->vui_time_scale        = avctx->time_base.den;\n\n        }\n\n\n\n        vseq->intra_period     = ctx->p_per_i * (ctx->b_per_p + 1);\n\n        vseq->intra_idr_period = vseq->intra_period;\n\n        vseq->ip_period        = ctx->b_per_p + 1;\n\n    }\n\n\n\n    {\n\n        vpic->decoded_curr_pic.picture_id = VA_INVALID_ID;\n\n        vpic->decoded_curr_pic.flags      = VA_PICTURE_HEVC_INVALID;\n\n\n\n        for (i = 0; i < FF_ARRAY_ELEMS(vpic->reference_frames); i++) {\n\n            vpic->reference_frames[i].picture_id = VA_INVALID_ID;\n\n            vpic->reference_frames[i].flags      = VA_PICTURE_HEVC_INVALID;\n\n        }\n\n\n\n        vpic->collocated_ref_pic_index = 0xff;\n\n\n\n        vpic->last_picture = 0;\n\n\n\n        vpic->pic_init_qp = priv->fixed_qp_idr;\n\n\n\n        vpic->diff_cu_qp_delta_depth = 0;\n\n        vpic->pps_cb_qp_offset = 0;\n\n        vpic->pps_cr_qp_offset = 0;\n\n\n\n        // tiles_enabled_flag == 0, so ignore num_tile_(rows|columns)_minus1.\n\n\n\n        vpic->log2_parallel_merge_level_minus2 = 0;\n\n\n\n        // No limit on size.\n\n        vpic->ctu_max_bitsize_allowed = 0;\n\n\n\n        vpic->num_ref_idx_l0_default_active_minus1 = 0;\n\n        vpic->num_ref_idx_l1_default_active_minus1 = 0;\n\n\n\n        vpic->slice_pic_parameter_set_id = 0;\n\n\n\n        vpic->pic_fields.bits.screen_content_flag = 0;\n\n        vpic->pic_fields.bits.enable_gpu_weighted_prediction = 0;\n\n\n\n        // Per-CU QP changes are required for non-constant-QP modes.\n\n        vpic->pic_fields.bits.cu_qp_delta_enabled_flag =\n\n            ctx->va_rc_mode != VA_RC_CQP;\n\n    }\n\n\n\n    {\n\n        mseq->video_parameter_set_id = 5;\n\n        mseq->seq_parameter_set_id = 5;\n\n\n\n        mseq->vps_max_layers_minus1 = 0;\n\n        mseq->vps_max_sub_layers_minus1 = 0;\n\n        mseq->vps_temporal_id_nesting_flag = 1;\n\n        mseq->sps_max_sub_layers_minus1 = 0;\n\n        mseq->sps_temporal_id_nesting_flag = 1;\n\n\n\n        for (i = 0; i < 32; i++) {\n\n            mseq->general_profile_compatibility_flag[i] =\n\n                (i == vseq->general_profile_idc);\n\n        }\n\n\n\n        mseq->general_progressive_source_flag    = 1;\n\n        mseq->general_interlaced_source_flag     = 0;\n\n        mseq->general_non_packed_constraint_flag = 0;\n\n        mseq->general_frame_only_constraint_flag = 1;\n\n        mseq->general_inbld_flag = 0;\n\n\n\n        mseq->log2_max_pic_order_cnt_lsb_minus4 = 8;\n\n        mseq->vps_sub_layer_ordering_info_present_flag = 0;\n\n        mseq->vps_max_dec_pic_buffering_minus1[0] = 1;\n\n        mseq->vps_max_num_reorder_pics[0]         = ctx->b_per_p;\n\n        mseq->vps_max_latency_increase_plus1[0]   = 0;\n\n        mseq->sps_sub_layer_ordering_info_present_flag = 0;\n\n        mseq->sps_max_dec_pic_buffering_minus1[0] = 1;\n\n        mseq->sps_max_num_reorder_pics[0]         = ctx->b_per_p;\n\n        mseq->sps_max_latency_increase_plus1[0]   = 0;\n\n\n\n        mseq->vps_timing_info_present_flag = 1;\n\n        mseq->vps_num_units_in_tick = avctx->time_base.num;\n\n        mseq->vps_time_scale        = avctx->time_base.den;\n\n        mseq->vps_poc_proportional_to_timing_flag = 1;\n\n        mseq->vps_num_ticks_poc_diff_minus1 = 0;\n\n\n\n        if (ctx->input_width  != ctx->aligned_width ||\n\n            ctx->input_height != ctx->aligned_height) {\n\n            mseq->conformance_window_flag = 1;\n\n            mseq->conf_win_left_offset   = 0;\n\n            mseq->conf_win_right_offset  =\n\n                (ctx->aligned_width - ctx->input_width) / 2;\n\n            mseq->conf_win_top_offset    = 0;\n\n            mseq->conf_win_bottom_offset =\n\n                (ctx->aligned_height - ctx->input_height) / 2;\n\n        } else {\n\n            mseq->conformance_window_flag = 0;\n\n        }\n\n\n\n        mseq->num_short_term_ref_pic_sets = 0;\n\n        // STRPSs should ideally be here rather than repeated in each slice.\n\n\n\n        mseq->vui_parameters_present_flag = 1;\n\n        if (avctx->sample_aspect_ratio.num != 0) {\n\n            mseq->aspect_ratio_info_present_flag = 1;\n\n            if (avctx->sample_aspect_ratio.num ==\n\n                avctx->sample_aspect_ratio.den) {\n\n                mseq->aspect_ratio_idc = 1;\n\n            } else {\n\n                mseq->aspect_ratio_idc = 255; // Extended SAR.\n\n                mseq->sar_width  = avctx->sample_aspect_ratio.num;\n\n                mseq->sar_height = avctx->sample_aspect_ratio.den;\n\n            }\n\n        }\n\n        if (1) {\n\n            // Should this be conditional on some of these being set?\n\n            mseq->video_signal_type_present_flag = 1;\n\n            mseq->video_format = 5; // Unspecified.\n\n            mseq->video_full_range_flag = 0;\n\n            mseq->colour_description_present_flag = 1;\n\n            mseq->colour_primaries = avctx->color_primaries;\n\n            mseq->transfer_characteristics = avctx->color_trc;\n\n            mseq->matrix_coeffs = avctx->colorspace;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23870}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "int ff_h264_decode_mb_cabac(const H264Context *h, H264SliceContext *sl)\n\n{\n\n    int mb_xy;\n\n    int mb_type, partition_count, cbp = 0;\n\n    int dct8x8_allowed= h->pps.transform_8x8_mode;\n\n    int decode_chroma = h->sps.chroma_format_idc == 1 || h->sps.chroma_format_idc == 2;\n\n    const int pixel_shift = h->pixel_shift;\n\n\n\n    mb_xy = sl->mb_xy = sl->mb_x + sl->mb_y*h->mb_stride;\n\n\n\n    ff_tlog(h->avctx, \"pic:%d mb:%d/%d\\n\", h->frame_num, sl->mb_x, sl->mb_y);\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n        int skip;\n\n        /* a skipped mb needs the aff flag from the following mb */\n\n        if (FRAME_MBAFF(h) && (sl->mb_y & 1) == 1 && sl->prev_mb_skipped)\n\n            skip = sl->next_mb_skipped;\n\n        else\n\n            skip = decode_cabac_mb_skip(h, sl, sl->mb_x, sl->mb_y );\n\n        /* read skip flags */\n\n        if( skip ) {\n\n            if (FRAME_MBAFF(h) && (sl->mb_y & 1) == 0) {\n\n                h->cur_pic.mb_type[mb_xy] = MB_TYPE_SKIP;\n\n                sl->next_mb_skipped = decode_cabac_mb_skip(h, sl, sl->mb_x, sl->mb_y+1 );\n\n                if(!sl->next_mb_skipped)\n\n                    sl->mb_mbaff = sl->mb_field_decoding_flag = decode_cabac_field_decoding_flag(h, sl);\n\n            }\n\n\n\n            decode_mb_skip(h, sl);\n\n\n\n            h->cbp_table[mb_xy] = 0;\n\n            h->chroma_pred_mode_table[mb_xy] = 0;\n\n            sl->last_qscale_diff = 0;\n\n\n\n            return 0;\n\n\n\n        }\n\n    }\n\n    if (FRAME_MBAFF(h)) {\n\n        if ((sl->mb_y & 1) == 0)\n\n            sl->mb_mbaff =\n\n            sl->mb_field_decoding_flag = decode_cabac_field_decoding_flag(h, sl);\n\n    }\n\n\n\n    sl->prev_mb_skipped = 0;\n\n\n\n    fill_decode_neighbors(h, sl, -(MB_FIELD(sl)));\n\n\n\n    if (sl->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n        int ctx = 0;\n\n        assert(sl->slice_type_nos == AV_PICTURE_TYPE_B);\n\n\n\n        if (!IS_DIRECT(sl->left_type[LTOP] - 1))\n\n            ctx++;\n\n        if (!IS_DIRECT(sl->top_type - 1))\n\n            ctx++;\n\n\n\n        if( !get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+ctx] ) ){\n\n            mb_type= 0; /* B_Direct_16x16 */\n\n        }else if( !get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+3] ) ) {\n\n            mb_type= 1 + get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] ); /* B_L[01]_16x16 */\n\n        }else{\n\n            int bits;\n\n            bits = get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+4] ) << 3;\n\n            bits+= get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] ) << 2;\n\n            bits+= get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] ) << 1;\n\n            bits+= get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] );\n\n            if( bits < 8 ){\n\n                mb_type= bits + 3; /* B_Bi_16x16 through B_L1_L0_16x8 */\n\n            }else if( bits == 13 ){\n\n                mb_type = decode_cabac_intra_mb_type(sl, 32, 0);\n\n                goto decode_intra_mb;\n\n            }else if( bits == 14 ){\n\n                mb_type= 11; /* B_L1_L0_8x16 */\n\n            }else if( bits == 15 ){\n\n                mb_type= 22; /* B_8x8 */\n\n            }else{\n\n                bits= ( bits<<1 ) + get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] );\n\n                mb_type= bits - 4; /* B_L0_Bi_* through B_Bi_Bi_* */\n\n            }\n\n        }\n\n            partition_count = ff_h264_b_mb_type_info[mb_type].partition_count;\n\n            mb_type         = ff_h264_b_mb_type_info[mb_type].type;\n\n    } else if (sl->slice_type_nos == AV_PICTURE_TYPE_P) {\n\n        if( get_cabac_noinline( &sl->cabac, &sl->cabac_state[14] ) == 0 ) {\n\n            /* P-type */\n\n            if( get_cabac_noinline( &sl->cabac, &sl->cabac_state[15] ) == 0 ) {\n\n                /* P_L0_D16x16, P_8x8 */\n\n                mb_type= 3 * get_cabac_noinline( &sl->cabac, &sl->cabac_state[16] );\n\n            } else {\n\n                /* P_L0_D8x16, P_L0_D16x8 */\n\n                mb_type= 2 - get_cabac_noinline( &sl->cabac, &sl->cabac_state[17] );\n\n            }\n\n            partition_count = ff_h264_p_mb_type_info[mb_type].partition_count;\n\n            mb_type         = ff_h264_p_mb_type_info[mb_type].type;\n\n        } else {\n\n            mb_type = decode_cabac_intra_mb_type(sl, 17, 0);\n\n            goto decode_intra_mb;\n\n        }\n\n    } else {\n\n        mb_type = decode_cabac_intra_mb_type(sl, 3, 1);\n\n        if (sl->slice_type == AV_PICTURE_TYPE_SI && mb_type)\n\n            mb_type--;\n\n        assert(sl->slice_type_nos == AV_PICTURE_TYPE_I);\n\ndecode_intra_mb:\n\n        partition_count = 0;\n\n        cbp                      = ff_h264_i_mb_type_info[mb_type].cbp;\n\n        sl->intra16x16_pred_mode = ff_h264_i_mb_type_info[mb_type].pred_mode;\n\n        mb_type                  = ff_h264_i_mb_type_info[mb_type].type;\n\n    }\n\n    if (MB_FIELD(sl))\n\n        mb_type |= MB_TYPE_INTERLACED;\n\n\n\n    h->slice_table[mb_xy] = sl->slice_num;\n\n\n\n    if(IS_INTRA_PCM(mb_type)) {\n\n        const int mb_size = ff_h264_mb_sizes[h->sps.chroma_format_idc] *\n\n                            h->sps.bit_depth_luma >> 3;\n\n        const uint8_t *ptr;\n\n\n\n        // We assume these blocks are very rare so we do not optimize it.\n\n        // FIXME The two following lines get the bitstream position in the cabac\n\n        // decode, I think it should be done by a function in cabac.h (or cabac.c).\n\n        ptr= sl->cabac.bytestream;\n\n        if(sl->cabac.low&0x1) ptr--;\n\n        if(CABAC_BITS==16){\n\n            if(sl->cabac.low&0x1FF) ptr--;\n\n        }\n\n\n\n        // The pixels are stored in the same order as levels in h->mb array.\n\n        if ((int) (sl->cabac.bytestream_end - ptr) < mb_size)\n\n            return -1;\n\n        sl->intra_pcm_ptr = ptr;\n\n        ptr += mb_size;\n\n\n\n        ff_init_cabac_decoder(&sl->cabac, ptr, sl->cabac.bytestream_end - ptr);\n\n\n\n        // All blocks are present\n\n        h->cbp_table[mb_xy] = 0xf7ef;\n\n        h->chroma_pred_mode_table[mb_xy] = 0;\n\n        // In deblocking, the quantizer is 0\n\n        h->cur_pic.qscale_table[mb_xy] = 0;\n\n        // All coeffs are present\n\n        memset(h->non_zero_count[mb_xy], 16, 48);\n\n        h->cur_pic.mb_type[mb_xy] = mb_type;\n\n        sl->last_qscale_diff = 0;\n\n        return 0;\n\n    }\n\n\n\n    fill_decode_caches(h, sl, mb_type);\n\n\n\n    if( IS_INTRA( mb_type ) ) {\n\n        int i, pred_mode;\n\n        if( IS_INTRA4x4( mb_type ) ) {\n\n            if (dct8x8_allowed && get_cabac_noinline(&sl->cabac, &sl->cabac_state[399 + sl->neighbor_transform_size])) {\n\n                mb_type |= MB_TYPE_8x8DCT;\n\n                for( i = 0; i < 16; i+=4 ) {\n\n                    int pred = pred_intra_mode(h, sl, i);\n\n                    int mode = decode_cabac_mb_intra4x4_pred_mode(sl, pred);\n\n                    fill_rectangle(&sl->intra4x4_pred_mode_cache[scan8[i]], 2, 2, 8, mode, 1);\n\n                }\n\n            } else {\n\n                for( i = 0; i < 16; i++ ) {\n\n                    int pred = pred_intra_mode(h, sl, i);\n\n                    sl->intra4x4_pred_mode_cache[scan8[i]] = decode_cabac_mb_intra4x4_pred_mode(sl, pred);\n\n\n\n                    ff_dlog(h->avctx, \"i4x4 pred=%d mode=%d\\n\", pred,\n\n                            sl->intra4x4_pred_mode_cache[scan8[i]]);\n\n                }\n\n            }\n\n            write_back_intra_pred_mode(h, sl);\n\n            if (ff_h264_check_intra4x4_pred_mode(sl->intra4x4_pred_mode_cache, h->avctx,\n\n                                                 sl->top_samples_available, sl->left_samples_available) < 0 )\n\n                return -1;\n\n        } else {\n\n            sl->intra16x16_pred_mode = ff_h264_check_intra_pred_mode(h->avctx, sl->top_samples_available,\n\n                                                                     sl->left_samples_available, sl->intra16x16_pred_mode, 0);\n\n            if (sl->intra16x16_pred_mode < 0) return -1;\n\n        }\n\n        if(decode_chroma){\n\n            h->chroma_pred_mode_table[mb_xy] =\n\n            pred_mode                        = decode_cabac_mb_chroma_pre_mode(h, sl);\n\n\n\n            pred_mode= ff_h264_check_intra_pred_mode(h->avctx, sl->top_samples_available,\n\n                                                     sl->left_samples_available, pred_mode, 1 );\n\n            if( pred_mode < 0 ) return -1;\n\n            sl->chroma_pred_mode = pred_mode;\n\n        } else {\n\n            sl->chroma_pred_mode = DC_128_PRED8x8;\n\n        }\n\n    } else if( partition_count == 4 ) {\n\n        int i, j, sub_partition_count[4], list, ref[2][4];\n\n\n\n        if (sl->slice_type_nos == AV_PICTURE_TYPE_B ) {\n\n            for( i = 0; i < 4; i++ ) {\n\n                sl->sub_mb_type[i] = decode_cabac_b_mb_sub_type(sl);\n\n                sub_partition_count[i] = ff_h264_b_sub_mb_type_info[sl->sub_mb_type[i]].partition_count;\n\n                sl->sub_mb_type[i]     = ff_h264_b_sub_mb_type_info[sl->sub_mb_type[i]].type;\n\n            }\n\n            if (IS_DIRECT(sl->sub_mb_type[0] | sl->sub_mb_type[1] |\n\n                          sl->sub_mb_type[2] | sl->sub_mb_type[3])) {\n\n                ff_h264_pred_direct_motion(h, sl, &mb_type);\n\n                sl->ref_cache[0][scan8[4]] =\n\n                sl->ref_cache[1][scan8[4]] =\n\n                sl->ref_cache[0][scan8[12]] =\n\n                sl->ref_cache[1][scan8[12]] = PART_NOT_AVAILABLE;\n\n                    for( i = 0; i < 4; i++ )\n\n                        fill_rectangle(&sl->direct_cache[scan8[4*i]], 2, 2, 8, (sl->sub_mb_type[i] >> 1) & 0xFF, 1);\n\n            }\n\n        } else {\n\n            for( i = 0; i < 4; i++ ) {\n\n                sl->sub_mb_type[i] = decode_cabac_p_mb_sub_type(sl);\n\n                sub_partition_count[i] = ff_h264_p_sub_mb_type_info[sl->sub_mb_type[i]].partition_count;\n\n                sl->sub_mb_type[i]     = ff_h264_p_sub_mb_type_info[sl->sub_mb_type[i]].type;\n\n            }\n\n        }\n\n\n\n        for( list = 0; list < sl->list_count; list++ ) {\n\n                for( i = 0; i < 4; i++ ) {\n\n                    if(IS_DIRECT(sl->sub_mb_type[i])) continue;\n\n                    if(IS_DIR(sl->sub_mb_type[i], 0, list)){\n\n                        int rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                        if (rc > 1) {\n\n                            ref[list][i] = decode_cabac_mb_ref(sl, list, 4 * i);\n\n                            if (ref[list][i] >= (unsigned) rc) {\n\n                                av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref[list][i], rc);\n\n                                return -1;\n\n                            }\n\n                        }else\n\n                            ref[list][i] = 0;\n\n                    } else {\n\n                        ref[list][i] = -1;\n\n                    }\n\n                    sl->ref_cache[list][scan8[4 * i] + 1] =\n\n                    sl->ref_cache[list][scan8[4 * i] + 8] = sl->ref_cache[list][scan8[4 * i] + 9] = ref[list][i];\n\n                }\n\n        }\n\n\n\n        if(dct8x8_allowed)\n\n            dct8x8_allowed = get_dct8x8_allowed(h, sl);\n\n\n\n        for (list = 0; list < sl->list_count; list++) {\n\n            for(i=0; i<4; i++){\n\n                sl->ref_cache[list][scan8[4 * i]] = sl->ref_cache[list][scan8[4 * i] + 1];\n\n                if(IS_DIRECT(sl->sub_mb_type[i])){\n\n                    fill_rectangle(sl->mvd_cache[list][scan8[4*i]], 2, 2, 8, 0, 2);\n\n                    continue;\n\n                }\n\n\n\n                if(IS_DIR(sl->sub_mb_type[i], 0, list) && !IS_DIRECT(sl->sub_mb_type[i])){\n\n                    const int sub_mb_type= sl->sub_mb_type[i];\n\n                    const int block_width= (sub_mb_type & (MB_TYPE_16x16|MB_TYPE_16x8)) ? 2 : 1;\n\n                    for(j=0; j<sub_partition_count[i]; j++){\n\n                        int mpx, mpy;\n\n                        int mx, my;\n\n                        const int index= 4*i + block_width*j;\n\n                        int16_t (* mv_cache)[2] = &sl->mv_cache[list][ scan8[index] ];\n\n                        uint8_t (* mvd_cache)[2]= &sl->mvd_cache[list][ scan8[index] ];\n\n                        pred_motion(h, sl, index, block_width, list, sl->ref_cache[list][ scan8[index] ], &mx, &my);\n\n                        DECODE_CABAC_MB_MVD(sl, list, index)\n\n                        ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        if(IS_SUB_8X8(sub_mb_type)){\n\n                            mv_cache[ 1 ][0]=\n\n                            mv_cache[ 8 ][0]= mv_cache[ 9 ][0]= mx;\n\n                            mv_cache[ 1 ][1]=\n\n                            mv_cache[ 8 ][1]= mv_cache[ 9 ][1]= my;\n\n\n\n                            mvd_cache[ 1 ][0]=\n\n                            mvd_cache[ 8 ][0]= mvd_cache[ 9 ][0]= mpx;\n\n                            mvd_cache[ 1 ][1]=\n\n                            mvd_cache[ 8 ][1]= mvd_cache[ 9 ][1]= mpy;\n\n                        }else if(IS_SUB_8X4(sub_mb_type)){\n\n                            mv_cache[ 1 ][0]= mx;\n\n                            mv_cache[ 1 ][1]= my;\n\n\n\n                            mvd_cache[ 1 ][0]=  mpx;\n\n                            mvd_cache[ 1 ][1]= mpy;\n\n                        }else if(IS_SUB_4X8(sub_mb_type)){\n\n                            mv_cache[ 8 ][0]= mx;\n\n                            mv_cache[ 8 ][1]= my;\n\n\n\n                            mvd_cache[ 8 ][0]= mpx;\n\n                            mvd_cache[ 8 ][1]= mpy;\n\n                        }\n\n                        mv_cache[ 0 ][0]= mx;\n\n                        mv_cache[ 0 ][1]= my;\n\n\n\n                        mvd_cache[ 0 ][0]= mpx;\n\n                        mvd_cache[ 0 ][1]= mpy;\n\n                    }\n\n                }else{\n\n                    fill_rectangle(sl->mv_cache [list][ scan8[4*i] ], 2, 2, 8, 0, 4);\n\n                    fill_rectangle(sl->mvd_cache[list][ scan8[4*i] ], 2, 2, 8, 0, 2);\n\n                }\n\n            }\n\n        }\n\n    } else if( IS_DIRECT(mb_type) ) {\n\n        ff_h264_pred_direct_motion(h, sl, &mb_type);\n\n        fill_rectangle(sl->mvd_cache[0][scan8[0]], 4, 4, 8, 0, 2);\n\n        fill_rectangle(sl->mvd_cache[1][scan8[0]], 4, 4, 8, 0, 2);\n\n        dct8x8_allowed &= h->sps.direct_8x8_inference_flag;\n\n    } else {\n\n        int list, i;\n\n        if(IS_16X16(mb_type)){\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                if(IS_DIR(mb_type, 0, list)){\n\n                    int ref, rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                    if (rc > 1) {\n\n                        ref= decode_cabac_mb_ref(sl, list, 0);\n\n                        if (ref >= (unsigned) rc) {\n\n                            av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref, rc);\n\n                            return -1;\n\n                        }\n\n                    }else\n\n                        ref=0;\n\n                    fill_rectangle(&sl->ref_cache[list][ scan8[0] ], 4, 4, 8, ref, 1);\n\n                }\n\n            }\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                if(IS_DIR(mb_type, 0, list)){\n\n                    int mx,my,mpx,mpy;\n\n                    pred_motion(h, sl, 0, 4, list, sl->ref_cache[list][ scan8[0] ], &mx, &my);\n\n                    DECODE_CABAC_MB_MVD(sl, list, 0)\n\n                    ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                    fill_rectangle(sl->mvd_cache[list][ scan8[0] ], 4, 4, 8, pack8to16(mpx,mpy), 2);\n\n                    fill_rectangle(sl->mv_cache[list][ scan8[0] ], 4, 4, 8, pack16to32(mx,my), 4);\n\n                }\n\n            }\n\n        }\n\n        else if(IS_16X8(mb_type)){\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                    for(i=0; i<2; i++){\n\n                        if(IS_DIR(mb_type, i, list)){\n\n                            int ref, rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                            if (rc > 1) {\n\n                                ref= decode_cabac_mb_ref(sl, list, 8 * i);\n\n                                if (ref >= (unsigned) rc) {\n\n                                    av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref, rc);\n\n                                    return -1;\n\n                                }\n\n                            }else\n\n                                ref=0;\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 16*i ], 4, 2, 8, ref, 1);\n\n                        }else\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 16*i ], 4, 2, 8, (LIST_NOT_USED&0xFF), 1);\n\n                    }\n\n            }\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                for(i=0; i<2; i++){\n\n                    if(IS_DIR(mb_type, i, list)){\n\n                        int mx,my,mpx,mpy;\n\n                        pred_16x8_motion(h, sl, 8*i, list, sl->ref_cache[list][scan8[0] + 16*i], &mx, &my);\n\n                        DECODE_CABAC_MB_MVD(sl, list, 8*i)\n\n                        ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 16*i ], 4, 2, 8, pack8to16(mpx,mpy), 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 16*i ], 4, 2, 8, pack16to32(mx,my), 4);\n\n                    }else{\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 16*i ], 4, 2, 8, 0, 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 16*i ], 4, 2, 8, 0, 4);\n\n                    }\n\n                }\n\n            }\n\n        }else{\n\n            assert(IS_8X16(mb_type));\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                    for(i=0; i<2; i++){\n\n                        if(IS_DIR(mb_type, i, list)){ //FIXME optimize\n\n                            int ref, rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                            if (rc > 1) {\n\n                                ref = decode_cabac_mb_ref(sl, list, 4 * i);\n\n                                if (ref >= (unsigned) rc) {\n\n                                    av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref, rc);\n\n                                    return -1;\n\n                                }\n\n                            }else\n\n                                ref=0;\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 2*i ], 2, 4, 8, ref, 1);\n\n                        }else\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 2*i ], 2, 4, 8, (LIST_NOT_USED&0xFF), 1);\n\n                    }\n\n            }\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                for(i=0; i<2; i++){\n\n                    if(IS_DIR(mb_type, i, list)){\n\n                        int mx,my,mpx,mpy;\n\n                        pred_8x16_motion(h, sl, i*4, list, sl->ref_cache[list][ scan8[0] + 2*i ], &mx, &my);\n\n                        DECODE_CABAC_MB_MVD(sl, list, 4*i)\n\n\n\n                        ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 2*i ], 2, 4, 8, pack8to16(mpx,mpy), 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 2*i ], 2, 4, 8, pack16to32(mx,my), 4);\n\n                    }else{\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 2*i ], 2, 4, 8, 0, 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 2*i ], 2, 4, 8, 0, 4);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n   if( IS_INTER( mb_type ) ) {\n\n        h->chroma_pred_mode_table[mb_xy] = 0;\n\n        write_back_motion(h, sl, mb_type);\n\n   }\n\n\n\n    if( !IS_INTRA16x16( mb_type ) ) {\n\n        cbp  = decode_cabac_mb_cbp_luma(sl);\n\n        if(decode_chroma)\n\n            cbp |= decode_cabac_mb_cbp_chroma(sl) << 4;\n\n    }\n\n\n\n    h->cbp_table[mb_xy] = sl->cbp = cbp;\n\n\n\n    if( dct8x8_allowed && (cbp&15) && !IS_INTRA( mb_type ) ) {\n\n        mb_type |= MB_TYPE_8x8DCT * get_cabac_noinline(&sl->cabac, &sl->cabac_state[399 + sl->neighbor_transform_size]);\n\n    }\n\n\n\n    /* It would be better to do this in fill_decode_caches, but we don't know\n\n     * the transform mode of the current macroblock there. */\n\n    if (CHROMA444(h) && IS_8x8DCT(mb_type)){\n\n        int i;\n\n        uint8_t *nnz_cache = sl->non_zero_count_cache;\n\n        for (i = 0; i < 2; i++){\n\n            if (sl->left_type[LEFT(i)] && !IS_8x8DCT(sl->left_type[LEFT(i)])) {\n\n                nnz_cache[3+8* 1 + 2*8*i]=\n\n                nnz_cache[3+8* 2 + 2*8*i]=\n\n                nnz_cache[3+8* 6 + 2*8*i]=\n\n                nnz_cache[3+8* 7 + 2*8*i]=\n\n                nnz_cache[3+8*11 + 2*8*i]=\n\n                nnz_cache[3+8*12 + 2*8*i]= IS_INTRA(mb_type) ? 64 : 0;\n\n            }\n\n        }\n\n        if (sl->top_type && !IS_8x8DCT(sl->top_type)){\n\n            uint32_t top_empty = CABAC(h) && !IS_INTRA(mb_type) ? 0 : 0x40404040;\n\n            AV_WN32A(&nnz_cache[4+8* 0], top_empty);\n\n            AV_WN32A(&nnz_cache[4+8* 5], top_empty);\n\n            AV_WN32A(&nnz_cache[4+8*10], top_empty);\n\n        }\n\n    }\n\n    h->cur_pic.mb_type[mb_xy] = mb_type;\n\n\n\n    if( cbp || IS_INTRA16x16( mb_type ) ) {\n\n        const uint8_t *scan, *scan8x8;\n\n        const uint32_t *qmul;\n\n\n\n        if(IS_INTERLACED(mb_type)){\n\n            scan8x8 = sl->qscale ? h->field_scan8x8 : h->field_scan8x8_q0;\n\n            scan    = sl->qscale ? h->field_scan : h->field_scan_q0;\n\n        }else{\n\n            scan8x8 = sl->qscale ? h->zigzag_scan8x8 : h->zigzag_scan8x8_q0;\n\n            scan    = sl->qscale ? h->zigzag_scan : h->zigzag_scan_q0;\n\n        }\n\n\n\n        // decode_cabac_mb_dqp\n\n        if(get_cabac_noinline( &sl->cabac, &sl->cabac_state[60 + (sl->last_qscale_diff != 0)])){\n\n            int val = 1;\n\n            int ctx= 2;\n\n            const int max_qp = 51 + 6*(h->sps.bit_depth_luma-8);\n\n\n\n            while( get_cabac_noinline( &sl->cabac, &sl->cabac_state[60 + ctx] ) ) {\n\n                ctx= 3;\n\n                val++;\n\n                if(val > 2*max_qp){ //prevent infinite loop\n\n                    av_log(h->avctx, AV_LOG_ERROR, \"cabac decode of qscale diff failed at %d %d\\n\", sl->mb_x, sl->mb_y);\n\n                    return -1;\n\n                }\n\n            }\n\n\n\n            if( val&0x01 )\n\n                val=   (val + 1)>>1 ;\n\n            else\n\n                val= -((val + 1)>>1);\n\n            sl->last_qscale_diff = val;\n\n            sl->qscale += val;\n\n            if (((unsigned)sl->qscale) > max_qp){\n\n                if (sl->qscale < 0) sl->qscale += max_qp + 1;\n\n                else                sl->qscale -= max_qp + 1;\n\n            }\n\n            sl->chroma_qp[0] = get_chroma_qp(h, 0, sl->qscale);\n\n            sl->chroma_qp[1] = get_chroma_qp(h, 1, sl->qscale);\n\n        }else\n\n            sl->last_qscale_diff=0;\n\n\n\n        decode_cabac_luma_residual(h, sl, scan, scan8x8, pixel_shift, mb_type, cbp, 0);\n\n        if (CHROMA444(h)) {\n\n            decode_cabac_luma_residual(h, sl, scan, scan8x8, pixel_shift, mb_type, cbp, 1);\n\n            decode_cabac_luma_residual(h, sl, scan, scan8x8, pixel_shift, mb_type, cbp, 2);\n\n        } else if (CHROMA422(h)) {\n\n            if( cbp&0x30 ){\n\n                int c;\n\n                for (c = 0; c < 2; c++)\n\n                    decode_cabac_residual_dc_422(h, sl, sl->mb + ((256 + 16*16*c) << pixel_shift), 3,\n\n                                                 CHROMA_DC_BLOCK_INDEX + c,\n\n                                                 ff_h264_chroma422_dc_scan, 8);\n\n            }\n\n\n\n            if( cbp&0x20 ) {\n\n                int c, i, i8x8;\n\n                for( c = 0; c < 2; c++ ) {\n\n                    int16_t *mb = sl->mb + (16*(16 + 16*c) << pixel_shift);\n\n                    qmul = h->dequant4_coeff[c+1+(IS_INTRA( mb_type ) ? 0:3)][sl->chroma_qp[c]];\n\n                    for (i8x8 = 0; i8x8 < 2; i8x8++) {\n\n                        for (i = 0; i < 4; i++) {\n\n                            const int index = 16 + 16 * c + 8*i8x8 + i;\n\n                            decode_cabac_residual_nondc(h, sl, mb, 4, index, scan + 1, qmul, 15);\n\n                            mb += 16<<pixel_shift;\n\n                        }\n\n                    }\n\n                }\n\n            } else {\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n            }\n\n        } else /* yuv420 */ {\n\n            if( cbp&0x30 ){\n\n                int c;\n\n                for (c = 0; c < 2; c++)\n\n                    decode_cabac_residual_dc(h, sl, sl->mb + ((256 + 16 * 16 * c) << pixel_shift),\n\n                                             3, CHROMA_DC_BLOCK_INDEX + c, ff_h264_chroma_dc_scan, 4);\n\n            }\n\n\n\n            if( cbp&0x20 ) {\n\n                int c, i;\n\n                for( c = 0; c < 2; c++ ) {\n\n                    qmul = h->dequant4_coeff[c+1+(IS_INTRA( mb_type ) ? 0:3)][sl->chroma_qp[c]];\n\n                    for( i = 0; i < 4; i++ ) {\n\n                        const int index = 16 + 16 * c + i;\n\n                        decode_cabac_residual_nondc(h, sl, sl->mb + (16*index << pixel_shift), 4, index, scan + 1, qmul, 15);\n\n                    }\n\n                }\n\n            } else {\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n            }\n\n        }\n\n    } else {\n\n        fill_rectangle(&sl->non_zero_count_cache[scan8[ 0]], 4, 4, 8, 0, 1);\n\n        fill_rectangle(&sl->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n        fill_rectangle(&sl->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n        sl->last_qscale_diff = 0;\n\n    }\n\n\n\n    h->cur_pic.qscale_table[mb_xy] = sl->qscale;\n\n    write_back_non_zero_count(h, sl);\n\n\n\n    return 0;\n\n}\n", "idx": 23871}
{"project": "FFmpeg", "commit_id": "0780ad9c688cc8272daa7780d3f112a9f55208ca", "target": 0, "func": "static void rdft_calc_c(RDFTContext *s, FFTSample *data)\n\n{\n\n    int i, i1, i2;\n\n    FFTComplex ev, od;\n\n    const int n = 1 << s->nbits;\n\n    const float k1 = 0.5;\n\n    const float k2 = 0.5 - s->inverse;\n\n    const FFTSample *tcos = s->tcos;\n\n    const FFTSample *tsin = s->tsin;\n\n\n\n    if (!s->inverse) {\n\n        s->fft.fft_permute(&s->fft, (FFTComplex*)data);\n\n        s->fft.fft_calc(&s->fft, (FFTComplex*)data);\n\n    }\n\n    /* i=0 is a special case because of packing, the DC term is real, so we\n\n       are going to throw the N/2 term (also real) in with it. */\n\n    ev.re = data[0];\n\n    data[0] = ev.re+data[1];\n\n    data[1] = ev.re-data[1];\n\n    for (i = 1; i < (n>>2); i++) {\n\n        i1 = 2*i;\n\n        i2 = n-i1;\n\n        /* Separate even and odd FFTs */\n\n        ev.re =  k1*(data[i1  ]+data[i2  ]);\n\n        od.im = -k2*(data[i1  ]-data[i2  ]);\n\n        ev.im =  k1*(data[i1+1]-data[i2+1]);\n\n        od.re =  k2*(data[i1+1]+data[i2+1]);\n\n        /* Apply twiddle factors to the odd FFT and add to the even FFT */\n\n        data[i1  ] =  ev.re + od.re*tcos[i] - od.im*tsin[i];\n\n        data[i1+1] =  ev.im + od.im*tcos[i] + od.re*tsin[i];\n\n        data[i2  ] =  ev.re - od.re*tcos[i] + od.im*tsin[i];\n\n        data[i2+1] = -ev.im + od.im*tcos[i] + od.re*tsin[i];\n\n    }\n\n    data[2*i+1]=s->sign_convention*data[2*i+1];\n\n    if (s->inverse) {\n\n        data[0] *= k1;\n\n        data[1] *= k1;\n\n        s->fft.fft_permute(&s->fft, (FFTComplex*)data);\n\n        s->fft.fft_calc(&s->fft, (FFTComplex*)data);\n\n    }\n\n}\n", "idx": 23872}
{"project": "FFmpeg", "commit_id": "eb3f81e4ef73bb8d7e2c75ff0e8cb43de1c7dac5", "target": 0, "func": "static int targa_decode_rle(AVCodecContext *avctx, TargaContext *s, const uint8_t *src, int src_size, uint8_t *dst, int w, int h, int stride, int bpp)\n\n{\n\n    int i, x, y;\n\n    int depth = (bpp + 1) >> 3;\n\n    int type, count;\n\n    int diff;\n\n    const uint8_t *src_end = src + src_size;\n\n\n\n    diff = stride - w * depth;\n\n    x = y = 0;\n\n    while(y < h){\n\n        CHECK_BUFFER_SIZE(src, src_end, 1, \"image type\");\n\n        type = *src++;\n\n        count = (type & 0x7F) + 1;\n\n        type &= 0x80;\n\n        if((x + count > w) && (x + count + 1 > (h - y) * w)){\n\n            av_log(avctx, AV_LOG_ERROR, \"Packet went out of bounds: position (%i,%i) size %i\\n\", x, y, count);\n\n            return -1;\n\n        }\n\n        if(type){\n\n            CHECK_BUFFER_SIZE(src, src_end, depth, \"image data\");\n\n        }else{\n\n            CHECK_BUFFER_SIZE(src, src_end, count * depth, \"image data\");\n\n        }\n\n        for(i = 0; i < count; i++){\n\n            switch(depth){\n\n            case 1:\n\n                *dst = *src;\n\n                break;\n\n            case 2:\n\n                AV_WN16A(dst, AV_RN16A(src));\n\n                break;\n\n            case 3:\n\n                dst[0] = src[0];\n\n                dst[1] = src[1];\n\n                dst[2] = src[2];\n\n                break;\n\n            case 4:\n\n                AV_WN32A(dst, AV_RN32A(src));\n\n                break;\n\n            }\n\n            dst += depth;\n\n            if(!type)\n\n                src += depth;\n\n\n\n            x++;\n\n            if(x == w){\n\n                x = 0;\n\n                y++;\n\n                dst += diff;\n\n            }\n\n        }\n\n        if(type)\n\n            src += depth;\n\n    }\n\n    return src_size;\n\n}\n", "idx": 23873}
{"project": "FFmpeg", "commit_id": "a1ba71aace8cca10ba2a921caa105b17370b0d27", "target": 0, "func": "static int udp_read_packet(AVFormatContext *s, RTSPStream **prtsp_st,\n\n                           uint8_t *buf, int buf_size)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    RTSPStream *rtsp_st;\n\n    fd_set rfds;\n\n    int fd, fd_max, n, i, ret, tcp_fd, timeout_cnt = 0;\n\n    struct timeval tv;\n\n\n\n    for (;;) {\n\n        if (url_interrupt_cb())\n\n            return AVERROR(EINTR);\n\n        FD_ZERO(&rfds);\n\n        if (rt->rtsp_hd) {\n\n            tcp_fd = fd_max = url_get_file_handle(rt->rtsp_hd);\n\n            FD_SET(tcp_fd, &rfds);\n\n        } else {\n\n            fd_max = 0;\n\n            tcp_fd = -1;\n\n        }\n\n        for (i = 0; i < rt->nb_rtsp_streams; i++) {\n\n            rtsp_st = rt->rtsp_streams[i];\n\n            if (rtsp_st->rtp_handle) {\n\n                /* currently, we cannot probe RTCP handle because of\n\n                 * blocking restrictions */\n\n                fd = url_get_file_handle(rtsp_st->rtp_handle);\n\n                if (fd > fd_max)\n\n                    fd_max = fd;\n\n                FD_SET(fd, &rfds);\n\n            }\n\n        }\n\n        tv.tv_sec = 0;\n\n        tv.tv_usec = SELECT_TIMEOUT_MS * 1000;\n\n        n = select(fd_max + 1, &rfds, NULL, NULL, &tv);\n\n        if (n > 0) {\n\n            timeout_cnt = 0;\n\n            for (i = 0; i < rt->nb_rtsp_streams; i++) {\n\n                rtsp_st = rt->rtsp_streams[i];\n\n                if (rtsp_st->rtp_handle) {\n\n                    fd = url_get_file_handle(rtsp_st->rtp_handle);\n\n                    if (FD_ISSET(fd, &rfds)) {\n\n                        ret = url_read(rtsp_st->rtp_handle, buf, buf_size);\n\n                        if (ret > 0) {\n\n                            *prtsp_st = rtsp_st;\n\n                            return ret;\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n#if CONFIG_RTSP_DEMUXER\n\n            if (tcp_fd != -1 && FD_ISSET(tcp_fd, &rfds)) {\n\n                RTSPMessageHeader reply;\n\n\n\n                ret = ff_rtsp_read_reply(s, &reply, NULL, 0);\n\n                if (ret < 0)\n\n                    return ret;\n\n                /* XXX: parse message */\n\n                if (rt->state != RTSP_STATE_STREAMING)\n\n                    return 0;\n\n            }\n\n#endif\n\n        } else if (n == 0 && ++timeout_cnt >= MAX_TIMEOUTS) {\n\n            return FF_NETERROR(ETIMEDOUT);\n\n        } else if (n < 0 && errno != EINTR)\n\n            return AVERROR(errno);\n\n    }\n\n}\n", "idx": 23876}
{"project": "FFmpeg", "commit_id": "aca490777f9da2a71b537874ed4e16105bb3df02", "target": 0, "func": "static av_cold int g726_init(AVCodecContext * avctx)\n\n{\n\n    AVG726Context* c = (AVG726Context*)avctx->priv_data;\n\n    unsigned int index= (avctx->bit_rate + avctx->sample_rate/2) / avctx->sample_rate - 2;\n\n\n\n    if (\n\n        (avctx->bit_rate != 16000 && avctx->bit_rate != 24000 &&\n\n         avctx->bit_rate != 32000 && avctx->bit_rate != 40000)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"G726: unsupported audio format\\n\");\n\n        return -1;\n\n    }\n\n    if (avctx->sample_rate != 8000 && avctx->strict_std_compliance>FF_COMPLIANCE_INOFFICIAL) {\n\n        av_log(avctx, AV_LOG_ERROR, \"G726: unsupported audio format\\n\");\n\n        return -1;\n\n    }\n\n    if(avctx->channels != 1){\n\n        av_log(avctx, AV_LOG_ERROR, \"Only mono is supported\\n\");\n\n        return -1;\n\n    }\n\n    if(index>3){\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported number of bits %d\\n\", index+2);\n\n        return -1;\n\n    }\n\n    g726_reset(&c->c, index);\n\n    c->code_size = c->c.tbls->bits;\n\n    c->bit_buffer = 0;\n\n    c->bits_left = 0;\n\n\n\n    avctx->coded_frame = avcodec_alloc_frame();\n\n    if (!avctx->coded_frame)\n\n        return AVERROR(ENOMEM);\n\n    avctx->coded_frame->key_frame = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 23877}
{"project": "FFmpeg", "commit_id": "df2bd71aeb3e68509e3afc5502ef7cd6e5a69583", "target": 0, "func": "static int amf_parse_object(AVFormatContext *s, AVStream *astream, AVStream *vstream, const char *key, int64_t max_pos, int depth) {\n\n    AVCodecContext *acodec, *vcodec;\n\n    ByteIOContext *ioc;\n\n    AMFDataType amf_type;\n\n    char str_val[256];\n\n    double num_val;\n\n\n\n    num_val = 0;\n\n    ioc = s->pb;\n\n\n\n    amf_type = get_byte(ioc);\n\n\n\n    switch(amf_type) {\n\n        case AMF_DATA_TYPE_NUMBER:\n\n            num_val = av_int2dbl(get_be64(ioc)); break;\n\n        case AMF_DATA_TYPE_BOOL:\n\n            num_val = get_byte(ioc); break;\n\n        case AMF_DATA_TYPE_STRING:\n\n            if(amf_get_string(ioc, str_val, sizeof(str_val)) < 0)\n\n                return -1;\n\n            break;\n\n        case AMF_DATA_TYPE_OBJECT: {\n\n            unsigned int keylen;\n\n\n\n            while(url_ftell(ioc) < max_pos - 2 && (keylen = get_be16(ioc))) {\n\n                url_fskip(ioc, keylen); //skip key string\n\n                if(amf_parse_object(s, NULL, NULL, NULL, max_pos, depth + 1) < 0)\n\n                    return -1; //if we couldn't skip, bomb out.\n\n            }\n\n            if(get_byte(ioc) != AMF_END_OF_OBJECT)\n\n                return -1;\n\n        }\n\n            break;\n\n        case AMF_DATA_TYPE_NULL:\n\n        case AMF_DATA_TYPE_UNDEFINED:\n\n        case AMF_DATA_TYPE_UNSUPPORTED:\n\n            break; //these take up no additional space\n\n        case AMF_DATA_TYPE_MIXEDARRAY:\n\n            url_fskip(ioc, 4); //skip 32-bit max array index\n\n            while(url_ftell(ioc) < max_pos - 2 && amf_get_string(ioc, str_val, sizeof(str_val)) > 0) {\n\n                //this is the only case in which we would want a nested parse to not skip over the object\n\n                if(amf_parse_object(s, astream, vstream, str_val, max_pos, depth + 1) < 0)\n\n                    return -1;\n\n            }\n\n            if(get_byte(ioc) != AMF_END_OF_OBJECT)\n\n                return -1;\n\n            break;\n\n        case AMF_DATA_TYPE_ARRAY: {\n\n            unsigned int arraylen, i;\n\n\n\n            arraylen = get_be32(ioc);\n\n            for(i = 0; i < arraylen && url_ftell(ioc) < max_pos - 1; i++) {\n\n                if(amf_parse_object(s, NULL, NULL, NULL, max_pos, depth + 1) < 0)\n\n                    return -1; //if we couldn't skip, bomb out.\n\n            }\n\n        }\n\n            break;\n\n        case AMF_DATA_TYPE_DATE:\n\n            url_fskip(ioc, 8 + 2); //timestamp (double) and UTC offset (int16)\n\n            break;\n\n        default: //unsupported type, we couldn't skip\n\n            return -1;\n\n    }\n\n\n\n    if(depth == 1 && key) { //only look for metadata values when we are not nested and key != NULL\n\n        acodec = astream ? astream->codec : NULL;\n\n        vcodec = vstream ? vstream->codec : NULL;\n\n\n\n        if(amf_type == AMF_DATA_TYPE_BOOL) {\n\n        } else if(amf_type == AMF_DATA_TYPE_NUMBER) {\n\n            if(!strcmp(key, \"duration\")) s->duration = num_val * AV_TIME_BASE;\n\n            else if(!strcmp(key, \"videodatarate\") && vcodec && 0 <= (int)(num_val * 1024.0))\n\n                vcodec->bit_rate = num_val * 1024.0;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23878}
{"project": "FFmpeg", "commit_id": "b1306823d0b3ae998c8e10ad832004eb13bdd93e", "target": 0, "func": "static void mkv_write_simpletag(AVIOContext *pb, AVDictionaryEntry *t)\n\n{\n\n    uint8_t *key = av_strdup(t->key);\n\n    uint8_t *p   = key;\n\n    const uint8_t *lang = NULL;\n\n    ebml_master tag;\n\n\n\n    if ((p = strrchr(p, '-')) &&\n\n        (lang = av_convert_lang_to(p + 1, AV_LANG_ISO639_2_BIBL)))\n\n        *p = 0;\n\n\n\n    p = key;\n\n    while (*p) {\n\n        if (*p == ' ')\n\n            *p = '_';\n\n        else if (*p >= 'a' && *p <= 'z')\n\n            *p -= 'a' - 'A';\n\n        p++;\n\n    }\n\n\n\n    tag = start_ebml_master(pb, MATROSKA_ID_SIMPLETAG, 0);\n\n    put_ebml_string(pb, MATROSKA_ID_TAGNAME, key);\n\n    if (lang)\n\n        put_ebml_string(pb, MATROSKA_ID_TAGLANG, lang);\n\n    put_ebml_string(pb, MATROSKA_ID_TAGSTRING, t->value);\n\n    end_ebml_master(pb, tag);\n\n\n\n    av_freep(&key);\n\n}\n", "idx": 23879}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "static inline int decode_hrd_parameters(H264Context *h, SPS *sps)\n\n{\n\n    int cpb_count, i;\n\n    cpb_count = get_ue_golomb_31(&h->gb) + 1;\n\n\n\n    if (cpb_count > 32U) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"cpb_count %d invalid\\n\", cpb_count);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    get_bits(&h->gb, 4); /* bit_rate_scale */\n\n    get_bits(&h->gb, 4); /* cpb_size_scale */\n\n    for (i = 0; i < cpb_count; i++) {\n\n        get_ue_golomb_long(&h->gb); /* bit_rate_value_minus1 */\n\n        get_ue_golomb_long(&h->gb); /* cpb_size_value_minus1 */\n\n        get_bits1(&h->gb);          /* cbr_flag */\n\n    }\n\n    sps->initial_cpb_removal_delay_length = get_bits(&h->gb, 5) + 1;\n\n    sps->cpb_removal_delay_length         = get_bits(&h->gb, 5) + 1;\n\n    sps->dpb_output_delay_length          = get_bits(&h->gb, 5) + 1;\n\n    sps->time_offset_length               = get_bits(&h->gb, 5);\n\n    sps->cpb_cnt                          = cpb_count;\n\n    return 0;\n\n}\n", "idx": 23880}
{"project": "FFmpeg", "commit_id": "79d4c96a1a708f8da145121cee118c7bdd596344", "target": 0, "func": "int av_aes_init(AVAES *a, const uint8_t *key, int key_bits, int decrypt) {\n\n    int i, j, t, rconpointer = 0;\n\n    uint8_t tk[8][4];\n\n    int KC= key_bits>>5;\n\n    int rounds= KC + 6;\n\n    uint8_t  log8[256];\n\n    uint8_t alog8[512];\n\n\n\n    if(!enc_multbl[4][1023]){\n\n        j=1;\n\n        for(i=0; i<255; i++){\n\n            alog8[i]=\n\n            alog8[i+255]= j;\n\n            log8[j]= i;\n\n            j^= j+j;\n\n            if(j>255) j^= 0x11B;\n\n        }\n\n        for(i=0; i<256; i++){\n\n            j= i ? alog8[255-log8[i]] : 0;\n\n            j ^= (j<<1) ^ (j<<2) ^ (j<<3) ^ (j<<4);\n\n            j = (j ^ (j>>8) ^ 99) & 255;\n\n            inv_sbox[j]= i;\n\n            sbox    [i]= j;\n\n        }\n\n        init_multbl2(dec_multbl[0], (int[4]){0xe, 0x9, 0xd, 0xb}, log8, alog8, inv_sbox);\n\n        init_multbl2(enc_multbl[0], (int[4]){0x2, 0x1, 0x1, 0x3}, log8, alog8, sbox);\n\n    }\n\n\n\n    if(key_bits!=128 && key_bits!=192 && key_bits!=256)\n\n        return -1;\n\n\n\n    a->rounds= rounds;\n\n\n\n    memcpy(tk, key, KC*4);\n\n\n\n    for(t= 0; t < (rounds+1)*16;) {\n\n        memcpy(a->round_key[0][0]+t, tk, KC*4);\n\n        t+= KC*4;\n\n\n\n        for(i = 0; i < 4; i++)\n\n            tk[0][i] ^= sbox[tk[KC-1][(i+1)&3]];\n\n        tk[0][0] ^= rcon[rconpointer++];\n\n\n\n        for(j = 1; j < KC; j++){\n\n            if(KC != 8 || j != KC>>1)\n\n                for(i = 0; i < 4; i++) tk[j][i] ^=      tk[j-1][i];\n\n            else\n\n                for(i = 0; i < 4; i++) tk[j][i] ^= sbox[tk[j-1][i]];\n\n        }\n\n    }\n\n\n\n    if(decrypt){\n\n        for(i=1; i<rounds; i++){\n\n            uint8_t tmp[3][16];\n\n            memcpy(tmp[2], a->round_key[i][0], 16);\n\n            subshift(tmp[1], 0, sbox);\n\n            mix(tmp, dec_multbl, 1, 3);\n\n            memcpy(a->round_key[i][0], tmp[0], 16);\n\n        }\n\n    }else{\n\n        for(i=0; i<(rounds+1)>>1; i++){\n\n            for(j=0; j<16; j++)\n\n                FFSWAP(int, a->round_key[i][0][j], a->round_key[rounds-i][0][j]);\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23881}
{"project": "FFmpeg", "commit_id": "229843aa359ae0c9519977d7fa952688db63f559", "target": 0, "func": "static int grab_read_header(AVFormatContext *s1, AVFormatParameters *ap)\n\n{\n\n    VideoData *s = s1->priv_data;\n\n    AVStream *st;\n\n    int video_fd;\n\n    int desired_palette, desired_depth;\n\n    struct video_tuner tuner;\n\n    struct video_audio audio;\n\n    struct video_picture pict;\n\n    int j;\n\n    int vformat_num = FF_ARRAY_ELEMS(video_formats);\n\n\n\n    av_log(s1, AV_LOG_WARNING, \"V4L input device is deprecated and will be removed in the next release.\");\n\n\n\n    if (ap->time_base.den <= 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"Wrong time base (%d)\\n\", ap->time_base.den);\n\n        return -1;\n\n    }\n\n    s->time_base = ap->time_base;\n\n\n\n    s->video_win.width = ap->width;\n\n    s->video_win.height = ap->height;\n\n\n\n    st = avformat_new_stream(s1, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n    avpriv_set_pts_info(st, 64, 1, 1000000); /* 64 bits pts in us */\n\n\n\n    video_fd = open(s1->filename, O_RDWR);\n\n    if (video_fd < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"%s: %s\\n\", s1->filename, strerror(errno));\n\n        goto fail;\n\n    }\n\n\n\n    if (ioctl(video_fd, VIDIOCGCAP, &s->video_cap) < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"VIDIOCGCAP: %s\\n\", strerror(errno));\n\n        goto fail;\n\n    }\n\n\n\n    if (!(s->video_cap.type & VID_TYPE_CAPTURE)) {\n\n        av_log(s1, AV_LOG_ERROR, \"Fatal: grab device does not handle capture\\n\");\n\n        goto fail;\n\n    }\n\n\n\n    /* no values set, autodetect them */\n\n    if (s->video_win.width <= 0 || s->video_win.height <= 0) {\n\n        if (ioctl(video_fd, VIDIOCGWIN, &s->video_win, sizeof(s->video_win)) < 0) {\n\n            av_log(s1, AV_LOG_ERROR, \"VIDIOCGWIN: %s\\n\", strerror(errno));\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n    if(av_image_check_size(s->video_win.width, s->video_win.height, 0, s1) < 0)\n\n        return -1;\n\n\n\n    desired_palette = -1;\n\n    desired_depth = -1;\n\n    for (j = 0; j < vformat_num; j++) {\n\n        if (ap->pix_fmt == video_formats[j].pix_fmt) {\n\n            desired_palette = video_formats[j].palette;\n\n            desired_depth = video_formats[j].depth;\n\n            break;\n\n        }\n\n    }\n\n\n\n    /* set tv standard */\n\n    if (!ioctl(video_fd, VIDIOCGTUNER, &tuner)) {\n\n        tuner.mode = s->standard;\n\n        ioctl(video_fd, VIDIOCSTUNER, &tuner);\n\n    }\n\n\n\n    /* unmute audio */\n\n    audio.audio = 0;\n\n    ioctl(video_fd, VIDIOCGAUDIO, &audio);\n\n    memcpy(&s->audio_saved, &audio, sizeof(audio));\n\n    audio.flags &= ~VIDEO_AUDIO_MUTE;\n\n    ioctl(video_fd, VIDIOCSAUDIO, &audio);\n\n\n\n    ioctl(video_fd, VIDIOCGPICT, &pict);\n\n    av_dlog(s1, \"v4l: colour=%d hue=%d brightness=%d constrast=%d whiteness=%d\\n\",\n\n            pict.colour, pict.hue, pict.brightness, pict.contrast, pict.whiteness);\n\n    /* try to choose a suitable video format */\n\n    pict.palette = desired_palette;\n\n    pict.depth= desired_depth;\n\n    if (desired_palette == -1 || ioctl(video_fd, VIDIOCSPICT, &pict) < 0) {\n\n        for (j = 0; j < vformat_num; j++) {\n\n            pict.palette = video_formats[j].palette;\n\n            pict.depth = video_formats[j].depth;\n\n            if (-1 != ioctl(video_fd, VIDIOCSPICT, &pict))\n\n                break;\n\n        }\n\n        if (j >= vformat_num)\n\n            goto fail1;\n\n    }\n\n\n\n    if (ioctl(video_fd, VIDIOCGMBUF, &s->gb_buffers) < 0) {\n\n        /* try to use read based access */\n\n        int val;\n\n\n\n        s->video_win.x = 0;\n\n        s->video_win.y = 0;\n\n        s->video_win.chromakey = -1;\n\n        s->video_win.flags = 0;\n\n\n\n        if (ioctl(video_fd, VIDIOCSWIN, s->video_win) < 0) {\n\n            av_log(s1, AV_LOG_ERROR, \"VIDIOCSWIN: %s\\n\", strerror(errno));\n\n            goto fail;\n\n        }\n\n\n\n        s->frame_format = pict.palette;\n\n\n\n        val = 1;\n\n        if (ioctl(video_fd, VIDIOCCAPTURE, &val) < 0) {\n\n            av_log(s1, AV_LOG_ERROR, \"VIDIOCCAPTURE: %s\\n\", strerror(errno));\n\n            goto fail;\n\n        }\n\n\n\n        s->time_frame = av_gettime() * s->time_base.den / s->time_base.num;\n\n        s->use_mmap = 0;\n\n    } else {\n\n        s->video_buf = mmap(0, s->gb_buffers.size, PROT_READ|PROT_WRITE, MAP_SHARED, video_fd, 0);\n\n        if ((unsigned char*)-1 == s->video_buf) {\n\n            s->video_buf = mmap(0, s->gb_buffers.size, PROT_READ|PROT_WRITE, MAP_PRIVATE, video_fd, 0);\n\n            if ((unsigned char*)-1 == s->video_buf) {\n\n                av_log(s1, AV_LOG_ERROR, \"mmap: %s\\n\", strerror(errno));\n\n                goto fail;\n\n            }\n\n        }\n\n        s->gb_frame = 0;\n\n        s->time_frame = av_gettime() * s->time_base.den / s->time_base.num;\n\n\n\n        /* start to grab the first frame */\n\n        s->gb_buf.frame = s->gb_frame % s->gb_buffers.frames;\n\n        s->gb_buf.height = s->video_win.height;\n\n        s->gb_buf.width = s->video_win.width;\n\n        s->gb_buf.format = pict.palette;\n\n\n\n        if (ioctl(video_fd, VIDIOCMCAPTURE, &s->gb_buf) < 0) {\n\n            if (errno != EAGAIN) {\n\n            fail1:\n\n                av_log(s1, AV_LOG_ERROR, \"VIDIOCMCAPTURE: %s\\n\", strerror(errno));\n\n            } else {\n\n                av_log(s1, AV_LOG_ERROR, \"Fatal: grab device does not receive any video signal\\n\");\n\n            }\n\n            goto fail;\n\n        }\n\n        for (j = 1; j < s->gb_buffers.frames; j++) {\n\n          s->gb_buf.frame = j;\n\n          ioctl(video_fd, VIDIOCMCAPTURE, &s->gb_buf);\n\n        }\n\n        s->frame_format = s->gb_buf.format;\n\n        s->use_mmap = 1;\n\n    }\n\n\n\n    for (j = 0; j < vformat_num; j++) {\n\n        if (s->frame_format == video_formats[j].palette) {\n\n            s->frame_size = s->video_win.width * s->video_win.height * video_formats[j].depth / 8;\n\n            st->codec->pix_fmt = video_formats[j].pix_fmt;\n\n            break;\n\n        }\n\n    }\n\n\n\n    if (j >= vformat_num)\n\n        goto fail;\n\n\n\n    s->fd = video_fd;\n\n\n\n    st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id = AV_CODEC_ID_RAWVIDEO;\n\n    st->codec->width = s->video_win.width;\n\n    st->codec->height = s->video_win.height;\n\n    st->codec->time_base = s->time_base;\n\n    st->codec->bit_rate = s->frame_size * 1/av_q2d(st->codec->time_base) * 8;\n\n\n\n    return 0;\n\n fail:\n\n    if (video_fd >= 0)\n\n        close(video_fd);\n\n    return AVERROR(EIO);\n\n}\n", "idx": 23882}
{"project": "FFmpeg", "commit_id": "69dde1ad36b7d95b8b9268f414aa6c076212ed41", "target": 0, "func": "int mov_write_ftyp_tag(ByteIOContext *pb, AVFormatContext *s)\n\n{\n\n    put_be32(pb, 0x14 ); /* size */\n\n    put_tag(pb, \"ftyp\");\n\n\n\n    if (!strcmp(\"3gp\", s->oformat->name))\n\n        put_tag(pb, \"3gp4\");\n\n    else\n\n        put_tag(pb, \"isom\");\n\n\n\n    put_be32(pb, 0x200 );\n\n\n\n    if (!strcmp(\"3gp\", s->oformat->name))\n\n        put_tag(pb, \"3gp4\");\n\n    else\n\n        put_tag(pb, \"mp41\");\n\n\n\n    return 0x14;\n\n}\n", "idx": 23883}
{"project": "FFmpeg", "commit_id": "6433b393ba2b1b410ff18e386f84781a760549f5", "target": 1, "func": "static void stereo_processing(PSContext *ps, float (*l)[32][2], float (*r)[32][2], int is34)\n\n{\n\n    int e, b, k;\n\n\n\n    float (*H11)[PS_MAX_NUM_ENV+1][PS_MAX_NR_IIDICC] = ps->H11;\n\n    float (*H12)[PS_MAX_NUM_ENV+1][PS_MAX_NR_IIDICC] = ps->H12;\n\n    float (*H21)[PS_MAX_NUM_ENV+1][PS_MAX_NR_IIDICC] = ps->H21;\n\n    float (*H22)[PS_MAX_NUM_ENV+1][PS_MAX_NR_IIDICC] = ps->H22;\n\n    int8_t *opd_hist = ps->opd_hist;\n\n    int8_t *ipd_hist = ps->ipd_hist;\n\n    int8_t iid_mapped_buf[PS_MAX_NUM_ENV][PS_MAX_NR_IIDICC];\n\n    int8_t icc_mapped_buf[PS_MAX_NUM_ENV][PS_MAX_NR_IIDICC];\n\n    int8_t ipd_mapped_buf[PS_MAX_NUM_ENV][PS_MAX_NR_IIDICC];\n\n    int8_t opd_mapped_buf[PS_MAX_NUM_ENV][PS_MAX_NR_IIDICC];\n\n    int8_t (*iid_mapped)[PS_MAX_NR_IIDICC] = iid_mapped_buf;\n\n    int8_t (*icc_mapped)[PS_MAX_NR_IIDICC] = icc_mapped_buf;\n\n    int8_t (*ipd_mapped)[PS_MAX_NR_IIDICC] = ipd_mapped_buf;\n\n    int8_t (*opd_mapped)[PS_MAX_NR_IIDICC] = opd_mapped_buf;\n\n    const int8_t *k_to_i = is34 ? k_to_i_34 : k_to_i_20;\n\n    TABLE_CONST float (*H_LUT)[8][4] = (PS_BASELINE || ps->icc_mode < 3) ? HA : HB;\n\n\n\n    //Remapping\n\n    if (ps->num_env_old) {\n\n        memcpy(H11[0][0], H11[0][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H11[0][0][0]));\n\n        memcpy(H11[1][0], H11[1][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H11[1][0][0]));\n\n        memcpy(H12[0][0], H12[0][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H12[0][0][0]));\n\n        memcpy(H12[1][0], H12[1][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H12[1][0][0]));\n\n        memcpy(H21[0][0], H21[0][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H21[0][0][0]));\n\n        memcpy(H21[1][0], H21[1][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H21[1][0][0]));\n\n        memcpy(H22[0][0], H22[0][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H22[0][0][0]));\n\n        memcpy(H22[1][0], H22[1][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H22[1][0][0]));\n\n    }\n\n\n\n    if (is34) {\n\n        remap34(&iid_mapped, ps->iid_par, ps->nr_iid_par, ps->num_env, 1);\n\n        remap34(&icc_mapped, ps->icc_par, ps->nr_icc_par, ps->num_env, 1);\n\n        if (ps->enable_ipdopd) {\n\n            remap34(&ipd_mapped, ps->ipd_par, ps->nr_ipdopd_par, ps->num_env, 0);\n\n            remap34(&opd_mapped, ps->opd_par, ps->nr_ipdopd_par, ps->num_env, 0);\n\n        }\n\n        if (!ps->is34bands_old) {\n\n            map_val_20_to_34(H11[0][0]);\n\n            map_val_20_to_34(H11[1][0]);\n\n            map_val_20_to_34(H12[0][0]);\n\n            map_val_20_to_34(H12[1][0]);\n\n            map_val_20_to_34(H21[0][0]);\n\n            map_val_20_to_34(H21[1][0]);\n\n            map_val_20_to_34(H22[0][0]);\n\n            map_val_20_to_34(H22[1][0]);\n\n            ipdopd_reset(ipd_hist, opd_hist);\n\n        }\n\n    } else {\n\n        remap20(&iid_mapped, ps->iid_par, ps->nr_iid_par, ps->num_env, 1);\n\n        remap20(&icc_mapped, ps->icc_par, ps->nr_icc_par, ps->num_env, 1);\n\n        if (ps->enable_ipdopd) {\n\n            remap20(&ipd_mapped, ps->ipd_par, ps->nr_ipdopd_par, ps->num_env, 0);\n\n            remap20(&opd_mapped, ps->opd_par, ps->nr_ipdopd_par, ps->num_env, 0);\n\n        }\n\n        if (ps->is34bands_old) {\n\n            map_val_34_to_20(H11[0][0]);\n\n            map_val_34_to_20(H11[1][0]);\n\n            map_val_34_to_20(H12[0][0]);\n\n            map_val_34_to_20(H12[1][0]);\n\n            map_val_34_to_20(H21[0][0]);\n\n            map_val_34_to_20(H21[1][0]);\n\n            map_val_34_to_20(H22[0][0]);\n\n            map_val_34_to_20(H22[1][0]);\n\n            ipdopd_reset(ipd_hist, opd_hist);\n\n        }\n\n    }\n\n\n\n    //Mixing\n\n    for (e = 0; e < ps->num_env; e++) {\n\n        for (b = 0; b < NR_PAR_BANDS[is34]; b++) {\n\n            float h11, h12, h21, h22;\n\n            h11 = H_LUT[iid_mapped[e][b] + 7 + 23 * ps->iid_quant][icc_mapped[e][b]][0];\n\n            h12 = H_LUT[iid_mapped[e][b] + 7 + 23 * ps->iid_quant][icc_mapped[e][b]][1];\n\n            h21 = H_LUT[iid_mapped[e][b] + 7 + 23 * ps->iid_quant][icc_mapped[e][b]][2];\n\n            h22 = H_LUT[iid_mapped[e][b] + 7 + 23 * ps->iid_quant][icc_mapped[e][b]][3];\n\n\n\n            if (!PS_BASELINE && ps->enable_ipdopd && 2*b <= NR_PAR_BANDS[is34]) {\n\n                //The spec say says to only run this smoother when enable_ipdopd\n\n                //is set but the reference decoder appears to run it constantly\n\n                float h11i, h12i, h21i, h22i;\n\n                float ipd_adj_re, ipd_adj_im;\n\n                int opd_idx = opd_hist[b] * 8 + opd_mapped[e][b];\n\n                int ipd_idx = ipd_hist[b] * 8 + ipd_mapped[e][b];\n\n                float opd_re = pd_re_smooth[opd_idx];\n\n                float opd_im = pd_im_smooth[opd_idx];\n\n                float ipd_re = pd_re_smooth[ipd_idx];\n\n                float ipd_im = pd_im_smooth[ipd_idx];\n\n                opd_hist[b] = opd_idx & 0x3F;\n\n                ipd_hist[b] = ipd_idx & 0x3F;\n\n\n\n                ipd_adj_re = opd_re*ipd_re + opd_im*ipd_im;\n\n                ipd_adj_im = opd_im*ipd_re - opd_re*ipd_im;\n\n                h11i = h11 * opd_im;\n\n                h11  = h11 * opd_re;\n\n                h12i = h12 * ipd_adj_im;\n\n                h12  = h12 * ipd_adj_re;\n\n                h21i = h21 * opd_im;\n\n                h21  = h21 * opd_re;\n\n                h22i = h22 * ipd_adj_im;\n\n                h22  = h22 * ipd_adj_re;\n\n                H11[1][e+1][b] = h11i;\n\n                H12[1][e+1][b] = h12i;\n\n                H21[1][e+1][b] = h21i;\n\n                H22[1][e+1][b] = h22i;\n\n            }\n\n            H11[0][e+1][b] = h11;\n\n            H12[0][e+1][b] = h12;\n\n            H21[0][e+1][b] = h21;\n\n            H22[0][e+1][b] = h22;\n\n        }\n\n        for (k = 0; k < NR_BANDS[is34]; k++) {\n\n            float h[2][4];\n\n            float h_step[2][4];\n\n            int start = ps->border_position[e];\n\n            int stop  = ps->border_position[e+1];\n\n            float width = 1.f / (stop - start);\n\n            b = k_to_i[k];\n\n            h[0][0] = H11[0][e][b];\n\n            h[0][1] = H12[0][e][b];\n\n            h[0][2] = H21[0][e][b];\n\n            h[0][3] = H22[0][e][b];\n\n            if (!PS_BASELINE && ps->enable_ipdopd) {\n\n            //Is this necessary? ps_04_new seems unchanged\n\n            if ((is34 && k <= 13 && k >= 9) || (!is34 && k <= 1)) {\n\n                h[1][0] = -H11[1][e][b];\n\n                h[1][1] = -H12[1][e][b];\n\n                h[1][2] = -H21[1][e][b];\n\n                h[1][3] = -H22[1][e][b];\n\n            } else {\n\n                h[1][0] = H11[1][e][b];\n\n                h[1][1] = H12[1][e][b];\n\n                h[1][2] = H21[1][e][b];\n\n                h[1][3] = H22[1][e][b];\n\n            }\n\n            }\n\n            //Interpolation\n\n            h_step[0][0] = (H11[0][e+1][b] - h[0][0]) * width;\n\n            h_step[0][1] = (H12[0][e+1][b] - h[0][1]) * width;\n\n            h_step[0][2] = (H21[0][e+1][b] - h[0][2]) * width;\n\n            h_step[0][3] = (H22[0][e+1][b] - h[0][3]) * width;\n\n            if (!PS_BASELINE && ps->enable_ipdopd) {\n\n                h_step[1][0] = (H11[1][e+1][b] - h[1][0]) * width;\n\n                h_step[1][1] = (H12[1][e+1][b] - h[1][1]) * width;\n\n                h_step[1][2] = (H21[1][e+1][b] - h[1][2]) * width;\n\n                h_step[1][3] = (H22[1][e+1][b] - h[1][3]) * width;\n\n            }\n\n            ps->dsp.stereo_interpolate[!PS_BASELINE && ps->enable_ipdopd](\n\n                l[k] + start + 1, r[k] + start + 1,\n\n                h, h_step, stop - start);\n\n        }\n\n    }\n\n}\n", "idx": 23886}
{"project": "FFmpeg", "commit_id": "8e453fc3c76ee59c111fa5b40e87341d2bab2dcd", "target": 1, "func": "static int decode_header(MPADecodeContext *s, uint32_t header)\n\n{\n\n    int sample_rate, frame_size, mpeg25, padding;\n\n    int sample_rate_index, bitrate_index;\n\n    if (header & (1<<20)) {\n\n        s->lsf = (header & (1<<19)) ? 0 : 1;\n\n        mpeg25 = 0;\n\n    } else {\n\n        s->lsf = 1;\n\n        mpeg25 = 1;\n\n    }\n\n\n\n    s->layer = 4 - ((header >> 17) & 3);\n\n    /* extract frequency */\n\n    sample_rate_index = (header >> 10) & 3;\n\n    sample_rate = mpa_freq_tab[sample_rate_index] >> (s->lsf + mpeg25);\n\n    sample_rate_index += 3 * (s->lsf + mpeg25);\n\n    s->sample_rate_index = sample_rate_index;\n\n    s->error_protection = ((header >> 16) & 1) ^ 1;\n\n    s->sample_rate = sample_rate;\n\n\n\n    bitrate_index = (header >> 12) & 0xf;\n\n    padding = (header >> 9) & 1;\n\n    //extension = (header >> 8) & 1;\n\n    s->mode = (header >> 6) & 3;\n\n    s->mode_ext = (header >> 4) & 3;\n\n    //copyright = (header >> 3) & 1;\n\n    //original = (header >> 2) & 1;\n\n    //emphasis = header & 3;\n\n\n\n    if (s->mode == MPA_MONO)\n\n        s->nb_channels = 1;\n\n    else\n\n        s->nb_channels = 2;\n\n\n\n    if (bitrate_index != 0) {\n\n        frame_size = mpa_bitrate_tab[s->lsf][s->layer - 1][bitrate_index];\n\n        s->bit_rate = frame_size * 1000;\n\n        switch(s->layer) {\n\n        case 1:\n\n            frame_size = (frame_size * 12000) / sample_rate;\n\n            frame_size = (frame_size + padding) * 4;\n\n            break;\n\n        case 2:\n\n            frame_size = (frame_size * 144000) / sample_rate;\n\n            frame_size += padding;\n\n            break;\n\n        default:\n\n        case 3:\n\n            frame_size = (frame_size * 144000) / (sample_rate << s->lsf);\n\n            frame_size += padding;\n\n            break;\n\n        }\n\n        s->frame_size = frame_size;\n\n    } else {\n\n        /* if no frame size computed, signal it */\n\n        if (!s->free_format_frame_size)\n\n            return 1;\n\n        /* free format: compute bitrate and real frame size from the\n\n           frame size we extracted by reading the bitstream */\n\n        s->frame_size = s->free_format_frame_size;\n\n        switch(s->layer) {\n\n        case 1:\n\n            s->frame_size += padding  * 4;\n\n            s->bit_rate = (s->frame_size * sample_rate) / 48000;\n\n            break;\n\n        case 2:\n\n            s->frame_size += padding;\n\n            s->bit_rate = (s->frame_size * sample_rate) / 144000;\n\n            break;\n\n        default:\n\n        case 3:\n\n            s->frame_size += padding;\n\n            s->bit_rate = (s->frame_size * (sample_rate << s->lsf)) / 144000;\n\n            break;\n\n        }\n\n    }\n\n\n\n#if defined(DEBUG)\n\n    dprintf(\"layer%d, %d Hz, %d kbits/s, \",\n\n           s->layer, s->sample_rate, s->bit_rate);\n\n    if (s->nb_channels == 2) {\n\n        if (s->layer == 3) {\n\n            if (s->mode_ext & MODE_EXT_MS_STEREO)\n\n                dprintf(\"ms-\");\n\n            if (s->mode_ext & MODE_EXT_I_STEREO)\n\n                dprintf(\"i-\");\n\n        }\n\n        dprintf(\"stereo\");\n\n    } else {\n\n        dprintf(\"mono\");\n\n    }\n\n    dprintf(\"\\n\");\n\n#endif\n\n    return 0;\n\n}\n", "idx": 23889}
{"project": "FFmpeg", "commit_id": "6e1a167c5564085385488b4f579e9efb987d4bfa", "target": 1, "func": "static int dx2_decode_slice_rgb(GetBitContext *gb, AVFrame *frame,\n\n                                int line, int left, uint8_t lru[3][8])\n\n{\n\n    int x, y;\n\n    int width    = frame->width;\n\n    int stride   = frame->linesize[0];\n\n    uint8_t *dst = frame->data[0] + stride * line;\n\n\n\n    for (y = 0; y < left && get_bits_left(gb) > 16; y++) {\n\n        for (x = 0; x < width; x++) {\n\n            dst[x * 3 + 0] = decode_sym(gb, lru[0]);\n\n            dst[x * 3 + 1] = decode_sym(gb, lru[1]);\n\n            dst[x * 3 + 2] = decode_sym(gb, lru[2]);\n\n        }\n\n\n\n        dst += stride;\n\n    }\n\n\n\n    return y;\n\n}\n", "idx": 23898}
{"project": "FFmpeg", "commit_id": "0273ceebbd01f9fd5238558e6151e0b9aa3305ab", "target": 0, "func": "static int mjpeg_decode_frame(AVCodecContext *avctx, \n\n                              void *data, int *data_size,\n\n                              uint8_t *buf, int buf_size)\n\n{\n\n    MJpegDecodeContext *s = avctx->priv_data;\n\n    uint8_t *buf_end, *buf_ptr;\n\n    int i, start_code;\n\n    AVPicture *picture = data;\n\n\n\n    *data_size = 0;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0)\n\n        return 0;\n\n\n\n    buf_ptr = buf;\n\n    buf_end = buf + buf_size;\n\n    while (buf_ptr < buf_end) {\n\n        /* find start next marker */\n\n        start_code = find_marker(&buf_ptr, buf_end);\n\n\t{\n\n\t    /* EOF */\n\n            if (start_code < 0) {\n\n\t\tgoto the_end;\n\n            } else {\n\n                dprintf(\"marker=%x avail_size_in_buf=%d\\n\", start_code, buf_end - buf_ptr);\n\n\t\t\n\n\t\tif ((buf_end - buf_ptr) > s->buffer_size)\n\n\t\t{\n\n\t\t    av_free(s->buffer);\n\n\t\t    s->buffer_size = buf_end-buf_ptr;\n\n\t\t    s->buffer = av_malloc(s->buffer_size);\n\n\t\t    dprintf(\"buffer too small, expanding to %d bytes\\n\",\n\n\t\t\ts->buffer_size);\n\n\t\t}\n\n\t\t\n\n\t\t/* unescape buffer of SOS */\n\n\t\tif (start_code == SOS)\n\n\t\t{\n\n\t\t    uint8_t *src = buf_ptr;\n\n\t\t    uint8_t *dst = s->buffer;\n\n\n\n\t\t    while (src<buf_end)\n\n\t\t    {\n\n\t\t\tuint8_t x = *(src++);\n\n\n\n\t\t\t*(dst++) = x;\n\n\t\t\tif (x == 0xff)\n\n\t\t\t{\n\n\t\t\t    while(*src == 0xff) src++;\n\n\n\n\t\t\t    x = *(src++);\n\n\t\t\t    if (x >= 0xd0 && x <= 0xd7)\n\n\t\t\t\t*(dst++) = x;\n\n\t\t\t    else if (x)\n\n\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t    }\n\n\t\t    init_get_bits(&s->gb, s->buffer, (dst - s->buffer)*8);\n\n\t\t    \n\n\t\t    dprintf(\"escaping removed %d bytes\\n\",\n\n\t\t\t(buf_end - buf_ptr) - (dst - s->buffer));\n\n\t\t}\n\n\t\telse\n\n\t\t    init_get_bits(&s->gb, buf_ptr, (buf_end - buf_ptr)*8);\n\n\t\t\n\n\t\ts->start_code = start_code;\n\n                if(s->avctx->debug & FF_DEBUG_STARTCODE){\n\n                    printf(\"startcode: %X\\n\", start_code);\n\n                }\n\n\n\n\t\t/* process markers */\n\n\t\tif (start_code >= 0xd0 && start_code <= 0xd7) {\n\n\t\t    dprintf(\"restart marker: %d\\n\", start_code&0x0f);\n\n\t\t} else if (s->first_picture) {\n\n\t\t    /* APP fields */\n\n\t\t    if (start_code >= 0xe0 && start_code <= 0xef)\n\n\t\t\tmjpeg_decode_app(s);\n\n\t\t    /* Comment */\n\n\t\t    else if (start_code == COM)\n\n\t\t\tmjpeg_decode_com(s);\n\n\t\t}\n\n\n\n                switch(start_code) {\n\n                case SOI:\n\n\t\t    s->restart_interval = 0;\n\n                    /* nothing to do on SOI */\n\n                    break;\n\n                case DQT:\n\n                    mjpeg_decode_dqt(s);\n\n                    break;\n\n                case DHT:\n\n                    mjpeg_decode_dht(s);\n\n                    break;\n\n                case SOF0:\n\n                    s->lossless=0;\n\n                    if (mjpeg_decode_sof(s) < 0) \n\n\t\t\treturn -1;\n\n                    break;\n\n                case SOF3:\n\n                    s->lossless=1;\n\n                    if (mjpeg_decode_sof(s) < 0) \n\n\t\t\treturn -1;\n\n                    break;\n\n\t\tcase EOI:\n\neoi_parser:\n\n\t\t    {\n\n                        if (s->interlaced) {\n\n                            s->bottom_field ^= 1;\n\n                            /* if not bottom field, do not output image yet */\n\n                            if (s->bottom_field)\n\n                                goto not_the_end;\n\n                        }\n\n                        for(i=0;i<3;i++) {\n\n                            picture->data[i] = s->current_picture[i];\n\n\t\t\t    picture->linesize[i] = (s->interlaced) ?\n\n\t\t\t\ts->linesize[i] >> 1 : s->linesize[i];\n\n                        }\n\n                        *data_size = sizeof(AVPicture);\n\n                        avctx->height = s->height;\n\n                        if (s->interlaced)\n\n                            avctx->height *= 2;\n\n                        avctx->width = s->width;\n\n                        /* XXX: not complete test ! */\n\n                        switch((s->h_count[0] << 4) | s->v_count[0]) {\n\n                        case 0x11:\n\n                            if(s->rgb){\n\n                                avctx->pix_fmt = PIX_FMT_RGBA32;\n\n                            }else\n\n                                avctx->pix_fmt = PIX_FMT_YUV444P;\n\n                            break;\n\n                        case 0x21:\n\n                            avctx->pix_fmt = PIX_FMT_YUV422P;\n\n                            break;\n\n                        default:\n\n                        case 0x22:\n\n                            avctx->pix_fmt = PIX_FMT_YUV420P;\n\n                            break;\n\n                        }\n\n                        /* dummy quality */\n\n                        /* XXX: infer it with matrix */\n\n//                    \tavctx->quality = 3; \n\n                        goto the_end;\n\n                    }\n\n\t\t    break;\n\n                case SOS:\n\n                    mjpeg_decode_sos(s);\n\n\t\t    /* buggy avid puts EOI every 10-20th frame */\n\n\t\t    /* if restart period is over process EOI */\n\n\t\t    if ((s->buggy_avid && !s->interlaced) || s->restart_interval)\n\n\t\t\tgoto eoi_parser;\n\n                    break;\n\n\t\tcase DRI:\n\n\t\t    mjpeg_decode_dri(s);\n\n\t\t    break;\n\n\t\tcase SOF1:\n\n\t\tcase SOF2:\n\n\t\tcase SOF5:\n\n\t\tcase SOF6:\n\n\t\tcase SOF7:\n\n\t\tcase SOF9:\n\n\t\tcase SOF10:\n\n\t\tcase SOF11:\n\n\t\tcase SOF13:\n\n\t\tcase SOF14:\n\n\t\tcase SOF15:\n\n\t\tcase JPG:\n\n\t\t    printf(\"mjpeg: unsupported coding type (%x)\\n\", start_code);\n\n\t\t    break;\n\n//\t\tdefault:\n\n//\t\t    printf(\"mjpeg: unsupported marker (%x)\\n\", start_code);\n\n//\t\t    break;\n\n                }\n\n\n\nnot_the_end:\n\n\t\t/* eof process start code */\n\n\t\tbuf_ptr += (get_bits_count(&s->gb)+7)/8;\n\n\t\tdprintf(\"marker parser used %d bytes (%d bits)\\n\",\n\n\t\t    (get_bits_count(&s->gb)+7)/8, get_bits_count(&s->gb));\n\n            }\n\n        }\n\n    }\n\nthe_end:\n\n    dprintf(\"mjpeg decode frame unused %d bytes\\n\", buf_end - buf_ptr);\n\n//    return buf_end - buf_ptr;\n\n    return buf_ptr - buf;\n\n}\n", "idx": 23900}
{"project": "FFmpeg", "commit_id": "8155233413540c63e53a620ff5734fb4b0635611", "target": 1, "func": "static int int_pow(int i, int *exp_ptr)\n\n{\n\n    int e, er, eq, j;\n\n    int a, a1;\n\n    \n\n    /* renormalize */\n\n    a = i;\n\n    e = POW_FRAC_BITS;\n\n    while (a < (1 << (POW_FRAC_BITS - 1))) {\n\n        a = a << 1;\n\n        e--;\n\n    }\n\n    a -= (1 << POW_FRAC_BITS);\n\n    a1 = 0;\n\n    for(j = DEV_ORDER - 1; j >= 0; j--)\n\n        a1 = POW_MULL(a, dev_4_3_coefs[j] + a1);\n\n    a = (1 << POW_FRAC_BITS) + a1;\n\n    /* exponent compute (exact) */\n\n    e = e * 4;\n\n    er = e % 3;\n\n    eq = e / 3;\n\n    a = POW_MULL(a, pow_mult3[er]);\n\n    while (a >= 2 * POW_FRAC_ONE) {\n\n        a = a >> 1;\n\n        eq++;\n\n    }\n\n    /* convert to float */\n\n    while (a < POW_FRAC_ONE) {\n\n        a = a << 1;\n\n        eq--;\n\n    }\n\n    /* now POW_FRAC_ONE <= a < 2 * POW_FRAC_ONE */\n\n#if (POW_FRAC_BITS - 1) > FRAC_BITS\n\n    a = (a + (1 << (POW_FRAC_BITS - FRAC_BITS - 1))) >> (POW_FRAC_BITS - FRAC_BITS);\n\n    /* correct overflow */\n\n    if (a >= 2 * (1 << FRAC_BITS)) {\n\n        a = a >> 1;\n\n        eq++;\n\n    }\n\n#endif\n\n    *exp_ptr = eq;\n\n    return a;\n\n}\n", "idx": 23903}
{"project": "FFmpeg", "commit_id": "4fa706a4a64f9e06b08c1a42a62893ff2f7de82f", "target": 1, "func": "static av_cold int svq3_decode_init(AVCodecContext *avctx)\n\n{\n\n    SVQ3Context *svq3 = avctx->priv_data;\n\n    H264Context *h = &svq3->h;\n\n    MpegEncContext *s = &h->s;\n\n    int m;\n\n    unsigned char *extradata;\n\n    unsigned char *extradata_end;\n\n    unsigned int size;\n\n    int marker_found = 0;\n\n\n\n    if (ff_h264_decode_init(avctx) < 0)\n\n        return -1;\n\n\n\n    s->flags  = avctx->flags;\n\n    s->flags2 = avctx->flags2;\n\n    s->unrestricted_mv = 1;\n\n    h->is_complex=1;\n\n    h->sps.chroma_format_idc = 1;\n\n    avctx->pix_fmt = avctx->codec->pix_fmts[0];\n\n\n\n    if (!s->context_initialized) {\n\n        h->chroma_qp[0] = h->chroma_qp[1] = 4;\n\n\n\n        svq3->halfpel_flag  = 1;\n\n        svq3->thirdpel_flag = 1;\n\n        svq3->unknown_flag  = 0;\n\n\n\n\n\n        /* prowl for the \"SEQH\" marker in the extradata */\n\n        extradata = (unsigned char *)avctx->extradata;\n\n        extradata_end = avctx->extradata + avctx->extradata_size;\n\n        if (extradata) {\n\n            for (m = 0; m + 8 < avctx->extradata_size; m++) {\n\n                if (!memcmp(extradata, \"SEQH\", 4)) {\n\n                    marker_found = 1;\n\n                    break;\n\n                }\n\n                extradata++;\n\n            }\n\n        }\n\n\n\n        /* if a match was found, parse the extra data */\n\n        if (marker_found) {\n\n\n\n            GetBitContext gb;\n\n            int frame_size_code;\n\n\n\n            size = AV_RB32(&extradata[4]);\n\n            if (size > extradata_end - extradata - 8)\n\n                return AVERROR_INVALIDDATA;\n\n            init_get_bits(&gb, extradata + 8, size*8);\n\n\n\n            /* 'frame size code' and optional 'width, height' */\n\n            frame_size_code = get_bits(&gb, 3);\n\n            switch (frame_size_code) {\n\n                case 0: avctx->width = 160; avctx->height = 120; break;\n\n                case 1: avctx->width = 128; avctx->height =  96; break;\n\n                case 2: avctx->width = 176; avctx->height = 144; break;\n\n                case 3: avctx->width = 352; avctx->height = 288; break;\n\n                case 4: avctx->width = 704; avctx->height = 576; break;\n\n                case 5: avctx->width = 240; avctx->height = 180; break;\n\n                case 6: avctx->width = 320; avctx->height = 240; break;\n\n                case 7:\n\n                    avctx->width  = get_bits(&gb, 12);\n\n                    avctx->height = get_bits(&gb, 12);\n\n                    break;\n\n            }\n\n\n\n            svq3->halfpel_flag  = get_bits1(&gb);\n\n            svq3->thirdpel_flag = get_bits1(&gb);\n\n\n\n            /* unknown fields */\n\n            skip_bits1(&gb);\n\n            skip_bits1(&gb);\n\n            skip_bits1(&gb);\n\n            skip_bits1(&gb);\n\n\n\n            s->low_delay = get_bits1(&gb);\n\n\n\n            /* unknown field */\n\n            skip_bits1(&gb);\n\n\n\n            while (get_bits1(&gb)) {\n\n                skip_bits(&gb, 8);\n\n            }\n\n\n\n            svq3->unknown_flag = get_bits1(&gb);\n\n            avctx->has_b_frames = !s->low_delay;\n\n            if (svq3->unknown_flag) {\n\n#if CONFIG_ZLIB\n\n                unsigned watermark_width  = svq3_get_ue_golomb(&gb);\n\n                unsigned watermark_height = svq3_get_ue_golomb(&gb);\n\n                int u1 = svq3_get_ue_golomb(&gb);\n\n                int u2 = get_bits(&gb, 8);\n\n                int u3 = get_bits(&gb, 2);\n\n                int u4 = svq3_get_ue_golomb(&gb);\n\n                unsigned long buf_len = watermark_width*watermark_height*4;\n\n                int offset = (get_bits_count(&gb)+7)>>3;\n\n                uint8_t *buf;\n\n\n\n                if ((uint64_t)watermark_width*4 > UINT_MAX/watermark_height)\n\n                    return -1;\n\n\n\n                buf = av_malloc(buf_len);\n\n                av_log(avctx, AV_LOG_DEBUG, \"watermark size: %dx%d\\n\", watermark_width, watermark_height);\n\n                av_log(avctx, AV_LOG_DEBUG, \"u1: %x u2: %x u3: %x compressed data size: %d offset: %d\\n\", u1, u2, u3, u4, offset);\n\n                if (uncompress(buf, &buf_len, extradata + 8 + offset, size - offset) != Z_OK) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"could not uncompress watermark logo\\n\");\n\n                    av_free(buf);\n\n                    return -1;\n\n                }\n\n                svq3->watermark_key = ff_svq1_packet_checksum(buf, buf_len, 0);\n\n                svq3->watermark_key = svq3->watermark_key << 16 | svq3->watermark_key;\n\n                av_log(avctx, AV_LOG_DEBUG, \"watermark key %#x\\n\", svq3->watermark_key);\n\n                av_free(buf);\n\n#else\n\n                av_log(avctx, AV_LOG_ERROR, \"this svq3 file contains watermark which need zlib support compiled in\\n\");\n\n                return -1;\n\n#endif\n\n            }\n\n        }\n\n\n\n        s->width  = avctx->width;\n\n        s->height = avctx->height;\n\n\n\n        if (ff_MPV_common_init(s) < 0)\n\n            return -1;\n\n\n\n        h->b_stride = 4*s->mb_width;\n\n\n\n        if (ff_h264_alloc_tables(h) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"svq3 memory allocation failed\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23905}
{"project": "FFmpeg", "commit_id": "7c249d4fbaf4431b20a90a3c942f3370c0039d9e", "target": 0, "func": "int ff_vp56_decode_frame(AVCodecContext *avctx, void *data, int *data_size,\n\n                         AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    VP56Context *s = avctx->priv_data;\n\n    AVFrame *const p = s->framep[VP56_FRAME_CURRENT];\n\n    int remaining_buf_size = avpkt->size;\n\n    int is_alpha, av_uninit(alpha_offset);\n\n\n\n    if (s->has_alpha) {\n\n        if (remaining_buf_size < 3)\n\n            return -1;\n\n        alpha_offset = bytestream_get_be24(&buf);\n\n        remaining_buf_size -= 3;\n\n        if (remaining_buf_size < alpha_offset)\n\n            return -1;\n\n    }\n\n\n\n    for (is_alpha=0; is_alpha < 1+s->has_alpha; is_alpha++) {\n\n        int mb_row, mb_col, mb_row_flip, mb_offset = 0;\n\n        int block, y, uv, stride_y, stride_uv;\n\n        int golden_frame = 0;\n\n        int res;\n\n\n\n        s->modelp = &s->models[is_alpha];\n\n\n\n        res = s->parse_header(s, buf, remaining_buf_size, &golden_frame);\n\n        if (!res)\n\n            return -1;\n\n\n\n        if (res == 2) {\n\n            int i;\n\n            for (i = 0; i < 4; i++) {\n\n                if (s->frames[i].data[0])\n\n                    avctx->release_buffer(avctx, &s->frames[i]);\n\n            }\n\n            if (is_alpha)\n\n                return -1;\n\n        }\n\n\n\n        if (!is_alpha) {\n\n            p->reference = 1;\n\n            if (avctx->get_buffer(avctx, p) < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n                return -1;\n\n            }\n\n\n\n            if (res == 2)\n\n                if (vp56_size_changed(avctx)) {\n\n                    avctx->release_buffer(avctx, p);\n\n                    return -1;\n\n                }\n\n        }\n\n\n\n        if (p->key_frame) {\n\n            p->pict_type = AV_PICTURE_TYPE_I;\n\n            s->default_models_init(s);\n\n            for (block=0; block<s->mb_height*s->mb_width; block++)\n\n                s->macroblocks[block].type = VP56_MB_INTRA;\n\n        } else {\n\n            p->pict_type = AV_PICTURE_TYPE_P;\n\n            vp56_parse_mb_type_models(s);\n\n            s->parse_vector_models(s);\n\n            s->mb_type = VP56_MB_INTER_NOVEC_PF;\n\n        }\n\n\n\n        s->parse_coeff_models(s);\n\n\n\n        memset(s->prev_dc, 0, sizeof(s->prev_dc));\n\n        s->prev_dc[1][VP56_FRAME_CURRENT] = 128;\n\n        s->prev_dc[2][VP56_FRAME_CURRENT] = 128;\n\n\n\n        for (block=0; block < 4*s->mb_width+6; block++) {\n\n            s->above_blocks[block].ref_frame = VP56_FRAME_NONE;\n\n            s->above_blocks[block].dc_coeff = 0;\n\n            s->above_blocks[block].not_null_dc = 0;\n\n        }\n\n        s->above_blocks[2*s->mb_width + 2].ref_frame = VP56_FRAME_CURRENT;\n\n        s->above_blocks[3*s->mb_width + 4].ref_frame = VP56_FRAME_CURRENT;\n\n\n\n        stride_y  = p->linesize[0];\n\n        stride_uv = p->linesize[1];\n\n\n\n        if (s->flip < 0)\n\n            mb_offset = 7;\n\n\n\n        /* main macroblocks loop */\n\n        for (mb_row=0; mb_row<s->mb_height; mb_row++) {\n\n            if (s->flip < 0)\n\n                mb_row_flip = s->mb_height - mb_row - 1;\n\n            else\n\n                mb_row_flip = mb_row;\n\n\n\n            for (block=0; block<4; block++) {\n\n                s->left_block[block].ref_frame = VP56_FRAME_NONE;\n\n                s->left_block[block].dc_coeff = 0;\n\n                s->left_block[block].not_null_dc = 0;\n\n            }\n\n            memset(s->coeff_ctx, 0, sizeof(s->coeff_ctx));\n\n            memset(s->coeff_ctx_last, 24, sizeof(s->coeff_ctx_last));\n\n\n\n            s->above_block_idx[0] = 1;\n\n            s->above_block_idx[1] = 2;\n\n            s->above_block_idx[2] = 1;\n\n            s->above_block_idx[3] = 2;\n\n            s->above_block_idx[4] = 2*s->mb_width + 2 + 1;\n\n            s->above_block_idx[5] = 3*s->mb_width + 4 + 1;\n\n\n\n            s->block_offset[s->frbi] = (mb_row_flip*16 + mb_offset) * stride_y;\n\n            s->block_offset[s->srbi] = s->block_offset[s->frbi] + 8*stride_y;\n\n            s->block_offset[1] = s->block_offset[0] + 8;\n\n            s->block_offset[3] = s->block_offset[2] + 8;\n\n            s->block_offset[4] = (mb_row_flip*8 + mb_offset) * stride_uv;\n\n            s->block_offset[5] = s->block_offset[4];\n\n\n\n            for (mb_col=0; mb_col<s->mb_width; mb_col++) {\n\n                vp56_decode_mb(s, mb_row, mb_col, is_alpha);\n\n\n\n                for (y=0; y<4; y++) {\n\n                    s->above_block_idx[y] += 2;\n\n                    s->block_offset[y] += 16;\n\n                }\n\n\n\n                for (uv=4; uv<6; uv++) {\n\n                    s->above_block_idx[uv] += 1;\n\n                    s->block_offset[uv] += 8;\n\n                }\n\n            }\n\n        }\n\n\n\n        if (p->key_frame || golden_frame) {\n\n            if (s->framep[VP56_FRAME_GOLDEN]->data[0] &&\n\n                s->framep[VP56_FRAME_GOLDEN] != s->framep[VP56_FRAME_GOLDEN2])\n\n                avctx->release_buffer(avctx, s->framep[VP56_FRAME_GOLDEN]);\n\n            s->framep[VP56_FRAME_GOLDEN] = p;\n\n        }\n\n\n\n        if (s->has_alpha) {\n\n            FFSWAP(AVFrame *, s->framep[VP56_FRAME_GOLDEN],\n\n                              s->framep[VP56_FRAME_GOLDEN2]);\n\n            buf += alpha_offset;\n\n            remaining_buf_size -= alpha_offset;\n\n        }\n\n    }\n\n\n\n    if (s->framep[VP56_FRAME_PREVIOUS] == s->framep[VP56_FRAME_GOLDEN] ||\n\n        s->framep[VP56_FRAME_PREVIOUS] == s->framep[VP56_FRAME_GOLDEN2]) {\n\n        if (s->framep[VP56_FRAME_UNUSED] != s->framep[VP56_FRAME_GOLDEN] &&\n\n            s->framep[VP56_FRAME_UNUSED] != s->framep[VP56_FRAME_GOLDEN2])\n\n            FFSWAP(AVFrame *, s->framep[VP56_FRAME_PREVIOUS],\n\n                              s->framep[VP56_FRAME_UNUSED]);\n\n        else\n\n            FFSWAP(AVFrame *, s->framep[VP56_FRAME_PREVIOUS],\n\n                              s->framep[VP56_FRAME_UNUSED2]);\n\n    } else if (s->framep[VP56_FRAME_PREVIOUS]->data[0])\n\n        avctx->release_buffer(avctx, s->framep[VP56_FRAME_PREVIOUS]);\n\n    FFSWAP(AVFrame *, s->framep[VP56_FRAME_CURRENT],\n\n                      s->framep[VP56_FRAME_PREVIOUS]);\n\n\n\n    p->qstride = 0;\n\n    p->qscale_table = s->qscale_table;\n\n    p->qscale_type = FF_QSCALE_TYPE_VP56;\n\n    *(AVFrame*)data = *p;\n\n    *data_size = sizeof(AVFrame);\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 23906}
{"project": "FFmpeg", "commit_id": "6a63ff19b6a7fe3bc32c7fb4a62fca8f65786432", "target": 0, "func": "static int mov_read_esds(MOVContext *c, ByteIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st = c->fc->streams[c->fc->nb_streams-1];\n\n    int tag, len;\n\n\n\n    get_be32(pb); /* version + flags */\n\n    len = mp4_read_descr(c, pb, &tag);\n\n    if (tag == MP4ESDescrTag) {\n\n        get_be16(pb); /* ID */\n\n        get_byte(pb); /* priority */\n\n    } else\n\n        get_be16(pb); /* ID */\n\n\n\n    len = mp4_read_descr(c, pb, &tag);\n\n    if (tag == MP4DecConfigDescrTag) {\n\n        int object_type_id = get_byte(pb);\n\n        get_byte(pb); /* stream type */\n\n        get_be24(pb); /* buffer size db */\n\n        get_be32(pb); /* max bitrate */\n\n        get_be32(pb); /* avg bitrate */\n\n\n\n        st->codec->codec_id= ff_codec_get_id(ff_mp4_obj_type, object_type_id);\n\n        dprintf(c->fc, \"esds object type id %d\\n\", object_type_id);\n\n        len = mp4_read_descr(c, pb, &tag);\n\n        if (tag == MP4DecSpecificDescrTag) {\n\n            dprintf(c->fc, \"Specific MPEG4 header len=%d\\n\", len);\n\n            if((uint64_t)len > (1<<30))\n\n                return -1;\n\n            st->codec->extradata = av_mallocz(len + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (!st->codec->extradata)\n\n                return AVERROR(ENOMEM);\n\n            get_buffer(pb, st->codec->extradata, len);\n\n            st->codec->extradata_size = len;\n\n            if (st->codec->codec_id == CODEC_ID_AAC) {\n\n                MPEG4AudioConfig cfg;\n\n                ff_mpeg4audio_get_config(&cfg, st->codec->extradata,\n\n                                         st->codec->extradata_size);\n\n                if (cfg.chan_config > 7)\n\n                    return -1;\n\n                st->codec->channels = ff_mpeg4audio_channels[cfg.chan_config];\n\n                if (cfg.object_type == 29 && cfg.sampling_index < 3) // old mp3on4\n\n                    st->codec->sample_rate = ff_mpa_freq_tab[cfg.sampling_index];\n\n                else\n\n                    st->codec->sample_rate = cfg.sample_rate; // ext sample rate ?\n\n                dprintf(c->fc, \"mp4a config channels %d obj %d ext obj %d \"\n\n                        \"sample rate %d ext sample rate %d\\n\", st->codec->channels,\n\n                        cfg.object_type, cfg.ext_object_type,\n\n                        cfg.sample_rate, cfg.ext_sample_rate);\n\n                if (!(st->codec->codec_id = ff_codec_get_id(mp4_audio_types,\n\n                                                            cfg.object_type)))\n\n                    st->codec->codec_id = CODEC_ID_AAC;\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 23907}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "av_cold int ff_nvenc_encode_close(AVCodecContext *avctx)\n\n{\n\n    NVENCContext *ctx               = avctx->priv_data;\n\n    NV_ENCODE_API_FUNCTION_LIST *nv = &ctx->nvel.nvenc_funcs;\n\n    int i;\n\n\n\n    av_frame_free(&avctx->coded_frame);\n\n\n\n    if (ctx->in) {\n\n        for (i = 0; i < ctx->nb_surfaces; ++i) {\n\n            nv->nvEncDestroyInputBuffer(ctx->nvenc_ctx, ctx->in[i].in);\n\n            nv->nvEncDestroyBitstreamBuffer(ctx->nvenc_ctx, ctx->out[i].out);\n\n        }\n\n    }\n\n\n\n    av_freep(&ctx->in);\n\n    av_freep(&ctx->out);\n\n\n\n    if (ctx->nvenc_ctx)\n\n        nv->nvEncDestroyEncoder(ctx->nvenc_ctx);\n\n\n\n    if (ctx->cu_context)\n\n        ctx->nvel.cu_ctx_destroy(ctx->cu_context);\n\n\n\n    if (ctx->nvel.nvenc)\n\n        dlclose(ctx->nvel.nvenc);\n\n\n\n    if (ctx->nvel.cuda)\n\n        dlclose(ctx->nvel.cuda);\n\n\n\n    return 0;\n\n}\n", "idx": 23908}
{"project": "FFmpeg", "commit_id": "4b1f5e5090abed6c618c8ba380cd7d28d140f867", "target": 0, "func": "static QDM2SubPNode *qdm2_search_subpacket_type_in_list(QDM2SubPNode *list,\n\n                                                        int type)\n\n{\n\n    while (list != NULL && list->packet != NULL) {\n\n        if (list->packet->type == type)\n\n            return list;\n\n        list = list->next;\n\n    }\n\n    return NULL;\n\n}\n", "idx": 23909}
{"project": "FFmpeg", "commit_id": "fa6716c66d31385a0f306c2a3f46f44e0d928ff9", "target": 0, "func": "static int segment_end(AVFormatContext *s, int write_trailer, int is_last)\n\n{\n\n    SegmentContext *seg = s->priv_data;\n\n    AVFormatContext *oc = seg->avf;\n\n    int ret = 0;\n\n\n\n    av_write_frame(oc, NULL); /* Flush any buffered data (fragmented mp4) */\n\n    if (write_trailer)\n\n        ret = av_write_trailer(oc);\n\n\n\n    if (ret < 0)\n\n        av_log(s, AV_LOG_ERROR, \"Failure occurred when ending segment '%s'\\n\",\n\n               oc->filename);\n\n\n\n    if (seg->list) {\n\n        if (seg->list_size || seg->list_type == LIST_TYPE_M3U8) {\n\n            SegmentListEntry *entry = av_mallocz(sizeof(*entry));\n\n            if (!entry) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto end;\n\n            }\n\n\n\n            /* append new element */\n\n            memcpy(entry, &seg->cur_entry, sizeof(*entry));\n\n            if (!seg->segment_list_entries)\n\n                seg->segment_list_entries = seg->segment_list_entries_end = entry;\n\n            else\n\n                seg->segment_list_entries_end->next = entry;\n\n            seg->segment_list_entries_end = entry;\n\n\n\n            /* drop first item */\n\n            if (seg->list_size && seg->segment_count > seg->list_size) {\n\n                entry = seg->segment_list_entries;\n\n                seg->segment_list_entries = seg->segment_list_entries->next;\n\n                av_free(entry->filename);\n\n                av_freep(&entry);\n\n            }\n\n\n\n            avio_close(seg->list_pb);\n\n            if ((ret = segment_list_open(s)) < 0)\n\n                goto end;\n\n            for (entry = seg->segment_list_entries; entry; entry = entry->next)\n\n                segment_list_print_entry(seg->list_pb, seg->list_type, entry, s);\n\n            if (seg->list_type == LIST_TYPE_M3U8 && is_last)\n\n                avio_printf(seg->list_pb, \"#EXT-X-ENDLIST\\n\");\n\n        } else {\n\n            segment_list_print_entry(seg->list_pb, seg->list_type, &seg->cur_entry, s);\n\n        }\n\n        avio_flush(seg->list_pb);\n\n    }\n\n\n\n    av_log(s, AV_LOG_VERBOSE, \"segment:'%s' count:%d ended\\n\",\n\n           seg->avf->filename, seg->segment_count);\n\n    seg->segment_count++;\n\n\n\nend:\n\n    avio_close(oc->pb);\n\n\n\n    return ret;\n\n}\n", "idx": 23910}
{"project": "FFmpeg", "commit_id": "369cb092ecbbaff20bb0a2a1d60536c3bc04a8f0", "target": 1, "func": "static void get_default_channel_layouts(OutputStream *ost, InputStream *ist)\n\n{\n\n    char layout_name[256];\n\n    AVCodecContext *enc = ost->st->codec;\n\n    AVCodecContext *dec = ist->st->codec;\n\n\n\n    if (dec->channel_layout &&\n\n        av_get_channel_layout_nb_channels(dec->channel_layout) != dec->channels) {\n\n        av_get_channel_layout_string(layout_name, sizeof(layout_name),\n\n                                     dec->channels, dec->channel_layout);\n\n        av_log(NULL, AV_LOG_ERROR, \"New channel layout (%s) is invalid\\n\",\n\n               layout_name);\n\n        dec->channel_layout = 0;\n\n    }\n\n    if (!dec->channel_layout) {\n\n        if (enc->channel_layout && dec->channels == enc->channels) {\n\n            dec->channel_layout = enc->channel_layout;\n\n        } else {\n\n            dec->channel_layout = av_get_default_channel_layout(dec->channels);\n\n\n\n            if (!dec->channel_layout) {\n\n                av_log(NULL, AV_LOG_FATAL, \"Unable to find default channel \"\n\n                       \"layout for Input Stream #%d.%d\\n\", ist->file_index,\n\n                       ist->st->index);\n\n                exit_program(1);\n\n            }\n\n        }\n\n        av_get_channel_layout_string(layout_name, sizeof(layout_name),\n\n                                     dec->channels, dec->channel_layout);\n\n        av_log(NULL, AV_LOG_WARNING, \"Guessed Channel Layout for  Input Stream \"\n\n               \"#%d.%d : %s\\n\", ist->file_index, ist->st->index, layout_name);\n\n    }\n\n    if (!enc->channel_layout) {\n\n        if (dec->channels == enc->channels) {\n\n            enc->channel_layout = dec->channel_layout;\n\n            return;\n\n        } else {\n\n            enc->channel_layout = av_get_default_channel_layout(enc->channels);\n\n        }\n\n        if (!enc->channel_layout) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Unable to find default channel layout \"\n\n                   \"for Output Stream #%d.%d\\n\", ost->file_index,\n\n                   ost->st->index);\n\n            exit_program(1);\n\n        }\n\n        av_get_channel_layout_string(layout_name, sizeof(layout_name),\n\n                                     enc->channels, enc->channel_layout);\n\n        av_log(NULL, AV_LOG_WARNING, \"Guessed Channel Layout for Output Stream \"\n\n               \"#%d.%d : %s\\n\", ost->file_index, ost->st->index, layout_name);\n\n    }\n\n}\n", "idx": 23913}
{"project": "FFmpeg", "commit_id": "78a5fc4579deb63e1e6b93cd4d6e2ec2dceff931", "target": 1, "func": "static enum AVPixelFormat get_format(HEVCContext *s, const HEVCSPS *sps)\n\n{\n\n    #define HWACCEL_MAX (CONFIG_HEVC_DXVA2_HWACCEL + CONFIG_HEVC_D3D11VA_HWACCEL + CONFIG_HEVC_VAAPI_HWACCEL + CONFIG_HEVC_VDPAU_HWACCEL)\n\n    enum AVPixelFormat pix_fmts[HWACCEL_MAX + 2], *fmt = pix_fmts;\n\n\n\n    switch (sps->pix_fmt) {\n\n    case AV_PIX_FMT_YUV420P:\n\n    case AV_PIX_FMT_YUVJ420P:\n\n#if CONFIG_HEVC_DXVA2_HWACCEL\n\n        *fmt++ = AV_PIX_FMT_DXVA2_VLD;\n\n#endif\n\n#if CONFIG_HEVC_D3D11VA_HWACCEL\n\n        *fmt++ = AV_PIX_FMT_D3D11VA_VLD;\n\n#endif\n\n#if CONFIG_HEVC_VAAPI_HWACCEL\n\n        *fmt++ = AV_PIX_FMT_VAAPI;\n\n#endif\n\n#if CONFIG_HEVC_VDPAU_HWACCEL\n\n        *fmt++ = AV_PIX_FMT_VDPAU;\n\n#endif\n\n        break;\n\n    case AV_PIX_FMT_YUV420P10:\n\n#if CONFIG_HEVC_DXVA2_HWACCEL\n\n        *fmt++ = AV_PIX_FMT_DXVA2_VLD;\n\n#endif\n\n#if CONFIG_HEVC_D3D11VA_HWACCEL\n\n        *fmt++ = AV_PIX_FMT_D3D11VA_VLD;\n\n#endif\n\n#if CONFIG_HEVC_VAAPI_HWACCEL\n\n        *fmt++ = AV_PIX_FMT_VAAPI;\n\n#endif\n\n        break;\n\n    }\n\n\n\n    *fmt++ = sps->pix_fmt;\n\n    *fmt = AV_PIX_FMT_NONE;\n\n\n\n    return ff_get_format(s->avctx, pix_fmts);\n\n}\n", "idx": 23915}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int pnm_encode_init(AVCodecContext *avctx)\n\n{\n\n    avctx->coded_frame = av_frame_alloc();\n\n    if (!avctx->coded_frame)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;\n\n    avctx->coded_frame->key_frame = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 23920}
{"project": "FFmpeg", "commit_id": "d24888ef19ba38b787b11d1ee091a3d94920c76a", "target": 0, "func": "static int ljpeg_decode_yuv_scan(MJpegDecodeContext *s, int predictor,\n\n                                 int point_transform, int nb_components)\n\n{\n\n    int i, mb_x, mb_y, mask;\n\n    int bits= (s->bits+7)&~7;\n\n    int resync_mb_y = 0;\n\n    int resync_mb_x = 0;\n\n\n\n    point_transform += bits - s->bits;\n\n    mask = ((1 << s->bits) - 1) << point_transform;\n\n\n\n    av_assert0(nb_components>=1 && nb_components<=4);\n\n\n\n    for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n\n        for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n            if (s->restart_interval && !s->restart_count){\n\n                s->restart_count = s->restart_interval;\n\n                resync_mb_x = mb_x;\n\n                resync_mb_y = mb_y;\n\n            }\n\n\n\n            if(!mb_x || mb_y == resync_mb_y || mb_y == resync_mb_y+1 && mb_x < resync_mb_x || s->interlaced){\n\n                int toprow  = mb_y == resync_mb_y || mb_y == resync_mb_y+1 && mb_x < resync_mb_x;\n\n                int leftcol = !mb_x || mb_y == resync_mb_y && mb_x == resync_mb_x;\n\n                for (i = 0; i < nb_components; i++) {\n\n                    uint8_t *ptr;\n\n                    uint16_t *ptr16;\n\n                    int n, h, v, x, y, c, j, linesize;\n\n                    n = s->nb_blocks[i];\n\n                    c = s->comp_index[i];\n\n                    h = s->h_scount[i];\n\n                    v = s->v_scount[i];\n\n                    x = 0;\n\n                    y = 0;\n\n                    linesize= s->linesize[c];\n\n\n\n                    if(bits>8) linesize /= 2;\n\n\n\n                    for(j=0; j<n; j++) {\n\n                        int pred, dc;\n\n\n\n                        dc = mjpeg_decode_dc(s, s->dc_index[i]);\n\n                        if(dc == 0xFFFFF)\n\n                            return -1;\n\n                        if(bits<=8){\n\n                        ptr = s->picture_ptr->data[c] + (linesize * (v * mb_y + y)) + (h * mb_x + x); //FIXME optimize this crap\n\n                        if(y==0 && toprow){\n\n                            if(x==0 && leftcol){\n\n                                pred= 1 << (bits - 1);\n\n                            }else{\n\n                                pred= ptr[-1];\n\n                            }\n\n                        }else{\n\n                            if(x==0 && leftcol){\n\n                                pred= ptr[-linesize];\n\n                            }else{\n\n                                PREDICT(pred, ptr[-linesize-1], ptr[-linesize], ptr[-1], predictor);\n\n                            }\n\n                        }\n\n\n\n                        if (s->interlaced && s->bottom_field)\n\n                            ptr += linesize >> 1;\n\n                        pred &= mask;\n\n                        *ptr= pred + (dc << point_transform);\n\n                        }else{\n\n                            ptr16 = (uint16_t*)(s->picture_ptr->data[c] + 2*(linesize * (v * mb_y + y)) + 2*(h * mb_x + x)); //FIXME optimize this crap\n\n                            if(y==0 && toprow){\n\n                                if(x==0 && leftcol){\n\n                                    pred= 1 << (bits - 1);\n\n                                }else{\n\n                                    pred= ptr16[-1];\n\n                                }\n\n                            }else{\n\n                                if(x==0 && leftcol){\n\n                                    pred= ptr16[-linesize];\n\n                                }else{\n\n                                    PREDICT(pred, ptr16[-linesize-1], ptr16[-linesize], ptr16[-1], predictor);\n\n                                }\n\n                            }\n\n\n\n                            if (s->interlaced && s->bottom_field)\n\n                                ptr16 += linesize >> 1;\n\n                            pred &= mask;\n\n                            *ptr16= pred + (dc << point_transform);\n\n                        }\n\n                        if (++x == h) {\n\n                            x = 0;\n\n                            y++;\n\n                        }\n\n                    }\n\n                }\n\n            } else {\n\n                for (i = 0; i < nb_components; i++) {\n\n                    uint8_t *ptr;\n\n                    uint16_t *ptr16;\n\n                    int n, h, v, x, y, c, j, linesize, dc;\n\n                    n        = s->nb_blocks[i];\n\n                    c        = s->comp_index[i];\n\n                    h        = s->h_scount[i];\n\n                    v        = s->v_scount[i];\n\n                    x        = 0;\n\n                    y        = 0;\n\n                    linesize = s->linesize[c];\n\n\n\n                    if(bits>8) linesize /= 2;\n\n\n\n                    for (j = 0; j < n; j++) {\n\n                        int pred;\n\n\n\n                        dc = mjpeg_decode_dc(s, s->dc_index[i]);\n\n                        if(dc == 0xFFFFF)\n\n                            return -1;\n\n                        if(bits<=8){\n\n                            ptr = s->picture_ptr->data[c] +\n\n                              (linesize * (v * mb_y + y)) +\n\n                              (h * mb_x + x); //FIXME optimize this crap\n\n                            PREDICT(pred, ptr[-linesize-1], ptr[-linesize], ptr[-1], predictor);\n\n\n\n                            pred &= mask;\n\n                            *ptr = pred + (dc << point_transform);\n\n                        }else{\n\n                            ptr16 = (uint16_t*)(s->picture_ptr->data[c] + 2*(linesize * (v * mb_y + y)) + 2*(h * mb_x + x)); //FIXME optimize this crap\n\n                            PREDICT(pred, ptr16[-linesize-1], ptr16[-linesize], ptr16[-1], predictor);\n\n\n\n                            pred &= mask;\n\n                            *ptr16= pred + (dc << point_transform);\n\n                        }\n\n\n\n                        if (++x == h) {\n\n                            x = 0;\n\n                            y++;\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n            if (s->restart_interval && !--s->restart_count) {\n\n                align_get_bits(&s->gb);\n\n                skip_bits(&s->gb, 16); /* skip RSTn */\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 23921}
{"project": "FFmpeg", "commit_id": "153b36fc62849e0e1540a43829794e0503994ebb", "target": 0, "func": "unsigned ff_dxva2_get_surface_index(const AVCodecContext *avctx,\n\n                                    const AVDXVAContext *ctx,\n\n                                    const AVFrame *frame)\n\n{\n\n    void *surface = get_surface(frame);\n\n    unsigned i;\n\n\n\n    for (i = 0; i < DXVA_CONTEXT_COUNT(avctx, ctx); i++) {\n\n#if CONFIG_D3D11VA\n\n        if (avctx->pix_fmt == AV_PIX_FMT_D3D11VA_VLD && ctx->d3d11va.surface[i] == surface)\n\n        {\n\n            D3D11_VIDEO_DECODER_OUTPUT_VIEW_DESC viewDesc;\n\n            ID3D11VideoDecoderOutputView_GetDesc(ctx->d3d11va.surface[i], &viewDesc);\n\n            return viewDesc.Texture2D.ArraySlice;\n\n        }\n\n#endif\n\n#if CONFIG_DXVA2\n\n        if (avctx->pix_fmt == AV_PIX_FMT_DXVA2_VLD && ctx->dxva2.surface[i] == surface)\n\n            return i;\n\n#endif\n\n    }\n\n\n\n    assert(0);\n\n    return 0;\n\n}\n", "idx": 23929}
{"project": "FFmpeg", "commit_id": "3f4fccf4d6d2a9a6db46bfca0e6fb648d8e3708b", "target": 0, "func": "static int read_table(AVFormatContext *avctx, AVStream *st,\n\n                       int (*parse)(AVFormatContext *avctx, AVStream *st,\n\n                                    const char *name, int size))\n\n{\n\n    int count, i;\n\n    AVIOContext *pb = avctx->pb;\n\n    avio_skip(pb, 4);\n\n    count = avio_rb32(pb);\n\n    avio_skip(pb, 4);\n\n    for (i = 0; i < count; i++) {\n\n        char name[17];\n\n        int size;\n\n        avio_read(pb, name, 16);\n\n        name[sizeof(name) - 1] = 0;\n\n        size = avio_rb32(pb);\n\n        if (size < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"entry size %d is invalid\\n\", size);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (parse(avctx, st, name, size) < 0) {\n\n            avpriv_request_sample(avctx, \"Variable %s\", name);\n\n            avio_skip(pb, size);\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 23940}
{"project": "FFmpeg", "commit_id": "87ecefdab0097537c5c30014e57b19113ab05eee", "target": 1, "func": "void avpriv_do_elbg(int *points, int dim, int numpoints, int *codebook,\n\n                int numCB, int max_steps, int *closest_cb,\n\n                AVLFG *rand_state)\n\n{\n\n    int dist;\n\n    elbg_data elbg_d;\n\n    elbg_data *elbg = &elbg_d;\n\n    int i, j, k, last_error, steps=0;\n\n    int *dist_cb = av_malloc(numpoints*sizeof(int));\n\n    int *size_part = av_malloc(numCB*sizeof(int));\n\n    cell *list_buffer = av_malloc(numpoints*sizeof(cell));\n\n    cell *free_cells;\n\n    int best_dist, best_idx = 0;\n\n\n\n    elbg->error = INT_MAX;\n\n    elbg->dim = dim;\n\n    elbg->numCB = numCB;\n\n    elbg->codebook = codebook;\n\n    elbg->cells = av_malloc(numCB*sizeof(cell *));\n\n    elbg->utility = av_malloc(numCB*sizeof(int));\n\n    elbg->nearest_cb = closest_cb;\n\n    elbg->points = points;\n\n    elbg->utility_inc = av_malloc(numCB*sizeof(int));\n\n    elbg->scratchbuf = av_malloc(5*dim*sizeof(int));\n\n\n\n    elbg->rand_state = rand_state;\n\n\n\n    do {\n\n        free_cells = list_buffer;\n\n        last_error = elbg->error;\n\n        steps++;\n\n        memset(elbg->utility, 0, numCB*sizeof(int));\n\n        memset(elbg->cells, 0, numCB*sizeof(cell *));\n\n\n\n        elbg->error = 0;\n\n\n\n        /* This loop evaluate the actual Voronoi partition. It is the most\n\n           costly part of the algorithm. */\n\n        for (i=0; i < numpoints; i++) {\n\n            best_dist = distance_limited(elbg->points + i*elbg->dim, elbg->codebook + best_idx*elbg->dim, dim, INT_MAX);\n\n            for (k=0; k < elbg->numCB; k++) {\n\n                dist = distance_limited(elbg->points + i*elbg->dim, elbg->codebook + k*elbg->dim, dim, best_dist);\n\n                if (dist < best_dist) {\n\n                    best_dist = dist;\n\n                    best_idx = k;\n\n                }\n\n            }\n\n            elbg->nearest_cb[i] = best_idx;\n\n            dist_cb[i] = best_dist;\n\n            elbg->error += dist_cb[i];\n\n            elbg->utility[elbg->nearest_cb[i]] += dist_cb[i];\n\n            free_cells->index = i;\n\n            free_cells->next = elbg->cells[elbg->nearest_cb[i]];\n\n            elbg->cells[elbg->nearest_cb[i]] = free_cells;\n\n            free_cells++;\n\n        }\n\n\n\n        do_shiftings(elbg);\n\n\n\n        memset(size_part, 0, numCB*sizeof(int));\n\n\n\n        memset(elbg->codebook, 0, elbg->numCB*dim*sizeof(int));\n\n\n\n        for (i=0; i < numpoints; i++) {\n\n            size_part[elbg->nearest_cb[i]]++;\n\n            for (j=0; j < elbg->dim; j++)\n\n                elbg->codebook[elbg->nearest_cb[i]*elbg->dim + j] +=\n\n                    elbg->points[i*elbg->dim + j];\n\n        }\n\n\n\n        for (i=0; i < elbg->numCB; i++)\n\n            vect_division(elbg->codebook + i*elbg->dim,\n\n                          elbg->codebook + i*elbg->dim, size_part[i], elbg->dim);\n\n\n\n    } while(((last_error - elbg->error) > DELTA_ERR_MAX*elbg->error) &&\n\n            (steps < max_steps));\n\n\n\n    av_free(dist_cb);\n\n    av_free(size_part);\n\n    av_free(elbg->utility);\n\n    av_free(list_buffer);\n\n    av_free(elbg->cells);\n\n    av_free(elbg->utility_inc);\n\n    av_free(elbg->scratchbuf);\n\n}\n", "idx": 23943}
{"project": "FFmpeg", "commit_id": "79c4a338e4b2bf0bc6f81c9f455994f673a92f78", "target": 0, "func": "static int xmv_read_packet(AVFormatContext *s,\n\n                           AVPacket *pkt)\n\n{\n\n    XMVDemuxContext *xmv = s->priv_data;\n\n    int result;\n\n\n\n    if (xmv->video.current_frame == xmv->video.frame_count) {\n\n        /* No frames left in this packet, so we fetch a new one */\n\n\n\n        result = xmv_fetch_new_packet(s);\n\n        if (result)\n\n            return result;\n\n    }\n\n\n\n    if (xmv->current_stream == 0) {\n\n        /* Fetch a video frame */\n\n\n\n        result = xmv_fetch_video_packet(s, pkt);\n\n    } else {\n\n        /* Fetch an audio frame */\n\n\n\n        result = xmv_fetch_audio_packet(s, pkt, xmv->current_stream - 1);\n\n    }\n\n    if (result)\n\n        return result;\n\n\n\n\n\n    /* Increase our counters */\n\n    if (++xmv->current_stream >= xmv->stream_count) {\n\n        xmv->current_stream       = 0;\n\n        xmv->video.current_frame += 1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23952}
{"project": "FFmpeg", "commit_id": "b00307ecd04f80d8021c50f9fa76fd452e54a3d1", "target": 0, "func": "static void sbr_mapping(AACContext *ac, SpectralBandReplication *sbr,\n\n                        SBRData *ch_data, int e_a[2])\n\n{\n\n    int e, i, m;\n\n\n\n    memset(ch_data->s_indexmapped[1], 0, 7*sizeof(ch_data->s_indexmapped[1]));\n\n    for (e = 0; e < ch_data->bs_num_env; e++) {\n\n        const unsigned int ilim = sbr->n[ch_data->bs_freq_res[e + 1]];\n\n        uint16_t *table = ch_data->bs_freq_res[e + 1] ? sbr->f_tablehigh : sbr->f_tablelow;\n\n        int k;\n\n\n\n        for (i = 0; i < ilim; i++)\n\n            for (m = table[i]; m < table[i + 1]; m++)\n\n                sbr->e_origmapped[e][m - sbr->kx[1]] = ch_data->env_facs[e+1][i];\n\n\n\n        // ch_data->bs_num_noise > 1 => 2 noise floors\n\n        k = (ch_data->bs_num_noise > 1) && (ch_data->t_env[e] >= ch_data->t_q[1]);\n\n        for (i = 0; i < sbr->n_q; i++)\n\n            for (m = sbr->f_tablenoise[i]; m < sbr->f_tablenoise[i + 1]; m++)\n\n                sbr->q_mapped[e][m - sbr->kx[1]] = ch_data->noise_facs[k+1][i];\n\n\n\n        for (i = 0; i < sbr->n[1]; i++) {\n\n            if (ch_data->bs_add_harmonic_flag) {\n\n                const unsigned int m_midpoint =\n\n                    (sbr->f_tablehigh[i] + sbr->f_tablehigh[i + 1]) >> 1;\n\n\n\n                ch_data->s_indexmapped[e + 1][m_midpoint - sbr->kx[1]] = ch_data->bs_add_harmonic[i] *\n\n                    (e >= e_a[1] || (ch_data->s_indexmapped[0][m_midpoint - sbr->kx[1]] == 1));\n\n            }\n\n        }\n\n\n\n        for (i = 0; i < ilim; i++) {\n\n            int additional_sinusoid_present = 0;\n\n            for (m = table[i]; m < table[i + 1]; m++) {\n\n                if (ch_data->s_indexmapped[e + 1][m - sbr->kx[1]]) {\n\n                    additional_sinusoid_present = 1;\n\n                    break;\n\n                }\n\n            }\n\n            memset(&sbr->s_mapped[e][table[i] - sbr->kx[1]], additional_sinusoid_present,\n\n                   (table[i + 1] - table[i]) * sizeof(sbr->s_mapped[e][0]));\n\n        }\n\n    }\n\n\n\n    memcpy(ch_data->s_indexmapped[0], ch_data->s_indexmapped[ch_data->bs_num_env], sizeof(ch_data->s_indexmapped[0]));\n\n}\n", "idx": 23964}
{"project": "FFmpeg", "commit_id": "656911d84da9205c004c17c9fb14815f86a7db93", "target": 1, "func": "static void draw_mandelbrot(AVFilterContext *ctx, uint32_t *color, int linesize, int64_t pts)\n\n{\n\n    MBContext *mb = ctx->priv;\n\n    int x,y,i, in_cidx=0, next_cidx=0, tmp_cidx;\n\n    double scale= mb->start_scale*pow(mb->end_scale/mb->start_scale, pts/mb->end_pts);\n\n    int use_zyklus=0;\n\n    fill_from_cache(ctx, NULL, &in_cidx, NULL, mb->start_y+scale*(-mb->h/2-0.5), scale);\n\n    tmp_cidx= in_cidx;\n\n    memset(color, 0, sizeof(*color)*mb->w);\n\n    for(y=0; y<mb->h; y++){\n\n        int y1= y+1;\n\n        const double ci=mb->start_y+scale*(y-mb->h/2);\n\n        fill_from_cache(ctx, NULL, &in_cidx, &next_cidx, ci, scale);\n\n        if(y1<mb->h){\n\n            memset(color+linesize*y1, 0, sizeof(*color)*mb->w);\n\n            fill_from_cache(ctx, color+linesize*y1, &tmp_cidx, NULL, ci + 3*scale/2, scale);\n\n        }\n\n\n\n        for(x=0; x<mb->w; x++){\n\n            float epsilon;\n\n            const double cr=mb->start_x+scale*(x-mb->w/2);\n\n            double zr=cr;\n\n            double zi=ci;\n\n            uint32_t c=0;\n\n            double dv= mb->dither / (double)(1LL<<32);\n\n            mb->dither= mb->dither*1664525+1013904223;\n\n\n\n            if(color[x + y*linesize] & 0xFF000000)\n\n                continue;\n\n            if(interpol(mb, color, x, y, linesize)){\n\n                if(next_cidx < mb->cache_allocated){\n\n                    mb->next_cache[next_cidx  ].p[0]= cr;\n\n                    mb->next_cache[next_cidx  ].p[1]= ci;\n\n                    mb->next_cache[next_cidx++].val = color[x + y*linesize];\n\n                }\n\n                continue;\n\n            }\n\n\n\n            use_zyklus= (x==0 || mb->inner!=BLACK ||color[x-1 + y*linesize] == 0xFF000000);\n\n            if(use_zyklus)\n\n                epsilon= scale*1*sqrt(SQR(x-mb->w/2) + SQR(y-mb->h/2))/mb->w;\n\n\n\n#define Z_Z2_C(outr,outi,inr,ini)\\\n\n            outr= inr*inr - ini*ini + cr;\\\n\n            outi= 2*inr*ini + ci;\n\n\n\n#define Z_Z2_C_ZYKLUS(outr,outi,inr,ini, Z)\\\n\n            Z_Z2_C(outr,outi,inr,ini)\\\n\n            if(use_zyklus){\\\n\n                if(Z && fabs(mb->zyklus[i>>1][0]-outr)+fabs(mb->zyklus[i>>1][1]-outi) <= epsilon)\\\n\n                    break;\\\n\n            }\\\n\n            mb->zyklus[i][0]= outr;\\\n\n            mb->zyklus[i][1]= outi;\\\n\n\n\n\n\n\n\n            for(i=0; i<mb->maxiter-8; i++){\n\n                double t;\n\n                Z_Z2_C_ZYKLUS(t, zi, zr, zi, 0)\n\n                i++;\n\n                Z_Z2_C_ZYKLUS(zr, zi, t, zi, 1)\n\n                i++;\n\n                Z_Z2_C_ZYKLUS(t, zi, zr, zi, 0)\n\n                i++;\n\n                Z_Z2_C_ZYKLUS(zr, zi, t, zi, 1)\n\n                i++;\n\n                Z_Z2_C_ZYKLUS(t, zi, zr, zi, 0)\n\n                i++;\n\n                Z_Z2_C_ZYKLUS(zr, zi, t, zi, 1)\n\n                i++;\n\n                Z_Z2_C_ZYKLUS(t, zi, zr, zi, 0)\n\n                i++;\n\n                Z_Z2_C_ZYKLUS(zr, zi, t, zi, 1)\n\n                if(zr*zr + zi*zi > mb->bailout){\n\n                    i-= FFMIN(7, i);\n\n                    for(; i<mb->maxiter; i++){\n\n                        zr= mb->zyklus[i][0];\n\n                        zi= mb->zyklus[i][1];\n\n                        if(zr*zr + zi*zi > mb->bailout){\n\n                            switch(mb->outer){\n\n                            case            ITERATION_COUNT: zr = i; break;\n\n                            case NORMALIZED_ITERATION_COUNT: zr= i + log2(log(mb->bailout) / log(zr*zr + zi*zi)); break;\n\n                            }\n\n                            c= lrintf((sin(zr)+1)*127) + lrintf((sin(zr/1.234)+1)*127)*256*256 + lrintf((sin(zr/100)+1)*127)*256;\n\n                            break;\n\n                        }\n\n                    }\n\n                    break;\n\n                }\n\n            }\n\n            if(!c){\n\n                if(mb->inner==PERIOD){\n\n                int j;\n\n                for(j=i-1; j; j--)\n\n                    if(SQR(mb->zyklus[j][0]-zr) + SQR(mb->zyklus[j][1]-zi) < epsilon*epsilon*10)\n\n                        break;\n\n                if(j){\n\n                    c= i-j;\n\n                    c= ((c<<5)&0xE0) + ((c<<16)&0xE000) + ((c<<27)&0xE00000);\n\n                }\n\n                }else if(mb->inner==CONVTIME){\n\n                    c= floor(i*255.0/mb->maxiter+dv)*0x010101;\n\n                } else if(mb->inner==MINCOL){\n\n                    int j;\n\n                    double closest=9999;\n\n                    int closest_index=0;\n\n                    for(j=i-1; j>=0; j--)\n\n                        if(SQR(mb->zyklus[j][0]) + SQR(mb->zyklus[j][1]) < closest){\n\n                            closest= SQR(mb->zyklus[j][0]) + SQR(mb->zyklus[j][1]);\n\n                            closest_index= j;\n\n                        }\n\n                    closest = sqrt(closest);\n\n                    c= lrintf((mb->zyklus[closest_index][0]/closest+1)*127+dv) + lrintf((mb->zyklus[closest_index][1]/closest+1)*127+dv)*256;\n\n                }\n\n            }\n\n            c |= 0xFF000000;\n\n            color[x + y*linesize]= c;\n\n            if(next_cidx < mb->cache_allocated){\n\n                mb->next_cache[next_cidx  ].p[0]= cr;\n\n                mb->next_cache[next_cidx  ].p[1]= ci;\n\n                mb->next_cache[next_cidx++].val = c;\n\n            }\n\n        }\n\n        fill_from_cache(ctx, NULL, &in_cidx, &next_cidx, ci + scale/2, scale);\n\n    }\n\n    FFSWAP(void*, mb->next_cache, mb->point_cache);\n\n    mb->cache_used = next_cidx;\n\n    if(mb->cache_used == mb->cache_allocated)\n\n        av_log(0, AV_LOG_INFO, \"Mandelbrot cache is too small!\\n\");\n\n}\n", "idx": 23966}
{"project": "FFmpeg", "commit_id": "7fc73d9ab781f66b63f3bbe2f384f4f639ae78e9", "target": 1, "func": "static int rm_assemble_video_frame(AVFormatContext *s, AVIOContext *pb,\n\n                                   RMDemuxContext *rm, RMStream *vst,\n\n                                   AVPacket *pkt, int len, int *pseq,\n\n                                   int64_t *timestamp)\n\n{\n\n    int hdr, seq, pic_num, len2, pos;\n\n    int type;\n\n\n\n    hdr = avio_r8(pb); len--;\n\n    type = hdr >> 6;\n\n\n\n    if(type != 3){  // not frame as a part of packet\n\n        seq = avio_r8(pb); len--;\n\n    }\n\n    if(type != 1){  // not whole frame\n\n        len2 = get_num(pb, &len);\n\n        pos  = get_num(pb, &len);\n\n        pic_num = avio_r8(pb); len--;\n\n    }\n\n    if(len<0)\n\n        return -1;\n\n    rm->remaining_len = len;\n\n    if(type&1){     // frame, not slice\n\n        if(type == 3){  // frame as a part of packet\n\n            len= len2;\n\n            *timestamp = pos;\n\n        }\n\n        if(rm->remaining_len < len)\n\n            return -1;\n\n        rm->remaining_len -= len;\n\n        if(av_new_packet(pkt, len + 9) < 0)\n\n            return AVERROR(EIO);\n\n        pkt->data[0] = 0;\n\n        AV_WL32(pkt->data + 1, 1);\n\n        AV_WL32(pkt->data + 5, 0);\n\n        avio_read(pb, pkt->data + 9, len);\n\n        return 0;\n\n    }\n\n    //now we have to deal with single slice\n\n\n\n    *pseq = seq;\n\n    if((seq & 0x7F) == 1 || vst->curpic_num != pic_num){\n\n        vst->slices = ((hdr & 0x3F) << 1) + 1;\n\n        vst->videobufsize = len2 + 8*vst->slices + 1;\n\n        av_free_packet(&vst->pkt); //FIXME this should be output.\n\n        if(av_new_packet(&vst->pkt, vst->videobufsize) < 0)\n\n            return AVERROR(ENOMEM);\n\n        vst->videobufpos = 8*vst->slices + 1;\n\n        vst->cur_slice = 0;\n\n        vst->curpic_num = pic_num;\n\n        vst->pktpos = avio_tell(pb);\n\n    }\n\n    if(type == 2)\n\n        len = FFMIN(len, pos);\n\n\n\n    if(++vst->cur_slice > vst->slices)\n\n        return 1;\n\n    AV_WL32(vst->pkt.data - 7 + 8*vst->cur_slice, 1);\n\n    AV_WL32(vst->pkt.data - 3 + 8*vst->cur_slice, vst->videobufpos - 8*vst->slices - 1);\n\n    if(vst->videobufpos + len > vst->videobufsize)\n\n        return 1;\n\n    if (avio_read(pb, vst->pkt.data + vst->videobufpos, len) != len)\n\n        return AVERROR(EIO);\n\n    vst->videobufpos += len;\n\n    rm->remaining_len-= len;\n\n\n\n    if (type == 2 || vst->videobufpos == vst->videobufsize) {\n\n        vst->pkt.data[0] = vst->cur_slice-1;\n\n        *pkt= vst->pkt;\n\n        vst->pkt.data= NULL;\n\n        vst->pkt.size= 0;\n\n        if(vst->slices != vst->cur_slice) //FIXME find out how to set slices correct from the begin\n\n            memmove(pkt->data + 1 + 8*vst->cur_slice, pkt->data + 1 + 8*vst->slices,\n\n                vst->videobufpos - 1 - 8*vst->slices);\n\n        pkt->size = vst->videobufpos + 8*(vst->cur_slice - vst->slices);\n\n        pkt->pts = AV_NOPTS_VALUE;\n\n        pkt->pos = vst->pktpos;\n\n        vst->slices = 0;\n\n        return 0;\n\n    }\n\n\n\n    return 1;\n\n}\n", "idx": 23967}
{"project": "FFmpeg", "commit_id": "c82bf15dca00f67a701d126e47ea9075fc9459cb", "target": 1, "func": "static void nal_send(AVFormatContext *s1, const uint8_t *buf, int size, int last)\n\n{\n\n    RTPMuxContext *s = s1->priv_data;\n\n\n\n    av_log(s1, AV_LOG_DEBUG, \"Sending NAL %x of len %d M=%d\\n\", buf[0] & 0x1F, size, last);\n\n    if (size <= s->max_payload_size) {\n\n        int buffered_size = s->buf_ptr - s->buf;\n\n        // Flush buffered NAL units if the current unit doesn't fit\n\n        if (buffered_size + 2 + size > s->max_payload_size) {\n\n            flush_buffered(s1, 0);\n\n            buffered_size = 0;\n\n        }\n\n        // If we aren't using mode 0, and the NAL unit fits including the\n\n        // framing (2 bytes length, plus 1 byte for the STAP-A marker),\n\n        // write the unit to the buffer as a STAP-A packet, otherwise flush\n\n        // and send as single NAL.\n\n        if (buffered_size + 3 + size <= s->max_payload_size &&\n\n            !(s->flags & FF_RTP_FLAG_H264_MODE0)) {\n\n            if (buffered_size == 0)\n\n                *s->buf_ptr++ = 24;\n\n            AV_WB16(s->buf_ptr, size);\n\n            s->buf_ptr += 2;\n\n            memcpy(s->buf_ptr, buf, size);\n\n            s->buf_ptr += size;\n\n            s->buffered_nals++;\n\n        } else {\n\n            flush_buffered(s1, 0);\n\n            ff_rtp_send_data(s1, buf, size, last);\n\n        }\n\n    } else {\n\n        uint8_t type = buf[0] & 0x1F;\n\n        uint8_t nri = buf[0] & 0x60;\n\n\n\n        flush_buffered(s1, 0);\n\n        if (s->flags & FF_RTP_FLAG_H264_MODE0) {\n\n            av_log(s1, AV_LOG_ERROR,\n\n                   \"NAL size %d > %d, try -slice-max-size %d\\n\", size,\n\n                   s->max_payload_size, s->max_payload_size);\n\n            return;\n\n        }\n\n        av_log(s1, AV_LOG_DEBUG, \"NAL size %d > %d\\n\", size, s->max_payload_size);\n\n        s->buf[0] = 28;        /* FU Indicator; Type = 28 ---> FU-A */\n\n        s->buf[0] |= nri;\n\n        s->buf[1] = type;\n\n        s->buf[1] |= 1 << 7;\n\n        buf += 1;\n\n        size -= 1;\n\n        while (size + 2 > s->max_payload_size) {\n\n            memcpy(&s->buf[2], buf, s->max_payload_size - 2);\n\n            ff_rtp_send_data(s1, s->buf, s->max_payload_size, 0);\n\n            buf += s->max_payload_size - 2;\n\n            size -= s->max_payload_size - 2;\n\n            s->buf[1] &= ~(1 << 7);\n\n        }\n\n        s->buf[1] |= 1 << 6;\n\n        memcpy(&s->buf[2], buf, size);\n\n        ff_rtp_send_data(s1, s->buf, size + 2, last);\n\n    }\n\n}\n", "idx": 23970}
{"project": "FFmpeg", "commit_id": "61cd19b8bc32185c8caf64d89d1b0909877a0707", "target": 1, "func": "static av_always_inline int vmnc_get_pixel(const uint8_t *buf, int bpp, int be)\n\n{\n\n    switch (bpp * 2 + be) {\n\n    case 2:\n\n    case 3:\n\n        return *buf;\n\n    case 4:\n\n        return AV_RL16(buf);\n\n    case 5:\n\n        return AV_RB16(buf);\n\n    case 8:\n\n        return AV_RL32(buf);\n\n    case 9:\n\n        return AV_RB32(buf);\n\n    default:\n\n        return 0;\n\n    }\n\n}\n", "idx": 23971}
{"project": "FFmpeg", "commit_id": "da048c6d24729d3bab6ccb0ac340ea129e3e88d5", "target": 1, "func": "static int get_moov_size(AVFormatContext *s)\n\n{\n\n    int ret;\n\n    AVIOContext *moov_buf;\n\n    MOVMuxContext *mov = s->priv_data;\n\n\n\n    if ((ret = ffio_open_null_buf(&moov_buf)) < 0)\n\n        return ret;\n\n    mov_write_moov_tag(moov_buf, mov, s);\n\n    return ffio_close_null_buf(moov_buf);\n\n}\n", "idx": 23974}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static void vc1_mc_4mv_luma(VC1Context *v, int n, int dir, int avg)\n\n{\n\n    MpegEncContext *s = &v->s;\n\n    uint8_t *srcY;\n\n    int dxy, mx, my, src_x, src_y;\n\n    int off;\n\n    int fieldmv = (v->fcm == ILACE_FRAME) ? v->blk_mv_type[s->block_index[n]] : 0;\n\n    int v_edge_pos = s->v_edge_pos >> v->field_mode;\n\n    uint8_t (*luty)[256];\n\n    int use_ic;\n\n\n\n    if ((!v->field_mode ||\n\n         (v->ref_field_type[dir] == 1 && v->cur_field_type == 1)) &&\n\n        !v->s.last_picture.f.data[0])\n\n        return;\n\n\n\n    mx = s->mv[dir][n][0];\n\n    my = s->mv[dir][n][1];\n\n\n\n    if (!dir) {\n\n        if (v->field_mode && (v->cur_field_type != v->ref_field_type[dir]) && v->second_field) {\n\n            srcY = s->current_picture.f.data[0];\n\n            luty = v->curr_luty;\n\n            use_ic = v->curr_use_ic;\n\n        } else {\n\n            srcY = s->last_picture.f.data[0];\n\n            luty = v->last_luty;\n\n            use_ic = v->last_use_ic;\n\n        }\n\n    } else {\n\n        srcY = s->next_picture.f.data[0];\n\n        luty = v->next_luty;\n\n        use_ic = v->next_use_ic;\n\n    }\n\n\n\n    if (!srcY) {\n\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Referenced frame missing.\\n\");\n\n        return;\n\n    }\n\n\n\n    if (v->field_mode) {\n\n        if (v->cur_field_type != v->ref_field_type[dir])\n\n            my = my - 2 + 4 * v->cur_field_type;\n\n    }\n\n\n\n    if (s->pict_type == AV_PICTURE_TYPE_P && n == 3 && v->field_mode) {\n\n        int same_count = 0, opp_count = 0, k;\n\n        int chosen_mv[2][4][2], f;\n\n        int tx, ty;\n\n        for (k = 0; k < 4; k++) {\n\n            f = v->mv_f[0][s->block_index[k] + v->blocks_off];\n\n            chosen_mv[f][f ? opp_count : same_count][0] = s->mv[0][k][0];\n\n            chosen_mv[f][f ? opp_count : same_count][1] = s->mv[0][k][1];\n\n            opp_count  += f;\n\n            same_count += 1 - f;\n\n        }\n\n        f = opp_count > same_count;\n\n        switch (f ? opp_count : same_count) {\n\n        case 4:\n\n            tx = median4(chosen_mv[f][0][0], chosen_mv[f][1][0],\n\n                         chosen_mv[f][2][0], chosen_mv[f][3][0]);\n\n            ty = median4(chosen_mv[f][0][1], chosen_mv[f][1][1],\n\n                         chosen_mv[f][2][1], chosen_mv[f][3][1]);\n\n            break;\n\n        case 3:\n\n            tx = mid_pred(chosen_mv[f][0][0], chosen_mv[f][1][0], chosen_mv[f][2][0]);\n\n            ty = mid_pred(chosen_mv[f][0][1], chosen_mv[f][1][1], chosen_mv[f][2][1]);\n\n            break;\n\n        case 2:\n\n            tx = (chosen_mv[f][0][0] + chosen_mv[f][1][0]) / 2;\n\n            ty = (chosen_mv[f][0][1] + chosen_mv[f][1][1]) / 2;\n\n            break;\n\n        }\n\n        s->current_picture.motion_val[1][s->block_index[0] + v->blocks_off][0] = tx;\n\n        s->current_picture.motion_val[1][s->block_index[0] + v->blocks_off][1] = ty;\n\n        for (k = 0; k < 4; k++)\n\n            v->mv_f[1][s->block_index[k] + v->blocks_off] = f;\n\n    }\n\n\n\n    if (v->fcm == ILACE_FRAME) {  // not sure if needed for other types of picture\n\n        int qx, qy;\n\n        int width  = s->avctx->coded_width;\n\n        int height = s->avctx->coded_height >> 1;\n\n        if (s->pict_type == AV_PICTURE_TYPE_P) {\n\n            s->current_picture.motion_val[1][s->block_index[n] + v->blocks_off][0] = mx;\n\n            s->current_picture.motion_val[1][s->block_index[n] + v->blocks_off][1] = my;\n\n        }\n\n        qx = (s->mb_x * 16) + (mx >> 2);\n\n        qy = (s->mb_y *  8) + (my >> 3);\n\n\n\n        if (qx < -17)\n\n            mx -= 4 * (qx + 17);\n\n        else if (qx > width)\n\n            mx -= 4 * (qx - width);\n\n        if (qy < -18)\n\n            my -= 8 * (qy + 18);\n\n        else if (qy > height + 1)\n\n            my -= 8 * (qy - height - 1);\n\n    }\n\n\n\n    if ((v->fcm == ILACE_FRAME) && fieldmv)\n\n        off = ((n > 1) ? s->linesize : 0) + (n & 1) * 8;\n\n    else\n\n        off = s->linesize * 4 * (n & 2) + (n & 1) * 8;\n\n\n\n    src_x = s->mb_x * 16 + (n & 1) * 8 + (mx >> 2);\n\n    if (!fieldmv)\n\n        src_y = s->mb_y * 16 + (n & 2) * 4 + (my >> 2);\n\n    else\n\n        src_y = s->mb_y * 16 + ((n > 1) ? 1 : 0) + (my >> 2);\n\n\n\n    if (v->profile != PROFILE_ADVANCED) {\n\n        src_x = av_clip(src_x, -16, s->mb_width  * 16);\n\n        src_y = av_clip(src_y, -16, s->mb_height * 16);\n\n    } else {\n\n        src_x = av_clip(src_x, -17, s->avctx->coded_width);\n\n        if (v->fcm == ILACE_FRAME) {\n\n            if (src_y & 1)\n\n                src_y = av_clip(src_y, -17, s->avctx->coded_height + 1);\n\n            else\n\n                src_y = av_clip(src_y, -18, s->avctx->coded_height);\n\n        } else {\n\n            src_y = av_clip(src_y, -18, s->avctx->coded_height + 1);\n\n        }\n\n    }\n\n\n\n    srcY += src_y * s->linesize + src_x;\n\n    if (v->field_mode && v->ref_field_type[dir])\n\n        srcY += s->current_picture_ptr->f.linesize[0];\n\n\n\n    if (fieldmv && !(src_y & 1))\n\n        v_edge_pos--;\n\n    if (fieldmv && (src_y & 1) && src_y < 4)\n\n        src_y--;\n\n    if (v->rangeredfrm || use_ic\n\n        || s->h_edge_pos < 13 || v_edge_pos < 23\n\n        || (unsigned)(src_x - s->mspel) > s->h_edge_pos - (mx & 3) - 8 - s->mspel * 2\n\n        || (unsigned)(src_y - (s->mspel << fieldmv)) > v_edge_pos - (my & 3) - ((8 + s->mspel * 2) << fieldmv)) {\n\n        srcY -= s->mspel * (1 + (s->linesize << fieldmv));\n\n        /* check emulate edge stride and offset */\n\n        s->vdsp.emulated_edge_mc(s->edge_emu_buffer, srcY,\n\n                                 s->linesize, s->linesize,\n\n                                 9 + s->mspel * 2, (9 + s->mspel * 2) << fieldmv,\n\n                                 src_x - s->mspel, src_y - (s->mspel << fieldmv),\n\n                                 s->h_edge_pos, v_edge_pos);\n\n        srcY = s->edge_emu_buffer;\n\n        /* if we deal with range reduction we need to scale source blocks */\n\n        if (v->rangeredfrm) {\n\n            int i, j;\n\n            uint8_t *src;\n\n\n\n            src = srcY;\n\n            for (j = 0; j < 9 + s->mspel * 2; j++) {\n\n                for (i = 0; i < 9 + s->mspel * 2; i++)\n\n                    src[i] = ((src[i] - 128) >> 1) + 128;\n\n                src += s->linesize << fieldmv;\n\n            }\n\n        }\n\n        /* if we deal with intensity compensation we need to scale source blocks */\n\n        if (use_ic) {\n\n            int i, j;\n\n            uint8_t *src;\n\n\n\n            src = srcY;\n\n            for (j = 0; j < 9 + s->mspel * 2; j++) {\n\n                int f = v->field_mode ? v->ref_field_type[dir] : (((j<<fieldmv)+src_y - (s->mspel << fieldmv)) & 1);\n\n                for (i = 0; i < 9 + s->mspel * 2; i++)\n\n                    src[i] = luty[f][src[i]];\n\n                src += s->linesize << fieldmv;\n\n            }\n\n        }\n\n        srcY += s->mspel * (1 + (s->linesize << fieldmv));\n\n    }\n\n\n\n    if (s->mspel) {\n\n        dxy = ((my & 3) << 2) | (mx & 3);\n\n        if (avg)\n\n            v->vc1dsp.avg_vc1_mspel_pixels_tab[dxy](s->dest[0] + off, srcY, s->linesize << fieldmv, v->rnd);\n\n        else\n\n            v->vc1dsp.put_vc1_mspel_pixels_tab[dxy](s->dest[0] + off, srcY, s->linesize << fieldmv, v->rnd);\n\n    } else { // hpel mc - always used for luma\n\n        dxy = (my & 2) | ((mx & 2) >> 1);\n\n        if (!v->rnd)\n\n            s->hdsp.put_pixels_tab[1][dxy](s->dest[0] + off, srcY, s->linesize, 8);\n\n        else\n\n            s->hdsp.put_no_rnd_pixels_tab[1][dxy](s->dest[0] + off, srcY, s->linesize, 8);\n\n    }\n\n}\n", "idx": 23975}
{"project": "FFmpeg", "commit_id": "d44e0d8b930732a4a247b4884d75cf62b4ad3664", "target": 1, "func": "static int recover(WtvContext *wtv, uint64_t broken_pos)\n\n{\n\n    AVIOContext *pb = wtv->pb;\n\n    int i;\n\n    for (i = 0; i < wtv->nb_index_entries; i++) {\n\n        if (wtv->index_entries[i].pos > broken_pos) {\n\n            int ret = avio_seek(pb, wtv->index_entries[i].pos, SEEK_SET);\n\n            if (ret < 0)\n\n                return ret;\n\n            wtv->pts = wtv->index_entries[i].timestamp;\n\n            return 0;\n\n         }\n\n     }\n\n     return AVERROR(EIO);\n\n}\n", "idx": 23976}
{"project": "FFmpeg", "commit_id": "5f6c92d40c2003471b005cc05430ec8488000867", "target": 1, "func": "static always_inline void mpeg_motion_lowres(MpegEncContext *s,\n\n                               uint8_t *dest_y, uint8_t *dest_cb, uint8_t *dest_cr,\n\n                               int field_based, int bottom_field, int field_select,\n\n                               uint8_t **ref_picture, h264_chroma_mc_func *pix_op,\n\n                               int motion_x, int motion_y, int h)\n\n{\n\n    uint8_t *ptr_y, *ptr_cb, *ptr_cr;\n\n    int mx, my, src_x, src_y, uvsrc_x, uvsrc_y, uvlinesize, linesize, sx, sy, uvsx, uvsy;\n\n    const int lowres= s->avctx->lowres;\n\n    const int block_s= 8>>lowres;\n\n    const int s_mask= (2<<lowres)-1;\n\n    const int h_edge_pos = s->h_edge_pos >> lowres;\n\n    const int v_edge_pos = s->v_edge_pos >> lowres;\n\n    linesize   = s->current_picture.linesize[0] << field_based;\n\n    uvlinesize = s->current_picture.linesize[1] << field_based;\n\n\n\n    if(s->quarter_sample){ //FIXME obviously not perfect but qpel wont work in lowres anyway\n\n        motion_x/=2;\n\n        motion_y/=2;\n\n    }\n\n    \n\n    if(field_based){\n\n        motion_y += (bottom_field - field_select)*((1<<lowres)-1);\n\n    }\n\n\n\n    sx= motion_x & s_mask;\n\n    sy= motion_y & s_mask;\n\n    src_x = s->mb_x*2*block_s               + (motion_x >> (lowres+1));\n\n    src_y =(s->mb_y*2*block_s>>field_based) + (motion_y >> (lowres+1));\n\n    \n\n    if (s->out_format == FMT_H263) {\n\n        uvsx = ((motion_x>>1) & s_mask) | (sx&1);\n\n        uvsy = ((motion_y>>1) & s_mask) | (sy&1);\n\n        uvsrc_x = src_x>>1;\n\n        uvsrc_y = src_y>>1;\n\n    }else if(s->out_format == FMT_H261){//even chroma mv's are full pel in H261\n\n        mx = motion_x / 4;\n\n        my = motion_y / 4;\n\n        uvsx = (2*mx) & s_mask;\n\n        uvsy = (2*my) & s_mask;\n\n        uvsrc_x = s->mb_x*block_s               + (mx >> lowres);\n\n        uvsrc_y = s->mb_y*block_s               + (my >> lowres);\n\n    } else {\n\n        mx = motion_x / 2;\n\n        my = motion_y / 2;\n\n        uvsx = mx & s_mask;\n\n        uvsy = my & s_mask;\n\n        uvsrc_x = s->mb_x*block_s               + (mx >> (lowres+1));\n\n        uvsrc_y =(s->mb_y*block_s>>field_based) + (my >> (lowres+1));\n\n    }\n\n\n\n    ptr_y  = ref_picture[0] + src_y * linesize + src_x;\n\n    ptr_cb = ref_picture[1] + uvsrc_y * uvlinesize + uvsrc_x;\n\n    ptr_cr = ref_picture[2] + uvsrc_y * uvlinesize + uvsrc_x;\n\n\n\n    if(   (unsigned)src_x > h_edge_pos                 - (!!sx) - 2*block_s\n\n       || (unsigned)src_y >(v_edge_pos >> field_based) - (!!sy) - h){\n\n            ff_emulated_edge_mc(s->edge_emu_buffer, ptr_y, s->linesize, 17, 17+field_based,\n\n                             src_x, src_y<<field_based, h_edge_pos, v_edge_pos);\n\n            ptr_y = s->edge_emu_buffer;\n\n            if(!(s->flags&CODEC_FLAG_GRAY)){\n\n                uint8_t *uvbuf= s->edge_emu_buffer+18*s->linesize;\n\n                ff_emulated_edge_mc(uvbuf  , ptr_cb, s->uvlinesize, 9, 9+field_based, \n\n                                 uvsrc_x, uvsrc_y<<field_based, h_edge_pos>>1, v_edge_pos>>1);\n\n                ff_emulated_edge_mc(uvbuf+16, ptr_cr, s->uvlinesize, 9, 9+field_based, \n\n                                 uvsrc_x, uvsrc_y<<field_based, h_edge_pos>>1, v_edge_pos>>1);\n\n                ptr_cb= uvbuf;\n\n                ptr_cr= uvbuf+16;\n\n            }\n\n    }\n\n\n\n    if(bottom_field){ //FIXME use this for field pix too instead of the obnoxious hack which changes picture.data\n\n        dest_y += s->linesize;\n\n        dest_cb+= s->uvlinesize;\n\n        dest_cr+= s->uvlinesize;\n\n    }\n\n\n\n    if(field_select){\n\n        ptr_y += s->linesize;\n\n        ptr_cb+= s->uvlinesize;\n\n        ptr_cr+= s->uvlinesize;\n\n    }\n\n\n\n    sx <<= 2 - lowres;\n\n    sy <<= 2 - lowres;\n\n    pix_op[lowres-1](dest_y, ptr_y, linesize, h, sx, sy);\n\n    \n\n    if(!(s->flags&CODEC_FLAG_GRAY)){\n\n        uvsx <<= 2 - lowres;\n\n        uvsy <<= 2 - lowres;\n\n        pix_op[lowres](dest_cb, ptr_cb, uvlinesize, h >> s->chroma_y_shift, uvsx, uvsy);\n\n        pix_op[lowres](dest_cr, ptr_cr, uvlinesize, h >> s->chroma_y_shift, uvsx, uvsy);\n\n    }\n\n\n}", "idx": 23977}
{"project": "FFmpeg", "commit_id": "d43696309a64a19e2e738f9e7aa94f6c96409aee", "target": 1, "func": "static const uint8_t *decode_nal(H264Context *h, const uint8_t *src, int *dst_length, int *consumed, int length){\n\n    int i, si, di;\n\n    uint8_t *dst;\n\n    int bufidx;\n\n\n\n//    src[0]&0x80;                //forbidden bit\n\n    h->nal_ref_idc= src[0]>>5;\n\n    h->nal_unit_type= src[0]&0x1F;\n\n\n\n    src++; length--;\n\n#if 0\n\n    for(i=0; i<length; i++)\n\n        printf(\"%2X \", src[i]);\n\n#endif\n\n    for(i=0; i+1<length; i+=2){\n\n        if(src[i]) continue;\n\n        if(i>0 && src[i-1]==0) i--;\n\n        if(i+2<length && src[i+1]==0 && src[i+2]<=3){\n\n            if(src[i+2]!=3){\n\n                /* startcode, so we must be past the end */\n\n                length=i;\n\n            }\n\n            break;\n\n        }\n\n    }\n\n\n\n    if(i>=length-1){ //no escaped 0\n\n        *dst_length= length;\n\n        *consumed= length+1; //+1 for the header\n\n        return src;\n\n    }\n\n\n\n    bufidx = h->nal_unit_type == NAL_DPC ? 1 : 0; // use second escape buffer for inter data\n\n    h->rbsp_buffer[bufidx]= av_fast_realloc(h->rbsp_buffer[bufidx], &h->rbsp_buffer_size[bufidx], length);\n\n    dst= h->rbsp_buffer[bufidx];\n\n\n\n    if (dst == NULL){\n\n        return NULL;\n\n    }\n\n\n\n//printf(\"decoding esc\\n\");\n\n    si=di=0;\n\n    while(si<length){\n\n        //remove escapes (very rare 1:2^22)\n\n        if(si+2<length && src[si]==0 && src[si+1]==0 && src[si+2]<=3){\n\n            if(src[si+2]==3){ //escape\n\n                dst[di++]= 0;\n\n                dst[di++]= 0;\n\n                si+=3;\n\n                continue;\n\n            }else //next start code\n\n                break;\n\n        }\n\n\n\n        dst[di++]= src[si++];\n\n    }\n\n\n\n    *dst_length= di;\n\n    *consumed= si + 1;//+1 for the header\n\n//FIXME store exact number of bits in the getbitcontext (it is needed for decoding)\n\n    return dst;\n\n}\n", "idx": 23979}
{"project": "FFmpeg", "commit_id": "f0dd9d4505675daa0f4fda6fcf4274416a23bf24", "target": 1, "func": "static int smka_decode_frame(AVCodecContext *avctx, void *data, int *data_size, uint8_t *buf, int buf_size)\n\n{\n\n    GetBitContext gb;\n\n    HuffContext h[4];\n\n    VLC vlc[4];\n\n    int16_t *samples = data;\n\n    int val;\n\n    int i, res;\n\n    int unp_size;\n\n    int bits, stereo;\n\n    int pred[2] = {0, 0};\n\n\n\n    unp_size = AV_RL32(buf);\n\n\n\n    init_get_bits(&gb, buf + 4, (buf_size - 4) * 8);\n\n\n\n    if(!get_bits1(&gb)){\n\n        av_log(avctx, AV_LOG_INFO, \"Sound: no data\\n\");\n\n        *data_size = 0;\n\n        return 1;\n\n    }\n\n    stereo = get_bits1(&gb);\n\n    bits = get_bits1(&gb);\n\n    if ((unp_size << !bits) > *data_size) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Frame is too large to fit in buffer\\n\");\n\n        return -1;\n\n    }\n\n\n\n    memset(vlc, 0, sizeof(VLC) * 4);\n\n    memset(h, 0, sizeof(HuffContext) * 4);\n\n    // Initialize\n\n    for(i = 0; i < (1 << (bits + stereo)); i++) {\n\n        h[i].length = 256;\n\n        h[i].maxlength = 0;\n\n        h[i].current = 0;\n\n        h[i].bits = av_mallocz(256 * 4);\n\n        h[i].lengths = av_mallocz(256 * sizeof(int));\n\n        h[i].values = av_mallocz(256 * sizeof(int));\n\n        skip_bits1(&gb);\n\n        smacker_decode_tree(&gb, &h[i], 0, 0);\n\n        skip_bits1(&gb);\n\n        if(h[i].current > 1) {\n\n            res = init_vlc(&vlc[i], SMKTREE_BITS, h[i].length,\n\n                    h[i].lengths, sizeof(int), sizeof(int),\n\n                    h[i].bits, sizeof(uint32_t), sizeof(uint32_t), INIT_VLC_LE);\n\n            if(res < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Cannot build VLC table\\n\");\n\n                return -1;\n\n            }\n\n        }\n\n    }\n\n    if(bits) { //decode 16-bit data\n\n        for(i = stereo; i >= 0; i--)\n\n            pred[i] = bswap_16(get_bits(&gb, 16));\n\n        for(i = 0; i < stereo; i++)\n\n            *samples++ = pred[i];\n\n        for(i = 0; i < unp_size / 2; i++) {\n\n            if(i & stereo) {\n\n                if(vlc[2].table)\n\n                    res = get_vlc2(&gb, vlc[2].table, SMKTREE_BITS, 3);\n\n                else\n\n                    res = 0;\n\n                val  = h[2].values[res];\n\n                if(vlc[3].table)\n\n                    res = get_vlc2(&gb, vlc[3].table, SMKTREE_BITS, 3);\n\n                else\n\n                    res = 0;\n\n                val |= h[3].values[res] << 8;\n\n                pred[1] += (int16_t)val;\n\n                *samples++ = pred[1];\n\n            } else {\n\n                if(vlc[0].table)\n\n                    res = get_vlc2(&gb, vlc[0].table, SMKTREE_BITS, 3);\n\n                else\n\n                    res = 0;\n\n                val  = h[0].values[res];\n\n                if(vlc[1].table)\n\n                    res = get_vlc2(&gb, vlc[1].table, SMKTREE_BITS, 3);\n\n                else\n\n                    res = 0;\n\n                val |= h[1].values[res] << 8;\n\n                pred[0] += val;\n\n                *samples++ = pred[0];\n\n            }\n\n        }\n\n    } else { //8-bit data\n\n        for(i = stereo; i >= 0; i--)\n\n            pred[i] = get_bits(&gb, 8);\n\n        for(i = 0; i < stereo; i++)\n\n            *samples++ = (pred[i] - 0x80) << 8;\n\n        for(i = 0; i < unp_size; i++) {\n\n            if(i & stereo){\n\n                if(vlc[1].table)\n\n                    res = get_vlc2(&gb, vlc[1].table, SMKTREE_BITS, 3);\n\n                else\n\n                    res = 0;\n\n                pred[1] += (int8_t)h[1].values[res];\n\n                *samples++ = (pred[1] - 0x80) << 8;\n\n            } else {\n\n                if(vlc[0].table)\n\n                    res = get_vlc2(&gb, vlc[0].table, SMKTREE_BITS, 3);\n\n                else\n\n                    res = 0;\n\n                pred[0] += (int8_t)h[0].values[res];\n\n                *samples++ = (pred[0] - 0x80) << 8;\n\n            }\n\n        }\n\n        unp_size *= 2;\n\n    }\n\n\n\n    for(i = 0; i < 4; i++) {\n\n        if(vlc[i].table)\n\n            free_vlc(&vlc[i]);\n\n        if(h[i].bits)\n\n            av_free(h[i].bits);\n\n        if(h[i].lengths)\n\n            av_free(h[i].lengths);\n\n        if(h[i].values)\n\n            av_free(h[i].values);\n\n    }\n\n\n\n    *data_size = unp_size;\n\n    return buf_size;\n\n}\n", "idx": 23983}
{"project": "FFmpeg", "commit_id": "bcd7bf7eeb09a395cc01698842d1b8be9af483fc", "target": 0, "func": "static void avc_wgt_4width_msa(uint8_t *data,\n\n                               int32_t stride,\n\n                               int32_t height,\n\n                               int32_t log2_denom,\n\n                               int32_t src_weight,\n\n                               int32_t offset_in)\n\n{\n\n    if (2 == height) {\n\n        avc_wgt_4x2_msa(data, stride, log2_denom, src_weight, offset_in);\n\n    } else {\n\n        avc_wgt_4x4multiple_msa(data, stride, height, log2_denom,\n\n                                src_weight, offset_in);\n\n    }\n\n}\n", "idx": 23990}
{"project": "FFmpeg", "commit_id": "d3e5fbb1406995e07fccbff3ca8c1e24f57a1f7b", "target": 0, "func": "static void do_apply_filter(APEContext *ctx, int version, APEFilter *f,\n\n                            int32_t *data, int count, int order, int fracbits)\n\n{\n\n    int res;\n\n    int absres;\n\n\n\n    while (count--) {\n\n        /* round fixedpoint scalar product */\n\n        res = ctx->adsp.scalarproduct_and_madd_int16(f->coeffs,\n\n                                                     f->delay - order,\n\n                                                     f->adaptcoeffs - order,\n\n                                                     order, APESIGN(*data));\n\n        res = (res + (1 << (fracbits - 1))) >> fracbits;\n\n        res += *data;\n\n        *data++ = res;\n\n\n\n        /* Update the output history */\n\n        *f->delay++ = av_clip_int16(res);\n\n\n\n        if (version < 3980) {\n\n            /* Version ??? to < 3.98 files (untested) */\n\n            f->adaptcoeffs[0]  = (res == 0) ? 0 : ((res >> 28) & 8) - 4;\n\n            f->adaptcoeffs[-4] >>= 1;\n\n            f->adaptcoeffs[-8] >>= 1;\n\n        } else {\n\n            /* Version 3.98 and later files */\n\n\n\n            /* Update the adaption coefficients */\n\n            absres = FFABS(res);\n\n            if (absres)\n\n                *f->adaptcoeffs = ((res & (-1<<31)) ^ (-1<<30)) >>\n\n                                  (25 + (absres <= f->avg*3) + (absres <= f->avg*4/3));\n\n            else\n\n                *f->adaptcoeffs = 0;\n\n\n\n            f->avg += (absres - f->avg) / 16;\n\n\n\n            f->adaptcoeffs[-1] >>= 1;\n\n            f->adaptcoeffs[-2] >>= 1;\n\n            f->adaptcoeffs[-8] >>= 1;\n\n        }\n\n\n\n        f->adaptcoeffs++;\n\n\n\n        /* Have we filled the history buffer? */\n\n        if (f->delay == f->historybuffer + HISTORY_SIZE + (order * 2)) {\n\n            memmove(f->historybuffer, f->delay - (order * 2),\n\n                    (order * 2) * sizeof(*f->historybuffer));\n\n            f->delay = f->historybuffer + order * 2;\n\n            f->adaptcoeffs = f->historybuffer + order;\n\n        }\n\n    }\n\n}\n", "idx": 23991}
{"project": "FFmpeg", "commit_id": "78baa450d9939957f52d5187beb95d763d2f1f18", "target": 1, "func": "static int ffm2_read_header(AVFormatContext *s)\n\n{\n\n    FFMContext *ffm = s->priv_data;\n\n    AVStream *st;\n\n    AVIOContext *pb = s->pb;\n\n    AVCodecContext *codec;\n\n    const AVCodecDescriptor *codec_desc;\n\n    int ret, i;\n\n    int f_main = 0, f_cprv = -1, f_stvi = -1, f_stau = -1;\n\n    AVCodec *enc;\n\n    char *buffer;\n\n\n\n    ffm->packet_size = avio_rb32(pb);\n\n    if (ffm->packet_size != FFM_PACKET_SIZE) {\n\n        av_log(s, AV_LOG_ERROR, \"Invalid packet size %d, expected size was %d\\n\",\n\n               ffm->packet_size, FFM_PACKET_SIZE);\n\n        ret = AVERROR_INVALIDDATA;\n\n\n\n\n\n    ffm->write_index = avio_rb64(pb);\n\n    /* get also filesize */\n\n    if (pb->seekable) {\n\n        ffm->file_size = avio_size(pb);\n\n        if (ffm->write_index && 0)\n\n            adjust_write_index(s);\n\n    } else {\n\n        ffm->file_size = (UINT64_C(1) << 63) - 1;\n\n\n\n\n    while(!avio_feof(pb)) {\n\n        unsigned id = avio_rb32(pb);\n\n        unsigned size = avio_rb32(pb);\n\n        int64_t next = avio_tell(pb) + size;\n\n        char rc_eq_buf[128];\n\n\n\n        if(!id)\n\n            break;\n\n\n\n        switch(id) {\n\n        case MKBETAG('M', 'A', 'I', 'N'):\n\n            if (f_main++) {\n\n                ret = AVERROR(EINVAL);\n\n\n\n            avio_rb32(pb); /* nb_streams */\n\n            avio_rb32(pb); /* total bitrate */\n\n            break;\n\n        case MKBETAG('C', 'O', 'M', 'M'):\n\n            f_cprv = f_stvi = f_stau = 0;\n\n            st = avformat_new_stream(s, NULL);\n\n            if (!st) {\n\n                ret = AVERROR(ENOMEM);\n\n\n\n\n\n            avpriv_set_pts_info(st, 64, 1, 1000000);\n\n\n\n            codec = st->codec;\n\n            /* generic info */\n\n            codec->codec_id = avio_rb32(pb);\n\n            codec_desc = avcodec_descriptor_get(codec->codec_id);\n\n            if (!codec_desc) {\n\n                av_log(s, AV_LOG_ERROR, \"Invalid codec id: %d\\n\", codec->codec_id);\n\n                codec->codec_id = AV_CODEC_ID_NONE;\n\n\n\n            codec->codec_type = avio_r8(pb);\n\n            if (codec->codec_type != codec_desc->type) {\n\n                av_log(s, AV_LOG_ERROR, \"Codec type mismatch: expected %d, found %d\\n\",\n\n                       codec_desc->type, codec->codec_type);\n\n                codec->codec_id = AV_CODEC_ID_NONE;\n\n                codec->codec_type = AVMEDIA_TYPE_UNKNOWN;\n\n\n\n            codec->bit_rate = avio_rb32(pb);\n\n            codec->flags = avio_rb32(pb);\n\n            codec->flags2 = avio_rb32(pb);\n\n            codec->debug = avio_rb32(pb);\n\n            if (codec->flags & AV_CODEC_FLAG_GLOBAL_HEADER) {\n\n                int size = avio_rb32(pb);\n\n                codec->extradata = av_mallocz(size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n                if (!codec->extradata)\n\n                    return AVERROR(ENOMEM);\n\n                codec->extradata_size = size;\n\n                avio_read(pb, codec->extradata, size);\n\n\n            break;\n\n        case MKBETAG('S', 'T', 'V', 'I'):\n\n            if (f_stvi++) {\n\n                ret = AVERROR(EINVAL);\n\n\n\n            codec->time_base.num = avio_rb32(pb);\n\n            codec->time_base.den = avio_rb32(pb);\n\n            if (codec->time_base.num <= 0 || codec->time_base.den <= 0) {\n\n                av_log(s, AV_LOG_ERROR, \"Invalid time base %d/%d\\n\",\n\n                       codec->time_base.num, codec->time_base.den);\n\n                ret = AVERROR_INVALIDDATA;\n\n\n\n            codec->width = avio_rb16(pb);\n\n            codec->height = avio_rb16(pb);\n\n            codec->gop_size = avio_rb16(pb);\n\n            codec->pix_fmt = avio_rb32(pb);\n\n\n\n\n\n\n            codec->qmin = avio_r8(pb);\n\n            codec->qmax = avio_r8(pb);\n\n            codec->max_qdiff = avio_r8(pb);\n\n            codec->qcompress = avio_rb16(pb) / 10000.0;\n\n            codec->qblur = avio_rb16(pb) / 10000.0;\n\n            codec->bit_rate_tolerance = avio_rb32(pb);\n\n            avio_get_str(pb, INT_MAX, rc_eq_buf, sizeof(rc_eq_buf));\n\n            codec->rc_eq = av_strdup(rc_eq_buf);\n\n            codec->rc_max_rate = avio_rb32(pb);\n\n            codec->rc_min_rate = avio_rb32(pb);\n\n            codec->rc_buffer_size = avio_rb32(pb);\n\n            codec->i_quant_factor = av_int2double(avio_rb64(pb));\n\n            codec->b_quant_factor = av_int2double(avio_rb64(pb));\n\n            codec->i_quant_offset = av_int2double(avio_rb64(pb));\n\n            codec->b_quant_offset = av_int2double(avio_rb64(pb));\n\n            codec->dct_algo = avio_rb32(pb);\n\n            codec->strict_std_compliance = avio_rb32(pb);\n\n            codec->max_b_frames = avio_rb32(pb);\n\n            codec->mpeg_quant = avio_rb32(pb);\n\n            codec->intra_dc_precision = avio_rb32(pb);\n\n            codec->me_method = avio_rb32(pb);\n\n            codec->mb_decision = avio_rb32(pb);\n\n            codec->nsse_weight = avio_rb32(pb);\n\n            codec->frame_skip_cmp = avio_rb32(pb);\n\n            codec->rc_buffer_aggressivity = av_int2double(avio_rb64(pb));\n\n            codec->codec_tag = avio_rb32(pb);\n\n            codec->thread_count = avio_r8(pb);\n\n            codec->coder_type = avio_rb32(pb);\n\n            codec->me_cmp = avio_rb32(pb);\n\n            codec->me_subpel_quality = avio_rb32(pb);\n\n            codec->me_range = avio_rb32(pb);\n\n            codec->keyint_min = avio_rb32(pb);\n\n            codec->scenechange_threshold = avio_rb32(pb);\n\n            codec->b_frame_strategy = avio_rb32(pb);\n\n            codec->qcompress = av_int2double(avio_rb64(pb));\n\n            codec->qblur = av_int2double(avio_rb64(pb));\n\n            codec->max_qdiff = avio_rb32(pb);\n\n            codec->refs = avio_rb32(pb);\n\n            break;\n\n        case MKBETAG('S', 'T', 'A', 'U'):\n\n            if (f_stau++) {\n\n                ret = AVERROR(EINVAL);\n\n\n\n            codec->sample_rate = avio_rb32(pb);\n\n            codec->channels = avio_rl16(pb);\n\n            codec->frame_size = avio_rl16(pb);\n\n            break;\n\n        case MKBETAG('C', 'P', 'R', 'V'):\n\n            if (f_cprv++) {\n\n                ret = AVERROR(EINVAL);\n\n\n\n            enc = avcodec_find_encoder(codec->codec_id);\n\n            if (enc && enc->priv_data_size && enc->priv_class) {\n\n                buffer = av_malloc(size + 1);\n\n                if (!buffer) {\n\n                    ret = AVERROR(ENOMEM);\n\n\n\n                avio_get_str(pb, size, buffer, size + 1);\n\n                if ((ret = ffm_append_recommended_configuration(st, &buffer)) < 0)\n\n\n\n            break;\n\n        case MKBETAG('S', '2', 'V', 'I'):\n\n            if (f_stvi++ || !size) {\n\n                ret = AVERROR(EINVAL);\n\n\n\n            buffer = av_malloc(size);\n\n            if (!buffer) {\n\n                ret = AVERROR(ENOMEM);\n\n\n\n            avio_get_str(pb, INT_MAX, buffer, size);\n\n            av_set_options_string(codec, buffer, \"=\", \",\");\n\n            if ((ret = ffm_append_recommended_configuration(st, &buffer)) < 0)\n\n\n            break;\n\n        case MKBETAG('S', '2', 'A', 'U'):\n\n            if (f_stau++ || !size) {\n\n                ret = AVERROR(EINVAL);\n\n\n\n            buffer = av_malloc(size);\n\n            if (!buffer) {\n\n                ret = AVERROR(ENOMEM);\n\n\n\n            avio_get_str(pb, INT_MAX, buffer, size);\n\n            av_set_options_string(codec, buffer, \"=\", \",\");\n\n            if ((ret = ffm_append_recommended_configuration(st, &buffer)) < 0)\n\n\n            break;\n\n\n        avio_seek(pb, next, SEEK_SET);\n\n\n\n\n    for (i = 0; i < s->nb_streams; i++)\n\n        avcodec_parameters_from_context(s->streams[i]->codecpar, s->streams[i]->codec);\n\n\n\n    /* get until end of block reached */\n\n    while ((avio_tell(pb) % ffm->packet_size) != 0 && !pb->eof_reached)\n\n        avio_r8(pb);\n\n\n\n    /* init packet demux */\n\n    ffm->packet_ptr = ffm->packet;\n\n    ffm->packet_end = ffm->packet;\n\n    ffm->frame_offset = 0;\n\n    ffm->dts = 0;\n\n    ffm->read_state = READ_HEADER;\n\n    ffm->first_packet = 1;\n\n    return 0;\n\n fail:\n\n    ffm_close(s);\n\n    return ret;\n", "idx": 23992}
{"project": "FFmpeg", "commit_id": "12c3e120fe8f8d6881001eade390d8a5c185783d", "target": 1, "func": "static int h263p_decode_umotion(MpegEncContext * s, int pred)\n\n{\n\n   int code = 0, sign;\n\n\n\n   if (get_bits1(&s->gb)) /* Motion difference = 0 */\n\n      return pred;\n\n\n\n   code = 2 + get_bits1(&s->gb);\n\n\n\n   while (get_bits1(&s->gb))\n\n   {\n\n      code <<= 1;\n\n      code += get_bits1(&s->gb);\n\n      if (code >= 32768) {\n\n          avpriv_request_sample(s->avctx, \"Huge DMV\");\n\n          return AVERROR_INVALIDDATA;\n\n      }\n\n   }\n\n   sign = code & 1;\n\n   code >>= 1;\n\n\n\n   code = (sign) ? (pred - code) : (pred + code);\n\n   ff_tlog(s->avctx,\"H.263+ UMV Motion = %d\\n\", code);\n\n   return code;\n\n\n\n}\n", "idx": 23993}
{"project": "FFmpeg", "commit_id": "68aefbe81cb3b9dd002108782bb8d798e1c12806", "target": 1, "func": "static void stream_pause(VideoState *is)\n\n{\n\n    is->paused = !is->paused;\n\n    if (!is->paused) {\n\n        if(is->read_pause_return != AVERROR(ENOSYS)){\n\n            is->video_current_pts = get_video_clock(is);\n\n        }\n\n\n\n        is->frame_timer += (av_gettime() - is->video_current_pts_time) / 1000000.0;\n\n        is->video_current_pts_time= av_gettime();\n\n    }\n\n}\n", "idx": 23994}
{"project": "FFmpeg", "commit_id": "19000122a4cc7551cef19ccc6ce4db82d7d290bd", "target": 1, "func": "int ff_MPV_encode_picture(AVCodecContext *avctx, AVPacket *pkt,\n\n                          const AVFrame *pic_arg, int *got_packet)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int i, stuffing_count, ret;\n\n    int context_count = s->slice_context_count;\n\n\n\n    s->picture_in_gop_number++;\n\n\n\n    if (load_input_picture(s, pic_arg) < 0)\n\n        return -1;\n\n\n\n    if (select_input_picture(s) < 0) {\n\n        return -1;\n\n    }\n\n\n\n    /* output? */\n\n    if (s->new_picture.f.data[0]) {\n\n        if (!pkt->data &&\n\n            (ret = ff_alloc_packet(pkt, s->mb_width*s->mb_height*MAX_MB_BYTES)) < 0)\n\n            return ret;\n\n        if (s->mb_info) {\n\n            s->mb_info_ptr = av_packet_new_side_data(pkt,\n\n                                 AV_PKT_DATA_H263_MB_INFO,\n\n                                 s->mb_width*s->mb_height*12);\n\n            s->prev_mb_info = s->last_mb_info = s->mb_info_size = 0;\n\n        }\n\n\n\n        for (i = 0; i < context_count; i++) {\n\n            int start_y = s->thread_context[i]->start_mb_y;\n\n            int   end_y = s->thread_context[i]->  end_mb_y;\n\n            int h       = s->mb_height;\n\n            uint8_t *start = pkt->data + (size_t)(((int64_t) pkt->size) * start_y / h);\n\n            uint8_t *end   = pkt->data + (size_t)(((int64_t) pkt->size) *   end_y / h);\n\n\n\n            init_put_bits(&s->thread_context[i]->pb, start, end - start);\n\n        }\n\n\n\n        s->pict_type = s->new_picture.f.pict_type;\n\n        //emms_c();\n\n        //printf(\"qs:%f %f %d\\n\", s->new_picture.quality,\n\n        //       s->current_picture.quality, s->qscale);\n\n        ff_MPV_frame_start(s, avctx);\n\nvbv_retry:\n\n        if (encode_picture(s, s->picture_number) < 0)\n\n            return -1;\n\n\n\n        avctx->header_bits = s->header_bits;\n\n        avctx->mv_bits     = s->mv_bits;\n\n        avctx->misc_bits   = s->misc_bits;\n\n        avctx->i_tex_bits  = s->i_tex_bits;\n\n        avctx->p_tex_bits  = s->p_tex_bits;\n\n        avctx->i_count     = s->i_count;\n\n        // FIXME f/b_count in avctx\n\n        avctx->p_count     = s->mb_num - s->i_count - s->skip_count;\n\n        avctx->skip_count  = s->skip_count;\n\n\n\n        ff_MPV_frame_end(s);\n\n\n\n        if (CONFIG_MJPEG_ENCODER && s->out_format == FMT_MJPEG)\n\n            ff_mjpeg_encode_picture_trailer(s);\n\n\n\n        if (avctx->rc_buffer_size) {\n\n            RateControlContext *rcc = &s->rc_context;\n\n            int max_size = rcc->buffer_index * avctx->rc_max_available_vbv_use;\n\n\n\n            if (put_bits_count(&s->pb) > max_size &&\n\n                s->lambda < s->avctx->lmax) {\n\n                s->next_lambda = FFMAX(s->lambda + 1, s->lambda *\n\n                                       (s->qscale + 1) / s->qscale);\n\n                if (s->adaptive_quant) {\n\n                    int i;\n\n                    for (i = 0; i < s->mb_height * s->mb_stride; i++)\n\n                        s->lambda_table[i] =\n\n                            FFMAX(s->lambda_table[i] + 1,\n\n                                  s->lambda_table[i] * (s->qscale + 1) /\n\n                                  s->qscale);\n\n                }\n\n                s->mb_skipped = 0;        // done in MPV_frame_start()\n\n                // done in encode_picture() so we must undo it\n\n                if (s->pict_type == AV_PICTURE_TYPE_P) {\n\n                    if (s->flipflop_rounding          ||\n\n                        s->codec_id == AV_CODEC_ID_H263P ||\n\n                        s->codec_id == AV_CODEC_ID_MPEG4)\n\n                        s->no_rounding ^= 1;\n\n                }\n\n                if (s->pict_type != AV_PICTURE_TYPE_B) {\n\n                    s->time_base       = s->last_time_base;\n\n                    s->last_non_b_time = s->time - s->pp_time;\n\n                }\n\n                //av_log(NULL, AV_LOG_ERROR, \"R:%d \", s->next_lambda);\n\n                for (i = 0; i < context_count; i++) {\n\n                    PutBitContext *pb = &s->thread_context[i]->pb;\n\n                    init_put_bits(pb, pb->buf, pb->buf_end - pb->buf);\n\n                }\n\n                goto vbv_retry;\n\n            }\n\n\n\n            assert(s->avctx->rc_max_rate);\n\n        }\n\n\n\n        if (s->flags & CODEC_FLAG_PASS1)\n\n            ff_write_pass1_stats(s);\n\n\n\n        for (i = 0; i < 4; i++) {\n\n            s->current_picture_ptr->f.error[i] = s->current_picture.f.error[i];\n\n            avctx->error[i] += s->current_picture_ptr->f.error[i];\n\n        }\n\n\n\n        if (s->flags & CODEC_FLAG_PASS1)\n\n            assert(avctx->header_bits + avctx->mv_bits + avctx->misc_bits +\n\n                   avctx->i_tex_bits + avctx->p_tex_bits ==\n\n                       put_bits_count(&s->pb));\n\n        flush_put_bits(&s->pb);\n\n        s->frame_bits  = put_bits_count(&s->pb);\n\n\n\n        stuffing_count = ff_vbv_update(s, s->frame_bits);\n\n        if (stuffing_count) {\n\n            if (s->pb.buf_end - s->pb.buf - (put_bits_count(&s->pb) >> 3) <\n\n                    stuffing_count + 50) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"stuffing too large\\n\");\n\n                return -1;\n\n            }\n\n\n\n            switch (s->codec_id) {\n\n            case AV_CODEC_ID_MPEG1VIDEO:\n\n            case AV_CODEC_ID_MPEG2VIDEO:\n\n                while (stuffing_count--) {\n\n                    put_bits(&s->pb, 8, 0);\n\n                }\n\n            break;\n\n            case AV_CODEC_ID_MPEG4:\n\n                put_bits(&s->pb, 16, 0);\n\n                put_bits(&s->pb, 16, 0x1C3);\n\n                stuffing_count -= 4;\n\n                while (stuffing_count--) {\n\n                    put_bits(&s->pb, 8, 0xFF);\n\n                }\n\n            break;\n\n            default:\n\n                av_log(s->avctx, AV_LOG_ERROR, \"vbv buffer overflow\\n\");\n\n            }\n\n            flush_put_bits(&s->pb);\n\n            s->frame_bits  = put_bits_count(&s->pb);\n\n        }\n\n\n\n        /* update mpeg1/2 vbv_delay for CBR */\n\n        if (s->avctx->rc_max_rate                          &&\n\n            s->avctx->rc_min_rate == s->avctx->rc_max_rate &&\n\n            s->out_format == FMT_MPEG1                     &&\n\n            90000LL * (avctx->rc_buffer_size - 1) <=\n\n                s->avctx->rc_max_rate * 0xFFFFLL) {\n\n            int vbv_delay, min_delay;\n\n            double inbits  = s->avctx->rc_max_rate *\n\n                             av_q2d(s->avctx->time_base);\n\n            int    minbits = s->frame_bits - 8 *\n\n                             (s->vbv_delay_ptr - s->pb.buf - 1);\n\n            double bits    = s->rc_context.buffer_index + minbits - inbits;\n\n\n\n            if (bits < 0)\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"Internal error, negative bits\\n\");\n\n\n\n            assert(s->repeat_first_field == 0);\n\n\n\n            vbv_delay = bits * 90000 / s->avctx->rc_max_rate;\n\n            min_delay = (minbits * 90000LL + s->avctx->rc_max_rate - 1) /\n\n                        s->avctx->rc_max_rate;\n\n\n\n            vbv_delay = FFMAX(vbv_delay, min_delay);\n\n\n\n            assert(vbv_delay < 0xFFFF);\n\n\n\n            s->vbv_delay_ptr[0] &= 0xF8;\n\n            s->vbv_delay_ptr[0] |= vbv_delay >> 13;\n\n            s->vbv_delay_ptr[1]  = vbv_delay >> 5;\n\n            s->vbv_delay_ptr[2] &= 0x07;\n\n            s->vbv_delay_ptr[2] |= vbv_delay << 3;\n\n            avctx->vbv_delay     = vbv_delay * 300;\n\n        }\n\n        s->total_bits     += s->frame_bits;\n\n        avctx->frame_bits  = s->frame_bits;\n\n\n\n        pkt->pts = s->current_picture.f.pts;\n\n        if (!s->low_delay) {\n\n            if (!s->current_picture.f.coded_picture_number)\n\n                pkt->dts = pkt->pts - s->dts_delta;\n\n            else\n\n                pkt->dts = s->reordered_pts;\n\n            s->reordered_pts = s->input_picture[0]->f.pts;\n\n        } else\n\n            pkt->dts = pkt->pts;\n\n        if (s->current_picture.f.key_frame)\n\n            pkt->flags |= AV_PKT_FLAG_KEY;\n\n        if (s->mb_info)\n\n            av_packet_shrink_side_data(pkt, AV_PKT_DATA_H263_MB_INFO, s->mb_info_size);\n\n    } else {\n\n        assert((put_bits_ptr(&s->pb) == s->pb.buf));\n\n        s->frame_bits = 0;\n\n    }\n\n    assert((s->frame_bits & 7) == 0);\n\n\n\n    pkt->size = s->frame_bits / 8;\n\n    *got_packet = !!pkt->size;\n\n    return 0;\n\n}\n", "idx": 23996}
{"project": "FFmpeg", "commit_id": "ae4cffd9fc5bc495692920d646d7d1462315cfa6", "target": 0, "func": "static inline void RENAME(rgb32tobgr15)(const uint8_t *src, uint8_t *dst, unsigned src_size)\n\n{\n\n\tconst uint8_t *s = src;\n\n\tconst uint8_t *end;\n\n#ifdef HAVE_MMX\n\n\tconst uint8_t *mm_end;\n\n#endif\n\n\tuint16_t *d = (uint16_t *)dst;\n\n\tend = s + src_size;\n\n#ifdef HAVE_MMX\n\n\t__asm __volatile(PREFETCH\"\t%0\"::\"m\"(*src):\"memory\");\n\n\t__asm __volatile(\n\n\t    \"movq\t%0, %%mm7\\n\\t\"\n\n\t    \"movq\t%1, %%mm6\\n\\t\"\n\n\t    ::\"m\"(red_15mask),\"m\"(green_15mask));\n\n\tmm_end = end - 15;\n\n\twhile(s < mm_end)\n\n\t{\n\n\t    __asm __volatile(\n\n\t\tPREFETCH\" 32%1\\n\\t\"\n\n\t\t\"movd\t%1, %%mm0\\n\\t\"\n\n\t\t\"movd\t4%1, %%mm3\\n\\t\"\n\n\t\t\"punpckldq 8%1, %%mm0\\n\\t\"\n\n\t\t\"punpckldq 12%1, %%mm3\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm1\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm2\\n\\t\"\n\n\t\t\"movq\t%%mm3, %%mm4\\n\\t\"\n\n\t\t\"movq\t%%mm3, %%mm5\\n\\t\"\n\n\t\t\"psllq\t$7, %%mm0\\n\\t\"\n\n\t\t\"psllq\t$7, %%mm3\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm0\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm3\\n\\t\"\n\n\t\t\"psrlq\t$6, %%mm1\\n\\t\"\n\n\t\t\"psrlq\t$6, %%mm4\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm1\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm4\\n\\t\"\n\n\t\t\"psrlq\t$19, %%mm2\\n\\t\"\n\n\t\t\"psrlq\t$19, %%mm5\\n\\t\"\n\n\t\t\"pand\t%2, %%mm2\\n\\t\"\n\n\t\t\"pand\t%2, %%mm5\\n\\t\"\n\n\t\t\"por\t%%mm1, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm4, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm2, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm5, %%mm3\\n\\t\"\n\n\t\t\"psllq\t$16, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm3, %%mm0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\t:\"=m\"(*d):\"m\"(*s),\"m\"(blue_15mask):\"memory\");\n\n\t\td += 4;\n\n\t\ts += 16;\n\n\t}\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\twhile(s < end)\n\n\t{\n\n\t\tconst int src= *((uint32_t*)s)++;\n\n\t\t*d++ = ((src&0xF8)<<7) + ((src&0xF800)>>6) + ((src&0xF80000)>>19);\n\n\t}\n\n}\n", "idx": 23997}
{"project": "FFmpeg", "commit_id": "8eeacf31c5ea37baf6b222dc38d20cf4fd33c455", "target": 0, "func": "static void FUNC(hevc_loop_filter_chroma)(uint8_t *_pix, ptrdiff_t _xstride,\n\n                                          ptrdiff_t _ystride, int *_tc,\n\n                                          uint8_t *_no_p, uint8_t *_no_q)\n\n{\n\n    int d, j, no_p, no_q;\n\n    pixel *pix        = (pixel *)_pix;\n\n    ptrdiff_t xstride = _xstride / sizeof(pixel);\n\n    ptrdiff_t ystride = _ystride / sizeof(pixel);\n\n\n\n    for (j = 0; j < 2; j++) {\n\n        const int tc = _tc[j] << (BIT_DEPTH - 8);\n\n        if (tc <= 0) {\n\n            pix += 4 * ystride;\n\n            continue;\n\n        }\n\n        no_p = _no_p[j];\n\n        no_q = _no_q[j];\n\n\n\n        for (d = 0; d < 4; d++) {\n\n            int delta0;\n\n            const int p1 = P1;\n\n            const int p0 = P0;\n\n            const int q0 = Q0;\n\n            const int q1 = Q1;\n\n            delta0 = av_clip((((q0 - p0) << 2) + p1 - q1 + 4) >> 3, -tc, tc);\n\n            if (!no_p)\n\n                P0 = av_clip_pixel(p0 + delta0);\n\n            if (!no_q)\n\n                Q0 = av_clip_pixel(q0 - delta0);\n\n            pix += ystride;\n\n        }\n\n    }\n\n}\n", "idx": 23998}
{"project": "FFmpeg", "commit_id": "4e987f8282ff7658a6f804b9db39954bb59fa72e", "target": 0, "func": "static inline void xchg_mb_border(H264Context *h, uint8_t *src_y,\n\n                                  uint8_t *src_cb, uint8_t *src_cr,\n\n                                  int linesize, int uvlinesize,\n\n                                  int xchg, int simple, int pixel_shift){\n\n    MpegEncContext * const s = &h->s;\n\n    int deblock_left;\n\n    int deblock_top;\n\n    int top_idx = 1;\n\n    uint8_t *top_border_m1;\n\n    uint8_t *top_border;\n\n\n\n    if(!simple && FRAME_MBAFF){\n\n        if(s->mb_y&1){\n\n            if(!MB_MBAFF)\n\n                return;\n\n        }else{\n\n            top_idx = MB_MBAFF ? 0 : 1;\n\n        }\n\n    }\n\n\n\n    if(h->deblocking_filter == 2) {\n\n        deblock_left = h->left_type[0];\n\n        deblock_top  = h->top_type;\n\n    } else {\n\n        deblock_left = (s->mb_x > 0);\n\n        deblock_top =  (s->mb_y > !!MB_FIELD);\n\n    }\n\n\n\n    src_y  -=   linesize + 1 + pixel_shift;\n\n    src_cb -= uvlinesize + 1 + pixel_shift;\n\n    src_cr -= uvlinesize + 1 + pixel_shift;\n\n\n\n    top_border_m1 = h->top_borders[top_idx][s->mb_x-1];\n\n    top_border    = h->top_borders[top_idx][s->mb_x];\n\n\n\n#define XCHG(a,b,xchg)\\\n\n    if (pixel_shift) {\\\n\n        if (xchg) {\\\n\n            AV_SWAP64(b+0,a+0);\\\n\n            AV_SWAP64(b+8,a+8);\\\n\n        } else {\\\n\n            AV_COPY128(b,a); \\\n\n        }\\\n\n    } else \\\n\nif (xchg) AV_SWAP64(b,a);\\\n\nelse      AV_COPY64(b,a);\n\n\n\n    if(deblock_top){\n\n        if(deblock_left){\n\n            XCHG(top_border_m1 + (8 << pixel_shift), src_y - (7 << pixel_shift), 1);\n\n        }\n\n        XCHG(top_border + (0 << pixel_shift), src_y + (1 << pixel_shift), xchg);\n\n        XCHG(top_border + (8 << pixel_shift), src_y + (9 << pixel_shift), 1);\n\n        if(s->mb_x+1 < s->mb_width){\n\n            XCHG(h->top_borders[top_idx][s->mb_x+1], src_y + (17 << pixel_shift), 1);\n\n        }\n\n    }\n\n    if(simple || !CONFIG_GRAY || !(s->flags&CODEC_FLAG_GRAY)){\n\n        if(deblock_top){\n\n            if(deblock_left){\n\n                XCHG(top_border_m1 + (16 << pixel_shift), src_cb - (7 << pixel_shift), 1);\n\n                XCHG(top_border_m1 + (24 << pixel_shift), src_cr - (7 << pixel_shift), 1);\n\n            }\n\n            XCHG(top_border + (16 << pixel_shift), src_cb+1+pixel_shift, 1);\n\n            XCHG(top_border + (24 << pixel_shift), src_cr+1+pixel_shift, 1);\n\n        }\n\n    }\n\n}\n", "idx": 23999}
{"project": "FFmpeg", "commit_id": "f1783c05f1398b7a08f16f6aafbcf38a5323e770", "target": 0, "func": "static int hevc_decode_frame(AVCodecContext *avctx, void *data, int *got_output,\n\n                             AVPacket *avpkt)\n\n{\n\n    int ret;\n\n    HEVCContext *s = avctx->priv_data;\n\n\n\n    if (!avpkt->size) {\n\n        ret = ff_hevc_output_frame(s, data, 1);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        *got_output = ret;\n\n        return 0;\n\n    }\n\n\n\n    s->ref = NULL;\n\n    ret    = decode_nal_units(s, avpkt->data, avpkt->size);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    /* verify the SEI checksum */\n\n    if (avctx->err_recognition & AV_EF_CRCCHECK && s->is_decoded &&\n\n        avctx->err_recognition & AV_EF_EXPLODE &&\n\n        s->is_md5) {\n\n        ret = verify_md5(s, s->ref->frame);\n\n        if (ret < 0) {\n\n            ff_hevc_unref_frame(s, s->ref, ~0);\n\n            return ret;\n\n        }\n\n    }\n\n    s->is_md5 = 0;\n\n\n\n    if (s->is_decoded) {\n\n        av_log(avctx, AV_LOG_DEBUG, \"Decoded frame with POC %d.\\n\", s->poc);\n\n        s->is_decoded = 0;\n\n    }\n\n\n\n    if (s->output_frame->buf[0]) {\n\n        av_frame_move_ref(data, s->output_frame);\n\n        *got_output = 1;\n\n    }\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 24000}
{"project": "FFmpeg", "commit_id": "03616af2c91309d58f9419becf45d292cb93e625", "target": 1, "func": "static int decode_subframe(TAKDecContext *s, int32_t *decoded,\n\n                           int subframe_size, int prev_subframe_size)\n\n{\n\n    GetBitContext *gb = &s->gb;\n\n    int x, y, i, j, ret = 0;\n\n    int dshift, size, filter_quant, filter_order, filter_order16;\n\n    int tfilter[MAX_PREDICTORS];\n\n\n\n    if (!get_bits1(gb))\n\n        return decode_residues(s, decoded, subframe_size);\n\n\n\n    filter_order = predictor_sizes[get_bits(gb, 4)];\n\n\n\n    if (prev_subframe_size > 0 && get_bits1(gb)) {\n\n        if (filter_order > prev_subframe_size)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        decoded       -= filter_order;\n\n        subframe_size += filter_order;\n\n\n\n        if (filter_order > subframe_size)\n\n            return AVERROR_INVALIDDATA;\n\n    } else {\n\n        int lpc_mode;\n\n\n\n        if (filter_order > subframe_size)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        lpc_mode = get_bits(gb, 2);\n\n        if (lpc_mode > 2)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        if ((ret = decode_residues(s, decoded, filter_order)) < 0)\n\n            return ret;\n\n\n\n        if (lpc_mode)\n\n            decode_lpc(decoded, lpc_mode, filter_order);\n\n    }\n\n\n\n    dshift = get_bits_esc4(gb);\n\n    size   = get_bits1(gb) + 6;\n\n\n\n    filter_quant = 10;\n\n    if (get_bits1(gb)) {\n\n        filter_quant -= get_bits(gb, 3) + 1;\n\n        if (filter_quant < 3)\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    s->predictors[0] = get_sbits(gb, 10);\n\n    s->predictors[1] = get_sbits(gb, 10);\n\n    s->predictors[2] = get_sbits(gb, size) << (10 - size);\n\n    s->predictors[3] = get_sbits(gb, size) << (10 - size);\n\n    if (filter_order > 4) {\n\n        int tmp = size - get_bits1(gb);\n\n\n\n        for (i = 4; i < filter_order; i++) {\n\n            if (!(i & 3))\n\n                x = tmp - get_bits(gb, 2);\n\n            s->predictors[i] = get_sbits(gb, x) << (10 - size);\n\n        }\n\n    }\n\n\n\n    tfilter[0] = s->predictors[0] << 6;\n\n    for (i = 1; i < filter_order; i++) {\n\n        int32_t *p1 = &tfilter[0];\n\n        int32_t *p2 = &tfilter[i - 1];\n\n\n\n        for (j = 0; j < (i + 1) / 2; j++) {\n\n            x     = *p1 + (s->predictors[i] * *p2 + 256 >> 9);\n\n            *p2  += s->predictors[i] * *p1 + 256 >> 9;\n\n            *p1++ = x;\n\n            p2--;\n\n        }\n\n\n\n        tfilter[i] = s->predictors[i] << 6;\n\n    }\n\n\n\n    filter_order16 = FFALIGN(filter_order, 16);\n\n    AV_ZERO128(s->filter + filter_order16 - 16);\n\n    AV_ZERO128(s->filter + filter_order16 -  8);\n\n    x = 1 << (32 - (15 - filter_quant));\n\n    y = 1 << ((15 - filter_quant) - 1);\n\n    for (i = 0, j = filter_order - 1; i < filter_order / 2; i++, j--) {\n\n        s->filter[j] = x - ((tfilter[i] + y) >> (15 - filter_quant));\n\n        s->filter[i] = x - ((tfilter[j] + y) >> (15 - filter_quant));\n\n    }\n\n\n\n    if ((ret = decode_residues(s, &decoded[filter_order],\n\n                               subframe_size - filter_order)) < 0)\n\n        return ret;\n\n\n\n    for (i = 0; i < filter_order; i++)\n\n        s->residues[i] = *decoded++ >> dshift;\n\n\n\n    y    = FF_ARRAY_ELEMS(s->residues) - filter_order;\n\n    x    = subframe_size - filter_order;\n\n    while (x > 0) {\n\n        int tmp = FFMIN(y, x);\n\n\n\n        for (i = 0; i < tmp; i++) {\n\n            int v = 1 << (filter_quant - 1);\n\n\n\n            v += s->adsp.scalarproduct_int16(&s->residues[i], s->filter,\n\n                                             filter_order16);\n\n            v = (av_clip_intp2(v >> filter_quant, 13) << dshift) - *decoded;\n\n            *decoded++ = v;\n\n            s->residues[filter_order + i] = v >> dshift;\n\n        }\n\n\n\n        x -= tmp;\n\n        if (x > 0)\n\n            memcpy(s->residues, &s->residues[y], 2 * filter_order);\n\n    }\n\n\n\n    emms_c();\n\n\n\n    return 0;\n\n}\n", "idx": 24002}
{"project": "FFmpeg", "commit_id": "4a24837e07c4782658d1475b77506bccc3d0b5e2", "target": 1, "func": "static int dca_decode_frame(AVCodecContext * avctx,\n\n                            void *data, int *data_size,\n\n                            const uint8_t * buf, int buf_size)\n\n{\n\n\n\n    int i, j, k;\n\n    int16_t *samples = data;\n\n    DCAContext *s = avctx->priv_data;\n\n    int channels;\n\n\n\n\n\n    s->dca_buffer_size = dca_convert_bitstream(buf, buf_size, s->dca_buffer, DCA_MAX_FRAME_SIZE);\n\n    if (s->dca_buffer_size == -1) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Not a valid DCA frame\\n\");\n\n        return -1;\n\n    }\n\n\n\n    init_get_bits(&s->gb, s->dca_buffer, s->dca_buffer_size * 8);\n\n    if (dca_parse_frame_header(s) < 0) {\n\n        //seems like the frame is corrupt, try with the next one\n\n        *data_size=0;\n\n        return buf_size;\n\n    }\n\n    //set AVCodec values with parsed data\n\n    avctx->sample_rate = s->sample_rate;\n\n    avctx->bit_rate = s->bit_rate;\n\n\n\n    channels = s->prim_channels + !!s->lfe;\n\n    if(avctx->request_channels == 2 && s->prim_channels > 2) {\n\n        channels = 2;\n\n        s->output = DCA_STEREO;\n\n    }\n\n\n\n    avctx->channels = channels;\n\n    if(*data_size < (s->sample_blocks / 8) * 256 * sizeof(int16_t) * channels)\n\n        return -1;\n\n    *data_size = 0;\n\n    for (i = 0; i < (s->sample_blocks / 8); i++) {\n\n        dca_decode_block(s);\n\n        s->dsp.float_to_int16(s->tsamples, s->samples, 256 * channels);\n\n        /* interleave samples */\n\n        for (j = 0; j < 256; j++) {\n\n            for (k = 0; k < channels; k++)\n\n                samples[k] = s->tsamples[j + k * 256];\n\n            samples += channels;\n\n        }\n\n        *data_size += 256 * sizeof(int16_t) * channels;\n\n    }\n\n\n\n    return buf_size;\n\n}\n", "idx": 24004}
{"project": "FFmpeg", "commit_id": "229843aa359ae0c9519977d7fa952688db63f559", "target": 0, "func": "static int teletext_decode_frame(AVCodecContext *avctx, void *data, int *data_size, AVPacket *pkt)\n\n{\n\n    TeletextContext *ctx = avctx->priv_data;\n\n    AVSubtitle      *sub = data;\n\n    int             ret = 0;\n\n\n\n    if (!ctx->vbi) {\n\n        if (!(ctx->vbi = vbi_decoder_new()))\n\n            return AVERROR(ENOMEM);\n\n        if (!vbi_event_handler_add(ctx->vbi, VBI_EVENT_TTX_PAGE, handler, ctx)) {\n\n            vbi_decoder_delete(ctx->vbi);\n\n            ctx->vbi = NULL;\n\n            return AVERROR(ENOMEM);\n\n        }\n\n    }\n\n\n\n    if (avctx->pkt_timebase.den && pkt->pts != AV_NOPTS_VALUE)\n\n        ctx->pts = av_rescale_q(pkt->pts, avctx->pkt_timebase, AV_TIME_BASE_Q);\n\n\n\n    if (pkt->size) {\n\n        int lines;\n\n        const int full_pes_size = pkt->size + 45; /* PES header is 45 bytes */\n\n\n\n        // We allow unreasonably big packets, even if the standard only allows a max size of 1472\n\n        if (full_pes_size < 184 || full_pes_size > 65504 || full_pes_size % 184 != 0)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        ctx->handler_ret = pkt->size;\n\n\n\n        if (data_identifier_is_teletext(*pkt->data)) {\n\n            if ((lines = slice_to_vbi_lines(ctx, pkt->data + 1, pkt->size - 1)) < 0)\n\n                return lines;\n\n            av_dlog(avctx, \"ctx=%p buf_size=%d lines=%u pkt_pts=%7.3f\\n\",\n\n                    ctx, pkt->size, lines, (double)pkt->pts/90000.0);\n\n            if (lines > 0) {\n\n#ifdef DEBUG\n\n                int i;\n\n                av_log(avctx, AV_LOG_DEBUG, \"line numbers:\");\n\n                for(i = 0; i < lines; i++)\n\n                    av_log(avctx, AV_LOG_DEBUG, \" %d\", ctx->sliced[i].line);\n\n                av_log(avctx, AV_LOG_DEBUG, \"\\n\");\n\n#endif\n\n                vbi_decode(ctx->vbi, ctx->sliced, lines, 0.0);\n\n                ctx->lines_processed += lines;\n\n            }\n\n        }\n\n        ctx->pts = AV_NOPTS_VALUE;\n\n        ret = ctx->handler_ret;\n\n    }\n\n\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    // is there a subtitle to pass?\n\n    if (ctx->nb_pages) {\n\n        int i;\n\n        sub->format = ctx->format_id;\n\n        sub->start_display_time = 0;\n\n        sub->end_display_time = ctx->sub_duration;\n\n        sub->num_rects = 0;\n\n        sub->pts = ctx->pages->pts;\n\n\n\n        if (ctx->pages->sub_rect->type != SUBTITLE_NONE) {\n\n            sub->rects = av_malloc(sizeof(*sub->rects));\n\n            if (sub->rects) {\n\n                sub->num_rects = 1;\n\n                sub->rects[0] = ctx->pages->sub_rect;\n\n            } else {\n\n                ret = AVERROR(ENOMEM);\n\n            }\n\n        } else {\n\n            av_log(avctx, AV_LOG_DEBUG, \"sending empty sub\\n\");\n\n            sub->rects = NULL;\n\n        }\n\n        if (!sub->rects) // no rect was passed\n\n            subtitle_rect_free(&ctx->pages->sub_rect);\n\n\n\n        for (i = 0; i < ctx->nb_pages - 1; i++)\n\n            ctx->pages[i] = ctx->pages[i + 1];\n\n        ctx->nb_pages--;\n\n\n\n        if (ret >= 0)\n\n            *data_size = 1;\n\n    } else\n\n        *data_size = 0;\n\n\n\n    return ret;\n\n}\n", "idx": 24005}
{"project": "FFmpeg", "commit_id": "c341f734e5f9d6af4a8fdcceb6f5d12de6395c76", "target": 1, "func": "static inline int hpel_motion_lowres(MpegEncContext *s,\n\n                                     uint8_t *dest, uint8_t *src,\n\n                                     int field_based, int field_select,\n\n                                     int src_x, int src_y,\n\n                                     int width, int height, int stride,\n\n                                     int h_edge_pos, int v_edge_pos,\n\n                                     int w, int h, h264_chroma_mc_func *pix_op,\n\n                                     int motion_x, int motion_y)\n\n{\n\n    const int lowres   = s->avctx->lowres;\n\n    const int op_index = FFMIN(lowres, 3);\n\n    const int s_mask   = (2 << lowres) - 1;\n\n    int emu = 0;\n\n    int sx, sy;\n\n\n\n    if (s->quarter_sample) {\n\n        motion_x /= 2;\n\n        motion_y /= 2;\n\n    }\n\n\n\n    sx = motion_x & s_mask;\n\n    sy = motion_y & s_mask;\n\n    src_x += motion_x >> lowres + 1;\n\n    src_y += motion_y >> lowres + 1;\n\n\n\n    src   += src_y * stride + src_x;\n\n\n\n    if ((unsigned)src_x > FFMAX( h_edge_pos - (!!sx) - w,                 0) ||\n\n        (unsigned)src_y > FFMAX((v_edge_pos >> field_based) - (!!sy) - h, 0)) {\n\n        s->vdsp.emulated_edge_mc(s->edge_emu_buffer, src, s->linesize, w + 1,\n\n                                (h + 1) << field_based, src_x,\n\n                                src_y   << field_based,\n\n                                h_edge_pos,\n\n                                v_edge_pos);\n\n        src = s->edge_emu_buffer;\n\n        emu = 1;\n\n    }\n\n\n\n    sx = (sx << 2) >> lowres;\n\n    sy = (sy << 2) >> lowres;\n\n    if (field_select)\n\n        src += s->linesize;\n\n    pix_op[op_index](dest, src, stride, h, sx, sy);\n\n    return emu;\n\n}\n", "idx": 24008}
{"project": "FFmpeg", "commit_id": "2f7a12fab5a2ea17bd78b155e9af965669fb9b52", "target": 1, "func": "av_cold void ff_mlz_init_dict(void* context, MLZ *mlz) {\n\n    mlz->dict = av_malloc_array(TABLE_SIZE, sizeof(*mlz->dict));\n\n\n\n    mlz->flush_code            = FLUSH_CODE;\n\n    mlz->current_dic_index_max = DIC_INDEX_INIT;\n\n    mlz->dic_code_bit          = CODE_BIT_INIT;\n\n    mlz->bump_code             = (DIC_INDEX_INIT - 1);\n\n    mlz->next_code             = FIRST_CODE;\n\n    mlz->freeze_flag           = 0;\n\n    mlz->context               = context;\n\n}\n", "idx": 24011}
{"project": "FFmpeg", "commit_id": "4f5eaf0b5956e492ee5023929669b1d09aaf6299", "target": 1, "func": "static int decode_slice_chroma(AVCodecContext *avctx, SliceContext *slice,\n\n                               uint16_t *dst, int dst_stride,\n\n                               const uint8_t *buf, unsigned buf_size,\n\n                               const int16_t *qmat, int log2_blocks_per_mb)\n\n{\n\n    ProresContext *ctx = avctx->priv_data;\n\n    LOCAL_ALIGNED_16(int16_t, blocks, [8*4*64]);\n\n    int16_t *block;\n\n    GetBitContext gb;\n\n    int i, j, blocks_per_slice = slice->mb_count << log2_blocks_per_mb;\n\n    int ret;\n\n\n\n    for (i = 0; i < blocks_per_slice; i++)\n\n        ctx->bdsp.clear_block(blocks+(i<<6));\n\n\n\n    init_get_bits(&gb, buf, buf_size << 3);\n\n\n\n    decode_dc_coeffs(&gb, blocks, blocks_per_slice);\n\n    if ((ret = decode_ac_coeffs(avctx, &gb, blocks, blocks_per_slice)) < 0)\n\n        return ret;\n\n\n\n    block = blocks;\n\n    for (i = 0; i < slice->mb_count; i++) {\n\n        for (j = 0; j < log2_blocks_per_mb; j++) {\n\n            ctx->prodsp.idct_put(dst,              dst_stride, block+(0<<6), qmat);\n\n            ctx->prodsp.idct_put(dst+4*dst_stride, dst_stride, block+(1<<6), qmat);\n\n            block += 2*64;\n\n            dst += 8;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 24012}
{"project": "FFmpeg", "commit_id": "c0b17ea106b94f79255f81ec36ea50096e1ae985", "target": 1, "func": "static int roq_dpcm_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n\n                                 const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    int i, stereo, data_size, ret;\n\n    const int16_t *in = frame ? (const int16_t *)frame->data[0] : NULL;\n\n    uint8_t *out;\n\n    ROQDPCMContext *context = avctx->priv_data;\n\n\n\n    stereo = (avctx->channels == 2);\n\n\n\n    if (!in && context->input_frames >= 8)\n\n        return 0;\n\n\n\n    if (in && context->input_frames < 8) {\n\n        memcpy(&context->frame_buffer[context->buffered_samples * avctx->channels],\n\n               in, avctx->frame_size * avctx->channels * sizeof(*in));\n\n        context->buffered_samples += avctx->frame_size;\n\n        if (context->input_frames == 0)\n\n            context->first_pts = frame->pts;\n\n        if (context->input_frames < 7) {\n\n            context->input_frames++;\n\n            return 0;\n\n\n\n\n        in = context->frame_buffer;\n\n\n\n\n    if (stereo) {\n\n        context->lastSample[0] &= 0xFF00;\n\n        context->lastSample[1] &= 0xFF00;\n\n\n\n\n    if (context->input_frames == 7 || !in)\n\n        data_size = avctx->channels * context->buffered_samples;\n\n    else\n\n        data_size = avctx->channels * avctx->frame_size;\n\n\n\n    if ((ret = ff_alloc_packet2(avctx, avpkt, ROQ_HEADER_SIZE + data_size)))\n\n        return ret;\n\n    out = avpkt->data;\n\n\n\n    bytestream_put_byte(&out, stereo ? 0x21 : 0x20);\n\n    bytestream_put_byte(&out, 0x10);\n\n    bytestream_put_le32(&out, data_size);\n\n\n\n    if (stereo) {\n\n        bytestream_put_byte(&out, (context->lastSample[1])>>8);\n\n        bytestream_put_byte(&out, (context->lastSample[0])>>8);\n\n    } else\n\n        bytestream_put_le16(&out, context->lastSample[0]);\n\n\n\n    /* Write the actual samples */\n\n    for (i = 0; i < data_size; i++)\n\n        *out++ = dpcm_predict(&context->lastSample[i & 1], *in++);\n\n\n\n    avpkt->pts      = context->input_frames <= 7 ? context->first_pts : frame->pts;\n\n    avpkt->duration = data_size / avctx->channels;\n\n\n\n    context->input_frames++;\n\n    if (!in)\n\n        context->input_frames = FFMAX(context->input_frames, 8);\n\n\n\n    *got_packet_ptr = 1;\n\n    return 0;\n", "idx": 24013}
{"project": "FFmpeg", "commit_id": "7684a36113fa12c88ba80b5498f05849a6b58632", "target": 0, "func": "static int mxf_write_footer(AVFormatContext *s)\n\n{\n\n    MXFContext *mxf = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n\n\n    mxf->duration = mxf->last_indexed_edit_unit + mxf->edit_units_count;\n\n\n\n    mxf_write_klv_fill(s);\n\n    mxf->footer_partition_offset = avio_tell(pb);\n\n    if (mxf->edit_unit_byte_count) { // no need to repeat index\n\n        mxf_write_partition(s, 0, 0, footer_partition_key, 0);\n\n    } else {\n\n        mxf_write_partition(s, 0, 2, footer_partition_key, 0);\n\n\n\n        mxf_write_klv_fill(s);\n\n        mxf_write_index_table_segment(s);\n\n    }\n\n\n\n    mxf_write_klv_fill(s);\n\n    mxf_write_random_index_pack(s);\n\n\n\n    if (s->pb->seekable) {\n\n        avio_seek(pb, 0, SEEK_SET);\n\n        if (mxf->edit_unit_byte_count) {\n\n            mxf_write_partition(s, 1, 2, header_closed_partition_key, 1);\n\n            mxf_write_klv_fill(s);\n\n            mxf_write_index_table_segment(s);\n\n        } else {\n\n            mxf_write_partition(s, 0, 0, header_closed_partition_key, 1);\n\n        }\n\n    }\n\n\n\n    ff_audio_interleave_close(s);\n\n\n\n    av_freep(&mxf->index_entries);\n\n    av_freep(&mxf->body_partition_offset);\n\n    av_freep(&mxf->timecode_track->priv_data);\n\n    av_freep(&mxf->timecode_track);\n\n\n\n    mxf_free(s);\n\n\n\n    return 0;\n\n}\n", "idx": 24014}
{"project": "FFmpeg", "commit_id": "cd19c677cb5dcaecc472c021bd38370817740a5e", "target": 1, "func": "static int decode_frame(AVCodecContext *avctx, \n\n                             void *data, int *data_size,\n\n                             uint8_t *buf, int buf_size)\n\n{\n\n    H264Context *h = avctx->priv_data;\n\n    MpegEncContext *s = &h->s;\n\n    AVFrame *pict = data; \n\n    int buf_index;\n\n    \n\n    s->flags= avctx->flags;\n\n    s->flags2= avctx->flags2;\n\n\n\n   /* no supplementary picture */\n\n    if (buf_size == 0) {\n\n        return 0;\n\n    }\n\n    \n\n    if(s->flags&CODEC_FLAG_TRUNCATED){\n\n        int next= find_frame_end(h, buf, buf_size);\n\n        \n\n        if( ff_combine_frame(&s->parse_context, next, &buf, &buf_size) < 0 )\n\n            return buf_size;\n\n//printf(\"next:%d buf_size:%d last_index:%d\\n\", next, buf_size, s->parse_context.last_index);\n\n    }\n\n\n\n    if(h->is_avc && !h->got_avcC) {\n\n        int i, cnt, nalsize;\n\n        unsigned char *p = avctx->extradata;\n\n        if(avctx->extradata_size < 7) {\n\n            av_log(avctx, AV_LOG_ERROR, \"avcC too short\\n\");\n\n            return -1;\n\n        }\n\n        if(*p != 1) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Unknown avcC version %d\\n\", *p);\n\n            return -1;\n\n        }\n\n        /* sps and pps in the avcC always have length coded with 2 bytes,\n\n           so put a fake nal_length_size = 2 while parsing them */\n\n        h->nal_length_size = 2;\n\n        // Decode sps from avcC\n\n        cnt = *(p+5) & 0x1f; // Number of sps\n\n        p += 6;\n\n        for (i = 0; i < cnt; i++) {\n\n            nalsize = BE_16(p) + 2;\n\n            if(decode_nal_units(h, p, nalsize) < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Decoding sps %d from avcC failed\\n\", i);\n\n                return -1;\n\n            }\n\n            p += nalsize;\n\n        }        \n\n        // Decode pps from avcC\n\n        cnt = *(p++); // Number of pps\n\n        for (i = 0; i < cnt; i++) {\n\n            nalsize = BE_16(p) + 2;\n\n            if(decode_nal_units(h, p, nalsize)  != nalsize) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Decoding pps %d from avcC failed\\n\", i);\n\n                return -1;\n\n            }\n\n            p += nalsize;\n\n        }        \n\n        // Now store right nal length size, that will be use to parse all other nals\n\n        h->nal_length_size = ((*(((char*)(avctx->extradata))+4))&0x03)+1;\n\n        // Do not reparse avcC\n\n        h->got_avcC = 1;\n\n    }\n\n\n\n    if(!h->is_avc && s->avctx->extradata_size && s->picture_number==0){\n\n        if(decode_nal_units(h, s->avctx->extradata, s->avctx->extradata_size) < 0) \n\n            return -1;\n\n    }\n\n\n\n    buf_index=decode_nal_units(h, buf, buf_size);\n\n    if(buf_index < 0) \n\n        return -1;\n\n\n\n    //FIXME do something with unavailable reference frames    \n\n \n\n//    if(ret==FRAME_SKIPPED) return get_consumed_bytes(s, buf_index, buf_size);\n\n    if(!s->current_picture_ptr){\n\n        av_log(h->s.avctx, AV_LOG_DEBUG, \"error, NO frame\\n\");\n\n        return -1;\n\n    }\n\n\n\n    {\n\n        Picture *out = s->current_picture_ptr;\n\n#if 0 //decode order\n\n        *data_size = sizeof(AVFrame);\n\n#else\n\n        /* Sort B-frames into display order */\n\n        Picture *cur = s->current_picture_ptr;\n\n        Picture *prev = h->delayed_output_pic;\n\n        int out_idx = 0;\n\n        int pics = 0;\n\n        int out_of_order;\n\n        int cross_idr = 0;\n\n        int dropped_frame = 0;\n\n        int i;\n\n\n\n        if(h->sps.bitstream_restriction_flag\n\n           && s->avctx->has_b_frames < h->sps.num_reorder_frames){\n\n            s->avctx->has_b_frames = h->sps.num_reorder_frames;\n\n            s->low_delay = 0;\n\n        }\n\n\n\n        while(h->delayed_pic[pics]) pics++;\n\n        h->delayed_pic[pics++] = cur;\n\n        if(cur->reference == 0)\n\n            cur->reference = 1;\n\n\n\n        for(i=0; h->delayed_pic[i]; i++)\n\n            if(h->delayed_pic[i]->key_frame || h->delayed_pic[i]->poc==0)\n\n                cross_idr = 1;\n\n\n\n        out = h->delayed_pic[0];\n\n        for(i=1; h->delayed_pic[i] && !h->delayed_pic[i]->key_frame; i++)\n\n            if(h->delayed_pic[i]->poc < out->poc){\n\n                out = h->delayed_pic[i];\n\n                out_idx = i;\n\n            }\n\n\n\n        out_of_order = !cross_idr && prev && out->poc < prev->poc;\n\n        if(prev && pics <= s->avctx->has_b_frames)\n\n            out = prev;\n\n        else if((out_of_order && pics-1 == s->avctx->has_b_frames)\n\n           || (s->low_delay && \n\n            ((!cross_idr && prev && out->poc > prev->poc + 2)\n\n             || cur->pict_type == B_TYPE)))\n\n        {\n\n            s->low_delay = 0;\n\n            s->avctx->has_b_frames++;\n\n            out = prev;\n\n        }\n\n        else if(out_of_order)\n\n            out = prev;\n\n\n\n        if(out_of_order || pics > s->avctx->has_b_frames){\n\n            dropped_frame = (out != h->delayed_pic[out_idx]);\n\n            for(i=out_idx; h->delayed_pic[i]; i++)\n\n                h->delayed_pic[i] = h->delayed_pic[i+1];\n\n        }\n\n\n\n        if(prev == out && !dropped_frame)\n\n            *data_size = 0;\n\n        else\n\n            *data_size = sizeof(AVFrame);\n\n        if(prev && prev != out && prev->reference == 1)\n\n            prev->reference = 0;\n\n        h->delayed_output_pic = out;\n\n#endif\n\n\n\n        *pict= *(AVFrame*)out;\n\n    }\n\n\n\n    assert(pict->data[0]);\n\n    ff_print_debug_info(s, pict);\n\n//printf(\"out %d\\n\", (int)pict->data[0]);\n\n#if 0 //?\n\n\n\n    /* Return the Picture timestamp as the frame number */\n\n    /* we substract 1 because it is added on utils.c    */\n\n    avctx->frame_number = s->picture_number - 1;\n\n#endif\n\n    return get_consumed_bytes(s, buf_index, buf_size);\n\n}\n", "idx": 24018}
{"project": "FFmpeg", "commit_id": "98308bd44face14ea3142b501d16226eec23b75a", "target": 0, "func": "static int mkv_write_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    MatroskaMuxContext *mkv = s->priv_data;\n\n    int codec_type          = s->streams[pkt->stream_index]->codec->codec_type;\n\n    int keyframe            = !!(pkt->flags & AV_PKT_FLAG_KEY);\n\n    int cluster_size;\n\n    int cluster_size_limit;\n\n    int64_t cluster_time;\n\n    int64_t cluster_time_limit;\n\n    AVIOContext *pb;\n\n    int ret;\n\n\n\n    if (mkv->tracks[pkt->stream_index].write_dts)\n\n        cluster_time = pkt->dts - mkv->cluster_pts;\n\n    else\n\n        cluster_time = pkt->pts - mkv->cluster_pts;\n\n\n\n    // start a new cluster every 5 MB or 5 sec, or 32k / 1 sec for streaming or\n\n    // after 4k and on a keyframe\n\n    if (s->pb->seekable) {\n\n        pb = s->pb;\n\n        cluster_size = avio_tell(pb) - mkv->cluster_pos;\n\n        cluster_time_limit = 5000;\n\n        cluster_size_limit = 5 * 1024 * 1024;\n\n    } else {\n\n        pb = mkv->dyn_bc;\n\n        cluster_size = avio_tell(pb);\n\n        cluster_time_limit = 1000;\n\n        cluster_size_limit = 32 * 1024;\n\n    }\n\n\n\n    if (mkv->cluster_pos &&\n\n        (cluster_size > cluster_size_limit ||\n\n         cluster_time > cluster_time_limit ||\n\n         (codec_type == AVMEDIA_TYPE_VIDEO && keyframe &&\n\n          cluster_size > 4 * 1024))) {\n\n        av_log(s, AV_LOG_DEBUG, \"Starting new cluster at offset %\" PRIu64\n\n               \" bytes, pts %\" PRIu64 \"dts %\" PRIu64 \"\\n\",\n\n               avio_tell(pb), pkt->pts, pkt->dts);\n\n        end_ebml_master(pb, mkv->cluster);\n\n        mkv->cluster_pos = 0;\n\n        if (mkv->dyn_bc)\n\n            mkv_flush_dynbuf(s);\n\n    }\n\n\n\n    // check if we have an audio packet cached\n\n    if (mkv->cur_audio_pkt.size > 0) {\n\n        ret = mkv_write_packet_internal(s, &mkv->cur_audio_pkt);\n\n        av_free_packet(&mkv->cur_audio_pkt);\n\n        if (ret < 0) {\n\n            av_log(s, AV_LOG_ERROR, \"Could not write cached audio packet ret:%d\\n\", ret);\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    // buffer an audio packet to ensure the packet containing the video\n\n    // keyframe's timecode is contained in the same cluster for WebM\n\n    if (codec_type == AVMEDIA_TYPE_AUDIO) {\n\n        mkv->cur_audio_pkt = *pkt;\n\n        if (pkt->buf) {\n\n            mkv->cur_audio_pkt.buf = av_buffer_ref(pkt->buf);\n\n            ret = mkv->cur_audio_pkt.buf ? 0 : AVERROR(ENOMEM);\n\n        } else\n\n            ret = av_dup_packet(&mkv->cur_audio_pkt);\n\n    } else\n\n        ret = mkv_write_packet_internal(s, pkt);\n\n    return ret;\n\n}\n", "idx": 24019}
{"project": "FFmpeg", "commit_id": "7495c3066d7b67bbc74b1d5565684ff48e430099", "target": 0, "func": "static int64_t getutime(void)\n\n{\n\n#ifdef HAVE_GETRUSAGE\n\n    struct rusage rusage;\n\n\n\n    getrusage(RUSAGE_SELF, &rusage);\n\n    return (rusage.ru_utime.tv_sec * 1000000LL) + rusage.ru_utime.tv_usec;\n\n#elif defined(__MINGW32__)\n\n  return av_gettime();\n\n#endif\n\n}\n", "idx": 24020}
{"project": "FFmpeg", "commit_id": "061e340c05bde91ac988677e47bc562b04be5c20", "target": 0, "func": "static void colored_fputs(int level, const char *str)\n\n{\n\n    if (!*str)\n\n        return;\n\n\n\n    if (use_color < 0) {\n\n#if HAVE_SETCONSOLETEXTATTRIBUTE\n\n        CONSOLE_SCREEN_BUFFER_INFO con_info;\n\n        con = GetStdHandle(STD_ERROR_HANDLE);\n\n        use_color = (con != INVALID_HANDLE_VALUE) && !getenv(\"NO_COLOR\") &&\n\n                    !getenv(\"AV_LOG_FORCE_NOCOLOR\");\n\n        if (use_color) {\n\n            GetConsoleScreenBufferInfo(con, &con_info);\n\n            attr_orig  = con_info.wAttributes;\n\n            background = attr_orig & 0xF0;\n\n        }\n\n#elif HAVE_ISATTY\n\n        use_color = !getenv(\"NO_COLOR\") && !getenv(\"AV_LOG_FORCE_NOCOLOR\") &&\n\n                    (getenv(\"TERM\") && isatty(2) ||\n\n                     getenv(\"AV_LOG_FORCE_COLOR\"));\n\n        if (getenv(\"AV_LOG_FORCE_256COLOR\"))\n\n            use_color *= 256;\n\n#else\n\n        use_color = getenv(\"AV_LOG_FORCE_COLOR\") && !getenv(\"NO_COLOR\") &&\n\n                   !getenv(\"AV_LOG_FORCE_NOCOLOR\");\n\n#endif\n\n    }\n\n\n\n#if HAVE_SETCONSOLETEXTATTRIBUTE\n\n    if (use_color && level != AV_LOG_INFO/8)\n\n        SetConsoleTextAttribute(con, background | color[level]);\n\n    fputs(str, stderr);\n\n    if (use_color && level != AV_LOG_INFO/8)\n\n        SetConsoleTextAttribute(con, attr_orig);\n\n#else\n\n    if (use_color == 1 && level != AV_LOG_INFO/8) {\n\n        fprintf(stderr,\n\n                \"\\033[%d;3%dm%s\\033[0m\",\n\n                (color[level] >> 4) & 15,\n\n                color[level] & 15,\n\n                str);\n\n    } else if (use_color == 256 && level != AV_LOG_INFO/8) {\n\n        fprintf(stderr,\n\n                \"\\033[48;5;%dm\\033[38;5;%dm%s\\033[0m\",\n\n                (color[level] >> 16) & 0xff,\n\n                (color[level] >> 8) & 0xff,\n\n                str);\n\n    } else\n\n        fputs(str, stderr);\n\n#endif\n\n\n\n}\n", "idx": 24021}
{"project": "FFmpeg", "commit_id": "cc276c85d15272df6e44fb3252657a43cbd49555", "target": 0, "func": "AVFilterBufferRef *avfilter_default_get_audio_buffer(AVFilterLink *link, int perms,\n\n                                                     enum AVSampleFormat sample_fmt, int size,\n\n                                                     int64_t channel_layout, int planar)\n\n{\n\n    AVFilterBuffer *samples = av_mallocz(sizeof(AVFilterBuffer));\n\n    AVFilterBufferRef *ref = NULL;\n\n    int i, sample_size, chans_nb, bufsize, per_channel_size, step_size = 0;\n\n    char *buf;\n\n\n\n    if (!samples || !(ref = av_mallocz(sizeof(AVFilterBufferRef))))\n\n        goto fail;\n\n\n\n    ref->buf                   = samples;\n\n    ref->format                = sample_fmt;\n\n\n\n    ref->audio = av_mallocz(sizeof(AVFilterBufferRefAudioProps));\n\n    if (!ref->audio)\n\n        goto fail;\n\n\n\n    ref->audio->channel_layout = channel_layout;\n\n    ref->audio->size           = size;\n\n    ref->audio->planar         = planar;\n\n\n\n    /* make sure the buffer gets read permission or it's useless for output */\n\n    ref->perms = perms | AV_PERM_READ;\n\n\n\n    samples->refcount   = 1;\n\n    samples->free       = ff_avfilter_default_free_buffer;\n\n\n\n    sample_size = av_get_bytes_per_sample(sample_fmt);\n\n    chans_nb = av_get_channel_layout_nb_channels(channel_layout);\n\n\n\n    per_channel_size = size/chans_nb;\n\n    ref->audio->nb_samples = per_channel_size/sample_size;\n\n\n\n    /* Set the number of bytes to traverse to reach next sample of a particular channel:\n\n     * For planar, this is simply the sample size.\n\n     * For packed, this is the number of samples * sample_size.\n\n     */\n\n    for (i = 0; i < chans_nb; i++)\n\n        samples->linesize[i] = planar > 0 ? per_channel_size : sample_size;\n\n    memset(&samples->linesize[chans_nb], 0, (8-chans_nb) * sizeof(samples->linesize[0]));\n\n\n\n    /* Calculate total buffer size, round to multiple of 16 to be SIMD friendly */\n\n    bufsize = (size + 15)&~15;\n\n    buf = av_malloc(bufsize);\n\n    if (!buf)\n\n        goto fail;\n\n\n\n    /* For planar, set the start point of each channel's data within the buffer\n\n     * For packed, set the start point of the entire buffer only\n\n     */\n\n    samples->data[0] = buf;\n\n    if (buf && planar) {\n\n        for (i = 1; i < chans_nb; i++) {\n\n            step_size += per_channel_size;\n\n            samples->data[i] = buf + step_size;\n\n        }\n\n    } else {\n\n        for (i = 1; i < chans_nb; i++)\n\n            samples->data[i] = buf;\n\n    }\n\n\n\n    memset(&samples->data[chans_nb], 0, (8-chans_nb) * sizeof(samples->data[0]));\n\n\n\n    memcpy(ref->data,     samples->data,     sizeof(ref->data));\n\n    memcpy(ref->linesize, samples->linesize, sizeof(ref->linesize));\n\n\n\n    return ref;\n\n\n\nfail:\n\n    if (ref)\n\n        av_free(ref->audio);\n\n    av_free(ref);\n\n    av_free(samples);\n\n    return NULL;\n\n}\n", "idx": 24023}
{"project": "FFmpeg", "commit_id": "3d5822d9cf07d08bce82903e4715658f46b01b5c", "target": 1, "func": "static int encode_packet(Jpeg2000EncoderContext *s, Jpeg2000ResLevel *rlevel, int precno,\n\n                          uint8_t *expn, int numgbits)\n\n{\n\n    int bandno, empty = 1;\n\n\n\n    // init bitstream\n\n    *s->buf = 0;\n\n    s->bit_index = 0;\n\n\n\n    // header\n\n\n\n    // is the packet empty?\n\n    for (bandno = 0; bandno < rlevel->nbands; bandno++){\n\n        if (rlevel->band[bandno].coord[0][0] < rlevel->band[bandno].coord[0][1]\n\n        &&  rlevel->band[bandno].coord[1][0] < rlevel->band[bandno].coord[1][1]){\n\n            empty = 0;\n\n            break;\n\n        }\n\n    }\n\n\n\n    put_bits(s, !empty, 1);\n\n    if (empty){\n\n        j2k_flush(s);\n\n        return 0;\n\n    }\n\n\n\n    for (bandno = 0; bandno < rlevel->nbands; bandno++){\n\n        Jpeg2000Band *band = rlevel->band + bandno;\n\n        Jpeg2000Prec *prec = band->prec + precno;\n\n        int yi, xi, pos;\n\n        int cblknw = prec->nb_codeblocks_width;\n\n\n\n        if (band->coord[0][0] == band->coord[0][1]\n\n        ||  band->coord[1][0] == band->coord[1][1])\n\n            continue;\n\n\n\n        for (pos=0, yi = 0; yi < prec->nb_codeblocks_height; yi++){\n\n            for (xi = 0; xi < cblknw; xi++, pos++){\n\n                prec->cblkincl[pos].val = prec->cblk[yi * cblknw + xi].ninclpasses == 0;\n\n                tag_tree_update(prec->cblkincl + pos);\n\n                prec->zerobits[pos].val = expn[bandno] + numgbits - 1 - prec->cblk[yi * cblknw + xi].nonzerobits;\n\n                tag_tree_update(prec->zerobits + pos);\n\n            }\n\n        }\n\n\n\n        for (pos=0, yi = 0; yi < prec->nb_codeblocks_height; yi++){\n\n            for (xi = 0; xi < cblknw; xi++, pos++){\n\n                int pad = 0, llen, length;\n\n                Jpeg2000Cblk *cblk = prec->cblk + yi * cblknw + xi;\n\n\n\n                if (s->buf_end - s->buf < 20) // approximately\n\n                    return -1;\n\n\n\n                // inclusion information\n\n                tag_tree_code(s, prec->cblkincl + pos, 1);\n\n                if (!cblk->ninclpasses)\n\n                    continue;\n\n                // zerobits information\n\n                tag_tree_code(s, prec->zerobits + pos, 100);\n\n                // number of passes\n\n                putnumpasses(s, cblk->ninclpasses);\n\n\n\n                length = cblk->passes[cblk->ninclpasses-1].rate;\n\n                llen = av_log2(length) - av_log2(cblk->ninclpasses) - 2;\n\n                if (llen < 0){\n\n                    pad = -llen;\n\n                    llen = 0;\n\n                }\n\n                // length of code block\n\n                put_bits(s, 1, llen);\n\n                put_bits(s, 0, 1);\n\n                put_num(s, length, av_log2(length)+1+pad);\n\n            }\n\n        }\n\n    }\n\n    j2k_flush(s);\n\n    for (bandno = 0; bandno < rlevel->nbands; bandno++){\n\n        Jpeg2000Band *band = rlevel->band + bandno;\n\n        Jpeg2000Prec *prec = band->prec + precno;\n\n        int yi, cblknw = prec->nb_codeblocks_width;\n\n        for (yi =0; yi < prec->nb_codeblocks_height; yi++){\n\n            int xi;\n\n            for (xi = 0; xi < cblknw; xi++){\n\n                Jpeg2000Cblk *cblk = prec->cblk + yi * cblknw + xi;\n\n                if (cblk->ninclpasses){\n\n                    if (s->buf_end - s->buf < cblk->passes[cblk->ninclpasses-1].rate)\n\n                        return -1;\n\n                    bytestream_put_buffer(&s->buf, cblk->data,   cblk->passes[cblk->ninclpasses-1].rate\n\n                                                               - cblk->passes[cblk->ninclpasses-1].flushed_len);\n\n                    bytestream_put_buffer(&s->buf, cblk->passes[cblk->ninclpasses-1].flushed,\n\n                                                   cblk->passes[cblk->ninclpasses-1].flushed_len);\n\n                }\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 24026}
{"project": "FFmpeg", "commit_id": "d164ad3298c155330e303bea907920643b5d74a3", "target": 1, "func": "static int ivi_init_tiles(IVIBandDesc *band, IVITile *ref_tile,\n\n                          int p, int b, int t_height, int t_width)\n\n{\n\n    int x, y;\n\n    IVITile *tile = band->tiles;\n\n\n\n    for (y = 0; y < band->height; y += t_height) {\n\n        for (x = 0; x < band->width; x += t_width) {\n\n            tile->xpos     = x;\n\n            tile->ypos     = y;\n\n            tile->mb_size  = band->mb_size;\n\n            tile->width    = FFMIN(band->width - x,  t_width);\n\n            tile->height   = FFMIN(band->height - y, t_height);\n\n            tile->is_empty = tile->data_size = 0;\n\n            /* calculate number of macroblocks */\n\n            tile->num_MBs  = IVI_MBs_PER_TILE(tile->width, tile->height,\n\n                                              band->mb_size);\n\n\n\n            av_freep(&tile->mbs);\n\n            tile->mbs = av_malloc(tile->num_MBs * sizeof(IVIMbInfo));\n\n            if (!tile->mbs)\n\n                return AVERROR(ENOMEM);\n\n\n\n            tile->ref_mbs = 0;\n\n            if (p || b) {\n\n                if (tile->num_MBs != ref_tile->num_MBs) {\n\n                    av_log(NULL, AV_LOG_DEBUG, \"ref_tile mismatch\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                tile->ref_mbs = ref_tile->mbs;\n\n                ref_tile++;\n\n            }\n\n            tile++;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24027}
{"project": "FFmpeg", "commit_id": "a0e7079a207fc38cb3754cf11a29863c81f633e4", "target": 1, "func": "static av_cold int common_end(AVCodecContext *avctx){\n    FFV1Context *s = avctx->priv_data;\n    int i, j;\n    for(j=0; j<s->slice_count; j++){\n        FFV1Context *fs= s->slice_context[j];\n        for(i=0; i<s->plane_count; i++){\n            PlaneContext *p= &fs->plane[i];\n            av_freep(&p->state);\n            av_freep(&p->vlc_state);\n        av_freep(&fs->sample_buffer);\n    av_freep(&avctx->stats_out);\n    for(j=0; j<s->quant_table_count; j++){\n        av_freep(&s->initial_states[j]);\n            FFV1Context *sf= s->slice_context[i];\n            av_freep(&sf->rc_stat2[j]);\n        av_freep(&s->rc_stat2[j]);\n    return 0;", "idx": 24028}
{"project": "FFmpeg", "commit_id": "be630b1e08ebe8f766b1798accd6b8e5e096f5aa", "target": 1, "func": "unsigned ff_dxva2_get_surface_index(const AVCodecContext *avctx,\n\n                                    const AVDXVAContext *ctx,\n\n                                    const AVFrame *frame)\n\n{\n\n    void *surface = ff_dxva2_get_surface(frame);\n\n    unsigned i;\n\n\n\n    for (i = 0; i < DXVA_CONTEXT_COUNT(avctx, ctx); i++)\n\n        if (DXVA_CONTEXT_SURFACE(avctx, ctx, i) == surface)\n\n            return i;\n\n\n\n    assert(0);\n\n    return 0;\n\n}\n", "idx": 24029}
{"project": "FFmpeg", "commit_id": "14bd2a9f25fc0de4fb1a2d4afaef09162c51bb35", "target": 0, "func": "static int find_optimal_param(uint32_t sum, int n)\n\n{\n\n    int k, k_opt;\n\n    uint32_t nbits[MAX_RICE_PARAM+1];\n\n\n\n    k_opt = 0;\n\n    nbits[0] = UINT32_MAX;\n\n    for(k=0; k<=MAX_RICE_PARAM; k++) {\n\n        nbits[k] = rice_encode_count(sum, n, k);\n\n        if(nbits[k] < nbits[k_opt]) {\n\n            k_opt = k;\n\n        }\n\n    }\n\n    return k_opt;\n\n}\n", "idx": 24037}
{"project": "FFmpeg", "commit_id": "cd2f7ed0007f4803b6bd845366b2398abb32c355", "target": 0, "func": "static void ts_str(char buffer[60], int64_t ts, AVRational base)\n\n{\n\n    if (ts == AV_NOPTS_VALUE) {\n\n        strcpy(buffer, \" NOPTS   \");\n\n        return;\n\n    }\n\n    ts= av_rescale_q(ts, base, (AVRational){1, 1000000});\n\n    snprintf(buffer, 60, \"%c%Ld.%06Ld\", ts<0 ? '-' : ' ', FFABS(ts)/1000000, FFABS(ts)%1000000);\n\n}\n", "idx": 24048}
{"project": "FFmpeg", "commit_id": "3819db745da2ac7fb3faacb116788c32f4753f34", "target": 0, "func": "static void rpza_decode_stream(RpzaContext *s)\n\n{\n\n    int width = s->avctx->width;\n\n    int stride = s->frame.linesize[0] / 2;\n\n    int row_inc = stride - 4;\n\n    int stream_ptr = 0;\n\n    int chunk_size;\n\n    unsigned char opcode;\n\n    int n_blocks;\n\n    unsigned short colorA = 0, colorB;\n\n    unsigned short color4[4];\n\n    unsigned char index, idx;\n\n    unsigned short ta, tb;\n\n    unsigned short *pixels = (unsigned short *)s->frame.data[0];\n\n\n\n    int row_ptr = 0;\n\n    int pixel_ptr = 0;\n\n    int block_ptr;\n\n    int pixel_x, pixel_y;\n\n    int total_blocks;\n\n\n\n    /* First byte is always 0xe1. Warn if it's different */\n\n    if (s->buf[stream_ptr] != 0xe1)\n\n        av_log(s->avctx, AV_LOG_ERROR, \"First chunk byte is 0x%02x instead of 0xe1\\n\",\n\n            s->buf[stream_ptr]);\n\n\n\n    /* Get chunk size, ingnoring first byte */\n\n    chunk_size = AV_RB32(&s->buf[stream_ptr]) & 0x00FFFFFF;\n\n    stream_ptr += 4;\n\n\n\n    /* If length mismatch use size from MOV file and try to decode anyway */\n\n    if (chunk_size != s->size)\n\n        av_log(s->avctx, AV_LOG_ERROR, \"MOV chunk size != encoded chunk size; using MOV chunk size\\n\");\n\n\n\n    chunk_size = s->size;\n\n\n\n    /* Number of 4x4 blocks in frame. */\n\n    total_blocks = ((s->avctx->width + 3) / 4) * ((s->avctx->height + 3) / 4);\n\n\n\n    /* Process chunk data */\n\n    while (stream_ptr < chunk_size) {\n\n        opcode = s->buf[stream_ptr++]; /* Get opcode */\n\n\n\n        n_blocks = (opcode & 0x1f) + 1; /* Extract block counter from opcode */\n\n\n\n        /* If opcode MSbit is 0, we need more data to decide what to do */\n\n        if ((opcode & 0x80) == 0) {\n\n            colorA = (opcode << 8) | (s->buf[stream_ptr++]);\n\n            opcode = 0;\n\n            if ((s->buf[stream_ptr] & 0x80) != 0) {\n\n                /* Must behave as opcode 110xxxxx, using colorA computed\n\n                 * above. Use fake opcode 0x20 to enter switch block at\n\n                 * the right place */\n\n                opcode = 0x20;\n\n                n_blocks = 1;\n\n            }\n\n        }\n\n\n\n        switch (opcode & 0xe0) {\n\n\n\n        /* Skip blocks */\n\n        case 0x80:\n\n            while (n_blocks--) {\n\n              ADVANCE_BLOCK();\n\n            }\n\n            break;\n\n\n\n        /* Fill blocks with one color */\n\n        case 0xa0:\n\n            colorA = AV_RB16 (&s->buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            while (n_blocks--) {\n\n                block_ptr = row_ptr + pixel_ptr;\n\n                for (pixel_y = 0; pixel_y < 4; pixel_y++) {\n\n                    for (pixel_x = 0; pixel_x < 4; pixel_x++){\n\n                        pixels[block_ptr] = colorA;\n\n                        block_ptr++;\n\n                    }\n\n                    block_ptr += row_inc;\n\n                }\n\n                ADVANCE_BLOCK();\n\n            }\n\n            break;\n\n\n\n        /* Fill blocks with 4 colors */\n\n        case 0xc0:\n\n            colorA = AV_RB16 (&s->buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n        case 0x20:\n\n            colorB = AV_RB16 (&s->buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n\n\n            /* sort out the colors */\n\n            color4[0] = colorB;\n\n            color4[1] = 0;\n\n            color4[2] = 0;\n\n            color4[3] = colorA;\n\n\n\n            /* red components */\n\n            ta = (colorA >> 10) & 0x1F;\n\n            tb = (colorB >> 10) & 0x1F;\n\n            color4[1] |= ((11 * ta + 21 * tb) >> 5) << 10;\n\n            color4[2] |= ((21 * ta + 11 * tb) >> 5) << 10;\n\n\n\n            /* green components */\n\n            ta = (colorA >> 5) & 0x1F;\n\n            tb = (colorB >> 5) & 0x1F;\n\n            color4[1] |= ((11 * ta + 21 * tb) >> 5) << 5;\n\n            color4[2] |= ((21 * ta + 11 * tb) >> 5) << 5;\n\n\n\n            /* blue components */\n\n            ta = colorA & 0x1F;\n\n            tb = colorB & 0x1F;\n\n            color4[1] |= ((11 * ta + 21 * tb) >> 5);\n\n            color4[2] |= ((21 * ta + 11 * tb) >> 5);\n\n\n\n            if (s->size - stream_ptr < n_blocks * 4)\n\n                return;\n\n            while (n_blocks--) {\n\n                block_ptr = row_ptr + pixel_ptr;\n\n                for (pixel_y = 0; pixel_y < 4; pixel_y++) {\n\n                    index = s->buf[stream_ptr++];\n\n                    for (pixel_x = 0; pixel_x < 4; pixel_x++){\n\n                        idx = (index >> (2 * (3 - pixel_x))) & 0x03;\n\n                        pixels[block_ptr] = color4[idx];\n\n                        block_ptr++;\n\n                    }\n\n                    block_ptr += row_inc;\n\n                }\n\n                ADVANCE_BLOCK();\n\n            }\n\n            break;\n\n\n\n        /* Fill block with 16 colors */\n\n        case 0x00:\n\n            if (s->size - stream_ptr < 16)\n\n                return;\n\n            block_ptr = row_ptr + pixel_ptr;\n\n            for (pixel_y = 0; pixel_y < 4; pixel_y++) {\n\n                for (pixel_x = 0; pixel_x < 4; pixel_x++){\n\n                    /* We already have color of upper left pixel */\n\n                    if ((pixel_y != 0) || (pixel_x !=0)) {\n\n                        colorA = AV_RB16 (&s->buf[stream_ptr]);\n\n                        stream_ptr += 2;\n\n                    }\n\n                    pixels[block_ptr] = colorA;\n\n                    block_ptr++;\n\n                }\n\n                block_ptr += row_inc;\n\n            }\n\n            ADVANCE_BLOCK();\n\n            break;\n\n\n\n        /* Unknown opcode */\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Unknown opcode %d in rpza chunk.\"\n\n                 \" Skip remaining %d bytes of chunk data.\\n\", opcode,\n\n                 chunk_size - stream_ptr);\n\n            return;\n\n        } /* Opcode switch */\n\n    }\n\n}\n", "idx": 24049}
{"project": "FFmpeg", "commit_id": "d0a503c97cc59b17e77585a726448dfa46245f4d", "target": 0, "func": "static int ast_read_header(AVFormatContext *s)\n\n{\n\n    int codec;\n\n    AVStream *st;\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avio_skip(s->pb, 8);\n\n    codec = avio_rb16(s->pb);\n\n    switch (codec) {\n\n    case 1:\n\n        st->codec->codec_id = AV_CODEC_ID_PCM_S16BE_PLANAR;\n\n        break;\n\n    default:\n\n        av_log(s, AV_LOG_ERROR, \"unsupported codec %d\\n\", codec);\n\n    }\n\n\n\n    avio_skip(s->pb, 2);\n\n\n\n    st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n    st->codec->channels = avio_rb16(s->pb);\n\n    if (!st->codec->channels)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (st->codec->channels == 2)\n\n        st->codec->channel_layout = AV_CH_LAYOUT_STEREO;\n\n    else if (st->codec->channels == 4)\n\n        st->codec->channel_layout = AV_CH_LAYOUT_4POINT0;\n\n\n\n    avio_skip(s->pb, 2);\n\n    st->codec->sample_rate = avio_rb32(s->pb);\n\n    if (st->codec->sample_rate <= 0)\n\n        return AVERROR_INVALIDDATA;\n\n    st->start_time         = 0;\n\n    st->duration           = avio_rb32(s->pb);\n\n    avio_skip(s->pb, 40);\n\n    avpriv_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n\n\n    return 0;\n\n}\n", "idx": 24055}
{"project": "FFmpeg", "commit_id": "e48ded8551172b58a78f30303a81dfce125344e0", "target": 0, "func": "static av_cold int vsink_init(AVFilterContext *ctx, void *opaque)\n\n{\n\n    BufferSinkContext *buf = ctx->priv;\n\n    AVBufferSinkParams *params = opaque;\n\n\n\n    if (params && params->pixel_fmts) {\n\n        const int *pixel_fmts = params->pixel_fmts;\n\n\n\n        buf->pixel_fmts = ff_copy_int_list(pixel_fmts);\n\n        if (!buf->pixel_fmts)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    return common_init(ctx);\n\n}\n", "idx": 24056}
{"project": "FFmpeg", "commit_id": "7f46a641bf2540b8cf1293d5e50c0c0e34264254", "target": 1, "func": "static int aac_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    AACContext *ac = avctx->priv_data;\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    GetBitContext gb;\n\n    int buf_consumed;\n\n    int buf_offset;\n\n    int err;\n\n    int new_extradata_size;\n\n    const uint8_t *new_extradata = av_packet_get_side_data(avpkt,\n\n                                       AV_PKT_DATA_NEW_EXTRADATA,\n\n                                       &new_extradata_size);\n\n    int jp_dualmono_size;\n\n    const uint8_t *jp_dualmono   = av_packet_get_side_data(avpkt,\n\n                                       AV_PKT_DATA_JP_DUALMONO,\n\n                                       &jp_dualmono_size);\n\n\n\n    if (new_extradata && 0) {\n\n        av_free(avctx->extradata);\n\n        avctx->extradata = av_mallocz(new_extradata_size +\n\n                                      AV_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!avctx->extradata)\n\n            return AVERROR(ENOMEM);\n\n        avctx->extradata_size = new_extradata_size;\n\n        memcpy(avctx->extradata, new_extradata, new_extradata_size);\n\n        push_output_configuration(ac);\n\n        if (decode_audio_specific_config(ac, ac->avctx, &ac->oc[1].m4ac,\n\n                                         avctx->extradata,\n\n                                         avctx->extradata_size*8, 1) < 0) {\n\n            pop_output_configuration(ac);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    ac->dmono_mode = 0;\n\n    if (jp_dualmono && jp_dualmono_size > 0)\n\n        ac->dmono_mode =  1 + *jp_dualmono;\n\n    if (ac->force_dmono_mode >= 0)\n\n        ac->dmono_mode = ac->force_dmono_mode;\n\n\n\n    if (INT_MAX / 8 <= buf_size)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if ((err = init_get_bits8(&gb, buf, buf_size)) < 0)\n\n        return err;\n\n\n\n    switch (ac->oc[1].m4ac.object_type) {\n\n    case AOT_ER_AAC_LC:\n\n    case AOT_ER_AAC_LTP:\n\n    case AOT_ER_AAC_LD:\n\n    case AOT_ER_AAC_ELD:\n\n        err = aac_decode_er_frame(avctx, data, got_frame_ptr, &gb);\n\n        break;\n\n    default:\n\n        err = aac_decode_frame_int(avctx, data, got_frame_ptr, &gb, avpkt);\n\n    }\n\n    if (err < 0)\n\n        return err;\n\n\n\n    buf_consumed = (get_bits_count(&gb) + 7) >> 3;\n\n    for (buf_offset = buf_consumed; buf_offset < buf_size; buf_offset++)\n\n        if (buf[buf_offset])\n\n            break;\n\n\n\n    return buf_size > buf_offset ? buf_consumed : buf_size;\n\n}\n", "idx": 24057}
{"project": "FFmpeg", "commit_id": "c595139f1fdb5ce5ee128c317ed9e4e836282436", "target": 1, "func": "int ff_dirac_golomb_read_32bit(DiracGolombLUT *lut_ctx, const uint8_t *buf,\n                               int bytes, uint8_t *_dst, int coeffs)\n{\n    int i, b, c_idx = 0;\n    int32_t *dst = (int32_t *)_dst;\n    DiracGolombLUT *future[4], *l = &lut_ctx[2*LUT_SIZE + buf[0]];\n    INIT_RESIDUE(res);\n    for (b = 1; b <= bytes; b++) {\n        future[0] = &lut_ctx[buf[b]];\n        future[1] = future[0] + 1*LUT_SIZE;\n        future[2] = future[0] + 2*LUT_SIZE;\n        future[3] = future[0] + 3*LUT_SIZE;\n        if ((c_idx + 1) > coeffs)\n            return c_idx;\n        /* res_bits is a hint for better branch prediction */\n        if (res_bits && l->sign) {\n            int32_t coeff = 1;\n            APPEND_RESIDUE(res, l->preamble);\n            for (i = 0; i < (res_bits >> 1) - 1; i++) {\n                coeff <<= 1;\n                coeff |= (res >> (RSIZE_BITS - 2*i - 2)) & 1;\n            }\n            dst[c_idx++] = l->sign * (coeff - 1);\n        }\n        memcpy(&dst[c_idx], l->ready, LUT_BITS*sizeof(int32_t));\n        c_idx += l->ready_num;\n        APPEND_RESIDUE(res, l->leftover);\n        l = future[l->need_s ? 3 : !res_bits ? 2 : res_bits & 1];\n    }\n    return c_idx;\n}", "idx": 24061}
{"project": "FFmpeg", "commit_id": "78cb39d2b2ad731dd3b984b0c0711b9f1d6de004", "target": 1, "func": "static void lz_unpack(const unsigned char *src, int src_len,\n\n                      unsigned char *dest, int dest_len)\n\n{\n\n    const unsigned char *s;\n\n    const unsigned char *s_end;\n\n    unsigned char *d;\n\n    unsigned char *d_end;\n\n    unsigned char queue[QUEUE_SIZE];\n\n    unsigned int qpos;\n\n    unsigned int dataleft;\n\n    unsigned int chainofs;\n\n    unsigned int chainlen;\n\n    unsigned int speclen;\n\n    unsigned char tag;\n\n    unsigned int i, j;\n\n\n\n    s = src;\n\n    s_end = src + src_len;\n\n    d = dest;\n\n    d_end = d + dest_len;\n\n\n\n    if (s_end - s < 8)\n\n        return;\n\n    dataleft = AV_RL32(s);\n\n    s += 4;\n\n    memset(queue, 0x20, QUEUE_SIZE);\n\n    if (AV_RL32(s) == 0x56781234) {\n\n        s += 4;\n\n        qpos = 0x111;\n\n        speclen = 0xF + 3;\n\n    } else {\n\n        qpos = 0xFEE;\n\n        speclen = 100;  /* no speclen */\n\n    }\n\n\n\n    while (s_end - s > 0 && dataleft > 0) {\n\n        tag = *s++;\n\n        if ((tag == 0xFF) && (dataleft > 8)) {\n\n            if (d + 8 > d_end || s_end - s < 8)\n\n                return;\n\n            for (i = 0; i < 8; i++) {\n\n                queue[qpos++] = *d++ = *s++;\n\n                qpos &= QUEUE_MASK;\n\n            }\n\n            dataleft -= 8;\n\n        } else {\n\n            for (i = 0; i < 8; i++) {\n\n                if (dataleft == 0)\n\n                    break;\n\n                if (tag & 0x01) {\n\n                    if (d + 1 > d_end || s_end - s < 1)\n\n                        return;\n\n                    queue[qpos++] = *d++ = *s++;\n\n                    qpos &= QUEUE_MASK;\n\n                    dataleft--;\n\n                } else {\n\n                    if (s_end - s < 2)\n\n                        return;\n\n                    chainofs = *s++;\n\n                    chainofs |= ((*s & 0xF0) << 4);\n\n                    chainlen = (*s++ & 0x0F) + 3;\n\n                    if (chainlen == speclen) {\n\n                        if (s_end - s < 1)\n\n                            return;\n\n                        chainlen = *s++ + 0xF + 3;\n\n                    }\n\n                    if (d + chainlen > d_end)\n\n                        return;\n\n                    for (j = 0; j < chainlen; j++) {\n\n                        *d = queue[chainofs++ & QUEUE_MASK];\n\n                        queue[qpos++] = *d++;\n\n                        qpos &= QUEUE_MASK;\n\n                    }\n\n                    dataleft -= chainlen;\n\n                }\n\n                tag >>= 1;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 24063}
{"project": "FFmpeg", "commit_id": "50c21814b9de5635cf01e2d1ea091a9a272a4d67", "target": 1, "func": "static void clone_tables(H264Context *dst, H264Context *src){\n\n    dst->intra4x4_pred_mode       = src->intra4x4_pred_mode;\n\n    dst->non_zero_count           = src->non_zero_count;\n\n    dst->slice_table              = src->slice_table;\n\n    dst->cbp_table                = src->cbp_table;\n\n    dst->mb2b_xy                  = src->mb2b_xy;\n\n    dst->mb2b8_xy                 = src->mb2b8_xy;\n\n    dst->chroma_pred_mode_table   = src->chroma_pred_mode_table;\n\n    dst->mvd_table[0]             = src->mvd_table[0];\n\n    dst->mvd_table[1]             = src->mvd_table[1];\n\n    dst->direct_table             = src->direct_table;\n\n\n\n    if(!dst->dequant4_coeff[0])\n\n        init_dequant_tables(dst);\n\n    dst->s.obmc_scratchpad = NULL;\n\n    ff_h264_pred_init(&dst->hpc, src->s.codec_id);\n\n    dst->dequant_coeff_pps= -1;\n\n}\n", "idx": 24067}
{"project": "FFmpeg", "commit_id": "80ca19f766aea8f4724aac1b3faa772d25163c8a", "target": 0, "func": "static int ipvideo_decode_block_opcode_0x9(IpvideoContext *s)\n\n{\n\n    int x, y;\n\n    unsigned char P[4];\n\n\n\n    /* 4-color encoding */\n\n    CHECK_STREAM_PTR(4);\n\n\n\n    memcpy(P, s->stream_ptr, 4);\n\n    s->stream_ptr += 4;\n\n\n\n    if (P[0] <= P[1]) {\n\n        if (P[2] <= P[3]) {\n\n\n\n            /* 1 of 4 colors for each pixel, need 16 more bytes */\n\n            CHECK_STREAM_PTR(16);\n\n\n\n            for (y = 0; y < 8; y++) {\n\n                /* get the next set of 8 2-bit flags */\n\n                int flags = bytestream_get_le16(&s->stream_ptr);\n\n                for (x = 0; x < 8; x++, flags >>= 2)\n\n                    *s->pixel_ptr++ = P[flags & 0x03];\n\n                s->pixel_ptr += s->line_inc;\n\n            }\n\n\n\n        } else {\n\n            uint32_t flags;\n\n\n\n            /* 1 of 4 colors for each 2x2 block, need 4 more bytes */\n\n            CHECK_STREAM_PTR(4);\n\n\n\n            flags = bytestream_get_le32(&s->stream_ptr);\n\n\n\n            for (y = 0; y < 8; y += 2) {\n\n                for (x = 0; x < 8; x += 2, flags >>= 2) {\n\n                    s->pixel_ptr[x                ] =\n\n                    s->pixel_ptr[x + 1            ] =\n\n                    s->pixel_ptr[x +     s->stride] =\n\n                    s->pixel_ptr[x + 1 + s->stride] = P[flags & 0x03];\n\n                }\n\n                s->pixel_ptr += s->stride * 2;\n\n            }\n\n\n\n        }\n\n    } else {\n\n        uint64_t flags;\n\n\n\n        /* 1 of 4 colors for each 2x1 or 1x2 block, need 8 more bytes */\n\n        CHECK_STREAM_PTR(8);\n\n\n\n        flags = bytestream_get_le64(&s->stream_ptr);\n\n        if (P[2] <= P[3]) {\n\n            for (y = 0; y < 8; y++) {\n\n                for (x = 0; x < 8; x += 2, flags >>= 2) {\n\n                    s->pixel_ptr[x    ] =\n\n                    s->pixel_ptr[x + 1] = P[flags & 0x03];\n\n                }\n\n                s->pixel_ptr += s->stride;\n\n            }\n\n        } else {\n\n            for (y = 0; y < 8; y += 2) {\n\n                for (x = 0; x < 8; x++, flags >>= 2) {\n\n                    s->pixel_ptr[x            ] =\n\n                    s->pixel_ptr[x + s->stride] = P[flags & 0x03];\n\n                }\n\n                s->pixel_ptr += s->stride * 2;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* report success */\n\n    return 0;\n\n}\n", "idx": 24069}
{"project": "FFmpeg", "commit_id": "b6c04b682176e72125b747b5982bcc4dea1f34c5", "target": 0, "func": "int ff_mjpeg_decode_frame(AVCodecContext *avctx,\n\n                              void *data, int *data_size,\n\n                              AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    MJpegDecodeContext *s = avctx->priv_data;\n\n    const uint8_t *buf_end, *buf_ptr;\n\n    const uint8_t *unescaped_buf_ptr;\n\n    int unescaped_buf_size;\n\n    int start_code;\n\n    AVFrame *picture = data;\n\n\n\n    s->got_picture = 0; // picture from previous image can not be reused\n\n    buf_ptr = buf;\n\n    buf_end = buf + buf_size;\n\n    while (buf_ptr < buf_end) {\n\n        /* find start next marker */\n\n        start_code = ff_mjpeg_find_marker(s, &buf_ptr, buf_end,\n\n                                          &unescaped_buf_ptr, &unescaped_buf_size);\n\n        {\n\n            /* EOF */\n\n            if (start_code < 0) {\n\n                goto the_end;\n\n            } else {\n\n                av_log(avctx, AV_LOG_DEBUG, \"marker=%x avail_size_in_buf=%td\\n\", start_code, buf_end - buf_ptr);\n\n\n\n                init_get_bits(&s->gb, unescaped_buf_ptr, unescaped_buf_size*8);\n\n\n\n                s->start_code = start_code;\n\n                if(s->avctx->debug & FF_DEBUG_STARTCODE){\n\n                    av_log(avctx, AV_LOG_DEBUG, \"startcode: %X\\n\", start_code);\n\n                }\n\n\n\n                /* process markers */\n\n                if (start_code >= 0xd0 && start_code <= 0xd7) {\n\n                    av_log(avctx, AV_LOG_DEBUG, \"restart marker: %d\\n\", start_code&0x0f);\n\n                    /* APP fields */\n\n                } else if (start_code >= APP0 && start_code <= APP15) {\n\n                    mjpeg_decode_app(s);\n\n                    /* Comment */\n\n                } else if (start_code == COM){\n\n                    mjpeg_decode_com(s);\n\n                }\n\n\n\n                switch(start_code) {\n\n                case SOI:\n\n                    s->restart_interval = 0;\n\n\n\n                    s->restart_count = 0;\n\n                    /* nothing to do on SOI */\n\n                    break;\n\n                case DQT:\n\n                    ff_mjpeg_decode_dqt(s);\n\n                    break;\n\n                case DHT:\n\n                    if(ff_mjpeg_decode_dht(s) < 0){\n\n                        av_log(avctx, AV_LOG_ERROR, \"huffman table decode error\\n\");\n\n                        return -1;\n\n                    }\n\n                    break;\n\n                case SOF0:\n\n                case SOF1:\n\n                    s->lossless=0;\n\n                    s->ls=0;\n\n                    s->progressive=0;\n\n                    if (ff_mjpeg_decode_sof(s) < 0)\n\n                        return -1;\n\n                    break;\n\n                case SOF2:\n\n                    s->lossless=0;\n\n                    s->ls=0;\n\n                    s->progressive=1;\n\n                    if (ff_mjpeg_decode_sof(s) < 0)\n\n                        return -1;\n\n                    break;\n\n                case SOF3:\n\n                    s->lossless=1;\n\n                    s->ls=0;\n\n                    s->progressive=0;\n\n                    if (ff_mjpeg_decode_sof(s) < 0)\n\n                        return -1;\n\n                    break;\n\n                case SOF48:\n\n                    s->lossless=1;\n\n                    s->ls=1;\n\n                    s->progressive=0;\n\n                    if (ff_mjpeg_decode_sof(s) < 0)\n\n                        return -1;\n\n                    break;\n\n                case LSE:\n\n                    if (!CONFIG_JPEGLS_DECODER || ff_jpegls_decode_lse(s) < 0)\n\n                        return -1;\n\n                    break;\n\n                case EOI:\n\n                    if ((s->buggy_avid && !s->interlaced) || s->restart_interval)\n\n                        break;\n\neoi_parser:\n\n                    s->cur_scan = 0;\n\n                    if (!s->got_picture) {\n\n                        av_log(avctx, AV_LOG_WARNING, \"Found EOI before any SOF, ignoring\\n\");\n\n                        break;\n\n                    }\n\n                    if (s->interlaced) {\n\n                        s->bottom_field ^= 1;\n\n                        /* if not bottom field, do not output image yet */\n\n                        if (s->bottom_field == !s->interlace_polarity)\n\n                            break;\n\n                    }\n\n                    *picture = *s->picture_ptr;\n\n                    *data_size = sizeof(AVFrame);\n\n\n\n                    if(!s->lossless){\n\n                        picture->quality= FFMAX3(s->qscale[0], s->qscale[1], s->qscale[2]);\n\n                        picture->qstride= 0;\n\n                        picture->qscale_table= s->qscale_table;\n\n                        memset(picture->qscale_table, picture->quality, (s->width+15)/16);\n\n                        if(avctx->debug & FF_DEBUG_QP)\n\n                            av_log(avctx, AV_LOG_DEBUG, \"QP: %d\\n\", picture->quality);\n\n                        picture->quality*= FF_QP2LAMBDA;\n\n                    }\n\n\n\n                    goto the_end;\n\n                case SOS:\n\n                    if (!s->got_picture) {\n\n                        av_log(avctx, AV_LOG_WARNING, \"Can not process SOS before SOF, skipping\\n\");\n\n                        break;\n\n                    }\n\n                    if (ff_mjpeg_decode_sos(s, NULL, NULL) < 0 &&\n\n                        avctx->error_recognition >= FF_ER_EXPLODE)\n\n                      return AVERROR_INVALIDDATA;\n\n                    /* buggy avid puts EOI every 10-20th frame */\n\n                    /* if restart period is over process EOI */\n\n                    if ((s->buggy_avid && !s->interlaced) || s->restart_interval)\n\n                        goto eoi_parser;\n\n                    break;\n\n                case DRI:\n\n                    mjpeg_decode_dri(s);\n\n                    break;\n\n                case SOF5:\n\n                case SOF6:\n\n                case SOF7:\n\n                case SOF9:\n\n                case SOF10:\n\n                case SOF11:\n\n                case SOF13:\n\n                case SOF14:\n\n                case SOF15:\n\n                case JPG:\n\n                    av_log(avctx, AV_LOG_ERROR, \"mjpeg: unsupported coding type (%x)\\n\", start_code);\n\n                    break;\n\n//                default:\n\n//                    printf(\"mjpeg: unsupported marker (%x)\\n\", start_code);\n\n//                    break;\n\n                }\n\n\n\n                /* eof process start code */\n\n                buf_ptr += (get_bits_count(&s->gb)+7)/8;\n\n                av_log(avctx, AV_LOG_DEBUG, \"marker parser used %d bytes (%d bits)\\n\",\n\n                       (get_bits_count(&s->gb)+7)/8, get_bits_count(&s->gb));\n\n            }\n\n        }\n\n    }\n\n    if (s->got_picture) {\n\n        av_log(avctx, AV_LOG_WARNING, \"EOI missing, emulating\\n\");\n\n        goto eoi_parser;\n\n    }\n\n    av_log(avctx, AV_LOG_FATAL, \"No JPEG data found in image\\n\");\n\n    return -1;\n\nthe_end:\n\n    av_log(avctx, AV_LOG_DEBUG, \"mjpeg decode frame unused %td bytes\\n\", buf_end - buf_ptr);\n\n//    return buf_end - buf_ptr;\n\n    return buf_ptr - buf;\n\n}\n", "idx": 24070}
{"project": "FFmpeg", "commit_id": "76cd98b445c5a1608e9a5974bef0b0be6b35f1ce", "target": 1, "func": "static int mjpeg_decode_scan(MJpegDecodeContext *s, int nb_components, int Ah, int Al,\n\n                             const uint8_t *mb_bitmask, const AVFrame *reference){\n\n    int i, mb_x, mb_y;\n\n    uint8_t* data[MAX_COMPONENTS];\n\n    const uint8_t *reference_data[MAX_COMPONENTS];\n\n    int linesize[MAX_COMPONENTS];\n\n    GetBitContext mb_bitmask_gb;\n\n\n\n    if (mb_bitmask) {\n\n        init_get_bits(&mb_bitmask_gb, mb_bitmask, s->mb_width*s->mb_height);\n\n\n\n\n    if(s->flipped && s->avctx->flags & CODEC_FLAG_EMU_EDGE) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Can not flip image with CODEC_FLAG_EMU_EDGE set!\\n\");\n\n        s->flipped = 0;\n\n\n    for(i=0; i < nb_components; i++) {\n\n        int c = s->comp_index[i];\n\n        data[c] = s->picture_ptr->data[c];\n\n        reference_data[c] = reference ? reference->data[c] : NULL;\n\n        linesize[c]=s->linesize[c];\n\n        s->coefs_finished[c] |= 1;\n\n        if(s->flipped) {\n\n            //picture should be flipped upside-down for this codec\n\n            int offset = (linesize[c] * (s->v_scount[i] * (8 * s->mb_height -((s->height/s->v_max)&7)) - 1 ));\n\n            data[c] += offset;\n\n            reference_data[c] += offset;\n\n            linesize[c] *= -1;\n\n\n\n\n\n    for(mb_y = 0; mb_y < s->mb_height; mb_y++) {\n\n        for(mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n            const int copy_mb = mb_bitmask && !get_bits1(&mb_bitmask_gb);\n\n\n\n            if (s->restart_interval && !s->restart_count)\n\n                s->restart_count = s->restart_interval;\n\n\n\n\n\n\n\n            for(i=0;i<nb_components;i++) {\n\n                uint8_t *ptr;\n\n                int n, h, v, x, y, c, j;\n\n                int block_offset;\n\n                n = s->nb_blocks[i];\n\n                c = s->comp_index[i];\n\n                h = s->h_scount[i];\n\n                v = s->v_scount[i];\n\n                x = 0;\n\n                y = 0;\n\n                for(j=0;j<n;j++) {\n\n                    block_offset = (((linesize[c] * (v * mb_y + y) * 8) +\n\n                                     (h * mb_x + x) * 8) >> s->avctx->lowres);\n\n\n\n                    if(s->interlaced && s->bottom_field)\n\n                        block_offset += linesize[c] >> 1;\n\n                    ptr = data[c] + block_offset;\n\n                    if(!s->progressive) {\n\n                        if (copy_mb) {\n\n                            mjpeg_copy_block(ptr, reference_data[c] + block_offset, linesize[c], s->avctx->lowres);\n\n                        } else {\n\n                        s->dsp.clear_block(s->block);\n\n                        if(decode_block(s, s->block, i,\n\n                                     s->dc_index[i], s->ac_index[i],\n\n                                     s->quant_matrixes[ s->quant_index[c] ]) < 0) {\n\n                            av_log(s->avctx, AV_LOG_ERROR, \"error y=%d x=%d\\n\", mb_y, mb_x);\n\n\n\n                        s->dsp.idct_put(ptr, linesize[c], s->block);\n\n\n                    } else {\n\n                        int block_idx = s->block_stride[c] * (v * mb_y + y) + (h * mb_x + x);\n\n                        DCTELEM *block = s->blocks[c][block_idx];\n\n                        if(Ah)\n\n                            block[0] += get_bits1(&s->gb) * s->quant_matrixes[ s->quant_index[c] ][0] << Al;\n\n                        else if(decode_dc_progressive(s, block, i, s->dc_index[i], s->quant_matrixes[ s->quant_index[c] ], Al) < 0) {\n\n                            av_log(s->avctx, AV_LOG_ERROR, \"error y=%d x=%d\\n\", mb_y, mb_x);\n\n\n\n\n//                    av_log(s->avctx, AV_LOG_DEBUG, \"mb: %d %d processed\\n\", mb_y, mb_x);\n\n//av_log(NULL, AV_LOG_DEBUG, \"%d %d %d %d %d %d %d %d \\n\", mb_x, mb_y, x, y, c, s->bottom_field, (v * mb_y + y) * 8, (h * mb_x + x) * 8);\n\n                    if (++x == h) {\n\n                        x = 0;\n\n                        y++;\n\n\n\n\n\n\n            if (s->restart_interval && !--s->restart_count) {\n\n                align_get_bits(&s->gb);\n\n                skip_bits(&s->gb, 16); /* skip RSTn */\n\n                for (i=0; i<nb_components; i++) /* reset dc */\n\n                    s->last_dc[i] = 1024;\n\n\n\n\n    return 0;\n", "idx": 24071}
{"project": "FFmpeg", "commit_id": "48e52e4edd12adbc36eee0eebe1b97ffe0255be3", "target": 0, "func": "static int nvenc_find_free_reg_resource(AVCodecContext *avctx)\n\n{\n\n    NvencContext *ctx = avctx->priv_data;\n\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n\n\n\n    int i;\n\n\n\n    if (ctx->nb_registered_frames == FF_ARRAY_ELEMS(ctx->registered_frames)) {\n\n        for (i = 0; i < ctx->nb_registered_frames; i++) {\n\n            if (!ctx->registered_frames[i].mapped) {\n\n                if (ctx->registered_frames[i].regptr) {\n\n                    p_nvenc->nvEncUnregisterResource(ctx->nvencoder,\n\n                                                ctx->registered_frames[i].regptr);\n\n                    ctx->registered_frames[i].regptr = NULL;\n\n                }\n\n                return i;\n\n            }\n\n        }\n\n    } else {\n\n        return ctx->nb_registered_frames++;\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_ERROR, \"Too many registered CUDA frames\\n\");\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 24072}
{"project": "FFmpeg", "commit_id": "629b2ed0ac77d7c4bf1aeac5e70cafee5fa0fcae", "target": 0, "func": "static int flv_data_packet(AVFormatContext *s, AVPacket *pkt,\n\n                           int64_t dts, int64_t next)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st    = NULL;\n\n    char buf[20];\n\n    int ret = AVERROR_INVALIDDATA;\n\n    int i, length = -1;\n\n\n\n    switch (avio_r8(pb)) {\n\n    case AMF_DATA_TYPE_MIXEDARRAY:\n\n        avio_seek(pb, 4, SEEK_CUR);\n\n    case AMF_DATA_TYPE_OBJECT:\n\n        break;\n\n    default:\n\n        goto skip;\n\n    }\n\n\n\n    while ((ret = amf_get_string(pb, buf, sizeof(buf))) > 0) {\n\n        AMFDataType type = avio_r8(pb);\n\n        if (type == AMF_DATA_TYPE_STRING && !strcmp(buf, \"text\")) {\n\n            length = avio_rb16(pb);\n\n            ret    = av_get_packet(pb, pkt, length);\n\n            if (ret < 0)\n\n                goto skip;\n\n            else\n\n                break;\n\n        } else {\n\n            if ((ret = amf_skip_tag(pb, type)) < 0)\n\n                goto skip;\n\n        }\n\n    }\n\n\n\n    if (length < 0) {\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto skip;\n\n    }\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        st = s->streams[i];\n\n        if (st->codec->codec_type == AVMEDIA_TYPE_DATA)\n\n            break;\n\n    }\n\n\n\n    if (i == s->nb_streams) {\n\n        st = create_stream(s, AVMEDIA_TYPE_DATA);\n\n        if (!st)\n\n            return AVERROR_INVALIDDATA;\n\n        st->codec->codec_id = AV_CODEC_ID_TEXT;\n\n    }\n\n\n\n    pkt->dts  = dts;\n\n    pkt->pts  = dts;\n\n    pkt->size = ret;\n\n\n\n    pkt->stream_index = st->index;\n\n    pkt->flags       |= AV_PKT_FLAG_KEY;\n\n\n\nskip:\n\n    avio_seek(s->pb, next + 4, SEEK_SET);\n\n\n\n    return ret;\n\n}\n", "idx": 24073}
{"project": "FFmpeg", "commit_id": "3b7ebeb4d52a25c7e1038ae90c6c19b0d6f11877", "target": 0, "func": "void ff_h264_write_back_intra_pred_mode(H264Context *h){\n\n    int8_t *mode= h->intra4x4_pred_mode + h->mb2br_xy[h->mb_xy];\n\n\n\n    AV_COPY32(mode, h->intra4x4_pred_mode_cache + 4 + 8*4);\n\n    mode[4]= h->intra4x4_pred_mode_cache[7+8*3];\n\n    mode[5]= h->intra4x4_pred_mode_cache[7+8*2];\n\n    mode[6]= h->intra4x4_pred_mode_cache[7+8*1];\n\n}\n", "idx": 24074}
{"project": "FFmpeg", "commit_id": "93ef29b6f47eda7d73eb9e71628f1f1abb64266d", "target": 1, "func": "static int noise(AVBitStreamFilterContext *bsfc, AVCodecContext *avctx, const char *args,\n                     uint8_t **poutbuf, int *poutbuf_size,\n                     const uint8_t *buf, int buf_size, int keyframe){\n    unsigned int *state= bsfc->priv_data;\n    int amount= args ? atoi(args) : (*state % 10001+1);\n    int i;\n    *poutbuf= av_malloc(buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n    memcpy(*poutbuf, buf, buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n    for(i=0; i<buf_size; i++){\n        (*state) += (*poutbuf)[i] + 1;\n        if(*state % amount == 0)\n            (*poutbuf)[i] = *state;\n    }\n    return 1;\n}", "idx": 24076}
{"project": "FFmpeg", "commit_id": "e268a352af893e47bd3ea2aed90761cb0b4feca7", "target": 0, "func": "static int mjpeg_decode_scan(MJpegDecodeContext *s, int nb_components, int Ah, int Al,\n\n                             const uint8_t *mb_bitmask, const AVFrame *reference){\n\n    int i, mb_x, mb_y;\n\n    uint8_t* data[MAX_COMPONENTS];\n\n    const uint8_t *reference_data[MAX_COMPONENTS];\n\n    int linesize[MAX_COMPONENTS];\n\n    GetBitContext mb_bitmask_gb;\n\n\n\n    if (mb_bitmask) {\n\n        init_get_bits(&mb_bitmask_gb, mb_bitmask, s->mb_width*s->mb_height);\n\n    }\n\n\n\n    if(s->flipped && s->avctx->flags & CODEC_FLAG_EMU_EDGE) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Can not flip image with CODEC_FLAG_EMU_EDGE set!\\n\");\n\n        s->flipped = 0;\n\n    }\n\n    for(i=0; i < nb_components; i++) {\n\n        int c = s->comp_index[i];\n\n        data[c] = s->picture_ptr->data[c];\n\n        reference_data[c] = reference ? reference->data[c] : NULL;\n\n        linesize[c]=s->linesize[c];\n\n        s->coefs_finished[c] |= 1;\n\n        if(s->flipped) {\n\n            //picture should be flipped upside-down for this codec\n\n            int offset = (linesize[c] * (s->v_scount[i] * (8 * s->mb_height -((s->height/s->v_max)&7)) - 1 ));\n\n            data[c] += offset;\n\n            reference_data[c] += offset;\n\n            linesize[c] *= -1;\n\n        }\n\n    }\n\n\n\n    for(mb_y = 0; mb_y < s->mb_height; mb_y++) {\n\n        for(mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n            const int copy_mb = mb_bitmask && !get_bits1(&mb_bitmask_gb);\n\n\n\n            if (s->restart_interval && !s->restart_count)\n\n                s->restart_count = s->restart_interval;\n\n\n\n            if(get_bits_count(&s->gb)>s->gb.size_in_bits){\n\n                av_log(s->avctx, AV_LOG_ERROR, \"overread %d\\n\", get_bits_count(&s->gb) - s->gb.size_in_bits);\n\n                return -1;\n\n            }\n\n            for(i=0;i<nb_components;i++) {\n\n                uint8_t *ptr;\n\n                int n, h, v, x, y, c, j;\n\n                int block_offset;\n\n                n = s->nb_blocks[i];\n\n                c = s->comp_index[i];\n\n                h = s->h_scount[i];\n\n                v = s->v_scount[i];\n\n                x = 0;\n\n                y = 0;\n\n                for(j=0;j<n;j++) {\n\n                    block_offset = (((linesize[c] * (v * mb_y + y) * 8) +\n\n                                     (h * mb_x + x) * 8) >> s->avctx->lowres);\n\n\n\n                    if(s->interlaced && s->bottom_field)\n\n                        block_offset += linesize[c] >> 1;\n\n                    ptr = data[c] + block_offset;\n\n                    if(!s->progressive) {\n\n                        if (copy_mb) {\n\n                            mjpeg_copy_block(ptr, reference_data[c] + block_offset, linesize[c], s->avctx->lowres);\n\n                        } else {\n\n                        s->dsp.clear_block(s->block);\n\n                        if(decode_block(s, s->block, i,\n\n                                     s->dc_index[i], s->ac_index[i],\n\n                                     s->quant_matrixes[ s->quant_index[c] ]) < 0) {\n\n                            av_log(s->avctx, AV_LOG_ERROR, \"error y=%d x=%d\\n\", mb_y, mb_x);\n\n                            return -1;\n\n                        }\n\n                        s->dsp.idct_put(ptr, linesize[c], s->block);\n\n                        }\n\n                    } else {\n\n                        int block_idx = s->block_stride[c] * (v * mb_y + y) + (h * mb_x + x);\n\n                        DCTELEM *block = s->blocks[c][block_idx];\n\n                        if(Ah)\n\n                            block[0] += get_bits1(&s->gb) * s->quant_matrixes[ s->quant_index[c] ][0] << Al;\n\n                        else if(decode_dc_progressive(s, block, i, s->dc_index[i], s->quant_matrixes[ s->quant_index[c] ], Al) < 0) {\n\n                            av_log(s->avctx, AV_LOG_ERROR, \"error y=%d x=%d\\n\", mb_y, mb_x);\n\n                            return -1;\n\n                        }\n\n                    }\n\n//                    av_log(s->avctx, AV_LOG_DEBUG, \"mb: %d %d processed\\n\", mb_y, mb_x);\n\n//av_log(NULL, AV_LOG_DEBUG, \"%d %d %d %d %d %d %d %d \\n\", mb_x, mb_y, x, y, c, s->bottom_field, (v * mb_y + y) * 8, (h * mb_x + x) * 8);\n\n                    if (++x == h) {\n\n                        x = 0;\n\n                        y++;\n\n                    }\n\n                }\n\n            }\n\n\n\n            if (s->restart_interval && show_bits(&s->gb, 8) == 0xFF){ /* skip RSTn */\n\n                --s->restart_count;\n\n                align_get_bits(&s->gb);\n\n                while(show_bits(&s->gb, 8) == 0xFF)\n\n                    skip_bits(&s->gb, 8);\n\n                skip_bits(&s->gb, 8);\n\n                for (i=0; i<nb_components; i++) /* reset dc */\n\n                    s->last_dc[i] = 1024;\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 24077}
{"project": "FFmpeg", "commit_id": "e29153f414f5b2d10e0386abf7921aed4a4fa454", "target": 1, "func": "static av_cold int avui_encode_init(AVCodecContext *avctx)\n\n{\n\n    avctx->coded_frame = av_frame_alloc();\n\n\n\n    if (avctx->width != 720 || avctx->height != 486 && avctx->height != 576) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Only 720x486 and 720x576 are supported.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    if (!avctx->coded_frame) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not allocate frame.\\n\");\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    if (!(avctx->extradata = av_mallocz(24 + FF_INPUT_BUFFER_PADDING_SIZE)))\n\n        return AVERROR(ENOMEM);\n\n    avctx->extradata_size = 24;\n\n    memcpy(avctx->extradata, \"\\0\\0\\0\\x18\"\"APRGAPRG0001\", 16);\n\n    if (avctx->field_order > AV_FIELD_PROGRESSIVE) {\n\n        avctx->extradata[19] = 2;\n\n    } else {\n\n        avctx->extradata[19] = 1;\n\n    }\n\n\n\n\n\n    return 0;\n\n}\n", "idx": 24079}
{"project": "FFmpeg", "commit_id": "955aec3c7c7be39b659197e1ec379a09f2b7c41c", "target": 0, "func": "static int decode_frame(AVCodecContext * avctx, void *data, int *got_frame_ptr,\n\n                        AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf  = avpkt->data;\n\n    int buf_size        = avpkt->size;\n\n    MPADecodeContext *s = avctx->priv_data;\n\n    uint32_t header;\n\n    int ret;\n\n\n\n    if (buf_size < HEADER_SIZE)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    header = AV_RB32(buf);\n\n    if (ff_mpa_check_header(header) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Header missing\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (avpriv_mpegaudio_decode_header((MPADecodeHeader *)s, header) == 1) {\n\n        /* free format: prepare to compute frame size */\n\n        s->frame_size = -1;\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    /* update codec info */\n\n    avctx->channels       = s->nb_channels;\n\n    avctx->channel_layout = s->nb_channels == 1 ? AV_CH_LAYOUT_MONO : AV_CH_LAYOUT_STEREO;\n\n    if (!avctx->bit_rate)\n\n        avctx->bit_rate = s->bit_rate;\n\n\n\n    s->frame = data;\n\n\n\n    ret = mp_decode_frame(s, NULL, buf, buf_size);\n\n    if (ret >= 0) {\n\n        s->frame->nb_samples = avctx->frame_size;\n\n        *got_frame_ptr       = 1;\n\n        avctx->sample_rate   = s->sample_rate;\n\n        //FIXME maybe move the other codec info stuff from above here too\n\n    } else {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error while decoding MPEG audio frame.\\n\");\n\n        /* Only return an error if the bad frame makes up the whole packet or\n\n         * the error is related to buffer management.\n\n         * If there is more data in the packet, just consume the bad frame\n\n         * instead of returning an error, which would discard the whole\n\n         * packet. */\n\n        *got_frame_ptr = 0;\n\n        if (buf_size == avpkt->size || ret != AVERROR_INVALIDDATA)\n\n            return ret;\n\n    }\n\n    s->frame_size = 0;\n\n    return buf_size;\n\n}\n", "idx": 24081}
{"project": "FFmpeg", "commit_id": "fde1bc64adbec49301c665efab2b49b94bb39c23", "target": 0, "func": "int attribute_align_arg avcodec_open2(AVCodecContext *avctx, AVCodec *codec, AVDictionary **options)\n\n{\n\n    int ret = 0;\n\n    AVDictionary *tmp = NULL;\n\n\n\n    if (avcodec_is_open(avctx))\n\n        return 0;\n\n\n\n    if ((!codec && !avctx->codec)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"No codec provided to avcodec_open2().\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    if ((codec && avctx->codec && codec != avctx->codec)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"This AVCodecContext was allocated for %s, \"\n\n               \"but %s passed to avcodec_open2().\\n\", avctx->codec->name, codec->name);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    if (!codec)\n\n        codec = avctx->codec;\n\n\n\n    if (avctx->extradata_size < 0 || avctx->extradata_size >= FF_MAX_EXTRADATA_SIZE)\n\n        return AVERROR(EINVAL);\n\n\n\n    if (options)\n\n        av_dict_copy(&tmp, *options, 0);\n\n\n\n    /* If there is a user-supplied mutex locking routine, call it. */\n\n    if (ff_lockmgr_cb) {\n\n        if ((*ff_lockmgr_cb)(&codec_mutex, AV_LOCK_OBTAIN))\n\n            return -1;\n\n    }\n\n\n\n    entangled_thread_counter++;\n\n    if(entangled_thread_counter != 1){\n\n        av_log(avctx, AV_LOG_ERROR, \"insufficient thread locking around avcodec_open/close()\\n\");\n\n        ret = -1;\n\n        goto end;\n\n    }\n\n\n\n    avctx->internal = av_mallocz(sizeof(AVCodecInternal));\n\n    if (!avctx->internal) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto end;\n\n    }\n\n\n\n    if (codec->priv_data_size > 0) {\n\n      if(!avctx->priv_data){\n\n        avctx->priv_data = av_mallocz(codec->priv_data_size);\n\n        if (!avctx->priv_data) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto end;\n\n        }\n\n        if (codec->priv_class) {\n\n            *(const AVClass**)avctx->priv_data= codec->priv_class;\n\n            av_opt_set_defaults(avctx->priv_data);\n\n        }\n\n      }\n\n      if (codec->priv_class && (ret = av_opt_set_dict(avctx->priv_data, &tmp)) < 0)\n\n          goto free_and_end;\n\n    } else {\n\n        avctx->priv_data = NULL;\n\n    }\n\n    if ((ret = av_opt_set_dict(avctx, &tmp)) < 0)\n\n        goto free_and_end;\n\n\n\n    if (codec->capabilities & CODEC_CAP_EXPERIMENTAL)\n\n        if (avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Codec is experimental but experimental codecs are not enabled, try -strict -2\\n\");\n\n            ret = -1;\n\n            goto free_and_end;\n\n        }\n\n\n\n    //We only call avcodec_set_dimensions() for non h264 codecs so as not to overwrite previously setup dimensions\n\n    if(!( avctx->coded_width && avctx->coded_height && avctx->width && avctx->height && avctx->codec_id == CODEC_ID_H264)){\n\n    if(avctx->coded_width && avctx->coded_height)\n\n        avcodec_set_dimensions(avctx, avctx->coded_width, avctx->coded_height);\n\n    else if(avctx->width && avctx->height)\n\n        avcodec_set_dimensions(avctx, avctx->width, avctx->height);\n\n    }\n\n\n\n    if ((avctx->coded_width || avctx->coded_height || avctx->width || avctx->height)\n\n        && (  av_image_check_size(avctx->coded_width, avctx->coded_height, 0, avctx) < 0\n\n           || av_image_check_size(avctx->width,       avctx->height,       0, avctx) < 0)) {\n\n        av_log(avctx, AV_LOG_WARNING, \"ignoring invalid width/height values\\n\");\n\n        avcodec_set_dimensions(avctx, 0, 0);\n\n    }\n\n\n\n    /* if the decoder init function was already called previously,\n\n       free the already allocated subtitle_header before overwriting it */\n\n    if (av_codec_is_decoder(codec))\n\n        av_freep(&avctx->subtitle_header);\n\n\n\n#define SANE_NB_CHANNELS 128U\n\n    if (avctx->channels > SANE_NB_CHANNELS) {\n\n        ret = AVERROR(EINVAL);\n\n        goto free_and_end;\n\n    }\n\n\n\n    avctx->codec = codec;\n\n    if ((avctx->codec_type == AVMEDIA_TYPE_UNKNOWN || avctx->codec_type == codec->type) &&\n\n        avctx->codec_id == CODEC_ID_NONE) {\n\n        avctx->codec_type = codec->type;\n\n        avctx->codec_id   = codec->id;\n\n    }\n\n    if (avctx->codec_id != codec->id || (avctx->codec_type != codec->type\n\n                           && avctx->codec_type != AVMEDIA_TYPE_ATTACHMENT)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"codec type or id mismatches\\n\");\n\n        ret = AVERROR(EINVAL);\n\n        goto free_and_end;\n\n    }\n\n    avctx->frame_number = 0;\n\n\n\n    if (avctx->codec_type == AVMEDIA_TYPE_AUDIO &&\n\n        (!avctx->time_base.num || !avctx->time_base.den)) {\n\n        avctx->time_base.num = 1;\n\n        avctx->time_base.den = avctx->sample_rate;\n\n    }\n\n\n\n    if (!HAVE_THREADS)\n\n        av_log(avctx, AV_LOG_WARNING, \"Warning: not compiled with thread support, using thread emulation\\n\");\n\n\n\n    if (HAVE_THREADS && !avctx->thread_opaque) {\n\n        ret = ff_thread_init(avctx);\n\n        if (ret < 0) {\n\n            goto free_and_end;\n\n        }\n\n    }\n\n    if (!HAVE_THREADS && !(codec->capabilities & CODEC_CAP_AUTO_THREADS))\n\n        avctx->thread_count = 1;\n\n\n\n    if (avctx->codec->max_lowres < avctx->lowres || avctx->lowres < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"The maximum value for lowres supported by the decoder is %d\\n\",\n\n               avctx->codec->max_lowres);\n\n        ret = AVERROR(EINVAL);\n\n        goto free_and_end;\n\n    }\n\n\n\n    if (av_codec_is_encoder(avctx->codec)) {\n\n        int i;\n\n        if (avctx->codec->sample_fmts) {\n\n            for (i = 0; avctx->codec->sample_fmts[i] != AV_SAMPLE_FMT_NONE; i++)\n\n                if (avctx->sample_fmt == avctx->codec->sample_fmts[i])\n\n                    break;\n\n            if (avctx->codec->sample_fmts[i] == AV_SAMPLE_FMT_NONE) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample_fmt is not supported.\\n\");\n\n                ret = AVERROR(EINVAL);\n\n                goto free_and_end;\n\n            }\n\n        }\n\n        if (avctx->codec->pix_fmts) {\n\n            for (i = 0; avctx->codec->pix_fmts[i] != PIX_FMT_NONE; i++)\n\n                if (avctx->pix_fmt == avctx->codec->pix_fmts[i])\n\n                    break;\n\n            if (avctx->codec->pix_fmts[i] == PIX_FMT_NONE\n\n                && !((avctx->codec_id == CODEC_ID_MJPEG || avctx->codec_id == CODEC_ID_LJPEG)\n\n                     && avctx->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL)) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Specified pix_fmt is not supported\\n\");\n\n                ret = AVERROR(EINVAL);\n\n                goto free_and_end;\n\n            }\n\n        }\n\n        if (avctx->codec->supported_samplerates) {\n\n            for (i = 0; avctx->codec->supported_samplerates[i] != 0; i++)\n\n                if (avctx->sample_rate == avctx->codec->supported_samplerates[i])\n\n                    break;\n\n            if (avctx->codec->supported_samplerates[i] == 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample_rate is not supported\\n\");\n\n                ret = AVERROR(EINVAL);\n\n                goto free_and_end;\n\n            }\n\n        }\n\n        if (avctx->codec->channel_layouts) {\n\n            if (!avctx->channel_layout) {\n\n                av_log(avctx, AV_LOG_WARNING, \"channel_layout not specified\\n\");\n\n            } else {\n\n                for (i = 0; avctx->codec->channel_layouts[i] != 0; i++)\n\n                    if (avctx->channel_layout == avctx->codec->channel_layouts[i])\n\n                        break;\n\n                if (avctx->codec->channel_layouts[i] == 0) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"Specified channel_layout is not supported\\n\");\n\n                    ret = AVERROR(EINVAL);\n\n                    goto free_and_end;\n\n                }\n\n            }\n\n        }\n\n        if (avctx->channel_layout && avctx->channels) {\n\n            if (av_get_channel_layout_nb_channels(avctx->channel_layout) != avctx->channels) {\n\n                av_log(avctx, AV_LOG_ERROR, \"channel layout does not match number of channels\\n\");\n\n                ret = AVERROR(EINVAL);\n\n                goto free_and_end;\n\n            }\n\n        } else if (avctx->channel_layout) {\n\n            avctx->channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n\n        }\n\n    }\n\n\n\n    avctx->pts_correction_num_faulty_pts =\n\n    avctx->pts_correction_num_faulty_dts = 0;\n\n    avctx->pts_correction_last_pts =\n\n    avctx->pts_correction_last_dts = INT64_MIN;\n\n\n\n    if(avctx->codec->init && !(avctx->active_thread_type&FF_THREAD_FRAME)){\n\n        ret = avctx->codec->init(avctx);\n\n        if (ret < 0) {\n\n            goto free_and_end;\n\n        }\n\n    }\n\n\n\n    ret=0;\n\n\n\n    if (av_codec_is_decoder(avctx->codec)) {\n\n        if (!avctx->bit_rate)\n\n            avctx->bit_rate = get_bit_rate(avctx);\n\n        /* validate channel layout from the decoder */\n\n        if (avctx->channel_layout &&\n\n            av_get_channel_layout_nb_channels(avctx->channel_layout) != avctx->channels) {\n\n            av_log(avctx, AV_LOG_WARNING, \"channel layout does not match number of channels\\n\");\n\n            avctx->channel_layout = 0;\n\n        }\n\n    }\n\nend:\n\n    entangled_thread_counter--;\n\n\n\n    /* Release any user-supplied mutex. */\n\n    if (ff_lockmgr_cb) {\n\n        (*ff_lockmgr_cb)(&codec_mutex, AV_LOCK_RELEASE);\n\n    }\n\n    if (options) {\n\n        av_dict_free(options);\n\n        *options = tmp;\n\n    }\n\n\n\n    return ret;\n\nfree_and_end:\n\n    av_dict_free(&tmp);\n\n    av_freep(&avctx->priv_data);\n\n    av_freep(&avctx->internal);\n\n    avctx->codec= NULL;\n\n    goto end;\n\n}\n", "idx": 24082}
{"project": "FFmpeg", "commit_id": "486637af8ef29ec215e0e0b7ecd3b5470f0e04e5", "target": 0, "func": "static int get_transform_coeffs1(uint8_t *exps, uint8_t *bap, float chcoeff,\n\n        float *coeffs, int start, int end, int dith_flag, GetBitContext *gb,\n\n        dither_state *state)\n\n{\n\n    int16_t mantissa;\n\n    int i;\n\n    int gcode;\n\n    mant_group l3_grp, l5_grp, l11_grp;\n\n\n\n    for (i = 0; i < 3; i++)\n\n        l3_grp.gcodes[i] = l5_grp.gcodes[i] = l11_grp.gcodes[i] = -1;\n\n    l3_grp.gcptr = l5_grp.gcptr = 3;\n\n    l11_grp.gcptr = 2;\n\n\n\n    i = 0;\n\n    while (i < start)\n\n        coeffs[i++] = 0;\n\n\n\n    for (i = start; i < end; i++) {\n\n        switch (bap[i]) {\n\n            case 0:\n\n                if (!dith_flag) {\n\n                    coeffs[i] = 0;\n\n                    continue;\n\n                }\n\n                else {\n\n                    mantissa = dither_int16(state);\n\n                    coeffs[i] = to_float(exps[i], mantissa) * chcoeff;\n\n                    continue;\n\n                }\n\n\n\n            case 1:\n\n                if (l3_grp.gcptr > 2) {\n\n                    gcode = get_bits(gb, 5);\n\n                    if (gcode > 26)\n\n                        return -1;\n\n                    l3_grp.gcodes[0] = gcode / 9;\n\n                    l3_grp.gcodes[1] = (gcode % 9) / 3;\n\n                    l3_grp.gcodes[2] = (gcode % 9) % 3;\n\n                    l3_grp.gcptr = 0;\n\n                }\n\n                mantissa = l3_q_tab[l3_grp.gcodes[l3_grp.gcptr++]];\n\n                coeffs[i] = to_float(exps[i], mantissa) * chcoeff;\n\n                continue;\n\n\n\n            case 2:\n\n                if (l5_grp.gcptr > 2) {\n\n                    gcode = get_bits(gb, 7);\n\n                    if (gcode > 124)\n\n                        return -1;\n\n                    l5_grp.gcodes[0] = gcode / 25;\n\n                    l5_grp.gcodes[1] = (gcode % 25) / 5;\n\n                    l5_grp.gcodes[2] = (gcode % 25) % 5;\n\n                    l5_grp.gcptr = 0;\n\n                }\n\n                mantissa = l5_q_tab[l5_grp.gcodes[l5_grp.gcptr++]];\n\n                coeffs[i] = to_float(exps[i], mantissa) * chcoeff;\n\n                continue;\n\n\n\n            case 3:\n\n                mantissa = get_bits(gb, 3);\n\n                if (mantissa > 6)\n\n                    return -1;\n\n                mantissa = l7_q_tab[mantissa];\n\n                coeffs[i] = to_float(exps[i], mantissa);\n\n                continue;\n\n\n\n            case 4:\n\n                if (l11_grp.gcptr > 1) {\n\n                    gcode = get_bits(gb, 7);\n\n                    if (gcode > 120)\n\n                        return -1;\n\n                    l11_grp.gcodes[0] = gcode / 11;\n\n                    l11_grp.gcodes[1] = gcode % 11;\n\n                }\n\n                mantissa = l11_q_tab[l11_grp.gcodes[l11_grp.gcptr++]];\n\n                coeffs[i] = to_float(exps[i], mantissa) * chcoeff;\n\n                continue;\n\n\n\n            case 5:\n\n                mantissa = get_bits(gb, 4);\n\n                if (mantissa > 14)\n\n                    return -1;\n\n                mantissa = l15_q_tab[mantissa];\n\n                coeffs[i] = to_float(exps[i], mantissa) * chcoeff;\n\n                continue;\n\n\n\n            default:\n\n                mantissa = get_bits(gb, qntztab[bap[i]]) << (16 - qntztab[bap[i]]);\n\n                coeffs[i] = to_float(exps[i], mantissa) * chcoeff;\n\n                continue;\n\n        }\n\n    }\n\n\n\n    i = end;\n\n    while (i < 256)\n\n        coeffs[i++] = 0;\n\n\n\n    return 0;\n\n}\n", "idx": 24083}
{"project": "FFmpeg", "commit_id": "284b432662b6e137148ff9d13ef2b554cb14b4ae", "target": 0, "func": "static int fits_write_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    write_image_header(s);\n\n    avio_write(s->pb, pkt->data, pkt->size);\n\n    return 0;\n\n}\n", "idx": 24093}
{"project": "FFmpeg", "commit_id": "eabbc64728c2fdb74f565aededec2ab023d20699", "target": 0, "func": "static int mkv_write_tag_targets(AVFormatContext *s,\n\n                                 unsigned int elementid, unsigned int uid,\n\n                                 ebml_master *tags, ebml_master* tag)\n\n{\n\n    AVIOContext *pb;\n\n    MatroskaMuxContext *mkv = s->priv_data;\n\n    ebml_master targets;\n\n    int ret;\n\n\n\n    if (!tags->pos) {\n\n        ret = mkv_add_seekhead_entry(mkv->main_seekhead, MATROSKA_ID_TAGS, avio_tell(s->pb));\n\n        if (ret < 0) return ret;\n\n\n\n        start_ebml_master_crc32(s->pb, &mkv->tags_bc, tags, MATROSKA_ID_TAGS, 0);\n\n    }\n\n    pb = mkv->tags_bc;\n\n\n\n    *tag     = start_ebml_master(pb, MATROSKA_ID_TAG,       0);\n\n    targets = start_ebml_master(pb, MATROSKA_ID_TAGTARGETS, 0);\n\n    if (elementid)\n\n        put_ebml_uint(pb, elementid, uid);\n\n    end_ebml_master(pb, targets);\n\n    return 0;\n\n}\n", "idx": 24104}
{"project": "FFmpeg", "commit_id": "05c36e0e5fbf0b75dbbbd327ad2f6a62992f9262", "target": 1, "func": "static void formant_postfilter(G723_1_Context *p, int16_t *lpc, int16_t *buf)\n\n{\n\n    int16_t filter_coef[2][LPC_ORDER], *buf_ptr;\n\n    int filter_signal[LPC_ORDER + FRAME_LEN], *signal_ptr;\n\n    int i, j, k;\n\n\n\n    memcpy(buf, p->fir_mem, LPC_ORDER * sizeof(*buf));\n\n    memcpy(filter_signal, p->iir_mem, LPC_ORDER * sizeof(*filter_signal));\n\n\n\n    for (i = LPC_ORDER, j = 0; j < SUBFRAMES; i += SUBFRAME_LEN, j++) {\n\n        for (k = 0; k < LPC_ORDER; k++) {\n\n            filter_coef[0][k] = (-lpc[k] * postfilter_tbl[0][k] +\n\n                                 (1 << 14)) >> 15;\n\n            filter_coef[1][k] = (-lpc[k] * postfilter_tbl[1][k] +\n\n                                 (1 << 14)) >> 15;\n\n        }\n\n        iir_filter(filter_coef[0], filter_coef[1], buf + i,\n\n                   filter_signal + i);\n\n        lpc += LPC_ORDER;\n\n    }\n\n\n\n    memcpy(p->fir_mem, buf + FRAME_LEN, LPC_ORDER * sizeof(*p->fir_mem));\n\n    memcpy(p->iir_mem, filter_signal + FRAME_LEN,\n\n           LPC_ORDER * sizeof(*p->iir_mem));\n\n\n\n    buf_ptr    = buf + LPC_ORDER;\n\n    signal_ptr = filter_signal + LPC_ORDER;\n\n    for (i = 0; i < SUBFRAMES; i++) {\n\n        int16_t temp_vector[SUBFRAME_LEN];\n\n        int temp;\n\n        int auto_corr[2];\n\n        int scale, energy;\n\n\n\n        /* Normalize */\n\n        memcpy(temp_vector, buf_ptr, SUBFRAME_LEN * sizeof(*temp_vector));\n\n        scale = scale_vector(temp_vector, SUBFRAME_LEN);\n\n\n\n        /* Compute auto correlation coefficients */\n\n        auto_corr[0] = dot_product(temp_vector, temp_vector + 1,\n\n                                   SUBFRAME_LEN - 1, 1);\n\n        auto_corr[1] = dot_product(temp_vector, temp_vector, SUBFRAME_LEN, 1);\n\n\n\n        /* Compute reflection coefficient */\n\n        temp = auto_corr[1] >> 16;\n\n        if (temp) {\n\n            temp = (auto_corr[0] >> 2) / temp;\n\n        }\n\n        p->reflection_coef = (3 * p->reflection_coef + temp + 2) >> 2;\n\n        temp = -p->reflection_coef >> 1 & ~3;\n\n\n\n        /* Compensation filter */\n\n        for (j = 0; j < SUBFRAME_LEN; j++) {\n\n            buf_ptr[j] = av_clipl_int32(signal_ptr[j] +\n\n                                        ((signal_ptr[j - 1] >> 16) *\n\n                                         temp << 1)) >> 16;\n\n        }\n\n\n\n        /* Compute normalized signal energy */\n\n        temp = 2 * scale + 4;\n\n        if (temp < 0) {\n\n            energy = av_clipl_int32((int64_t)auto_corr[1] << -temp);\n\n        } else\n\n            energy = auto_corr[1] >> temp;\n\n\n\n        gain_scale(p, buf_ptr, energy);\n\n\n\n        buf_ptr    += SUBFRAME_LEN;\n\n        signal_ptr += SUBFRAME_LEN;\n\n    }\n\n}\n", "idx": 24110}
{"project": "FFmpeg", "commit_id": "211ca69b13eb0a127a9ef7e70ddaccdab125d1c5", "target": 1, "func": "int attribute_align_arg avresample_convert(AVAudioResampleContext *avr,\n\n                                           uint8_t **output, int out_plane_size,\n\n                                           int out_samples, uint8_t **input,\n\n                                           int in_plane_size, int in_samples)\n\n{\n\n    AudioData input_buffer;\n\n    AudioData output_buffer;\n\n    AudioData *current_buffer;\n\n    int ret, direct_output;\n\n\n\n    /* reset internal buffers */\n\n    if (avr->in_buffer) {\n\n        avr->in_buffer->nb_samples = 0;\n\n        ff_audio_data_set_channels(avr->in_buffer,\n\n                                   avr->in_buffer->allocated_channels);\n\n    }\n\n    if (avr->resample_out_buffer) {\n\n        avr->resample_out_buffer->nb_samples = 0;\n\n        ff_audio_data_set_channels(avr->resample_out_buffer,\n\n                                   avr->resample_out_buffer->allocated_channels);\n\n    }\n\n    if (avr->out_buffer) {\n\n        avr->out_buffer->nb_samples = 0;\n\n        ff_audio_data_set_channels(avr->out_buffer,\n\n                                   avr->out_buffer->allocated_channels);\n\n    }\n\n\n\n    av_dlog(avr, \"[start conversion]\\n\");\n\n\n\n    /* initialize output_buffer with output data */\n\n    direct_output = output && av_audio_fifo_size(avr->out_fifo) == 0;\n\n    if (output) {\n\n        ret = ff_audio_data_init(&output_buffer, output, out_plane_size,\n\n                                 avr->out_channels, out_samples,\n\n                                 avr->out_sample_fmt, 0, \"output\");\n\n        if (ret < 0)\n\n            return ret;\n\n        output_buffer.nb_samples = 0;\n\n    }\n\n\n\n    if (input) {\n\n        /* initialize input_buffer with input data */\n\n        ret = ff_audio_data_init(&input_buffer, input, in_plane_size,\n\n                                 avr->in_channels, in_samples,\n\n                                 avr->in_sample_fmt, 1, \"input\");\n\n        if (ret < 0)\n\n            return ret;\n\n        current_buffer = &input_buffer;\n\n\n\n        if (avr->upmix_needed && !avr->in_convert_needed && !avr->resample_needed &&\n\n            !avr->out_convert_needed && direct_output && out_samples >= in_samples) {\n\n            /* in some rare cases we can copy input to output and upmix\n\n               directly in the output buffer */\n\n            av_dlog(avr, \"[copy] %s to output\\n\", current_buffer->name);\n\n            ret = ff_audio_data_copy(&output_buffer, current_buffer,\n\n                                     avr->remap_point == REMAP_OUT_COPY ?\n\n                                     &avr->ch_map_info : NULL);\n\n            if (ret < 0)\n\n                return ret;\n\n            current_buffer = &output_buffer;\n\n        } else if (avr->remap_point == REMAP_OUT_COPY &&\n\n                   (!direct_output || out_samples < in_samples)) {\n\n            /* if remapping channels during output copy, we may need to\n\n             * use an intermediate buffer in order to remap before adding\n\n             * samples to the output fifo */\n\n            av_dlog(avr, \"[copy] %s to out_buffer\\n\", current_buffer->name);\n\n            ret = ff_audio_data_copy(avr->out_buffer, current_buffer,\n\n                                     &avr->ch_map_info);\n\n            if (ret < 0)\n\n                return ret;\n\n            current_buffer = avr->out_buffer;\n\n        } else if (avr->in_copy_needed || avr->in_convert_needed) {\n\n            /* if needed, copy or convert input to in_buffer, and downmix if\n\n               applicable */\n\n            if (avr->in_convert_needed) {\n\n                ret = ff_audio_data_realloc(avr->in_buffer,\n\n                                            current_buffer->nb_samples);\n\n                if (ret < 0)\n\n                    return ret;\n\n                av_dlog(avr, \"[convert] %s to in_buffer\\n\", current_buffer->name);\n\n                ret = ff_audio_convert(avr->ac_in, avr->in_buffer,\n\n                                       current_buffer);\n\n                if (ret < 0)\n\n                    return ret;\n\n            } else {\n\n                av_dlog(avr, \"[copy] %s to in_buffer\\n\", current_buffer->name);\n\n                ret = ff_audio_data_copy(avr->in_buffer, current_buffer,\n\n                                         avr->remap_point == REMAP_IN_COPY ?\n\n                                         &avr->ch_map_info : NULL);\n\n                if (ret < 0)\n\n                    return ret;\n\n            }\n\n            ff_audio_data_set_channels(avr->in_buffer, avr->in_channels);\n\n            if (avr->downmix_needed) {\n\n                av_dlog(avr, \"[downmix] in_buffer\\n\");\n\n                ret = ff_audio_mix(avr->am, avr->in_buffer);\n\n                if (ret < 0)\n\n                    return ret;\n\n            }\n\n            current_buffer = avr->in_buffer;\n\n        }\n\n    } else {\n\n        /* flush resampling buffer and/or output FIFO if input is NULL */\n\n        if (!avr->resample_needed)\n\n            return handle_buffered_output(avr, output ? &output_buffer : NULL,\n\n                                          NULL);\n\n        current_buffer = NULL;\n\n    }\n\n\n\n    if (avr->resample_needed) {\n\n        AudioData *resample_out;\n\n\n\n        if (!avr->out_convert_needed && direct_output && out_samples > 0)\n\n            resample_out = &output_buffer;\n\n        else\n\n            resample_out = avr->resample_out_buffer;\n\n        av_dlog(avr, \"[resample] %s to %s\\n\", current_buffer->name,\n\n                resample_out->name);\n\n        ret = ff_audio_resample(avr->resample, resample_out,\n\n                                current_buffer);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        /* if resampling did not produce any samples, just return 0 */\n\n        if (resample_out->nb_samples == 0) {\n\n            av_dlog(avr, \"[end conversion]\\n\");\n\n            return 0;\n\n        }\n\n\n\n        current_buffer = resample_out;\n\n    }\n\n\n\n    if (avr->upmix_needed) {\n\n        av_dlog(avr, \"[upmix] %s\\n\", current_buffer->name);\n\n        ret = ff_audio_mix(avr->am, current_buffer);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    /* if we resampled or upmixed directly to output, return here */\n\n    if (current_buffer == &output_buffer) {\n\n        av_dlog(avr, \"[end conversion]\\n\");\n\n        return current_buffer->nb_samples;\n\n    }\n\n\n\n    if (avr->out_convert_needed) {\n\n        if (direct_output && out_samples >= current_buffer->nb_samples) {\n\n            /* convert directly to output */\n\n            av_dlog(avr, \"[convert] %s to output\\n\", current_buffer->name);\n\n            ret = ff_audio_convert(avr->ac_out, &output_buffer, current_buffer);\n\n            if (ret < 0)\n\n                return ret;\n\n\n\n            av_dlog(avr, \"[end conversion]\\n\");\n\n            return output_buffer.nb_samples;\n\n        } else {\n\n            ret = ff_audio_data_realloc(avr->out_buffer,\n\n                                        current_buffer->nb_samples);\n\n            if (ret < 0)\n\n                return ret;\n\n            av_dlog(avr, \"[convert] %s to out_buffer\\n\", current_buffer->name);\n\n            ret = ff_audio_convert(avr->ac_out, avr->out_buffer,\n\n                                   current_buffer);\n\n            if (ret < 0)\n\n                return ret;\n\n            current_buffer = avr->out_buffer;\n\n        }\n\n    }\n\n\n\n    return handle_buffered_output(avr, output ? &output_buffer : NULL,\n\n                                  current_buffer);\n\n}\n", "idx": 24111}
{"project": "FFmpeg", "commit_id": "568e18b15e2ddf494fd8926707d34ca08c8edce5", "target": 1, "func": "static int ogg_read_header(AVFormatContext *avfcontext, AVFormatParameters *ap)\n\n{\n\n    OggContext *context = avfcontext->priv_data;\n\n    ogg_packet op ;    \n\n    char *buf ;\n\n    ogg_page og ;\n\n    AVStream *ast ;\n\n    AVCodecContext *codec;\n\n    uint8_t *p;\n\n    int i;\n\n     \n\n    ogg_sync_init(&context->oy) ;\n\n    buf = ogg_sync_buffer(&context->oy, DECODER_BUFFER_SIZE) ;\n\n\n\n    if(get_buffer(&avfcontext->pb, buf, DECODER_BUFFER_SIZE) <= 0)\n\n\treturn AVERROR_IO ;\n\n    \n\n    ogg_sync_wrote(&context->oy, DECODER_BUFFER_SIZE) ;   \n\n    ogg_sync_pageout(&context->oy, &og) ;\n\n    ogg_stream_init(&context->os, ogg_page_serialno(&og)) ;\n\n    ogg_stream_pagein(&context->os, &og) ;\n\n    \n\n    /* currently only one vorbis stream supported */\n\n\n\n    ast = av_new_stream(avfcontext, 0) ;\n\n    if(!ast)\n\n\treturn AVERROR_NOMEM ;\n\n    av_set_pts_info(ast, 60, 1, AV_TIME_BASE);\n\n\n\n    codec= &ast->codec;\n\n    codec->codec_type = CODEC_TYPE_AUDIO;\n\n    codec->codec_id = CODEC_ID_VORBIS;\n\n    for(i=0; i<3; i++){\n\n        if(next_packet(avfcontext, &op)){\n\n\n        }\n\n\n\n        codec->extradata_size+= 2 + op.bytes;\n\n        codec->extradata= av_realloc(codec->extradata, codec->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n        p= codec->extradata + codec->extradata_size - 2 - op.bytes;\n\n        *(p++)= op.bytes>>8;\n\n        *(p++)= op.bytes&0xFF;\n\n        memcpy(p, op.packet, op.bytes);\n\n    }\n\n\n\n    return 0 ;\n\n}", "idx": 24112}
{"project": "FFmpeg", "commit_id": "6e913f212907048d7009cf2f15551781c69b9985", "target": 1, "func": "static int vp56_size_changed(VP56Context *s)\n{\n    AVCodecContext *avctx = s->avctx;\n    int stride = s->frames[VP56_FRAME_CURRENT]->linesize[0];\n    int i;\n    s->plane_width[0]  = s->plane_width[3]  = avctx->coded_width;\n    s->plane_width[1]  = s->plane_width[2]  = avctx->coded_width/2;\n    s->plane_height[0] = s->plane_height[3] = avctx->coded_height;\n    s->plane_height[1] = s->plane_height[2] = avctx->coded_height/2;\n    for (i=0; i<4; i++)\n        s->stride[i] = s->flip * s->frames[VP56_FRAME_CURRENT]->linesize[i];\n    s->mb_width  = (avctx->coded_width +15) / 16;\n    s->mb_height = (avctx->coded_height+15) / 16;\n    if (s->mb_width > 1000 || s->mb_height > 1000) {\n        ff_set_dimensions(avctx, 0, 0);\n        av_log(avctx, AV_LOG_ERROR, \"picture too big\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    av_reallocp_array(&s->above_blocks, 4*s->mb_width+6,\n                      sizeof(*s->above_blocks));\n    av_reallocp_array(&s->macroblocks, s->mb_width*s->mb_height,\n                      sizeof(*s->macroblocks));\n    av_free(s->edge_emu_buffer_alloc);\n    s->edge_emu_buffer_alloc = av_malloc(16*stride);\n    s->edge_emu_buffer = s->edge_emu_buffer_alloc;\n    if (!s->above_blocks || !s->macroblocks || !s->edge_emu_buffer_alloc)\n        return AVERROR(ENOMEM);\n    if (s->flip < 0)\n        s->edge_emu_buffer += 15 * stride;\n    if (s->alpha_context)\n        return vp56_size_changed(s->alpha_context);\n    return 0;\n}", "idx": 24115}
{"project": "FFmpeg", "commit_id": "b0b2faa70995caf710bf49c7c6eb6dc502a67672", "target": 1, "func": "static void rtsp_cmd_teardown(HTTPContext *c, const char *url, RTSPHeader *h)\n\n{\n\n    HTTPContext *rtp_c;\n\n\n\n    rtp_c = find_rtp_session_with_url(url, h->session_id);\n\n    if (!rtp_c) {\n\n        rtsp_reply_error(c, RTSP_STATUS_SESSION);\n\n        return;\n\n    }\n\n\n\n    /* abort the session */\n\n    close_connection(rtp_c);\n\n\n\n    /* now everything is OK, so we can send the connection parameters */\n\n    rtsp_reply_header(c, RTSP_STATUS_OK);\n\n    /* session ID */\n\n    url_fprintf(c->pb, \"Session: %s\\r\\n\", rtp_c->session_id);\n\n    url_fprintf(c->pb, \"\\r\\n\");\n\n}\n", "idx": 24116}
{"project": "FFmpeg", "commit_id": "8cc72ce5a0d8ab6bc88d28cf55cd62674240121d", "target": 1, "func": "static av_cold int twin_decode_init(AVCodecContext *avctx)\n\n{\n\n    int ret;\n\n    TwinContext *tctx = avctx->priv_data;\n\n    int isampf, ibps;\n\n\n\n    tctx->avctx       = avctx;\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_FLTP;\n\n\n\n    if (!avctx->extradata || avctx->extradata_size < 12) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Missing or incomplete extradata\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avctx->channels = AV_RB32(avctx->extradata    ) + 1;\n\n    avctx->bit_rate = AV_RB32(avctx->extradata + 4) * 1000;\n\n    isampf          = AV_RB32(avctx->extradata + 8);\n\n    switch (isampf) {\n\n    case 44: avctx->sample_rate = 44100;         break;\n\n    case 22: avctx->sample_rate = 22050;         break;\n\n    case 11: avctx->sample_rate = 11025;         break;\n\n    default: avctx->sample_rate = isampf * 1000; break;\n\n    }\n\n\n\n    if (avctx->channels > CHANNELS_MAX) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported number of channels: %i\\n\",\n\n               avctx->channels);\n\n        return -1;\n\n    }\n\n    ibps = avctx->bit_rate / (1000 * avctx->channels);\n\n\n\n    switch ((isampf << 8) +  ibps) {\n\n    case (8 <<8) +  8: tctx->mtab = &mode_08_08; break;\n\n    case (11<<8) +  8: tctx->mtab = &mode_11_08; break;\n\n    case (11<<8) + 10: tctx->mtab = &mode_11_10; break;\n\n    case (16<<8) + 16: tctx->mtab = &mode_16_16; break;\n\n    case (22<<8) + 20: tctx->mtab = &mode_22_20; break;\n\n    case (22<<8) + 24: tctx->mtab = &mode_22_24; break;\n\n    case (22<<8) + 32: tctx->mtab = &mode_22_32; break;\n\n    case (44<<8) + 40: tctx->mtab = &mode_44_40; break;\n\n    case (44<<8) + 48: tctx->mtab = &mode_44_48; break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"This version does not support %d kHz - %d kbit/s/ch mode.\\n\", isampf, isampf);\n\n        return -1;\n\n    }\n\n\n\n    ff_dsputil_init(&tctx->dsp, avctx);\n\n    avpriv_float_dsp_init(&tctx->fdsp, avctx->flags & CODEC_FLAG_BITEXACT);\n\n    if ((ret = init_mdct_win(tctx))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error initializing MDCT\\n\");\n\n        twin_decode_close(avctx);\n\n        return ret;\n\n    }\n\n    init_bitstream_params(tctx);\n\n\n\n    memset_float(tctx->bark_hist[0][0], 0.1, FF_ARRAY_ELEMS(tctx->bark_hist));\n\n\n\n    avcodec_get_frame_defaults(&tctx->frame);\n\n    avctx->coded_frame = &tctx->frame;\n\n\n\n    return 0;\n\n}\n", "idx": 24119}
{"project": "FFmpeg", "commit_id": "bdddcb7b030d075dffa2989222d687106c06d50c", "target": 1, "func": "static int mov_read_sidx(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    int64_t offset = avio_tell(pb) + atom.size, pts, timestamp;\n\n    uint8_t version;\n\n    unsigned i, j, track_id, item_count;\n\n    AVStream *st = NULL;\n\n    AVStream *ref_st = NULL;\n\n    MOVStreamContext *sc, *ref_sc = NULL;\n\n    AVRational timescale;\n\n\n\n    version = avio_r8(pb);\n\n    if (version > 1) {\n\n        avpriv_request_sample(c->fc, \"sidx version %u\", version);\n\n        return 0;\n\n    }\n\n\n\n    avio_rb24(pb); // flags\n\n\n\n    track_id = avio_rb32(pb); // Reference ID\n\n    for (i = 0; i < c->fc->nb_streams; i++) {\n\n        if (c->fc->streams[i]->id == track_id) {\n\n            st = c->fc->streams[i];\n\n            break;\n\n        }\n\n    }\n\n    if (!st) {\n\n        av_log(c->fc, AV_LOG_WARNING, \"could not find corresponding track id %d\\n\", track_id);\n\n        return 0;\n\n    }\n\n\n\n    sc = st->priv_data;\n\n\n\n    timescale = av_make_q(1, avio_rb32(pb));\n\n\n\n    if (timescale.den <= 0) {\n\n        av_log(c->fc, AV_LOG_ERROR, \"Invalid sidx timescale 1/%d\\n\", timescale.den);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (version == 0) {\n\n        pts = avio_rb32(pb);\n\n        offset += avio_rb32(pb);\n\n    } else {\n\n        pts = avio_rb64(pb);\n\n        offset += avio_rb64(pb);\n\n    }\n\n\n\n    avio_rb16(pb); // reserved\n\n\n\n    item_count = avio_rb16(pb);\n\n\n\n    for (i = 0; i < item_count; i++) {\n\n        int index;\n\n        MOVFragmentStreamInfo * frag_stream_info;\n\n        uint32_t size = avio_rb32(pb);\n\n        uint32_t duration = avio_rb32(pb);\n\n        if (size & 0x80000000) {\n\n            avpriv_request_sample(c->fc, \"sidx reference_type 1\");\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n        avio_rb32(pb); // sap_flags\n\n        timestamp = av_rescale_q(pts, st->time_base, timescale);\n\n\n\n        index = update_frag_index(c, offset);\n\n        frag_stream_info = get_frag_stream_info(&c->frag_index, index, track_id);\n\n        if (frag_stream_info)\n\n            frag_stream_info->sidx_pts = timestamp;\n\n\n\n        offset += size;\n\n        pts += duration;\n\n    }\n\n\n\n    st->duration = sc->track_end = pts;\n\n\n\n    sc->has_sidx = 1;\n\n\n\n    if (offset == avio_size(pb)) {\n\n        // Find first entry in fragment index that came from an sidx.\n\n        // This will pretty much always be the first entry.\n\n        for (i = 0; i < c->frag_index.nb_items; i++) {\n\n            MOVFragmentIndexItem * item = &c->frag_index.item[i];\n\n            for (j = 0; ref_st == NULL && j < item->nb_stream_info; j++) {\n\n                MOVFragmentStreamInfo * si;\n\n                si = &item->stream_info[j];\n\n                if (si->sidx_pts != AV_NOPTS_VALUE) {\n\n                    ref_st = c->fc->streams[i];\n\n                    ref_sc = ref_st->priv_data;\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n        for (i = 0; i < c->fc->nb_streams; i++) {\n\n            st = c->fc->streams[i];\n\n            sc = st->priv_data;\n\n            if (!sc->has_sidx) {\n\n                st->duration = sc->track_end = av_rescale(ref_st->duration, sc->time_scale, ref_sc->time_scale);\n\n            }\n\n        }\n\n\n\n        c->frag_index.complete = 1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24120}
{"project": "FFmpeg", "commit_id": "933aa91e31d5cbf9dbc0cf416a988e6011bc4a40", "target": 1, "func": "void ff_hevc_cabac_init(HEVCContext *s, int ctb_addr_ts)\n\n{\n\n    if (ctb_addr_ts == s->ps.pps->ctb_addr_rs_to_ts[s->sh.slice_ctb_addr_rs]) {\n\n        cabac_init_decoder(s);\n\n        if (s->sh.dependent_slice_segment_flag == 0 ||\n\n            (s->ps.pps->tiles_enabled_flag &&\n\n             s->ps.pps->tile_id[ctb_addr_ts] != s->ps.pps->tile_id[ctb_addr_ts - 1]))\n\n            cabac_init_state(s);\n\n\n\n        if (!s->sh.first_slice_in_pic_flag &&\n\n            s->ps.pps->entropy_coding_sync_enabled_flag) {\n\n            if (ctb_addr_ts % s->ps.sps->ctb_width == 0) {\n\n                if (s->ps.sps->ctb_width == 1)\n\n                    cabac_init_state(s);\n\n                else if (s->sh.dependent_slice_segment_flag == 1)\n\n                    load_states(s);\n\n            }\n\n        }\n\n    } else {\n\n        if (s->ps.pps->tiles_enabled_flag &&\n\n            s->ps.pps->tile_id[ctb_addr_ts] != s->ps.pps->tile_id[ctb_addr_ts - 1]) {\n\n            if (s->threads_number == 1)\n\n                cabac_reinit(s->HEVClc);\n\n            else\n\n                cabac_init_decoder(s);\n\n            cabac_init_state(s);\n\n        }\n\n        if (s->ps.pps->entropy_coding_sync_enabled_flag) {\n\n            if (ctb_addr_ts % s->ps.sps->ctb_width == 0) {\n\n                get_cabac_terminate(&s->HEVClc->cc);\n\n                if (s->threads_number == 1)\n\n                    cabac_reinit(s->HEVClc);\n\n                else\n\n                    cabac_init_decoder(s);\n\n\n\n                if (s->ps.sps->ctb_width == 1)\n\n                    cabac_init_state(s);\n\n                else\n\n                    load_states(s);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 24125}
{"project": "FFmpeg", "commit_id": "f13e733145132e39056027229ff954a798f58410", "target": 1, "func": "int ff_snow_frame_start(SnowContext *s){\n\n   AVFrame tmp;\n\n   int i, ret;\n\n   int w= s->avctx->width; //FIXME round up to x16 ?\n\n   int h= s->avctx->height;\n\n\n\n    if (s->current_picture.data[0] && !(s->avctx->flags&CODEC_FLAG_EMU_EDGE)) {\n\n        s->dsp.draw_edges(s->current_picture.data[0],\n\n                          s->current_picture.linesize[0], w   , h   ,\n\n                          EDGE_WIDTH  , EDGE_WIDTH  , EDGE_TOP | EDGE_BOTTOM);\n\n        s->dsp.draw_edges(s->current_picture.data[1],\n\n                          s->current_picture.linesize[1], w>>s->chroma_h_shift, h>>s->chroma_v_shift,\n\n                          EDGE_WIDTH>>s->chroma_h_shift, EDGE_WIDTH>>s->chroma_v_shift, EDGE_TOP | EDGE_BOTTOM);\n\n        s->dsp.draw_edges(s->current_picture.data[2],\n\n                          s->current_picture.linesize[2], w>>s->chroma_h_shift, h>>s->chroma_v_shift,\n\n                          EDGE_WIDTH>>s->chroma_h_shift, EDGE_WIDTH>>s->chroma_v_shift, EDGE_TOP | EDGE_BOTTOM);\n\n    }\n\n\n\n    ff_snow_release_buffer(s->avctx);\n\n\n\n    av_frame_move_ref(&tmp, &s->last_picture[s->max_ref_frames-1]);\n\n    for(i=s->max_ref_frames-1; i>0; i--)\n\n        av_frame_move_ref(&s->last_picture[i], &s->last_picture[i-1]);\n\n    memmove(s->halfpel_plane+1, s->halfpel_plane, (s->max_ref_frames-1)*sizeof(void*)*4*4);\n\n    if(USE_HALFPEL_PLANE && s->current_picture.data[0])\n\n        halfpel_interpol(s, s->halfpel_plane[0], &s->current_picture);\n\n    av_frame_move_ref(&s->last_picture[0], &s->current_picture);\n\n    av_frame_move_ref(&s->current_picture, &tmp);\n\n\n\n    if(s->keyframe){\n\n        s->ref_frames= 0;\n\n    }else{\n\n        int i;\n\n        for(i=0; i<s->max_ref_frames && s->last_picture[i].data[0]; i++)\n\n            if(i && s->last_picture[i-1].key_frame)\n\n                break;\n\n        s->ref_frames= i;\n\n        if(s->ref_frames==0){\n\n            av_log(s->avctx,AV_LOG_ERROR, \"No reference frames\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    if ((ret = ff_get_buffer(s->avctx, &s->current_picture, AV_GET_BUFFER_FLAG_REF)) < 0)\n\n        return ret;\n\n\n\n    s->current_picture.key_frame= s->keyframe;\n\n\n\n    return 0;\n\n}\n", "idx": 24128}
{"project": "FFmpeg", "commit_id": "09096fb68713089a8f97c8fa24e9d7f3bb9231d5", "target": 1, "func": "static int h264_slice_header_parse(const H264Context *h, H264SliceContext *sl,\n\n                                   const H2645NAL *nal)\n\n{\n\n    const SPS *sps;\n\n    const PPS *pps;\n\n    int ret;\n\n    unsigned int slice_type, tmp, i;\n\n    int field_pic_flag, bottom_field_flag;\n\n    int first_slice = sl == h->slice_ctx && !h->current_slice;\n\n    int picture_structure;\n\n\n\n    if (first_slice)\n\n        av_assert0(!h->setup_finished);\n\n\n\n    sl->first_mb_addr = get_ue_golomb_long(&sl->gb);\n\n\n\n    slice_type = get_ue_golomb_31(&sl->gb);\n\n    if (slice_type > 9) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"slice type %d too large at %d\\n\",\n\n               slice_type, sl->first_mb_addr);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (slice_type > 4) {\n\n        slice_type -= 5;\n\n        sl->slice_type_fixed = 1;\n\n    } else\n\n        sl->slice_type_fixed = 0;\n\n\n\n    slice_type         = ff_h264_golomb_to_pict_type[slice_type];\n\n    sl->slice_type     = slice_type;\n\n    sl->slice_type_nos = slice_type & 3;\n\n\n\n    if (nal->type  == H264_NAL_IDR_SLICE &&\n\n        sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"A non-intra slice in an IDR NAL unit.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    sl->pps_id = get_ue_golomb(&sl->gb);\n\n    if (sl->pps_id >= MAX_PPS_COUNT) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"pps_id %u out of range\\n\", sl->pps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (!h->ps.pps_list[sl->pps_id]) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"non-existing PPS %u referenced\\n\",\n\n               sl->pps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    pps = (const PPS*)h->ps.pps_list[sl->pps_id]->data;\n\n\n\n    if (!h->ps.sps_list[pps->sps_id]) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"non-existing SPS %u referenced\\n\", pps->sps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    sps = (const SPS*)h->ps.sps_list[pps->sps_id]->data;\n\n\n\n    sl->frame_num = get_bits(&sl->gb, sps->log2_max_frame_num);\n\n    if (!first_slice) {\n\n        if (h->poc.frame_num != sl->frame_num) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"Frame num change from %d to %d\\n\",\n\n                   h->poc.frame_num, sl->frame_num);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    sl->mb_mbaff       = 0;\n\n\n\n    if (sps->frame_mbs_only_flag) {\n\n        picture_structure = PICT_FRAME;\n\n    } else {\n\n        if (!sps->direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"This stream was generated by a broken encoder, invalid 8x8 inference\\n\");\n\n            return -1;\n\n        }\n\n        field_pic_flag = get_bits1(&sl->gb);\n\n        if (field_pic_flag) {\n\n            bottom_field_flag = get_bits1(&sl->gb);\n\n            picture_structure = PICT_TOP_FIELD + bottom_field_flag;\n\n        } else {\n\n            picture_structure = PICT_FRAME;\n\n        }\n\n    }\n\n    sl->picture_structure      = picture_structure;\n\n    sl->mb_field_decoding_flag = picture_structure != PICT_FRAME;\n\n\n\n    if (picture_structure == PICT_FRAME) {\n\n        sl->curr_pic_num = sl->frame_num;\n\n        sl->max_pic_num  = 1 << sps->log2_max_frame_num;\n\n    } else {\n\n        sl->curr_pic_num = 2 * sl->frame_num + 1;\n\n        sl->max_pic_num  = 1 << (sps->log2_max_frame_num + 1);\n\n    }\n\n\n\n    if (nal->type == H264_NAL_IDR_SLICE)\n\n        get_ue_golomb_long(&sl->gb); /* idr_pic_id */\n\n\n\n    if (sps->poc_type == 0) {\n\n        sl->poc_lsb = get_bits(&sl->gb, sps->log2_max_poc_lsb);\n\n\n\n        if (pps->pic_order_present == 1 && picture_structure == PICT_FRAME)\n\n            sl->delta_poc_bottom = get_se_golomb(&sl->gb);\n\n    }\n\n\n\n    if (sps->poc_type == 1 && !sps->delta_pic_order_always_zero_flag) {\n\n        sl->delta_poc[0] = get_se_golomb(&sl->gb);\n\n\n\n        if (pps->pic_order_present == 1 && picture_structure == PICT_FRAME)\n\n            sl->delta_poc[1] = get_se_golomb(&sl->gb);\n\n    }\n\n\n\n    sl->redundant_pic_count = 0;\n\n    if (pps->redundant_pic_cnt_present)\n\n        sl->redundant_pic_count = get_ue_golomb(&sl->gb);\n\n\n\n    if (sl->slice_type_nos == AV_PICTURE_TYPE_B)\n\n        sl->direct_spatial_mv_pred = get_bits1(&sl->gb);\n\n\n\n    ret = ff_h264_parse_ref_count(&sl->list_count, sl->ref_count,\n\n                                  &sl->gb, pps, sl->slice_type_nos,\n\n                                  picture_structure, h->avctx);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n       ret = ff_h264_decode_ref_pic_list_reordering(sl, h->avctx);\n\n       if (ret < 0) {\n\n           sl->ref_count[1] = sl->ref_count[0] = 0;\n\n           return ret;\n\n       }\n\n    }\n\n\n\n    sl->pwt.use_weight = 0;\n\n    for (i = 0; i < 2; i++) {\n\n        sl->pwt.luma_weight_flag[i]   = 0;\n\n        sl->pwt.chroma_weight_flag[i] = 0;\n\n    }\n\n    if ((pps->weighted_pred && sl->slice_type_nos == AV_PICTURE_TYPE_P) ||\n\n        (pps->weighted_bipred_idc == 1 &&\n\n         sl->slice_type_nos == AV_PICTURE_TYPE_B)) {\n\n        ret = ff_h264_pred_weight_table(&sl->gb, sps, sl->ref_count,\n\n                                  sl->slice_type_nos, &sl->pwt, h->avctx);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    sl->explicit_ref_marking = 0;\n\n    if (nal->ref_idc) {\n\n        ret = ff_h264_decode_ref_pic_marking(sl, &sl->gb, nal, h->avctx);\n\n        if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I && pps->cabac) {\n\n        tmp = get_ue_golomb_31(&sl->gb);\n\n        if (tmp > 2) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"cabac_init_idc %u overflow\\n\", tmp);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        sl->cabac_init_idc = tmp;\n\n    }\n\n\n\n    sl->last_qscale_diff = 0;\n\n    tmp = pps->init_qp + get_se_golomb(&sl->gb);\n\n    if (tmp > 51 + 6 * (sps->bit_depth_luma - 8)) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"QP %u out of range\\n\", tmp);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    sl->qscale       = tmp;\n\n    sl->chroma_qp[0] = get_chroma_qp(pps, 0, sl->qscale);\n\n    sl->chroma_qp[1] = get_chroma_qp(pps, 1, sl->qscale);\n\n    // FIXME qscale / qp ... stuff\n\n    if (sl->slice_type == AV_PICTURE_TYPE_SP)\n\n        get_bits1(&sl->gb); /* sp_for_switch_flag */\n\n    if (sl->slice_type == AV_PICTURE_TYPE_SP ||\n\n        sl->slice_type == AV_PICTURE_TYPE_SI)\n\n        get_se_golomb(&sl->gb); /* slice_qs_delta */\n\n\n\n    sl->deblocking_filter     = 1;\n\n    sl->slice_alpha_c0_offset = 0;\n\n    sl->slice_beta_offset     = 0;\n\n    if (pps->deblocking_filter_parameters_present) {\n\n        tmp = get_ue_golomb_31(&sl->gb);\n\n        if (tmp > 2) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"deblocking_filter_idc %u out of range\\n\", tmp);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        sl->deblocking_filter = tmp;\n\n        if (sl->deblocking_filter < 2)\n\n            sl->deblocking_filter ^= 1;  // 1<->0\n\n\n\n        if (sl->deblocking_filter) {\n\n            sl->slice_alpha_c0_offset = get_se_golomb(&sl->gb) * 2;\n\n            sl->slice_beta_offset     = get_se_golomb(&sl->gb) * 2;\n\n            if (sl->slice_alpha_c0_offset >  12 ||\n\n                sl->slice_alpha_c0_offset < -12 ||\n\n                sl->slice_beta_offset >  12     ||\n\n                sl->slice_beta_offset < -12) {\n\n                av_log(h->avctx, AV_LOG_ERROR,\n\n                       \"deblocking filter parameters %d %d out of range\\n\",\n\n                       sl->slice_alpha_c0_offset, sl->slice_beta_offset);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24129}
{"project": "FFmpeg", "commit_id": "009f829dde811af654af7110326aea3a72c05d5e", "target": 1, "func": "static inline void RENAME(yuv2rgb565_2)(SwsContext *c, const uint16_t *buf0,\n\n                                        const uint16_t *buf1, const uint16_t *ubuf0,\n\n                                        const uint16_t *ubuf1, const uint16_t *vbuf0,\n\n                                        const uint16_t *vbuf1, const uint16_t *abuf0,\n\n                                        const uint16_t *abuf1, uint8_t *dest,\n\n                                        int dstW, int yalpha, int uvalpha, int y)\n\n{\n\n    x86_reg uv_off = c->uv_off << 1;\n\n\n\n    //Note 8280 == DSTW_OFFSET but the preprocessor can't handle that there :(\n\n    __asm__ volatile(\n\n        \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n        \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n        \"push %%\"REG_BP\"                        \\n\\t\"\n\n        YSCALEYUV2RGB(%%REGBP, %5, %6)\n\n        \"pxor    %%mm7, %%mm7                   \\n\\t\"\n\n        /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n        \"paddusb \"BLUE_DITHER\"(%5), %%mm2      \\n\\t\"\n\n        \"paddusb \"GREEN_DITHER\"(%5), %%mm4      \\n\\t\"\n\n        \"paddusb \"RED_DITHER\"(%5), %%mm5      \\n\\t\"\n\n#endif\n\n        WRITERGB16(%%REGb, 8280(%5), %%REGBP)\n\n        \"pop %%\"REG_BP\"                         \\n\\t\"\n\n        \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n        :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n           \"a\" (&c->redDither), \"m\"(uv_off)\n\n    );\n\n}\n", "idx": 24130}
{"project": "FFmpeg", "commit_id": "da048c6d24729d3bab6ccb0ac340ea129e3e88d5", "target": 1, "func": "static int mov_write_moov_tag(AVIOContext *pb, MOVMuxContext *mov,\n\n                              AVFormatContext *s)\n\n{\n\n    int i;\n\n    int64_t pos = avio_tell(pb);\n\n    avio_wb32(pb, 0); /* size placeholder*/\n\n    ffio_wfourcc(pb, \"moov\");\n\n\n\n    for (i = 0; i < mov->nb_streams; i++) {\n\n        if (mov->tracks[i].entry <= 0 && !(mov->flags & FF_MOV_FLAG_FRAGMENT))\n\n            continue;\n\n\n\n        mov->tracks[i].time     = mov->time;\n\n        mov->tracks[i].track_id = i + 1;\n\n\n\n        if (mov->tracks[i].entry)\n\n            build_chunks(&mov->tracks[i]);\n\n    }\n\n\n\n    if (mov->chapter_track)\n\n        for (i = 0; i < s->nb_streams; i++) {\n\n            mov->tracks[i].tref_tag = MKTAG('c','h','a','p');\n\n            mov->tracks[i].tref_id  = mov->tracks[mov->chapter_track].track_id;\n\n        }\n\n    for (i = 0; i < mov->nb_streams; i++) {\n\n        if (mov->tracks[i].tag == MKTAG('r','t','p',' ')) {\n\n            mov->tracks[i].tref_tag = MKTAG('h','i','n','t');\n\n            mov->tracks[i].tref_id =\n\n                mov->tracks[mov->tracks[i].src_track].track_id;\n\n        }\n\n    }\n\n    for (i = 0; i < mov->nb_streams; i++) {\n\n        if (mov->tracks[i].tag == MKTAG('t','m','c','d')) {\n\n            int src_trk = mov->tracks[i].src_track;\n\n            mov->tracks[src_trk].tref_tag = mov->tracks[i].tag;\n\n            mov->tracks[src_trk].tref_id  = mov->tracks[i].track_id;\n\n            //src_trk may have a different timescale than the tmcd track\n\n            mov->tracks[i].track_duration = av_rescale(mov->tracks[src_trk].track_duration,\n\n                                                       mov->tracks[i].timescale,\n\n                                                       mov->tracks[src_trk].timescale);\n\n        }\n\n    }\n\n\n\n    mov_write_mvhd_tag(pb, mov);\n\n    if (mov->mode != MODE_MOV && !mov->iods_skip)\n\n        mov_write_iods_tag(pb, mov);\n\n    for (i = 0; i < mov->nb_streams; i++) {\n\n        if (mov->tracks[i].entry > 0 || mov->flags & FF_MOV_FLAG_FRAGMENT) {\n\n            mov_write_trak_tag(pb, mov, &(mov->tracks[i]), i < s->nb_streams ? s->streams[i] : NULL);\n\n        }\n\n    }\n\n    if (mov->flags & FF_MOV_FLAG_FRAGMENT)\n\n        mov_write_mvex_tag(pb, mov); /* QuickTime requires trak to precede this */\n\n\n\n    if (mov->mode == MODE_PSP)\n\n        mov_write_uuidusmt_tag(pb, s);\n\n    else\n\n        mov_write_udta_tag(pb, mov, s);\n\n\n\n    return update_size(pb, pos);\n\n}\n", "idx": 24132}
{"project": "FFmpeg", "commit_id": "f78cd0c243b9149c7f604ecf1006d78e344aa6ca", "target": 1, "func": "void FUNC(ff_simple_idct_put)(uint8_t *dest_, int line_size, DCTELEM *block)\n\n{\n\n    pixel *dest = (pixel *)dest_;\n\n    int i;\n\n\n\n    line_size /= sizeof(pixel);\n\n\n\n    for (i = 0; i < 8; i++)\n\n        FUNC(idctRowCondDC)(block + i*8);\n\n\n\n    for (i = 0; i < 8; i++)\n\n        FUNC(idctSparseColPut)(dest + i, line_size, block + i);\n\n}\n", "idx": 24134}
{"project": "FFmpeg", "commit_id": "01ecb7172b684f1c4b3e748f95c5a9a494ca36ec", "target": 1, "func": "static void quantize_and_encode_band_cost_UPAIR7_mips(struct AACEncContext *s,\n\n                                                      PutBitContext *pb, const float *in, float *out,\n\n                                                      const float *scaled, int size, int scale_idx,\n\n                                                      int cb, const float lambda, const float uplim,\n\n                                                      int *bits, const float ROUNDING)\n\n{\n\n    const float Q34 = ff_aac_pow34sf_tab[POW_SF2_ZERO - scale_idx + SCALE_ONE_POS - SCALE_DIV_512];\n\n    const float IQ  = ff_aac_pow2sf_tab [POW_SF2_ZERO + scale_idx - SCALE_ONE_POS + SCALE_DIV_512];\n\n    int i;\n\n    int qc1, qc2, qc3, qc4;\n\n\n\n    uint8_t  *p_bits  = (uint8_t*) ff_aac_spectral_bits[cb-1];\n\n    uint16_t *p_codes = (uint16_t*)ff_aac_spectral_codes[cb-1];\n\n    float    *p_vec   = (float    *)ff_aac_codebook_vectors[cb-1];\n\n\n\n    abs_pow34_v(s->scoefs, in, size);\n\n    scaled = s->scoefs;\n\n    for (i = 0; i < size; i += 4) {\n\n        int curidx1, curidx2, sign1, count1, sign2, count2;\n\n        int *in_int = (int *)&in[i];\n\n        uint8_t v_bits;\n\n        unsigned int v_codes;\n\n        int t0, t1, t2, t3, t4;\n\n        const float *vec1, *vec2;\n\n\n\n        qc1 = scaled[i  ] * Q34 + ROUND_STANDARD;\n\n        qc2 = scaled[i+1] * Q34 + ROUND_STANDARD;\n\n        qc3 = scaled[i+2] * Q34 + ROUND_STANDARD;\n\n        qc4 = scaled[i+3] * Q34 + ROUND_STANDARD;\n\n\n\n        __asm__ volatile (\n\n            \".set push                              \\n\\t\"\n\n            \".set noreorder                         \\n\\t\"\n\n\n\n            \"ori    %[t4],      $zero,      7       \\n\\t\"\n\n            \"ori    %[sign1],   $zero,      0       \\n\\t\"\n\n            \"ori    %[sign2],   $zero,      0       \\n\\t\"\n\n            \"slt    %[t0],      %[t4],      %[qc1]  \\n\\t\"\n\n            \"slt    %[t1],      %[t4],      %[qc2]  \\n\\t\"\n\n            \"slt    %[t2],      %[t4],      %[qc3]  \\n\\t\"\n\n            \"slt    %[t3],      %[t4],      %[qc4]  \\n\\t\"\n\n            \"movn   %[qc1],     %[t4],      %[t0]   \\n\\t\"\n\n            \"movn   %[qc2],     %[t4],      %[t1]   \\n\\t\"\n\n            \"movn   %[qc3],     %[t4],      %[t2]   \\n\\t\"\n\n            \"movn   %[qc4],     %[t4],      %[t3]   \\n\\t\"\n\n            \"lw     %[t0],      0(%[in_int])        \\n\\t\"\n\n            \"lw     %[t1],      4(%[in_int])        \\n\\t\"\n\n            \"lw     %[t2],      8(%[in_int])        \\n\\t\"\n\n            \"lw     %[t3],      12(%[in_int])       \\n\\t\"\n\n            \"slt    %[t0],      %[t0],      $zero   \\n\\t\"\n\n            \"movn   %[sign1],   %[t0],      %[qc1]  \\n\\t\"\n\n            \"slt    %[t2],      %[t2],      $zero   \\n\\t\"\n\n            \"movn   %[sign2],   %[t2],      %[qc3]  \\n\\t\"\n\n            \"slt    %[t1],      %[t1],      $zero   \\n\\t\"\n\n            \"sll    %[t0],      %[sign1],   1       \\n\\t\"\n\n            \"or     %[t0],      %[t0],      %[t1]   \\n\\t\"\n\n            \"movn   %[sign1],   %[t0],      %[qc2]  \\n\\t\"\n\n            \"slt    %[t3],      %[t3],      $zero   \\n\\t\"\n\n            \"sll    %[t0],      %[sign2],   1       \\n\\t\"\n\n            \"or     %[t0],      %[t0],      %[t3]   \\n\\t\"\n\n            \"movn   %[sign2],   %[t0],      %[qc4]  \\n\\t\"\n\n            \"slt    %[count1],  $zero,      %[qc1]  \\n\\t\"\n\n            \"slt    %[t1],      $zero,      %[qc2]  \\n\\t\"\n\n            \"slt    %[count2],  $zero,      %[qc3]  \\n\\t\"\n\n            \"slt    %[t2],      $zero,      %[qc4]  \\n\\t\"\n\n            \"addu   %[count1],  %[count1],  %[t1]   \\n\\t\"\n\n            \"addu   %[count2],  %[count2],  %[t2]   \\n\\t\"\n\n\n\n            \".set pop                               \\n\\t\"\n\n\n\n            : [qc1]\"+r\"(qc1), [qc2]\"+r\"(qc2),\n\n              [qc3]\"+r\"(qc3), [qc4]\"+r\"(qc4),\n\n              [sign1]\"=&r\"(sign1), [count1]\"=&r\"(count1),\n\n              [sign2]\"=&r\"(sign2), [count2]\"=&r\"(count2),\n\n              [t0]\"=&r\"(t0), [t1]\"=&r\"(t1), [t2]\"=&r\"(t2), [t3]\"=&r\"(t3),\n\n              [t4]\"=&r\"(t4)\n\n            : [in_int]\"r\"(in_int)\n\n            : \"t0\", \"t1\", \"t2\", \"t3\", \"t4\",\n\n              \"memory\"\n\n        );\n\n\n\n        curidx1  = 8 * qc1;\n\n        curidx1 += qc2;\n\n\n\n        v_codes = (p_codes[curidx1] << count1) | sign1;\n\n        v_bits  = p_bits[curidx1] + count1;\n\n        put_bits(pb, v_bits, v_codes);\n\n\n\n        curidx2  = 8 * qc3;\n\n        curidx2 += qc4;\n\n\n\n        v_codes = (p_codes[curidx2] << count2) | sign2;\n\n        v_bits  = p_bits[curidx2] + count2;\n\n        put_bits(pb, v_bits, v_codes);\n\n\n\n        if (out) {\n\n           vec1 = &p_vec[curidx1*2];\n\n           vec2 = &p_vec[curidx2*2];\n\n           out[i+0] = copysignf(vec1[0] * IQ, in[i+0]);\n\n           out[i+1] = copysignf(vec1[1] * IQ, in[i+1]);\n\n           out[i+2] = copysignf(vec2[0] * IQ, in[i+2]);\n\n           out[i+3] = copysignf(vec2[1] * IQ, in[i+3]);\n\n        }\n\n    }\n\n}\n", "idx": 24135}
{"project": "FFmpeg", "commit_id": "f21c263c8979aa8a71c1c10909efb991679045c1", "target": 1, "func": "static int rtmp_packet_read_one_chunk(URLContext *h, RTMPPacket *p,\n\n                                      int chunk_size, RTMPPacket **prev_pkt_ptr,\n\n                                      int *nb_prev_pkt, uint8_t hdr)\n\n{\n\n\n\n    uint8_t buf[16];\n\n    int channel_id, timestamp, size;\n\n    uint32_t ts_field; // non-extended timestamp or delta field\n\n    uint32_t extra = 0;\n\n    enum RTMPPacketType type;\n\n    int written = 0;\n\n    int ret, toread;\n\n    RTMPPacket *prev_pkt;\n\n\n\n    written++;\n\n    channel_id = hdr & 0x3F;\n\n\n\n    if (channel_id < 2) { //special case for channel number >= 64\n\n        buf[1] = 0;\n\n        if (ffurl_read_complete(h, buf, channel_id + 1) != channel_id + 1)\n\n            return AVERROR(EIO);\n\n        written += channel_id + 1;\n\n        channel_id = AV_RL16(buf) + 64;\n\n    }\n\n    if ((ret = ff_rtmp_check_alloc_array(prev_pkt_ptr, nb_prev_pkt,\n\n                                         channel_id)) < 0)\n\n        return ret;\n\n    prev_pkt = *prev_pkt_ptr;\n\n    size  = prev_pkt[channel_id].size;\n\n    type  = prev_pkt[channel_id].type;\n\n    extra = prev_pkt[channel_id].extra;\n\n\n\n    hdr >>= 6; // header size indicator\n\n    if (hdr == RTMP_PS_ONEBYTE) {\n\n        ts_field = prev_pkt[channel_id].ts_field;\n\n    } else {\n\n        if (ffurl_read_complete(h, buf, 3) != 3)\n\n            return AVERROR(EIO);\n\n        written += 3;\n\n        ts_field = AV_RB24(buf);\n\n        if (hdr != RTMP_PS_FOURBYTES) {\n\n            if (ffurl_read_complete(h, buf, 3) != 3)\n\n                return AVERROR(EIO);\n\n            written += 3;\n\n            size = AV_RB24(buf);\n\n            if (ffurl_read_complete(h, buf, 1) != 1)\n\n                return AVERROR(EIO);\n\n            written++;\n\n            type = buf[0];\n\n            if (hdr == RTMP_PS_TWELVEBYTES) {\n\n                if (ffurl_read_complete(h, buf, 4) != 4)\n\n                    return AVERROR(EIO);\n\n                written += 4;\n\n                extra = AV_RL32(buf);\n\n            }\n\n        }\n\n    }\n\n    if (ts_field == 0xFFFFFF) {\n\n        if (ffurl_read_complete(h, buf, 4) != 4)\n\n            return AVERROR(EIO);\n\n        timestamp = AV_RB32(buf);\n\n    } else {\n\n        timestamp = ts_field;\n\n    }\n\n    if (hdr != RTMP_PS_TWELVEBYTES)\n\n        timestamp += prev_pkt[channel_id].timestamp;\n\n\n\n    if (!prev_pkt[channel_id].read) {\n\n        if ((ret = ff_rtmp_packet_create(p, channel_id, type, timestamp,\n\n                                         size)) < 0)\n\n            return ret;\n\n        p->read = written;\n\n        p->offset = 0;\n\n        prev_pkt[channel_id].ts_field   = ts_field;\n\n        prev_pkt[channel_id].timestamp  = timestamp;\n\n    } else {\n\n        // previous packet in this channel hasn't completed reading\n\n        RTMPPacket *prev = &prev_pkt[channel_id];\n\n        p->data          = prev->data;\n\n        p->size          = prev->size;\n\n        p->channel_id    = prev->channel_id;\n\n        p->type          = prev->type;\n\n        p->ts_field      = prev->ts_field;\n\n        p->extra         = prev->extra;\n\n        p->offset        = prev->offset;\n\n        p->read          = prev->read + written;\n\n        p->timestamp     = prev->timestamp;\n\n        prev->data       = NULL;\n\n    }\n\n    p->extra = extra;\n\n    // save history\n\n    prev_pkt[channel_id].channel_id = channel_id;\n\n    prev_pkt[channel_id].type       = type;\n\n    prev_pkt[channel_id].size       = size;\n\n    prev_pkt[channel_id].extra      = extra;\n\n    size = size - p->offset;\n\n\n\n    toread = FFMIN(size, chunk_size);\n\n    if (ffurl_read_complete(h, p->data + p->offset, toread) != toread) {\n\n        ff_rtmp_packet_destroy(p);\n\n        return AVERROR(EIO);\n\n    }\n\n    size      -= toread;\n\n    p->read   += toread;\n\n    p->offset += toread;\n\n\n\n    if (size > 0) {\n\n       RTMPPacket *prev = &prev_pkt[channel_id];\n\n       prev->data = p->data;\n\n       prev->read = p->read;\n\n       prev->offset = p->offset;\n\n\n       return AVERROR(EAGAIN);\n\n    }\n\n\n\n    prev_pkt[channel_id].read = 0; // read complete; reset if needed\n\n    return p->read;\n\n}", "idx": 24136}
{"project": "FFmpeg", "commit_id": "92002db3eb437414281ad4fb6e84e34862f7fc92", "target": 1, "func": "int ff_h264_execute_ref_pic_marking(H264Context *h, MMCO *mmco, int mmco_count)\n\n{\n\n    int i, av_uninit(j);\n\n    int current_ref_assigned = 0, err = 0;\n\n    Picture *av_uninit(pic);\n\n\n\n    if ((h->avctx->debug & FF_DEBUG_MMCO) && mmco_count == 0)\n\n        av_log(h->avctx, AV_LOG_DEBUG, \"no mmco here\\n\");\n\n\n\n    for (i = 0; i < mmco_count; i++) {\n\n        int av_uninit(structure), av_uninit(frame_num);\n\n        if (h->avctx->debug & FF_DEBUG_MMCO)\n\n            av_log(h->avctx, AV_LOG_DEBUG, \"mmco:%d %d %d\\n\", h->mmco[i].opcode,\n\n                   h->mmco[i].short_pic_num, h->mmco[i].long_arg);\n\n\n\n        if (mmco[i].opcode == MMCO_SHORT2UNUSED ||\n\n            mmco[i].opcode == MMCO_SHORT2LONG) {\n\n            frame_num = pic_num_extract(h, mmco[i].short_pic_num, &structure);\n\n            pic       = find_short(h, frame_num, &j);\n\n            if (!pic) {\n\n                if (mmco[i].opcode != MMCO_SHORT2LONG ||\n\n                    !h->long_ref[mmco[i].long_arg]    ||\n\n                    h->long_ref[mmco[i].long_arg]->frame_num != frame_num) {\n\n                    av_log(h->avctx, AV_LOG_ERROR, \"mmco: unref short failure\\n\");\n\n                    err = AVERROR_INVALIDDATA;\n\n\n                continue;\n\n\n\n\n\n        switch (mmco[i].opcode) {\n\n        case MMCO_SHORT2UNUSED:\n\n            if (h->avctx->debug & FF_DEBUG_MMCO)\n\n                av_log(h->avctx, AV_LOG_DEBUG, \"mmco: unref short %d count %d\\n\",\n\n                       h->mmco[i].short_pic_num, h->short_ref_count);\n\n            remove_short(h, frame_num, structure ^ PICT_FRAME);\n\n            break;\n\n        case MMCO_SHORT2LONG:\n\n                if (h->long_ref[mmco[i].long_arg] != pic)\n\n                    remove_long(h, mmco[i].long_arg, 0);\n\n\n\n                remove_short_at_index(h, j);\n\n                h->long_ref[ mmco[i].long_arg ] = pic;\n\n                if (h->long_ref[mmco[i].long_arg]) {\n\n                    h->long_ref[mmco[i].long_arg]->long_ref = 1;\n\n                    h->long_ref_count++;\n\n\n            break;\n\n        case MMCO_LONG2UNUSED:\n\n            j   = pic_num_extract(h, mmco[i].long_arg, &structure);\n\n            pic = h->long_ref[j];\n\n            if (pic) {\n\n                remove_long(h, j, structure ^ PICT_FRAME);\n\n            } else if (h->avctx->debug & FF_DEBUG_MMCO)\n\n                av_log(h->avctx, AV_LOG_DEBUG, \"mmco: unref long failure\\n\");\n\n            break;\n\n        case MMCO_LONG:\n\n                    // Comment below left from previous code as it is an interresting note.\n\n                    /* First field in pair is in short term list or\n\n                     * at a different long term index.\n\n                     * This is not allowed; see 7.4.3.3, notes 2 and 3.\n\n                     * Report the problem and keep the pair where it is,\n\n                     * and mark this field valid.\n\n                     */\n\n\n\n            if (h->long_ref[mmco[i].long_arg] != h->cur_pic_ptr) {\n\n                remove_long(h, mmco[i].long_arg, 0);\n\n\n\n\n\n\n                h->long_ref[mmco[i].long_arg]           = h->cur_pic_ptr;\n\n                h->long_ref[mmco[i].long_arg]->long_ref = 1;\n\n                h->long_ref_count++;\n\n\n\n\n            h->cur_pic_ptr->reference |= h->picture_structure;\n\n            current_ref_assigned = 1;\n\n            break;\n\n        case MMCO_SET_MAX_LONG:\n\n            assert(mmco[i].long_arg <= 16);\n\n            // just remove the long term which index is greater than new max\n\n            for (j = mmco[i].long_arg; j < 16; j++) {\n\n                remove_long(h, j, 0);\n\n\n            break;\n\n        case MMCO_RESET:\n\n            while (h->short_ref_count) {\n\n                remove_short(h, h->short_ref[0]->frame_num, 0);\n\n\n            for (j = 0; j < 16; j++) {\n\n                remove_long(h, j, 0);\n\n\n            h->frame_num  = h->cur_pic_ptr->frame_num = 0;\n\n            h->mmco_reset = 1;\n\n            h->cur_pic_ptr->mmco_reset = 1;\n\n            for (j = 0; j < MAX_DELAYED_PIC_COUNT; j++)\n\n                h->last_pocs[j] = INT_MIN;\n\n            break;\n\n        default: assert(0);\n\n\n\n\n\n    if (!current_ref_assigned) {\n\n        /* Second field of complementary field pair; the first field of\n\n         * which is already referenced. If short referenced, it\n\n         * should be first entry in short_ref. If not, it must exist\n\n         * in long_ref; trying to put it on the short list here is an\n\n         * error in the encoded bit stream (ref: 7.4.3.3, NOTE 2 and 3).\n\n         */\n\n        if (h->short_ref_count && h->short_ref[0] == h->cur_pic_ptr) {\n\n            /* Just mark the second field valid */\n\n            h->cur_pic_ptr->reference = PICT_FRAME;\n\n        } else if (h->cur_pic_ptr->long_ref) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"illegal short term reference \"\n\n                                           \"assignment for second field \"\n\n                                           \"in complementary field pair \"\n\n                                           \"(first field is long term)\\n\");\n\n            err = AVERROR_INVALIDDATA;\n\n        } else {\n\n            pic = remove_short(h, h->cur_pic_ptr->frame_num, 0);\n\n            if (pic) {\n\n                av_log(h->avctx, AV_LOG_ERROR, \"illegal short term buffer state detected\\n\");\n\n                err = AVERROR_INVALIDDATA;\n\n\n\n\n            if (h->short_ref_count)\n\n                memmove(&h->short_ref[1], &h->short_ref[0],\n\n                        h->short_ref_count * sizeof(Picture*));\n\n\n\n            h->short_ref[0] = h->cur_pic_ptr;\n\n            h->short_ref_count++;\n\n            h->cur_pic_ptr->reference |= h->picture_structure;\n\n\n\n\n\n    if (h->long_ref_count + h->short_ref_count > FFMAX(h->sps.ref_frame_count, 1)) {\n\n\n\n        /* We have too many reference frames, probably due to corrupted\n\n         * stream. Need to discard one frame. Prevents overrun of the\n\n         * short_ref and long_ref buffers.\n\n         */\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"number of reference frames (%d+%d) exceeds max (%d; probably \"\n\n               \"corrupt input), discarding one\\n\",\n\n               h->long_ref_count, h->short_ref_count, h->sps.ref_frame_count);\n\n        err = AVERROR_INVALIDDATA;\n\n\n\n        if (h->long_ref_count && !h->short_ref_count) {\n\n            for (i = 0; i < 16; ++i)\n\n                if (h->long_ref[i])\n\n                    break;\n\n\n\n            assert(i < 16);\n\n            remove_long(h, i, 0);\n\n        } else {\n\n            pic = h->short_ref[h->short_ref_count - 1];\n\n            remove_short(h, pic->frame_num, 0);\n\n\n\n\n\n    print_short_term(h);\n\n    print_long_term(h);\n\n\n\n    if(err >= 0 && h->long_ref_count==0 && h->short_ref_count<=2 && h->pps.ref_count[0]<=1 + (h->picture_structure != PICT_FRAME) && h->cur_pic_ptr->f.pict_type == AV_PICTURE_TYPE_I){\n\n        h->cur_pic_ptr->sync |= 1;\n\n        if(!h->avctx->has_b_frames)\n\n            h->sync = 2;\n\n\n\n\n    return (h->avctx->err_recognition & AV_EF_EXPLODE) ? err : 0;\n", "idx": 24137}
{"project": "FFmpeg", "commit_id": "eed36075645ecc3d3ef202c94badb66818114c2c", "target": 1, "func": "void *av_tree_insert(AVTreeNode **tp, void *key, int (*cmp)(void *key, const void *b), AVTreeNode **next){\n\n    AVTreeNode *t= *tp;\n\n    if(t){\n\n        unsigned int v= cmp(t->elem, key);\n\n        void *ret;\n\n        if(!v){\n\n            if(*next)\n\n                return t->elem;\n\n            else if(t->child[0]||t->child[1]){\n\n                int i= !t->child[0];\n\n                void *next_elem[2];\n\n                av_tree_find(t->child[i], key, cmp, next_elem);\n\n                key= t->elem= next_elem[i];\n\n                v= -i;\n\n            }else{\n\n                *next= t;\n\n                *tp=NULL;\n\n                return NULL;\n\n            }\n\n        }\n\n        ret= av_tree_insert(&t->child[v>>31], key, cmp, next);\n\n        if(!ret){\n\n            int i= (v>>31) ^ !!*next;\n\n            AVTreeNode **child= &t->child[i];\n\n            t->state += 2*i - 1;\n\n\n\n            if(!(t->state&1)){\n\n                if(t->state){\n\n                    /* The following code is equivalent to\n\n                    if((*child)->state*2 == -t->state)\n\n                        rotate(child, i^1);\n\n                    rotate(tp, i);\n\n\n\n                    with rotate():\n\n                    static void rotate(AVTreeNode **tp, int i){\n\n                        AVTreeNode *t= *tp;\n\n\n\n                        *tp= t->child[i];\n\n                        t->child[i]= t->child[i]->child[i^1];\n\n                        (*tp)->child[i^1]= t;\n\n                        i= 4*t->state + 2*(*tp)->state + 12;\n\n                          t  ->state=                     ((0x614586 >> i) & 3)-1;\n\n                        (*tp)->state= ((*tp)->state>>1) + ((0x400EEA >> i) & 3)-1;\n\n                    }\n\n                    but such a rotate function is both bigger and slower\n\n                    */\n\n                    if((*child)->state*2 == -t->state){\n\n                        *tp= (*child)->child[i^1];\n\n                        (*child)->child[i^1]= (*tp)->child[i];\n\n                        (*tp)->child[i]= *child;\n\n                        *child= (*tp)->child[i^1];\n\n                        (*tp)->child[i^1]= t;\n\n\n\n                        (*tp)->child[0]->state= -((*tp)->state>0);\n\n                        (*tp)->child[1]->state=   (*tp)->state<0 ;\n\n                        (*tp)->state=0;\n\n                    }else{\n\n                        *tp= *child;\n\n                        *child= (*child)->child[i^1];\n\n                        (*tp)->child[i^1]= t;\n\n                        if((*tp)->state) t->state  = 0;\n\n                        else             t->state>>= 1;\n\n                        (*tp)->state= -t->state;\n\n                    }\n\n                }\n\n            }\n\n            if(!(*tp)->state ^ !!*next)\n\n                return key;\n\n        }\n\n        return ret;\n\n    }else{\n\n        *tp= *next; *next= NULL;\n\n        (*tp)->elem= key;\n\n        return NULL;\n\n    }\n\n}\n", "idx": 24139}
{"project": "FFmpeg", "commit_id": "aa13b0fc55f5aec58fce24d1a047271b3e5727f1", "target": 1, "func": "static inline void RENAME(hyscale)(SwsContext *c, uint16_t *dst, long dstWidth, uint8_t *src, int srcW, int xInc,\n\n                                   int flags, int canMMX2BeUsed, int16_t *hLumFilter,\n\n                                   int16_t *hLumFilterPos, int hLumFilterSize, void *funnyYCode,\n\n                                   int srcFormat, uint8_t *formatConvBuffer, int16_t *mmx2Filter,\n\n                                   int32_t *mmx2FilterPos, uint8_t *pal)\n\n{\n\n    if (srcFormat==PIX_FMT_YUYV422 || srcFormat==PIX_FMT_GRAY16BE)\n\n    {\n\n        RENAME(yuy2ToY)(formatConvBuffer, src, srcW);\n\n        src= formatConvBuffer;\n\n    }\n\n    else if (srcFormat==PIX_FMT_UYVY422 || srcFormat==PIX_FMT_GRAY16LE)\n\n    {\n\n        RENAME(uyvyToY)(formatConvBuffer, src, srcW);\n\n        src= formatConvBuffer;\n\n    }\n\n    else if (srcFormat==PIX_FMT_RGB32)\n\n    {\n\n        RENAME(bgr32ToY)(formatConvBuffer, src, srcW);\n\n        src= formatConvBuffer;\n\n    }\n\n    else if (srcFormat==PIX_FMT_RGB32_1)\n\n    {\n\n        RENAME(bgr32ToY)(formatConvBuffer, src+ALT32_CORR, srcW);\n\n        src= formatConvBuffer;\n\n    }\n\n    else if (srcFormat==PIX_FMT_BGR24)\n\n    {\n\n        RENAME(bgr24ToY)(formatConvBuffer, src, srcW);\n\n        src= formatConvBuffer;\n\n    }\n\n    else if (srcFormat==PIX_FMT_BGR565)\n\n    {\n\n        RENAME(bgr16ToY)(formatConvBuffer, src, srcW);\n\n        src= formatConvBuffer;\n\n    }\n\n    else if (srcFormat==PIX_FMT_BGR555)\n\n    {\n\n        RENAME(bgr15ToY)(formatConvBuffer, src, srcW);\n\n        src= formatConvBuffer;\n\n    }\n\n    else if (srcFormat==PIX_FMT_BGR32)\n\n    {\n\n        RENAME(rgb32ToY)(formatConvBuffer, src, srcW);\n\n        src= formatConvBuffer;\n\n    }\n\n    else if (srcFormat==PIX_FMT_BGR32_1)\n\n    {\n\n        RENAME(rgb32ToY)(formatConvBuffer, src+ALT32_CORR, srcW);\n\n        src= formatConvBuffer;\n\n    }\n\n    else if (srcFormat==PIX_FMT_RGB24)\n\n    {\n\n        RENAME(rgb24ToY)(formatConvBuffer, src, srcW);\n\n        src= formatConvBuffer;\n\n    }\n\n    else if (srcFormat==PIX_FMT_RGB565)\n\n    {\n\n        RENAME(rgb16ToY)(formatConvBuffer, src, srcW);\n\n        src= formatConvBuffer;\n\n    }\n\n    else if (srcFormat==PIX_FMT_RGB555)\n\n    {\n\n        RENAME(rgb15ToY)(formatConvBuffer, src, srcW);\n\n        src= formatConvBuffer;\n\n    }\n\n    else if (srcFormat==PIX_FMT_RGB8 || srcFormat==PIX_FMT_BGR8 || srcFormat==PIX_FMT_PAL8 || srcFormat==PIX_FMT_BGR4_BYTE  || srcFormat==PIX_FMT_RGB4_BYTE)\n\n    {\n\n        RENAME(palToY)(formatConvBuffer, src, srcW, (uint32_t*)pal);\n\n        src= formatConvBuffer;\n\n    }\n\n\n\n#ifdef HAVE_MMX\n\n    // Use the new MMX scaler if the MMX2 one can't be used (it is faster than the x86 ASM one).\n\n    if (!(flags&SWS_FAST_BILINEAR) || (!canMMX2BeUsed))\n\n#else\n\n    if (!(flags&SWS_FAST_BILINEAR))\n\n#endif\n\n    {\n\n        RENAME(hScale)(dst, dstWidth, src, srcW, xInc, hLumFilter, hLumFilterPos, hLumFilterSize);\n\n    }\n\n    else // fast bilinear upscale / crap downscale\n\n    {\n\n#if defined(ARCH_X86)\n\n#ifdef HAVE_MMX2\n\n        int i;\n\n#if defined(PIC)\n\n        uint64_t ebxsave __attribute__((aligned(8)));\n\n#endif\n\n        if (canMMX2BeUsed)\n\n        {\n\n            asm volatile(\n\n#if defined(PIC)\n\n            \"mov               %%\"REG_b\", %5        \\n\\t\"\n\n#endif\n\n            \"pxor                  %%mm7, %%mm7     \\n\\t\"\n\n            \"mov                      %0, %%\"REG_c\" \\n\\t\"\n\n            \"mov                      %1, %%\"REG_D\" \\n\\t\"\n\n            \"mov                      %2, %%\"REG_d\" \\n\\t\"\n\n            \"mov                      %3, %%\"REG_b\" \\n\\t\"\n\n            \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\" // i\n\n            PREFETCH\"        (%%\"REG_c\")            \\n\\t\"\n\n            PREFETCH\"      32(%%\"REG_c\")            \\n\\t\"\n\n            PREFETCH\"      64(%%\"REG_c\")            \\n\\t\"\n\n\n\n#ifdef ARCH_X86_64\n\n\n\n#define FUNNY_Y_CODE \\\n\n            \"movl            (%%\"REG_b\"), %%esi     \\n\\t\"\\\n\n            \"call                    *%4            \\n\\t\"\\\n\n            \"movl (%%\"REG_b\", %%\"REG_a\"), %%esi     \\n\\t\"\\\n\n            \"add               %%\"REG_S\", %%\"REG_c\" \\n\\t\"\\\n\n            \"add               %%\"REG_a\", %%\"REG_D\" \\n\\t\"\\\n\n            \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\"\\\n\n\n\n#else\n\n\n\n#define FUNNY_Y_CODE \\\n\n            \"movl (%%\"REG_b\"), %%esi        \\n\\t\"\\\n\n            \"call         *%4                       \\n\\t\"\\\n\n            \"addl (%%\"REG_b\", %%\"REG_a\"), %%\"REG_c\" \\n\\t\"\\\n\n            \"add               %%\"REG_a\", %%\"REG_D\" \\n\\t\"\\\n\n            \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\"\\\n\n\n\n#endif /* ARCH_X86_64 */\n\n\n\nFUNNY_Y_CODE\n\nFUNNY_Y_CODE\n\nFUNNY_Y_CODE\n\nFUNNY_Y_CODE\n\nFUNNY_Y_CODE\n\nFUNNY_Y_CODE\n\nFUNNY_Y_CODE\n\nFUNNY_Y_CODE\n\n\n\n#if defined(PIC)\n\n            \"mov                      %5, %%\"REG_b\" \\n\\t\"\n\n#endif\n\n            :: \"m\" (src), \"m\" (dst), \"m\" (mmx2Filter), \"m\" (mmx2FilterPos),\n\n            \"m\" (funnyYCode)\n\n#if defined(PIC)\n\n            ,\"m\" (ebxsave)\n\n#endif\n\n            : \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S, \"%\"REG_D\n\n#if !defined(PIC)\n\n            ,\"%\"REG_b\n\n#endif\n\n            );\n\n            for (i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--) dst[i] = src[srcW-1]*128;\n\n        }\n\n        else\n\n        {\n\n#endif /* HAVE_MMX2 */\n\n        long xInc_shr16 = xInc >> 16;\n\n        uint16_t xInc_mask = xInc & 0xffff;\n\n        //NO MMX just normal asm ...\n\n        asm volatile(\n\n        \"xor %%\"REG_a\", %%\"REG_a\"            \\n\\t\" // i\n\n        \"xor %%\"REG_d\", %%\"REG_d\"            \\n\\t\" // xx\n\n        \"xorl    %%ecx, %%ecx                \\n\\t\" // 2*xalpha\n\n        ASMALIGN(4)\n\n        \"1:                                  \\n\\t\"\n\n        \"movzbl    (%0, %%\"REG_d\"), %%edi    \\n\\t\" //src[xx]\n\n        \"movzbl   1(%0, %%\"REG_d\"), %%esi    \\n\\t\" //src[xx+1]\n\n        \"subl    %%edi, %%esi                \\n\\t\" //src[xx+1] - src[xx]\n\n        \"imull   %%ecx, %%esi                \\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n        \"shll      $16, %%edi                \\n\\t\"\n\n        \"addl    %%edi, %%esi                \\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n        \"mov        %1, %%\"REG_D\"            \\n\\t\"\n\n        \"shrl       $9, %%esi                \\n\\t\"\n\n        \"movw     %%si, (%%\"REG_D\", %%\"REG_a\", 2)   \\n\\t\"\n\n        \"addw       %4, %%cx                 \\n\\t\" //2*xalpha += xInc&0xFF\n\n        \"adc        %3, %%\"REG_d\"            \\n\\t\" //xx+= xInc>>8 + carry\n\n\n\n        \"movzbl    (%0, %%\"REG_d\"), %%edi    \\n\\t\" //src[xx]\n\n        \"movzbl   1(%0, %%\"REG_d\"), %%esi    \\n\\t\" //src[xx+1]\n\n        \"subl    %%edi, %%esi                \\n\\t\" //src[xx+1] - src[xx]\n\n        \"imull   %%ecx, %%esi                \\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n        \"shll      $16, %%edi                \\n\\t\"\n\n        \"addl    %%edi, %%esi                \\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n        \"mov        %1, %%\"REG_D\"            \\n\\t\"\n\n        \"shrl       $9, %%esi                \\n\\t\"\n\n        \"movw     %%si, 2(%%\"REG_D\", %%\"REG_a\", 2)  \\n\\t\"\n\n        \"addw       %4, %%cx                 \\n\\t\" //2*xalpha += xInc&0xFF\n\n        \"adc        %3, %%\"REG_d\"            \\n\\t\" //xx+= xInc>>8 + carry\n\n\n\n\n\n        \"add        $2, %%\"REG_a\"            \\n\\t\"\n\n        \"cmp        %2, %%\"REG_a\"            \\n\\t\"\n\n        \" jb        1b                       \\n\\t\"\n\n\n\n\n\n        :: \"r\" (src), \"m\" (dst), \"m\" (dstWidth), \"m\" (xInc_shr16), \"m\" (xInc_mask)\n\n        : \"%\"REG_a, \"%\"REG_d, \"%ecx\", \"%\"REG_D, \"%esi\"\n\n        );\n\n#ifdef HAVE_MMX2\n\n        } //if MMX2 can't be used\n\n#endif\n\n#else\n\n        int i;\n\n        unsigned int xpos=0;\n\n        for (i=0;i<dstWidth;i++)\n\n        {\n\n            register unsigned int xx=xpos>>16;\n\n            register unsigned int xalpha=(xpos&0xFFFF)>>9;\n\n            dst[i]= (src[xx]<<7) + (src[xx+1] - src[xx])*xalpha;\n\n            xpos+=xInc;\n\n        }\n\n#endif /* defined(ARCH_X86) */\n\n    }\n\n\n\n    if(c->srcRange != c->dstRange && !(isRGB(c->dstFormat) || isBGR(c->dstFormat))){\n\n        int i;\n\n        //FIXME all pal and rgb srcFormats could do this convertion as well\n\n        //FIXME all scalers more complex than bilinear could do half of this transform\n\n        if(c->srcRange){\n\n            for (i=0; i<dstWidth; i++)\n\n                dst[i]= (dst[i]*14071 + 33561947)>>14;\n\n        }else{\n\n            for (i=0; i<dstWidth; i++)\n\n                dst[i]= (dst[i]*19077 - 39057361)>>14;\n\n        }\n\n    }\n\n}\n", "idx": 24142}
{"project": "FFmpeg", "commit_id": "b79c3df08807c96a945d9cea21c5d923c464d622", "target": 1, "func": "static int applehttp_read_header(AVFormatContext *s, AVFormatParameters *ap)\n\n{\n\n    AppleHTTPContext *c = s->priv_data;\n\n    int ret = 0, i, j, stream_offset = 0;\n\n\n\n    if ((ret = parse_playlist(c, s->filename, NULL, s->pb)) < 0)\n\n        goto fail;\n\n\n\n    if (c->n_variants == 0) {\n\n        av_log(NULL, AV_LOG_WARNING, \"Empty playlist\\n\");\n\n        ret = AVERROR_EOF;\n\n        goto fail;\n\n    }\n\n    /* If the playlist only contained variants, parse each individual\n\n     * variant playlist. */\n\n    if (c->n_variants > 1 || c->variants[0]->n_segments == 0) {\n\n        for (i = 0; i < c->n_variants; i++) {\n\n            struct variant *v = c->variants[i];\n\n            if ((ret = parse_playlist(c, v->url, v, NULL)) < 0)\n\n                goto fail;\n\n        }\n\n    }\n\n\n\n    if (c->variants[0]->n_segments == 0) {\n\n        av_log(NULL, AV_LOG_WARNING, \"Empty playlist\\n\");\n\n        ret = AVERROR_EOF;\n\n        goto fail;\n\n    }\n\n\n\n    /* If this isn't a live stream, calculate the total duration of the\n\n     * stream. */\n\n    if (c->finished) {\n\n        int duration = 0;\n\n        for (i = 0; i < c->variants[0]->n_segments; i++)\n\n            duration += c->variants[0]->segments[i]->duration;\n\n        s->duration = duration * AV_TIME_BASE;\n\n    }\n\n\n\n    c->min_end_seq = INT_MAX;\n\n    /* Open the demuxer for each variant */\n\n    for (i = 0; i < c->n_variants; i++) {\n\n        struct variant *v = c->variants[i];\n\n        if (v->n_segments == 0)\n\n            continue;\n\n        c->max_start_seq = FFMAX(c->max_start_seq, v->start_seq_no);\n\n        c->min_end_seq   = FFMIN(c->min_end_seq,   v->start_seq_no +\n\n                                                   v->n_segments);\n\n        ret = av_open_input_file(&v->ctx, v->segments[0]->url, NULL, 0, NULL);\n\n        if (ret < 0)\n\n            goto fail;\n\n        url_fclose(v->ctx->pb);\n\n        v->ctx->pb = NULL;\n\n        v->stream_offset = stream_offset;\n\n        /* Create new AVStreams for each stream in this variant */\n\n        for (j = 0; j < v->ctx->nb_streams; j++) {\n\n            AVStream *st = av_new_stream(s, i);\n\n            if (!st) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto fail;\n\n            }\n\n            avcodec_copy_context(st->codec, v->ctx->streams[j]->codec);\n\n        }\n\n        stream_offset += v->ctx->nb_streams;\n\n    }\n\n    c->last_packet_dts = AV_NOPTS_VALUE;\n\n\n\n    c->cur_seq_no = c->max_start_seq;\n\n    /* If this is a live stream with more than 3 segments, start at the\n\n     * third last segment. */\n\n    if (!c->finished && c->min_end_seq - c->max_start_seq > 3)\n\n        c->cur_seq_no = c->min_end_seq - 2;\n\n\n\n    return 0;\n\nfail:\n\n    free_variant_list(c);\n\n    return ret;\n\n}\n", "idx": 24143}
{"project": "FFmpeg", "commit_id": "82d705e245050c1040321022e200969f9c3ff9c3", "target": 1, "func": "static int nvenc_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n\n    const AVFrame *frame, int *got_packet)\n\n{\n\n    NVENCSTATUS nv_status;\n\n    NvencOutputSurface *tmpoutsurf;\n\n    int res, i = 0;\n\n\n\n    NvencContext *ctx = avctx->priv_data;\n\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n\n\n\n    NV_ENC_PIC_PARAMS pic_params = { 0 };\n\n    pic_params.version = NV_ENC_PIC_PARAMS_VER;\n\n\n\n    if (frame) {\n\n        NV_ENC_LOCK_INPUT_BUFFER lockBufferParams = { 0 };\n\n        NvencInputSurface *inSurf = NULL;\n\n\n\n        for (i = 0; i < ctx->max_surface_count; ++i) {\n\n            if (!ctx->input_surfaces[i].lockCount) {\n\n                inSurf = &ctx->input_surfaces[i];\n\n                break;\n\n            }\n\n        }\n\n\n\n        av_assert0(inSurf);\n\n\n\n        inSurf->lockCount = 1;\n\n\n\n        lockBufferParams.version = NV_ENC_LOCK_INPUT_BUFFER_VER;\n\n        lockBufferParams.inputBuffer = inSurf->input_surface;\n\n\n\n        nv_status = p_nvenc->nvEncLockInputBuffer(ctx->nvencoder, &lockBufferParams);\n\n        if (nv_status != NV_ENC_SUCCESS) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Failed locking nvenc input buffer\\n\");\n\n            return 0;\n\n        }\n\n\n\n        if (avctx->pix_fmt == AV_PIX_FMT_YUV420P) {\n\n            uint8_t *buf = lockBufferParams.bufferDataPtr;\n\n\n\n            av_image_copy_plane(buf, lockBufferParams.pitch,\n\n                frame->data[0], frame->linesize[0],\n\n                avctx->width, avctx->height);\n\n\n\n            buf += inSurf->height * lockBufferParams.pitch;\n\n\n\n            av_image_copy_plane(buf, lockBufferParams.pitch >> 1,\n\n                frame->data[2], frame->linesize[2],\n\n                avctx->width >> 1, avctx->height >> 1);\n\n\n\n            buf += (inSurf->height * lockBufferParams.pitch) >> 2;\n\n\n\n            av_image_copy_plane(buf, lockBufferParams.pitch >> 1,\n\n                frame->data[1], frame->linesize[1],\n\n                avctx->width >> 1, avctx->height >> 1);\n\n        } else if (avctx->pix_fmt == AV_PIX_FMT_NV12) {\n\n            uint8_t *buf = lockBufferParams.bufferDataPtr;\n\n\n\n            av_image_copy_plane(buf, lockBufferParams.pitch,\n\n                frame->data[0], frame->linesize[0],\n\n                avctx->width, avctx->height);\n\n\n\n            buf += inSurf->height * lockBufferParams.pitch;\n\n\n\n            av_image_copy_plane(buf, lockBufferParams.pitch,\n\n                frame->data[1], frame->linesize[1],\n\n                avctx->width, avctx->height >> 1);\n\n        } else if (avctx->pix_fmt == AV_PIX_FMT_YUV444P) {\n\n            uint8_t *buf = lockBufferParams.bufferDataPtr;\n\n\n\n            av_image_copy_plane(buf, lockBufferParams.pitch,\n\n                frame->data[0], frame->linesize[0],\n\n                avctx->width, avctx->height);\n\n\n\n            buf += inSurf->height * lockBufferParams.pitch;\n\n\n\n            av_image_copy_plane(buf, lockBufferParams.pitch,\n\n                frame->data[1], frame->linesize[1],\n\n                avctx->width, avctx->height);\n\n\n\n            buf += inSurf->height * lockBufferParams.pitch;\n\n\n\n            av_image_copy_plane(buf, lockBufferParams.pitch,\n\n                frame->data[2], frame->linesize[2],\n\n                avctx->width, avctx->height);\n\n        } else {\n\n            av_log(avctx, AV_LOG_FATAL, \"Invalid pixel format!\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n\n\n        nv_status = p_nvenc->nvEncUnlockInputBuffer(ctx->nvencoder, inSurf->input_surface);\n\n        if (nv_status != NV_ENC_SUCCESS) {\n\n            av_log(avctx, AV_LOG_FATAL, \"Failed unlocking input buffer!\\n\");\n\n            return AVERROR_EXTERNAL;\n\n        }\n\n\n\n        for (i = 0; i < ctx->max_surface_count; ++i)\n\n            if (!ctx->output_surfaces[i].busy)\n\n                break;\n\n\n\n        if (i == ctx->max_surface_count) {\n\n            inSurf->lockCount = 0;\n\n            av_log(avctx, AV_LOG_FATAL, \"No free output surface found!\\n\");\n\n            return AVERROR_EXTERNAL;\n\n        }\n\n\n\n        ctx->output_surfaces[i].input_surface = inSurf;\n\n\n\n        pic_params.inputBuffer = inSurf->input_surface;\n\n        pic_params.bufferFmt = inSurf->format;\n\n        pic_params.inputWidth = avctx->width;\n\n        pic_params.inputHeight = avctx->height;\n\n        pic_params.outputBitstream = ctx->output_surfaces[i].output_surface;\n\n        pic_params.completionEvent = 0;\n\n\n\n        if (avctx->flags & AV_CODEC_FLAG_INTERLACED_DCT) {\n\n            if (frame->top_field_first) {\n\n                pic_params.pictureStruct = NV_ENC_PIC_STRUCT_FIELD_TOP_BOTTOM;\n\n            } else {\n\n                pic_params.pictureStruct = NV_ENC_PIC_STRUCT_FIELD_BOTTOM_TOP;\n\n            }\n\n        } else {\n\n            pic_params.pictureStruct = NV_ENC_PIC_STRUCT_FRAME;\n\n        }\n\n\n\n        pic_params.encodePicFlags = 0;\n\n        pic_params.inputTimeStamp = frame->pts;\n\n        pic_params.inputDuration = 0;\n\n        switch (avctx->codec->id) {\n\n        case AV_CODEC_ID_H264:\n\n          pic_params.codecPicParams.h264PicParams.sliceMode = ctx->encode_config.encodeCodecConfig.h264Config.sliceMode;\n\n          pic_params.codecPicParams.h264PicParams.sliceModeData = ctx->encode_config.encodeCodecConfig.h264Config.sliceModeData;\n\n          break;\n\n        case AV_CODEC_ID_H265:\n\n          pic_params.codecPicParams.hevcPicParams.sliceMode = ctx->encode_config.encodeCodecConfig.hevcConfig.sliceMode;\n\n          pic_params.codecPicParams.hevcPicParams.sliceModeData = ctx->encode_config.encodeCodecConfig.hevcConfig.sliceModeData;\n\n          break;\n\n        default:\n\n          av_log(avctx, AV_LOG_ERROR, \"Unknown codec name\\n\");\n\n          return AVERROR(EINVAL);\n\n        }\n\n\n\n        res = timestamp_queue_enqueue(&ctx->timestamp_list, frame->pts);\n\n\n\n        if (res)\n\n            return res;\n\n    } else {\n\n        pic_params.encodePicFlags = NV_ENC_PIC_FLAG_EOS;\n\n    }\n\n\n\n    nv_status = p_nvenc->nvEncEncodePicture(ctx->nvencoder, &pic_params);\n\n\n\n    if (frame && nv_status == NV_ENC_ERR_NEED_MORE_INPUT) {\n\n        res = out_surf_queue_enqueue(&ctx->output_surface_queue, &ctx->output_surfaces[i]);\n\n\n\n        if (res)\n\n            return res;\n\n\n\n        ctx->output_surfaces[i].busy = 1;\n\n    }\n\n\n\n    if (nv_status != NV_ENC_SUCCESS && nv_status != NV_ENC_ERR_NEED_MORE_INPUT) {\n\n        av_log(avctx, AV_LOG_ERROR, \"EncodePicture failed!\\n\");\n\n        return AVERROR_EXTERNAL;\n\n    }\n\n\n\n    if (nv_status != NV_ENC_ERR_NEED_MORE_INPUT) {\n\n        while (ctx->output_surface_queue.count) {\n\n            tmpoutsurf = out_surf_queue_dequeue(&ctx->output_surface_queue);\n\n            res = out_surf_queue_enqueue(&ctx->output_surface_ready_queue, tmpoutsurf);\n\n\n\n            if (res)\n\n                return res;\n\n        }\n\n\n\n        if (frame) {\n\n            res = out_surf_queue_enqueue(&ctx->output_surface_ready_queue, &ctx->output_surfaces[i]);\n\n\n\n            if (res)\n\n                return res;\n\n\n\n            ctx->output_surfaces[i].busy = 1;\n\n        }\n\n    }\n\n\n\n    if (ctx->output_surface_ready_queue.count && (!frame || ctx->output_surface_ready_queue.count + ctx->output_surface_queue.count >= ctx->buffer_delay)) {\n\n        tmpoutsurf = out_surf_queue_dequeue(&ctx->output_surface_ready_queue);\n\n\n\n        res = process_output_surface(avctx, pkt, tmpoutsurf);\n\n\n\n        if (res)\n\n            return res;\n\n\n\n        tmpoutsurf->busy = 0;\n\n        av_assert0(tmpoutsurf->input_surface->lockCount);\n\n        tmpoutsurf->input_surface->lockCount--;\n\n\n\n        *got_packet = 1;\n\n    } else {\n\n        *got_packet = 0;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24144}
{"project": "FFmpeg", "commit_id": "6a63ff19b6a7fe3bc32c7fb4a62fca8f65786432", "target": 0, "func": "static int mov_read_glbl(MOVContext *c, ByteIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st = c->fc->streams[c->fc->nb_streams-1];\n\n\n\n    if((uint64_t)atom.size > (1<<30))\n\n        return -1;\n\n\n\n    av_free(st->codec->extradata);\n\n    st->codec->extradata = av_mallocz(atom.size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    if (!st->codec->extradata)\n\n        return AVERROR(ENOMEM);\n\n    st->codec->extradata_size = atom.size;\n\n    get_buffer(pb, st->codec->extradata, atom.size);\n\n    return 0;\n\n}\n", "idx": 24145}
{"project": "FFmpeg", "commit_id": "465e1dadbef7596a3eb87089a66bb4ecdc26d3c4", "target": 0, "func": "static uint64_t find_any_startcode(ByteIOContext *bc, int64_t pos){\n\n    uint64_t state=0;\n\n    \n\n    if(pos >= 0)\n\n        url_fseek(bc, pos, SEEK_SET); //note, this may fail if the stream isnt seekable, but that shouldnt matter, as in this case we simply start where we are currently\n\n\n\n    while(bytes_left(bc)){\n\n        state= (state<<8) | get_byte(bc);\n\n        if((state>>56) != 'N')\n\n            continue;\n\n        switch(state){\n\n        case MAIN_STARTCODE:\n\n        case STREAM_STARTCODE:\n\n        case KEYFRAME_STARTCODE:\n\n        case INFO_STARTCODE:\n\n        case INDEX_STARTCODE:\n\n            return state;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 24146}
{"project": "FFmpeg", "commit_id": "b164d66e35d349de414e2f0d7365a147aba8a620", "target": 0, "func": "static void ape_unpack_stereo(APEContext *ctx, int count)\n\n{\n\n    int32_t left, right;\n\n    int32_t *decoded0 = ctx->decoded[0];\n\n    int32_t *decoded1 = ctx->decoded[1];\n\n\n\n    if (ctx->frameflags & APE_FRAMECODE_STEREO_SILENCE) {\n\n        /* We are pure silence, so we're done. */\n\n        av_log(ctx->avctx, AV_LOG_DEBUG, \"pure silence stereo\\n\");\n\n        return;\n\n    }\n\n\n\n    entropy_decode(ctx, count, 1);\n\n    ape_apply_filters(ctx, decoded0, decoded1, count);\n\n\n\n    /* Now apply the predictor decoding */\n\n    predictor_decode_stereo(ctx, count);\n\n\n\n    /* Decorrelate and scale to output depth */\n\n    while (count--) {\n\n        left = *decoded1 - (*decoded0 / 2);\n\n        right = left + *decoded0;\n\n\n\n        *(decoded0++) = left;\n\n        *(decoded1++) = right;\n\n    }\n\n}\n", "idx": 24147}
{"project": "FFmpeg", "commit_id": "70f9661542a581dfe93b636b1c55b5558e4a4e3c", "target": 0, "func": "static int jpeg2000_decode_frame(AVCodecContext *avctx, void *data,\n\n                                 int *got_frame, AVPacket *avpkt)\n\n{\n\n    Jpeg2000DecoderContext *s = avctx->priv_data;\n\n    ThreadFrame frame = { .f = data };\n\n    AVFrame *picture = data;\n\n    int tileno, ret;\n\n\n\n    s->avctx     = avctx;\n\n    s->buf       = s->buf_start = avpkt->data;\n\n    s->buf_end   = s->buf_start + avpkt->size;\n\n    s->curtileno = 0; // TODO: only one tile in DCI JP2K. to implement for more tiles\n\n\n\n    // reduction factor, i.e number of resolution levels to skip\n\n    s->reduction_factor = s->lowres;\n\n\n\n    ff_jpeg2000_init_tier1_luts();\n\n\n\n    if (s->buf_end - s->buf < 2)\n\n        return AVERROR(EINVAL);\n\n\n\n    // check if the image is in jp2 format\n\n    if ((AV_RB32(s->buf) == 12) &&\n\n        (AV_RB32(s->buf + 4) == JP2_SIG_TYPE) &&\n\n        (AV_RB32(s->buf + 8) == JP2_SIG_VALUE)) {\n\n        if (!jp2_find_codestream(s)) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"couldn't find jpeg2k codestream atom\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    if (bytestream_get_be16(&s->buf) != JPEG2000_SOC) {\n\n        av_log(avctx, AV_LOG_ERROR, \"SOC marker not present\\n\");\n\n        return -1;\n\n    }\n\n    if (ret = jpeg2000_read_main_headers(s))\n\n        goto end;\n\n\n\n    /* get picture buffer */\n\n    if ((ret = ff_thread_get_buffer(avctx, &frame, 0)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"ff_thread_get_buffer() failed.\\n\");\n\n        goto end;\n\n    }\n\n    picture->pict_type = AV_PICTURE_TYPE_I;\n\n    picture->key_frame = 1;\n\n\n\n    if (ret = jpeg2000_read_bitstream_packets(s))\n\n        goto end;\n\n    for (tileno = 0; tileno < s->numXtiles * s->numYtiles; tileno++)\n\n        if (ret = jpeg2000_decode_tile(s, s->tile + tileno, picture))\n\n            goto end;\n\n\n\n    *got_frame = 1;\n\n\n\nend:\n\n    jpeg2000_dec_cleanup(s);\n\n    return ret ? ret : s->buf - s->buf_start;\n\n}\n", "idx": 24148}
{"project": "FFmpeg", "commit_id": "a057ef6923fba7947d8ccf27b751bf91fde3a755", "target": 0, "func": "static int mp_decode_layer3(MPADecodeContext *s)\n\n{\n\n    int nb_granules, main_data_begin;\n\n    int gr, ch, blocksplit_flag, i, j, k, n, bits_pos;\n\n    GranuleDef *g;\n\n    int16_t exponents[576]; //FIXME try INTFLOAT\n\n\n\n    /* read side info */\n\n    if (s->lsf) {\n\n        main_data_begin = get_bits(&s->gb, 8);\n\n        skip_bits(&s->gb, s->nb_channels);\n\n        nb_granules = 1;\n\n    } else {\n\n        main_data_begin = get_bits(&s->gb, 9);\n\n        if (s->nb_channels == 2)\n\n            skip_bits(&s->gb, 3);\n\n        else\n\n            skip_bits(&s->gb, 5);\n\n        nb_granules = 2;\n\n        for (ch = 0; ch < s->nb_channels; ch++) {\n\n            s->granules[ch][0].scfsi = 0;/* all scale factors are transmitted */\n\n            s->granules[ch][1].scfsi = get_bits(&s->gb, 4);\n\n        }\n\n    }\n\n\n\n    for (gr = 0; gr < nb_granules; gr++) {\n\n        for (ch = 0; ch < s->nb_channels; ch++) {\n\n            av_dlog(s->avctx, \"gr=%d ch=%d: side_info\\n\", gr, ch);\n\n            g = &s->granules[ch][gr];\n\n            g->part2_3_length = get_bits(&s->gb, 12);\n\n            g->big_values     = get_bits(&s->gb,  9);\n\n            if (g->big_values > 288) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"big_values too big\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            g->global_gain = get_bits(&s->gb, 8);\n\n            /* if MS stereo only is selected, we precompute the\n\n               1/sqrt(2) renormalization factor */\n\n            if ((s->mode_ext & (MODE_EXT_MS_STEREO | MODE_EXT_I_STEREO)) ==\n\n                MODE_EXT_MS_STEREO)\n\n                g->global_gain -= 2;\n\n            if (s->lsf)\n\n                g->scalefac_compress = get_bits(&s->gb, 9);\n\n            else\n\n                g->scalefac_compress = get_bits(&s->gb, 4);\n\n            blocksplit_flag = get_bits1(&s->gb);\n\n            if (blocksplit_flag) {\n\n                g->block_type = get_bits(&s->gb, 2);\n\n                if (g->block_type == 0) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"invalid block type\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                g->switch_point = get_bits1(&s->gb);\n\n                for (i = 0; i < 2; i++)\n\n                    g->table_select[i] = get_bits(&s->gb, 5);\n\n                for (i = 0; i < 3; i++)\n\n                    g->subblock_gain[i] = get_bits(&s->gb, 3);\n\n                ff_init_short_region(s, g);\n\n            } else {\n\n                int region_address1, region_address2;\n\n                g->block_type = 0;\n\n                g->switch_point = 0;\n\n                for (i = 0; i < 3; i++)\n\n                    g->table_select[i] = get_bits(&s->gb, 5);\n\n                /* compute huffman coded region sizes */\n\n                region_address1 = get_bits(&s->gb, 4);\n\n                region_address2 = get_bits(&s->gb, 3);\n\n                av_dlog(s->avctx, \"region1=%d region2=%d\\n\",\n\n                        region_address1, region_address2);\n\n                ff_init_long_region(s, g, region_address1, region_address2);\n\n            }\n\n            ff_region_offset2size(g);\n\n            ff_compute_band_indexes(s, g);\n\n\n\n            g->preflag = 0;\n\n            if (!s->lsf)\n\n                g->preflag = get_bits1(&s->gb);\n\n            g->scalefac_scale     = get_bits1(&s->gb);\n\n            g->count1table_select = get_bits1(&s->gb);\n\n            av_dlog(s->avctx, \"block_type=%d switch_point=%d\\n\",\n\n                    g->block_type, g->switch_point);\n\n        }\n\n    }\n\n\n\n    if (!s->adu_mode) {\n\n        const uint8_t *ptr = s->gb.buffer + (get_bits_count(&s->gb)>>3);\n\n        int extrasize = av_clip(get_bits_left(&s->gb) >> 3, 0, EXTRABYTES);\n\n        assert((get_bits_count(&s->gb) & 7) == 0);\n\n        /* now we get bits from the main_data_begin offset */\n\n        av_dlog(s->avctx, \"seekback: %d\\n\", main_data_begin);\n\n    //av_log(NULL, AV_LOG_ERROR, \"backstep:%d, lastbuf:%d\\n\", main_data_begin, s->last_buf_size);\n\n\n\n        memcpy(s->last_buf + s->last_buf_size, ptr, extrasize);\n\n        s->in_gb = s->gb;\n\n        init_get_bits(&s->gb, s->last_buf, s->last_buf_size*8);\n\n#if !UNCHECKED_BITSTREAM_READER\n\n        s->gb.size_in_bits_plus8 += FFMAX(extrasize, LAST_BUF_SIZE - s->last_buf_size) * 8;\n\n#endif\n\n        skip_bits_long(&s->gb, 8*(s->last_buf_size - main_data_begin));\n\n    }\n\n\n\n    for (gr = 0; gr < nb_granules; gr++) {\n\n        for (ch = 0; ch < s->nb_channels; ch++) {\n\n            g = &s->granules[ch][gr];\n\n            if (get_bits_count(&s->gb) < 0) {\n\n                av_log(s->avctx, AV_LOG_DEBUG, \"mdb:%d, lastbuf:%d skipping granule %d\\n\",\n\n                       main_data_begin, s->last_buf_size, gr);\n\n                skip_bits_long(&s->gb, g->part2_3_length);\n\n                memset(g->sb_hybrid, 0, sizeof(g->sb_hybrid));\n\n                if (get_bits_count(&s->gb) >= s->gb.size_in_bits && s->in_gb.buffer) {\n\n                    skip_bits_long(&s->in_gb, get_bits_count(&s->gb) - s->gb.size_in_bits);\n\n                    s->gb           = s->in_gb;\n\n                    s->in_gb.buffer = NULL;\n\n                }\n\n                continue;\n\n            }\n\n\n\n            bits_pos = get_bits_count(&s->gb);\n\n\n\n            if (!s->lsf) {\n\n                uint8_t *sc;\n\n                int slen, slen1, slen2;\n\n\n\n                /* MPEG1 scale factors */\n\n                slen1 = slen_table[0][g->scalefac_compress];\n\n                slen2 = slen_table[1][g->scalefac_compress];\n\n                av_dlog(s->avctx, \"slen1=%d slen2=%d\\n\", slen1, slen2);\n\n                if (g->block_type == 2) {\n\n                    n = g->switch_point ? 17 : 18;\n\n                    j = 0;\n\n                    if (slen1) {\n\n                        for (i = 0; i < n; i++)\n\n                            g->scale_factors[j++] = get_bits(&s->gb, slen1);\n\n                    } else {\n\n                        for (i = 0; i < n; i++)\n\n                            g->scale_factors[j++] = 0;\n\n                    }\n\n                    if (slen2) {\n\n                        for (i = 0; i < 18; i++)\n\n                            g->scale_factors[j++] = get_bits(&s->gb, slen2);\n\n                        for (i = 0; i < 3; i++)\n\n                            g->scale_factors[j++] = 0;\n\n                    } else {\n\n                        for (i = 0; i < 21; i++)\n\n                            g->scale_factors[j++] = 0;\n\n                    }\n\n                } else {\n\n                    sc = s->granules[ch][0].scale_factors;\n\n                    j = 0;\n\n                    for (k = 0; k < 4; k++) {\n\n                        n = k == 0 ? 6 : 5;\n\n                        if ((g->scfsi & (0x8 >> k)) == 0) {\n\n                            slen = (k < 2) ? slen1 : slen2;\n\n                            if (slen) {\n\n                                for (i = 0; i < n; i++)\n\n                                    g->scale_factors[j++] = get_bits(&s->gb, slen);\n\n                            } else {\n\n                                for (i = 0; i < n; i++)\n\n                                    g->scale_factors[j++] = 0;\n\n                            }\n\n                        } else {\n\n                            /* simply copy from last granule */\n\n                            for (i = 0; i < n; i++) {\n\n                                g->scale_factors[j] = sc[j];\n\n                                j++;\n\n                            }\n\n                        }\n\n                    }\n\n                    g->scale_factors[j++] = 0;\n\n                }\n\n            } else {\n\n                int tindex, tindex2, slen[4], sl, sf;\n\n\n\n                /* LSF scale factors */\n\n                if (g->block_type == 2)\n\n                    tindex = g->switch_point ? 2 : 1;\n\n                else\n\n                    tindex = 0;\n\n\n\n                sf = g->scalefac_compress;\n\n                if ((s->mode_ext & MODE_EXT_I_STEREO) && ch == 1) {\n\n                    /* intensity stereo case */\n\n                    sf >>= 1;\n\n                    if (sf < 180) {\n\n                        lsf_sf_expand(slen, sf, 6, 6, 0);\n\n                        tindex2 = 3;\n\n                    } else if (sf < 244) {\n\n                        lsf_sf_expand(slen, sf - 180, 4, 4, 0);\n\n                        tindex2 = 4;\n\n                    } else {\n\n                        lsf_sf_expand(slen, sf - 244, 3, 0, 0);\n\n                        tindex2 = 5;\n\n                    }\n\n                } else {\n\n                    /* normal case */\n\n                    if (sf < 400) {\n\n                        lsf_sf_expand(slen, sf, 5, 4, 4);\n\n                        tindex2 = 0;\n\n                    } else if (sf < 500) {\n\n                        lsf_sf_expand(slen, sf - 400, 5, 4, 0);\n\n                        tindex2 = 1;\n\n                    } else {\n\n                        lsf_sf_expand(slen, sf - 500, 3, 0, 0);\n\n                        tindex2 = 2;\n\n                        g->preflag = 1;\n\n                    }\n\n                }\n\n\n\n                j = 0;\n\n                for (k = 0; k < 4; k++) {\n\n                    n  = lsf_nsf_table[tindex2][tindex][k];\n\n                    sl = slen[k];\n\n                    if (sl) {\n\n                        for (i = 0; i < n; i++)\n\n                            g->scale_factors[j++] = get_bits(&s->gb, sl);\n\n                    } else {\n\n                        for (i = 0; i < n; i++)\n\n                            g->scale_factors[j++] = 0;\n\n                    }\n\n                }\n\n                /* XXX: should compute exact size */\n\n                for (; j < 40; j++)\n\n                    g->scale_factors[j] = 0;\n\n            }\n\n\n\n            exponents_from_scale_factors(s, g, exponents);\n\n\n\n            /* read Huffman coded residue */\n\n            huffman_decode(s, g, exponents, bits_pos + g->part2_3_length);\n\n        } /* ch */\n\n\n\n        if (s->nb_channels == 2)\n\n            compute_stereo(s, &s->granules[0][gr], &s->granules[1][gr]);\n\n\n\n        for (ch = 0; ch < s->nb_channels; ch++) {\n\n            g = &s->granules[ch][gr];\n\n\n\n            reorder_block(s, g);\n\n            compute_antialias(s, g);\n\n            compute_imdct(s, g, &s->sb_samples[ch][18 * gr][0], s->mdct_buf[ch]);\n\n        }\n\n    } /* gr */\n\n    if (get_bits_count(&s->gb) < 0)\n\n        skip_bits_long(&s->gb, -get_bits_count(&s->gb));\n\n    return nb_granules * 18;\n\n}\n", "idx": 24155}
{"project": "FFmpeg", "commit_id": "08b520636e96ba6888b669b9b3f4c414631ea1d2", "target": 0, "func": "static int decorrelate(TAKDecContext *s, int c1, int c2, int length)\n\n{\n\n    GetBitContext *gb = &s->gb;\n\n    int32_t *p1       = s->decoded[c1] + (s->dmode > 5);\n\n    int32_t *p2       = s->decoded[c2] + (s->dmode > 5);\n\n    int32_t bp1       = p1[0];\n\n    int32_t bp2       = p2[0];\n\n    int i;\n\n    int dshift, dfactor;\n\n\n\n    length += s->dmode < 6;\n\n\n\n    switch (s->dmode) {\n\n    case 1: /* left/side */\n\n        s->tdsp.decorrelate_ls(p1, p2, length);\n\n        break;\n\n    case 2: /* side/right */\n\n        s->tdsp.decorrelate_sr(p1, p2, length);\n\n        break;\n\n    case 3: /* side/mid */\n\n        s->tdsp.decorrelate_sm(p1, p2, length);\n\n        break;\n\n    case 4: /* side/left with scale factor */\n\n        FFSWAP(int32_t*, p1, p2);\n\n        FFSWAP(int32_t, bp1, bp2);\n\n    case 5: /* side/right with scale factor */\n\n        dshift  = get_bits_esc4(gb);\n\n        dfactor = get_sbits(gb, 10);\n\n        s->tdsp.decorrelate_sf(p1, p2, length, dshift, dfactor);\n\n        break;\n\n    case 6:\n\n        FFSWAP(int32_t*, p1, p2);\n\n    case 7: {\n\n        int length2, order_half, filter_order, dval1, dval2;\n\n        int tmp, x, code_size;\n\n\n\n        if (length < 256)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        dshift       = get_bits_esc4(gb);\n\n        filter_order = 8 << get_bits1(gb);\n\n        dval1        = get_bits1(gb);\n\n        dval2        = get_bits1(gb);\n\n\n\n        for (i = 0; i < filter_order; i++) {\n\n            if (!(i & 3))\n\n                code_size = 14 - get_bits(gb, 3);\n\n            s->filter[i] = get_sbits(gb, code_size);\n\n        }\n\n\n\n        order_half = filter_order / 2;\n\n        length2    = length - (filter_order - 1);\n\n\n\n        /* decorrelate beginning samples */\n\n        if (dval1) {\n\n            for (i = 0; i < order_half; i++) {\n\n                int32_t a = p1[i];\n\n                int32_t b = p2[i];\n\n                p1[i]     = a + b;\n\n            }\n\n        }\n\n\n\n        /* decorrelate ending samples */\n\n        if (dval2) {\n\n            for (i = length2 + order_half; i < length; i++) {\n\n                int32_t a = p1[i];\n\n                int32_t b = p2[i];\n\n                p1[i]     = a + b;\n\n            }\n\n        }\n\n\n\n\n\n        for (i = 0; i < filter_order; i++)\n\n            s->residues[i] = *p2++ >> dshift;\n\n\n\n        p1 += order_half;\n\n        x = FF_ARRAY_ELEMS(s->residues) - filter_order;\n\n        for (; length2 > 0; length2 -= tmp) {\n\n            tmp = FFMIN(length2, x);\n\n\n\n            for (i = 0; i < tmp; i++)\n\n                s->residues[filter_order + i] = *p2++ >> dshift;\n\n\n\n            for (i = 0; i < tmp; i++) {\n\n                int v = 1 << 9;\n\n\n\n                if (filter_order == 16) {\n\n                    v += s->adsp.scalarproduct_int16(&s->residues[i], s->filter,\n\n                                                     filter_order);\n\n                } else {\n\n                    v += s->residues[i + 7] * s->filter[7] +\n\n                         s->residues[i + 6] * s->filter[6] +\n\n                         s->residues[i + 5] * s->filter[5] +\n\n                         s->residues[i + 4] * s->filter[4] +\n\n                         s->residues[i + 3] * s->filter[3] +\n\n                         s->residues[i + 2] * s->filter[2] +\n\n                         s->residues[i + 1] * s->filter[1] +\n\n                         s->residues[i    ] * s->filter[0];\n\n                }\n\n\n\n                v = (av_clip_intp2(v >> 10, 13) << dshift) - *p1;\n\n                *p1++ = v;\n\n            }\n\n\n\n            memmove(s->residues, &s->residues[tmp], 2 * filter_order);\n\n        }\n\n\n\n        emms_c();\n\n        break;\n\n    }\n\n    }\n\n\n\n    if (s->dmode > 0 && s->dmode < 6) {\n\n        p1[0] = bp1;\n\n        p2[0] = bp2;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24166}
{"project": "FFmpeg", "commit_id": "77d2ef13a8fa630e5081f14bde3fd20f84c90aec", "target": 1, "func": "static int ebml_parse_elem(MatroskaDemuxContext *matroska,\n\n                           EbmlSyntax *syntax, void *data)\n\n{\n\n    static const uint64_t max_lengths[EBML_TYPE_COUNT] = {\n\n        [EBML_UINT]  = 8,\n\n        [EBML_FLOAT] = 8,\n\n        // max. 16 MB for strings\n\n        [EBML_STR]   = 0x1000000,\n\n        [EBML_UTF8]  = 0x1000000,\n\n        // max. 256 MB for binary data\n\n        [EBML_BIN]   = 0x10000000,\n\n        // no limits for anything else\n\n    };\n\n    AVIOContext *pb = matroska->ctx->pb;\n\n    uint32_t id = syntax->id;\n\n    uint64_t length;\n\n    int res;\n\n\n\n    data = (char *)data + syntax->data_offset;\n\n    if (syntax->list_elem_size) {\n\n        EbmlList *list = data;\n\n        list->elem = av_realloc(list->elem, (list->nb_elem+1)*syntax->list_elem_size);\n\n        data = (char*)list->elem + list->nb_elem*syntax->list_elem_size;\n\n        memset(data, 0, syntax->list_elem_size);\n\n        list->nb_elem++;\n\n    }\n\n\n\n    if (syntax->type != EBML_PASS && syntax->type != EBML_STOP) {\n\n        matroska->current_id = 0;\n\n        if ((res = ebml_read_length(matroska, pb, &length)) < 0)\n\n            return res;\n\n        if (max_lengths[syntax->type] && length > max_lengths[syntax->type]) {\n\n            av_log(matroska->ctx, AV_LOG_ERROR,\n\n                   \"Invalid length 0x%\"PRIx64\" > 0x%\"PRIx64\" for syntax element %i\\n\",\n\n                   length, max_lengths[syntax->type], syntax->type);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    switch (syntax->type) {\n\n    case EBML_UINT:  res = ebml_read_uint  (pb, length, data);  break;\n\n    case EBML_FLOAT: res = ebml_read_float (pb, length, data);  break;\n\n    case EBML_STR:\n\n    case EBML_UTF8:  res = ebml_read_ascii (pb, length, data);  break;\n\n    case EBML_BIN:   res = ebml_read_binary(pb, length, data);  break;\n\n    case EBML_NEST:  if ((res=ebml_read_master(matroska, length)) < 0)\n\n                         return res;\n\n                     if (id == MATROSKA_ID_SEGMENT)\n\n                         matroska->segment_start = avio_tell(matroska->ctx->pb);\n\n                     return ebml_parse_nest(matroska, syntax->def.n, data);\n\n    case EBML_PASS:  return ebml_parse_id(matroska, syntax->def.n, id, data);\n\n    case EBML_STOP:  return 1;\n\n    default:         return avio_skip(pb,length)<0 ? AVERROR(EIO) : 0;\n\n    }\n\n    if (res == AVERROR_INVALIDDATA)\n\n        av_log(matroska->ctx, AV_LOG_ERROR, \"Invalid element\\n\");\n\n    else if (res == AVERROR(EIO))\n\n        av_log(matroska->ctx, AV_LOG_ERROR, \"Read error\\n\");\n\n    return res;\n\n}\n", "idx": 24169}
{"project": "FFmpeg", "commit_id": "0dcfccaa691bf533b0f144b6d98b49eb59f1f3ab", "target": 1, "func": "static int au_write_header(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    AVCodecContext *enc = s->streams[0]->codec;\n\n\n\n    if (!enc->codec_tag)\n\n        return AVERROR(EINVAL);\n\n\n\n    ffio_wfourcc(pb, \".snd\");                   /* magic number */\n\n    avio_wb32(pb, AU_HEADER_SIZE);              /* header size */\n\n    avio_wb32(pb, AU_UNKNOWN_SIZE);             /* data size */\n\n    avio_wb32(pb, enc->codec_tag);              /* codec ID */\n\n    avio_wb32(pb, enc->sample_rate);\n\n    avio_wb32(pb, enc->channels);\n\n    avio_wb64(pb, 0); /* annotation field */\n\n    avio_flush(pb);\n\n\n\n    return 0;\n\n}\n", "idx": 24175}
{"project": "FFmpeg", "commit_id": "229843aa359ae0c9519977d7fa952688db63f559", "target": 0, "func": "static int process_cc608(CCaptionSubContext *ctx, int64_t pts, uint8_t hi, uint8_t lo)\n\n{\n\n    int ret = 0;\n\n#define COR3(var, with1, with2, with3)  ( (var) == (with1) ||  (var) == (with2) || (var) == (with3) )\n\n    if ( hi == ctx->prev_cmd[0] && lo == ctx->prev_cmd[1]) {\n\n    /* ignore redundant command */\n\n    } else if ( (hi == 0x10 && (lo >= 0x40 || lo <= 0x5f)) ||\n\n              ( (hi >= 0x11 && hi <= 0x17) && (lo >= 0x40 && lo <= 0x7f) ) ) {\n\n        handle_pac(ctx, hi, lo);\n\n    } else if ( ( hi == 0x11 && lo >= 0x20 && lo <= 0x2f ) ||\n\n                ( hi == 0x17 && lo >= 0x2e && lo <= 0x2f) ) {\n\n        handle_textattr(ctx, hi, lo);\n\n    } else if ( COR3(hi, 0x14, 0x15, 0x1C) && lo == 0x20 ) {\n\n    /* resume caption loading */\n\n        ctx->mode = CCMODE_POPON;\n\n    } else if ( COR3(hi, 0x14, 0x15, 0x1C) && lo == 0x24 ) {\n\n        handle_delete_end_of_row(ctx, hi, lo);\n\n    } else if ( COR3(hi, 0x14, 0x15, 0x1C) && lo == 0x25 ) {\n\n        ctx->rollup = 2;\n\n        ctx->mode = CCMODE_ROLLUP_2;\n\n    } else if ( COR3(hi, 0x14, 0x15, 0x1C) && lo == 0x26 ) {\n\n        ctx->rollup = 3;\n\n        ctx->mode = CCMODE_ROLLUP_3;\n\n    } else if ( COR3(hi, 0x14, 0x15, 0x1C) && lo == 0x27 ) {\n\n        ctx->rollup = 4;\n\n        ctx->mode = CCMODE_ROLLUP_4;\n\n    } else if ( COR3(hi, 0x14, 0x15, 0x1C) && lo == 0x29 ) {\n\n    /* resume direct captioning */\n\n        ctx->mode = CCMODE_PAINTON;\n\n    } else if ( COR3(hi, 0x14, 0x15, 0x1C) && lo == 0x2B ) {\n\n    /* resume text display */\n\n        ctx->mode = CCMODE_TEXT;\n\n    } else if ( COR3(hi, 0x14, 0x15, 0x1C) && lo == 0x2C ) {\n\n    /* erase display memory */\n\n        ret = handle_edm(ctx, pts);\n\n    } else if ( COR3(hi, 0x14, 0x15, 0x1C) && lo == 0x2D ) {\n\n    /* carriage return */\n\n        av_dlog(ctx, \"carriage return\\n\");\n\n        reap_screen(ctx, pts);\n\n        roll_up(ctx);\n\n        ctx->screen_changed = 1;\n\n        ctx->cursor_column = 0;\n\n    } else if ( COR3(hi, 0x14, 0x15, 0x1C) && lo == 0x2F ) {\n\n    /* end of caption */\n\n        av_dlog(ctx, \"handle_eoc\\n\");\n\n        ret = handle_eoc(ctx, pts);\n\n    } else if (hi>=0x20) {\n\n    /* Standard characters (always in pairs) */\n\n        handle_char(ctx, hi, lo, pts);\n\n    } else {\n\n    /* Ignoring all other non data code */\n\n        av_dlog(ctx, \"Unknown command 0x%hhx 0x%hhx\\n\", hi, lo);\n\n    }\n\n\n\n    /* set prev command */\n\n     ctx->prev_cmd[0] = hi;\n\n     ctx->prev_cmd[1] = lo;\n\n\n\n#undef COR3\n\n    return ret;\n\n\n\n}\n", "idx": 24182}
{"project": "FFmpeg", "commit_id": "5c2fb561d94fc51d76ab21d6f7cc5b6cc3aa599c", "target": 0, "func": "static int h264_find_frame_end(H264ParseContext *p, const uint8_t *buf,\n\n                               int buf_size)\n\n{\n\n    int i;\n\n    uint32_t state;\n\n    ParseContext *pc = &p->pc;\n\n//    mb_addr= pc->mb_addr - 1;\n\n    state = pc->state;\n\n    if (state > 13)\n\n        state = 7;\n\n\n\n    for (i = 0; i < buf_size; i++) {\n\n        if (state == 7) {\n\n            i += p->h264dsp.startcode_find_candidate(buf + i, buf_size - i);\n\n            if (i < buf_size)\n\n                state = 2;\n\n        } else if (state <= 2) {\n\n            if (buf[i] == 1)\n\n                state ^= 5;            // 2->7, 1->4, 0->5\n\n            else if (buf[i])\n\n                state = 7;\n\n            else\n\n                state >>= 1;           // 2->1, 1->0, 0->0\n\n        } else if (state <= 5) {\n\n            int nalu_type = buf[i] & 0x1F;\n\n            if (nalu_type == NAL_SEI || nalu_type == NAL_SPS ||\n\n                nalu_type == NAL_PPS || nalu_type == NAL_AUD) {\n\n                if (pc->frame_start_found) {\n\n                    i++;\n\n                    goto found;\n\n                }\n\n            } else if (nalu_type == NAL_SLICE || nalu_type == NAL_DPA ||\n\n                       nalu_type == NAL_IDR_SLICE) {\n\n                if (pc->frame_start_found) {\n\n                    state += 8;\n\n                    continue;\n\n                } else\n\n                    pc->frame_start_found = 1;\n\n            }\n\n            state = 7;\n\n        } else {\n\n            // first_mb_in_slice is 0, probably the first nal of a new slice\n\n            if (buf[i] & 0x80)\n\n                goto found;\n\n            state = 7;\n\n        }\n\n    }\n\n    pc->state = state;\n\n    return END_NOT_FOUND;\n\n\n\nfound:\n\n    pc->state             = 7;\n\n    pc->frame_start_found = 0;\n\n    return i - (state & 5);\n\n}\n", "idx": 24193}
{"project": "FFmpeg", "commit_id": "1dba8371d93cf1c83bcd5c432d921905206a60f3", "target": 0, "func": "int ffurl_connect(URLContext *uc, AVDictionary **options)\n\n{\n\n    int err =\n\n        uc->prot->url_open2 ? uc->prot->url_open2(uc,\n\n                                                  uc->filename,\n\n                                                  uc->flags,\n\n                                                  options) :\n\n        uc->prot->url_open(uc, uc->filename, uc->flags);\n\n    if (err)\n\n        return err;\n\n    uc->is_connected = 1;\n\n    /* We must be careful here as ffurl_seek() could be slow,\n\n     * for example for http */\n\n    if ((uc->flags & AVIO_FLAG_WRITE) || !strcmp(uc->prot->name, \"file\"))\n\n        if (!uc->is_streamed && ffurl_seek(uc, 0, SEEK_SET) < 0)\n\n            uc->is_streamed = 1;\n\n    return 0;\n\n}\n", "idx": 24205}
{"project": "FFmpeg", "commit_id": "e45a2872fafe631c14aee9f79d0963d68c4fc1fd", "target": 0, "func": "void put_pixels8_xy2_altivec(uint8_t *block, const uint8_t *pixels, int line_size, int h)\n\n{\n\nPOWERPC_TBL_DECLARE(altivec_put_pixels8_xy2_num, 1);\n\n#ifdef ALTIVEC_USE_REFERENCE_C_CODE\n\n    int j;\n\nPOWERPC_TBL_START_COUNT(altivec_put_pixels8_xy2_num, 1);\n\n    for (j = 0; j < 2; j++) {\n\n      int i;\n\n      const uint32_t a = (((const struct unaligned_32 *) (pixels))->l);\n\n      const uint32_t b =\n\n        (((const struct unaligned_32 *) (pixels + 1))->l);\n\n      uint32_t l0 =\n\n        (a & 0x03030303UL) + (b & 0x03030303UL) + 0x02020202UL;\n\n      uint32_t h0 =\n\n        ((a & 0xFCFCFCFCUL) >> 2) + ((b & 0xFCFCFCFCUL) >> 2);\n\n      uint32_t l1, h1;\n\n      pixels += line_size;\n\n      for (i = 0; i < h; i += 2) {\n\n        uint32_t a = (((const struct unaligned_32 *) (pixels))->l);\n\n        uint32_t b = (((const struct unaligned_32 *) (pixels + 1))->l);\n\n        l1 = (a & 0x03030303UL) + (b & 0x03030303UL);\n\n        h1 = ((a & 0xFCFCFCFCUL) >> 2) + ((b & 0xFCFCFCFCUL) >> 2);\n\n        *((uint32_t *) block) =\n\n          h0 + h1 + (((l0 + l1) >> 2) & 0x0F0F0F0FUL);\n\n        pixels += line_size;\n\n        block += line_size;\n\n        a = (((const struct unaligned_32 *) (pixels))->l);\n\n        b = (((const struct unaligned_32 *) (pixels + 1))->l);\n\n        l0 = (a & 0x03030303UL) + (b & 0x03030303UL) + 0x02020202UL;\n\n        h0 = ((a & 0xFCFCFCFCUL) >> 2) + ((b & 0xFCFCFCFCUL) >> 2);\n\n        *((uint32_t *) block) =\n\n          h0 + h1 + (((l0 + l1) >> 2) & 0x0F0F0F0FUL);\n\n        pixels += line_size;\n\n        block += line_size;\n\n      } pixels += 4 - line_size * (h + 1);\n\n      block += 4 - line_size * h;\n\n    }\n\n\n\nPOWERPC_TBL_STOP_COUNT(altivec_put_pixels8_xy2_num, 1);\n\n\n\n#else /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n   register int i;\n\n   register vector unsigned char\n\n     pixelsv1, pixelsv2,\n\n     pixelsavg;\n\n   register vector unsigned char\n\n     blockv, temp1, temp2;\n\n   register vector unsigned short\n\n     pixelssum1, pixelssum2, temp3;\n\n   register const vector unsigned char vczero = (const vector unsigned char)vec_splat_u8(0);\n\n   register const vector unsigned short vctwo = (const vector unsigned short)vec_splat_u16(2);\n\n   \n\n   temp1 = vec_ld(0, pixels);\n\n   temp2 = vec_ld(16, pixels);\n\n   pixelsv1 = vec_perm(temp1, temp2, vec_lvsl(0, pixels));\n\n   if ((((unsigned long)pixels) & 0x0000000F) ==  0x0000000F)\n\n   {\n\n     pixelsv2 = temp2;\n\n   }\n\n   else\n\n   {\n\n     pixelsv2 = vec_perm(temp1, temp2, vec_lvsl(1, pixels));\n\n   }\n\n   pixelsv1 = vec_mergeh(vczero, pixelsv1);\n\n   pixelsv2 = vec_mergeh(vczero, pixelsv2);\n\n   pixelssum1 = vec_add((vector unsigned short)pixelsv1,\n\n                        (vector unsigned short)pixelsv2);\n\n   pixelssum1 = vec_add(pixelssum1, vctwo);\n\n   \n\nPOWERPC_TBL_START_COUNT(altivec_put_pixels8_xy2_num, 1); \n\n   for (i = 0; i < h ; i++) {\n\n     int rightside = ((unsigned long)block & 0x0000000F);\n\n     blockv = vec_ld(0, block);\n\n\n\n     temp1 = vec_ld(line_size, pixels);\n\n     temp2 = vec_ld(line_size + 16, pixels);\n\n     pixelsv1 = vec_perm(temp1, temp2, vec_lvsl(line_size, pixels));\n\n     if (((((unsigned long)pixels) + line_size) & 0x0000000F) ==  0x0000000F)\n\n     {\n\n       pixelsv2 = temp2;\n\n     }\n\n     else\n\n     {\n\n       pixelsv2 = vec_perm(temp1, temp2, vec_lvsl(line_size + 1, pixels));\n\n     }\n\n\n\n     pixelsv1 = vec_mergeh(vczero, pixelsv1);\n\n     pixelsv2 = vec_mergeh(vczero, pixelsv2);\n\n     pixelssum2 = vec_add((vector unsigned short)pixelsv1,\n\n                          (vector unsigned short)pixelsv2);\n\n     temp3 = vec_add(pixelssum1, pixelssum2);\n\n     temp3 = vec_sra(temp3, vctwo);\n\n     pixelssum1 = vec_add(pixelssum2, vctwo);\n\n     pixelsavg = vec_packsu(temp3, (vector unsigned short) vczero);\n\n     \n\n     if (rightside)\n\n     {\n\n       blockv = vec_perm(blockv, pixelsavg, vcprm(0, 1, s0, s1));\n\n     }\n\n     else\n\n     {\n\n       blockv = vec_perm(blockv, pixelsavg, vcprm(s0, s1, 2, 3));\n\n     }\n\n     \n\n     vec_st(blockv, 0, block);\n\n     \n\n     block += line_size;\n\n     pixels += line_size;\n\n   }\n\n   \n\nPOWERPC_TBL_STOP_COUNT(altivec_put_pixels8_xy2_num, 1);\n\n#endif /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n}\n", "idx": 24216}
{"project": "FFmpeg", "commit_id": "26fc6ffec45c954cd8ca46342ac75cd90bcc7e02", "target": 1, "func": "static inline void libopenjpeg_copy_to_packed16(AVFrame *picture, opj_image_t *image) {\n\n    uint16_t *img_ptr;\n\n    int index, x, y, c;\n\n    int adjust[4];\n\n    for (x = 0; x < image->numcomps; x++)\n\n        adjust[x] = FFMAX(FFMIN(av_pix_fmt_desc_get(picture->format)->comp[x].depth_minus1 + 1 - image->comps[x].prec, 8), 0);\n\n\n\n    for (y = 0; y < picture->height; y++) {\n\n        index = y*picture->width;\n\n        img_ptr = (uint16_t*) (picture->data[0] + y*picture->linesize[0]);\n\n        for (x = 0; x < picture->width; x++, index++) {\n\n            for (c = 0; c < image->numcomps; c++) {\n\n                *img_ptr++ = 0x8000 * image->comps[c].sgnd + (image->comps[c].data[index] << adjust[c]);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 24221}
{"project": "FFmpeg", "commit_id": "0ecca7a49f8e254c12a3a1de048d738bfbb614c6", "target": 1, "func": "static int flic_read_packet(AVFormatContext *s,\n\n                            AVPacket *pkt)\n\n{\n\n    FlicDemuxContext *flic = (FlicDemuxContext *)s->priv_data;\n\n    ByteIOContext *pb = &s->pb;\n\n    int packet_read = 0;\n\n    unsigned int size;\n\n    int magic;\n\n    int ret = 0;\n\n    unsigned char preamble[FLIC_PREAMBLE_SIZE];\n\n\n\n    while (!packet_read) {\n\n\n\n        if ((ret = get_buffer(pb, preamble, FLIC_PREAMBLE_SIZE)) !=\n\n            FLIC_PREAMBLE_SIZE) {\n\n            ret = AVERROR_IO;\n\n            break;\n\n        }\n\n\n\n        size = LE_32(&preamble[0]);\n\n        magic = LE_16(&preamble[4]);\n\n\n\n        if ((magic == FLIC_CHUNK_MAGIC_1) || (magic == FLIC_CHUNK_MAGIC_2)) {\n\n            if (av_new_packet(pkt, size)) {\n\n                ret = AVERROR_IO;\n\n                break;\n\n            }\n\n            pkt->stream_index = flic->video_stream_index;\n\n            pkt->pts = flic->pts;\n\n            memcpy(pkt->data, preamble, FLIC_PREAMBLE_SIZE);\n\n            ret = get_buffer(pb, pkt->data + FLIC_PREAMBLE_SIZE, \n\n                size - FLIC_PREAMBLE_SIZE);\n\n            if (ret != size - FLIC_PREAMBLE_SIZE) {\n\n                av_free_packet(pkt);\n\n                ret = AVERROR_IO;\n\n            }\n\n            flic->pts += flic->frame_pts_inc;\n\n            packet_read = 1;\n\n        } else {\n\n            /* not interested in this chunk */\n\n            url_fseek(pb, size - 6, SEEK_CUR);\n\n        }\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 24223}
{"project": "FFmpeg", "commit_id": "075060023d978975ed5328e269d6e20163e669d2", "target": 1, "func": "int MPV_encode_picture(AVCodecContext *avctx,\n\n                       unsigned char *buf, int buf_size, void *data)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    AVFrame *pic_arg = data;\n\n    int i, stuffing_count;\n\n\n\n    for(i=0; i<avctx->thread_count; i++){\n\n        int start_y= s->thread_context[i]->start_mb_y;\n\n        int   end_y= s->thread_context[i]->  end_mb_y;\n\n        int h= s->mb_height;\n\n        uint8_t *start= buf + (size_t)(((int64_t) buf_size)*start_y/h);\n\n        uint8_t *end  = buf + (size_t)(((int64_t) buf_size)*  end_y/h);\n\n\n\n        init_put_bits(&s->thread_context[i]->pb, start, end - start);\n\n    }\n\n\n\n    s->picture_in_gop_number++;\n\n\n\n    if(load_input_picture(s, pic_arg) < 0)\n\n        return -1;\n\n\n\n    select_input_picture(s);\n\n\n\n    /* output? */\n\n    if(s->new_picture.data[0]){\n\n        s->pict_type= s->new_picture.pict_type;\n\n//emms_c();\n\n//printf(\"qs:%f %f %d\\n\", s->new_picture.quality, s->current_picture.quality, s->qscale);\n\n        MPV_frame_start(s, avctx);\n\n\n\n        if (encode_picture(s, s->picture_number) < 0)\n\n            return -1;\n\n\n\n        avctx->real_pict_num  = s->picture_number;\n\n        avctx->header_bits = s->header_bits;\n\n        avctx->mv_bits     = s->mv_bits;\n\n        avctx->misc_bits   = s->misc_bits;\n\n        avctx->i_tex_bits  = s->i_tex_bits;\n\n        avctx->p_tex_bits  = s->p_tex_bits;\n\n        avctx->i_count     = s->i_count;\n\n        avctx->p_count     = s->mb_num - s->i_count - s->skip_count; //FIXME f/b_count in avctx\n\n        avctx->skip_count  = s->skip_count;\n\n\n\n        MPV_frame_end(s);\n\n\n\n        if (s->out_format == FMT_MJPEG)\n\n            mjpeg_picture_trailer(s);\n\n\n\n        if(s->flags&CODEC_FLAG_PASS1)\n\n            ff_write_pass1_stats(s);\n\n\n\n        for(i=0; i<4; i++){\n\n            s->current_picture_ptr->error[i]= s->current_picture.error[i];\n\n            avctx->error[i] += s->current_picture_ptr->error[i];\n\n        }\n\n\n\n        if(s->flags&CODEC_FLAG_PASS1)\n\n            assert(avctx->header_bits + avctx->mv_bits + avctx->misc_bits + avctx->i_tex_bits + avctx->p_tex_bits == put_bits_count(&s->pb));\n\n        flush_put_bits(&s->pb);\n\n        s->frame_bits  = put_bits_count(&s->pb);\n\n\n\n        stuffing_count= ff_vbv_update(s, s->frame_bits);\n\n        if(stuffing_count){\n\n            if(s->pb.buf_end - s->pb.buf - (put_bits_count(&s->pb)>>3) < stuffing_count + 50){\n\n                av_log(s->avctx, AV_LOG_ERROR, \"stuffing too large\\n\");\n\n                return -1;\n\n            }\n\n\n\n            switch(s->codec_id){\n\n            case CODEC_ID_MPEG1VIDEO:\n\n            case CODEC_ID_MPEG2VIDEO:\n\n                while(stuffing_count--){\n\n                    put_bits(&s->pb, 8, 0);\n\n                }\n\n            break;\n\n            case CODEC_ID_MPEG4:\n\n                put_bits(&s->pb, 16, 0);\n\n                put_bits(&s->pb, 16, 0x1C3);\n\n                stuffing_count -= 4;\n\n                while(stuffing_count--){\n\n                    put_bits(&s->pb, 8, 0xFF);\n\n                }\n\n            break;\n\n            default:\n\n                av_log(s->avctx, AV_LOG_ERROR, \"vbv buffer overflow\\n\");\n\n            }\n\n            flush_put_bits(&s->pb);\n\n            s->frame_bits  = put_bits_count(&s->pb);\n\n        }\n\n\n\n        /* update mpeg1/2 vbv_delay for CBR */\n\n        if(s->avctx->rc_max_rate && s->avctx->rc_min_rate == s->avctx->rc_max_rate && s->out_format == FMT_MPEG1\n\n           && 90000LL * (avctx->rc_buffer_size-1) <= s->avctx->rc_max_rate*0xFFFFLL){\n\n            int vbv_delay;\n\n\n\n            assert(s->repeat_first_field==0);\n\n\n\n            vbv_delay= lrintf(90000 * s->rc_context.buffer_index / s->avctx->rc_max_rate);\n\n            assert(vbv_delay < 0xFFFF);\n\n\n\n            s->vbv_delay_ptr[0] &= 0xF8;\n\n            s->vbv_delay_ptr[0] |= vbv_delay>>13;\n\n            s->vbv_delay_ptr[1]  = vbv_delay>>5;\n\n            s->vbv_delay_ptr[2] &= 0x07;\n\n            s->vbv_delay_ptr[2] |= vbv_delay<<3;\n\n        }\n\n        s->total_bits += s->frame_bits;\n\n        avctx->frame_bits  = s->frame_bits;\n\n    }else{\n\n        assert((pbBufPtr(&s->pb) == s->pb.buf));\n\n        s->frame_bits=0;\n\n    }\n\n    assert((s->frame_bits&7)==0);\n\n\n\n    return s->frame_bits/8;\n\n}\n", "idx": 24224}
{"project": "FFmpeg", "commit_id": "4c7b023d56e09a78a587d036db1b64bf7c493b3d", "target": 0, "func": "static int get_ref_idx(AVFrame *frame)\n\n{\n\n    FrameDecodeData *fdd;\n\n    NVDECFrame *cf;\n\n\n\n    if (!frame || !frame->private_ref)\n\n        return -1;\n\n\n\n    fdd = (FrameDecodeData*)frame->private_ref->data;\n\n    cf  = (NVDECFrame*)fdd->hwaccel_priv;\n\n\n\n    return cf->idx;\n\n}\n", "idx": 24225}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static void vp3_draw_horiz_band(Vp3DecodeContext *s, int y)\n\n{\n\n    int h, cy, i;\n\n    int offset[AV_NUM_DATA_POINTERS];\n\n\n\n    if (HAVE_THREADS && s->avctx->active_thread_type & FF_THREAD_FRAME) {\n\n        int y_flipped = s->flipped_image ? s->avctx->height - y : y;\n\n\n\n        /* At the end of the frame, report INT_MAX instead of the height of\n\n         * the frame. This makes the other threads' ff_thread_await_progress()\n\n         * calls cheaper, because they don't have to clip their values. */\n\n        ff_thread_report_progress(&s->current_frame,\n\n                                  y_flipped == s->avctx->height ? INT_MAX\n\n                                                                : y_flipped - 1,\n\n                                  0);\n\n    }\n\n\n\n    if (s->avctx->draw_horiz_band == NULL)\n\n        return;\n\n\n\n    h = y - s->last_slice_end;\n\n    s->last_slice_end = y;\n\n    y -= h;\n\n\n\n    if (!s->flipped_image)\n\n        y = s->avctx->height - y - h;\n\n\n\n    cy        = y >> s->chroma_y_shift;\n\n    offset[0] = s->current_frame.f->linesize[0] * y;\n\n    offset[1] = s->current_frame.f->linesize[1] * cy;\n\n    offset[2] = s->current_frame.f->linesize[2] * cy;\n\n    for (i = 3; i < AV_NUM_DATA_POINTERS; i++)\n\n        offset[i] = 0;\n\n\n\n    emms_c();\n\n    s->avctx->draw_horiz_band(s->avctx, s->current_frame.f, offset, y, 3, h);\n\n}\n", "idx": 24226}
{"project": "FFmpeg", "commit_id": "d31e3f7ccc5d1e198b3a582f4413ce7342928d8c", "target": 0, "func": "static int gif_write_header(AVFormatContext *s)\n\n{\n\n    GIFContext *gif = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVCodecContext *enc, *video_enc;\n\n    int i, width, height, loop_count /*, rate*/;\n\n\n\n/* XXX: do we reject audio streams or just ignore them ?\n\n    if(s->nb_streams > 1)\n\n        return -1;\n\n*/\n\n    gif->time = 0;\n\n    gif->file_time = 0;\n\n\n\n    video_enc = NULL;\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        enc = s->streams[i]->codec;\n\n        if (enc->codec_type != AVMEDIA_TYPE_AUDIO)\n\n            video_enc = enc;\n\n    }\n\n\n\n    if (!video_enc) {\n\n        av_free(gif);\n\n        return -1;\n\n    } else {\n\n        width = video_enc->width;\n\n        height = video_enc->height;\n\n        loop_count = s->loop_output;\n\n//        rate = video_enc->time_base.den;\n\n    }\n\n\n\n    if (video_enc->pix_fmt != PIX_FMT_RGB24) {\n\n        av_log(s, AV_LOG_ERROR, \"ERROR: gif only handles the rgb24 pixel format. Use -pix_fmt rgb24.\\n\");\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    gif_image_write_header(pb, width, height, loop_count, NULL);\n\n\n\n    avio_flush(s->pb);\n\n    return 0;\n\n}\n", "idx": 24227}
{"project": "FFmpeg", "commit_id": "a26e1d4c1f7c93d24250dd9c0786241f92fcdea4", "target": 0, "func": "static int put_packetheader(NUTContext *nut, ByteIOContext *bc, int max_size, int calculate_checksum)\n\n{\n\n    put_flush_packet(bc);\n\n    nut->packet_start[2]= url_ftell(bc) - 8;\n\n    nut->written_packet_size = max_size;\n\n    \n\n    if(calculate_checksum)\n\n        init_checksum(bc, update_adler32, 0);\n\n\n\n    /* packet header */\n\n    put_v(bc, nut->written_packet_size); /* forward ptr */\n\n\n\n    return 0;\n\n}\n", "idx": 24228}
{"project": "FFmpeg", "commit_id": "4bb9adcff1be7ccbb6b8fab40cd68b3808544edc", "target": 0, "func": "inline static void RENAME(hcscale)(SwsContext *c, uint16_t *dst, long dstWidth, uint8_t *src1, uint8_t *src2,\n\n                                   int srcW, int xInc, int flags, int canMMX2BeUsed, int16_t *hChrFilter,\n\n                                   int16_t *hChrFilterPos, int hChrFilterSize, void *funnyUVCode,\n\n                                   int srcFormat, uint8_t *formatConvBuffer, int16_t *mmx2Filter,\n\n                                   int32_t *mmx2FilterPos, uint8_t *pal)\n\n{\n\n    if (srcFormat==PIX_FMT_YUYV422)\n\n    {\n\n        RENAME(yuy2ToUV)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n    else if (srcFormat==PIX_FMT_UYVY422)\n\n    {\n\n        RENAME(uyvyToUV)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n    else if (srcFormat==PIX_FMT_RGB32)\n\n    {\n\n        if(c->chrSrcHSubSample)\n\n            RENAME(bgr32ToUV_half)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        else\n\n            RENAME(bgr32ToUV)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n    else if (srcFormat==PIX_FMT_RGB32_1)\n\n    {\n\n        if(c->chrSrcHSubSample)\n\n            RENAME(bgr32ToUV_half)(formatConvBuffer, formatConvBuffer+VOFW, src1+ALT32_CORR, src2+ALT32_CORR, srcW);\n\n        else\n\n            RENAME(bgr32ToUV)(formatConvBuffer, formatConvBuffer+VOFW, src1+ALT32_CORR, src2+ALT32_CORR, srcW);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n    else if (srcFormat==PIX_FMT_BGR24)\n\n    {\n\n        if(c->chrSrcHSubSample)\n\n            RENAME(bgr24ToUV_half)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        else\n\n            RENAME(bgr24ToUV)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n    else if (srcFormat==PIX_FMT_BGR565)\n\n    {\n\n        if(c->chrSrcHSubSample)\n\n            RENAME(bgr16ToUV_half)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        else\n\n            RENAME(bgr16ToUV)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n    else if (srcFormat==PIX_FMT_BGR555)\n\n    {\n\n        if(c->chrSrcHSubSample)\n\n            RENAME(bgr15ToUV_half)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        else\n\n            RENAME(bgr15ToUV)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n    else if (srcFormat==PIX_FMT_BGR32)\n\n    {\n\n        if(c->chrSrcHSubSample)\n\n            RENAME(rgb32ToUV_half)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        else\n\n            RENAME(rgb32ToUV)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n    else if (srcFormat==PIX_FMT_BGR32_1)\n\n    {\n\n        if(c->chrSrcHSubSample)\n\n            RENAME(rgb32ToUV_half)(formatConvBuffer, formatConvBuffer+VOFW, src1+ALT32_CORR, src2+ALT32_CORR, srcW);\n\n        else\n\n            RENAME(rgb32ToUV)(formatConvBuffer, formatConvBuffer+VOFW, src1+ALT32_CORR, src2+ALT32_CORR, srcW);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n    else if (srcFormat==PIX_FMT_RGB24)\n\n    {\n\n        if(c->chrSrcHSubSample)\n\n            RENAME(rgb24ToUV_half)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        else\n\n            RENAME(rgb24ToUV)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n    else if (srcFormat==PIX_FMT_RGB565)\n\n    {\n\n        if(c->chrSrcHSubSample)\n\n            RENAME(rgb16ToUV_half)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        else\n\n            RENAME(rgb16ToUV)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n    else if (srcFormat==PIX_FMT_RGB555)\n\n    {\n\n        if(c->chrSrcHSubSample)\n\n            RENAME(rgb15ToUV_half)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        else\n\n            RENAME(rgb15ToUV)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n    else if (isGray(srcFormat) || srcFormat==PIX_FMT_MONOBLACK || PIX_FMT_MONOWHITE)\n\n    {\n\n        return;\n\n    }\n\n    else if (srcFormat==PIX_FMT_RGB8 || srcFormat==PIX_FMT_BGR8 || srcFormat==PIX_FMT_PAL8 || srcFormat==PIX_FMT_BGR4_BYTE  || srcFormat==PIX_FMT_RGB4_BYTE)\n\n    {\n\n        RENAME(palToUV)(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW, (uint32_t*)pal);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n\n\n#ifdef HAVE_MMX\n\n    // Use the new MMX scaler if the MMX2 one can't be used (it is faster than the x86 ASM one).\n\n    if (!(flags&SWS_FAST_BILINEAR) || (!canMMX2BeUsed))\n\n#else\n\n    if (!(flags&SWS_FAST_BILINEAR))\n\n#endif\n\n    {\n\n        RENAME(hScale)(dst     , dstWidth, src1, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n        RENAME(hScale)(dst+VOFW, dstWidth, src2, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n    }\n\n    else // fast bilinear upscale / crap downscale\n\n    {\n\n#if defined(ARCH_X86)\n\n#ifdef HAVE_MMX2\n\n        int i;\n\n#if defined(PIC)\n\n        uint64_t ebxsave __attribute__((aligned(8)));\n\n#endif\n\n        if (canMMX2BeUsed)\n\n        {\n\n            asm volatile(\n\n#if defined(PIC)\n\n            \"mov          %%\"REG_b\", %6         \\n\\t\"\n\n#endif\n\n            \"pxor             %%mm7, %%mm7      \\n\\t\"\n\n            \"mov                 %0, %%\"REG_c\"  \\n\\t\"\n\n            \"mov                 %1, %%\"REG_D\"  \\n\\t\"\n\n            \"mov                 %2, %%\"REG_d\"  \\n\\t\"\n\n            \"mov                 %3, %%\"REG_b\"  \\n\\t\"\n\n            \"xor          %%\"REG_a\", %%\"REG_a\"  \\n\\t\" // i\n\n            PREFETCH\"   (%%\"REG_c\")             \\n\\t\"\n\n            PREFETCH\" 32(%%\"REG_c\")             \\n\\t\"\n\n            PREFETCH\" 64(%%\"REG_c\")             \\n\\t\"\n\n\n\n#ifdef ARCH_X86_64\n\n\n\n#define FUNNY_UV_CODE \\\n\n            \"movl       (%%\"REG_b\"), %%esi      \\n\\t\"\\\n\n            \"call               *%4             \\n\\t\"\\\n\n            \"movl (%%\"REG_b\", %%\"REG_a\"), %%esi \\n\\t\"\\\n\n            \"add          %%\"REG_S\", %%\"REG_c\"  \\n\\t\"\\\n\n            \"add          %%\"REG_a\", %%\"REG_D\"  \\n\\t\"\\\n\n            \"xor          %%\"REG_a\", %%\"REG_a\"  \\n\\t\"\\\n\n\n\n#else\n\n\n\n#define FUNNY_UV_CODE \\\n\n            \"movl       (%%\"REG_b\"), %%esi      \\n\\t\"\\\n\n            \"call               *%4             \\n\\t\"\\\n\n            \"addl (%%\"REG_b\", %%\"REG_a\"), %%\"REG_c\" \\n\\t\"\\\n\n            \"add          %%\"REG_a\", %%\"REG_D\"  \\n\\t\"\\\n\n            \"xor          %%\"REG_a\", %%\"REG_a\"  \\n\\t\"\\\n\n\n\n#endif /* ARCH_X86_64 */\n\n\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\n            \"xor          %%\"REG_a\", %%\"REG_a\"  \\n\\t\" // i\n\n            \"mov                 %5, %%\"REG_c\"  \\n\\t\" // src\n\n            \"mov                 %1, %%\"REG_D\"  \\n\\t\" // buf1\n\n            \"add              $\"AV_STRINGIFY(VOF)\", %%\"REG_D\"  \\n\\t\"\n\n            PREFETCH\"   (%%\"REG_c\")             \\n\\t\"\n\n            PREFETCH\" 32(%%\"REG_c\")             \\n\\t\"\n\n            PREFETCH\" 64(%%\"REG_c\")             \\n\\t\"\n\n\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\n\n\n#if defined(PIC)\n\n            \"mov %6, %%\"REG_b\"    \\n\\t\"\n\n#endif\n\n            :: \"m\" (src1), \"m\" (dst), \"m\" (mmx2Filter), \"m\" (mmx2FilterPos),\n\n            \"m\" (funnyUVCode), \"m\" (src2)\n\n#if defined(PIC)\n\n            ,\"m\" (ebxsave)\n\n#endif\n\n            : \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S, \"%\"REG_D\n\n#if !defined(PIC)\n\n             ,\"%\"REG_b\n\n#endif\n\n            );\n\n            for (i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--)\n\n            {\n\n                //printf(\"%d %d %d\\n\", dstWidth, i, srcW);\n\n                dst[i] = src1[srcW-1]*128;\n\n                dst[i+VOFW] = src2[srcW-1]*128;\n\n            }\n\n        }\n\n        else\n\n        {\n\n#endif /* HAVE_MMX2 */\n\n            long xInc_shr16 = (long) (xInc >> 16);\n\n            uint16_t xInc_mask = xInc & 0xffff;\n\n            asm volatile(\n\n            \"xor %%\"REG_a\", %%\"REG_a\"               \\n\\t\" // i\n\n            \"xor %%\"REG_d\", %%\"REG_d\"               \\n\\t\" // xx\n\n            \"xorl    %%ecx, %%ecx                   \\n\\t\" // 2*xalpha\n\n            ASMALIGN(4)\n\n            \"1:                                     \\n\\t\"\n\n            \"mov        %0, %%\"REG_S\"               \\n\\t\"\n\n            \"movzbl  (%%\"REG_S\", %%\"REG_d\"), %%edi  \\n\\t\" //src[xx]\n\n            \"movzbl 1(%%\"REG_S\", %%\"REG_d\"), %%esi  \\n\\t\" //src[xx+1]\n\n            \"subl    %%edi, %%esi                   \\n\\t\" //src[xx+1] - src[xx]\n\n            \"imull   %%ecx, %%esi                   \\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n            \"shll      $16, %%edi                   \\n\\t\"\n\n            \"addl    %%edi, %%esi                   \\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n            \"mov        %1, %%\"REG_D\"               \\n\\t\"\n\n            \"shrl       $9, %%esi                   \\n\\t\"\n\n            \"movw     %%si, (%%\"REG_D\", %%\"REG_a\", 2)   \\n\\t\"\n\n\n\n            \"movzbl    (%5, %%\"REG_d\"), %%edi       \\n\\t\" //src[xx]\n\n            \"movzbl   1(%5, %%\"REG_d\"), %%esi       \\n\\t\" //src[xx+1]\n\n            \"subl    %%edi, %%esi                   \\n\\t\" //src[xx+1] - src[xx]\n\n            \"imull   %%ecx, %%esi                   \\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n            \"shll      $16, %%edi                   \\n\\t\"\n\n            \"addl    %%edi, %%esi                   \\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n            \"mov        %1, %%\"REG_D\"               \\n\\t\"\n\n            \"shrl       $9, %%esi                   \\n\\t\"\n\n            \"movw     %%si, \"AV_STRINGIFY(VOF)\"(%%\"REG_D\", %%\"REG_a\", 2)   \\n\\t\"\n\n\n\n            \"addw       %4, %%cx                    \\n\\t\" //2*xalpha += xInc&0xFF\n\n            \"adc        %3, %%\"REG_d\"               \\n\\t\" //xx+= xInc>>8 + carry\n\n            \"add        $1, %%\"REG_a\"               \\n\\t\"\n\n            \"cmp        %2, %%\"REG_a\"               \\n\\t\"\n\n            \" jb        1b                          \\n\\t\"\n\n\n\n/* GCC 3.3 makes MPlayer crash on IA-32 machines when using \"g\" operand here,\n\n   which is needed to support GCC 4.0. */\n\n#if defined(ARCH_X86_64) && ((__GNUC__ > 3) || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))\n\n            :: \"m\" (src1), \"m\" (dst), \"g\" ((long)dstWidth), \"m\" (xInc_shr16), \"m\" (xInc_mask),\n\n#else\n\n            :: \"m\" (src1), \"m\" (dst), \"m\" ((long)dstWidth), \"m\" (xInc_shr16), \"m\" (xInc_mask),\n\n#endif\n\n            \"r\" (src2)\n\n            : \"%\"REG_a, \"%\"REG_d, \"%ecx\", \"%\"REG_D, \"%esi\"\n\n            );\n\n#ifdef HAVE_MMX2\n\n        } //if MMX2 can't be used\n\n#endif\n\n#else\n\n        int i;\n\n        unsigned int xpos=0;\n\n        for (i=0;i<dstWidth;i++)\n\n        {\n\n            register unsigned int xx=xpos>>16;\n\n            register unsigned int xalpha=(xpos&0xFFFF)>>9;\n\n            dst[i]=(src1[xx]*(xalpha^127)+src1[xx+1]*xalpha);\n\n            dst[i+VOFW]=(src2[xx]*(xalpha^127)+src2[xx+1]*xalpha);\n\n            /* slower\n\n            dst[i]= (src1[xx]<<7) + (src1[xx+1] - src1[xx])*xalpha;\n\n            dst[i+VOFW]=(src2[xx]<<7) + (src2[xx+1] - src2[xx])*xalpha;\n\n            */\n\n            xpos+=xInc;\n\n        }\n\n#endif /* defined(ARCH_X86) */\n\n    }\n\n    if(c->srcRange != c->dstRange && !(isRGB(c->dstFormat) || isBGR(c->dstFormat))){\n\n        int i;\n\n        //FIXME all pal and rgb srcFormats could do this convertion as well\n\n        //FIXME all scalers more complex than bilinear could do half of this transform\n\n        if(c->srcRange){\n\n            for (i=0; i<dstWidth; i++){\n\n                dst[i     ]= (dst[i     ]*1799 + 4081085)>>11; //1469\n\n                dst[i+VOFW]= (dst[i+VOFW]*1799 + 4081085)>>11; //1469\n\n            }\n\n        }else{\n\n            for (i=0; i<dstWidth; i++){\n\n                dst[i     ]= (FFMIN(dst[i     ],30775)*4663 - 9289992)>>12; //-264\n\n                dst[i+VOFW]= (FFMIN(dst[i+VOFW],30775)*4663 - 9289992)>>12; //-264\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 24229}
{"project": "FFmpeg", "commit_id": "86dfcfd0e30d6645eea2c63c1c60a0550e7c97ea", "target": 1, "func": "static int read_kuki_chunk(AVFormatContext *s, int64_t size)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st      = s->streams[0];\n\n\n\n    if (size < 0 || size > INT_MAX - FF_INPUT_BUFFER_PADDING_SIZE)\n\n        return -1;\n\n\n\n    if (st->codec->codec_id == AV_CODEC_ID_AAC) {\n\n        /* The magic cookie format for AAC is an mp4 esds atom.\n\n           The lavc AAC decoder requires the data from the codec specific\n\n           description as extradata input. */\n\n        int strt, skip;\n\n        MOVAtom atom;\n\n\n\n        strt = avio_tell(pb);\n\n        ff_mov_read_esds(s, pb, atom);\n\n        skip = size - (avio_tell(pb) - strt);\n\n        if (skip < 0 || !st->codec->extradata ||\n\n            st->codec->codec_id != AV_CODEC_ID_AAC) {\n\n            av_log(s, AV_LOG_ERROR, \"invalid AAC magic cookie\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        avio_skip(pb, skip);\n\n    } else if (st->codec->codec_id == AV_CODEC_ID_ALAC) {\n\n#define ALAC_PREAMBLE 12\n\n#define ALAC_HEADER   36\n\n#define ALAC_NEW_KUKI 24\n\n        uint8_t preamble[12];\n\n        if (size < ALAC_NEW_KUKI) {\n\n            av_log(s, AV_LOG_ERROR, \"invalid ALAC magic cookie\\n\");\n\n            avio_skip(pb, size);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        avio_read(pb, preamble, ALAC_PREAMBLE);\n\n\n\n        st->codec->extradata = av_mallocz(ALAC_HEADER + FF_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!st->codec->extradata)\n\n            return AVERROR(ENOMEM);\n\n\n\n        /* For the old style cookie, we skip 12 bytes, then read 36 bytes.\n\n         * The new style cookie only contains the last 24 bytes of what was\n\n         * 36 bytes in the old style cookie, so we fabricate the first 12 bytes\n\n         * in that case to maintain compatibility. */\n\n        if (!memcmp(&preamble[4], \"frmaalac\", 8)) {\n\n            if (size < ALAC_PREAMBLE + ALAC_HEADER) {\n\n                av_log(s, AV_LOG_ERROR, \"invalid ALAC magic cookie\\n\");\n\n                av_freep(&st->codec->extradata);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            avio_read(pb, st->codec->extradata, ALAC_HEADER);\n\n            avio_skip(pb, size - ALAC_PREAMBLE - ALAC_HEADER);\n\n        } else {\n\n            AV_WB32(st->codec->extradata, 36);\n\n            memcpy(&st->codec->extradata[4], \"alac\", 4);\n\n            AV_WB32(&st->codec->extradata[8], 0);\n\n            memcpy(&st->codec->extradata[12], preamble, 12);\n\n            avio_read(pb, &st->codec->extradata[24], ALAC_NEW_KUKI - 12);\n\n            avio_skip(pb, size - ALAC_NEW_KUKI);\n\n        }\n\n        st->codec->extradata_size = ALAC_HEADER;\n\n    } else {\n\n        st->codec->extradata = av_mallocz(size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!st->codec->extradata)\n\n            return AVERROR(ENOMEM);\n\n        avio_read(pb, st->codec->extradata, size);\n\n        st->codec->extradata_size = size;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24230}
{"project": "FFmpeg", "commit_id": "a04c2c707de2ce850f79870e84ac9d7ec7aa9143", "target": 1, "func": "int avpriv_unlock_avformat(void)\n\n{\n\n    if (lockmgr_cb) {\n\n        if ((*lockmgr_cb)(&avformat_mutex, AV_LOCK_RELEASE))\n\n            return -1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 24232}
{"project": "FFmpeg", "commit_id": "033f1644b59abd755bb529afa5db394d18d9c30b", "target": 1, "func": "fixup_vorbis_headers(AVFormatContext * as, struct oggvorbis_private *priv,\n\n                     uint8_t **buf)\n\n{\n\n    int i,offset, len, buf_len;\n\n    unsigned char *ptr;\n\n\n\n    len = priv->len[0] + priv->len[1] + priv->len[2];\n\n    buf_len = len + len/255 + 64;\n\n    ptr = *buf = av_realloc(NULL, buf_len);\n\n\n\n    memset(*buf, '\\0', buf_len);\n\n\n\n    ptr[0] = 2;\n\n    offset = 1;\n\n    offset += av_xiphlacing(&ptr[offset], priv->len[0]);\n\n    offset += av_xiphlacing(&ptr[offset], priv->len[1]);\n\n    for (i = 0; i < 3; i++) {\n\n        memcpy(&ptr[offset], priv->packet[i], priv->len[i]);\n\n        offset += priv->len[i];\n\n        av_freep(&priv->packet[i]);\n\n    }\n\n    *buf = av_realloc(*buf, offset + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    return offset;\n\n}", "idx": 24235}
{"project": "FFmpeg", "commit_id": "073c2593c9f0aa4445a6fc1b9b24e6e52a8cc2c1", "target": 1, "func": "static int build_vlc(VLC *vlc, const uint8_t *bits_table, const uint8_t *val_table, \n\n                      int nb_codes)\n\n{\n\n    uint8_t huff_size[256];\n\n    uint16_t huff_code[256];\n\n\n\n    memset(huff_size, 0, sizeof(huff_size));\n\n    build_huffman_codes(huff_size, huff_code, bits_table, val_table);\n\n    \n\n    return init_vlc(vlc, 9, nb_codes, huff_size, 1, 1, huff_code, 2, 2);\n\n}\n", "idx": 24239}
{"project": "FFmpeg", "commit_id": "b90912be6802dc64bcd6cd808961f9e0a0f7f6ed", "target": 1, "func": "static int lavfi_read_packet(AVFormatContext *avctx, AVPacket *pkt)\n\n{\n\n    LavfiContext *lavfi = avctx->priv_data;\n\n    double min_pts = DBL_MAX;\n\n    int stream_idx, min_pts_sink_idx = 0;\n\n    AVFilterBufferRef *ref;\n\n    AVPicture pict;\n\n    int ret, i;\n\n    int size = 0;\n\n\n\n    /* iterate through all the graph sinks. Select the sink with the\n\n     * minimum PTS */\n\n    for (i = 0; i < avctx->nb_streams; i++) {\n\n        AVRational tb = lavfi->sinks[i]->inputs[0]->time_base;\n\n        double d;\n\n        int ret;\n\n\n\n        if (lavfi->sink_eof[i])\n\n            continue;\n\n\n\n        ret = av_buffersink_get_buffer_ref(lavfi->sinks[i],\n\n                                       &ref, AV_BUFFERSINK_FLAG_PEEK);\n\n        if (ret == AVERROR_EOF) {\n\n            av_dlog(avctx, \"EOF sink_idx:%d\\n\", i);\n\n            lavfi->sink_eof[i] = 1;\n\n            continue;\n\n        } else if (ret < 0)\n\n            return ret;\n\n        d = av_rescale_q(ref->pts, tb, AV_TIME_BASE_Q);\n\n        av_dlog(avctx, \"sink_idx:%d time:%f\\n\", i, d);\n\n\n\n        if (d < min_pts) {\n\n            min_pts = d;\n\n            min_pts_sink_idx = i;\n\n        }\n\n    }\n\n    if (min_pts == DBL_MAX)\n\n        return AVERROR_EOF;\n\n\n\n    av_dlog(avctx, \"min_pts_sink_idx:%i\\n\", min_pts_sink_idx);\n\n\n\n    av_buffersink_get_buffer_ref(lavfi->sinks[min_pts_sink_idx], &ref, 0);\n\n    stream_idx = lavfi->sink_stream_map[min_pts_sink_idx];\n\n\n\n    if (ref->video) {\n\n        size = avpicture_get_size(ref->format, ref->video->w, ref->video->h);\n\n        if ((ret = av_new_packet(pkt, size)) < 0)\n\n            return ret;\n\n\n\n        memcpy(pict.data,     ref->data,     4*sizeof(ref->data[0]));\n\n        memcpy(pict.linesize, ref->linesize, 4*sizeof(ref->linesize[0]));\n\n\n\n        avpicture_layout(&pict, ref->format, ref->video->w,\n\n                         ref->video->h, pkt->data, size);\n\n    } else if (ref->audio) {\n\n        size = ref->audio->nb_samples *\n\n            av_get_bytes_per_sample(ref->format) *\n\n            av_get_channel_layout_nb_channels(ref->audio->channel_layout);\n\n        if ((ret = av_new_packet(pkt, size)) < 0)\n\n            return ret;\n\n        memcpy(pkt->data, ref->data[0], size);\n\n    }\n\n\n\n    if (ref->metadata) {\n\n        uint8_t *metadata;\n\n        AVDictionaryEntry *e = NULL;\n\n        AVBPrint meta_buf;\n\n\n\n        av_bprint_init(&meta_buf, 0, AV_BPRINT_SIZE_UNLIMITED);\n\n        while ((e = av_dict_get(ref->metadata, \"\", e, AV_DICT_IGNORE_SUFFIX))) {\n\n            av_bprintf(&meta_buf, \"%s\", e->key);\n\n            av_bprint_chars(&meta_buf, '\\0', 1);\n\n            av_bprintf(&meta_buf, \"%s\", e->value);\n\n            av_bprint_chars(&meta_buf, '\\0', 1);\n\n        }\n\n        if (!av_bprint_is_complete(&meta_buf) ||\n\n            !(metadata = av_packet_new_side_data(pkt, AV_PKT_DATA_STRINGS_METADATA,\n\n                                                 meta_buf.len))) {\n\n            av_bprint_finalize(&meta_buf, NULL);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        memcpy(metadata, meta_buf.str, meta_buf.len);\n\n        av_bprint_finalize(&meta_buf, NULL);\n\n    }\n\n\n\n    pkt->stream_index = stream_idx;\n\n    pkt->pts = ref->pts;\n\n    pkt->pos = ref->pos;\n\n    pkt->size = size;\n\n    avfilter_unref_buffer(ref);\n\n    return size;\n\n}\n", "idx": 24240}
{"project": "FFmpeg", "commit_id": "7fb92be7e50ea4ba5712804326c6814ae02dd190", "target": 1, "func": "static inline void qtrle_decode_2n4bpp(QtrleContext *s, int stream_ptr,\n\n                             int row_ptr, int lines_to_change, int bpp)\n\n{\n\n    int rle_code, i;\n\n    int pixel_ptr;\n\n    int row_inc = s->frame.linesize[0];\n\n    unsigned char pi[16];  /* 16 palette indices */\n\n    unsigned char *rgb = s->frame.data[0];\n\n    int pixel_limit = s->frame.linesize[0] * s->avctx->height;\n\n    int num_pixels = (bpp == 4) ? 8 : 16;\n\n\n\n    while (lines_to_change--) {\n\n        CHECK_STREAM_PTR(2);\n\n        pixel_ptr = row_ptr + (num_pixels * (s->buf[stream_ptr++] - 1));\n\n\n\n\n        while ((rle_code = (signed char)s->buf[stream_ptr++]) != -1) {\n\n            if (rle_code == 0) {\n\n                /* there's another skip code in the stream */\n\n                CHECK_STREAM_PTR(1);\n\n                pixel_ptr += (num_pixels * (s->buf[stream_ptr++] - 1));\n\n\n            } else if (rle_code < 0) {\n\n                /* decode the run length code */\n\n                rle_code = -rle_code;\n\n                /* get the next 4 bytes from the stream, treat them as palette\n\n                 * indexes, and output them rle_code times */\n\n                CHECK_STREAM_PTR(4);\n\n                for (i = num_pixels-1; i >= 0; i--) {\n\n                    pi[num_pixels-1-i] = (s->buf[stream_ptr] >> ((i*bpp) & 0x07)) & ((1<<bpp)-1);\n\n                    stream_ptr+= ((i & ((num_pixels>>2)-1)) == 0);\n\n                }\n\n                CHECK_PIXEL_PTR(rle_code * num_pixels);\n\n                while (rle_code--) {\n\n                    for (i = 0; i < num_pixels; i++)\n\n                        rgb[pixel_ptr++] = pi[i];\n\n                }\n\n            } else {\n\n                /* copy the same pixel directly to output 4 times */\n\n                rle_code *= 4;\n\n                CHECK_STREAM_PTR(rle_code);\n\n                CHECK_PIXEL_PTR(rle_code*(num_pixels>>2));\n\n                while (rle_code--) {\n\n                    if(bpp == 4) {\n\n                        rgb[pixel_ptr++] = ((s->buf[stream_ptr]) >> 4) & 0x0f;\n\n                        rgb[pixel_ptr++] = (s->buf[stream_ptr++]) & 0x0f;\n\n                    } else {\n\n                        rgb[pixel_ptr++] = ((s->buf[stream_ptr]) >> 6) & 0x03;\n\n                        rgb[pixel_ptr++] = ((s->buf[stream_ptr]) >> 4) & 0x03;\n\n                        rgb[pixel_ptr++] = ((s->buf[stream_ptr]) >> 2) & 0x03;\n\n                        rgb[pixel_ptr++] = (s->buf[stream_ptr++]) & 0x03;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        row_ptr += row_inc;\n\n    }\n\n}", "idx": 24241}
{"project": "FFmpeg", "commit_id": "f0da370a523d76fb5f48e58537f26a9d949e9c05", "target": 1, "func": "static void display_picref(AVFilterBufferRef *picref, AVRational time_base)\n\n{\n\n    int x, y;\n\n    uint8_t *p0, *p;\n\n    int64_t delay;\n\n\n\n    if (picref->pts != AV_NOPTS_VALUE) {\n\n        if (last_pts != AV_NOPTS_VALUE) {\n\n            /* sleep roughly the right amount of time;\n\n             * usleep is in microseconds, just like AV_TIME_BASE. */\n\n            delay = av_rescale_q(picref->pts - last_pts,\n\n                                 time_base, AV_TIME_BASE_Q);\n\n            if (delay > 0 && delay < 1000000)\n\n                usleep(delay);\n\n        }\n\n        last_pts = picref->pts;\n\n    }\n\n\n\n    /* Trivial ASCII grayscale display. */\n\n    p0 = picref->data[0];\n\n    puts(\"\\033c\");\n\n    for (y = 0; y < picref->video->h; y++) {\n\n        p = p0;\n\n        for (x = 0; x < picref->video->w; x++)\n\n            putchar(\" .-+#\"[*(p++) / 52]);\n\n        putchar('\\n');\n\n        p0 += picref->linesize[0];\n\n    }\n\n    fflush(stdout);\n\n}\n", "idx": 24242}
{"project": "FFmpeg", "commit_id": "ddfa3751c092feaf1e080f66587024689dfe603c", "target": 1, "func": "static int decode_codestream(J2kDecoderContext *s)\n\n{\n\n    J2kCodingStyle *codsty = s->codsty;\n\n    J2kQuantStyle  *qntsty = s->qntsty;\n\n    uint8_t *properties = s->properties;\n\n\n\n    for (;;){\n\n        int marker, len, ret = 0;\n\n        const uint8_t *oldbuf;\n\n        if (s->buf_end - s->buf < 2){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Missing EOC\\n\");\n\n            break;\n\n        }\n\n\n\n        marker = bytestream_get_be16(&s->buf);\n\n        if(s->avctx->debug & FF_DEBUG_STARTCODE)\n\n            av_log(s->avctx, AV_LOG_DEBUG, \"marker 0x%.4X at pos 0x%tx\\n\", marker, s->buf - s->buf_start - 4);\n\n        oldbuf = s->buf;\n\n\n\n        if (marker == J2K_SOD){\n\n            J2kTile *tile = s->tile + s->curtileno;\n\n            if (ret = init_tile(s, s->curtileno))\n\n                return ret;\n\n            if (ret = decode_packets(s, tile))\n\n                return ret;\n\n            continue;\n\n        }\n\n        if (marker == J2K_EOC)\n\n            break;\n\n\n\n        if (s->buf_end - s->buf < 2)\n\n            return AVERROR(EINVAL);\n\n        len = bytestream_get_be16(&s->buf);\n\n        switch(marker){\n\n            case J2K_SIZ:\n\n                ret = get_siz(s); break;\n\n            case J2K_COC:\n\n                ret = get_coc(s, codsty, properties); break;\n\n            case J2K_COD:\n\n                ret = get_cod(s, codsty, properties); break;\n\n            case J2K_QCC:\n\n                ret = get_qcc(s, len, qntsty, properties); break;\n\n            case J2K_QCD:\n\n                ret = get_qcd(s, len, qntsty, properties); break;\n\n            case J2K_SOT:\n\n                if (!(ret = get_sot(s))){\n\n                    codsty = s->tile[s->curtileno].codsty;\n\n                    qntsty = s->tile[s->curtileno].qntsty;\n\n                    properties = s->tile[s->curtileno].properties;\n\n                }\n\n                break;\n\n            case J2K_COM:\n\n                // the comment is ignored\n\n                s->buf += len - 2; break;\n\n            default:\n\n                av_log(s->avctx, AV_LOG_ERROR, \"unsupported marker 0x%.4X at pos 0x%tx\\n\", marker, s->buf - s->buf_start - 4);\n\n                s->buf += len - 2; break;\n\n        }\n\n        if (s->buf - oldbuf != len || ret){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"error during processing marker segment %.4x\\n\", marker);\n\n            return ret ? ret : -1;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 24244}
{"project": "FFmpeg", "commit_id": "361e0310d95bf2a0377f168518d1135ae15ca3f8", "target": 1, "func": "static int read_channel_params(MLPDecodeContext *m, unsigned int substr,\n\n                               GetBitContext *gbp, unsigned int ch)\n\n{\n\n    SubStream *s = &m->substream[substr];\n\n    ChannelParams *cp = &s->channel_params[ch];\n\n    FilterParams *fir = &cp->filter_params[FIR];\n\n    FilterParams *iir = &cp->filter_params[IIR];\n\n    int ret;\n\n\n\n    if (s->param_presence_flags & PARAM_FIR)\n\n        if (get_bits1(gbp))\n\n            if ((ret = read_filter_params(m, gbp, substr, ch, FIR)) < 0)\n\n                return ret;\n\n\n\n    if (s->param_presence_flags & PARAM_IIR)\n\n        if (get_bits1(gbp))\n\n            if ((ret = read_filter_params(m, gbp, substr, ch, IIR)) < 0)\n\n                return ret;\n\n\n\n    if (fir->order + iir->order > 8) {\n\n        av_log(m->avctx, AV_LOG_ERROR, \"Total filter orders too high.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (fir->order && iir->order &&\n\n        fir->shift != iir->shift) {\n\n        av_log(m->avctx, AV_LOG_ERROR,\n\n                \"FIR and IIR filters must use the same precision.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    /* The FIR and IIR filters must have the same precision.\n\n     * To simplify the filtering code, only the precision of the\n\n     * FIR filter is considered. If only the IIR filter is employed,\n\n     * the FIR filter precision is set to that of the IIR filter, so\n\n     * that the filtering code can use it. */\n\n    if (!fir->order && iir->order)\n\n        fir->shift = iir->shift;\n\n\n\n    if (s->param_presence_flags & PARAM_HUFFOFFSET)\n\n        if (get_bits1(gbp))\n\n            cp->huff_offset = get_sbits(gbp, 15);\n\n\n\n    cp->codebook  = get_bits(gbp, 2);\n\n    cp->huff_lsbs = get_bits(gbp, 5);\n\n\n\n    if (cp->huff_lsbs > 24) {\n\n        av_log(m->avctx, AV_LOG_ERROR, \"Invalid huff_lsbs.\\n\");\n\n        cp->huff_lsbs = 0;\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    cp->sign_huff_offset = calculate_sign_huff(m, substr, ch);\n\n\n\n    return 0;\n\n}\n", "idx": 24246}
{"project": "FFmpeg", "commit_id": "b2c2589ecf87e6d42d4134e726552a35b2820e09", "target": 1, "func": "static int wsvqa_read_packet(AVFormatContext *s,\n\n                             AVPacket *pkt)\n\n{\n\n    WsVqaDemuxContext *wsvqa = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int ret = -1;\n\n    unsigned char preamble[VQA_PREAMBLE_SIZE];\n\n    unsigned int chunk_type;\n\n    unsigned int chunk_size;\n\n    int skip_byte;\n\n\n\n    while (avio_read(pb, preamble, VQA_PREAMBLE_SIZE) == VQA_PREAMBLE_SIZE) {\n\n        chunk_type = AV_RB32(&preamble[0]);\n\n        chunk_size = AV_RB32(&preamble[4]);\n\n\n\n        skip_byte = chunk_size & 0x01;\n\n\n\n        if ((chunk_type == SND0_TAG) || (chunk_type == SND1_TAG) ||\n\n            (chunk_type == SND2_TAG) || (chunk_type == VQFR_TAG)) {\n\n\n\n            ret= av_get_packet(pb, pkt, chunk_size);\n\n            if (ret<0)\n\n                return AVERROR(EIO);\n\n\n\n            switch (chunk_type) {\n\n            case SND0_TAG:\n\n            case SND1_TAG:\n\n            case SND2_TAG:\n\n                if (wsvqa->audio_stream_index == -1) {\n\n                    AVStream *st = avformat_new_stream(s, NULL);\n\n                    if (!st)\n\n                        return AVERROR(ENOMEM);\n\n\n\n                    wsvqa->audio_stream_index = st->index;\n\n                    if (!wsvqa->sample_rate)\n\n                        wsvqa->sample_rate = 22050;\n\n                    if (!wsvqa->channels)\n\n                        wsvqa->channels = 1;\n\n                    if (!wsvqa->bps)\n\n                        wsvqa->bps = 8;\n\n                    st->codec->sample_rate = wsvqa->sample_rate;\n\n                    st->codec->bits_per_coded_sample = wsvqa->bps;\n\n                    st->codec->channels = wsvqa->channels;\n\n                    st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n\n\n                    avpriv_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n\n\n                    switch (chunk_type) {\n\n                    case SND0_TAG:\n\n                        if (wsvqa->bps == 16)\n\n                            st->codec->codec_id = AV_CODEC_ID_PCM_S16LE;\n\n                        else\n\n                            st->codec->codec_id = AV_CODEC_ID_PCM_U8;\n\n                        break;\n\n                    case SND1_TAG:\n\n                        st->codec->codec_id = AV_CODEC_ID_WESTWOOD_SND1;\n\n                        break;\n\n                    case SND2_TAG:\n\n                        st->codec->codec_id = AV_CODEC_ID_ADPCM_IMA_WS;\n\n                        st->codec->extradata_size = 2;\n\n                        st->codec->extradata = av_mallocz(2 + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                        if (!st->codec->extradata)\n\n                            return AVERROR(ENOMEM);\n\n                        AV_WL16(st->codec->extradata, wsvqa->version);\n\n                        break;\n\n                    }\n\n                }\n\n\n\n                pkt->stream_index = wsvqa->audio_stream_index;\n\n                switch (chunk_type) {\n\n                case SND1_TAG:\n\n                    /* unpacked size is stored in header */\n\n                    pkt->duration = AV_RL16(pkt->data) / wsvqa->channels;\n\n                    break;\n\n                case SND2_TAG:\n\n                    /* 2 samples/byte, 1 or 2 samples per frame depending on stereo */\n\n                    pkt->duration = (chunk_size * 2) / wsvqa->channels;\n\n                    break;\n\n                }\n\n                break;\n\n            case VQFR_TAG:\n\n                pkt->stream_index = wsvqa->video_stream_index;\n\n                pkt->duration = 1;\n\n                break;\n\n            }\n\n\n\n            /* stay on 16-bit alignment */\n\n            if (skip_byte)\n\n                avio_skip(pb, 1);\n\n\n\n            return ret;\n\n        } else {\n\n            switch(chunk_type){\n\n            case CMDS_TAG:\n\n                break;\n\n            default:\n\n                av_log(s, AV_LOG_INFO, \"Skipping unknown chunk 0x%08X\\n\", chunk_type);\n\n            }\n\n            avio_skip(pb, chunk_size + skip_byte);\n\n        }\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 24247}
{"project": "FFmpeg", "commit_id": "61af627d56c785650ac3d235f6356ee3bc5676ee", "target": 0, "func": "static int create_filter(AVFilterContext **filt_ctx, AVFilterGraph *ctx, int index,\n\n                         const char *filt_name, const char *args, void *log_ctx)\n\n{\n\n    AVFilter *filt;\n\n    char inst_name[30];\n\n    char tmp_args[256];\n\n    int ret;\n\n\n\n    snprintf(inst_name, sizeof(inst_name), \"Parsed_%s_%d\", filt_name, index);\n\n\n\n    filt = avfilter_get_by_name(filt_name);\n\n\n\n    if (!filt) {\n\n        av_log(log_ctx, AV_LOG_ERROR,\n\n               \"No such filter: '%s'\\n\", filt_name);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    *filt_ctx = avfilter_graph_alloc_filter(ctx, filt, inst_name);\n\n    if (!*filt_ctx) {\n\n        av_log(log_ctx, AV_LOG_ERROR,\n\n               \"Error creating filter '%s'\\n\", filt_name);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    if (!strcmp(filt_name, \"scale\") && args && !strstr(args, \"flags\") &&\n\n        ctx->scale_sws_opts) {\n\n        snprintf(tmp_args, sizeof(tmp_args), \"%s:%s\",\n\n                 args, ctx->scale_sws_opts);\n\n        args = tmp_args;\n\n    }\n\n\n\n    ret = avfilter_init_str(*filt_ctx, args);\n\n    if (ret < 0) {\n\n        av_log(log_ctx, AV_LOG_ERROR,\n\n               \"Error initializing filter '%s'\", filt_name);\n\n        if (args)\n\n            av_log(log_ctx, AV_LOG_ERROR, \" with args '%s'\", args);\n\n        av_log(log_ctx, AV_LOG_ERROR, \"\\n\");\n\n        return ret;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24248}
{"project": "FFmpeg", "commit_id": "224944895efe6ac23e3b8f9d35abfee9f5c6c440", "target": 0, "func": "static void flush_packet(AVFormatContext *ctx, int stream_index, \n\n                         int64_t pts, int64_t dts, int64_t scr)\n\n{\n\n    MpegMuxContext *s = ctx->priv_data;\n\n    StreamInfo *stream = ctx->streams[stream_index]->priv_data;\n\n    uint8_t *buf_ptr;\n\n    int size, payload_size, startcode, id, stuffing_size, i, header_len;\n\n    int packet_size;\n\n    uint8_t buffer[128];\n\n    int zero_trail_bytes = 0;\n\n    int pad_packet_bytes = 0;\n\n    \n\n    id = stream->id;\n\n    \n\n#if 0\n\n    printf(\"packet ID=%2x PTS=%0.3f\\n\", \n\n           id, pts / 90000.0);\n\n#endif\n\n\n\n    buf_ptr = buffer;\n\n\n\n    if (((s->packet_number % s->pack_header_freq) == 0)) {\n\n        /* output pack and systems header if needed */\n\n        size = put_pack_header(ctx, buf_ptr, scr);\n\n        buf_ptr += size;\n\n\n\n        if (s->is_vcd) {\n\n            /* there is exactly one system header for each stream in a VCD MPEG,\n\n               One in the very first video packet and one in the very first\n\n               audio packet (see VCD standard p. IV-7 and IV-8).*/\n\n            \n\n            if (stream->packet_number==0) {\n\n                size = put_system_header(ctx, buf_ptr, id);\n\n                buf_ptr += size;\n\n            }\n\n        } else {\n\n            if ((s->packet_number % s->system_header_freq) == 0) {\n\n                size = put_system_header(ctx, buf_ptr, 0);\n\n                buf_ptr += size;\n\n            }\n\n        }\n\n    }\n\n    size = buf_ptr - buffer;\n\n    put_buffer(&ctx->pb, buffer, size);\n\n\n\n    packet_size = s->packet_size - size;\n\n\n\n    if (s->is_vcd && id == AUDIO_ID)\n\n        /* The VCD standard demands that 20 zero bytes follow\n\n           each audio pack (see standard p. IV-8).*/\n\n        zero_trail_bytes += 20;\n\n            \n\n    if (s->is_vcd && stream->packet_number==0) {\n\n        /* the first pack of each stream contains only the pack header,\n\n           the system header and lots of padding (see VCD standard p. IV-6).\n\n           In the case of an audio pack, 20 zero bytes are also added at\n\n           the end.*/\n\n        pad_packet_bytes = packet_size - zero_trail_bytes;\n\n    }\n\n\n\n    packet_size -= pad_packet_bytes + zero_trail_bytes;\n\n\n\n    if (packet_size > 0) {\n\n\n\n        /* packet header size */\n\n        packet_size -= 6;\n\n        \n\n        /* packet header */\n\n        if (s->is_mpeg2) {\n\n            header_len = 3;\n\n        } else {\n\n            header_len = 0;\n\n        }\n\n        if (pts != AV_NOPTS_VALUE) {\n\n            if (dts != pts)\n\n                header_len += 5 + 5;\n\n            else\n\n                header_len += 5;\n\n        } else {\n\n            if (!s->is_mpeg2)\n\n                header_len++;\n\n        }\n\n\n\n        payload_size = packet_size - header_len;\n\n        if (id < 0xc0) {\n\n            startcode = PRIVATE_STREAM_1;\n\n            payload_size -= 4;\n\n            if (id >= 0xa0)\n\n                payload_size -= 3;\n\n        } else {\n\n            startcode = 0x100 + id;\n\n        }\n\n\n\n        stuffing_size = payload_size - stream->buffer_ptr;\n\n        if (stuffing_size < 0)\n\n            stuffing_size = 0;\n\n        put_be32(&ctx->pb, startcode);\n\n\n\n        put_be16(&ctx->pb, packet_size);\n\n        \n\n        if (!s->is_mpeg2)\n\n            for(i=0;i<stuffing_size;i++)\n\n                put_byte(&ctx->pb, 0xff);\n\n\n\n        if (s->is_mpeg2) {\n\n            put_byte(&ctx->pb, 0x80); /* mpeg2 id */\n\n\n\n            if (pts != AV_NOPTS_VALUE) {\n\n                if (dts != pts) {\n\n                    put_byte(&ctx->pb, 0xc0); /* flags */\n\n                    put_byte(&ctx->pb, header_len - 3 + stuffing_size);\n\n                    put_timestamp(&ctx->pb, 0x03, pts);\n\n                    put_timestamp(&ctx->pb, 0x01, dts);\n\n                } else {\n\n                    put_byte(&ctx->pb, 0x80); /* flags */\n\n                    put_byte(&ctx->pb, header_len - 3 + stuffing_size);\n\n                    put_timestamp(&ctx->pb, 0x02, pts);\n\n                }\n\n            } else {\n\n                put_byte(&ctx->pb, 0x00); /* flags */\n\n                put_byte(&ctx->pb, header_len - 3 + stuffing_size);\n\n            }\n\n        } else {\n\n            if (pts != AV_NOPTS_VALUE) {\n\n                if (dts != pts) {\n\n                    put_timestamp(&ctx->pb, 0x03, pts);\n\n                    put_timestamp(&ctx->pb, 0x01, dts);\n\n                } else {\n\n                    put_timestamp(&ctx->pb, 0x02, pts);\n\n                }\n\n            } else {\n\n                put_byte(&ctx->pb, 0x0f);\n\n            }\n\n        }\n\n\n\n        if (startcode == PRIVATE_STREAM_1) {\n\n            put_byte(&ctx->pb, id);\n\n            if (id >= 0xa0) {\n\n                /* LPCM (XXX: check nb_frames) */\n\n                put_byte(&ctx->pb, 7);\n\n                put_be16(&ctx->pb, 4); /* skip 3 header bytes */\n\n                put_byte(&ctx->pb, stream->lpcm_header[0]);\n\n                put_byte(&ctx->pb, stream->lpcm_header[1]);\n\n                put_byte(&ctx->pb, stream->lpcm_header[2]);\n\n            } else {\n\n                /* AC3 */\n\n                put_byte(&ctx->pb, stream->nb_frames);\n\n                put_be16(&ctx->pb, stream->frame_start_offset);\n\n            }\n\n        }\n\n\n\n        if (s->is_mpeg2)\n\n            for(i=0;i<stuffing_size;i++)\n\n                put_byte(&ctx->pb, 0xff);\n\n\n\n        /* output data */\n\n        put_buffer(&ctx->pb, stream->buffer, payload_size - stuffing_size);\n\n    }\n\n\n\n    if (pad_packet_bytes > 0)\n\n        put_padding_packet(ctx,&ctx->pb, pad_packet_bytes);    \n\n\n\n    for(i=0;i<zero_trail_bytes;i++)\n\n        put_byte(&ctx->pb, 0x00);\n\n        \n\n    put_flush_packet(&ctx->pb);\n\n    \n\n    s->packet_number++;\n\n    stream->packet_number++;\n\n    stream->nb_frames = 0;\n\n    stream->frame_start_offset = 0;\n\n}\n", "idx": 24249}
{"project": "FFmpeg", "commit_id": "dcc39ee10e82833ce24aa57926c00ffeb1948198", "target": 0, "func": "void ff_xvmc_init_block(MpegEncContext *s)\n\n{\n\n    struct xvmc_pix_fmt *render = (struct xvmc_pix_fmt*)s->current_picture.f->data[2];\n\n    assert(render && render->xvmc_id == AV_XVMC_ID);\n\n\n\n    s->block = (int16_t (*)[64])(render->data_blocks + render->next_free_data_block_num * 64);\n\n}\n", "idx": 24250}
{"project": "FFmpeg", "commit_id": "0d21a84605bad4e75dacb8196e5859902ed36f01", "target": 0, "func": "static inline int small_diamond_search4MV(MpegEncContext * s, int *best, int dmin,\n\n                                       UINT8 *new_pic, UINT8 *old_pic, int pic_stride,\n\n                                       int pred_x, int pred_y, UINT16 *mv_penalty, int quant,\n\n                                       int xmin, int ymin, int xmax, int ymax, int shift)\n\n{\n\n    int next_dir=-1;\n\n\n\n    for(;;){\n\n        int d;\n\n        const int dir= next_dir;\n\n        const int x= best[0];\n\n        const int y= best[1];\n\n        next_dir=-1;\n\n\n\n//printf(\"%d\", dir);\n\n        if(dir!=2 && x>xmin) CHECK_MV4_DIR(x-1, y  , 0)\n\n        if(dir!=3 && y>ymin) CHECK_MV4_DIR(x  , y-1, 1)\n\n        if(dir!=0 && x<xmax) CHECK_MV4_DIR(x+1, y  , 2)\n\n        if(dir!=1 && y<ymax) CHECK_MV4_DIR(x  , y+1, 3)\n\n\n\n        if(next_dir==-1){\n\n            return dmin;\n\n        }\n\n    }\n\n}\n", "idx": 24251}
{"project": "FFmpeg", "commit_id": "0d21a84605bad4e75dacb8196e5859902ed36f01", "target": 0, "func": "static inline void set_p_mv_tables(MpegEncContext * s, int mx, int my)\n\n{\n\n    const int xy= s->mb_x + 1 + (s->mb_y + 1)*(s->mb_width + 2);\n\n    \n\n    s->p_mv_table[xy][0] = mx;\n\n    s->p_mv_table[xy][1] = my;\n\n\n\n    /* has allready been set to the 4 MV if 4MV is done */\n\n    if(!(s->flags&CODEC_FLAG_4MV)){\n\n        int mot_xy= s->block_index[0];\n\n\n\n        s->motion_val[mot_xy  ][0]= mx;\n\n        s->motion_val[mot_xy  ][1]= my;\n\n        s->motion_val[mot_xy+1][0]= mx;\n\n        s->motion_val[mot_xy+1][1]= my;\n\n\n\n        mot_xy += s->block_wrap[0];\n\n        s->motion_val[mot_xy  ][0]= mx;\n\n        s->motion_val[mot_xy  ][1]= my;\n\n        s->motion_val[mot_xy+1][0]= mx;\n\n        s->motion_val[mot_xy+1][1]= my;\n\n    }\n\n}\n", "idx": 24252}
{"project": "FFmpeg", "commit_id": "9f61abc8111c7c43f49ca012e957a108b9cc7610", "target": 0, "func": "static int hds_flush(AVFormatContext *s, OutputStream *os, int final,\n\n                     int64_t end_ts)\n\n{\n\n    HDSContext *c = s->priv_data;\n\n    int i, ret = 0;\n\n    char target_filename[1024];\n\n    int index = s->streams[os->first_stream]->id;\n\n\n\n    if (!os->packets_written)\n\n        return 0;\n\n\n\n    avio_flush(os->ctx->pb);\n\n    os->packets_written = 0;\n\n    close_file(os);\n\n\n\n    snprintf(target_filename, sizeof(target_filename),\n\n             \"%s/stream%dSeg1-Frag%d\", s->filename, index, os->fragment_index);\n\n    ret = ff_rename(os->temp_filename, target_filename);\n\n    if (ret < 0)\n\n        return ret;\n\n    add_fragment(os, target_filename, os->frag_start_ts, end_ts - os->frag_start_ts);\n\n\n\n    if (!final) {\n\n        ret = init_file(s, os, end_ts);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    if (c->window_size || (final && c->remove_at_exit)) {\n\n        int remove = os->nb_fragments - c->window_size - c->extra_window_size;\n\n        if (final && c->remove_at_exit)\n\n            remove = os->nb_fragments;\n\n        if (remove > 0) {\n\n            for (i = 0; i < remove; i++) {\n\n                unlink(os->fragments[i]->file);\n\n                av_free(os->fragments[i]);\n\n            }\n\n            os->nb_fragments -= remove;\n\n            memmove(os->fragments, os->fragments + remove,\n\n                    os->nb_fragments * sizeof(*os->fragments));\n\n        }\n\n    }\n\n\n\n    if (ret >= 0)\n\n        ret = write_abst(s, os, final);\n\n    return ret;\n\n}\n", "idx": 24253}
{"project": "FFmpeg", "commit_id": "74853ed3f845212f4092e7b7e89dc2262926f4f5", "target": 1, "func": "static void init_input_filter(FilterGraph *fg, AVFilterInOut *in)\n\n{\n\n    InputStream *ist;\n\n    enum AVMediaType type = avfilter_pad_get_type(in->filter_ctx->input_pads, in->pad_idx);\n\n    int i;\n\n\n\n    // TODO: support other filter types\n\n    if (type != AVMEDIA_TYPE_VIDEO && type != AVMEDIA_TYPE_AUDIO) {\n\n        av_log(NULL, AV_LOG_FATAL, \"Only video and audio filters supported \"\n\n               \"currently.\\n\");\n\n        exit_program(1);\n\n    }\n\n\n\n    if (in->name) {\n\n        AVFormatContext *s;\n\n        AVStream       *st = NULL;\n\n        char *p;\n\n        int file_idx = strtol(in->name, &p, 0);\n\n\n\n        if (file_idx < 0 || file_idx >= nb_input_files) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Invalid file index %d in filtegraph description %s.\\n\",\n\n                   file_idx, fg->graph_desc);\n\n            exit_program(1);\n\n        }\n\n        s = input_files[file_idx]->ctx;\n\n\n\n        for (i = 0; i < s->nb_streams; i++) {\n\n            if (s->streams[i]->codec->codec_type != type)\n\n                continue;\n\n            if (check_stream_specifier(s, s->streams[i], *p == ':' ? p + 1 : p) == 1) {\n\n                st = s->streams[i];\n\n                break;\n\n            }\n\n        }\n\n        if (!st) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Stream specifier '%s' in filtergraph description %s \"\n\n                   \"matches no streams.\\n\", p, fg->graph_desc);\n\n            exit_program(1);\n\n        }\n\n        ist = input_streams[input_files[file_idx]->ist_index + st->index];\n\n    } else {\n\n        /* find the first unused stream of corresponding type */\n\n        for (i = 0; i < nb_input_streams; i++) {\n\n            ist = input_streams[i];\n\n            if (ist->st->codec->codec_type == type && ist->discard)\n\n                break;\n\n        }\n\n        if (i == nb_input_streams) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Cannot find a matching stream for \"\n\n                   \"unlabeled input pad %d on filter %s\", in->pad_idx,\n\n                   in->filter_ctx->name);\n\n            exit_program(1);\n\n        }\n\n    }\n\n    ist->discard         = 0;\n\n    ist->decoding_needed = 1;\n\n    ist->st->discard = AVDISCARD_NONE;\n\n\n\n    fg->inputs = grow_array(fg->inputs, sizeof(*fg->inputs),\n\n                            &fg->nb_inputs, fg->nb_inputs + 1);\n\n    if (!(fg->inputs[fg->nb_inputs - 1] = av_mallocz(sizeof(*fg->inputs[0]))))\n\n        exit_program(1);\n\n    fg->inputs[fg->nb_inputs - 1]->ist   = ist;\n\n    fg->inputs[fg->nb_inputs - 1]->graph = fg;\n\n\n\n    ist->filters = grow_array(ist->filters, sizeof(*ist->filters),\n\n                              &ist->nb_filters, ist->nb_filters + 1);\n\n    ist->filters[ist->nb_filters - 1] = fg->inputs[fg->nb_inputs - 1];\n\n}\n", "idx": 24255}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(yuy2ToY)(uint8_t *dst, uint8_t *src, int width)\n\n{\n\n#ifdef HAVE_MMX\n\n\tasm volatile(\n\n\t\t\"movq \"MANGLE(bm01010101)\", %%mm2\\n\\t\"\n\n\t\t\"mov %0, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\"movq (%1, %%\"REG_a\",2), %%mm0\t\\n\\t\"\n\n\t\t\"movq 8(%1, %%\"REG_a\",2), %%mm1\t\\n\\t\"\n\n\t\t\"pand %%mm2, %%mm0\t\t\\n\\t\"\n\n\t\t\"pand %%mm2, %%mm1\t\t\\n\\t\"\n\n\t\t\"packuswb %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\"movq %%mm0, (%2, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\"add $8, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\" js 1b\t\t\t\t\\n\\t\"\n\n\t\t: : \"g\" ((long)-width), \"r\" (src+width*2), \"r\" (dst+width)\n\n\t\t: \"%\"REG_a\n\n\t);\n\n#else\n\n\tint i;\n\n\tfor(i=0; i<width; i++)\n\n\t\tdst[i]= src[2*i];\n\n#endif\n\n}\n", "idx": 24256}
{"project": "FFmpeg", "commit_id": "a1684cf82d1aa35de0ae97724477501f92395c2b", "target": 1, "func": "av_cold void ff_msmpeg4_encode_init(MpegEncContext *s)\n\n{\n\n    static int init_done=0;\n\n    int i;\n\n\n\n    common_init(s);\n\n    if(s->msmpeg4_version>=4){\n\n        s->min_qcoeff= -255;\n\n        s->max_qcoeff=  255;\n\n    }\n\n\n\n    if (!init_done) {\n\n        /* init various encoding tables */\n\n        init_done = 1;\n\n        init_mv_table(&mv_tables[0]);\n\n        init_mv_table(&mv_tables[1]);\n\n        for(i=0;i<NB_RL_TABLES;i++)\n\n            init_rl(&rl_table[i], static_rl_table_store[i]);\n\n\n\n        for(i=0; i<NB_RL_TABLES; i++){\n\n            int level;\n\n            for(level=0; level<=MAX_LEVEL; level++){\n\n                int run;\n\n                for(run=0; run<=MAX_RUN; run++){\n\n                    int last;\n\n                    for(last=0; last<2; last++){\n\n                        rl_length[i][level][run][last]= get_size_of_code(s, &rl_table[  i], last, run, level, 0);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 24258}
{"project": "FFmpeg", "commit_id": "5f928c5201c077b9765610bc5304235c3f1d9bd6", "target": 1, "func": "av_cold void ff_init_range_decoder(RangeCoder *c, const uint8_t *buf,\n\n                                   int buf_size)\n\n{\n\n    /* cast to avoid compiler warning */\n\n    ff_init_range_encoder(c, (uint8_t *)buf, buf_size);\n\n\n\n    c->low         = AV_RB16(c->bytestream);\n\n    c->bytestream += 2;\n\n\n\n\n", "idx": 24259}
{"project": "FFmpeg", "commit_id": "8aba7968dd604aae91ee42cbce0be3dad7dceb30", "target": 1, "func": "static int vcr1_decode_frame(AVCodecContext *avctx, void *data,\n\n                             int *got_frame, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf        = avpkt->data;\n\n    int buf_size              = avpkt->size;\n\n    VCR1Context *const a      = avctx->priv_data;\n\n    AVFrame *const p          = data;\n\n    const uint8_t *bytestream = buf;\n\n    int i, x, y, ret;\n\n\n\n    if ((ret = ff_get_buffer(avctx, p, 0)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n    p->pict_type = AV_PICTURE_TYPE_I;\n\n    p->key_frame = 1;\n\n\n\n    if (buf_size < 32)\n\n        goto packet_small;\n\n\n\n    for (i = 0; i < 16; i++) {\n\n        a->delta[i] = *bytestream++;\n\n        bytestream++;\n\n        buf_size--;\n\n    }\n\n\n\n    for (y = 0; y < avctx->height; y++) {\n\n        int offset;\n\n        uint8_t *luma = &p->data[0][y * p->linesize[0]];\n\n\n\n        if ((y & 3) == 0) {\n\n            uint8_t *cb = &p->data[1][(y >> 2) * p->linesize[1]];\n\n            uint8_t *cr = &p->data[2][(y >> 2) * p->linesize[2]];\n\n\n\n            if (buf_size < 4 + avctx->width)\n\n                goto packet_small;\n\n\n\n            for (i = 0; i < 4; i++)\n\n                a->offset[i] = *bytestream++;\n\n            buf_size -= 4;\n\n\n\n            offset = a->offset[0] - a->delta[bytestream[2] & 0xF];\n\n            for (x = 0; x < avctx->width; x += 4) {\n\n                luma[0]     = offset += a->delta[bytestream[2] & 0xF];\n\n                luma[1]     = offset += a->delta[bytestream[2] >>  4];\n\n                luma[2]     = offset += a->delta[bytestream[0] & 0xF];\n\n                luma[3]     = offset += a->delta[bytestream[0] >>  4];\n\n                luma       += 4;\n\n\n\n                *cb++       = bytestream[3];\n\n                *cr++       = bytestream[1];\n\n\n\n                bytestream += 4;\n\n\n            }\n\n        } else {\n\n            if (buf_size < avctx->width / 2)\n\n                goto packet_small;\n\n\n\n            offset = a->offset[y & 3] - a->delta[bytestream[2] & 0xF];\n\n\n\n            for (x = 0; x < avctx->width; x += 8) {\n\n                luma[0]     = offset += a->delta[bytestream[2] & 0xF];\n\n                luma[1]     = offset += a->delta[bytestream[2] >>  4];\n\n                luma[2]     = offset += a->delta[bytestream[3] & 0xF];\n\n                luma[3]     = offset += a->delta[bytestream[3] >>  4];\n\n                luma[4]     = offset += a->delta[bytestream[0] & 0xF];\n\n                luma[5]     = offset += a->delta[bytestream[0] >>  4];\n\n                luma[6]     = offset += a->delta[bytestream[1] & 0xF];\n\n                luma[7]     = offset += a->delta[bytestream[1] >>  4];\n\n                luma       += 8;\n\n                bytestream += 4;\n\n\n            }\n\n        }\n\n    }\n\n\n\n    *got_frame = 1;\n\n\n\n    return buf_size;\n\npacket_small:\n\n    av_log(avctx, AV_LOG_ERROR, \"Input packet too small.\\n\");\n\n    return AVERROR_INVALIDDATA;\n\n}", "idx": 24261}
{"project": "FFmpeg", "commit_id": "4cc2a357f5dce9bad36b59fb31ba5cf61cc56272", "target": 1, "func": "static void sbr_hf_inverse_filter(SBRDSPContext *dsp,\n\n                                  int (*alpha0)[2], int (*alpha1)[2],\n\n                                  const int X_low[32][40][2], int k0)\n\n{\n\n    int k;\n\n    int shift, round;\n\n\n\n    for (k = 0; k < k0; k++) {\n\n        SoftFloat phi[3][2][2];\n\n        SoftFloat a00, a01, a10, a11;\n\n        SoftFloat dk;\n\n\n\n        dsp->autocorrelate(X_low[k], phi);\n\n\n\n        dk = av_sub_sf(av_mul_sf(phi[2][1][0], phi[1][0][0]),\n\n             av_mul_sf(av_add_sf(av_mul_sf(phi[1][1][0], phi[1][1][0]),\n\n             av_mul_sf(phi[1][1][1], phi[1][1][1])), FLOAT_0999999));\n\n\n\n        if (!dk.mant) {\n\n            a10 = FLOAT_0;\n\n            a11 = FLOAT_0;\n\n        } else {\n\n            SoftFloat temp_real, temp_im;\n\n            temp_real = av_sub_sf(av_sub_sf(av_mul_sf(phi[0][0][0], phi[1][1][0]),\n\n                                            av_mul_sf(phi[0][0][1], phi[1][1][1])),\n\n                                  av_mul_sf(phi[0][1][0], phi[1][0][0]));\n\n            temp_im   = av_sub_sf(av_add_sf(av_mul_sf(phi[0][0][0], phi[1][1][1]),\n\n                                            av_mul_sf(phi[0][0][1], phi[1][1][0])),\n\n                                  av_mul_sf(phi[0][1][1], phi[1][0][0]));\n\n\n\n            a10 = av_div_sf(temp_real, dk);\n\n            a11 = av_div_sf(temp_im,   dk);\n\n        }\n\n\n\n        if (!phi[1][0][0].mant) {\n\n            a00 = FLOAT_0;\n\n            a01 = FLOAT_0;\n\n        } else {\n\n            SoftFloat temp_real, temp_im;\n\n            temp_real = av_add_sf(phi[0][0][0],\n\n                                  av_add_sf(av_mul_sf(a10, phi[1][1][0]),\n\n                                            av_mul_sf(a11, phi[1][1][1])));\n\n            temp_im   = av_add_sf(phi[0][0][1],\n\n                                  av_sub_sf(av_mul_sf(a11, phi[1][1][0]),\n\n                                            av_mul_sf(a10, phi[1][1][1])));\n\n\n\n            temp_real.mant = -temp_real.mant;\n\n            temp_im.mant   = -temp_im.mant;\n\n            a00 = av_div_sf(temp_real, phi[1][0][0]);\n\n            a01 = av_div_sf(temp_im,   phi[1][0][0]);\n\n        }\n\n\n\n        shift = a00.exp;\n\n        if (shift >= 3)\n\n            alpha0[k][0] = 0x7fffffff;\n\n        else if (shift <= -30)\n\n            alpha0[k][0] = 0;\n\n        else {\n\n            a00.mant *= 2;\n\n            shift = 2-shift;\n\n            if (shift == 0)\n\n                alpha0[k][0] = a00.mant;\n\n            else {\n\n                round = 1 << (shift-1);\n\n                alpha0[k][0] = (a00.mant + round) >> shift;\n\n            }\n\n        }\n\n\n\n        shift = a01.exp;\n\n        if (shift >= 3)\n\n            alpha0[k][1] = 0x7fffffff;\n\n        else if (shift <= -30)\n\n            alpha0[k][1] = 0;\n\n        else {\n\n            a01.mant *= 2;\n\n            shift = 2-shift;\n\n            if (shift == 0)\n\n                alpha0[k][1] = a01.mant;\n\n            else {\n\n                round = 1 << (shift-1);\n\n                alpha0[k][1] = (a01.mant + round) >> shift;\n\n            }\n\n        }\n\n        shift = a10.exp;\n\n        if (shift >= 3)\n\n            alpha1[k][0] = 0x7fffffff;\n\n        else if (shift <= -30)\n\n            alpha1[k][0] = 0;\n\n        else {\n\n            a10.mant *= 2;\n\n            shift = 2-shift;\n\n            if (shift == 0)\n\n                alpha1[k][0] = a10.mant;\n\n            else {\n\n                round = 1 << (shift-1);\n\n                alpha1[k][0] = (a10.mant + round) >> shift;\n\n            }\n\n        }\n\n\n\n        shift = a11.exp;\n\n        if (shift >= 3)\n\n            alpha1[k][1] = 0x7fffffff;\n\n        else if (shift <= -30)\n\n            alpha1[k][1] = 0;\n\n        else {\n\n            a11.mant *= 2;\n\n            shift = 2-shift;\n\n            if (shift == 0)\n\n                alpha1[k][1] = a11.mant;\n\n            else {\n\n                round = 1 << (shift-1);\n\n                alpha1[k][1] = (a11.mant + round) >> shift;\n\n            }\n\n        }\n\n\n\n        shift = (int)(((int64_t)(alpha1[k][0]>>1) * (alpha1[k][0]>>1) + \\\n\n                       (int64_t)(alpha1[k][1]>>1) * (alpha1[k][1]>>1) + \\\n\n                       0x40000000) >> 31);\n\n        if (shift >= 0x20000000){\n\n            alpha1[k][0] = 0;\n\n            alpha1[k][1] = 0;\n\n            alpha0[k][0] = 0;\n\n            alpha0[k][1] = 0;\n\n        }\n\n\n\n        shift = (int)(((int64_t)(alpha0[k][0]>>1) * (alpha0[k][0]>>1) + \\\n\n                       (int64_t)(alpha0[k][1]>>1) * (alpha0[k][1]>>1) + \\\n\n                       0x40000000) >> 31);\n\n        if (shift >= 0x20000000){\n\n            alpha1[k][0] = 0;\n\n            alpha1[k][1] = 0;\n\n            alpha0[k][0] = 0;\n\n            alpha0[k][1] = 0;\n\n        }\n\n    }\n\n}\n", "idx": 24263}
{"project": "FFmpeg", "commit_id": "9f61abc8111c7c43f49ca012e957a108b9cc7610", "target": 0, "func": "static int open_in(HLSContext *c, AVIOContext **in, const char *url)\n\n{\n\n    AVDictionary *tmp = NULL;\n\n    int ret;\n\n\n\n    av_dict_copy(&tmp, c->avio_opts, 0);\n\n\n\n    ret = avio_open2(in, url, AVIO_FLAG_READ, c->interrupt_callback, &tmp);\n\n\n\n    av_dict_free(&tmp);\n\n    return ret;\n\n}\n", "idx": 24266}
{"project": "FFmpeg", "commit_id": "af165acefacd89196c003c24802fa3c494d54d3a", "target": 0, "func": "static int mov_write_trak_tag(AVIOContext *pb, MOVMuxContext *mov,\n\n                              MOVTrack *track, AVStream *st)\n\n{\n\n    int64_t pos = avio_tell(pb);\n\n    avio_wb32(pb, 0); /* size */\n\n    ffio_wfourcc(pb, \"trak\");\n\n    mov_write_tkhd_tag(pb, track, st);\n\n    if (supports_edts(mov))\n\n        mov_write_edts_tag(pb, track);  // PSP Movies and several other cases require edts box\n\n    if (track->tref_tag)\n\n        mov_write_tref_tag(pb, track);\n\n    mov_write_mdia_tag(pb, track);\n\n    if (track->mode == MODE_PSP)\n\n        mov_write_uuid_tag_psp(pb, track); // PSP Movies require this uuid box\n\n    if (track->tag == MKTAG('r','t','p',' '))\n\n        mov_write_udta_sdp(pb, track);\n\n    if (track->mode == MODE_MOV) {\n\n        if (track->enc->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            double sample_aspect_ratio = av_q2d(st->sample_aspect_ratio);\n\n            if (st->sample_aspect_ratio.num && 1.0 != sample_aspect_ratio) {\n\n                mov_write_tapt_tag(pb, track);\n\n            }\n\n        }\n\n        if (is_clcp_track(track)) {\n\n            mov_write_tapt_tag(pb, track);\n\n        }\n\n    }\n\n    return update_size(pb, pos);\n\n}\n", "idx": 24267}
{"project": "FFmpeg", "commit_id": "4bb1070c154e49d35805fbcdac9c9e92f702ef96", "target": 0, "func": "static int write_extradata(FFV1Context *f)\n\n{\n\n    RangeCoder *const c = &f->c;\n\n    uint8_t state[CONTEXT_SIZE];\n\n    int i, j, k;\n\n    uint8_t state2[32][CONTEXT_SIZE];\n\n    unsigned v;\n\n\n\n    memset(state2, 128, sizeof(state2));\n\n    memset(state, 128, sizeof(state));\n\n\n\n    f->avctx->extradata_size = 10000 + 4 +\n\n                                    (11 * 11 * 5 * 5 * 5 + 11 * 11 * 11) * 32;\n\n    f->avctx->extradata = av_malloc(f->avctx->extradata_size);\n\n    ff_init_range_encoder(c, f->avctx->extradata, f->avctx->extradata_size);\n\n    ff_build_rac_states(c, 0.05 * (1LL << 32), 256 - 8);\n\n\n\n    put_symbol(c, state, f->version, 0);\n\n    if (f->version > 2) {\n\n        if (f->version == 3)\n\n            f->minor_version = 2;\n\n        put_symbol(c, state, f->minor_version, 0);\n\n    }\n\n\n\n    put_symbol(c, state, f->ac, 0);\n\n    if (f->ac > 1)\n\n        for (i = 1; i < 256; i++)\n\n            put_symbol(c, state, f->state_transition[i] - c->one_state[i], 1);\n\n\n\n    put_symbol(c, state, f->colorspace, 0); // YUV cs type\n\n    put_symbol(c, state, f->bits_per_raw_sample, 0);\n\n    put_rac(c, state, f->chroma_planes);\n\n    put_symbol(c, state, f->chroma_h_shift, 0);\n\n    put_symbol(c, state, f->chroma_v_shift, 0);\n\n    put_rac(c, state, f->transparency);\n\n    put_symbol(c, state, f->num_h_slices - 1, 0);\n\n    put_symbol(c, state, f->num_v_slices - 1, 0);\n\n\n\n    put_symbol(c, state, f->quant_table_count, 0);\n\n    for (i = 0; i < f->quant_table_count; i++)\n\n        write_quant_tables(c, f->quant_tables[i]);\n\n\n\n    for (i = 0; i < f->quant_table_count; i++) {\n\n        for (j = 0; j < f->context_count[i] * CONTEXT_SIZE; j++)\n\n            if (f->initial_states[i] && f->initial_states[i][0][j] != 128)\n\n                break;\n\n        if (j < f->context_count[i] * CONTEXT_SIZE) {\n\n            put_rac(c, state, 1);\n\n            for (j = 0; j < f->context_count[i]; j++)\n\n                for (k = 0; k < CONTEXT_SIZE; k++) {\n\n                    int pred = j ? f->initial_states[i][j - 1][k] : 128;\n\n                    put_symbol(c, state2[k],\n\n                               (int8_t)(f->initial_states[i][j][k] - pred), 1);\n\n                }\n\n        } else {\n\n            put_rac(c, state, 0);\n\n        }\n\n    }\n\n\n\n    if (f->version > 2) {\n\n        put_symbol(c, state, f->ec, 0);\n\n    }\n\n\n\n    f->avctx->extradata_size = ff_rac_terminate(c);\n\n\n\n    v = av_crc(av_crc_get_table(AV_CRC_32_IEEE), 0,\n\n               f->avctx->extradata, f->avctx->extradata_size);\n\n    AV_WL32(f->avctx->extradata + f->avctx->extradata_size, v);\n\n    f->avctx->extradata_size += 4;\n\n\n\n    return 0;\n\n}\n", "idx": 24268}
{"project": "FFmpeg", "commit_id": "9745f19ffc9031ce480e43d7cf1053b58100d70f", "target": 0, "func": "static av_cold int ass_decode_init(AVCodecContext *avctx)\n\n{\n\n    avctx->subtitle_header = av_malloc(avctx->extradata_size);\n\n    if (!avctx->extradata)\n\n        return AVERROR(ENOMEM);\n\n    memcpy(avctx->subtitle_header, avctx->extradata, avctx->extradata_size);\n\n    avctx->subtitle_header_size = avctx->extradata_size;\n\n    return 0;\n\n}\n", "idx": 24269}
{"project": "FFmpeg", "commit_id": "499c2d41d75fdadbf65daa9eaf743f61632f14f8", "target": 0, "func": "static int mpeg4_decode_gop_header(MpegEncContext * s, GetBitContext *gb){\n\n    int hours, minutes, seconds;\n\n\n\n    if(!show_bits(gb, 18)){\n\n        av_log(s->avctx, AV_LOG_WARNING, \"GOP header invalid\\n\");\n\n        return -1;\n\n    }\n\n\n\n    hours= get_bits(gb, 5);\n\n    minutes= get_bits(gb, 6);\n\n    skip_bits1(gb);\n\n    seconds= get_bits(gb, 6);\n\n\n\n    s->time_base= seconds + 60*(minutes + 60*hours);\n\n\n\n    skip_bits1(gb);\n\n    skip_bits1(gb);\n\n\n\n    return 0;\n\n}\n", "idx": 24270}
{"project": "FFmpeg", "commit_id": "073c2593c9f0aa4445a6fc1b9b24e6e52a8cc2c1", "target": 1, "func": "static void init_vlcs(ASV1Context *a){\n\n    static int done = 0;\n\n\n\n    if (!done) {\n\n        done = 1;\n\n\n\n        init_vlc(&ccp_vlc, VLC_BITS, 17, \n\n                 &ccp_tab[0][1], 2, 1,\n\n                 &ccp_tab[0][0], 2, 1);\n\n        init_vlc(&dc_ccp_vlc, VLC_BITS, 8, \n\n                 &dc_ccp_tab[0][1], 2, 1,\n\n                 &dc_ccp_tab[0][0], 2, 1);\n\n        init_vlc(&ac_ccp_vlc, VLC_BITS, 16, \n\n                 &ac_ccp_tab[0][1], 2, 1,\n\n                 &ac_ccp_tab[0][0], 2, 1);\n\n        init_vlc(&level_vlc,  VLC_BITS, 7, \n\n                 &level_tab[0][1], 2, 1,\n\n                 &level_tab[0][0], 2, 1);\n\n        init_vlc(&asv2_level_vlc, ASV2_LEVEL_VLC_BITS, 63, \n\n                 &asv2_level_tab[0][1], 2, 1,\n\n                 &asv2_level_tab[0][0], 2, 1);\n\n    }\n\n}\n", "idx": 24271}
{"project": "FFmpeg", "commit_id": "1ca87d600bc069fe4cf497c410b4f794e88a122d", "target": 1, "func": "static int applehttp_close(URLContext *h)\n\n{\n\n    AppleHTTPContext *s = h->priv_data;\n\n\n\n    free_segment_list(s);\n\n    free_variant_list(s);\n\n    ffurl_close(s->seg_hd);\n\n    av_free(s);\n\n    return 0;\n\n}\n", "idx": 24272}
{"project": "FFmpeg", "commit_id": "55d05286696473487ce51e347985378e28c0713b", "target": 1, "func": "int swri_dither_init(SwrContext *s, enum AVSampleFormat out_fmt, enum AVSampleFormat in_fmt)\n\n{\n\n    int i;\n\n    double scale = 0;\n\n\n\n    if (s->dither.method > SWR_DITHER_TRIANGULAR_HIGHPASS && s->dither.method <= SWR_DITHER_NS)\n\n        return AVERROR(EINVAL);\n\n\n\n    out_fmt = av_get_packed_sample_fmt(out_fmt);\n\n    in_fmt  = av_get_packed_sample_fmt( in_fmt);\n\n\n\n    if(in_fmt == AV_SAMPLE_FMT_FLT || in_fmt == AV_SAMPLE_FMT_DBL){\n\n        if(out_fmt == AV_SAMPLE_FMT_S32) scale = 1.0/(1L<<31);\n\n        if(out_fmt == AV_SAMPLE_FMT_S16) scale = 1.0/(1L<<15);\n\n        if(out_fmt == AV_SAMPLE_FMT_U8 ) scale = 1.0/(1L<< 7);\n\n    }\n\n    if(in_fmt == AV_SAMPLE_FMT_S32 && out_fmt == AV_SAMPLE_FMT_S16) scale = 1L<<16;\n\n    if(in_fmt == AV_SAMPLE_FMT_S32 && out_fmt == AV_SAMPLE_FMT_U8 ) scale = 1L<<24;\n\n    if(in_fmt == AV_SAMPLE_FMT_S16 && out_fmt == AV_SAMPLE_FMT_U8 ) scale = 1L<<8;\n\n\n\n    scale *= s->dither.scale;\n\n\n\n    s->dither.ns_pos = 0;\n\n    s->dither.noise_scale=   scale;\n\n    s->dither.ns_scale   =   scale;\n\n    s->dither.ns_scale_1 = 1/scale;\n\n    memset(s->dither.ns_errors, 0, sizeof(s->dither.ns_errors));\n\n    for (i=0; filters[i].coefs; i++) {\n\n        const filter_t *f = &filters[i];\n\n        if (fabs(s->out_sample_rate - f->rate) / f->rate <= .05 && f->name == s->dither.method) {\n\n            int j;\n\n            s->dither.ns_taps = f->len;\n\n            for (j=0; j<f->len; j++)\n\n                s->dither.ns_coeffs[j] = f->coefs[j];\n\n            s->dither.ns_scale_1 *= 1 - exp(f->gain_cB * M_LN10 * 0.005) * 2 / (1<<(8*av_get_bytes_per_sample(out_fmt)));\n\n            break;\n\n        }\n\n    }\n\n    if (!filters[i].coefs && s->dither.method > SWR_DITHER_NS) {\n\n        av_log(s, AV_LOG_WARNING, \"Requested noise shaping dither not available at this sampling rate, using triangular hp dither\\n\");\n\n        s->dither.method = SWR_DITHER_TRIANGULAR_HIGHPASS;\n\n    }\n\n\n\n    av_assert0(!s->preout.count);\n\n    s->dither.noise = s->preout;\n\n    s->dither.temp  = s->preout;\n\n    if (s->dither.method > SWR_DITHER_NS) {\n\n        s->dither.noise.bps = 4;\n\n        s->dither.noise.fmt = AV_SAMPLE_FMT_FLTP;\n\n        s->dither.noise_scale = 1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24273}
{"project": "FFmpeg", "commit_id": "dd561441b1e849df7d8681c6f32af82d4088dafd", "target": 0, "func": "static void h264_v_loop_filter_luma_intra_c(uint8_t *pix, int stride, int alpha, int beta)\n\n{\n\n    h264_loop_filter_luma_intra_c(pix, stride, 1, alpha, beta);\n\n}\n", "idx": 24277}
{"project": "FFmpeg", "commit_id": "ad5807f8aa883bee5431186dc1f24c5435d722d3", "target": 1, "func": "static int wsd_read_header(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st;\n\n    int version;\n\n    uint32_t text_offset, data_offset, channel_assign;\n\n    char playback_time[AV_TIMECODE_STR_SIZE];\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avio_skip(pb, 8);\n\n    version = avio_r8(pb);\n\n    av_log(s, AV_LOG_DEBUG, \"version: %i.%i\\n\", version >> 4, version & 0xF);\n\n    avio_skip(pb, 11);\n\n\n\n    if (version < 0x10) {\n\n        text_offset = 0x80;\n\n        data_offset = 0x800;\n\n        avio_skip(pb, 8);\n\n    } else {\n\n        text_offset = avio_rb32(pb);\n\n        data_offset = avio_rb32(pb);\n\n    }\n\n\n\n    avio_skip(pb, 4);\n\n    av_timecode_make_smpte_tc_string(playback_time, avio_rb32(pb), 0);\n\n    av_dict_set(&s->metadata, \"playback_time\", playback_time, 0);\n\n\n\n    st->codecpar->codec_type  = AVMEDIA_TYPE_AUDIO;\n\n    st->codecpar->codec_id    = s->iformat->raw_codec_id;\n\n    st->codecpar->sample_rate = avio_rb32(pb) / 8;\n\n    avio_skip(pb, 4);\n\n    st->codecpar->channels    = avio_r8(pb) & 0xF;\n\n    st->codecpar->bit_rate    = st->codecpar->channels * st->codecpar->sample_rate * 8LL;\n\n    if (!st->codecpar->channels)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    avio_skip(pb, 3);\n\n    channel_assign         = avio_rb32(pb);\n\n    if (!(channel_assign & 1)) {\n\n        int i;\n\n        for (i = 1; i < 32; i++)\n\n            if (channel_assign & (1 << i))\n\n                st->codecpar->channel_layout |= wsd_to_av_channel_layoyt(s, i);\n\n    }\n\n\n\n    avio_skip(pb, 16);\n\n    if (avio_rb32(pb))\n\n       avpriv_request_sample(s, \"emphasis\");\n\n\n\n    if (avio_seek(pb, text_offset, SEEK_SET) >= 0) {\n\n        get_metadata(s, \"title\",       128);\n\n        get_metadata(s, \"composer\",    128);\n\n        get_metadata(s, \"song_writer\", 128);\n\n        get_metadata(s, \"artist\",      128);\n\n        get_metadata(s, \"album\",       128);\n\n        get_metadata(s, \"genre\",        32);\n\n        get_metadata(s, \"date\",         32);\n\n        get_metadata(s, \"location\",     32);\n\n        get_metadata(s, \"comment\",     512);\n\n        get_metadata(s, \"user\",        512);\n\n    }\n\n\n\n    return avio_seek(pb, data_offset, SEEK_SET);\n\n}\n", "idx": 24283}
{"project": "FFmpeg", "commit_id": "3faa303a47e0c3b59a53988e0f76018930c6cb1a", "target": 0, "func": "static inline void decode_subblock3(DCTELEM *dst, int code, const int is_block2, GetBitContext *gb, VLC *vlc,\n\n                                    int q_dc, int q_ac1, int q_ac2)\n\n{\n\n    int coeffs[4];\n\n\n\n    coeffs[0] = modulo_three_table[code][0];\n\n    coeffs[1] = modulo_three_table[code][1];\n\n    coeffs[2] = modulo_three_table[code][2];\n\n    coeffs[3] = modulo_three_table[code][3];\n\n    decode_coeff(dst  , coeffs[0], 3, gb, vlc, q_dc);\n\n    if(is_block2){\n\n        decode_coeff(dst+8, coeffs[1], 2, gb, vlc, q_ac1);\n\n        decode_coeff(dst+1, coeffs[2], 2, gb, vlc, q_ac1);\n\n    }else{\n\n        decode_coeff(dst+1, coeffs[1], 2, gb, vlc, q_ac1);\n\n        decode_coeff(dst+8, coeffs[2], 2, gb, vlc, q_ac1);\n\n    }\n\n    decode_coeff(dst+9, coeffs[3], 2, gb, vlc, q_ac2);\n\n}\n", "idx": 24284}
{"project": "FFmpeg", "commit_id": "e09ad5bd0de40da9ac33d86f973a85beed85cc47", "target": 0, "func": "void ff_h264_remove_all_refs(H264Context *h)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 16; i++) {\n\n        remove_long(h, i, 0);\n\n    }\n\n    assert(h->long_ref_count == 0);\n\n\n\n    ff_h264_unref_picture(h, &h->last_pic_for_ec);\n\n    if (h->short_ref_count)\n\n        ff_h264_ref_picture(h, &h->last_pic_for_ec, h->short_ref[0]);\n\n\n\n    for (i = 0; i < h->short_ref_count; i++) {\n\n        unreference_pic(h, h->short_ref[i], 0);\n\n        h->short_ref[i] = NULL;\n\n    }\n\n    h->short_ref_count = 0;\n\n\n\n    memset(h->default_ref_list, 0, sizeof(h->default_ref_list));\n\n    memset(h->ref_list, 0, sizeof(h->ref_list));\n\n}\n", "idx": 24285}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int mm_probe(AVProbeData *p)\n\n{\n\n    /* the first chunk is always the header */\n\n    if (p->buf_size < MM_PREAMBLE_SIZE)\n\n        return 0;\n\n    if (AV_RL16(&p->buf[0]) != MM_TYPE_HEADER)\n\n        return 0;\n\n    if (AV_RL32(&p->buf[2]) != MM_HEADER_LEN_V && AV_RL32(&p->buf[2]) != MM_HEADER_LEN_AV)\n\n        return 0;\n\n\n\n    /* only return half certainty since this check is a bit sketchy */\n\n    return AVPROBE_SCORE_MAX / 2;\n\n}\n", "idx": 24286}
{"project": "FFmpeg", "commit_id": "403ee835e7913eb9536b22c2b22edfdd700166a9", "target": 0, "func": "static int tcp_write_packet(AVFormatContext *s, RTSPStream *rtsp_st)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    AVFormatContext *rtpctx = rtsp_st->transport_priv;\n\n    uint8_t *buf, *ptr;\n\n    int size;\n\n    uint8_t *interleave_header, *interleaved_packet;\n\n\n\n    size = avio_close_dyn_buf(rtpctx->pb, &buf);\n\n    ptr = buf;\n\n    while (size > 4) {\n\n        uint32_t packet_len = AV_RB32(ptr);\n\n        int id;\n\n        /* The interleaving header is exactly 4 bytes, which happens to be\n\n         * the same size as the packet length header from\n\n         * url_open_dyn_packet_buf. So by writing the interleaving header\n\n         * over these bytes, we get a consecutive interleaved packet\n\n         * that can be written in one call. */\n\n        interleaved_packet = interleave_header = ptr;\n\n        ptr += 4;\n\n        size -= 4;\n\n        if (packet_len > size || packet_len < 2)\n\n            break;\n\n        if (ptr[1] >= RTCP_SR && ptr[1] <= RTCP_APP)\n\n            id = rtsp_st->interleaved_max; /* RTCP */\n\n        else\n\n            id = rtsp_st->interleaved_min; /* RTP */\n\n        interleave_header[0] = '$';\n\n        interleave_header[1] = id;\n\n        AV_WB16(interleave_header + 2, packet_len);\n\n        url_write(rt->rtsp_hd_out, interleaved_packet, 4 + packet_len);\n\n        ptr += packet_len;\n\n        size -= packet_len;\n\n    }\n\n    av_free(buf);\n\n    url_open_dyn_packet_buf(&rtpctx->pb, RTSP_TCP_MAX_PACKET_SIZE);\n\n    return 0;\n\n}\n", "idx": 24287}
{"project": "FFmpeg", "commit_id": "b19e3983cfb157751301aec87237ea28676665f0", "target": 0, "func": "static int find_and_decode_index(NUTContext *nut){\n\n    AVFormatContext *s= nut->avf;\n\n    ByteIOContext *bc = s->pb;\n\n    uint64_t tmp, end;\n\n    int i, j, syncpoint_count;\n\n    int64_t filesize= url_fsize(bc);\n\n    int64_t *syncpoints;\n\n    int8_t *has_keyframe;\n\n\n\n    url_fseek(bc, filesize-12, SEEK_SET);\n\n    url_fseek(bc, filesize-get_be64(bc), SEEK_SET);\n\n    if(get_be64(bc) != INDEX_STARTCODE){\n\n        av_log(s, AV_LOG_ERROR, \"no index at the end\\n\");\n\n        return -1;\n\n    }\n\n\n\n    end= get_packetheader(nut, bc, 1, INDEX_STARTCODE);\n\n    end += url_ftell(bc);\n\n\n\n    ff_get_v(bc); //max_pts\n\n    GET_V(syncpoint_count, tmp < INT_MAX/8 && tmp > 0)\n\n    syncpoints= av_malloc(sizeof(int64_t)*syncpoint_count);\n\n    has_keyframe= av_malloc(sizeof(int8_t)*(syncpoint_count+1));\n\n    for(i=0; i<syncpoint_count; i++){\n\n        GET_V(syncpoints[i], tmp>0)\n\n        if(i)\n\n            syncpoints[i] += syncpoints[i-1];\n\n    }\n\n\n\n    for(i=0; i<s->nb_streams; i++){\n\n        int64_t last_pts= -1;\n\n        for(j=0; j<syncpoint_count;){\n\n            uint64_t x= ff_get_v(bc);\n\n            int type= x&1;\n\n            int n= j;\n\n            x>>=1;\n\n            if(type){\n\n                int flag= x&1;\n\n                x>>=1;\n\n                if(n+x >= syncpoint_count + 1){\n\n                    av_log(s, AV_LOG_ERROR, \"index overflow A\\n\");\n\n                    return -1;\n\n                }\n\n                while(x--)\n\n                    has_keyframe[n++]= flag;\n\n                has_keyframe[n++]= !flag;\n\n            }else{\n\n                while(x != 1){\n\n                    if(n>=syncpoint_count + 1){\n\n                        av_log(s, AV_LOG_ERROR, \"index overflow B\\n\");\n\n                        return -1;\n\n                    }\n\n                    has_keyframe[n++]= x&1;\n\n                    x>>=1;\n\n                }\n\n            }\n\n            if(has_keyframe[0]){\n\n                av_log(s, AV_LOG_ERROR, \"keyframe before first syncpoint in index\\n\");\n\n                return -1;\n\n            }\n\n            assert(n<=syncpoint_count+1);\n\n            for(; j<n; j++){\n\n                if(has_keyframe[j]){\n\n                    uint64_t B, A= ff_get_v(bc);\n\n                    if(!A){\n\n                        A= ff_get_v(bc);\n\n                        B= ff_get_v(bc);\n\n                        //eor_pts[j][i] = last_pts + A + B\n\n                    }else\n\n                        B= 0;\n\n                    av_add_index_entry(\n\n                        s->streams[i],\n\n                        16*syncpoints[j-1],\n\n                        last_pts + A,\n\n                        0,\n\n                        0,\n\n                        AVINDEX_KEYFRAME);\n\n                    last_pts += A + B;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    if(skip_reserved(bc, end) || get_checksum(bc)){\n\n        av_log(s, AV_LOG_ERROR, \"index checksum mismatch\\n\");\n\n        return -1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 24288}
{"project": "FFmpeg", "commit_id": "16c6795465fd7663792fe535256c760560714863", "target": 0, "func": "x11grab_read_header(AVFormatContext *s1)\n\n{\n\n    struct x11grab *x11grab = s1->priv_data;\n\n    Display *dpy;\n\n    AVStream *st = NULL;\n\n    enum AVPixelFormat input_pixfmt;\n\n    XImage *image;\n\n    int x_off = 0;\n\n    int y_off = 0;\n\n    int screen;\n\n    int use_shm;\n\n    char *dpyname, *offset;\n\n    int ret = 0;\n\n    Colormap color_map;\n\n    XColor color[256];\n\n    int i;\n\n\n\n    dpyname = av_strdup(s1->filename);\n\n    if (!dpyname)\n\n        goto out;\n\n\n\n    offset = strchr(dpyname, '+');\n\n    if (offset) {\n\n        sscanf(offset, \"%d,%d\", &x_off, &y_off);\n\n        if (strstr(offset, \"nomouse\")) {\n\n            av_log(s1, AV_LOG_WARNING,\n\n                   \"'nomouse' specification in argument is deprecated: \"\n\n                   \"use 'draw_mouse' option with value 0 instead\\n\");\n\n            x11grab->draw_mouse = 0;\n\n        }\n\n        *offset= 0;\n\n    }\n\n\n\n    av_log(s1, AV_LOG_INFO, \"device: %s -> display: %s x: %d y: %d width: %d height: %d\\n\",\n\n           s1->filename, dpyname, x_off, y_off, x11grab->width, x11grab->height);\n\n\n\n    dpy = XOpenDisplay(dpyname);\n\n    av_freep(&dpyname);\n\n    if(!dpy) {\n\n        av_log(s1, AV_LOG_ERROR, \"Could not open X display.\\n\");\n\n        ret = AVERROR(EIO);\n\n        goto out;\n\n    }\n\n\n\n    st = avformat_new_stream(s1, NULL);\n\n    if (!st) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto out;\n\n    }\n\n    avpriv_set_pts_info(st, 64, 1, 1000000); /* 64 bits pts in us */\n\n\n\n    screen = DefaultScreen(dpy);\n\n\n\n    if (x11grab->follow_mouse) {\n\n        int screen_w, screen_h;\n\n        Window w;\n\n\n\n        screen_w = DisplayWidth(dpy, screen);\n\n        screen_h = DisplayHeight(dpy, screen);\n\n        XQueryPointer(dpy, RootWindow(dpy, screen), &w, &w, &x_off, &y_off, &ret, &ret, &ret);\n\n        x_off -= x11grab->width / 2;\n\n        y_off -= x11grab->height / 2;\n\n        x_off = FFMIN(FFMAX(x_off, 0), screen_w - x11grab->width);\n\n        y_off = FFMIN(FFMAX(y_off, 0), screen_h - x11grab->height);\n\n        av_log(s1, AV_LOG_INFO, \"followmouse is enabled, resetting grabbing region to x: %d y: %d\\n\", x_off, y_off);\n\n    }\n\n\n\n    use_shm = XShmQueryExtension(dpy);\n\n    av_log(s1, AV_LOG_INFO, \"shared memory extension%s found\\n\", use_shm ? \"\" : \" not\");\n\n\n\n    if(use_shm) {\n\n        int scr = XDefaultScreen(dpy);\n\n        image = XShmCreateImage(dpy,\n\n                                DefaultVisual(dpy, scr),\n\n                                DefaultDepth(dpy, scr),\n\n                                ZPixmap,\n\n                                NULL,\n\n                                &x11grab->shminfo,\n\n                                x11grab->width, x11grab->height);\n\n        x11grab->shminfo.shmid = shmget(IPC_PRIVATE,\n\n                                        image->bytes_per_line * image->height,\n\n                                        IPC_CREAT|0777);\n\n        if (x11grab->shminfo.shmid == -1) {\n\n            av_log(s1, AV_LOG_ERROR, \"Fatal: Can't get shared memory!\\n\");\n\n            ret = AVERROR(ENOMEM);\n\n            goto out;\n\n        }\n\n        x11grab->shminfo.shmaddr = image->data = shmat(x11grab->shminfo.shmid, 0, 0);\n\n        x11grab->shminfo.readOnly = False;\n\n\n\n        if (!XShmAttach(dpy, &x11grab->shminfo)) {\n\n            av_log(s1, AV_LOG_ERROR, \"Fatal: Failed to attach shared memory!\\n\");\n\n            /* needs some better error subroutine :) */\n\n            ret = AVERROR(EIO);\n\n            goto out;\n\n        }\n\n    } else {\n\n        image = XGetImage(dpy, RootWindow(dpy, screen),\n\n                          x_off,y_off,\n\n                          x11grab->width, x11grab->height,\n\n                          AllPlanes, ZPixmap);\n\n    }\n\n\n\n    switch (image->bits_per_pixel) {\n\n    case 8:\n\n        av_log (s1, AV_LOG_DEBUG, \"8 bit palette\\n\");\n\n        input_pixfmt = AV_PIX_FMT_PAL8;\n\n        color_map = DefaultColormap(dpy, screen);\n\n        for (i = 0; i < 256; ++i)\n\n            color[i].pixel = i;\n\n        XQueryColors(dpy, color_map, color, 256);\n\n        for (i = 0; i < 256; ++i)\n\n            x11grab->palette[i] = (color[i].red   & 0xFF00) << 8 |\n\n                                  (color[i].green & 0xFF00)      |\n\n                                  (color[i].blue  & 0xFF00) >> 8;\n\n        x11grab->palette_changed = 1;\n\n        break;\n\n    case 16:\n\n        if (       image->red_mask   == 0xf800 &&\n\n                   image->green_mask == 0x07e0 &&\n\n                   image->blue_mask  == 0x001f ) {\n\n            av_log (s1, AV_LOG_DEBUG, \"16 bit RGB565\\n\");\n\n            input_pixfmt = AV_PIX_FMT_RGB565;\n\n        } else if (image->red_mask   == 0x7c00 &&\n\n                   image->green_mask == 0x03e0 &&\n\n                   image->blue_mask  == 0x001f ) {\n\n            av_log(s1, AV_LOG_DEBUG, \"16 bit RGB555\\n\");\n\n            input_pixfmt = AV_PIX_FMT_RGB555;\n\n        } else {\n\n            av_log(s1, AV_LOG_ERROR, \"RGB ordering at image depth %i not supported ... aborting\\n\", image->bits_per_pixel);\n\n            av_log(s1, AV_LOG_ERROR, \"color masks: r 0x%.6lx g 0x%.6lx b 0x%.6lx\\n\", image->red_mask, image->green_mask, image->blue_mask);\n\n            ret = AVERROR_PATCHWELCOME;\n\n            goto out;\n\n        }\n\n        break;\n\n    case 24:\n\n        if (        image->red_mask   == 0xff0000 &&\n\n                    image->green_mask == 0x00ff00 &&\n\n                    image->blue_mask  == 0x0000ff ) {\n\n            input_pixfmt = AV_PIX_FMT_BGR24;\n\n        } else if ( image->red_mask   == 0x0000ff &&\n\n                    image->green_mask == 0x00ff00 &&\n\n                    image->blue_mask  == 0xff0000 ) {\n\n            input_pixfmt = AV_PIX_FMT_RGB24;\n\n        } else {\n\n            av_log(s1, AV_LOG_ERROR,\"rgb ordering at image depth %i not supported ... aborting\\n\", image->bits_per_pixel);\n\n            av_log(s1, AV_LOG_ERROR, \"color masks: r 0x%.6lx g 0x%.6lx b 0x%.6lx\\n\", image->red_mask, image->green_mask, image->blue_mask);\n\n            ret = AVERROR_PATCHWELCOME;\n\n            goto out;\n\n        }\n\n        break;\n\n    case 32:\n\n        input_pixfmt = AV_PIX_FMT_0RGB32;\n\n        break;\n\n    default:\n\n        av_log(s1, AV_LOG_ERROR, \"image depth %i not supported ... aborting\\n\", image->bits_per_pixel);\n\n        ret = AVERROR_PATCHWELCOME;\n\n        goto out;\n\n    }\n\n\n\n    x11grab->frame_size = x11grab->width * x11grab->height * image->bits_per_pixel/8;\n\n    x11grab->dpy = dpy;\n\n    x11grab->time_base  = av_inv_q(x11grab->framerate);\n\n    x11grab->time_frame = av_gettime() / av_q2d(x11grab->time_base);\n\n    x11grab->x_off = x_off;\n\n    x11grab->y_off = y_off;\n\n    x11grab->image = image;\n\n    x11grab->use_shm = use_shm;\n\n\n\n    st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id = AV_CODEC_ID_RAWVIDEO;\n\n    st->codec->width  = x11grab->width;\n\n    st->codec->height = x11grab->height;\n\n    st->codec->pix_fmt = input_pixfmt;\n\n    st->codec->time_base = x11grab->time_base;\n\n    st->codec->bit_rate = x11grab->frame_size * 1/av_q2d(x11grab->time_base) * 8;\n\n\n\nout:\n\n    av_free(dpyname);\n\n    return ret;\n\n}\n", "idx": 24289}
{"project": "FFmpeg", "commit_id": "474176bf927870168a20413f2a9c28f09b6b1afa", "target": 0, "func": "static int get_max_p_order(int max_porder, int n, int order)\n\n{\n\n    int porder, max_parts;\n\n\n\n    porder = max_porder;\n\n    while(porder > 0) {\n\n        max_parts = (1 << porder);\n\n        if(!(n % max_parts) && (n > max_parts*order)) {\n\n            break;\n\n        }\n\n        porder--;\n\n    }\n\n    return porder;\n\n}\n", "idx": 24290}
{"project": "FFmpeg", "commit_id": "b8664c929437d6d079e16979c496a2db40cf2324", "target": 0, "func": "static void vp8_h_loop_filter_simple_c(uint8_t *dst, ptrdiff_t stride, int flim)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 16; i++)\n\n        if (simple_limit(dst+i*stride, 1, flim))\n\n            filter_common(dst+i*stride, 1, 1);\n\n}\n", "idx": 24291}
{"project": "FFmpeg", "commit_id": "1509c018bd5b054a2354e20021ccbac9c934d213", "target": 1, "func": "static int get_packet_size(const uint8_t *buf, int size)\n\n{\n\n    int score, fec_score, dvhs_score;\n\n\n\n    if (size < (TS_FEC_PACKET_SIZE * 5 + 1))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    score      = analyze(buf, size, TS_PACKET_SIZE, NULL);\n\n    dvhs_score = analyze(buf, size, TS_DVHS_PACKET_SIZE, NULL);\n\n    fec_score  = analyze(buf, size, TS_FEC_PACKET_SIZE, NULL);\n\n    av_dlog(NULL, \"score: %d, dvhs_score: %d, fec_score: %d \\n\",\n\n            score, dvhs_score, fec_score);\n\n\n\n    if (score > fec_score && score > dvhs_score)\n\n        return TS_PACKET_SIZE;\n\n    else if (dvhs_score > score && dvhs_score > fec_score)\n\n        return TS_DVHS_PACKET_SIZE;\n\n    else if (score < fec_score && dvhs_score < fec_score)\n\n        return TS_FEC_PACKET_SIZE;\n\n    else\n\n        return AVERROR_INVALIDDATA;\n\n}\n", "idx": 24295}
{"project": "FFmpeg", "commit_id": "faaec4676cb4c7a2303d50df66c6290bc96a7657", "target": 1, "func": "static void matroska_execute_seekhead(MatroskaDemuxContext *matroska)\n\n{\n\n    EbmlList *seekhead_list = &matroska->seekhead;\n\n    MatroskaSeekhead *seekhead = seekhead_list->elem;\n\n    int64_t before_pos = avio_tell(matroska->ctx->pb);\n\n    int i;\n\n\n\n    // we should not do any seeking in the streaming case\n\n    if (!matroska->ctx->pb->seekable ||\n\n        (matroska->ctx->flags & AVFMT_FLAG_IGNIDX))\n\n        return;\n\n\n\n    for (i = 0; i < seekhead_list->nb_elem; i++) {\n\n        if (seekhead[i].pos <= before_pos)\n\n            continue;\n\n\n\n        // defer cues parsing until we actually need cue data.\n\n        if (seekhead[i].id == MATROSKA_ID_CUES) {\n\n            matroska->cues_parsing_deferred = 1;\n\n            continue;\n\n        }\n\n\n\n        if (matroska_parse_seekhead_entry(matroska, i) < 0)\n\n            break;\n\n    }\n\n}\n", "idx": 24296}
{"project": "FFmpeg", "commit_id": "61cd19b8bc32185c8caf64d89d1b0909877a0707", "target": 1, "func": "static void load_cursor(VmncContext *c, const uint8_t *src)\n\n{\n\n    int i, j, p;\n\n    const int bpp   = c->bpp2;\n\n    uint8_t *dst8   =             c->curbits;\n\n    uint16_t *dst16 = (uint16_t *)c->curbits;\n\n    uint32_t *dst32 = (uint32_t *)c->curbits;\n\n\n\n    for (j = 0; j < c->cur_h; j++) {\n\n        for (i = 0; i < c->cur_w; i++) {\n\n            p = vmnc_get_pixel(src, bpp, c->bigendian);\n\n            src += bpp;\n\n            if (bpp == 1)\n\n                *dst8++ = p;\n\n            if (bpp == 2)\n\n                *dst16++ = p;\n\n            if (bpp == 4)\n\n                *dst32++ = p;\n\n        }\n\n    }\n\n    dst8  =            c->curmask;\n\n    dst16 = (uint16_t*)c->curmask;\n\n    dst32 = (uint32_t*)c->curmask;\n\n    for (j = 0; j < c->cur_h; j++) {\n\n        for (i = 0; i < c->cur_w; i++) {\n\n            p = vmnc_get_pixel(src, bpp, c->bigendian);\n\n            src += bpp;\n\n            if (bpp == 1)\n\n                *dst8++ = p;\n\n            if (bpp == 2)\n\n                *dst16++ = p;\n\n            if (bpp == 4)\n\n                *dst32++ = p;\n\n        }\n\n    }\n\n}\n", "idx": 24299}
{"project": "FFmpeg", "commit_id": "28f9ab7029bd1a02f659995919f899f84ee7361b", "target": 0, "func": "av_cold void ff_dsputil_init(DSPContext* c, AVCodecContext *avctx)\n\n{\n\n    int i, j;\n\n\n\n    ff_check_alignment();\n\n\n\n#if CONFIG_ENCODERS\n\n    if (avctx->bits_per_raw_sample == 10) {\n\n        c->fdct    = ff_jpeg_fdct_islow_10;\n\n        c->fdct248 = ff_fdct248_islow_10;\n\n    } else {\n\n        if(avctx->dct_algo==FF_DCT_FASTINT) {\n\n            c->fdct    = ff_fdct_ifast;\n\n            c->fdct248 = ff_fdct_ifast248;\n\n        }\n\n        else if(avctx->dct_algo==FF_DCT_FAAN) {\n\n            c->fdct    = ff_faandct;\n\n            c->fdct248 = ff_faandct248;\n\n        }\n\n        else {\n\n            c->fdct    = ff_jpeg_fdct_islow_8; //slow/accurate/default\n\n            c->fdct248 = ff_fdct248_islow_8;\n\n        }\n\n    }\n\n#endif //CONFIG_ENCODERS\n\n\n\n    if (avctx->bits_per_raw_sample == 10) {\n\n        c->idct_put              = ff_simple_idct_put_10;\n\n        c->idct_add              = ff_simple_idct_add_10;\n\n        c->idct                  = ff_simple_idct_10;\n\n        c->idct_permutation_type = FF_NO_IDCT_PERM;\n\n    } else {\n\n        if(avctx->idct_algo==FF_IDCT_INT){\n\n            c->idct_put= ff_jref_idct_put;\n\n            c->idct_add= ff_jref_idct_add;\n\n            c->idct    = ff_j_rev_dct;\n\n            c->idct_permutation_type= FF_LIBMPEG2_IDCT_PERM;\n\n        }else if((CONFIG_VP3_DECODER || CONFIG_VP5_DECODER || CONFIG_VP6_DECODER ) &&\n\n                avctx->idct_algo==FF_IDCT_VP3){\n\n            c->idct_put= ff_vp3_idct_put_c;\n\n            c->idct_add= ff_vp3_idct_add_c;\n\n            c->idct    = ff_vp3_idct_c;\n\n            c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n        }else if(avctx->idct_algo==FF_IDCT_WMV2){\n\n            c->idct_put= ff_wmv2_idct_put_c;\n\n            c->idct_add= ff_wmv2_idct_add_c;\n\n            c->idct    = ff_wmv2_idct_c;\n\n            c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n        }else if(avctx->idct_algo==FF_IDCT_FAAN){\n\n            c->idct_put= ff_faanidct_put;\n\n            c->idct_add= ff_faanidct_add;\n\n            c->idct    = ff_faanidct;\n\n            c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n        }else if(CONFIG_EATGQ_DECODER && avctx->idct_algo==FF_IDCT_EA) {\n\n            c->idct_put= ff_ea_idct_put_c;\n\n            c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n        }else{ //accurate/default\n\n            c->idct_put = ff_simple_idct_put_8;\n\n            c->idct_add = ff_simple_idct_add_8;\n\n            c->idct     = ff_simple_idct_8;\n\n            c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n        }\n\n    }\n\n\n\n    c->diff_pixels = diff_pixels_c;\n\n    c->put_pixels_clamped = ff_put_pixels_clamped_c;\n\n    c->put_signed_pixels_clamped = ff_put_signed_pixels_clamped_c;\n\n    c->add_pixels_clamped = ff_add_pixels_clamped_c;\n\n    c->sum_abs_dctelem = sum_abs_dctelem_c;\n\n    c->gmc1 = gmc1_c;\n\n    c->gmc = ff_gmc_c;\n\n    c->pix_sum = pix_sum_c;\n\n    c->pix_norm1 = pix_norm1_c;\n\n\n\n    c->fill_block_tab[0] = fill_block16_c;\n\n    c->fill_block_tab[1] = fill_block8_c;\n\n\n\n    /* TODO [0] 16  [1] 8 */\n\n    c->pix_abs[0][0] = pix_abs16_c;\n\n    c->pix_abs[0][1] = pix_abs16_x2_c;\n\n    c->pix_abs[0][2] = pix_abs16_y2_c;\n\n    c->pix_abs[0][3] = pix_abs16_xy2_c;\n\n    c->pix_abs[1][0] = pix_abs8_c;\n\n    c->pix_abs[1][1] = pix_abs8_x2_c;\n\n    c->pix_abs[1][2] = pix_abs8_y2_c;\n\n    c->pix_abs[1][3] = pix_abs8_xy2_c;\n\n\n\n    c->put_tpel_pixels_tab[ 0] = put_tpel_pixels_mc00_c;\n\n    c->put_tpel_pixels_tab[ 1] = put_tpel_pixels_mc10_c;\n\n    c->put_tpel_pixels_tab[ 2] = put_tpel_pixels_mc20_c;\n\n    c->put_tpel_pixels_tab[ 4] = put_tpel_pixels_mc01_c;\n\n    c->put_tpel_pixels_tab[ 5] = put_tpel_pixels_mc11_c;\n\n    c->put_tpel_pixels_tab[ 6] = put_tpel_pixels_mc21_c;\n\n    c->put_tpel_pixels_tab[ 8] = put_tpel_pixels_mc02_c;\n\n    c->put_tpel_pixels_tab[ 9] = put_tpel_pixels_mc12_c;\n\n    c->put_tpel_pixels_tab[10] = put_tpel_pixels_mc22_c;\n\n\n\n    c->avg_tpel_pixels_tab[ 0] = avg_tpel_pixels_mc00_c;\n\n    c->avg_tpel_pixels_tab[ 1] = avg_tpel_pixels_mc10_c;\n\n    c->avg_tpel_pixels_tab[ 2] = avg_tpel_pixels_mc20_c;\n\n    c->avg_tpel_pixels_tab[ 4] = avg_tpel_pixels_mc01_c;\n\n    c->avg_tpel_pixels_tab[ 5] = avg_tpel_pixels_mc11_c;\n\n    c->avg_tpel_pixels_tab[ 6] = avg_tpel_pixels_mc21_c;\n\n    c->avg_tpel_pixels_tab[ 8] = avg_tpel_pixels_mc02_c;\n\n    c->avg_tpel_pixels_tab[ 9] = avg_tpel_pixels_mc12_c;\n\n    c->avg_tpel_pixels_tab[10] = avg_tpel_pixels_mc22_c;\n\n\n\n#define dspfunc(PFX, IDX, NUM) \\\n\n    c->PFX ## _pixels_tab[IDX][ 0] = PFX ## NUM ## _mc00_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 1] = PFX ## NUM ## _mc10_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 2] = PFX ## NUM ## _mc20_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 3] = PFX ## NUM ## _mc30_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 4] = PFX ## NUM ## _mc01_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 5] = PFX ## NUM ## _mc11_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 6] = PFX ## NUM ## _mc21_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 7] = PFX ## NUM ## _mc31_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 8] = PFX ## NUM ## _mc02_c; \\\n\n    c->PFX ## _pixels_tab[IDX][ 9] = PFX ## NUM ## _mc12_c; \\\n\n    c->PFX ## _pixels_tab[IDX][10] = PFX ## NUM ## _mc22_c; \\\n\n    c->PFX ## _pixels_tab[IDX][11] = PFX ## NUM ## _mc32_c; \\\n\n    c->PFX ## _pixels_tab[IDX][12] = PFX ## NUM ## _mc03_c; \\\n\n    c->PFX ## _pixels_tab[IDX][13] = PFX ## NUM ## _mc13_c; \\\n\n    c->PFX ## _pixels_tab[IDX][14] = PFX ## NUM ## _mc23_c; \\\n\n    c->PFX ## _pixels_tab[IDX][15] = PFX ## NUM ## _mc33_c\n\n\n\n    dspfunc(put_qpel, 0, 16);\n\n    dspfunc(put_no_rnd_qpel, 0, 16);\n\n\n\n    dspfunc(avg_qpel, 0, 16);\n\n    /* dspfunc(avg_no_rnd_qpel, 0, 16); */\n\n\n\n    dspfunc(put_qpel, 1, 8);\n\n    dspfunc(put_no_rnd_qpel, 1, 8);\n\n\n\n    dspfunc(avg_qpel, 1, 8);\n\n    /* dspfunc(avg_no_rnd_qpel, 1, 8); */\n\n\n\n#undef dspfunc\n\n\n\n#if CONFIG_MLP_DECODER || CONFIG_TRUEHD_DECODER\n\n    ff_mlp_init(c, avctx);\n\n#endif\n\n#if CONFIG_WMV2_DECODER || CONFIG_VC1_DECODER\n\n    ff_intrax8dsp_init(c,avctx);\n\n#endif\n\n\n\n    c->put_mspel_pixels_tab[0]= ff_put_pixels8x8_c;\n\n    c->put_mspel_pixels_tab[1]= put_mspel8_mc10_c;\n\n    c->put_mspel_pixels_tab[2]= put_mspel8_mc20_c;\n\n    c->put_mspel_pixels_tab[3]= put_mspel8_mc30_c;\n\n    c->put_mspel_pixels_tab[4]= put_mspel8_mc02_c;\n\n    c->put_mspel_pixels_tab[5]= put_mspel8_mc12_c;\n\n    c->put_mspel_pixels_tab[6]= put_mspel8_mc22_c;\n\n    c->put_mspel_pixels_tab[7]= put_mspel8_mc32_c;\n\n\n\n#define SET_CMP_FUNC(name) \\\n\n    c->name[0]= name ## 16_c;\\\n\n    c->name[1]= name ## 8x8_c;\n\n\n\n    SET_CMP_FUNC(hadamard8_diff)\n\n    c->hadamard8_diff[4]= hadamard8_intra16_c;\n\n    c->hadamard8_diff[5]= hadamard8_intra8x8_c;\n\n    SET_CMP_FUNC(dct_sad)\n\n    SET_CMP_FUNC(dct_max)\n\n#if CONFIG_GPL\n\n    SET_CMP_FUNC(dct264_sad)\n\n#endif\n\n    c->sad[0]= pix_abs16_c;\n\n    c->sad[1]= pix_abs8_c;\n\n    c->sse[0]= sse16_c;\n\n    c->sse[1]= sse8_c;\n\n    c->sse[2]= sse4_c;\n\n    SET_CMP_FUNC(quant_psnr)\n\n    SET_CMP_FUNC(rd)\n\n    SET_CMP_FUNC(bit)\n\n    c->vsad[0]= vsad16_c;\n\n    c->vsad[4]= vsad_intra16_c;\n\n    c->vsad[5]= vsad_intra8_c;\n\n    c->vsse[0]= vsse16_c;\n\n    c->vsse[4]= vsse_intra16_c;\n\n    c->vsse[5]= vsse_intra8_c;\n\n    c->nsse[0]= nsse16_c;\n\n    c->nsse[1]= nsse8_c;\n\n#if CONFIG_DWT\n\n    ff_dsputil_init_dwt(c);\n\n#endif\n\n\n\n    c->ssd_int8_vs_int16 = ssd_int8_vs_int16_c;\n\n\n\n    c->add_bytes= add_bytes_c;\n\n    c->diff_bytes= diff_bytes_c;\n\n    c->add_hfyu_median_prediction= add_hfyu_median_prediction_c;\n\n    c->sub_hfyu_median_prediction= sub_hfyu_median_prediction_c;\n\n    c->add_hfyu_left_prediction  = add_hfyu_left_prediction_c;\n\n    c->add_hfyu_left_prediction_bgr32 = add_hfyu_left_prediction_bgr32_c;\n\n    c->bswap_buf= bswap_buf;\n\n    c->bswap16_buf = bswap16_buf;\n\n\n\n    if (CONFIG_H263_DECODER || CONFIG_H263_ENCODER) {\n\n        c->h263_h_loop_filter= h263_h_loop_filter_c;\n\n        c->h263_v_loop_filter= h263_v_loop_filter_c;\n\n    }\n\n\n\n    if (CONFIG_VP3_DECODER) {\n\n        c->vp3_h_loop_filter= ff_vp3_h_loop_filter_c;\n\n        c->vp3_v_loop_filter= ff_vp3_v_loop_filter_c;\n\n        c->vp3_idct_dc_add= ff_vp3_idct_dc_add_c;\n\n    }\n\n\n\n    c->h261_loop_filter= h261_loop_filter_c;\n\n\n\n    c->try_8x8basis= try_8x8basis_c;\n\n    c->add_8x8basis= add_8x8basis_c;\n\n\n\n#if CONFIG_VORBIS_DECODER\n\n    c->vorbis_inverse_coupling = ff_vorbis_inverse_coupling;\n\n#endif\n\n#if CONFIG_AC3_DECODER\n\n    c->ac3_downmix = ff_ac3_downmix_c;\n\n#endif\n\n    c->vector_fmul_reverse = vector_fmul_reverse_c;\n\n    c->vector_fmul_add = vector_fmul_add_c;\n\n    c->vector_fmul_window = vector_fmul_window_c;\n\n    c->vector_clipf = vector_clipf_c;\n\n    c->scalarproduct_int16 = scalarproduct_int16_c;\n\n    c->scalarproduct_and_madd_int16 = scalarproduct_and_madd_int16_c;\n\n    c->apply_window_int16 = apply_window_int16_c;\n\n    c->vector_clip_int32 = vector_clip_int32_c;\n\n    c->scalarproduct_float = scalarproduct_float_c;\n\n    c->butterflies_float = butterflies_float_c;\n\n    c->butterflies_float_interleave = butterflies_float_interleave_c;\n\n    c->vector_fmul_scalar = vector_fmul_scalar_c;\n\n\n\n    c->shrink[0]= av_image_copy_plane;\n\n    c->shrink[1]= ff_shrink22;\n\n    c->shrink[2]= ff_shrink44;\n\n    c->shrink[3]= ff_shrink88;\n\n\n\n    c->prefetch= just_return;\n\n\n\n    memset(c->put_2tap_qpel_pixels_tab, 0, sizeof(c->put_2tap_qpel_pixels_tab));\n\n    memset(c->avg_2tap_qpel_pixels_tab, 0, sizeof(c->avg_2tap_qpel_pixels_tab));\n\n\n\n#undef FUNC\n\n#undef FUNCC\n\n#define FUNC(f, depth) f ## _ ## depth\n\n#define FUNCC(f, depth) f ## _ ## depth ## _c\n\n\n\n#define dspfunc1(PFX, IDX, NUM, depth)\\\n\n    c->PFX ## _pixels_tab[IDX][0] = FUNCC(PFX ## _pixels ## NUM        , depth);\\\n\n    c->PFX ## _pixels_tab[IDX][1] = FUNCC(PFX ## _pixels ## NUM ## _x2 , depth);\\\n\n    c->PFX ## _pixels_tab[IDX][2] = FUNCC(PFX ## _pixels ## NUM ## _y2 , depth);\\\n\n    c->PFX ## _pixels_tab[IDX][3] = FUNCC(PFX ## _pixels ## NUM ## _xy2, depth)\n\n\n\n#define dspfunc2(PFX, IDX, NUM, depth)\\\n\n    c->PFX ## _pixels_tab[IDX][ 0] = FUNCC(PFX ## NUM ## _mc00, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 1] = FUNCC(PFX ## NUM ## _mc10, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 2] = FUNCC(PFX ## NUM ## _mc20, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 3] = FUNCC(PFX ## NUM ## _mc30, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 4] = FUNCC(PFX ## NUM ## _mc01, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 5] = FUNCC(PFX ## NUM ## _mc11, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 6] = FUNCC(PFX ## NUM ## _mc21, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 7] = FUNCC(PFX ## NUM ## _mc31, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 8] = FUNCC(PFX ## NUM ## _mc02, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][ 9] = FUNCC(PFX ## NUM ## _mc12, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][10] = FUNCC(PFX ## NUM ## _mc22, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][11] = FUNCC(PFX ## NUM ## _mc32, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][12] = FUNCC(PFX ## NUM ## _mc03, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][13] = FUNCC(PFX ## NUM ## _mc13, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][14] = FUNCC(PFX ## NUM ## _mc23, depth);\\\n\n    c->PFX ## _pixels_tab[IDX][15] = FUNCC(PFX ## NUM ## _mc33, depth)\n\n\n\n\n\n#define BIT_DEPTH_FUNCS(depth, dct)\\\n\n    c->get_pixels                    = FUNCC(get_pixels   ## dct   , depth);\\\n\n    c->draw_edges                    = FUNCC(draw_edges            , depth);\\\n\n    c->emulated_edge_mc              = FUNC (ff_emulated_edge_mc   , depth);\\\n\n    c->clear_block                   = FUNCC(clear_block  ## dct   , depth);\\\n\n    c->clear_blocks                  = FUNCC(clear_blocks ## dct   , depth);\\\n\n    c->add_pixels8                   = FUNCC(add_pixels8  ## dct   , depth);\\\n\n    c->add_pixels4                   = FUNCC(add_pixels4  ## dct   , depth);\\\n\n    c->put_no_rnd_pixels_l2[0]       = FUNCC(put_no_rnd_pixels16_l2, depth);\\\n\n    c->put_no_rnd_pixels_l2[1]       = FUNCC(put_no_rnd_pixels8_l2 , depth);\\\n\n\\\n\n    c->put_h264_chroma_pixels_tab[0] = FUNCC(put_h264_chroma_mc8   , depth);\\\n\n    c->put_h264_chroma_pixels_tab[1] = FUNCC(put_h264_chroma_mc4   , depth);\\\n\n    c->put_h264_chroma_pixels_tab[2] = FUNCC(put_h264_chroma_mc2   , depth);\\\n\n    c->avg_h264_chroma_pixels_tab[0] = FUNCC(avg_h264_chroma_mc8   , depth);\\\n\n    c->avg_h264_chroma_pixels_tab[1] = FUNCC(avg_h264_chroma_mc4   , depth);\\\n\n    c->avg_h264_chroma_pixels_tab[2] = FUNCC(avg_h264_chroma_mc2   , depth);\\\n\n\\\n\n    dspfunc1(put       , 0, 16, depth);\\\n\n    dspfunc1(put       , 1,  8, depth);\\\n\n    dspfunc1(put       , 2,  4, depth);\\\n\n    dspfunc1(put       , 3,  2, depth);\\\n\n    dspfunc1(put_no_rnd, 0, 16, depth);\\\n\n    dspfunc1(put_no_rnd, 1,  8, depth);\\\n\n    dspfunc1(avg       , 0, 16, depth);\\\n\n    dspfunc1(avg       , 1,  8, depth);\\\n\n    dspfunc1(avg       , 2,  4, depth);\\\n\n    dspfunc1(avg       , 3,  2, depth);\\\n\n    dspfunc1(avg_no_rnd, 0, 16, depth);\\\n\n    dspfunc1(avg_no_rnd, 1,  8, depth);\\\n\n\\\n\n    dspfunc2(put_h264_qpel, 0, 16, depth);\\\n\n    dspfunc2(put_h264_qpel, 1,  8, depth);\\\n\n    dspfunc2(put_h264_qpel, 2,  4, depth);\\\n\n    dspfunc2(put_h264_qpel, 3,  2, depth);\\\n\n    dspfunc2(avg_h264_qpel, 0, 16, depth);\\\n\n    dspfunc2(avg_h264_qpel, 1,  8, depth);\\\n\n    dspfunc2(avg_h264_qpel, 2,  4, depth);\n\n\n\n    switch (avctx->bits_per_raw_sample) {\n\n    case 9:\n\n        if (c->dct_bits == 32) {\n\n            BIT_DEPTH_FUNCS(9, _32);\n\n        } else {\n\n            BIT_DEPTH_FUNCS(9, _16);\n\n        }\n\n        break;\n\n    case 10:\n\n        if (c->dct_bits == 32) {\n\n            BIT_DEPTH_FUNCS(10, _32);\n\n        } else {\n\n            BIT_DEPTH_FUNCS(10, _16);\n\n        }\n\n        break;\n\n    default:\n\n        BIT_DEPTH_FUNCS(8, _16);\n\n        break;\n\n    }\n\n\n\n\n\n    if (HAVE_MMX)        ff_dsputil_init_mmx   (c, avctx);\n\n    if (ARCH_ARM)        ff_dsputil_init_arm   (c, avctx);\n\n    if (HAVE_VIS)        ff_dsputil_init_vis   (c, avctx);\n\n    if (ARCH_ALPHA)      ff_dsputil_init_alpha (c, avctx);\n\n    if (ARCH_PPC)        ff_dsputil_init_ppc   (c, avctx);\n\n    if (HAVE_MMI)        ff_dsputil_init_mmi   (c, avctx);\n\n    if (ARCH_SH4)        ff_dsputil_init_sh4   (c, avctx);\n\n    if (ARCH_BFIN)       ff_dsputil_init_bfin  (c, avctx);\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        for (j = 0; j < 16; j++) {\n\n            if(!c->put_2tap_qpel_pixels_tab[i][j])\n\n                c->put_2tap_qpel_pixels_tab[i][j] =\n\n                    c->put_h264_qpel_pixels_tab[i][j];\n\n            if(!c->avg_2tap_qpel_pixels_tab[i][j])\n\n                c->avg_2tap_qpel_pixels_tab[i][j] =\n\n                    c->avg_h264_qpel_pixels_tab[i][j];\n\n        }\n\n    }\n\n\n\n    ff_init_scantable_permutation(c->idct_permutation,\n\n                                  c->idct_permutation_type);\n\n}\n", "idx": 24301}
{"project": "FFmpeg", "commit_id": "d24e08e978792e09d212018677d1c0b8208ecef8", "target": 0, "func": "static int dash_flush(AVFormatContext *s, int final, int stream)\n\n{\n\n    DASHContext *c = s->priv_data;\n\n    int i, ret = 0;\n\n\n\n    const char *proto = avio_find_protocol_name(s->filename);\n\n    int use_rename = proto && !strcmp(proto, \"file\");\n\n\n\n    int cur_flush_segment_index = 0;\n\n    if (stream >= 0)\n\n        cur_flush_segment_index = c->streams[stream].segment_index;\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        OutputStream *os = &c->streams[i];\n\n        AVStream *st = s->streams[i];\n\n        char filename[1024] = \"\", full_path[1024], temp_path[1024];\n\n        int range_length, index_length = 0;\n\n\n\n        if (!os->packets_written)\n\n            continue;\n\n\n\n        // Flush the single stream that got a keyframe right now.\n\n        // Flush all audio streams as well, in sync with video keyframes,\n\n        // but not the other video streams.\n\n        if (stream >= 0 && i != stream) {\n\n            if (s->streams[i]->codecpar->codec_type != AVMEDIA_TYPE_AUDIO)\n\n                continue;\n\n            // Make sure we don't flush audio streams multiple times, when\n\n            // all video streams are flushed one at a time.\n\n            if (c->has_video && os->segment_index > cur_flush_segment_index)\n\n                continue;\n\n        }\n\n\n\n        if (!os->init_range_length) {\n\n            flush_init_segment(s, os);\n\n        }\n\n\n\n        if (!c->single_file) {\n\n            ff_dash_fill_tmpl_params(filename, sizeof(filename), c->media_seg_name, i, os->segment_index, os->bit_rate, os->start_pts);\n\n            snprintf(full_path, sizeof(full_path), \"%s%s\", c->dirname, filename);\n\n            snprintf(temp_path, sizeof(temp_path), use_rename ? \"%s.tmp\" : \"%s\", full_path);\n\n            ret = s->io_open(s, &os->out, temp_path, AVIO_FLAG_WRITE, NULL);\n\n            if (ret < 0)\n\n                break;\n\n            if (!strcmp(os->format_name, \"mp4\"))\n\n                write_styp(os->ctx->pb);\n\n        } else {\n\n            snprintf(full_path, sizeof(full_path), \"%s%s\", c->dirname, os->initfile);\n\n        }\n\n\n\n        ret = flush_dynbuf(os, &range_length);\n\n        if (ret < 0)\n\n            break;\n\n        os->packets_written = 0;\n\n\n\n        if (c->single_file) {\n\n            find_index_range(s, full_path, os->pos, &index_length);\n\n        } else {\n\n            ff_format_io_close(s, &os->out);\n\n\n\n            if (use_rename) {\n\n                ret = avpriv_io_move(temp_path, full_path);\n\n                if (ret < 0)\n\n                    break;\n\n            }\n\n        }\n\n\n\n        if (!os->bit_rate) {\n\n            // calculate average bitrate of first segment\n\n            int64_t bitrate = (int64_t) range_length * 8 * AV_TIME_BASE / av_rescale_q(os->max_pts - os->start_pts,\n\n                                                                                       st->time_base,\n\n                                                                                       AV_TIME_BASE_Q);\n\n            if (bitrate >= 0) {\n\n                os->bit_rate = bitrate;\n\n                snprintf(os->bandwidth_str, sizeof(os->bandwidth_str),\n\n                     \" bandwidth=\\\"%d\\\"\", os->bit_rate);\n\n            }\n\n        }\n\n        add_segment(os, filename, os->start_pts, os->max_pts - os->start_pts, os->pos, range_length, index_length);\n\n        av_log(s, AV_LOG_VERBOSE, \"Representation %d media segment %d written to: %s\\n\", i, os->segment_index, full_path);\n\n\n\n        os->pos += range_length;\n\n    }\n\n\n\n    if (c->window_size || (final && c->remove_at_exit)) {\n\n        for (i = 0; i < s->nb_streams; i++) {\n\n            OutputStream *os = &c->streams[i];\n\n            int j;\n\n            int remove = os->nb_segments - c->window_size - c->extra_window_size;\n\n            if (final && c->remove_at_exit)\n\n                remove = os->nb_segments;\n\n            if (remove > 0) {\n\n                for (j = 0; j < remove; j++) {\n\n                    char filename[1024];\n\n                    snprintf(filename, sizeof(filename), \"%s%s\", c->dirname, os->segments[j]->file);\n\n                    unlink(filename);\n\n                    av_free(os->segments[j]);\n\n                }\n\n                os->nb_segments -= remove;\n\n                memmove(os->segments, os->segments + remove, os->nb_segments * sizeof(*os->segments));\n\n            }\n\n        }\n\n    }\n\n\n\n    if (ret >= 0)\n\n        ret = write_manifest(s, final);\n\n    return ret;\n\n}\n", "idx": 24302}
{"project": "FFmpeg", "commit_id": "e45a2872fafe631c14aee9f79d0963d68c4fc1fd", "target": 0, "func": "void put_pixels16_xy2_altivec(uint8_t * block, const uint8_t * pixels, int line_size, int h)\n\n{\n\nPOWERPC_TBL_DECLARE(altivec_put_pixels16_xy2_num, 1);\n\n#ifdef ALTIVEC_USE_REFERENCE_C_CODE\n\n    int j;\n\nPOWERPC_TBL_START_COUNT(altivec_put_pixels16_xy2_num, 1);\n\n      for (j = 0; j < 4; j++) {\n\n      int i;\n\n      const uint32_t a = (((const struct unaligned_32 *) (pixels))->l);\n\n      const uint32_t b =\n\n        (((const struct unaligned_32 *) (pixels + 1))->l);\n\n      uint32_t l0 =\n\n        (a & 0x03030303UL) + (b & 0x03030303UL) + 0x02020202UL;\n\n      uint32_t h0 =\n\n        ((a & 0xFCFCFCFCUL) >> 2) + ((b & 0xFCFCFCFCUL) >> 2);\n\n      uint32_t l1, h1;\n\n      pixels += line_size;\n\n      for (i = 0; i < h; i += 2) {\n\n        uint32_t a = (((const struct unaligned_32 *) (pixels))->l);\n\n        uint32_t b = (((const struct unaligned_32 *) (pixels + 1))->l);\n\n        l1 = (a & 0x03030303UL) + (b & 0x03030303UL);\n\n        h1 = ((a & 0xFCFCFCFCUL) >> 2) + ((b & 0xFCFCFCFCUL) >> 2);\n\n        *((uint32_t *) block) =\n\n          h0 + h1 + (((l0 + l1) >> 2) & 0x0F0F0F0FUL);\n\n        pixels += line_size;\n\n        block += line_size;\n\n        a = (((const struct unaligned_32 *) (pixels))->l);\n\n        b = (((const struct unaligned_32 *) (pixels + 1))->l);\n\n        l0 = (a & 0x03030303UL) + (b & 0x03030303UL) + 0x02020202UL;\n\n        h0 = ((a & 0xFCFCFCFCUL) >> 2) + ((b & 0xFCFCFCFCUL) >> 2);\n\n        *((uint32_t *) block) =\n\n          h0 + h1 + (((l0 + l1) >> 2) & 0x0F0F0F0FUL);\n\n        pixels += line_size;\n\n        block += line_size;\n\n      } pixels += 4 - line_size * (h + 1);\n\n      block += 4 - line_size * h;\n\n    }\n\n\n\nPOWERPC_TBL_STOP_COUNT(altivec_put_pixels16_xy2_num, 1);\n\n\n\n#else /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n   register int i;\n\n   register vector unsigned char\n\n     pixelsv1, pixelsv2, pixelsv3, pixelsv4;\n\n   register vector unsigned char\n\n     blockv, temp1, temp2;\n\n   register vector unsigned short\n\n     pixelssum1, pixelssum2, temp3,\n\n     pixelssum3, pixelssum4, temp4;\n\n   register const vector unsigned char vczero = (const vector unsigned char)vec_splat_u8(0);\n\n   register const vector unsigned short vctwo = (const vector unsigned short)vec_splat_u16(2);\n\n\n\nPOWERPC_TBL_START_COUNT(altivec_put_pixels16_xy2_num, 1);\n\n \n\n   temp1 = vec_ld(0, pixels);\n\n   temp2 = vec_ld(16, pixels);\n\n   pixelsv1 = vec_perm(temp1, temp2, vec_lvsl(0, pixels));\n\n   if ((((unsigned long)pixels) & 0x0000000F) ==  0x0000000F)\n\n   {\n\n     pixelsv2 = temp2;\n\n   }\n\n   else\n\n   {\n\n     pixelsv2 = vec_perm(temp1, temp2, vec_lvsl(1, pixels));\n\n   }\n\n   pixelsv3 = vec_mergel(vczero, pixelsv1);\n\n   pixelsv4 = vec_mergel(vczero, pixelsv2);\n\n   pixelsv1 = vec_mergeh(vczero, pixelsv1);\n\n   pixelsv2 = vec_mergeh(vczero, pixelsv2);\n\n   pixelssum3 = vec_add((vector unsigned short)pixelsv3,\n\n                        (vector unsigned short)pixelsv4);\n\n   pixelssum3 = vec_add(pixelssum3, vctwo);\n\n   pixelssum1 = vec_add((vector unsigned short)pixelsv1,\n\n                        (vector unsigned short)pixelsv2);\n\n   pixelssum1 = vec_add(pixelssum1, vctwo);\n\n   \n\n   for (i = 0; i < h ; i++) {\n\n     blockv = vec_ld(0, block);\n\n\n\n     temp1 = vec_ld(line_size, pixels);\n\n     temp2 = vec_ld(line_size + 16, pixels);\n\n     pixelsv1 = vec_perm(temp1, temp2, vec_lvsl(line_size, pixels));\n\n     if (((((unsigned long)pixels) + line_size) & 0x0000000F) ==  0x0000000F)\n\n     {\n\n       pixelsv2 = temp2;\n\n     }\n\n     else\n\n     {\n\n       pixelsv2 = vec_perm(temp1, temp2, vec_lvsl(line_size + 1, pixels));\n\n     }\n\n\n\n     pixelsv3 = vec_mergel(vczero, pixelsv1);\n\n     pixelsv4 = vec_mergel(vczero, pixelsv2);\n\n     pixelsv1 = vec_mergeh(vczero, pixelsv1);\n\n     pixelsv2 = vec_mergeh(vczero, pixelsv2);\n\n     \n\n     pixelssum4 = vec_add((vector unsigned short)pixelsv3,\n\n                          (vector unsigned short)pixelsv4);\n\n     pixelssum2 = vec_add((vector unsigned short)pixelsv1,\n\n                          (vector unsigned short)pixelsv2);\n\n     temp4 = vec_add(pixelssum3, pixelssum4);\n\n     temp4 = vec_sra(temp4, vctwo);\n\n     temp3 = vec_add(pixelssum1, pixelssum2);\n\n     temp3 = vec_sra(temp3, vctwo);\n\n\n\n     pixelssum3 = vec_add(pixelssum4, vctwo);\n\n     pixelssum1 = vec_add(pixelssum2, vctwo);\n\n\n\n     blockv = vec_packsu(temp3, temp4);\n\n     \n\n     vec_st(blockv, 0, block);\n\n     \n\n     block += line_size;\n\n     pixels += line_size;\n\n   }\n\n   \n\nPOWERPC_TBL_STOP_COUNT(altivec_put_pixels16_xy2_num, 1);\n\n#endif /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n}\n", "idx": 24305}
{"project": "FFmpeg", "commit_id": "570745cc5114ea13d0054f73776533f5e6e538f8", "target": 0, "func": "AVChapter *ff_new_chapter(AVFormatContext *s, int id, AVRational time_base, int64_t start, int64_t end, const char *title)\n\n{\n\n    AVChapter *chapter = NULL;\n\n    int i;\n\n\n\n    for(i=0; i<s->nb_chapters; i++)\n\n        if(s->chapters[i]->id == id)\n\n            chapter = s->chapters[i];\n\n\n\n    if(!chapter){\n\n        chapter= av_mallocz(sizeof(AVChapter));\n\n        if(!chapter)\n\n            return NULL;\n\n        dynarray_add(&s->chapters, &s->nb_chapters, chapter);\n\n    }\n\n    if(chapter->title)\n\n        av_free(chapter->title);\n\n    chapter->title = av_strdup(title);\n\n    chapter->id    = id;\n\n    chapter->time_base= time_base;\n\n    chapter->start = start;\n\n    chapter->end   = end;\n\n\n\n    return chapter;\n\n}\n", "idx": 24316}
{"project": "FFmpeg", "commit_id": "4791a910c0dc3dd5861d38202457c9fb9bf1154c", "target": 0, "func": "int ff_hevc_split_packet(HEVCContext *s, HEVCPacket *pkt, const uint8_t *buf, int length,\n\n                         AVCodecContext *avctx, int is_nalff, int nal_length_size)\n\n{\n\n    int consumed, ret = 0;\n\n\n\n    pkt->nb_nals = 0;\n\n    while (length >= 4) {\n\n        HEVCNAL *nal;\n\n        int extract_length = 0;\n\n\n\n        if (is_nalff) {\n\n            int i;\n\n            for (i = 0; i < nal_length_size; i++)\n\n                extract_length = (extract_length << 8) | buf[i];\n\n            buf    += nal_length_size;\n\n            length -= nal_length_size;\n\n\n\n            if (extract_length > length) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Invalid NAL unit size.\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        } else {\n\n            /* search start code */\n\n            while (buf[0] != 0 || buf[1] != 0 || buf[2] != 1) {\n\n                ++buf;\n\n                --length;\n\n                if (length < 4) {\n\n                    if (pkt->nb_nals > 0) {\n\n                        // No more start codes: we discarded some irrelevant\n\n                        // bytes at the end of the packet.\n\n                        return 0;\n\n                    } else {\n\n                        av_log(avctx, AV_LOG_ERROR, \"No start code is found.\\n\");\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                }\n\n            }\n\n\n\n            buf           += 3;\n\n            length        -= 3;\n\n            extract_length = length;\n\n        }\n\n\n\n        if (pkt->nals_allocated < pkt->nb_nals + 1) {\n\n            int new_size = pkt->nals_allocated + 1;\n\n            void *tmp = av_realloc_array(pkt->nals, new_size, sizeof(*pkt->nals));\n\n\n\n            if (!tmp)\n\n                return AVERROR(ENOMEM);\n\n\n\n            pkt->nals = tmp;\n\n            memset(pkt->nals + pkt->nals_allocated, 0,\n\n                   (new_size - pkt->nals_allocated) * sizeof(*pkt->nals));\n\n\n\n            nal = &pkt->nals[pkt->nb_nals];\n\n            nal->skipped_bytes_pos_size = 1024; // initial buffer size\n\n            nal->skipped_bytes_pos = av_malloc_array(nal->skipped_bytes_pos_size, sizeof(*nal->skipped_bytes_pos));\n\n            if (!nal->skipped_bytes_pos)\n\n                return AVERROR(ENOMEM);\n\n\n\n            pkt->nals_allocated = new_size;\n\n        }\n\n        nal = &pkt->nals[pkt->nb_nals];\n\n\n\n        consumed = ff_hevc_extract_rbsp(s, buf, extract_length, nal);\n\n        if (consumed < 0)\n\n            return consumed;\n\n\n\n        pkt->nb_nals++;\n\n\n\n        ret = init_get_bits8(&nal->gb, nal->data, nal->size);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        ret = hls_nal_unit(nal, avctx);\n\n        if (ret <= 0) {\n\n            if (ret < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Invalid NAL unit %d, skipping.\\n\",\n\n                       nal->type);\n\n            }\n\n            pkt->nb_nals--;\n\n        }\n\n\n\n        buf    += consumed;\n\n        length -= consumed;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24332}
{"project": "FFmpeg", "commit_id": "0c46e958d1fd3817b8e9fa048d0450d509c80378", "target": 1, "func": "static int mxf_decrypt_triplet(AVFormatContext *s, AVPacket *pkt, KLVPacket *klv)\n\n{\n\n    static const uint8_t checkv[16] = {0x43, 0x48, 0x55, 0x4b, 0x43, 0x48, 0x55, 0x4b, 0x43, 0x48, 0x55, 0x4b, 0x43, 0x48, 0x55, 0x4b};\n\n    MXFContext *mxf = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int64_t end = avio_tell(pb) + klv->length;\n\n    uint64_t size;\n\n    uint64_t orig_size;\n\n    uint64_t plaintext_size;\n\n    uint8_t ivec[16];\n\n    uint8_t tmpbuf[16];\n\n    int index;\n\n\n\n    if (!mxf->aesc && s->key && s->keylen == 16) {\n\n        mxf->aesc = av_malloc(av_aes_size);\n\n        if (!mxf->aesc)\n\n            return -1;\n\n        av_aes_init(mxf->aesc, s->key, 128, 1);\n\n    }\n\n    // crypto context\n\n    avio_skip(pb, klv_decode_ber_length(pb));\n\n    // plaintext offset\n\n    klv_decode_ber_length(pb);\n\n    plaintext_size = avio_rb64(pb);\n\n    // source klv key\n\n    klv_decode_ber_length(pb);\n\n    avio_read(pb, klv->key, 16);\n\n    if (!IS_KLV_KEY(klv, mxf_essence_element_key))\n\n        return -1;\n\n    index = mxf_get_stream_index(s, klv);\n\n    if (index < 0)\n\n        return -1;\n\n    // source size\n\n    klv_decode_ber_length(pb);\n\n    orig_size = avio_rb64(pb);\n\n    if (orig_size < plaintext_size)\n\n        return -1;\n\n    // enc. code\n\n    size = klv_decode_ber_length(pb);\n\n    if (size < 32 || size - 32 < orig_size)\n\n        return -1;\n\n    avio_read(pb, ivec, 16);\n\n    avio_read(pb, tmpbuf, 16);\n\n    if (mxf->aesc)\n\n        av_aes_crypt(mxf->aesc, tmpbuf, tmpbuf, 1, ivec, 1);\n\n    if (memcmp(tmpbuf, checkv, 16))\n\n        av_log(s, AV_LOG_ERROR, \"probably incorrect decryption key\\n\");\n\n    size -= 32;\n\n    av_get_packet(pb, pkt, size);\n\n    size -= plaintext_size;\n\n    if (mxf->aesc)\n\n        av_aes_crypt(mxf->aesc, &pkt->data[plaintext_size],\n\n                     &pkt->data[plaintext_size], size >> 4, ivec, 1);\n\n    pkt->size = orig_size;\n\n    pkt->stream_index = index;\n\n    avio_skip(pb, end - avio_tell(pb));\n\n    return 0;\n\n}\n", "idx": 24335}
{"project": "FFmpeg", "commit_id": "e4e02a7d4726e9370127741eb2873d6671d3f0c3", "target": 1, "func": "void avfilter_register_all(void)\n\n{\n\n    static int initialized;\n\n\n\n    if (initialized)\n\n        return;\n\n    initialized = 1;\n\n\n\n    REGISTER_FILTER (ACONVERT,    aconvert,    af);\n\n    REGISTER_FILTER (AFIFO,       afifo,       af);\n\n    REGISTER_FILTER (AFORMAT,     aformat,     af);\n\n    REGISTER_FILTER (AMERGE,      amerge,      af);\n\n    REGISTER_FILTER (AMIX,        amix,        af);\n\n    REGISTER_FILTER (ANULL,       anull,       af);\n\n    REGISTER_FILTER (ARESAMPLE,   aresample,   af);\n\n    REGISTER_FILTER (ASETNSAMPLES, asetnsamples, af);\n\n    REGISTER_FILTER (ASETPTS,     asetpts,     af);\n\n    REGISTER_FILTER (ASETTB,      asettb,      af);\n\n    REGISTER_FILTER (ASHOWINFO,   ashowinfo,   af);\n\n    REGISTER_FILTER (ASPLIT,      asplit,      af);\n\n    REGISTER_FILTER (ASTREAMSYNC, astreamsync, af);\n\n    REGISTER_FILTER (ASYNCTS,     asyncts,     af);\n\n    REGISTER_FILTER (ATEMPO,      atempo,      af);\n\n    REGISTER_FILTER (CHANNELMAP,  channelmap,  af);\n\n    REGISTER_FILTER (CHANNELSPLIT,channelsplit,af);\n\n    REGISTER_FILTER (EARWAX,      earwax,      af);\n\n    REGISTER_FILTER (JOIN,        join,        af);\n\n    REGISTER_FILTER (PAN,         pan,         af);\n\n    REGISTER_FILTER (SILENCEDETECT, silencedetect, af);\n\n    REGISTER_FILTER (VOLUME,      volume,      af);\n\n    REGISTER_FILTER (VOLUMEDETECT,volumedetect,af);\n\n    REGISTER_FILTER (RESAMPLE,    resample,    af);\n\n\n\n    REGISTER_FILTER (AEVALSRC,    aevalsrc,    asrc);\n\n    REGISTER_FILTER (ANULLSRC,    anullsrc,    asrc);\n\n    REGISTER_FILTER (FLITE,       flite,       asrc);\n\n\n\n\n    REGISTER_FILTER (ABUFFERSINK, abuffersink, asink);\n\n\n    REGISTER_FILTER (ANULLSINK,   anullsink,   asink);\n\n\n\n\n    REGISTER_FILTER (ALPHAEXTRACT, alphaextract, vf);\n\n    REGISTER_FILTER (ALPHAMERGE,  alphamerge,  vf);\n\n    REGISTER_FILTER (ASS,         ass,         vf);\n\n    REGISTER_FILTER (BBOX,        bbox,        vf);\n\n    REGISTER_FILTER (BLACKDETECT, blackdetect, vf);\n\n    REGISTER_FILTER (BLACKFRAME,  blackframe,  vf);\n\n    REGISTER_FILTER (BOXBLUR,     boxblur,     vf);\n\n    REGISTER_FILTER (COLORMATRIX, colormatrix, vf);\n\n    REGISTER_FILTER (COPY,        copy,        vf);\n\n    REGISTER_FILTER (CROP,        crop,        vf);\n\n    REGISTER_FILTER (CROPDETECT,  cropdetect,  vf);\n\n    REGISTER_FILTER (DECIMATE,    decimate,    vf);\n\n    REGISTER_FILTER (DELOGO,      delogo,      vf);\n\n    REGISTER_FILTER (DESHAKE,     deshake,     vf);\n\n    REGISTER_FILTER (DRAWBOX,     drawbox,     vf);\n\n    REGISTER_FILTER (DRAWTEXT,    drawtext,    vf);\n\n    REGISTER_FILTER (EDGEDETECT,  edgedetect,  vf);\n\n    REGISTER_FILTER (FADE,        fade,        vf);\n\n    REGISTER_FILTER (FIELDORDER,  fieldorder,  vf);\n\n    REGISTER_FILTER (FIFO,        fifo,        vf);\n\n    REGISTER_FILTER (FORMAT,      format,      vf);\n\n    REGISTER_FILTER (FPS,         fps,         vf);\n\n    REGISTER_FILTER (FRAMESTEP,   framestep,   vf);\n\n    REGISTER_FILTER (FREI0R,      frei0r,      vf);\n\n    REGISTER_FILTER (GRADFUN,     gradfun,     vf);\n\n    REGISTER_FILTER (HFLIP,       hflip,       vf);\n\n    REGISTER_FILTER (HQDN3D,      hqdn3d,      vf);\n\n    REGISTER_FILTER (HUE,         hue,         vf);\n\n    REGISTER_FILTER (IDET,        idet,        vf);\n\n    REGISTER_FILTER (LUT,         lut,         vf);\n\n    REGISTER_FILTER (LUTRGB,      lutrgb,      vf);\n\n    REGISTER_FILTER (LUTYUV,      lutyuv,      vf);\n\n    REGISTER_FILTER (MP,          mp,          vf);\n\n    REGISTER_FILTER (NEGATE,      negate,      vf);\n\n    REGISTER_FILTER (NOFORMAT,    noformat,    vf);\n\n    REGISTER_FILTER (NULL,        null,        vf);\n\n    REGISTER_FILTER (OCV,         ocv,         vf);\n\n    REGISTER_FILTER (OVERLAY,     overlay,     vf);\n\n    REGISTER_FILTER (PAD,         pad,         vf);\n\n    REGISTER_FILTER (PIXDESCTEST, pixdesctest, vf);\n\n    REGISTER_FILTER (REMOVELOGO,  removelogo,  vf);\n\n    REGISTER_FILTER (SCALE,       scale,       vf);\n\n    REGISTER_FILTER (SELECT,      select,      vf);\n\n    REGISTER_FILTER (SETDAR,      setdar,      vf);\n\n    REGISTER_FILTER (SETFIELD,    setfield,    vf);\n\n    REGISTER_FILTER (SETPTS,      setpts,      vf);\n\n    REGISTER_FILTER (SETSAR,      setsar,      vf);\n\n    REGISTER_FILTER (SETTB,       settb,       vf);\n\n    REGISTER_FILTER (SHOWINFO,    showinfo,    vf);\n\n    REGISTER_FILTER (SLICIFY,     slicify,     vf);\n\n    REGISTER_FILTER (SMARTBLUR,   smartblur,   vf);\n\n    REGISTER_FILTER (SPLIT,       split,       vf);\n\n    REGISTER_FILTER (SUPER2XSAI,  super2xsai,  vf);\n\n    REGISTER_FILTER (SWAPUV,      swapuv,      vf);\n\n    REGISTER_FILTER (THUMBNAIL,   thumbnail,   vf);\n\n    REGISTER_FILTER (TILE,        tile,        vf);\n\n    REGISTER_FILTER (TINTERLACE,  tinterlace,  vf);\n\n    REGISTER_FILTER (TRANSPOSE,   transpose,   vf);\n\n    REGISTER_FILTER (UNSHARP,     unsharp,     vf);\n\n    REGISTER_FILTER (VFLIP,       vflip,       vf);\n\n    REGISTER_FILTER (YADIF,       yadif,       vf);\n\n\n\n    REGISTER_FILTER (CELLAUTO,    cellauto,    vsrc);\n\n    REGISTER_FILTER (COLOR,       color,       vsrc);\n\n    REGISTER_FILTER (FREI0R,      frei0r_src,  vsrc);\n\n    REGISTER_FILTER (LIFE,        life,        vsrc);\n\n    REGISTER_FILTER (MANDELBROT,  mandelbrot,  vsrc);\n\n    REGISTER_FILTER (MPTESTSRC,   mptestsrc,   vsrc);\n\n    REGISTER_FILTER (NULLSRC,     nullsrc,     vsrc);\n\n    REGISTER_FILTER (RGBTESTSRC,  rgbtestsrc,  vsrc);\n\n    REGISTER_FILTER (SMPTEBARS,   smptebars,   vsrc);\n\n    REGISTER_FILTER (TESTSRC,     testsrc,     vsrc);\n\n\n\n\n    REGISTER_FILTER (BUFFERSINK,  buffersink,  vsink);\n\n\n    REGISTER_FILTER (FFBUFFERSINK,ffbuffersink,vsink);\n\n    REGISTER_FILTER (NULLSINK,    nullsink,    vsink);\n\n\n\n    /* multimedia filters */\n\n    REGISTER_FILTER (CONCAT,      concat,      avf);\n\n    REGISTER_FILTER (SHOWSPECTRUM,showspectrum,avf);\n\n    REGISTER_FILTER (SHOWWAVES,   showwaves,   avf);\n\n\n\n    /* multimedia sources */\n\n    REGISTER_FILTER (AMOVIE,      amovie,      avsrc);\n\n    REGISTER_FILTER (MOVIE,       movie,       avsrc);\n\n\n\n    /* those filters are part of public or internal API => registered\n\n     * unconditionally */\n\n    {\n\n        extern AVFilter avfilter_vsrc_buffer;\n\n        avfilter_register(&avfilter_vsrc_buffer);\n\n    }\n\n    {\n\n        extern AVFilter avfilter_asrc_abuffer;\n\n        avfilter_register(&avfilter_asrc_abuffer);\n\n    }\n\n    {\n\n        extern AVFilter avfilter_vsink_buffer;\n\n        avfilter_register(&avfilter_vsink_buffer);\n\n    }\n\n    {\n\n        extern AVFilter avfilter_asink_abuffer;\n\n        avfilter_register(&avfilter_asink_abuffer);\n\n    }\n\n}", "idx": 24338}
{"project": "FFmpeg", "commit_id": "5b0e811a65737463c7e4206b68a23e19d4473519", "target": 1, "func": "static void qtrle_decode_16bpp(QtrleContext *s)\n\n{\n\n    int stream_ptr;\n\n    int header;\n\n    int start_line;\n\n    int lines_to_change;\n\n    signed char rle_code;\n\n    int row_ptr, pixel_ptr;\n\n    int row_inc = s->frame.linesize[0];\n\n    unsigned short rgb16;\n\n    unsigned char *rgb = s->frame.data[0];\n\n    int pixel_limit = s->frame.linesize[0] * s->avctx->height;\n\n\n\n    /* check if this frame is even supposed to change */\n\n    if (s->size < 8)\n\n        return;\n\n\n\n    /* start after the chunk size */\n\n    stream_ptr = 4;\n\n\n\n    /* fetch the header */\n\n    CHECK_STREAM_PTR(2);\n\n    header = BE_16(&s->buf[stream_ptr]);\n\n    stream_ptr += 2;\n\n\n\n    /* if a header is present, fetch additional decoding parameters */\n\n    if (header & 0x0008) {\n\n        CHECK_STREAM_PTR(8);\n\n        start_line = BE_16(&s->buf[stream_ptr]);\n\n        stream_ptr += 4;\n\n        lines_to_change = BE_16(&s->buf[stream_ptr]);\n\n        stream_ptr += 4;\n\n    } else {\n\n        start_line = 0;\n\n        lines_to_change = s->avctx->height;\n\n    }\n\n\n\n    row_ptr = row_inc * start_line;\n\n    while (lines_to_change--) {\n\n        CHECK_STREAM_PTR(2);\n\n        pixel_ptr = row_ptr + (s->buf[stream_ptr++] - 1) * 2;\n\n\n\n        while ((rle_code = (signed char)s->buf[stream_ptr++]) != -1) {\n\n            if (rle_code == 0) {\n\n                /* there's another skip code in the stream */\n\n                CHECK_STREAM_PTR(1);\n\n                pixel_ptr += (s->buf[stream_ptr++] - 1) * 2;\n\n                CHECK_PIXEL_PTR(0);  /* make sure pixel_ptr is positive */\n\n            } else if (rle_code < 0) {\n\n                /* decode the run length code */\n\n                rle_code = -rle_code;\n\n                CHECK_STREAM_PTR(2);\n\n                rgb16 = BE_16(&s->buf[stream_ptr]);\n\n                stream_ptr += 2;\n\n\n\n                CHECK_PIXEL_PTR(rle_code * 2);\n\n\n\n                while (rle_code--) {\n\n                    *(unsigned short *)(&rgb[pixel_ptr]) = rgb16;\n\n                    pixel_ptr += 2;\n\n                }\n\n            } else {\n\n                CHECK_STREAM_PTR(rle_code * 2);\n\n                CHECK_PIXEL_PTR(rle_code * 2);\n\n\n\n                /* copy pixels directly to output */\n\n                while (rle_code--) {\n\n                    rgb16 = BE_16(&s->buf[stream_ptr]);\n\n                    stream_ptr += 2;\n\n                    *(unsigned short *)(&rgb[pixel_ptr]) = rgb16;\n\n                    pixel_ptr += 2;\n\n                }\n\n            }\n\n        }\n\n        row_ptr += row_inc;\n\n    }\n\n}\n", "idx": 24340}
{"project": "FFmpeg", "commit_id": "29ba091136a5e04574f7bfc1b17536c923958f6f", "target": 0, "func": "void show_banner(void)\n\n{\n\n    fprintf(stderr, \"%s version \" FFMPEG_VERSION \", Copyright (c) %d-%d the FFmpeg developers\\n\",\n\n            program_name, program_birth_year, this_year);\n\n    fprintf(stderr, \"  built on %s %s with %s %s\\n\",\n\n            __DATE__, __TIME__, CC_TYPE, CC_VERSION);\n\n    fprintf(stderr, \"  configuration: \" FFMPEG_CONFIGURATION \"\\n\");\n\n    print_all_libs_info(stderr, INDENT|SHOW_CONFIG);\n\n    print_all_libs_info(stderr, INDENT|SHOW_VERSION);\n\n}\n", "idx": 24341}
{"project": "FFmpeg", "commit_id": "82dd7d0dec29ee59af91ce18c29eb151b363ff37", "target": 0, "func": "static int decode_delta_block (bit_buffer_t *bitbuf,\n\n\t\t\tuint8_t *current, uint8_t *previous, int pitch,\n\n\t\t\tsvq1_pmv_t *motion, int x, int y) {\n\n  uint32_t bit_cache;\n\n  uint32_t block_type;\n\n  int\t   result = 0;\n\n\n\n  /* get block type */\n\n  bit_cache = get_bit_cache (bitbuf);\n\n\n\n  bit_cache\t>>= (32 - 3);\n\n  block_type\t  = block_type_table[bit_cache].value;\n\n  skip_bits(bitbuf,block_type_table[bit_cache].length);\n\n\n\n  /* reset motion vectors */\n\n  if (block_type == SVQ1_BLOCK_SKIP || block_type == SVQ1_BLOCK_INTRA) {\n\n    motion[0].x\t\t  = 0;\n\n    motion[0].y\t\t  = 0;\n\n    motion[(x / 8) + 2].x = 0;\n\n    motion[(x / 8) + 2].y = 0;\n\n    motion[(x / 8) + 3].x = 0;\n\n    motion[(x / 8) + 3].y = 0;\n\n  }\n\n\n\n  switch (block_type) {\n\n  case SVQ1_BLOCK_SKIP:\n\n    skip_block (current, previous, pitch, x, y);\n\n    break;\n\n\n\n  case SVQ1_BLOCK_INTER:\n\n    result = motion_inter_block (bitbuf, current, previous, pitch, motion, x, y);\n\n\n\n    if (result != 0)\n\n    {\n\n#ifdef DEBUG_SVQ1\n\n    printf(\"Error in motion_inter_block %i\\n\",result);\n\n#endif\n\n      break;\n\n    }\n\n    result = decode_svq1_block (bitbuf, current, pitch, 0);\n\n    break;\n\n\n\n  case SVQ1_BLOCK_INTER_4V:\n\n    result = motion_inter_4v_block (bitbuf, current, previous, pitch, motion, x, y);\n\n\n\n    if (result != 0)\n\n    {\n\n#ifdef DEBUG_SVQ1\n\n    printf(\"Error in motion_inter_4v_block %i\\n\",result);\n\n#endif\n\n      break;\n\n    }\n\n    result = decode_svq1_block (bitbuf, current, pitch, 0);\n\n    break;\n\n\n\n  case SVQ1_BLOCK_INTRA:\n\n    result = decode_svq1_block (bitbuf, current, pitch, 1);\n\n    break;\n\n  }\n\n\n\n  return result;\n\n}\n", "idx": 24342}
{"project": "FFmpeg", "commit_id": "e45a2872fafe631c14aee9f79d0963d68c4fc1fd", "target": 0, "func": "void powerpc_display_perf_report(void)\n\n{\n\n  int i;\n\n#ifndef POWERPC_PERF_USE_PMC\n\n  fprintf(stderr, \"PowerPC performance report\\n Values are from the Time Base register, and represent 4 bus cycles.\\n\");\n\n#else /* POWERPC_PERF_USE_PMC */\n\n  fprintf(stderr, \"PowerPC performance report\\n Values are from the PMC registers, and represent whatever the registers are set to record.\\n\");\n\n#endif /* POWERPC_PERF_USE_PMC */\n\n  for(i = 0 ; i < powerpc_perf_total ; i++)\n\n  {\n\n    if (perfdata[i][powerpc_data_num] != (unsigned long long)0)\n\n      fprintf(stderr, \" Function \\\"%s\\\" (pmc1):\\n\\tmin: %llu\\n\\tmax: %llu\\n\\tavg: %1.2lf (%llu)\\n\",\n\n              perfname[i],\n\n              perfdata[i][powerpc_data_min],\n\n              perfdata[i][powerpc_data_max],\n\n              (double)perfdata[i][powerpc_data_sum] /\n\n              (double)perfdata[i][powerpc_data_num],\n\n              perfdata[i][powerpc_data_num]);\n\n#ifdef POWERPC_PERF_USE_PMC\n\n    if (perfdata_pmc2[i][powerpc_data_num] != (unsigned long long)0)\n\n      fprintf(stderr, \" Function \\\"%s\\\" (pmc2):\\n\\tmin: %llu\\n\\tmax: %llu\\n\\tavg: %1.2lf (%llu)\\n\",\n\n              perfname[i],\n\n              perfdata_pmc2[i][powerpc_data_min],\n\n              perfdata_pmc2[i][powerpc_data_max],\n\n              (double)perfdata_pmc2[i][powerpc_data_sum] /\n\n              (double)perfdata_pmc2[i][powerpc_data_num],\n\n              perfdata_pmc2[i][powerpc_data_num]);\n\n    if (perfdata_pmc3[i][powerpc_data_num] != (unsigned long long)0)\n\n      fprintf(stderr, \" Function \\\"%s\\\" (pmc3):\\n\\tmin: %llu\\n\\tmax: %llu\\n\\tavg: %1.2lf (%llu)\\n\",\n\n              perfname[i],\n\n              perfdata_pmc3[i][powerpc_data_min],\n\n              perfdata_pmc3[i][powerpc_data_max],\n\n              (double)perfdata_pmc3[i][powerpc_data_sum] /\n\n              (double)perfdata_pmc3[i][powerpc_data_num],\n\n              perfdata_pmc3[i][powerpc_data_num]);\n\n#endif\n\n  }\n\n}\n", "idx": 24344}
{"project": "FFmpeg", "commit_id": "7d78a964413a50409b1db441d966cd2810eb6c86", "target": 1, "func": "static int msrle_decode_pal4(AVCodecContext *avctx, AVPicture *pic,\n\n                              const uint8_t *data, int data_size)\n\n{\n\n    int stream_ptr = 0;\n\n    unsigned char rle_code;\n\n    unsigned char extra_byte, odd_pixel;\n\n    unsigned char stream_byte;\n\n    int pixel_ptr = 0;\n\n    int row_dec = pic->linesize[0];\n\n    int row_ptr = (avctx->height - 1) * row_dec;\n\n    int frame_size = row_dec * avctx->height;\n\n    int i;\n\n\n\n    while (row_ptr >= 0) {\n\n        FETCH_NEXT_STREAM_BYTE();\n\n        rle_code = stream_byte;\n\n        if (rle_code == 0) {\n\n            /* fetch the next byte to see how to handle escape code */\n\n            FETCH_NEXT_STREAM_BYTE();\n\n            if (stream_byte == 0) {\n\n                /* line is done, goto the next one */\n\n                row_ptr -= row_dec;\n\n                pixel_ptr = 0;\n\n            } else if (stream_byte == 1) {\n\n                /* decode is done */\n\n                return 0;\n\n            } else if (stream_byte == 2) {\n\n                /* reposition frame decode coordinates */\n\n                FETCH_NEXT_STREAM_BYTE();\n\n                pixel_ptr += stream_byte;\n\n                FETCH_NEXT_STREAM_BYTE();\n\n                row_ptr -= stream_byte * row_dec;\n\n            } else {\n\n                // copy pixels from encoded stream\n\n                odd_pixel =  stream_byte & 1;\n\n                rle_code = (stream_byte + 1) / 2;\n\n                extra_byte = rle_code & 0x01;\n\n                if (row_ptr + pixel_ptr + stream_byte > frame_size) {\n\n                    av_log(avctx, AV_LOG_ERROR, \" MS RLE: frame ptr just went out of bounds (1)\\n\");\n\n                    return -1;\n\n                }\n\n\n\n                for (i = 0; i < rle_code; i++) {\n\n                    if (pixel_ptr >= avctx->width)\n\n                        break;\n\n                    FETCH_NEXT_STREAM_BYTE();\n\n                    pic->data[0][row_ptr + pixel_ptr] = stream_byte >> 4;\n\n                    pixel_ptr++;\n\n                    if (i + 1 == rle_code && odd_pixel)\n\n                        break;\n\n                    if (pixel_ptr >= avctx->width)\n\n                        break;\n\n                    pic->data[0][row_ptr + pixel_ptr] = stream_byte & 0x0F;\n\n                    pixel_ptr++;\n\n                }\n\n\n\n                // if the RLE code is odd, skip a byte in the stream\n\n                if (extra_byte)\n\n                    stream_ptr++;\n\n            }\n\n        } else {\n\n            // decode a run of data\n\n            if (row_ptr + pixel_ptr + stream_byte > frame_size) {\n\n                av_log(avctx, AV_LOG_ERROR, \" MS RLE: frame ptr just went out of bounds (1)\\n\");\n\n                return -1;\n\n            }\n\n            FETCH_NEXT_STREAM_BYTE();\n\n            for (i = 0; i < rle_code; i++) {\n\n                if (pixel_ptr >= avctx->width)\n\n                    break;\n\n                if ((i & 1) == 0)\n\n                    pic->data[0][row_ptr + pixel_ptr] = stream_byte >> 4;\n\n                else\n\n                    pic->data[0][row_ptr + pixel_ptr] = stream_byte & 0x0F;\n\n                pixel_ptr++;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* one last sanity check on the way out */\n\n    if (stream_ptr < data_size) {\n\n        av_log(avctx, AV_LOG_ERROR, \" MS RLE: ended frame decode with bytes left over (%d < %d)\\n\",\n\n            stream_ptr, data_size);\n\n        return -1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24346}
{"project": "FFmpeg", "commit_id": "bde6f6eadc24b372c12da2894f2ee0b86b5ff6a3", "target": 1, "func": "static void vc1_mc_4mv_chroma4(VC1Context *v)\n\n{\n\n    MpegEncContext *s = &v->s;\n\n    DSPContext *dsp = &v->s.dsp;\n\n    uint8_t *srcU, *srcV;\n\n    int uvsrc_x, uvsrc_y;\n\n    int uvmx_field[4], uvmy_field[4];\n\n    int i, off, tx, ty;\n\n    int fieldmv = v->blk_mv_type[s->block_index[0]];\n\n    static const int s_rndtblfield[16] = { 0, 0, 1, 2, 4, 4, 5, 6, 2, 2, 3, 8, 6, 6, 7, 12 };\n\n    int v_dist = fieldmv ? 1 : 4; // vertical offset for lower sub-blocks\n\n    int v_edge_pos = s->v_edge_pos >> 1;\n\n\n\n    if (!v->s.last_picture.f.data[0])\n\n        return;\n\n    if (s->flags & CODEC_FLAG_GRAY)\n\n        return;\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        tx = s->mv[0][i][0];\n\n        uvmx_field[i] = (tx + ((tx & 3) == 3)) >> 1;\n\n        ty = s->mv[0][i][1];\n\n        if (fieldmv)\n\n            uvmy_field[i] = (ty >> 4) * 8 + s_rndtblfield[ty & 0xF];\n\n        else\n\n            uvmy_field[i] = (ty + ((ty & 3) == 3)) >> 1;\n\n    }\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        off = (i & 1) * 4 + ((i & 2) ? v_dist * s->uvlinesize : 0);\n\n        uvsrc_x = s->mb_x * 8 +  (i & 1) * 4           + (uvmx_field[i] >> 2);\n\n        uvsrc_y = s->mb_y * 8 + ((i & 2) ? v_dist : 0) + (uvmy_field[i] >> 2);\n\n        // FIXME: implement proper pull-back (see vc1cropmv.c, vc1CROPMV_ChromaPullBack())\n\n        uvsrc_x = av_clip(uvsrc_x, -8, s->avctx->coded_width  >> 1);\n\n        uvsrc_y = av_clip(uvsrc_y, -8, s->avctx->coded_height >> 1);\n\n        srcU = s->last_picture.f.data[1] + uvsrc_y * s->uvlinesize + uvsrc_x;\n\n        srcV = s->last_picture.f.data[2] + uvsrc_y * s->uvlinesize + uvsrc_x;\n\n        uvmx_field[i] = (uvmx_field[i] & 3) << 1;\n\n        uvmy_field[i] = (uvmy_field[i] & 3) << 1;\n\n\n\n        if (fieldmv && !(uvsrc_y & 1))\n\n            v_edge_pos--;\n\n        if (fieldmv && (uvsrc_y & 1) && uvsrc_y < 2)\n\n            uvsrc_y--;\n\n        if ((v->mv_mode == MV_PMODE_INTENSITY_COMP)\n\n            || s->h_edge_pos < 10 || v_edge_pos < (5 << fieldmv)\n\n            || (unsigned)uvsrc_x > (s->h_edge_pos >> 1) - 5\n\n            || (unsigned)uvsrc_y > v_edge_pos - (5 << fieldmv)) {\n\n            s->dsp.emulated_edge_mc(s->edge_emu_buffer, srcU, s->uvlinesize,\n\n                                    5, (5 << fieldmv), uvsrc_x, uvsrc_y,\n\n                                    s->h_edge_pos >> 1, v_edge_pos);\n\n            s->dsp.emulated_edge_mc(s->edge_emu_buffer + 16, srcV, s->uvlinesize,\n\n                                    5, (5 << fieldmv), uvsrc_x, uvsrc_y,\n\n                                    s->h_edge_pos >> 1, v_edge_pos);\n\n            srcU = s->edge_emu_buffer;\n\n            srcV = s->edge_emu_buffer + 16;\n\n\n\n            /* if we deal with intensity compensation we need to scale source blocks */\n\n            if (v->mv_mode == MV_PMODE_INTENSITY_COMP) {\n\n                int i, j;\n\n                uint8_t *src, *src2;\n\n\n\n                src  = srcU;\n\n                src2 = srcV;\n\n                for (j = 0; j < 5; j++) {\n\n                    for (i = 0; i < 5; i++) {\n\n                        src[i]  = v->lutuv[src[i]];\n\n                        src2[i] = v->lutuv[src2[i]];\n\n                    }\n\n                    src  += s->uvlinesize << 1;\n\n                    src2 += s->uvlinesize << 1;\n\n                }\n\n            }\n\n        }\n\n        if (!v->rnd) {\n\n            dsp->put_h264_chroma_pixels_tab[1](s->dest[1] + off, srcU, s->uvlinesize << fieldmv, 4, uvmx_field[i], uvmy_field[i]);\n\n            dsp->put_h264_chroma_pixels_tab[1](s->dest[2] + off, srcV, s->uvlinesize << fieldmv, 4, uvmx_field[i], uvmy_field[i]);\n\n        } else {\n\n            v->vc1dsp.put_no_rnd_vc1_chroma_pixels_tab[1](s->dest[1] + off, srcU, s->uvlinesize << fieldmv, 4, uvmx_field[i], uvmy_field[i]);\n\n            v->vc1dsp.put_no_rnd_vc1_chroma_pixels_tab[1](s->dest[2] + off, srcV, s->uvlinesize << fieldmv, 4, uvmx_field[i], uvmy_field[i]);\n\n        }\n\n    }\n\n}\n", "idx": 24348}
{"project": "FFmpeg", "commit_id": "7cf22c79706d23d40d16cee37eb32d5797adcc2c", "target": 0, "func": "yuv2rgba64_1_c_template(SwsContext *c, const int32_t *buf0,\n\n                       const int32_t *ubuf[2], const int32_t *vbuf[2],\n\n                       const int32_t *abuf0, uint16_t *dest, int dstW,\n\n                       int uvalpha, int y, enum AVPixelFormat target, int hasAlpha, int eightbytes)\n\n{\n\n    const int32_t *ubuf0 = ubuf[0], *vbuf0 = vbuf[0];\n\n    int i;\n\n    int A1 = 0xffff<<14, A2= 0xffff<<14;\n\n\n\n    if (uvalpha < 2048) {\n\n        for (i = 0; i < ((dstW + 1) >> 1); i++) {\n\n            int Y1 = (buf0[i * 2]    ) >> 2;\n\n            int Y2 = (buf0[i * 2 + 1]) >> 2;\n\n            int U  = (ubuf0[i] + (-128 << 11)) >> 2;\n\n            int V  = (vbuf0[i] + (-128 << 11)) >> 2;\n\n            int R, G, B;\n\n\n\n            Y1 -= c->yuv2rgb_y_offset;\n\n            Y2 -= c->yuv2rgb_y_offset;\n\n            Y1 *= c->yuv2rgb_y_coeff;\n\n            Y2 *= c->yuv2rgb_y_coeff;\n\n            Y1 += 1 << 13;\n\n            Y2 += 1 << 13;\n\n\n\n            if (hasAlpha) {\n\n                A1 = abuf0[i * 2    ] << 11;\n\n                A2 = abuf0[i * 2 + 1] << 11;\n\n\n\n                A1 += 1 << 13;\n\n                A2 += 1 << 13;\n\n            }\n\n\n\n            R = V * c->yuv2rgb_v2r_coeff;\n\n            G = V * c->yuv2rgb_v2g_coeff + U * c->yuv2rgb_u2g_coeff;\n\n            B =                            U * c->yuv2rgb_u2b_coeff;\n\n\n\n            output_pixel(&dest[0], av_clip_uintp2(R_B + Y1, 30) >> 14);\n\n            output_pixel(&dest[1], av_clip_uintp2(  G + Y1, 30) >> 14);\n\n            output_pixel(&dest[2], av_clip_uintp2(B_R + Y1, 30) >> 14);\n\n            if (eightbytes) {\n\n                output_pixel(&dest[3], av_clip_uintp2(A1      , 30) >> 14);\n\n                output_pixel(&dest[4], av_clip_uintp2(R_B + Y2, 30) >> 14);\n\n                output_pixel(&dest[5], av_clip_uintp2(  G + Y2, 30) >> 14);\n\n                output_pixel(&dest[6], av_clip_uintp2(B_R + Y2, 30) >> 14);\n\n                output_pixel(&dest[7], av_clip_uintp2(A2      , 30) >> 14);\n\n                dest += 8;\n\n            } else {\n\n                output_pixel(&dest[3], av_clip_uintp2(R_B + Y2, 30) >> 14);\n\n                output_pixel(&dest[4], av_clip_uintp2(  G + Y2, 30) >> 14);\n\n                output_pixel(&dest[5], av_clip_uintp2(B_R + Y2, 30) >> 14);\n\n                dest += 6;\n\n            }\n\n        }\n\n    } else {\n\n        const int32_t *ubuf1 = ubuf[1], *vbuf1 = vbuf[1];\n\n        int A1 = 0xffff<<14, A2 = 0xffff<<14;\n\n        for (i = 0; i < ((dstW + 1) >> 1); i++) {\n\n            int Y1 = (buf0[i * 2]    ) >> 2;\n\n            int Y2 = (buf0[i * 2 + 1]) >> 2;\n\n            int U  = (ubuf0[i] + ubuf1[i] + (-128 << 12)) >> 3;\n\n            int V  = (vbuf0[i] + vbuf1[i] + (-128 << 12)) >> 3;\n\n            int R, G, B;\n\n\n\n            Y1 -= c->yuv2rgb_y_offset;\n\n            Y2 -= c->yuv2rgb_y_offset;\n\n            Y1 *= c->yuv2rgb_y_coeff;\n\n            Y2 *= c->yuv2rgb_y_coeff;\n\n            Y1 += 1 << 13;\n\n            Y2 += 1 << 13;\n\n\n\n            if (hasAlpha) {\n\n                A1 = abuf0[i * 2    ] << 11;\n\n                A2 = abuf0[i * 2 + 1] << 11;\n\n\n\n                A1 += 1 << 13;\n\n                A2 += 1 << 13;\n\n            }\n\n\n\n            R = V * c->yuv2rgb_v2r_coeff;\n\n            G = V * c->yuv2rgb_v2g_coeff + U * c->yuv2rgb_u2g_coeff;\n\n            B =                            U * c->yuv2rgb_u2b_coeff;\n\n\n\n            output_pixel(&dest[0], av_clip_uintp2(R_B + Y1, 30) >> 14);\n\n            output_pixel(&dest[1], av_clip_uintp2(  G + Y1, 30) >> 14);\n\n            output_pixel(&dest[2], av_clip_uintp2(B_R + Y1, 30) >> 14);\n\n            if (eightbytes) {\n\n                output_pixel(&dest[3], av_clip_uintp2(A1      , 30) >> 14);\n\n                output_pixel(&dest[4], av_clip_uintp2(R_B + Y2, 30) >> 14);\n\n                output_pixel(&dest[5], av_clip_uintp2(  G + Y2, 30) >> 14);\n\n                output_pixel(&dest[6], av_clip_uintp2(B_R + Y2, 30) >> 14);\n\n                output_pixel(&dest[7], av_clip_uintp2(A2      , 30) >> 14);\n\n                dest += 8;\n\n            } else {\n\n                output_pixel(&dest[3], av_clip_uintp2(R_B + Y2, 30) >> 14);\n\n                output_pixel(&dest[4], av_clip_uintp2(  G + Y2, 30) >> 14);\n\n                output_pixel(&dest[5], av_clip_uintp2(B_R + Y2, 30) >> 14);\n\n                dest += 6;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 24356}
{"project": "FFmpeg", "commit_id": "68f593b48433842f3407586679fe07f3e5199ab9", "target": 0, "func": "static int mjpegb_decode_frame(AVCodecContext *avctx, \n\n                              void *data, int *data_size,\n\n                              UINT8 *buf, int buf_size)\n\n{\n\n    MJpegDecodeContext *s = avctx->priv_data;\n\n    UINT8 *buf_end, *buf_ptr;\n\n    int i;\n\n    AVPicture *picture = data;\n\n    GetBitContext hgb; /* for the header */\n\n    uint32_t dqt_offs, dht_offs, sof_offs, sos_offs, second_field_offs;\n\n    uint32_t field_size;\n\n\n\n    *data_size = 0;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0)\n\n        return 0;\n\n\n\n    buf_ptr = buf;\n\n    buf_end = buf + buf_size;\n\n    \n\nread_header:\n\n    /* reset on every SOI */\n\n    s->restart_interval = 0;\n\n\n\n    init_get_bits(&hgb, buf_ptr, /*buf_size*/buf_end - buf_ptr);\n\n\n\n    skip_bits(&hgb, 32); /* reserved zeros */\n\n    \n\n    if (get_bits(&hgb, 32) != be2me_32(ff_get_fourcc(\"mjpg\")))\n\n    {\n\n\tdprintf(\"not mjpeg-b (bad fourcc)\\n\");\n\n\treturn 0;\n\n    }\n\n\n\n    field_size = get_bits(&hgb, 32); /* field size */\n\n    dprintf(\"field size: 0x%x\\n\", field_size);\n\n    skip_bits(&hgb, 32); /* padded field size */\n\n    second_field_offs = get_bits(&hgb, 32);\n\n    dprintf(\"second field offs: 0x%x\\n\", second_field_offs);\n\n    if (second_field_offs)\n\n\ts->interlaced = 1;\n\n\n\n    dqt_offs = get_bits(&hgb, 32);\n\n    dprintf(\"dqt offs: 0x%x\\n\", dqt_offs);\n\n    if (dqt_offs)\n\n    {\n\n\tinit_get_bits(&s->gb, buf+dqt_offs, buf_end - (buf+dqt_offs));\n\n\ts->start_code = DQT;\n\n\tmjpeg_decode_dqt(s);\n\n    }\n\n    \n\n    dht_offs = get_bits(&hgb, 32);\n\n    dprintf(\"dht offs: 0x%x\\n\", dht_offs);\n\n    if (dht_offs)\n\n    {\n\n\tinit_get_bits(&s->gb, buf+dht_offs, buf_end - (buf+dht_offs));\n\n\ts->start_code = DHT;\n\n\tmjpeg_decode_dht(s);\n\n    }\n\n\n\n    sof_offs = get_bits(&hgb, 32);\n\n    dprintf(\"sof offs: 0x%x\\n\", sof_offs);\n\n    if (sof_offs)\n\n    {\n\n\tinit_get_bits(&s->gb, buf+sof_offs, buf_end - (buf+sof_offs));\n\n\ts->start_code = SOF0;\n\n\tif (mjpeg_decode_sof0(s) < 0)\n\n\t    return -1;\n\n    }\n\n\n\n    sos_offs = get_bits(&hgb, 32);\n\n    dprintf(\"sos offs: 0x%x\\n\", sos_offs);\n\n    if (sos_offs)\n\n    {\n\n//\tinit_get_bits(&s->gb, buf+sos_offs, buf_end - (buf+sos_offs));\n\n\tinit_get_bits(&s->gb, buf+sos_offs, field_size);\n\n\ts->start_code = SOS;\n\n\tmjpeg_decode_sos(s);\n\n    }\n\n\n\n    skip_bits(&hgb, 32); /* start of data offset */\n\n\n\n    if (s->interlaced) {\n\n        s->bottom_field ^= 1;\n\n        /* if not bottom field, do not output image yet */\n\n        if (s->bottom_field && second_field_offs)\n\n\t{\n\n\t    buf_ptr = buf + second_field_offs;\n\n\t    second_field_offs = 0;\n\n\t    goto read_header;\n\n    \t}\n\n    }\n\n\n\n    for(i=0;i<3;i++) {\n\n        picture->data[i] = s->current_picture[i];\n\n        picture->linesize[i] = (s->interlaced) ?\n\n    \t    s->linesize[i] >> 1 : s->linesize[i];\n\n    }\n\n    *data_size = sizeof(AVPicture);\n\n    avctx->height = s->height;\n\n    if (s->interlaced)\n\n        avctx->height *= 2;\n\n    avctx->width = s->width;\n\n    /* XXX: not complete test ! */\n\n    switch((s->h_count[0] << 4) | s->v_count[0]) {\n\n        case 0x11:\n\n    \t    avctx->pix_fmt = PIX_FMT_YUV444P;\n\n            break;\n\n        case 0x21:\n\n            avctx->pix_fmt = PIX_FMT_YUV422P;\n\n            break;\n\n        default:\n\n\tcase 0x22:\n\n            avctx->pix_fmt = PIX_FMT_YUV420P;\n\n            break;\n\n    }\n\n    /* dummy quality */\n\n    /* XXX: infer it with matrix */\n\n//    avctx->quality = 3; \n\n\n\n    return buf_ptr - buf;\n\n}\n", "idx": 24357}
{"project": "FFmpeg", "commit_id": "d1923d15a3544cbb94563a59e7169291db76b312", "target": 1, "func": "static int idcin_read_seek(AVFormatContext *s, int stream_index,\n\n                           int64_t timestamp, int flags)\n\n{\n\n    IdcinDemuxContext *idcin = s->priv_data;\n\n\n\n    if (idcin->first_pkt_pos > 0) {\n\n        int ret = avio_seek(s->pb, idcin->first_pkt_pos, SEEK_SET);\n\n        if (ret < 0)\n\n            return ret;\n\n        ff_update_cur_dts(s, s->streams[idcin->video_stream_index], 0);\n\n        idcin->next_chunk_is_video = 1;\n\n        idcin->current_audio_chunk = 0;\n\n        return 0;\n\n    }\n\n    return -1;\n\n}\n", "idx": 24358}
{"project": "FFmpeg", "commit_id": "1189af429211ac650aac730368a6cf5b23756605", "target": 1, "func": "static int output_frame(H264Context *h, AVFrame *dst, H264Picture *srcp)\n{\n    AVFrame *src = srcp->f;\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(src->format);\n    int i;\n    int ret = av_frame_ref(dst, src);\n    if (ret < 0)\n        return ret;\n    av_dict_set(&dst->metadata, \"stereo_mode\", ff_h264_sei_stereo_mode(h), 0);\n    if (srcp->sei_recovery_frame_cnt == 0)\n        dst->key_frame = 1;\n    if (!srcp->crop)\n        return 0;\n    for (i = 0; i < desc->nb_components; i++) {\n        int hshift = (i > 0) ? desc->log2_chroma_w : 0;\n        int vshift = (i > 0) ? desc->log2_chroma_h : 0;\n        int off    = ((srcp->crop_left >> hshift) << h->pixel_shift) +\n                      (srcp->crop_top  >> vshift) * dst->linesize[i];\n        dst->data[i] += off;\n    }\n    return 0;\n}", "idx": 24360}
{"project": "FFmpeg", "commit_id": "45fa03b1f9b0475df666f7592f250c37763b7d64", "target": 1, "func": "int ff_mjpeg_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n\n                          AVPacket *avpkt)\n\n{\n\n    AVFrame     *frame = data;\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    MJpegDecodeContext *s = avctx->priv_data;\n\n    const uint8_t *buf_end, *buf_ptr;\n\n    const uint8_t *unescaped_buf_ptr;\n\n    int hshift, vshift;\n\n    int unescaped_buf_size;\n\n    int start_code;\n\n    int i, index;\n\n    int ret = 0;\n\n    int is16bit;\n\n\n\n    av_dict_free(&s->exif_metadata);\n\n    av_freep(&s->stereo3d);\n\n    s->adobe_transform = -1;\n\n\n\n    buf_ptr = buf;\n\n    buf_end = buf + buf_size;\n\n    while (buf_ptr < buf_end) {\n\n        /* find start next marker */\n\n        start_code = ff_mjpeg_find_marker(s, &buf_ptr, buf_end,\n\n                                          &unescaped_buf_ptr,\n\n                                          &unescaped_buf_size);\n\n        /* EOF */\n\n        if (start_code < 0) {\n\n            break;\n\n        } else if (unescaped_buf_size > INT_MAX / 8) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"MJPEG packet 0x%x too big (%d/%d), corrupt data?\\n\",\n\n                   start_code, unescaped_buf_size, buf_size);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        av_log(avctx, AV_LOG_DEBUG, \"marker=%x avail_size_in_buf=%\"PTRDIFF_SPECIFIER\"\\n\",\n\n               start_code, buf_end - buf_ptr);\n\n\n\n        ret = init_get_bits8(&s->gb, unescaped_buf_ptr, unescaped_buf_size);\n\n\n\n        if (ret < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid buffer\\n\");\n\n            goto fail;\n\n        }\n\n\n\n        s->start_code = start_code;\n\n        if (s->avctx->debug & FF_DEBUG_STARTCODE)\n\n            av_log(avctx, AV_LOG_DEBUG, \"startcode: %X\\n\", start_code);\n\n\n\n        /* process markers */\n\n        if (start_code >= 0xd0 && start_code <= 0xd7)\n\n            av_log(avctx, AV_LOG_DEBUG,\n\n                   \"restart marker: %d\\n\", start_code & 0x0f);\n\n            /* APP fields */\n\n        else if (start_code >= APP0 && start_code <= APP15)\n\n            mjpeg_decode_app(s);\n\n            /* Comment */\n\n        else if (start_code == COM)\n\n            mjpeg_decode_com(s);\n\n\n\n        ret = -1;\n\n\n\n        if (!CONFIG_JPEGLS_DECODER &&\n\n            (start_code == SOF48 || start_code == LSE)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"JPEG-LS support not enabled.\\n\");\n\n            return AVERROR(ENOSYS);\n\n        }\n\n\n\n        if (avctx->skip_frame == AVDISCARD_ALL) {\n\n            switch(start_code) {\n\n            case SOF0:\n\n            case SOF1:\n\n            case SOF2:\n\n            case SOF3:\n\n            case SOF48:\n\n            case SOI:\n\n            case SOS:\n\n            case EOI:\n\n                break;\n\n            default:\n\n                goto skip;\n\n            }\n\n        }\n\n\n\n        switch (start_code) {\n\n        case SOI:\n\n            s->restart_interval = 0;\n\n            s->restart_count    = 0;\n\n            /* nothing to do on SOI */\n\n            break;\n\n        case DQT:\n\n            ff_mjpeg_decode_dqt(s);\n\n            break;\n\n        case DHT:\n\n            if ((ret = ff_mjpeg_decode_dht(s)) < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"huffman table decode error\\n\");\n\n                goto fail;\n\n            }\n\n            break;\n\n        case SOF0:\n\n        case SOF1:\n\n            s->lossless    = 0;\n\n            s->ls          = 0;\n\n            s->progressive = 0;\n\n            if ((ret = ff_mjpeg_decode_sof(s)) < 0)\n\n                goto fail;\n\n            break;\n\n        case SOF2:\n\n            s->lossless    = 0;\n\n            s->ls          = 0;\n\n            s->progressive = 1;\n\n            if ((ret = ff_mjpeg_decode_sof(s)) < 0)\n\n                goto fail;\n\n            break;\n\n        case SOF3:\n\n            s->avctx->properties |= FF_CODEC_PROPERTY_LOSSLESS;\n\n            s->lossless    = 1;\n\n            s->ls          = 0;\n\n            s->progressive = 0;\n\n            if ((ret = ff_mjpeg_decode_sof(s)) < 0)\n\n                goto fail;\n\n            break;\n\n        case SOF48:\n\n            s->avctx->properties |= FF_CODEC_PROPERTY_LOSSLESS;\n\n            s->lossless    = 1;\n\n            s->ls          = 1;\n\n            s->progressive = 0;\n\n            if ((ret = ff_mjpeg_decode_sof(s)) < 0)\n\n                goto fail;\n\n            break;\n\n        case LSE:\n\n            if (!CONFIG_JPEGLS_DECODER ||\n\n                (ret = ff_jpegls_decode_lse(s)) < 0)\n\n                goto fail;\n\n            break;\n\n        case EOI:\n\neoi_parser:\n\n            s->cur_scan = 0;\n\n            if (!s->got_picture) {\n\n                av_log(avctx, AV_LOG_WARNING,\n\n                       \"Found EOI before any SOF, ignoring\\n\");\n\n                break;\n\n            }\n\n            if (s->interlaced) {\n\n                s->bottom_field ^= 1;\n\n                /* if not bottom field, do not output image yet */\n\n                if (s->bottom_field == !s->interlace_polarity)\n\n                    break;\n\n            }\n\n            if (avctx->skip_frame == AVDISCARD_ALL) {\n\n                s->got_picture = 0;\n\n                goto the_end_no_picture;\n\n            }\n\n            if ((ret = av_frame_ref(frame, s->picture_ptr)) < 0)\n\n                return ret;\n\n            *got_frame = 1;\n\n            s->got_picture = 0;\n\n\n\n            if (!s->lossless) {\n\n                int qp = FFMAX3(s->qscale[0],\n\n                                s->qscale[1],\n\n                                s->qscale[2]);\n\n                int qpw = (s->width + 15) / 16;\n\n                AVBufferRef *qp_table_buf = av_buffer_alloc(qpw);\n\n                if (qp_table_buf) {\n\n                    memset(qp_table_buf->data, qp, qpw);\n\n                    av_frame_set_qp_table(data, qp_table_buf, 0, FF_QSCALE_TYPE_MPEG1);\n\n                }\n\n\n\n                if(avctx->debug & FF_DEBUG_QP)\n\n                    av_log(avctx, AV_LOG_DEBUG, \"QP: %d\\n\", qp);\n\n            }\n\n\n\n            goto the_end;\n\n        case SOS:\n\n            s->cur_scan++;\n\n            if (avctx->skip_frame == AVDISCARD_ALL)\n\n                break;\n\n\n\n            if ((ret = ff_mjpeg_decode_sos(s, NULL, 0, NULL)) < 0 &&\n\n                (avctx->err_recognition & AV_EF_EXPLODE))\n\n                goto fail;\n\n            break;\n\n        case DRI:\n\n            mjpeg_decode_dri(s);\n\n            break;\n\n        case SOF5:\n\n        case SOF6:\n\n        case SOF7:\n\n        case SOF9:\n\n        case SOF10:\n\n        case SOF11:\n\n        case SOF13:\n\n        case SOF14:\n\n        case SOF15:\n\n        case JPG:\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"mjpeg: unsupported coding type (%x)\\n\", start_code);\n\n            break;\n\n        }\n\n\n\nskip:\n\n        /* eof process start code */\n\n        buf_ptr += (get_bits_count(&s->gb) + 7) / 8;\n\n        av_log(avctx, AV_LOG_DEBUG,\n\n               \"marker parser used %d bytes (%d bits)\\n\",\n\n               (get_bits_count(&s->gb) + 7) / 8, get_bits_count(&s->gb));\n\n    }\n\n    if (s->got_picture && s->cur_scan) {\n\n        av_log(avctx, AV_LOG_WARNING, \"EOI missing, emulating\\n\");\n\n        goto eoi_parser;\n\n    }\n\n    av_log(avctx, AV_LOG_FATAL, \"No JPEG data found in image\\n\");\n\n    return AVERROR_INVALIDDATA;\n\nfail:\n\n    s->got_picture = 0;\n\n    return ret;\n\nthe_end:\n\n\n\n    is16bit = av_pix_fmt_desc_get(s->avctx->pix_fmt)->comp[0].step > 1;\n\n\n\n    if (AV_RB32(s->upscale_h)) {\n\n        int p;\n\n        av_assert0(avctx->pix_fmt == AV_PIX_FMT_YUVJ444P ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUV444P  ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUVJ440P ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUV440P  ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUVA444P ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUVJ420P ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUV420P  ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUV420P16||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUVA420P  ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUVA420P16||\n\n                   avctx->pix_fmt == AV_PIX_FMT_GBRP     ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_GBRAP\n\n                  );\n\n        avcodec_get_chroma_sub_sample(s->avctx->pix_fmt, &hshift, &vshift);\n\n        for (p = 0; p<4; p++) {\n\n            uint8_t *line = s->picture_ptr->data[p];\n\n            int w = s->width;\n\n            int h = s->height;\n\n            if (!s->upscale_h[p])\n\n                continue;\n\n            if (p==1 || p==2) {\n\n                w = AV_CEIL_RSHIFT(w, hshift);\n\n                h = AV_CEIL_RSHIFT(h, vshift);\n\n            }\n\n            if (s->upscale_v[p])\n\n                h = (h+1)>>1;\n\n            av_assert0(w > 0);\n\n            for (i = 0; i < h; i++) {\n\n                if (s->upscale_h[p] == 1) {\n\n                    if (is16bit) ((uint16_t*)line)[w - 1] = ((uint16_t*)line)[(w - 1) / 2];\n\n                    else                      line[w - 1] = line[(w - 1) / 2];\n\n                    for (index = w - 2; index > 0; index--) {\n\n                        if (is16bit)\n\n                            ((uint16_t*)line)[index] = (((uint16_t*)line)[index / 2] + ((uint16_t*)line)[(index + 1) / 2]) >> 1;\n\n                        else\n\n                            line[index] = (line[index / 2] + line[(index + 1) / 2]) >> 1;\n\n                    }\n\n                } else if (s->upscale_h[p] == 2) {\n\n                    if (is16bit) {\n\n                        ((uint16_t*)line)[w - 1] = ((uint16_t*)line)[(w - 1) / 3];\n\n                        if (w > 1)\n\n                            ((uint16_t*)line)[w - 2] = ((uint16_t*)line)[w - 1];\n\n                    } else {\n\n                        line[w - 1] = line[(w - 1) / 3];\n\n                        if (w > 1)\n\n                            line[w - 2] = line[w - 1];\n\n                    }\n\n                    for (index = w - 3; index > 0; index--) {\n\n                        line[index] = (line[index / 3] + line[(index + 1) / 3] + line[(index + 2) / 3] + 1) / 3;\n\n                    }\n\n                }\n\n                line += s->linesize[p];\n\n            }\n\n        }\n\n    }\n\n    if (AV_RB32(s->upscale_v)) {\n\n        int p;\n\n        av_assert0(avctx->pix_fmt == AV_PIX_FMT_YUVJ444P ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUV444P  ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUVJ422P ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUV422P  ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUVJ420P ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUV420P  ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUV440P  ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUVJ440P ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUVA444P ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUVA420P  ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_YUVA420P16||\n\n                   avctx->pix_fmt == AV_PIX_FMT_GBRP     ||\n\n                   avctx->pix_fmt == AV_PIX_FMT_GBRAP\n\n                   );\n\n        avcodec_get_chroma_sub_sample(s->avctx->pix_fmt, &hshift, &vshift);\n\n        for (p = 0; p < 4; p++) {\n\n            uint8_t *dst;\n\n            int w = s->width;\n\n            int h = s->height;\n\n            if (!s->upscale_v[p])\n\n                continue;\n\n            if (p==1 || p==2) {\n\n                w = AV_CEIL_RSHIFT(w, hshift);\n\n                h = AV_CEIL_RSHIFT(h, vshift);\n\n            }\n\n            dst = &((uint8_t *)s->picture_ptr->data[p])[(h - 1) * s->linesize[p]];\n\n            for (i = h - 1; i; i--) {\n\n                uint8_t *src1 = &((uint8_t *)s->picture_ptr->data[p])[i / 2 * s->linesize[p]];\n\n                uint8_t *src2 = &((uint8_t *)s->picture_ptr->data[p])[(i + 1) / 2 * s->linesize[p]];\n\n                if (src1 == src2 || i == h - 1) {\n\n                    memcpy(dst, src1, w);\n\n                } else {\n\n                    for (index = 0; index < w; index++)\n\n                        dst[index] = (src1[index] + src2[index]) >> 1;\n\n                }\n\n                dst -= s->linesize[p];\n\n            }\n\n        }\n\n    }\n\n    if (s->flipped) {\n\n        int j;\n\n        avcodec_get_chroma_sub_sample(s->avctx->pix_fmt, &hshift, &vshift);\n\n        for (index=0; index<4; index++) {\n\n            uint8_t *dst = s->picture_ptr->data[index];\n\n            int w = s->picture_ptr->width;\n\n            int h = s->picture_ptr->height;\n\n            if(index && index<3){\n\n                w = AV_CEIL_RSHIFT(w, hshift);\n\n                h = AV_CEIL_RSHIFT(h, vshift);\n\n            }\n\n            if(dst){\n\n                uint8_t *dst2 = dst + s->picture_ptr->linesize[index]*(h-1);\n\n                for (i=0; i<h/2; i++) {\n\n                    for (j=0; j<w; j++)\n\n                        FFSWAP(int, dst[j], dst2[j]);\n\n                    dst  += s->picture_ptr->linesize[index];\n\n                    dst2 -= s->picture_ptr->linesize[index];\n\n                }\n\n            }\n\n        }\n\n    }\n\n    if (s->adobe_transform == 0 && s->avctx->pix_fmt == AV_PIX_FMT_GBRAP) {\n\n        int w = s->picture_ptr->width;\n\n        int h = s->picture_ptr->height;\n\n        for (i=0; i<h; i++) {\n\n            int j;\n\n            uint8_t *dst[4];\n\n            for (index=0; index<4; index++) {\n\n                dst[index] =   s->picture_ptr->data[index]\n\n                             + s->picture_ptr->linesize[index]*i;\n\n            }\n\n            for (j=0; j<w; j++) {\n\n                int k = dst[3][j];\n\n                int r = dst[0][j] * k;\n\n                int g = dst[1][j] * k;\n\n                int b = dst[2][j] * k;\n\n                dst[0][j] = g*257 >> 16;\n\n                dst[1][j] = b*257 >> 16;\n\n                dst[2][j] = r*257 >> 16;\n\n                dst[3][j] = 255;\n\n            }\n\n        }\n\n    }\n\n    if (s->adobe_transform == 2 && s->avctx->pix_fmt == AV_PIX_FMT_YUVA444P) {\n\n        int w = s->picture_ptr->width;\n\n        int h = s->picture_ptr->height;\n\n        for (i=0; i<h; i++) {\n\n            int j;\n\n            uint8_t *dst[4];\n\n            for (index=0; index<4; index++) {\n\n                dst[index] =   s->picture_ptr->data[index]\n\n                             + s->picture_ptr->linesize[index]*i;\n\n            }\n\n            for (j=0; j<w; j++) {\n\n                int k = dst[3][j];\n\n                int r = (255 - dst[0][j]) * k;\n\n                int g = (128 - dst[1][j]) * k;\n\n                int b = (128 - dst[2][j]) * k;\n\n                dst[0][j] = r*257 >> 16;\n\n                dst[1][j] = (g*257 >> 16) + 128;\n\n                dst[2][j] = (b*257 >> 16) + 128;\n\n                dst[3][j] = 255;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (s->stereo3d) {\n\n        AVStereo3D *stereo = av_stereo3d_create_side_data(data);\n\n        if (stereo) {\n\n            stereo->type  = s->stereo3d->type;\n\n            stereo->flags = s->stereo3d->flags;\n\n        }\n\n        av_freep(&s->stereo3d);\n\n    }\n\n\n\n    av_dict_copy(avpriv_frame_get_metadatap(data), s->exif_metadata, 0);\n\n    av_dict_free(&s->exif_metadata);\n\n\n\nthe_end_no_picture:\n\n    av_log(avctx, AV_LOG_DEBUG, \"decode frame unused %\"PTRDIFF_SPECIFIER\" bytes\\n\",\n\n           buf_end - buf_ptr);\n\n//  return buf_end - buf_ptr;\n\n    return buf_ptr - buf;\n\n}\n", "idx": 24361}
{"project": "FFmpeg", "commit_id": "247d30a7dba6684ccce4508424f35fd58465e535", "target": 1, "func": "static int vp3_update_thread_context(AVCodecContext *dst, const AVCodecContext *src)\n\n{\n\n    Vp3DecodeContext *s = dst->priv_data, *s1 = src->priv_data;\n\n    int qps_changed = 0, i, err;\n\n\n\n#define copy_fields(to, from, start_field, end_field) memcpy(&to->start_field, &from->start_field, (char*)&to->end_field - (char*)&to->start_field)\n\n\n\n    if (!s1->current_frame.data[0]\n\n        ||s->width != s1->width\n\n        ||s->height!= s1->height) {\n\n        if (s != s1)\n\n            copy_fields(s, s1, golden_frame, current_frame);\n\n        return -1;\n\n    }\n\n\n\n    if (s != s1) {\n\n        // init tables if the first frame hasn't been decoded\n\n        if (!s->current_frame.data[0]) {\n\n            int y_fragment_count, c_fragment_count;\n\n            s->avctx = dst;\n\n            err = allocate_tables(dst);\n\n            if (err)\n\n                return err;\n\n            y_fragment_count = s->fragment_width[0] * s->fragment_height[0];\n\n            c_fragment_count = s->fragment_width[1] * s->fragment_height[1];\n\n            memcpy(s->motion_val[0], s1->motion_val[0], y_fragment_count * sizeof(*s->motion_val[0]));\n\n            memcpy(s->motion_val[1], s1->motion_val[1], c_fragment_count * sizeof(*s->motion_val[1]));\n\n        }\n\n\n\n        // copy previous frame data\n\n        copy_fields(s, s1, golden_frame, dsp);\n\n\n\n        // copy qscale data if necessary\n\n        for (i = 0; i < 3; i++) {\n\n            if (s->qps[i] != s1->qps[1]) {\n\n                qps_changed = 1;\n\n                memcpy(&s->qmat[i], &s1->qmat[i], sizeof(s->qmat[i]));\n\n            }\n\n        }\n\n\n\n        if (s->qps[0] != s1->qps[0])\n\n            memcpy(&s->bounding_values_array, &s1->bounding_values_array, sizeof(s->bounding_values_array));\n\n\n\n        if (qps_changed)\n\n            copy_fields(s, s1, qps, superblock_count);\n\n#undef copy_fields\n\n    }\n\n\n\n    update_frames(dst);\n\n\n\n    return 0;\n\n}\n", "idx": 24366}
{"project": "FFmpeg", "commit_id": "e549933a270dd2cfc36f2cf9bb6b29acf3dc6d08", "target": 0, "func": "static void avc_luma_mid_8w_msa(const uint8_t *src, int32_t src_stride,\n\n                                uint8_t *dst, int32_t dst_stride,\n\n                                int32_t height)\n\n{\n\n    uint32_t loop_cnt;\n\n    v16i8 src0, src1, src2, src3, src4;\n\n    v16i8 mask0, mask1, mask2;\n\n    v8i16 hz_out0, hz_out1, hz_out2, hz_out3;\n\n    v8i16 hz_out4, hz_out5, hz_out6, hz_out7, hz_out8;\n\n    v8i16 dst0, dst1, dst2, dst3;\n\n    v16u8 out0, out1;\n\n\n\n    LD_SB3(&luma_mask_arr[0], 16, mask0, mask1, mask2);\n\n\n\n    LD_SB5(src, src_stride, src0, src1, src2, src3, src4);\n\n    XORI_B5_128_SB(src0, src1, src2, src3, src4);\n\n    src += (5 * src_stride);\n\n\n\n    hz_out0 = AVC_HORZ_FILTER_SH(src0, src0, mask0, mask1, mask2);\n\n    hz_out1 = AVC_HORZ_FILTER_SH(src1, src1, mask0, mask1, mask2);\n\n    hz_out2 = AVC_HORZ_FILTER_SH(src2, src2, mask0, mask1, mask2);\n\n    hz_out3 = AVC_HORZ_FILTER_SH(src3, src3, mask0, mask1, mask2);\n\n    hz_out4 = AVC_HORZ_FILTER_SH(src4, src4, mask0, mask1, mask2);\n\n\n\n    for (loop_cnt = (height >> 2); loop_cnt--;) {\n\n        LD_SB4(src, src_stride, src0, src1, src2, src3);\n\n        XORI_B4_128_SB(src0, src1, src2, src3);\n\n        src += (4 * src_stride);\n\n\n\n        hz_out5 = AVC_HORZ_FILTER_SH(src0, src0, mask0, mask1, mask2);\n\n        hz_out6 = AVC_HORZ_FILTER_SH(src1, src1, mask0, mask1, mask2);\n\n        hz_out7 = AVC_HORZ_FILTER_SH(src2, src2, mask0, mask1, mask2);\n\n        hz_out8 = AVC_HORZ_FILTER_SH(src3, src3, mask0, mask1, mask2);\n\n        dst0 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out0, hz_out1, hz_out2,\n\n                                               hz_out3, hz_out4, hz_out5);\n\n        dst1 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out1, hz_out2, hz_out3,\n\n                                               hz_out4, hz_out5, hz_out6);\n\n        dst2 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out2, hz_out3, hz_out4,\n\n                                               hz_out5, hz_out6, hz_out7);\n\n        dst3 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out3, hz_out4, hz_out5,\n\n                                               hz_out6, hz_out7, hz_out8);\n\n        out0 = PCKEV_XORI128_UB(dst0, dst1);\n\n        out1 = PCKEV_XORI128_UB(dst2, dst3);\n\n        ST8x4_UB(out0, out1, dst, dst_stride);\n\n\n\n        dst += (4 * dst_stride);\n\n        hz_out3 = hz_out7;\n\n        hz_out1 = hz_out5;\n\n        hz_out5 = hz_out4;\n\n        hz_out4 = hz_out8;\n\n        hz_out2 = hz_out6;\n\n        hz_out0 = hz_out5;\n\n    }\n\n}\n", "idx": 24368}
{"project": "FFmpeg", "commit_id": "ae2d41ec875965ce4ab9fdd88a5e8ba57cada67a", "target": 0, "func": "void ff_init_elbg(int *points, int dim, int numpoints, int *codebook,\n\n                  int numCB, int max_steps, int *closest_cb,\n\n                  AVLFG *rand_state)\n\n{\n\n    int i, k;\n\n\n\n    if (numpoints > 24*numCB) {\n\n        /* ELBG is very costly for a big number of points. So if we have a lot\n\n           of them, get a good initial codebook to save on iterations       */\n\n        int *temp_points = av_malloc(dim*(numpoints/8)*sizeof(int));\n\n        for (i=0; i<numpoints/8; i++) {\n\n            k = (i*BIG_PRIME) % numpoints;\n\n            memcpy(temp_points + i*dim, points + k*dim, dim*sizeof(int));\n\n        }\n\n\n\n        ff_init_elbg(temp_points, dim, numpoints/8, codebook, numCB, 2*max_steps, closest_cb, rand_state);\n\n        ff_do_elbg(temp_points, dim, numpoints/8, codebook, numCB, 2*max_steps, closest_cb, rand_state);\n\n\n\n        av_free(temp_points);\n\n\n\n    } else  // If not, initialize the codebook with random positions\n\n        for (i=0; i < numCB; i++)\n\n            memcpy(codebook + i*dim, points + ((i*BIG_PRIME)%numpoints)*dim,\n\n                   dim*sizeof(int));\n\n\n\n}\n", "idx": 24369}
{"project": "FFmpeg", "commit_id": "7fb758cd8ed08e4a37f10e25003953d13c68b8cd", "target": 0, "func": "av_cold void ff_lpc_init_x86(LPCContext *c)\n\n{\n\n#if HAVE_SSE2_INLINE\n\n    int cpu_flags = av_get_cpu_flags();\n\n\n\n    if (INLINE_SSE2(cpu_flags) && (cpu_flags & AV_CPU_FLAG_SSE2SLOW)) {\n\n        c->lpc_apply_welch_window = lpc_apply_welch_window_sse2;\n\n        c->lpc_compute_autocorr   = lpc_compute_autocorr_sse2;\n\n    }\n\n#endif /* HAVE_SSE2_INLINE */\n\n}\n", "idx": 24370}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int pam_encode_close(AVCodecContext *avctx)\n\n{\n\n    av_frame_free(&avctx->coded_frame);\n\n    return 0;\n\n}\n", "idx": 24371}
{"project": "FFmpeg", "commit_id": "4d09bc98974d4602d71e71520535457a53d44222", "target": 0, "func": "int ff_pcm_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    int ret, size;\n\n\n\n    size= RAW_SAMPLES*s->streams[0]->codec->block_align;\n\n    if (size <= 0)\n\n        return AVERROR(EINVAL);\n\n\n\n    ret= av_get_packet(s->pb, pkt, size);\n\n\n\n    pkt->flags &= ~AV_PKT_FLAG_CORRUPT;\n\n    pkt->stream_index = 0;\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    return ret;\n\n}\n", "idx": 24372}
{"project": "FFmpeg", "commit_id": "851ded8918c977d8160c6617b69604f758cabf50", "target": 0, "func": "static int decode_cabac_mb_skip( H264Context *h, int mb_x, int mb_y ) {\n\n    MpegEncContext * const s = &h->s;\n\n    int mba_xy, mbb_xy;\n\n    int ctx = 0;\n\n\n\n    if(FRAME_MBAFF){ //FIXME merge with the stuff in fill_caches?\n\n        int mb_xy = mb_x + (mb_y&~1)*s->mb_stride;\n\n        mba_xy = mb_xy - 1;\n\n        if( (mb_y&1)\n\n            && h->slice_table[mba_xy] == h->slice_num\n\n            && MB_FIELD == !!IS_INTERLACED( s->current_picture.mb_type[mba_xy] ) )\n\n            mba_xy += s->mb_stride;\n\n        if( MB_FIELD ){\n\n            mbb_xy = mb_xy - s->mb_stride;\n\n            if( !(mb_y&1)\n\n                && h->slice_table[mbb_xy] == h->slice_num\n\n                && IS_INTERLACED( s->current_picture.mb_type[mbb_xy] ) )\n\n                mbb_xy -= s->mb_stride;\n\n        }else\n\n            mbb_xy = mb_x + (mb_y-1)*s->mb_stride;\n\n    }else{\n\n        int mb_xy = mb_x + mb_y*s->mb_stride;\n\n        mba_xy = mb_xy - 1;\n\n        mbb_xy = mb_xy - s->mb_stride;\n\n    }\n\n\n\n    if( h->slice_table[mba_xy] == h->slice_num && !IS_SKIP( s->current_picture.mb_type[mba_xy] ))\n\n        ctx++;\n\n    if( h->slice_table[mbb_xy] == h->slice_num && !IS_SKIP( s->current_picture.mb_type[mbb_xy] ))\n\n        ctx++;\n\n\n\n    if( h->slice_type == B_TYPE )\n\n        ctx += 13;\n\n    return get_cabac( &h->cabac, &h->cabac_state[11+ctx] );\n\n}\n", "idx": 24373}
{"project": "FFmpeg", "commit_id": "ec23a47286a9be0ca67b78f4d8b9d87220c18286", "target": 0, "func": "static int handle_packets(AVFormatContext *s, int nb_packets)\n\n{\n\n    MpegTSContext *ts = s->priv_data;\n\n    ByteIOContext *pb = &s->pb;\n\n    uint8_t packet[TS_FEC_PACKET_SIZE];\n\n    int packet_num, len;\n\n\n\n    ts->stop_parse = 0;\n\n    packet_num = 0;\n\n    for(;;) {\n\n        if (ts->stop_parse)\n\n            break;\n\n        packet_num++;\n\n        if (nb_packets != 0 && packet_num >= nb_packets)\n\n            break;\n\n        len = get_buffer(pb, packet, ts->raw_packet_size);\n\n        if (len != ts->raw_packet_size)\n\n            return AVERROR_IO;\n\n        /* check paquet sync byte */\n\n        /* XXX: accept to resync ? */\n\n        if (packet[0] != 0x47)\n\n            return AVERROR_INVALIDDATA;\n\n        handle_packet(s, packet);\n\n    }\n\n    return 0;\n\n}\n", "idx": 24374}
{"project": "FFmpeg", "commit_id": "6f600ab35424823fb682b5669241edcc66590a8d", "target": 0, "func": "static av_cold int oggvorbis_init_encoder(vorbis_info *vi, AVCodecContext *avccontext)\n\n{\n\n    OggVorbisContext *context = avccontext->priv_data;\n\n    double cfreq;\n\n\n\n    if (avccontext->flags & CODEC_FLAG_QSCALE) {\n\n        /* variable bitrate */\n\n        if (vorbis_encode_setup_vbr(vi, avccontext->channels,\n\n                                    avccontext->sample_rate,\n\n                                    avccontext->global_quality / (float)FF_QP2LAMBDA / 10.0))\n\n            return -1;\n\n    } else {\n\n        int minrate = avccontext->rc_min_rate > 0 ? avccontext->rc_min_rate : -1;\n\n        int maxrate = avccontext->rc_min_rate > 0 ? avccontext->rc_max_rate : -1;\n\n\n\n        /* constant bitrate */\n\n        if (vorbis_encode_setup_managed(vi, avccontext->channels,\n\n                                        avccontext->sample_rate, minrate,\n\n                                        avccontext->bit_rate, maxrate))\n\n            return -1;\n\n\n\n        /* variable bitrate by estimate, disable slow rate management */\n\n        if (minrate == -1 && maxrate == -1)\n\n            if (vorbis_encode_ctl(vi, OV_ECTL_RATEMANAGE2_SET, NULL))\n\n                return -1;\n\n    }\n\n\n\n    /* cutoff frequency */\n\n    if (avccontext->cutoff > 0) {\n\n        cfreq = avccontext->cutoff / 1000.0;\n\n        if (vorbis_encode_ctl(vi, OV_ECTL_LOWPASS_SET, &cfreq))\n\n            return -1;\n\n    }\n\n\n\n    if (context->iblock) {\n\n        vorbis_encode_ctl(vi, OV_ECTL_IBLOCK_SET, &context->iblock);\n\n    }\n\n\n\n    return vorbis_encode_setup_init(vi);\n\n}\n", "idx": 24375}
{"project": "FFmpeg", "commit_id": "ddfa3751c092feaf1e080f66587024689dfe603c", "target": 1, "func": "static int decode_packet(J2kDecoderContext *s, J2kCodingStyle *codsty, J2kResLevel *rlevel, int precno,\n\n                         int layno, uint8_t *expn, int numgbits)\n\n{\n\n    int bandno, cblkny, cblknx, cblkno, ret;\n\n\n\n    if (!(ret = get_bits(s, 1))){\n\n        j2k_flush(s);\n\n        return 0;\n\n    } else if (ret < 0)\n\n        return ret;\n\n\n\n    for (bandno = 0; bandno < rlevel->nbands; bandno++){\n\n        J2kBand *band = rlevel->band + bandno;\n\n        J2kPrec *prec = band->prec + precno;\n\n        int pos = 0;\n\n\n\n        if (band->coord[0][0] == band->coord[0][1]\n\n        ||  band->coord[1][0] == band->coord[1][1])\n\n            continue;\n\n\n\n        for (cblkny = prec->yi0; cblkny < prec->yi1; cblkny++)\n\n            for(cblknx = prec->xi0, cblkno = cblkny * band->cblknx + cblknx; cblknx < prec->xi1; cblknx++, cblkno++, pos++){\n\n                J2kCblk *cblk = band->cblk + cblkno;\n\n                int incl, newpasses, llen;\n\n\n\n                if (cblk->npasses)\n\n                    incl = get_bits(s, 1);\n\n                else\n\n                    incl = tag_tree_decode(s, prec->cblkincl + pos, layno+1) == layno;\n\n                if (!incl)\n\n                    continue;\n\n                else if (incl < 0)\n\n                    return incl;\n\n\n\n                if (!cblk->npasses)\n\n                    cblk->nonzerobits = expn[bandno] + numgbits - 1 - tag_tree_decode(s, prec->zerobits + pos, 100);\n\n                if ((newpasses = getnpasses(s)) < 0)\n\n                    return newpasses;\n\n                if ((llen = getlblockinc(s)) < 0)\n\n                    return llen;\n\n                cblk->lblock += llen;\n\n                if ((ret = get_bits(s, av_log2(newpasses) + cblk->lblock)) < 0)\n\n                    return ret;\n\n                cblk->lengthinc = ret;\n\n                cblk->npasses += newpasses;\n\n            }\n\n    }\n\n    j2k_flush(s);\n\n\n\n    if (codsty->csty & J2K_CSTY_EPH) {\n\n        if (AV_RB16(s->buf) == J2K_EPH) {\n\n            s->buf += 2;\n\n        } else {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"EPH marker not found.\\n\");\n\n        }\n\n    }\n\n\n\n    for (bandno = 0; bandno < rlevel->nbands; bandno++){\n\n        J2kBand *band = rlevel->band + bandno;\n\n        int yi, cblknw = band->prec[precno].xi1 - band->prec[precno].xi0;\n\n        for (yi = band->prec[precno].yi0; yi < band->prec[precno].yi1; yi++){\n\n            int xi;\n\n            for (xi = band->prec[precno].xi0; xi < band->prec[precno].xi1; xi++){\n\n                J2kCblk *cblk = band->cblk + yi * cblknw + xi;\n\n                if (s->buf_end - s->buf < cblk->lengthinc)\n\n                    return AVERROR(EINVAL);\n\n                bytestream_get_buffer(&s->buf, cblk->data, cblk->lengthinc);\n\n                cblk->length += cblk->lengthinc;\n\n                cblk->lengthinc = 0;\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 24378}
{"project": "FFmpeg", "commit_id": "2da0d70d5eebe42f9fcd27ee554419ebe2a5da06", "target": 1, "func": "static inline void RENAME(palToY)(uint8_t *dst, uint8_t *src, int width, uint32_t *pal)\n\n{\n\n\tint i;\n\n\tfor(i=0; i<width; i++)\n\n\t{\n\n\t\tint d= src[i];\n\n\n\n\t\tdst[i]= pal[d] & 0xFF;\n\n\t}\n\n}\n", "idx": 24379}
{"project": "FFmpeg", "commit_id": "b315a3cf42a15358ab38279723f3c93406a66f6a", "target": 1, "func": "static SoftFloat sbr_sum_square_c(int (*x)[2], int n)\n\n{\n\n    SoftFloat ret;\n\n    uint64_t accu = 0, round;\n\n    int i, nz;\n\n    unsigned u;\n\n\n\n    for (i = 0; i < n; i += 2) {\n\n        // Larger values are inavlid and could cause overflows of accu.\n\n        av_assert2(FFABS(x[i + 0][0]) >> 29 == 0);\n\n        accu += (int64_t)x[i + 0][0] * x[i + 0][0];\n\n        av_assert2(FFABS(x[i + 0][1]) >> 29 == 0);\n\n        accu += (int64_t)x[i + 0][1] * x[i + 0][1];\n\n        av_assert2(FFABS(x[i + 1][0]) >> 29 == 0);\n\n        accu += (int64_t)x[i + 1][0] * x[i + 1][0];\n\n        av_assert2(FFABS(x[i + 1][1]) >> 29 == 0);\n\n        accu += (int64_t)x[i + 1][1] * x[i + 1][1];\n\n    }\n\n\n\n    u = accu >> 32;\n\n    if (u == 0) {\n\n        nz = 1;\n\n    } else {\n\n        nz = -1;\n\n        while (u < 0x80000000U) {\n\n            u <<= 1;\n\n            nz++;\n\n        }\n\n        nz = 32 - nz;\n\n    }\n\n\n\n    round = 1ULL << (nz-1);\n\n    u = ((accu + round) >> nz);\n\n    u >>= 1;\n\n    ret = av_int2sf(u, 15 - nz);\n\n\n\n    return ret;\n\n}\n", "idx": 24380}
{"project": "FFmpeg", "commit_id": "21234c835d2d003d390d462b6e1b2622e7b02c39", "target": 1, "func": "static int sofalizer_convolute(AVFilterContext *ctx, void *arg, int jobnr, int nb_jobs)\n\n{\n\n    SOFAlizerContext *s = ctx->priv;\n\n    ThreadData *td = arg;\n\n    AVFrame *in = td->in, *out = td->out;\n\n    int offset = jobnr;\n\n    int *write = &td->write[jobnr];\n\n    const int *const delay = td->delay[jobnr];\n\n    const float *const ir = td->ir[jobnr];\n\n    int *n_clippings = &td->n_clippings[jobnr];\n\n    float *ringbuffer = td->ringbuffer[jobnr];\n\n    float *temp_src = td->temp_src[jobnr];\n\n    const int n_samples = s->sofa.n_samples; /* length of one IR */\n\n    const float *src = (const float *)in->data[0]; /* get pointer to audio input buffer */\n\n    float *dst = (float *)out->data[0]; /* get pointer to audio output buffer */\n\n    const int in_channels = s->n_conv; /* number of input channels */\n\n    /* ring buffer length is: longest IR plus max. delay -> next power of 2 */\n\n    const int buffer_length = s->buffer_length;\n\n    /* -1 for AND instead of MODULO (applied to powers of 2): */\n\n    const uint32_t modulo = (uint32_t)buffer_length - 1;\n\n    float *buffer[16]; /* holds ringbuffer for each input channel */\n\n    int wr = *write;\n\n    int read;\n\n    int i, l;\n\n\n\n    dst += offset;\n\n    for (l = 0; l < in_channels; l++) {\n\n        /* get starting address of ringbuffer for each input channel */\n\n        buffer[l] = ringbuffer + l * buffer_length;\n\n    }\n\n\n\n    for (i = 0; i < in->nb_samples; i++) {\n\n        const float *temp_ir = ir; /* using same set of IRs for each sample */\n\n\n\n        *dst = 0;\n\n        for (l = 0; l < in_channels; l++) {\n\n            /* write current input sample to ringbuffer (for each channel) */\n\n            *(buffer[l] + wr) = src[l];\n\n        }\n\n\n\n        /* loop goes through all channels to be convolved */\n\n        for (l = 0; l < in_channels; l++) {\n\n            const float *const bptr = buffer[l];\n\n\n\n            if (l == s->lfe_channel) {\n\n                /* LFE is an input channel but requires no convolution */\n\n                /* apply gain to LFE signal and add to output buffer */\n\n                *dst += *(buffer[s->lfe_channel] + wr) * s->gain_lfe;\n\n                temp_ir += n_samples;\n\n                continue;\n\n            }\n\n\n\n            /* current read position in ringbuffer: input sample write position\n\n             * - delay for l-th ch. + diff. betw. IR length and buffer length\n\n             * (mod buffer length) */\n\n            read = (wr - *(delay + l) - (n_samples - 1) + buffer_length) & modulo;\n\n\n\n            if (read + n_samples < buffer_length) {\n\n                memcpy(temp_src, bptr + read, n_samples * sizeof(*temp_src));\n\n            } else {\n\n                int len = FFMIN(n_samples - (read % n_samples), buffer_length - read);\n\n\n\n                memcpy(temp_src, bptr + read, len * sizeof(*temp_src));\n\n                memcpy(temp_src + len, bptr, (n_samples - len) * sizeof(*temp_src));\n\n            }\n\n\n\n            /* multiply signal and IR, and add up the results */\n\n            dst[0] += s->fdsp->scalarproduct_float(temp_ir, temp_src, n_samples);\n\n            temp_ir += n_samples;\n\n        }\n\n\n\n        /* clippings counter */\n\n        if (fabs(*dst) > 1)\n\n            *n_clippings += 1;\n\n\n\n        /* move output buffer pointer by +2 to get to next sample of processed channel: */\n\n        dst += 2;\n\n        src += in_channels;\n\n        wr   = (wr + 1) & modulo; /* update ringbuffer write position */\n\n    }\n\n\n\n    *write = wr; /* remember write position in ringbuffer for next call */\n\n\n\n    return 0;\n\n}\n", "idx": 24383}
{"project": "FFmpeg", "commit_id": "c61715e2c505c15a5cfc9eab18b4311a6504055a", "target": 1, "func": "int ff_htmlmarkup_to_ass(void *log_ctx, AVBPrint *dst, const char *in)\n\n{\n\n    char *param, buffer[128], tmp[128];\n\n    int len, tag_close, sptr = 1, line_start = 1, an = 0, end = 0;\n\n    SrtStack stack[16];\n\n    int closing_brace_missing = 0;\n\n\n\n    stack[0].tag[0] = 0;\n\n    strcpy(stack[0].param[PARAM_SIZE],  \"{\\\\fs}\");\n\n    strcpy(stack[0].param[PARAM_COLOR], \"{\\\\c}\");\n\n    strcpy(stack[0].param[PARAM_FACE],  \"{\\\\fn}\");\n\n\n\n    for (; !end && *in; in++) {\n\n        switch (*in) {\n\n        case '\\r':\n\n            break;\n\n        case '\\n':\n\n            if (line_start) {\n\n                end = 1;\n\n                break;\n\n            }\n\n            rstrip_spaces_buf(dst);\n\n            av_bprintf(dst, \"\\\\N\");\n\n            line_start = 1;\n\n            break;\n\n        case ' ':\n\n            if (!line_start)\n\n                av_bprint_chars(dst, *in, 1);\n\n            break;\n\n        case '{':\n\n            handle_open_brace(dst, &in, &an, &closing_brace_missing);\n\n            break;\n\n        case '<':\n\n            tag_close = in[1] == '/';\n\n            len = 0;\n\n            if (sscanf(in+tag_close+1, \"%127[^>]>%n\", buffer, &len) >= 1 && len > 0) {\n\n                const char *tagname = buffer;\n\n                while (*tagname == ' ')\n\n                    tagname++;\n\n                if ((param = strchr(tagname, ' ')))\n\n                    *param++ = 0;\n\n                if ((!tag_close && sptr < FF_ARRAY_ELEMS(stack)) ||\n\n                    ( tag_close && sptr > 0 && !av_strcasecmp(stack[sptr-1].tag, tagname))) {\n\n                    int i, j, unknown = 0;\n\n                    in += len + tag_close;\n\n                    if (!tag_close)\n\n                        memset(stack+sptr, 0, sizeof(*stack));\n\n                    if (!av_strcasecmp(tagname, \"font\")) {\n\n                        if (tag_close) {\n\n                            for (i=PARAM_NUMBER-1; i>=0; i--)\n\n                                if (stack[sptr-1].param[i][0])\n\n                                    for (j=sptr-2; j>=0; j--)\n\n                                        if (stack[j].param[i][0]) {\n\n                                            av_bprintf(dst, \"%s\", stack[j].param[i]);\n\n                                            break;\n\n                                        }\n\n                        } else {\n\n                            while (param) {\n\n                                if (!av_strncasecmp(param, \"size=\", 5)) {\n\n                                    unsigned font_size;\n\n                                    param += 5 + (param[5] == '\"');\n\n                                    if (sscanf(param, \"%u\", &font_size) == 1) {\n\n                                        snprintf(stack[sptr].param[PARAM_SIZE],\n\n                                             sizeof(stack[0].param[PARAM_SIZE]),\n\n                                             \"{\\\\fs%u}\", font_size);\n\n                                    }\n\n                                } else if (!av_strncasecmp(param, \"color=\", 6)) {\n\n                                    param += 6 + (param[6] == '\"');\n\n                                    snprintf(stack[sptr].param[PARAM_COLOR],\n\n                                         sizeof(stack[0].param[PARAM_COLOR]),\n\n                                         \"{\\\\c&H%X&}\",\n\n                                         html_color_parse(log_ctx, param));\n\n                                } else if (!av_strncasecmp(param, \"face=\", 5)) {\n\n                                    param += 5 + (param[5] == '\"');\n\n                                    len = strcspn(param,\n\n                                                  param[-1] == '\"' ? \"\\\"\" :\" \");\n\n                                    av_strlcpy(tmp, param,\n\n                                               FFMIN(sizeof(tmp), len+1));\n\n                                    param += len;\n\n                                    snprintf(stack[sptr].param[PARAM_FACE],\n\n                                             sizeof(stack[0].param[PARAM_FACE]),\n\n                                             \"{\\\\fn%s}\", tmp);\n\n                                }\n\n                                if ((param = strchr(param, ' ')))\n\n                                    param++;\n\n                            }\n\n                            for (i=0; i<PARAM_NUMBER; i++)\n\n                                if (stack[sptr].param[i][0])\n\n                                    av_bprintf(dst, \"%s\", stack[sptr].param[i]);\n\n                        }\n\n                    } else if (tagname[0] && !tagname[1] && av_stristr(\"bisu\", tagname)) {\n\n                        av_bprintf(dst, \"{\\\\%c%d}\", (char)av_tolower(tagname[0]), !tag_close);\n\n                    } else if (!av_strcasecmp(tagname, \"br\")) {\n\n                        av_bprintf(dst, \"\\\\N\");\n\n                    } else {\n\n                        unknown = 1;\n\n                        snprintf(tmp, sizeof(tmp), \"</%s>\", tagname);\n\n                    }\n\n                    if (tag_close) {\n\n                        sptr--;\n\n                    } else if (unknown && !strstr(in, tmp)) {\n\n                        in -= len + tag_close;\n\n                        av_bprint_chars(dst, *in, 1);\n\n                    } else\n\n                        av_strlcpy(stack[sptr++].tag, tagname,\n\n                                   sizeof(stack[0].tag));\n\n                    break;\n\n                }\n\n            }\n\n        default:\n\n            av_bprint_chars(dst, *in, 1);\n\n            break;\n\n        }\n\n        if (*in != ' ' && *in != '\\r' && *in != '\\n')\n\n            line_start = 0;\n\n    }\n\n\n\n    if (!av_bprint_is_complete(dst))\n\n        return AVERROR(ENOMEM);\n\n\n\n    while (dst->len >= 2 && !strncmp(&dst->str[dst->len - 2], \"\\\\N\", 2))\n\n        dst->len -= 2;\n\n    dst->str[dst->len] = 0;\n\n    rstrip_spaces_buf(dst);\n\n\n\n    return 0;\n\n}\n", "idx": 24385}
{"project": "FFmpeg", "commit_id": "fd34dbea58e097609ff09cf7dcc59f74930195d3", "target": 1, "func": "static int mxf_read_partition_pack(void *arg, AVIOContext *pb, int tag, int size, UID uid)\n\n{\n\n    MXFContext *mxf = arg;\n\n    MXFPartition *partition;\n\n    UID op;\n\n    uint64_t footer_partition;\n\n\n\n    if (mxf->partitions_count+1 >= UINT_MAX / sizeof(*mxf->partitions))\n\n        return AVERROR(ENOMEM);\n\n\n\n    mxf->partitions = av_realloc(mxf->partitions, (mxf->partitions_count + 1) * sizeof(*mxf->partitions));\n\n    if (!mxf->partitions)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if (mxf->parsing_backward) {\n\n        /* insert the new partition pack in the middle\n\n         * this makes the entries in mxf->partitions sorted by offset */\n\n        memmove(&mxf->partitions[mxf->last_forward_partition+1],\n\n                &mxf->partitions[mxf->last_forward_partition],\n\n                (mxf->partitions_count - mxf->last_forward_partition)*sizeof(*mxf->partitions));\n\n        partition = mxf->current_partition = &mxf->partitions[mxf->last_forward_partition];\n\n    } else {\n\n        mxf->last_forward_partition++;\n\n        partition = mxf->current_partition = &mxf->partitions[mxf->partitions_count];\n\n    }\n\n\n\n    memset(partition, 0, sizeof(*partition));\n\n    mxf->partitions_count++;\n\n\n\n    switch(uid[13]) {\n\n    case 2:\n\n        partition->type = Header;\n\n        break;\n\n    case 3:\n\n        partition->type = BodyPartition;\n\n        break;\n\n    case 4:\n\n        partition->type = Footer;\n\n        break;\n\n    default:\n\n        av_log(mxf->fc, AV_LOG_ERROR, \"unknown partition type %i\\n\", uid[13]);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* consider both footers to be closed (there is only Footer and CompleteFooter) */\n\n    partition->closed = partition->type == Footer || !(uid[14] & 1);\n\n    partition->complete = uid[14] > 2;\n\n    avio_skip(pb, 8);\n\n    partition->this_partition = avio_rb64(pb);\n\n    partition->previous_partition = avio_rb64(pb);\n\n    footer_partition = avio_rb64(pb);\n\n    avio_skip(pb, 16);\n\n    partition->index_sid = avio_rb32(pb);\n\n    avio_skip(pb, 8);\n\n    partition->body_sid = avio_rb32(pb);\n\n    avio_read(pb, op, sizeof(UID));\n\n\n\n    /* some files don'thave FooterPartition set in every partition */\n\n    if (footer_partition) {\n\n        if (mxf->footer_partition && mxf->footer_partition != footer_partition) {\n\n            av_log(mxf->fc, AV_LOG_ERROR, \"inconsistent FooterPartition value: %li != %li\\n\",\n\n                   mxf->footer_partition, footer_partition);\n\n        } else {\n\n            mxf->footer_partition = footer_partition;\n\n        }\n\n    }\n\n\n\n    av_dlog(mxf->fc, \"PartitionPack: ThisPartition = 0x%lx, PreviousPartition = 0x%lx, \"\n\n            \"FooterPartition = 0x%lx, IndexSID = %i, BodySID = %i\\n\",\n\n            partition->this_partition,\n\n            partition->previous_partition, footer_partition,\n\n            partition->index_sid, partition->body_sid);\n\n\n\n    if      (op[12] == 1 && op[13] == 1) mxf->op = OP1a;\n\n    else if (op[12] == 1 && op[13] == 2) mxf->op = OP1b;\n\n    else if (op[12] == 1 && op[13] == 3) mxf->op = OP1c;\n\n    else if (op[12] == 2 && op[13] == 1) mxf->op = OP2a;\n\n    else if (op[12] == 2 && op[13] == 2) mxf->op = OP2b;\n\n    else if (op[12] == 2 && op[13] == 3) mxf->op = OP2c;\n\n    else if (op[12] == 3 && op[13] == 1) mxf->op = OP3a;\n\n    else if (op[12] == 3 && op[13] == 2) mxf->op = OP3b;\n\n    else if (op[12] == 3 && op[13] == 3) mxf->op = OP3c;\n\n    else if (op[12] == 0x10)             mxf->op = OPAtom;\n\n    else\n\n        av_log(mxf->fc, AV_LOG_ERROR, \"unknown operational pattern: %02xh %02xh\\n\", op[12], op[13]);\n\n\n\n    return 0;\n\n}\n", "idx": 24390}
{"project": "FFmpeg", "commit_id": "221b804f3491638ecf2eec1302c669ad2d9ec799", "target": 1, "func": "static uint64_t getSSD(uint8_t *src1, uint8_t *src2, int stride1, int stride2, int w, int h){\n\n\tint x,y;\n\n\tuint64_t ssd=0;\n\n\n\n//printf(\"%d %d\\n\", w, h);\n\n\n\n\tfor(y=0; y<h; y++){\n\n\t\tfor(x=0; x<w; x++){\n\n\t\t\tint d= src1[x + y*stride1] - src2[x + y*stride2];\n\n\t\t\tssd+= d*d;\n\n//printf(\"%d\", abs(src1[x + y*stride1] - src2[x + y*stride2])/26 );\n\n\t\t}\n\n//printf(\"\\n\");\n\n\t}\n\n\treturn ssd;\n\n}\n", "idx": 24391}
{"project": "FFmpeg", "commit_id": "24dc7776ff4452764d0365b12d0728153f879cf8", "target": 0, "func": "static int put_system_header(AVFormatContext *ctx, uint8_t *buf,int only_for_stream_id)\n\n{\n\n    MpegMuxContext *s = ctx->priv_data;\n\n    int size, i, private_stream_coded, id;\n\n    PutBitContext pb;\n\n\n\n    init_put_bits(&pb, buf, 128);\n\n\n\n    put_bits(&pb, 32, SYSTEM_HEADER_START_CODE);\n\n    put_bits(&pb, 16, 0);\n\n    put_bits(&pb, 1, 1);\n\n\n\n    put_bits(&pb, 22, s->mux_rate); /* maximum bit rate of the multiplexed stream */\n\n    put_bits(&pb, 1, 1); /* marker */\n\n    if (s->is_vcd && only_for_stream_id==VIDEO_ID) {\n\n        /* This header applies only to the video stream (see VCD standard p. IV-7)*/\n\n        put_bits(&pb, 6, 0);\n\n    } else\n\n        put_bits(&pb, 6, s->audio_bound);\n\n\n\n    if (s->is_vcd) {\n\n        /* see VCD standard, p. IV-7*/\n\n        put_bits(&pb, 1, 0);\n\n        put_bits(&pb, 1, 1);\n\n    } else {\n\n        put_bits(&pb, 1, 0); /* variable bitrate*/\n\n        put_bits(&pb, 1, 0); /* non constrainted bit stream */\n\n    }\n\n\n\n    if (s->is_vcd || s->is_dvd) {\n\n        /* see VCD standard p IV-7 */\n\n        put_bits(&pb, 1, 1); /* audio locked */\n\n        put_bits(&pb, 1, 1); /* video locked */\n\n    } else {\n\n        put_bits(&pb, 1, 0); /* audio locked */\n\n        put_bits(&pb, 1, 0); /* video locked */\n\n    }\n\n\n\n    put_bits(&pb, 1, 1); /* marker */\n\n\n\n    if (s->is_vcd && only_for_stream_id==AUDIO_ID) {\n\n        /* This header applies only to the audio stream (see VCD standard p. IV-7)*/\n\n        put_bits(&pb, 5, 0);\n\n    } else\n\n        put_bits(&pb, 5, s->video_bound);\n\n\n\n    if (s->is_dvd) {\n\n        put_bits(&pb, 1, 0);    /* packet_rate_restriction_flag */\n\n        put_bits(&pb, 7, 0x7f); /* reserved byte */\n\n    } else\n\n        put_bits(&pb, 8, 0xff); /* reserved byte */\n\n\n\n    /* DVD-Video Stream_bound entries\n\n    id (0xB9) video, maximum P-STD for stream 0xE0. (P-STD_buffer_bound_scale = 1)\n\n    id (0xB8) audio, maximum P-STD for any MPEG audio (0xC0 to 0xC7) streams. If there are none set to 4096 (32x128). (P-STD_buffer_bound_scale = 0)\n\n    id (0xBD) private stream 1 (audio other than MPEG and subpictures). (P-STD_buffer_bound_scale = 1)\n\n    id (0xBF) private stream 2, NAV packs, set to 2x1024. */\n\n    if (s->is_dvd) {\n\n\n\n        int P_STD_max_video = 0;\n\n        int P_STD_max_mpeg_audio = 0;\n\n        int P_STD_max_mpeg_PS1 = 0;\n\n\n\n        for(i=0;i<ctx->nb_streams;i++) {\n\n            StreamInfo *stream = ctx->streams[i]->priv_data;\n\n\n\n            id = stream->id;\n\n            if (id == 0xbd && stream->max_buffer_size > P_STD_max_mpeg_PS1) {\n\n                P_STD_max_mpeg_PS1 = stream->max_buffer_size;\n\n            } else if (id >= 0xc0 && id <= 0xc7 && stream->max_buffer_size > P_STD_max_mpeg_audio) {\n\n                P_STD_max_mpeg_audio = stream->max_buffer_size;\n\n            } else if (id == 0xe0 && stream->max_buffer_size > P_STD_max_video) {\n\n                P_STD_max_video = stream->max_buffer_size;\n\n            }\n\n        }\n\n\n\n        /* video */\n\n        put_bits(&pb, 8, 0xb9); /* stream ID */\n\n        put_bits(&pb, 2, 3);\n\n        put_bits(&pb, 1, 1);\n\n        put_bits(&pb, 13, P_STD_max_video / 1024);\n\n\n\n        /* audio */\n\n        if (P_STD_max_mpeg_audio == 0)\n\n            P_STD_max_mpeg_audio = 4096;\n\n        put_bits(&pb, 8, 0xb8); /* stream ID */\n\n        put_bits(&pb, 2, 3);\n\n        put_bits(&pb, 1, 0);\n\n        put_bits(&pb, 13, P_STD_max_mpeg_audio / 128);\n\n\n\n        /* private stream 1 */\n\n        put_bits(&pb, 8, 0xbd); /* stream ID */\n\n        put_bits(&pb, 2, 3);\n\n        put_bits(&pb, 1, 0);\n\n        put_bits(&pb, 13, P_STD_max_mpeg_PS1 / 128);\n\n\n\n        /* private stream 2 */\n\n        put_bits(&pb, 8, 0xbf); /* stream ID */\n\n        put_bits(&pb, 2, 3);\n\n        put_bits(&pb, 1, 1);\n\n        put_bits(&pb, 13, 2);\n\n    }\n\n    else {\n\n        /* audio stream info */\n\n        private_stream_coded = 0;\n\n        for(i=0;i<ctx->nb_streams;i++) {\n\n            StreamInfo *stream = ctx->streams[i]->priv_data;\n\n\n\n\n\n            /* For VCDs, only include the stream info for the stream\n\n            that the pack which contains this system belongs to.\n\n            (see VCD standard p. IV-7) */\n\n            if ( !s->is_vcd || stream->id==only_for_stream_id\n\n                || only_for_stream_id==0) {\n\n\n\n                id = stream->id;\n\n                if (id < 0xc0) {\n\n                    /* special case for private streams (AC-3 uses that) */\n\n                    if (private_stream_coded)\n\n                        continue;\n\n                    private_stream_coded = 1;\n\n                    id = 0xbd;\n\n                }\n\n                put_bits(&pb, 8, id); /* stream ID */\n\n                put_bits(&pb, 2, 3);\n\n                if (id < 0xe0) {\n\n                    /* audio */\n\n                    put_bits(&pb, 1, 0);\n\n                    put_bits(&pb, 13, stream->max_buffer_size / 128);\n\n                } else {\n\n                    /* video */\n\n                    put_bits(&pb, 1, 1);\n\n                    put_bits(&pb, 13, stream->max_buffer_size / 1024);\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    flush_put_bits(&pb);\n\n    size = put_bits_ptr(&pb) - pb.buf;\n\n    /* patch packet size */\n\n    buf[4] = (size - 6) >> 8;\n\n    buf[5] = (size - 6) & 0xff;\n\n\n\n    return size;\n\n}\n", "idx": 24394}
{"project": "FFmpeg", "commit_id": "e5540b3fd30367ce3cc33b2f34a04b660dbc4b38", "target": 0, "func": "static int standard_decode_i_mbs(VC9Context *v)\n\n{\n\n    int x, y, ac_pred, cbpcy;\n\n\n\n    /* Select ttmb table depending on pq */\n\n    if (v->pq < 5) v->ttmb_vlc = &vc9_ttmb_vlc[0];\n\n    else if (v->pq < 13) v->ttmb_vlc = &vc9_ttmb_vlc[1];\n\n    else v->ttmb_vlc = &vc9_ttmb_vlc[2];\n\n\n\n    for (y=0; y<v->height_mb; y++)\n\n    {\n\n        for (x=0; x<v->width_mb; x++)\n\n        {\n\n            cbpcy = get_vlc2(&v->gb, vc9_cbpcy_i_vlc.table,\n\n                             VC9_CBPCY_I_VLC_BITS, 2);\n\n            ac_pred = get_bits(&v->gb, 1);\n\n            //Decode blocks from that mb wrt cbpcy\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 24395}
{"project": "FFmpeg", "commit_id": "1d16a1cf99488f16492b1bb48e023f4da8377e07", "target": 0, "func": "static void ff_h264_idct8_dc_add_mmx2(uint8_t *dst, int16_t *block, int stride)\n\n{\n\n    int dc = (block[0] + 32) >> 6;\n\n    int y;\n\n    __asm__ volatile(\n\n        \"movd          %0, %%mm0 \\n\\t\"\n\n        \"pshufw $0, %%mm0, %%mm0 \\n\\t\"\n\n        \"pxor       %%mm1, %%mm1 \\n\\t\"\n\n        \"psubw      %%mm0, %%mm1 \\n\\t\"\n\n        \"packuswb   %%mm0, %%mm0 \\n\\t\"\n\n        \"packuswb   %%mm1, %%mm1 \\n\\t\"\n\n        ::\"r\"(dc)\n\n    );\n\n    for(y=2; y--; dst += 4*stride){\n\n    __asm__ volatile(\n\n        \"movq          %0, %%mm2 \\n\\t\"\n\n        \"movq          %1, %%mm3 \\n\\t\"\n\n        \"movq          %2, %%mm4 \\n\\t\"\n\n        \"movq          %3, %%mm5 \\n\\t\"\n\n        \"paddusb    %%mm0, %%mm2 \\n\\t\"\n\n        \"paddusb    %%mm0, %%mm3 \\n\\t\"\n\n        \"paddusb    %%mm0, %%mm4 \\n\\t\"\n\n        \"paddusb    %%mm0, %%mm5 \\n\\t\"\n\n        \"psubusb    %%mm1, %%mm2 \\n\\t\"\n\n        \"psubusb    %%mm1, %%mm3 \\n\\t\"\n\n        \"psubusb    %%mm1, %%mm4 \\n\\t\"\n\n        \"psubusb    %%mm1, %%mm5 \\n\\t\"\n\n        \"movq       %%mm2, %0    \\n\\t\"\n\n        \"movq       %%mm3, %1    \\n\\t\"\n\n        \"movq       %%mm4, %2    \\n\\t\"\n\n        \"movq       %%mm5, %3    \\n\\t\"\n\n        :\"+m\"(*(uint64_t*)(dst+0*stride)),\n\n         \"+m\"(*(uint64_t*)(dst+1*stride)),\n\n         \"+m\"(*(uint64_t*)(dst+2*stride)),\n\n         \"+m\"(*(uint64_t*)(dst+3*stride))\n\n    );\n\n    }\n\n}\n", "idx": 24396}
{"project": "FFmpeg", "commit_id": "d19d52d4a11547cc70bcbc3a2f8b83ccd24bb951", "target": 0, "func": "static int movie_get_frame(AVFilterLink *outlink)\n\n{\n\n    MovieContext *movie = outlink->src->priv;\n\n    AVPacket pkt;\n\n    int ret, frame_decoded;\n\n    AVStream *st = movie->format_ctx->streams[movie->stream_index];\n\n\n\n    if (movie->is_done == 1)\n\n        return 0;\n\n\n\n    while ((ret = av_read_frame(movie->format_ctx, &pkt)) >= 0) {\n\n        // Is this a packet from the video stream?\n\n        if (pkt.stream_index == movie->stream_index) {\n\n            avcodec_decode_video2(movie->codec_ctx, movie->frame, &frame_decoded, &pkt);\n\n\n\n            if (frame_decoded) {\n\n                /* FIXME: avoid the memcpy */\n\n                movie->picref = avfilter_get_video_buffer(outlink, AV_PERM_WRITE | AV_PERM_PRESERVE |\n\n                                                          AV_PERM_REUSE2, outlink->w, outlink->h);\n\n                av_image_copy(movie->picref->data, movie->picref->linesize,\n\n                              (void*)movie->frame->data,  movie->frame->linesize,\n\n                              movie->picref->format, outlink->w, outlink->h);\n\n                avfilter_copy_frame_props(movie->picref, movie->frame);\n\n\n\n                /* FIXME: use a PTS correction mechanism as that in\n\n                 * ffplay.c when some API will be available for that */\n\n                /* use pkt_dts if pkt_pts is not available */\n\n                movie->picref->pts = movie->frame->pkt_pts == AV_NOPTS_VALUE ?\n\n                    movie->frame->pkt_dts : movie->frame->pkt_pts;\n\n\n\n                if (!movie->frame->sample_aspect_ratio.num)\n\n                    movie->picref->video->sample_aspect_ratio = st->sample_aspect_ratio;\n\n                av_dlog(outlink->src,\n\n                        \"movie_get_frame(): file:'%s' pts:%\"PRId64\" time:%lf pos:%\"PRId64\" aspect:%d/%d\\n\",\n\n                        movie->file_name, movie->picref->pts,\n\n                        (double)movie->picref->pts * av_q2d(st->time_base),\n\n                        movie->picref->pos,\n\n                        movie->picref->video->sample_aspect_ratio.num,\n\n                        movie->picref->video->sample_aspect_ratio.den);\n\n                // We got it. Free the packet since we are returning\n\n                av_free_packet(&pkt);\n\n\n\n                return 0;\n\n            }\n\n        }\n\n        // Free the packet that was allocated by av_read_frame\n\n        av_free_packet(&pkt);\n\n    }\n\n\n\n    // On multi-frame source we should stop the mixing process when\n\n    // the movie source does not have more frames\n\n    if (ret == AVERROR_EOF)\n\n        movie->is_done = 1;\n\n    return ret;\n\n}\n", "idx": 24397}
{"project": "FFmpeg", "commit_id": "99e5a9d1ea2a61ac9429427431e5b9c2fefb76a5", "target": 0, "func": "void ff_dsputil_init_neon(DSPContext *c, AVCodecContext *avctx)\n\n{\n\n    c->put_pixels_tab[0][0] = ff_put_pixels16_neon;\n\n    c->put_pixels_tab[0][1] = ff_put_pixels16_x2_neon;\n\n    c->put_pixels_tab[0][2] = ff_put_pixels16_y2_neon;\n\n    c->put_pixels_tab[0][3] = ff_put_pixels16_xy2_neon;\n\n    c->put_pixels_tab[1][0] = ff_put_pixels8_neon;\n\n    c->put_pixels_tab[1][1] = ff_put_pixels8_x2_neon;\n\n    c->put_pixels_tab[1][2] = ff_put_pixels8_y2_neon;\n\n    c->put_pixels_tab[1][3] = ff_put_pixels8_xy2_neon;\n\n\n\n    c->put_no_rnd_pixels_tab[0][0] = ff_put_pixels16_neon;\n\n    c->put_no_rnd_pixels_tab[0][1] = ff_put_pixels16_x2_no_rnd_neon;\n\n    c->put_no_rnd_pixels_tab[0][2] = ff_put_pixels16_y2_no_rnd_neon;\n\n    c->put_no_rnd_pixels_tab[0][3] = ff_put_pixels16_xy2_no_rnd_neon;\n\n    c->put_no_rnd_pixels_tab[1][0] = ff_put_pixels8_neon;\n\n    c->put_no_rnd_pixels_tab[1][1] = ff_put_pixels8_x2_no_rnd_neon;\n\n    c->put_no_rnd_pixels_tab[1][2] = ff_put_pixels8_y2_no_rnd_neon;\n\n    c->put_no_rnd_pixels_tab[1][3] = ff_put_pixels8_xy2_no_rnd_neon;\n\n\n\n    c->avg_pixels_tab[0][0] = ff_avg_pixels16_neon;\n\n\n\n    c->add_pixels_clamped = ff_add_pixels_clamped_neon;\n\n    c->put_pixels_clamped = ff_put_pixels_clamped_neon;\n\n    c->put_signed_pixels_clamped = ff_put_signed_pixels_clamped_neon;\n\n\n\n    c->put_h264_chroma_pixels_tab[0] = ff_put_h264_chroma_mc8_neon;\n\n    c->put_h264_chroma_pixels_tab[1] = ff_put_h264_chroma_mc4_neon;\n\n\n\n    c->avg_h264_chroma_pixels_tab[0] = ff_avg_h264_chroma_mc8_neon;\n\n    c->avg_h264_chroma_pixels_tab[1] = ff_avg_h264_chroma_mc4_neon;\n\n\n\n    c->put_h264_qpel_pixels_tab[0][ 0] = ff_put_h264_qpel16_mc00_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 1] = ff_put_h264_qpel16_mc10_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 2] = ff_put_h264_qpel16_mc20_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 3] = ff_put_h264_qpel16_mc30_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 4] = ff_put_h264_qpel16_mc01_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 5] = ff_put_h264_qpel16_mc11_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 6] = ff_put_h264_qpel16_mc21_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 7] = ff_put_h264_qpel16_mc31_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 8] = ff_put_h264_qpel16_mc02_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 9] = ff_put_h264_qpel16_mc12_neon;\n\n    c->put_h264_qpel_pixels_tab[0][10] = ff_put_h264_qpel16_mc22_neon;\n\n    c->put_h264_qpel_pixels_tab[0][11] = ff_put_h264_qpel16_mc32_neon;\n\n    c->put_h264_qpel_pixels_tab[0][12] = ff_put_h264_qpel16_mc03_neon;\n\n    c->put_h264_qpel_pixels_tab[0][13] = ff_put_h264_qpel16_mc13_neon;\n\n    c->put_h264_qpel_pixels_tab[0][14] = ff_put_h264_qpel16_mc23_neon;\n\n    c->put_h264_qpel_pixels_tab[0][15] = ff_put_h264_qpel16_mc33_neon;\n\n\n\n    c->put_h264_qpel_pixels_tab[1][ 0] = ff_put_h264_qpel8_mc00_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 1] = ff_put_h264_qpel8_mc10_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 2] = ff_put_h264_qpel8_mc20_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 3] = ff_put_h264_qpel8_mc30_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 4] = ff_put_h264_qpel8_mc01_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 5] = ff_put_h264_qpel8_mc11_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 6] = ff_put_h264_qpel8_mc21_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 7] = ff_put_h264_qpel8_mc31_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 8] = ff_put_h264_qpel8_mc02_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 9] = ff_put_h264_qpel8_mc12_neon;\n\n    c->put_h264_qpel_pixels_tab[1][10] = ff_put_h264_qpel8_mc22_neon;\n\n    c->put_h264_qpel_pixels_tab[1][11] = ff_put_h264_qpel8_mc32_neon;\n\n    c->put_h264_qpel_pixels_tab[1][12] = ff_put_h264_qpel8_mc03_neon;\n\n    c->put_h264_qpel_pixels_tab[1][13] = ff_put_h264_qpel8_mc13_neon;\n\n    c->put_h264_qpel_pixels_tab[1][14] = ff_put_h264_qpel8_mc23_neon;\n\n    c->put_h264_qpel_pixels_tab[1][15] = ff_put_h264_qpel8_mc33_neon;\n\n\n\n    c->avg_h264_qpel_pixels_tab[0][ 0] = ff_avg_h264_qpel16_mc00_neon;\n\n\n\n    c->h264_v_loop_filter_luma = ff_h264_v_loop_filter_luma_neon;\n\n    c->h264_h_loop_filter_luma = ff_h264_h_loop_filter_luma_neon;\n\n    c->h264_v_loop_filter_chroma = ff_h264_v_loop_filter_chroma_neon;\n\n    c->h264_h_loop_filter_chroma = ff_h264_h_loop_filter_chroma_neon;\n\n\n\n    c->weight_h264_pixels_tab[0] = ff_weight_h264_pixels_16x16_neon;\n\n    c->weight_h264_pixels_tab[1] = ff_weight_h264_pixels_16x8_neon;\n\n    c->weight_h264_pixels_tab[2] = ff_weight_h264_pixels_8x16_neon;\n\n    c->weight_h264_pixels_tab[3] = ff_weight_h264_pixels_8x8_neon;\n\n    c->weight_h264_pixels_tab[4] = ff_weight_h264_pixels_8x4_neon;\n\n    c->weight_h264_pixels_tab[5] = ff_weight_h264_pixels_4x8_neon;\n\n    c->weight_h264_pixels_tab[6] = ff_weight_h264_pixels_4x4_neon;\n\n    c->weight_h264_pixels_tab[7] = ff_weight_h264_pixels_4x2_neon;\n\n\n\n    c->biweight_h264_pixels_tab[0] = ff_biweight_h264_pixels_16x16_neon;\n\n    c->biweight_h264_pixels_tab[1] = ff_biweight_h264_pixels_16x8_neon;\n\n    c->biweight_h264_pixels_tab[2] = ff_biweight_h264_pixels_8x16_neon;\n\n    c->biweight_h264_pixels_tab[3] = ff_biweight_h264_pixels_8x8_neon;\n\n    c->biweight_h264_pixels_tab[4] = ff_biweight_h264_pixels_8x4_neon;\n\n    c->biweight_h264_pixels_tab[5] = ff_biweight_h264_pixels_4x8_neon;\n\n    c->biweight_h264_pixels_tab[6] = ff_biweight_h264_pixels_4x4_neon;\n\n    c->biweight_h264_pixels_tab[7] = ff_biweight_h264_pixels_4x2_neon;\n\n\n\n    c->h264_idct_add = ff_h264_idct_add_neon;\n\n    c->h264_idct_dc_add = ff_h264_idct_dc_add_neon;\n\n    c->h264_idct_add16      = ff_h264_idct_add16_neon;\n\n    c->h264_idct_add16intra = ff_h264_idct_add16intra_neon;\n\n    c->h264_idct_add8       = ff_h264_idct_add8_neon;\n\n\n\n    if (CONFIG_VP3_DECODER || CONFIG_THEORA_DECODER) {\n\n        c->vp3_v_loop_filter = ff_vp3_v_loop_filter_neon;\n\n        c->vp3_h_loop_filter = ff_vp3_h_loop_filter_neon;\n\n    }\n\n\n\n    c->vector_fmul = ff_vector_fmul_neon;\n\n    c->vector_fmul_window = ff_vector_fmul_window_neon;\n\n\n\n    if (!(avctx->flags & CODEC_FLAG_BITEXACT)) {\n\n        c->float_to_int16 = ff_float_to_int16_neon;\n\n        c->float_to_int16_interleave = ff_float_to_int16_interleave_neon;\n\n    }\n\n}\n", "idx": 24398}
{"project": "FFmpeg", "commit_id": "439c3d5bcc4a4560eaf5fd43c6e156e3d9bc42f2", "target": 1, "func": "static int encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n\n                        const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    NellyMoserEncodeContext *s = avctx->priv_data;\n\n    int ret;\n\n\n\n    if (s->last_frame)\n\n        return 0;\n\n\n\n    memcpy(s->buf, s->buf + NELLY_SAMPLES, NELLY_BUF_LEN * sizeof(*s->buf));\n\n    if (frame) {\n\n        memcpy(s->buf + NELLY_BUF_LEN, frame->data[0],\n\n               frame->nb_samples * sizeof(*s->buf));\n\n        if (frame->nb_samples < NELLY_SAMPLES) {\n\n            memset(s->buf + NELLY_BUF_LEN + avctx->frame_size, 0,\n\n                   (NELLY_SAMPLES - frame->nb_samples) * sizeof(*s->buf));\n\n            if (frame->nb_samples >= NELLY_BUF_LEN)\n\n                s->last_frame = 1;\n\n        }\n\n        if ((ret = ff_af_queue_add(&s->afq, frame) < 0))\n\n            return ret;\n\n    } else {\n\n        memset(s->buf + NELLY_BUF_LEN, 0, NELLY_SAMPLES * sizeof(*s->buf));\n\n        s->last_frame = 1;\n\n    }\n\n\n\n    if ((ret = ff_alloc_packet(avpkt, NELLY_BLOCK_LEN))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n\n        return ret;\n\n    }\n\n    encode_block(s, avpkt->data, avpkt->size);\n\n\n\n    /* Get the next frame pts/duration */\n\n    ff_af_queue_remove(&s->afq, avctx->frame_size, &avpkt->pts,\n\n                       &avpkt->duration);\n\n\n\n    *got_packet_ptr = 1;\n\n    return 0;\n\n}\n", "idx": 24400}
{"project": "FFmpeg", "commit_id": "9cc9a155100d4364ad02d50e89b313ec94195102", "target": 1, "func": "static int rtp_new_av_stream(HTTPContext *c,\n\n                             int stream_index, struct sockaddr_in *dest_addr,\n\n                             HTTPContext *rtsp_c)\n\n{\n\n    AVFormatContext *ctx;\n\n    AVStream *st;\n\n    char *ipaddr;\n\n    URLContext *h = NULL;\n\n    uint8_t *dummy_buf;\n\n    int max_packet_size;\n\n\n\n    /* now we can open the relevant output stream */\n\n    ctx = avformat_alloc_context();\n\n    if (!ctx)\n\n        return -1;\n\n    ctx->oformat = av_guess_format(\"rtp\", NULL, NULL);\n\n\n\n    st = av_mallocz(sizeof(AVStream));\n\n    if (!st)\n\n        goto fail;\n\n    st->codec= avcodec_alloc_context();\n\n    ctx->nb_streams = 1;\n\n    ctx->streams[0] = st;\n\n\n\n    if (!c->stream->feed ||\n\n        c->stream->feed == c->stream)\n\n        memcpy(st, c->stream->streams[stream_index], sizeof(AVStream));\n\n    else\n\n        memcpy(st,\n\n               c->stream->feed->streams[c->stream->feed_streams[stream_index]],\n\n               sizeof(AVStream));\n\n    st->priv_data = NULL;\n\n\n\n    /* build destination RTP address */\n\n    ipaddr = inet_ntoa(dest_addr->sin_addr);\n\n\n\n    switch(c->rtp_protocol) {\n\n    case RTSP_LOWER_TRANSPORT_UDP:\n\n    case RTSP_LOWER_TRANSPORT_UDP_MULTICAST:\n\n        /* RTP/UDP case */\n\n\n\n        /* XXX: also pass as parameter to function ? */\n\n        if (c->stream->is_multicast) {\n\n            int ttl;\n\n            ttl = c->stream->multicast_ttl;\n\n            if (!ttl)\n\n                ttl = 16;\n\n            snprintf(ctx->filename, sizeof(ctx->filename),\n\n                     \"rtp://%s:%d?multicast=1&ttl=%d\",\n\n                     ipaddr, ntohs(dest_addr->sin_port), ttl);\n\n        } else {\n\n            snprintf(ctx->filename, sizeof(ctx->filename),\n\n                     \"rtp://%s:%d\", ipaddr, ntohs(dest_addr->sin_port));\n\n        }\n\n\n\n        if (url_open(&h, ctx->filename, URL_WRONLY) < 0)\n\n            goto fail;\n\n        c->rtp_handles[stream_index] = h;\n\n        max_packet_size = url_get_max_packet_size(h);\n\n        break;\n\n    case RTSP_LOWER_TRANSPORT_TCP:\n\n        /* RTP/TCP case */\n\n        c->rtsp_c = rtsp_c;\n\n        max_packet_size = RTSP_TCP_MAX_PACKET_SIZE;\n\n        break;\n\n    default:\n\n        goto fail;\n\n    }\n\n\n\n    http_log(\"%s:%d - - \\\"PLAY %s/streamid=%d %s\\\"\\n\",\n\n             ipaddr, ntohs(dest_addr->sin_port),\n\n             c->stream->filename, stream_index, c->protocol);\n\n\n\n    /* normally, no packets should be output here, but the packet size may be checked */\n\n    if (url_open_dyn_packet_buf(&ctx->pb, max_packet_size) < 0) {\n\n        /* XXX: close stream */\n\n        goto fail;\n\n    }\n\n    av_set_parameters(ctx, NULL);\n\n    if (av_write_header(ctx) < 0) {\n\n    fail:\n\n        if (h)\n\n            url_close(h);\n\n        av_free(ctx);\n\n        return -1;\n\n    }\n\n    url_close_dyn_buf(ctx->pb, &dummy_buf);\n\n    av_free(dummy_buf);\n\n\n\n    c->rtp_ctx[stream_index] = ctx;\n\n    return 0;\n\n}\n", "idx": 24401}
{"project": "FFmpeg", "commit_id": "8a69f2602fea04b7ebae2db16f2581e8ff5ee0cd", "target": 1, "func": "static int dvbsub_parse_clut_segment(AVCodecContext *avctx,\n\n                                     const uint8_t *buf, int buf_size)\n\n{\n\n    DVBSubContext *ctx = avctx->priv_data;\n\n\n\n    const uint8_t *buf_end = buf + buf_size;\n\n    int i, clut_id;\n\n    int version;\n\n    DVBSubCLUT *clut;\n\n    int entry_id, depth , full_range;\n\n    int y, cr, cb, alpha;\n\n    int r, g, b, r_add, g_add, b_add;\n\n\n\n    ff_dlog(avctx, \"DVB clut packet:\\n\");\n\n\n\n    for (i=0; i < buf_size; i++) {\n\n        ff_dlog(avctx, \"%02x \", buf[i]);\n\n        if (i % 16 == 15)\n\n            ff_dlog(avctx, \"\\n\");\n\n    }\n\n\n\n    if (i % 16)\n\n        ff_dlog(avctx, \"\\n\");\n\n\n\n    clut_id = *buf++;\n\n    version = ((*buf)>>4)&15;\n\n    buf += 1;\n\n\n\n    clut = get_clut(ctx, clut_id);\n\n\n\n    if (!clut) {\n\n        clut = av_malloc(sizeof(DVBSubCLUT));\n\n        if (!clut)\n\n            return AVERROR(ENOMEM);\n\n\n\n        memcpy(clut, &default_clut, sizeof(DVBSubCLUT));\n\n\n\n        clut->id = clut_id;\n\n        clut->version = -1;\n\n\n\n        clut->next = ctx->clut_list;\n\n        ctx->clut_list = clut;\n\n    }\n\n\n\n    if (clut->version != version) {\n\n\n\n    clut->version = version;\n\n\n\n    while (buf + 4 < buf_end) {\n\n        entry_id = *buf++;\n\n\n\n        depth = (*buf) & 0xe0;\n\n\n\n        if (depth == 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Invalid clut depth 0x%x!\\n\", *buf);\n\n        }\n\n\n\n        full_range = (*buf++) & 1;\n\n\n\n        if (full_range) {\n\n            y = *buf++;\n\n            cr = *buf++;\n\n            cb = *buf++;\n\n            alpha = *buf++;\n\n        } else {\n\n            y = buf[0] & 0xfc;\n\n            cr = (((buf[0] & 3) << 2) | ((buf[1] >> 6) & 3)) << 4;\n\n            cb = (buf[1] << 2) & 0xf0;\n\n            alpha = (buf[1] << 6) & 0xc0;\n\n\n\n            buf += 2;\n\n        }\n\n\n\n        if (y == 0)\n\n            alpha = 0xff;\n\n\n\n        YUV_TO_RGB1_CCIR(cb, cr);\n\n        YUV_TO_RGB2_CCIR(r, g, b, y);\n\n\n\n        ff_dlog(avctx, \"clut %d := (%d,%d,%d,%d)\\n\", entry_id, r, g, b, alpha);\n\n        if (!!(depth & 0x80) + !!(depth & 0x40) + !!(depth & 0x20) > 1) {\n\n            ff_dlog(avctx, \"More than one bit level marked: %x\\n\", depth);\n\n            if (avctx->strict_std_compliance > FF_COMPLIANCE_NORMAL)\n\n                return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        if (depth & 0x80)\n\n            clut->clut4[entry_id] = RGBA(r,g,b,255 - alpha);\n\n        else if (depth & 0x40)\n\n            clut->clut16[entry_id] = RGBA(r,g,b,255 - alpha);\n\n        else if (depth & 0x20)\n\n            clut->clut256[entry_id] = RGBA(r,g,b,255 - alpha);\n\n    }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24404}
{"project": "FFmpeg", "commit_id": "6136b989f658fff68e2b758db583f04358d3d412", "target": 1, "func": "static inline void vc1_pred_mv_intfr(VC1Context *v, int n, int dmv_x, int dmv_y,\n\n                                     int mvn, int r_x, int r_y, uint8_t* is_intra)\n\n{\n\n    MpegEncContext *s = &v->s;\n\n    int xy, wrap, off = 0;\n\n    int A[2], B[2], C[2];\n\n    int px, py;\n\n    int a_valid = 0, b_valid = 0, c_valid = 0;\n\n    int field_a, field_b, field_c; // 0: same, 1: opposit\n\n    int total_valid, num_samefield, num_oppfield;\n\n    int pos_c, pos_b, n_adj;\n\n\n\n    wrap = s->b8_stride;\n\n    xy = s->block_index[n];\n\n\n\n    if (s->mb_intra) {\n\n        s->mv[0][n][0] = s->current_picture.f.motion_val[0][xy][0] = 0;\n\n        s->mv[0][n][1] = s->current_picture.f.motion_val[0][xy][1] = 0;\n\n        s->current_picture.f.motion_val[1][xy][0] = 0;\n\n        s->current_picture.f.motion_val[1][xy][1] = 0;\n\n        if (mvn == 1) { /* duplicate motion data for 1-MV block */\n\n            s->current_picture.f.motion_val[0][xy + 1][0]        = 0;\n\n            s->current_picture.f.motion_val[0][xy + 1][1]        = 0;\n\n            s->current_picture.f.motion_val[0][xy + wrap][0]     = 0;\n\n            s->current_picture.f.motion_val[0][xy + wrap][1]     = 0;\n\n            s->current_picture.f.motion_val[0][xy + wrap + 1][0] = 0;\n\n            s->current_picture.f.motion_val[0][xy + wrap + 1][1] = 0;\n\n            v->luma_mv[s->mb_x][0] = v->luma_mv[s->mb_x][1] = 0;\n\n            s->current_picture.f.motion_val[1][xy + 1][0]        = 0;\n\n            s->current_picture.f.motion_val[1][xy + 1][1]        = 0;\n\n            s->current_picture.f.motion_val[1][xy + wrap][0]     = 0;\n\n            s->current_picture.f.motion_val[1][xy + wrap][1]     = 0;\n\n            s->current_picture.f.motion_val[1][xy + wrap + 1][0] = 0;\n\n            s->current_picture.f.motion_val[1][xy + wrap + 1][1] = 0;\n\n        }\n\n        return;\n\n    }\n\n\n\n    off = ((n == 0) || (n == 1)) ? 1 : -1;\n\n    /* predict A */\n\n    if (s->mb_x || (n == 1) || (n == 3)) {\n\n        if ((v->blk_mv_type[xy]) // current block (MB) has a field MV\n\n            || (!v->blk_mv_type[xy] && !v->blk_mv_type[xy - 1])) { // or both have frame MV\n\n            A[0] = s->current_picture.f.motion_val[0][xy - 1][0];\n\n            A[1] = s->current_picture.f.motion_val[0][xy - 1][1];\n\n            a_valid = 1;\n\n        } else { // current block has frame mv and cand. has field MV (so average)\n\n            A[0] = (s->current_picture.f.motion_val[0][xy - 1][0]\n\n                    + s->current_picture.f.motion_val[0][xy - 1 + off * wrap][0] + 1) >> 1;\n\n            A[1] = (s->current_picture.f.motion_val[0][xy - 1][1]\n\n                    + s->current_picture.f.motion_val[0][xy - 1 + off * wrap][1] + 1) >> 1;\n\n            a_valid = 1;\n\n        }\n\n        if (!(n & 1) && v->is_intra[s->mb_x - 1]) {\n\n            a_valid = 0;\n\n            A[0] = A[1] = 0;\n\n        }\n\n    } else\n\n        A[0] = A[1] = 0;\n\n    /* Predict B and C */\n\n    B[0] = B[1] = C[0] = C[1] = 0;\n\n    if (n == 0 || n == 1 || v->blk_mv_type[xy]) {\n\n        if (!s->first_slice_line) {\n\n            if (!v->is_intra[s->mb_x - s->mb_stride]) {\n\n                b_valid = 1;\n\n                n_adj   = n | 2;\n\n                pos_b   = s->block_index[n_adj] - 2 * wrap;\n\n                if (v->blk_mv_type[pos_b] && v->blk_mv_type[xy]) {\n\n                    n_adj = (n & 2) | (n & 1);\n\n                }\n\n                B[0] = s->current_picture.f.motion_val[0][s->block_index[n_adj] - 2 * wrap][0];\n\n                B[1] = s->current_picture.f.motion_val[0][s->block_index[n_adj] - 2 * wrap][1];\n\n                if (v->blk_mv_type[pos_b] && !v->blk_mv_type[xy]) {\n\n                    B[0] = (B[0] + s->current_picture.f.motion_val[0][s->block_index[n_adj ^ 2] - 2 * wrap][0] + 1) >> 1;\n\n                    B[1] = (B[1] + s->current_picture.f.motion_val[0][s->block_index[n_adj ^ 2] - 2 * wrap][1] + 1) >> 1;\n\n                }\n\n            }\n\n            if (s->mb_width > 1) {\n\n                if (!v->is_intra[s->mb_x - s->mb_stride + 1]) {\n\n                    c_valid = 1;\n\n                    n_adj   = 2;\n\n                    pos_c   = s->block_index[2] - 2 * wrap + 2;\n\n                    if (v->blk_mv_type[pos_c] && v->blk_mv_type[xy]) {\n\n                        n_adj = n & 2;\n\n                    }\n\n                    C[0] = s->current_picture.f.motion_val[0][s->block_index[n_adj] - 2 * wrap + 2][0];\n\n                    C[1] = s->current_picture.f.motion_val[0][s->block_index[n_adj] - 2 * wrap + 2][1];\n\n                    if (v->blk_mv_type[pos_c] && !v->blk_mv_type[xy]) {\n\n                        C[0] = (1 + C[0] + (s->current_picture.f.motion_val[0][s->block_index[n_adj ^ 2] - 2 * wrap + 2][0])) >> 1;\n\n                        C[1] = (1 + C[1] + (s->current_picture.f.motion_val[0][s->block_index[n_adj ^ 2] - 2 * wrap + 2][1])) >> 1;\n\n                    }\n\n                    if (s->mb_x == s->mb_width - 1) {\n\n                        if (!v->is_intra[s->mb_x - s->mb_stride - 1]) {\n\n                            c_valid = 1;\n\n                            n_adj   = 3;\n\n                            pos_c   = s->block_index[3] - 2 * wrap - 2;\n\n                            if (v->blk_mv_type[pos_c] && v->blk_mv_type[xy]) {\n\n                                n_adj = n | 1;\n\n                            }\n\n                            C[0] = s->current_picture.f.motion_val[0][s->block_index[n_adj] - 2 * wrap - 2][0];\n\n                            C[1] = s->current_picture.f.motion_val[0][s->block_index[n_adj] - 2 * wrap - 2][1];\n\n                            if (v->blk_mv_type[pos_c] && !v->blk_mv_type[xy]) {\n\n                                C[0] = (1 + C[0] + s->current_picture.f.motion_val[0][s->block_index[1] - 2 * wrap - 2][0]) >> 1;\n\n                                C[1] = (1 + C[1] + s->current_picture.f.motion_val[0][s->block_index[1] - 2 * wrap - 2][1]) >> 1;\n\n                            }\n\n                        } else\n\n                            c_valid = 0;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    } else {\n\n        pos_b   = s->block_index[1];\n\n        b_valid = 1;\n\n        B[0]    = s->current_picture.f.motion_val[0][pos_b][0];\n\n        B[1]    = s->current_picture.f.motion_val[0][pos_b][1];\n\n        pos_c   = s->block_index[0];\n\n        c_valid = 1;\n\n        C[0]    = s->current_picture.f.motion_val[0][pos_c][0];\n\n        C[1]    = s->current_picture.f.motion_val[0][pos_c][1];\n\n    }\n\n\n\n    total_valid = a_valid + b_valid + c_valid;\n\n    // check if predictor A is out of bounds\n\n    if (!s->mb_x && !(n == 1 || n == 3)) {\n\n        A[0] = A[1] = 0;\n\n    }\n\n    // check if predictor B is out of bounds\n\n    if ((s->first_slice_line && v->blk_mv_type[xy]) || (s->first_slice_line && !(n & 2))) {\n\n        B[0] = B[1] = C[0] = C[1] = 0;\n\n    }\n\n    if (!v->blk_mv_type[xy]) {\n\n        if (s->mb_width == 1) {\n\n            px = B[0];\n\n            py = B[1];\n\n        } else {\n\n            if (total_valid >= 2) {\n\n                px = mid_pred(A[0], B[0], C[0]);\n\n                py = mid_pred(A[1], B[1], C[1]);\n\n            } else if (total_valid) {\n\n                if (a_valid) { px = A[0]; py = A[1]; }\n\n                if (b_valid) { px = B[0]; py = B[1]; }\n\n                if (c_valid) { px = C[0]; py = C[1]; }\n\n            } else\n\n                px = py = 0;\n\n        }\n\n    } else {\n\n        if (a_valid)\n\n            field_a = (A[1] & 4) ? 1 : 0;\n\n        else\n\n            field_a = 0;\n\n        if (b_valid)\n\n            field_b = (B[1] & 4) ? 1 : 0;\n\n        else\n\n            field_b = 0;\n\n        if (c_valid)\n\n            field_c = (C[1] & 4) ? 1 : 0;\n\n        else\n\n            field_c = 0;\n\n\n\n        num_oppfield  = field_a + field_b + field_c;\n\n        num_samefield = total_valid - num_oppfield;\n\n        if (total_valid == 3) {\n\n            if ((num_samefield == 3) || (num_oppfield == 3)) {\n\n                px = mid_pred(A[0], B[0], C[0]);\n\n                py = mid_pred(A[1], B[1], C[1]);\n\n            } else if (num_samefield >= num_oppfield) {\n\n                /* take one MV from same field set depending on priority\n\n                the check for B may not be necessary */\n\n                px = !field_a ? A[0] : B[0];\n\n                py = !field_a ? A[1] : B[1];\n\n            } else {\n\n                px =  field_a ? A[0] : B[0];\n\n                py =  field_a ? A[1] : B[1];\n\n            }\n\n        } else if (total_valid == 2) {\n\n            if (num_samefield >= num_oppfield) {\n\n                if (!field_a && a_valid) {\n\n                    px = A[0];\n\n                    py = A[1];\n\n                } else if (!field_b && b_valid) {\n\n                    px = B[0];\n\n                    py = B[1];\n\n                } else if (c_valid) {\n\n                    px = C[0];\n\n                    py = C[1];\n\n                } else px = py = 0;\n\n            } else {\n\n                if (field_a && a_valid) {\n\n                    px = A[0];\n\n                    py = A[1];\n\n                } else if (field_b && b_valid) {\n\n                    px = B[0];\n\n                    py = B[1];\n\n                } else if (c_valid) {\n\n                    px = C[0];\n\n                    py = C[1];\n\n                } else px = py = 0;\n\n            }\n\n        } else if (total_valid == 1) {\n\n            px = (a_valid) ? A[0] : ((b_valid) ? B[0] : C[0]);\n\n            py = (a_valid) ? A[1] : ((b_valid) ? B[1] : C[1]);\n\n        } else\n\n            px = py = 0;\n\n    }\n\n\n\n    /* store MV using signed modulus of MV range defined in 4.11 */\n\n    s->mv[0][n][0] = s->current_picture.f.motion_val[0][xy][0] = ((px + dmv_x + r_x) & ((r_x << 1) - 1)) - r_x;\n\n    s->mv[0][n][1] = s->current_picture.f.motion_val[0][xy][1] = ((py + dmv_y + r_y) & ((r_y << 1) - 1)) - r_y;\n\n    if (mvn == 1) { /* duplicate motion data for 1-MV block */\n\n        s->current_picture.f.motion_val[0][xy +    1    ][0] = s->current_picture.f.motion_val[0][xy][0];\n\n        s->current_picture.f.motion_val[0][xy +    1    ][1] = s->current_picture.f.motion_val[0][xy][1];\n\n        s->current_picture.f.motion_val[0][xy + wrap    ][0] = s->current_picture.f.motion_val[0][xy][0];\n\n        s->current_picture.f.motion_val[0][xy + wrap    ][1] = s->current_picture.f.motion_val[0][xy][1];\n\n        s->current_picture.f.motion_val[0][xy + wrap + 1][0] = s->current_picture.f.motion_val[0][xy][0];\n\n        s->current_picture.f.motion_val[0][xy + wrap + 1][1] = s->current_picture.f.motion_val[0][xy][1];\n\n    } else if (mvn == 2) { /* duplicate motion data for 2-Field MV block */\n\n        s->current_picture.f.motion_val[0][xy + 1][0] = s->current_picture.f.motion_val[0][xy][0];\n\n        s->current_picture.f.motion_val[0][xy + 1][1] = s->current_picture.f.motion_val[0][xy][1];\n\n        s->mv[0][n + 1][0] = s->mv[0][n][0];\n\n        s->mv[0][n + 1][1] = s->mv[0][n][1];\n\n    }\n\n}\n", "idx": 24409}
{"project": "FFmpeg", "commit_id": "8b18288c08fd450601251700eb42d9efbef89803", "target": 1, "func": "static void qtrle_encode_line(QtrleEncContext *s, AVFrame *p, int line, uint8_t **buf)\n\n{\n\n    int width=s->logical_width;\n\n    int i;\n\n    signed char rlecode;\n\n\n\n    /* We will use it to compute the best bulk copy sequence */\n\n    unsigned int bulkcount;\n\n    /* This will be the number of pixels equal to the preivous frame one's\n\n     * starting from the ith pixel */\n\n    unsigned int skipcount;\n\n    /* This will be the number of consecutive equal pixels in the current\n\n     * frame, starting from the ith one also */\n\n    unsigned int repeatcount;\n\n\n\n    /* The cost of the three different possibilities */\n\n    int total_bulk_cost;\n\n    int total_skip_cost;\n\n    int total_repeat_cost;\n\n\n\n    int temp_cost;\n\n    int j;\n\n\n\n    uint8_t *this_line = p->               data[0] + line*p->               linesize[0] +\n\n        (width - 1)*s->pixel_size;\n\n    uint8_t *prev_line = s->previous_frame.data[0] + line*s->previous_frame.linesize[0] +\n\n        (width - 1)*s->pixel_size;\n\n\n\n    s->length_table[width] = 0;\n\n    skipcount = 0;\n\n\n\n    for (i = width - 1; i >= 0; i--) {\n\n\n\n        if (!s->frame.key_frame && !memcmp(this_line, prev_line, s->pixel_size))\n\n            skipcount = FFMIN(skipcount + 1, MAX_RLE_SKIP);\n\n        else\n\n            skipcount = 0;\n\n\n\n        total_skip_cost  = s->length_table[i + skipcount] + 2;\n\n        s->skip_table[i] = skipcount;\n\n\n\n\n\n        if (i < width - 1 && !memcmp(this_line, this_line + s->pixel_size, s->pixel_size))\n\n            repeatcount = FFMIN(repeatcount + 1, MAX_RLE_REPEAT);\n\n        else\n\n            repeatcount = 1;\n\n\n\n        total_repeat_cost = s->length_table[i + repeatcount] + 1 + s->pixel_size;\n\n\n\n        /* skip code is free for the first pixel, it costs one byte for repeat and bulk copy\n\n         * so let's make it aware */\n\n        if (i == 0) {\n\n            total_skip_cost--;\n\n            total_repeat_cost++;\n\n        }\n\n\n\n        if (repeatcount > 1 && (skipcount == 0 || total_repeat_cost < total_skip_cost)) {\n\n            /* repeat is the best */\n\n            s->length_table[i]  = total_repeat_cost;\n\n            s->rlecode_table[i] = -repeatcount;\n\n        }\n\n        else if (skipcount > 0) {\n\n            /* skip is the best choice here */\n\n            s->length_table[i]  = total_skip_cost;\n\n            s->rlecode_table[i] = 0;\n\n        }\n\n        else {\n\n            /* We cannot do neither skip nor repeat\n\n             * thus we search for the best bulk copy to do */\n\n\n\n            int limit = FFMIN(width - i, MAX_RLE_BULK);\n\n\n\n            temp_cost = 1 + s->pixel_size + !i;\n\n            total_bulk_cost = INT_MAX;\n\n\n\n            for (j = 1; j <= limit; j++) {\n\n                if (s->length_table[i + j] + temp_cost < total_bulk_cost) {\n\n                    /* We have found a better bulk copy ... */\n\n                    total_bulk_cost = s->length_table[i + j] + temp_cost;\n\n                    bulkcount = j;\n\n                }\n\n                temp_cost += s->pixel_size;\n\n            }\n\n\n\n            s->length_table[i]  = total_bulk_cost;\n\n            s->rlecode_table[i] = bulkcount;\n\n        }\n\n\n\n        this_line -= s->pixel_size;\n\n        prev_line -= s->pixel_size;\n\n    }\n\n\n\n    /* Good ! Now we have the best sequence for this line, let's output it */\n\n\n\n    /* We do a special case for the first pixel so that we avoid testing it in\n\n     * the whole loop */\n\n\n\n    i=0;\n\n    this_line = p->               data[0] + line*p->linesize[0];\n\n\n\n    if (s->rlecode_table[0] == 0) {\n\n        bytestream_put_byte(buf, s->skip_table[0] + 1);\n\n        i += s->skip_table[0];\n\n    }\n\n    else bytestream_put_byte(buf, 1);\n\n\n\n\n\n    while (i < width) {\n\n        rlecode = s->rlecode_table[i];\n\n        bytestream_put_byte(buf, rlecode);\n\n        if (rlecode == 0) {\n\n            /* Write a skip sequence */\n\n            bytestream_put_byte(buf, s->skip_table[i] + 1);\n\n            i += s->skip_table[i];\n\n        }\n\n        else if (rlecode > 0) {\n\n            /* bulk copy */\n\n            if (s->avctx->pix_fmt == PIX_FMT_GRAY8) {\n\n                int j;\n\n                // QT grayscale colorspace has 0=white and 255=black, we will\n\n                // ignore the palette that is included in the AVFrame because\n\n                // PIX_FMT_GRAY8 has defined color mapping\n\n                for (j = 0; j < rlecode*s->pixel_size; ++j)\n\n                    bytestream_put_byte(buf, *(this_line + i*s->pixel_size + j) ^ 0xff);\n\n            } else {\n\n                bytestream_put_buffer(buf, this_line + i*s->pixel_size, rlecode*s->pixel_size);\n\n            }\n\n            i += rlecode;\n\n        }\n\n        else {\n\n            /* repeat the bits */\n\n            if (s->avctx->pix_fmt == PIX_FMT_GRAY8) {\n\n                int j;\n\n                // QT grayscale colorspace has 0=white and 255=black, ...\n\n                for (j = 0; j < s->pixel_size; ++j)\n\n                    bytestream_put_byte(buf, *(this_line + i*s->pixel_size + j) ^ 0xff);\n\n            } else {\n\n                bytestream_put_buffer(buf, this_line + i*s->pixel_size, s->pixel_size);\n\n            }\n\n            i -= rlecode;\n\n        }\n\n    }\n\n    bytestream_put_byte(buf, -1); // end RLE line\n\n}\n", "idx": 24412}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "static void rv34_idct_add_c(uint8_t *dst, ptrdiff_t stride, DCTELEM *block){\n\n    int      temp[16];\n\n    uint8_t *cm = ff_cropTbl + MAX_NEG_CROP;\n\n    int      i;\n\n\n\n    rv34_row_transform(temp, block);\n\n    memset(block, 0, 16*sizeof(DCTELEM));\n\n\n\n    for(i = 0; i < 4; i++){\n\n        const int z0 = 13*(temp[4*0+i] +    temp[4*2+i]) + 0x200;\n\n        const int z1 = 13*(temp[4*0+i] -    temp[4*2+i]) + 0x200;\n\n        const int z2 =  7* temp[4*1+i] - 17*temp[4*3+i];\n\n        const int z3 = 17* temp[4*1+i] +  7*temp[4*3+i];\n\n\n\n        dst[0] = cm[ dst[0] + ( (z0 + z3) >> 10 ) ];\n\n        dst[1] = cm[ dst[1] + ( (z1 + z2) >> 10 ) ];\n\n        dst[2] = cm[ dst[2] + ( (z1 - z2) >> 10 ) ];\n\n        dst[3] = cm[ dst[3] + ( (z0 - z3) >> 10 ) ];\n\n\n\n        dst  += stride;\n\n    }\n\n}\n", "idx": 24413}
{"project": "FFmpeg", "commit_id": "3cfe88194a6ea8c720dfc85239d03c659473bcc3", "target": 1, "func": "int ff_lpc_calc_coefs(DSPContext *s,\n\n                      const int32_t *samples, int blocksize, int min_order,\n\n                      int max_order, int precision,\n\n                      int32_t coefs[][MAX_LPC_ORDER], int *shift, int use_lpc,\n\n                      int omethod, int max_shift, int zero_shift)\n\n{\n\n    double autoc[MAX_LPC_ORDER+1];\n\n    double ref[MAX_LPC_ORDER];\n\n    double lpc[MAX_LPC_ORDER][MAX_LPC_ORDER];\n\n    int i, j, pass;\n\n    int opt_order;\n\n\n\n    assert(max_order >= MIN_LPC_ORDER && max_order <= MAX_LPC_ORDER && use_lpc > 0);\n\n\n\n    if(use_lpc == 1){\n\n        s->flac_compute_autocorr(samples, blocksize, max_order, autoc);\n\n\n\n        compute_lpc_coefs(autoc, max_order, &lpc[0][0], MAX_LPC_ORDER, 0, 1);\n\n\n\n        for(i=0; i<max_order; i++)\n\n            ref[i] = fabs(lpc[i][i]);\n\n    }else{\n\n        LLSModel m[2];\n\n        double var[MAX_LPC_ORDER+1], weight;\n\n\n\n        for(pass=0; pass<use_lpc-1; pass++){\n\n            av_init_lls(&m[pass&1], max_order);\n\n\n\n            weight=0;\n\n            for(i=max_order; i<blocksize; i++){\n\n                for(j=0; j<=max_order; j++)\n\n                    var[j]= samples[i-j];\n\n\n\n                if(pass){\n\n                    double eval, inv, rinv;\n\n                    eval= av_evaluate_lls(&m[(pass-1)&1], var+1, max_order-1);\n\n                    eval= (512>>pass) + fabs(eval - var[0]);\n\n                    inv = 1/eval;\n\n                    rinv = sqrt(inv);\n\n                    for(j=0; j<=max_order; j++)\n\n                        var[j] *= rinv;\n\n                    weight += inv;\n\n                }else\n\n                    weight++;\n\n\n\n                av_update_lls(&m[pass&1], var, 1.0);\n\n            }\n\n            av_solve_lls(&m[pass&1], 0.001, 0);\n\n        }\n\n\n\n        for(i=0; i<max_order; i++){\n\n            for(j=0; j<max_order; j++)\n\n                lpc[i][j]=-m[(pass-1)&1].coeff[i][j];\n\n            ref[i]= sqrt(m[(pass-1)&1].variance[i] / weight) * (blocksize - max_order) / 4000;\n\n        }\n\n        for(i=max_order-1; i>0; i--)\n\n            ref[i] = ref[i-1] - ref[i];\n\n    }\n\n    opt_order = max_order;\n\n\n\n    if(omethod == ORDER_METHOD_EST) {\n\n        opt_order = estimate_best_order(ref, min_order, max_order);\n\n        i = opt_order-1;\n\n        quantize_lpc_coefs(lpc[i], i+1, precision, coefs[i], &shift[i], max_shift, zero_shift);\n\n    } else {\n\n        for(i=min_order-1; i<max_order; i++) {\n\n            quantize_lpc_coefs(lpc[i], i+1, precision, coefs[i], &shift[i], max_shift, zero_shift);\n\n        }\n\n    }\n\n\n\n    return opt_order;\n\n}\n", "idx": 24414}
{"project": "FFmpeg", "commit_id": "835d9f299cf6b3704989a7b3eccfa1c2ec6866d9", "target": 1, "func": "av_cold void ff_cavsdsp_init_x86(CAVSDSPContext *c, AVCodecContext *avctx)\n\n{\n\n    av_unused int cpu_flags = av_get_cpu_flags();\n\n\n\n    cavsdsp_init_mmx(c, avctx);\n\n#if HAVE_AMD3DNOW_INLINE\n\n    if (INLINE_AMD3DNOW(cpu_flags))\n\n        cavsdsp_init_3dnow(c, avctx);\n\n#endif /* HAVE_AMD3DNOW_INLINE */\n\n#if HAVE_MMXEXT_INLINE\n\n    if (INLINE_MMXEXT(cpu_flags)) {\n\n        DSPFUNC(put, 0, 16, mmxext);\n\n        DSPFUNC(put, 1,  8, mmxext);\n\n        DSPFUNC(avg, 0, 16, mmxext);\n\n        DSPFUNC(avg, 1,  8, mmxext);\n\n    }\n\n#endif\n\n#if HAVE_MMX_EXTERNAL\n\n    if (EXTERNAL_MMXEXT(cpu_flags)) {\n\n        c->avg_cavs_qpel_pixels_tab[0][0] = avg_cavs_qpel16_mc00_mmxext;\n\n        c->avg_cavs_qpel_pixels_tab[1][0] = avg_cavs_qpel8_mc00_mmxext;\n\n    }\n\n#endif\n\n#if HAVE_SSE2_EXTERNAL\n\n    if (EXTERNAL_SSE2(cpu_flags)) {\n\n        c->put_cavs_qpel_pixels_tab[0][0] = put_cavs_qpel16_mc00_sse2;\n\n        c->avg_cavs_qpel_pixels_tab[0][0] = avg_cavs_qpel16_mc00_sse2;\n\n    }\n\n#endif\n\n}\n", "idx": 24416}
{"project": "FFmpeg", "commit_id": "0c74098b1c4cc566ee0af19374b03d1e425dd1f0", "target": 1, "func": "static int svq3_decode_frame (AVCodecContext *avctx,\n\n                              void *data, int *data_size,\n\n                              uint8_t *buf, int buf_size) {\n\n  MpegEncContext *const s = avctx->priv_data;\n\n  H264Context *const h = avctx->priv_data;\n\n  int m, mb_type;\n\n  unsigned char *extradata;\n\n  unsigned int size;\n\n\n\n  s->flags = avctx->flags;\n\n  s->flags2 = avctx->flags2;\n\n  s->unrestricted_mv = 1;\n\n\n\n  if (!s->context_initialized) {\n\n    s->width = avctx->width;\n\n    s->height = avctx->height;\n\n    h->pred4x4[DIAG_DOWN_LEFT_PRED] = pred4x4_down_left_svq3_c;\n\n    h->pred16x16[PLANE_PRED8x8] = pred16x16_plane_svq3_c;\n\n    h->halfpel_flag = 1;\n\n    h->thirdpel_flag = 1;\n\n    h->unknown_svq3_flag = 0;\n\n    h->chroma_qp = 4;\n\n\n\n    if (MPV_common_init (s) < 0)\n\n      return -1;\n\n\n\n    h->b_stride = 4*s->mb_width;\n\n\n\n    alloc_tables (h);\n\n\n\n    /* prowl for the \"SEQH\" marker in the extradata */\n\n    extradata = (unsigned char *)avctx->extradata;\n\n    for (m = 0; m < avctx->extradata_size; m++) {\n\n      if (!memcmp (extradata, \"SEQH\", 4))\n\n        break;\n\n      extradata++;\n\n    }\n\n\n\n    /* if a match was found, parse the extra data */\n\n    if (extradata && !memcmp (extradata, \"SEQH\", 4)) {\n\n\n\n      GetBitContext gb;\n\n\n\n      size = AV_RB32(&extradata[4]);\n\n      init_get_bits (&gb, extradata + 8, size*8);\n\n\n\n      /* 'frame size code' and optional 'width, height' */\n\n      if (get_bits (&gb, 3) == 7) {\n\n        get_bits (&gb, 12);\n\n        get_bits (&gb, 12);\n\n      }\n\n\n\n      h->halfpel_flag = get_bits1 (&gb);\n\n      h->thirdpel_flag = get_bits1 (&gb);\n\n\n\n      /* unknown fields */\n\n      get_bits1 (&gb);\n\n      get_bits1 (&gb);\n\n      get_bits1 (&gb);\n\n      get_bits1 (&gb);\n\n\n\n      s->low_delay = get_bits1 (&gb);\n\n\n\n      /* unknown field */\n\n      get_bits1 (&gb);\n\n\n\n      while (get_bits1 (&gb)) {\n\n        get_bits (&gb, 8);\n\n      }\n\n\n\n      h->unknown_svq3_flag = get_bits1 (&gb);\n\n      avctx->has_b_frames = !s->low_delay;\n\n    }\n\n  }\n\n\n\n  /* special case for last picture */\n\n  if (buf_size == 0) {\n\n    if (s->next_picture_ptr && !s->low_delay) {\n\n      *(AVFrame *) data = *(AVFrame *) &s->next_picture;\n\n      *data_size = sizeof(AVFrame);\n\n    }\n\n    return 0;\n\n  }\n\n\n\n  init_get_bits (&s->gb, buf, 8*buf_size);\n\n\n\n  s->mb_x = s->mb_y = 0;\n\n\n\n  if (svq3_decode_slice_header (h))\n\n    return -1;\n\n\n\n  s->pict_type = h->slice_type;\n\n  s->picture_number = h->slice_num;\n\n\n\n  if(avctx->debug&FF_DEBUG_PICT_INFO){\n\n      av_log(h->s.avctx, AV_LOG_DEBUG, \"%c hpel:%d, tpel:%d aqp:%d qp:%d\\n\",\n\n      av_get_pict_type_char(s->pict_type), h->halfpel_flag, h->thirdpel_flag,\n\n      s->adaptive_quant, s->qscale\n\n      );\n\n  }\n\n\n\n  /* for hurry_up==5 */\n\n  s->current_picture.pict_type = s->pict_type;\n\n  s->current_picture.key_frame = (s->pict_type == I_TYPE);\n\n\n\n  /* skip b frames if we dont have reference frames */\n\n  if (s->last_picture_ptr == NULL && s->pict_type == B_TYPE) return 0;\n\n  /* skip b frames if we are in a hurry */\n\n  if (avctx->hurry_up && s->pict_type == B_TYPE) return 0;\n\n  /* skip everything if we are in a hurry >= 5 */\n\n  if (avctx->hurry_up >= 5) return 0;\n\n  if(  (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type==B_TYPE)\n\n     ||(avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type!=I_TYPE)\n\n     || avctx->skip_frame >= AVDISCARD_ALL)\n\n      return 0;\n\n\n\n  if (s->next_p_frame_damaged) {\n\n    if (s->pict_type == B_TYPE)\n\n      return 0;\n\n    else\n\n      s->next_p_frame_damaged = 0;\n\n  }\n\n\n\n  frame_start (h);\n\n\n\n  if (s->pict_type == B_TYPE) {\n\n    h->frame_num_offset = (h->slice_num - h->prev_frame_num);\n\n\n\n    if (h->frame_num_offset < 0) {\n\n      h->frame_num_offset += 256;\n\n    }\n\n    if (h->frame_num_offset == 0 || h->frame_num_offset >= h->prev_frame_num_offset) {\n\n      av_log(h->s.avctx, AV_LOG_ERROR, \"error in B-frame picture id\\n\");\n\n      return -1;\n\n    }\n\n  } else {\n\n    h->prev_frame_num = h->frame_num;\n\n    h->frame_num = h->slice_num;\n\n    h->prev_frame_num_offset = (h->frame_num - h->prev_frame_num);\n\n\n\n    if (h->prev_frame_num_offset < 0) {\n\n      h->prev_frame_num_offset += 256;\n\n    }\n\n  }\n\n\n\n  for(m=0; m<2; m++){\n\n    int i;\n\n    for(i=0; i<4; i++){\n\n      int j;\n\n      for(j=-1; j<4; j++)\n\n        h->ref_cache[m][scan8[0] + 8*i + j]= 1;\n\n      h->ref_cache[m][scan8[0] + 8*i + j]= PART_NOT_AVAILABLE;\n\n    }\n\n  }\n\n\n\n  for (s->mb_y=0; s->mb_y < s->mb_height; s->mb_y++) {\n\n    for (s->mb_x=0; s->mb_x < s->mb_width; s->mb_x++) {\n\n\n\n      if ( (get_bits_count(&s->gb) + 7) >= s->gb.size_in_bits &&\n\n          ((get_bits_count(&s->gb) & 7) == 0 || show_bits (&s->gb, (-get_bits_count(&s->gb) & 7)) == 0)) {\n\n\n\n        skip_bits(&s->gb, h->next_slice_index - get_bits_count(&s->gb));\n\n        s->gb.size_in_bits = 8*buf_size;\n\n\n\n        if (svq3_decode_slice_header (h))\n\n          return -1;\n\n\n\n        /* TODO: support s->mb_skip_run */\n\n      }\n\n\n\n      mb_type = svq3_get_ue_golomb (&s->gb);\n\n\n\n      if (s->pict_type == I_TYPE) {\n\n        mb_type += 8;\n\n      } else if (s->pict_type == B_TYPE && mb_type >= 4) {\n\n        mb_type += 4;\n\n      }\n\n      if (mb_type > 33 || svq3_decode_mb (h, mb_type)) {\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"error while decoding MB %d %d\\n\", s->mb_x, s->mb_y);\n\n        return -1;\n\n      }\n\n\n\n      if (mb_type != 0) {\n\n        hl_decode_mb (h);\n\n      }\n\n\n\n      if (s->pict_type != B_TYPE && !s->low_delay) {\n\n        s->current_picture.mb_type[s->mb_x + s->mb_y*s->mb_stride] =\n\n                        (s->pict_type == P_TYPE && mb_type < 8) ? (mb_type - 1) : -1;\n\n      }\n\n    }\n\n\n\n    ff_draw_horiz_band(s, 16*s->mb_y, 16);\n\n  }\n\n\n\n  MPV_frame_end(s);\n\n\n\n  if (s->pict_type == B_TYPE || s->low_delay) {\n\n    *(AVFrame *) data = *(AVFrame *) &s->current_picture;\n\n  } else {\n\n    *(AVFrame *) data = *(AVFrame *) &s->last_picture;\n\n  }\n\n\n\n  avctx->frame_number = s->picture_number - 1;\n\n\n\n  /* dont output the last pic after seeking */\n\n  if (s->last_picture_ptr || s->low_delay) {\n\n    *data_size = sizeof(AVFrame);\n\n  }\n\n\n\n  return buf_size;\n\n}\n", "idx": 24419}
{"project": "FFmpeg", "commit_id": "90901860c21468d6e9ae437c2bacb099c7bd3acf", "target": 0, "func": "static int vorbis_parse_id_hdr(vorbis_context *vc){\n\n    GetBitContext *gb=&vc->gb;\n\n    uint_fast8_t bl0, bl1;\n\n\n\n    if ((get_bits(gb, 8)!='v') || (get_bits(gb, 8)!='o') ||\n\n    (get_bits(gb, 8)!='r') || (get_bits(gb, 8)!='b') ||\n\n    (get_bits(gb, 8)!='i') || (get_bits(gb, 8)!='s')) {\n\n        av_log(vc->avccontext, AV_LOG_ERROR, \" Vorbis id header packet corrupt (no vorbis signature). \\n\");\n\n        return 1;\n\n    }\n\n\n\n    vc->version=get_bits_long(gb, 32);    //FIXME check 0\n\n    vc->audio_channels=get_bits(gb, 8);   //FIXME check >0\n\n    vc->audio_samplerate=get_bits_long(gb, 32);   //FIXME check >0\n\n    vc->bitrate_maximum=get_bits_long(gb, 32);\n\n    vc->bitrate_nominal=get_bits_long(gb, 32);\n\n    vc->bitrate_minimum=get_bits_long(gb, 32);\n\n    bl0=get_bits(gb, 4);\n\n    bl1=get_bits(gb, 4);\n\n    vc->blocksize[0]=(1<<bl0);\n\n    vc->blocksize[1]=(1<<bl1);\n\n    if (bl0>13 || bl0<6 || bl1>13 || bl1<6 || bl1<bl0) {\n\n        av_log(vc->avccontext, AV_LOG_ERROR, \" Vorbis id header packet corrupt (illegal blocksize). \\n\");\n\n        return 3;\n\n    }\n\n    // output format int16\n\n    if (vc->blocksize[1]/2 * vc->audio_channels * 2 >\n\n                                             AVCODEC_MAX_AUDIO_FRAME_SIZE) {\n\n        av_log(vc->avccontext, AV_LOG_ERROR, \"Vorbis channel count makes \"\n\n               \"output packets too large.\\n\");\n\n        return 4;\n\n    }\n\n    vc->win[0]=ff_vorbis_vwin[bl0-6];\n\n    vc->win[1]=ff_vorbis_vwin[bl1-6];\n\n\n\n    if(vc->exp_bias){\n\n        int i, j;\n\n        for(j=0; j<2; j++){\n\n            float *win = av_malloc(vc->blocksize[j]/2 * sizeof(float));\n\n            for(i=0; i<vc->blocksize[j]/2; i++)\n\n                win[i] = vc->win[j][i] * (1<<15);\n\n            vc->win[j] = win;\n\n        }\n\n    }\n\n\n\n    if ((get_bits1(gb)) == 0) {\n\n        av_log(vc->avccontext, AV_LOG_ERROR, \" Vorbis id header packet corrupt (framing flag not set). \\n\");\n\n        return 2;\n\n    }\n\n\n\n    vc->channel_residues=(float *)av_malloc((vc->blocksize[1]/2)*vc->audio_channels * sizeof(float));\n\n    vc->channel_floors=(float *)av_malloc((vc->blocksize[1]/2)*vc->audio_channels * sizeof(float));\n\n    vc->saved=(float *)av_malloc((vc->blocksize[1]/2)*vc->audio_channels * sizeof(float));\n\n    vc->ret=(float *)av_malloc((vc->blocksize[1]/2)*vc->audio_channels * sizeof(float));\n\n    vc->buf=(float *)av_malloc(vc->blocksize[1] * sizeof(float));\n\n    vc->buf_tmp=(float *)av_malloc(vc->blocksize[1] * sizeof(float));\n\n    vc->saved_start=0;\n\n\n\n    ff_mdct_init(&vc->mdct[0], bl0, 1);\n\n    ff_mdct_init(&vc->mdct[1], bl1, 1);\n\n\n\n    AV_DEBUG(\" vorbis version %d \\n audio_channels %d \\n audio_samplerate %d \\n bitrate_max %d \\n bitrate_nom %d \\n bitrate_min %d \\n blk_0 %d blk_1 %d \\n \",\n\n            vc->version, vc->audio_channels, vc->audio_samplerate, vc->bitrate_maximum, vc->bitrate_nominal, vc->bitrate_minimum, vc->blocksize[0], vc->blocksize[1]);\n\n\n\n/*\n\n    BLK=vc->blocksize[0];\n\n    for(i=0;i<BLK/2;++i) {\n\n        vc->win[0][i]=sin(0.5*3.14159265358*(sin(((float)i+0.5)/(float)BLK*3.14159265358))*(sin(((float)i+0.5)/(float)BLK*3.14159265358)));\n\n    }\n\n*/\n\n\n\n    return 0;\n\n}\n", "idx": 24421}
{"project": "FFmpeg", "commit_id": "7167bc94cb695a3027aea6aac34a1b040848c7dc", "target": 1, "func": "static void imdct_and_windowing(AACContext *ac, SingleChannelElement *sce, float bias)\n\n{\n\n    IndividualChannelStream *ics = &sce->ics;\n\n    float *in    = sce->coeffs;\n\n    float *out   = sce->ret;\n\n    float *saved = sce->saved;\n\n    const float *swindow      = ics->use_kb_window[0] ? ff_aac_kbd_short_128 : ff_sine_128;\n\n    const float *lwindow_prev = ics->use_kb_window[1] ? ff_aac_kbd_long_1024 : ff_sine_1024;\n\n    const float *swindow_prev = ics->use_kb_window[1] ? ff_aac_kbd_short_128 : ff_sine_128;\n\n    float *buf  = ac->buf_mdct;\n\n    float *temp = ac->temp;\n\n    int i;\n\n\n\n    // imdct\n\n    if (ics->window_sequence[0] == EIGHT_SHORT_SEQUENCE) {\n\n        if (ics->window_sequence[1] == ONLY_LONG_SEQUENCE || ics->window_sequence[1] == LONG_STOP_SEQUENCE)\n\n            av_log(ac->avctx, AV_LOG_WARNING,\n\n                   \"Transition from an ONLY_LONG or LONG_STOP to an EIGHT_SHORT sequence detected. \"\n\n                   \"If you heard an audible artifact, please submit the sample to the FFmpeg developers.\\n\");\n\n        for (i = 0; i < 1024; i += 128)\n\n            ff_imdct_half(&ac->mdct_small, buf + i, in + i);\n\n    } else\n\n        ff_imdct_half(&ac->mdct, buf, in);\n\n\n\n    /* window overlapping\n\n     * NOTE: To simplify the overlapping code, all 'meaningless' short to long\n\n     * and long to short transitions are considered to be short to short\n\n     * transitions. This leaves just two cases (long to long and short to short)\n\n     * with a little special sauce for EIGHT_SHORT_SEQUENCE.\n\n     */\n\n    if ((ics->window_sequence[1] == ONLY_LONG_SEQUENCE || ics->window_sequence[1] == LONG_STOP_SEQUENCE) &&\n\n            (ics->window_sequence[0] == ONLY_LONG_SEQUENCE || ics->window_sequence[0] == LONG_START_SEQUENCE)) {\n\n        ac->dsp.vector_fmul_window(    out,               saved,            buf,         lwindow_prev, bias, 512);\n\n    } else {\n\n        for (i = 0; i < 448; i++)\n\n            out[i] = saved[i] + bias;\n\n\n\n        if (ics->window_sequence[0] == EIGHT_SHORT_SEQUENCE) {\n\n            ac->dsp.vector_fmul_window(out + 448 + 0*128, saved + 448,      buf + 0*128, swindow_prev, bias, 64);\n\n            ac->dsp.vector_fmul_window(out + 448 + 1*128, buf + 0*128 + 64, buf + 1*128, swindow,      bias, 64);\n\n            ac->dsp.vector_fmul_window(out + 448 + 2*128, buf + 1*128 + 64, buf + 2*128, swindow,      bias, 64);\n\n            ac->dsp.vector_fmul_window(out + 448 + 3*128, buf + 2*128 + 64, buf + 3*128, swindow,      bias, 64);\n\n            ac->dsp.vector_fmul_window(temp,              buf + 3*128 + 64, buf + 4*128, swindow,      bias, 64);\n\n            memcpy(                    out + 448 + 4*128, temp, 64 * sizeof(float));\n\n        } else {\n\n            ac->dsp.vector_fmul_window(out + 448,         saved + 448,      buf,         swindow_prev, bias, 64);\n\n            for (i = 576; i < 1024; i++)\n\n                out[i] = buf[i-512] + bias;\n\n        }\n\n    }\n\n\n\n    // buffer update\n\n    if (ics->window_sequence[0] == EIGHT_SHORT_SEQUENCE) {\n\n        for (i = 0; i < 64; i++)\n\n            saved[i] = temp[64 + i] - bias;\n\n        ac->dsp.vector_fmul_window(saved + 64,  buf + 4*128 + 64, buf + 5*128, swindow, 0, 64);\n\n        ac->dsp.vector_fmul_window(saved + 192, buf + 5*128 + 64, buf + 6*128, swindow, 0, 64);\n\n        ac->dsp.vector_fmul_window(saved + 320, buf + 6*128 + 64, buf + 7*128, swindow, 0, 64);\n\n        memcpy(                    saved + 448, buf + 7*128 + 64,  64 * sizeof(float));\n\n    } else if (ics->window_sequence[0] == LONG_START_SEQUENCE) {\n\n        memcpy(                    saved,       buf + 512,        448 * sizeof(float));\n\n        memcpy(                    saved + 448, buf + 7*128 + 64,  64 * sizeof(float));\n\n    } else { // LONG_STOP or ONLY_LONG\n\n        memcpy(                    saved,       buf + 512,        512 * sizeof(float));\n\n    }\n\n}\n", "idx": 24424}
{"project": "FFmpeg", "commit_id": "70d54392f5015b9c6594fcae558f59f952501e3b", "target": 0, "func": "void ff_dsputil_init_alpha(DSPContext* c, AVCodecContext *avctx)\n\n{\n\n    const int high_bit_depth = avctx->bits_per_raw_sample > 8;\n\n\n\n    if (!high_bit_depth) {\n\n    c->put_pixels_tab[0][0] = put_pixels16_axp_asm;\n\n    c->put_pixels_tab[0][1] = put_pixels16_x2_axp;\n\n    c->put_pixels_tab[0][2] = put_pixels16_y2_axp;\n\n    c->put_pixels_tab[0][3] = put_pixels16_xy2_axp;\n\n\n\n    c->put_no_rnd_pixels_tab[0][0] = put_pixels16_axp_asm;\n\n    c->put_no_rnd_pixels_tab[0][1] = put_no_rnd_pixels16_x2_axp;\n\n    c->put_no_rnd_pixels_tab[0][2] = put_no_rnd_pixels16_y2_axp;\n\n    c->put_no_rnd_pixels_tab[0][3] = put_no_rnd_pixels16_xy2_axp;\n\n\n\n    c->avg_pixels_tab[0][0] = avg_pixels16_axp;\n\n    c->avg_pixels_tab[0][1] = avg_pixels16_x2_axp;\n\n    c->avg_pixels_tab[0][2] = avg_pixels16_y2_axp;\n\n    c->avg_pixels_tab[0][3] = avg_pixels16_xy2_axp;\n\n\n\n    c->avg_no_rnd_pixels_tab[0][0] = avg_no_rnd_pixels16_axp;\n\n    c->avg_no_rnd_pixels_tab[0][1] = avg_no_rnd_pixels16_x2_axp;\n\n    c->avg_no_rnd_pixels_tab[0][2] = avg_no_rnd_pixels16_y2_axp;\n\n    c->avg_no_rnd_pixels_tab[0][3] = avg_no_rnd_pixels16_xy2_axp;\n\n\n\n    c->put_pixels_tab[1][0] = put_pixels_axp_asm;\n\n    c->put_pixels_tab[1][1] = put_pixels_x2_axp;\n\n    c->put_pixels_tab[1][2] = put_pixels_y2_axp;\n\n    c->put_pixels_tab[1][3] = put_pixels_xy2_axp;\n\n\n\n    c->put_no_rnd_pixels_tab[1][0] = put_pixels_axp_asm;\n\n    c->put_no_rnd_pixels_tab[1][1] = put_no_rnd_pixels_x2_axp;\n\n    c->put_no_rnd_pixels_tab[1][2] = put_no_rnd_pixels_y2_axp;\n\n    c->put_no_rnd_pixels_tab[1][3] = put_no_rnd_pixels_xy2_axp;\n\n\n\n    c->avg_pixels_tab[1][0] = avg_pixels_axp;\n\n    c->avg_pixels_tab[1][1] = avg_pixels_x2_axp;\n\n    c->avg_pixels_tab[1][2] = avg_pixels_y2_axp;\n\n    c->avg_pixels_tab[1][3] = avg_pixels_xy2_axp;\n\n\n\n    c->avg_no_rnd_pixels_tab[1][0] = avg_no_rnd_pixels_axp;\n\n    c->avg_no_rnd_pixels_tab[1][1] = avg_no_rnd_pixels_x2_axp;\n\n    c->avg_no_rnd_pixels_tab[1][2] = avg_no_rnd_pixels_y2_axp;\n\n    c->avg_no_rnd_pixels_tab[1][3] = avg_no_rnd_pixels_xy2_axp;\n\n\n\n    c->clear_blocks = clear_blocks_axp;\n\n    }\n\n\n\n    /* amask clears all bits that correspond to present features.  */\n\n    if (amask(AMASK_MVI) == 0) {\n\n        c->put_pixels_clamped = put_pixels_clamped_mvi_asm;\n\n        c->add_pixels_clamped = add_pixels_clamped_mvi_asm;\n\n\n\n        if (!high_bit_depth)\n\n            c->get_pixels   = get_pixels_mvi;\n\n        c->diff_pixels      = diff_pixels_mvi;\n\n        c->sad[0]           = pix_abs16x16_mvi_asm;\n\n        c->sad[1]           = pix_abs8x8_mvi;\n\n        c->pix_abs[0][0]    = pix_abs16x16_mvi_asm;\n\n        c->pix_abs[1][0]    = pix_abs8x8_mvi;\n\n        c->pix_abs[0][1]    = pix_abs16x16_x2_mvi;\n\n        c->pix_abs[0][2]    = pix_abs16x16_y2_mvi;\n\n        c->pix_abs[0][3]    = pix_abs16x16_xy2_mvi;\n\n    }\n\n\n\n    put_pixels_clamped_axp_p = c->put_pixels_clamped;\n\n    add_pixels_clamped_axp_p = c->add_pixels_clamped;\n\n\n\n    if (avctx->bits_per_raw_sample <= 8 &&\n\n        (avctx->idct_algo == FF_IDCT_AUTO ||\n\n         avctx->idct_algo == FF_IDCT_SIMPLEALPHA)) {\n\n        c->idct_put = ff_simple_idct_put_axp;\n\n        c->idct_add = ff_simple_idct_add_axp;\n\n        c->idct =     ff_simple_idct_axp;\n\n    }\n\n}\n", "idx": 24426}
{"project": "FFmpeg", "commit_id": "b16830840eb9bdec88fce2aebb38a582e093ab6b", "target": 0, "func": "static int add_string_metadata(int count, const char *name,\n\n                               TiffContext *s)\n\n{\n\n    char *value;\n\n\n\n    if (bytestream2_get_bytes_left(&s->gb) < count)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    value = av_malloc(count + 1);\n\n    if (!value)\n\n        return AVERROR(ENOMEM);\n\n\n\n    bytestream2_get_bufferu(&s->gb, value, count);\n\n    value[count] = 0;\n\n\n\n    av_dict_set(&s->picture.metadata, name, value, AV_DICT_DONT_STRDUP_VAL);\n\n    return 0;\n\n}\n", "idx": 24427}
{"project": "FFmpeg", "commit_id": "16e0416fa47ca391214ad20d162240e5d492bf0e", "target": 0, "func": "static int idcin_read_header(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    IdcinDemuxContext *idcin = s->priv_data;\n\n    AVStream *st;\n\n    unsigned int width, height;\n\n    unsigned int sample_rate, bytes_per_sample, channels;\n\n    int ret;\n\n\n\n    /* get the 5 header parameters */\n\n    width = avio_rl32(pb);\n\n    height = avio_rl32(pb);\n\n    sample_rate = avio_rl32(pb);\n\n    bytes_per_sample = avio_rl32(pb);\n\n    channels = avio_rl32(pb);\n\n\n\n    if (s->pb->eof_reached) {\n\n        av_log(s, AV_LOG_ERROR, \"incomplete header\\n\");\n\n        return s->pb->error ? s->pb->error : AVERROR_EOF;\n\n    }\n\n\n\n    if (av_image_check_size(width, height, 0, s) < 0)\n\n        return AVERROR_INVALIDDATA;\n\n    if (sample_rate > 0) {\n\n        if (sample_rate < 14 || sample_rate > INT_MAX) {\n\n            av_log(s, AV_LOG_ERROR, \"invalid sample rate: %u\\n\", sample_rate);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (bytes_per_sample < 1 || bytes_per_sample > 2) {\n\n            av_log(s, AV_LOG_ERROR, \"invalid bytes per sample: %u\\n\",\n\n                   bytes_per_sample);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (channels < 1 || channels > 2) {\n\n            av_log(s, AV_LOG_ERROR, \"invalid channels: %u\\n\", channels);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        idcin->audio_present = 1;\n\n    } else {\n\n        /* if sample rate is 0, assume no audio */\n\n        idcin->audio_present = 0;\n\n    }\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n    avpriv_set_pts_info(st, 33, 1, IDCIN_FPS);\n\n    st->start_time = 0;\n\n    idcin->video_stream_index = st->index;\n\n    st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id = AV_CODEC_ID_IDCIN;\n\n    st->codec->codec_tag = 0;  /* no fourcc */\n\n    st->codec->width = width;\n\n    st->codec->height = height;\n\n\n\n    /* load up the Huffman tables into extradata */\n\n    st->codec->extradata_size = HUFFMAN_TABLE_SIZE;\n\n    st->codec->extradata = av_malloc(HUFFMAN_TABLE_SIZE);\n\n    ret = avio_read(pb, st->codec->extradata, HUFFMAN_TABLE_SIZE);\n\n    if (ret < 0) {\n\n        return ret;\n\n    } else if (ret != HUFFMAN_TABLE_SIZE) {\n\n        av_log(s, AV_LOG_ERROR, \"incomplete header\\n\");\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    if (idcin->audio_present) {\n\n        idcin->audio_present = 1;\n\n        st = avformat_new_stream(s, NULL);\n\n        if (!st)\n\n            return AVERROR(ENOMEM);\n\n        avpriv_set_pts_info(st, 63, 1, sample_rate);\n\n        st->start_time = 0;\n\n        idcin->audio_stream_index = st->index;\n\n        st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n        st->codec->codec_tag = 1;\n\n        st->codec->channels = channels;\n\n        st->codec->channel_layout = channels > 1 ? AV_CH_LAYOUT_STEREO :\n\n                                                   AV_CH_LAYOUT_MONO;\n\n        st->codec->sample_rate = sample_rate;\n\n        st->codec->bits_per_coded_sample = bytes_per_sample * 8;\n\n        st->codec->bit_rate = sample_rate * bytes_per_sample * 8 * channels;\n\n        st->codec->block_align = idcin->block_align = bytes_per_sample * channels;\n\n        if (bytes_per_sample == 1)\n\n            st->codec->codec_id = AV_CODEC_ID_PCM_U8;\n\n        else\n\n            st->codec->codec_id = AV_CODEC_ID_PCM_S16LE;\n\n\n\n        if (sample_rate % 14 != 0) {\n\n            idcin->audio_chunk_size1 = (sample_rate / 14) *\n\n            bytes_per_sample * channels;\n\n            idcin->audio_chunk_size2 = (sample_rate / 14 + 1) *\n\n                bytes_per_sample * channels;\n\n        } else {\n\n            idcin->audio_chunk_size1 = idcin->audio_chunk_size2 =\n\n                (sample_rate / 14) * bytes_per_sample * channels;\n\n        }\n\n        idcin->current_audio_chunk = 0;\n\n    }\n\n\n\n    idcin->next_chunk_is_video = 1;\n\n    idcin->first_pkt_pos = avio_tell(s->pb);\n\n\n\n    return 0;\n\n}\n", "idx": 24428}
{"project": "FFmpeg", "commit_id": "f85cc3bf12236e974403667610b39b802b8651d6", "target": 0, "func": "static int decode_profile_tier_level(GetBitContext *gb, AVCodecContext *avctx,\n\n                                      PTLCommon *ptl)\n\n{\n\n    int i;\n\n\n\n    if (get_bits_left(gb) < 2+1+5 + 32 + 4 + 16 + 16 + 12)\n\n        return -1;\n\n\n\n    ptl->profile_space = get_bits(gb, 2);\n\n    ptl->tier_flag     = get_bits1(gb);\n\n    ptl->profile_idc   = get_bits(gb, 5);\n\n    if (ptl->profile_idc == FF_PROFILE_HEVC_MAIN)\n\n        av_log(avctx, AV_LOG_DEBUG, \"Main profile bitstream\\n\");\n\n    else if (ptl->profile_idc == FF_PROFILE_HEVC_MAIN_10)\n\n        av_log(avctx, AV_LOG_DEBUG, \"Main 10 profile bitstream\\n\");\n\n    else if (ptl->profile_idc == FF_PROFILE_HEVC_MAIN_STILL_PICTURE)\n\n        av_log(avctx, AV_LOG_DEBUG, \"Main Still Picture profile bitstream\\n\");\n\n    else if (ptl->profile_idc == FF_PROFILE_HEVC_REXT)\n\n        av_log(avctx, AV_LOG_DEBUG, \"Range Extension profile bitstream\\n\");\n\n    else\n\n        av_log(avctx, AV_LOG_WARNING, \"Unknown HEVC profile: %d\\n\", ptl->profile_idc);\n\n\n\n    for (i = 0; i < 32; i++)\n\n        ptl->profile_compatibility_flag[i] = get_bits1(gb);\n\n    ptl->progressive_source_flag    = get_bits1(gb);\n\n    ptl->interlaced_source_flag     = get_bits1(gb);\n\n    ptl->non_packed_constraint_flag = get_bits1(gb);\n\n    ptl->frame_only_constraint_flag = get_bits1(gb);\n\n\n\n    skip_bits(gb, 16); // XXX_reserved_zero_44bits[0..15]\n\n    skip_bits(gb, 16); // XXX_reserved_zero_44bits[16..31]\n\n    skip_bits(gb, 12); // XXX_reserved_zero_44bits[32..43]\n\n\n\n    return 0;\n\n}\n", "idx": 24429}
{"project": "FFmpeg", "commit_id": "d1b284119bd5c6a52124443de2c45dbe569c25fc", "target": 0, "func": "static int filter_frame(AVFilterLink *link, AVFrame *frame)\n\n{\n\n    AVFilterContext *ctx = link->dst;\n\n    AudioFIRContext *s = ctx->priv;\n\n    AVFilterLink *outlink = ctx->outputs[0];\n\n    int ret = 0;\n\n\n\n    av_audio_fifo_write(s->fifo[0], (void **)frame->extended_data,\n\n                        frame->nb_samples);\n\n    if (s->pts == AV_NOPTS_VALUE)\n\n        s->pts = frame->pts;\n\n\n\n    av_frame_free(&frame);\n\n\n\n    if (!s->have_coeffs && s->eof_coeffs) {\n\n        ret = convert_coeffs(ctx);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    if (s->have_coeffs) {\n\n        while (av_audio_fifo_size(s->fifo[0]) >= s->part_size) {\n\n            ret = fir_frame(s, outlink);\n\n            if (ret < 0)\n\n                break;\n\n        }\n\n    }\n\n    return ret;\n\n}\n", "idx": 24430}
{"project": "FFmpeg", "commit_id": "27506aceda8115f82f89691a4441d62a8cf24a6e", "target": 0, "func": "int ff_dca_lbr_parse(DCALbrDecoder *s, uint8_t *data, DCAExssAsset *asset)\n\n{\n\n    struct {\n\n        LBRChunk    lfe;\n\n        LBRChunk    tonal;\n\n        LBRChunk    tonal_grp[5];\n\n        LBRChunk    grid1[DCA_LBR_CHANNELS / 2];\n\n        LBRChunk    hr_grid[DCA_LBR_CHANNELS / 2];\n\n        LBRChunk    ts1[DCA_LBR_CHANNELS / 2];\n\n        LBRChunk    ts2[DCA_LBR_CHANNELS / 2];\n\n    } chunk = { };\n\n\n\n    GetByteContext gb;\n\n\n\n    int i, ch, sb, sf, ret, group, chunk_id, chunk_len;\n\n\n\n    bytestream2_init(&gb, data + asset->lbr_offset, asset->lbr_size);\n\n\n\n    // LBR sync word\n\n    if (bytestream2_get_be32(&gb) != DCA_SYNCWORD_LBR) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid LBR sync word\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    // LBR header type\n\n    switch (bytestream2_get_byte(&gb)) {\n\n    case LBR_HEADER_SYNC_ONLY:\n\n        if (!s->sample_rate) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"LBR decoder not initialized\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        break;\n\n    case LBR_HEADER_DECODER_INIT:\n\n        if ((ret = parse_decoder_init(s, &gb)) < 0) {\n\n            s->sample_rate = 0;\n\n            return ret;\n\n        }\n\n        break;\n\n    default:\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid LBR header type\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    // LBR frame chunk header\n\n    chunk_id = bytestream2_get_byte(&gb);\n\n    chunk_len = (chunk_id & 0x80) ? bytestream2_get_be16(&gb) : bytestream2_get_byte(&gb);\n\n\n\n    if (chunk_len > bytestream2_get_bytes_left(&gb)) {\n\n        chunk_len = bytestream2_get_bytes_left(&gb);\n\n        av_log(s->avctx, AV_LOG_WARNING, \"LBR frame chunk was truncated\\n\");\n\n        if (s->avctx->err_recognition & AV_EF_EXPLODE)\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    bytestream2_init(&gb, gb.buffer, chunk_len);\n\n\n\n    switch (chunk_id & 0x7f) {\n\n    case LBR_CHUNK_FRAME:\n\n        if (s->avctx->err_recognition & (AV_EF_CRCCHECK | AV_EF_CAREFUL)) {\n\n            int checksum = bytestream2_get_be16(&gb);\n\n            uint16_t res = chunk_id;\n\n            res += (chunk_len >> 8) & 0xff;\n\n            res += chunk_len & 0xff;\n\n            for (i = 0; i < chunk_len - 2; i++)\n\n                res += gb.buffer[i];\n\n            if (checksum != res) {\n\n                av_log(s->avctx, AV_LOG_WARNING, \"Invalid LBR checksum\\n\");\n\n                if (s->avctx->err_recognition & AV_EF_EXPLODE)\n\n                    return AVERROR_INVALIDDATA;\n\n            }\n\n        } else {\n\n            bytestream2_skip(&gb, 2);\n\n        }\n\n        break;\n\n    case LBR_CHUNK_FRAME_NO_CSUM:\n\n        break;\n\n    default:\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid LBR frame chunk ID\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    // Clear current frame\n\n    memset(s->quant_levels, 0, sizeof(s->quant_levels));\n\n    memset(s->sb_indices, 0xff, sizeof(s->sb_indices));\n\n    memset(s->sec_ch_sbms, 0, sizeof(s->sec_ch_sbms));\n\n    memset(s->sec_ch_lrms, 0, sizeof(s->sec_ch_lrms));\n\n    memset(s->ch_pres, 0, sizeof(s->ch_pres));\n\n    memset(s->grid_1_scf, 0, sizeof(s->grid_1_scf));\n\n    memset(s->grid_2_scf, 0, sizeof(s->grid_2_scf));\n\n    memset(s->grid_3_avg, 0, sizeof(s->grid_3_avg));\n\n    memset(s->grid_3_scf, 0, sizeof(s->grid_3_scf));\n\n    memset(s->grid_3_pres, 0, sizeof(s->grid_3_pres));\n\n    memset(s->tonal_scf, 0, sizeof(s->tonal_scf));\n\n    memset(s->lfe_data, 0, sizeof(s->lfe_data));\n\n    s->part_stereo_pres = 0;\n\n    s->framenum = (s->framenum + 1) & 31;\n\n\n\n    for (ch = 0; ch < s->nchannels; ch++) {\n\n        for (sb = 0; sb < s->nsubbands / 4; sb++) {\n\n            s->part_stereo[ch][sb][0] = s->part_stereo[ch][sb][4];\n\n            s->part_stereo[ch][sb][4] = 16;\n\n        }\n\n    }\n\n\n\n    memset(s->lpc_coeff[s->framenum & 1], 0, sizeof(s->lpc_coeff[0]));\n\n\n\n    for (group = 0; group < 5; group++) {\n\n        for (sf = 0; sf < 1 << group; sf++) {\n\n            int sf_idx = ((s->framenum << group) + sf) & 31;\n\n            s->tonal_bounds[group][sf_idx][0] =\n\n            s->tonal_bounds[group][sf_idx][1] = s->ntones;\n\n        }\n\n    }\n\n\n\n    // Parse chunk headers\n\n    while (bytestream2_get_bytes_left(&gb) > 0) {\n\n        chunk_id = bytestream2_get_byte(&gb);\n\n        chunk_len = (chunk_id & 0x80) ? bytestream2_get_be16(&gb) : bytestream2_get_byte(&gb);\n\n        chunk_id &= 0x7f;\n\n\n\n        if (chunk_len > bytestream2_get_bytes_left(&gb)) {\n\n            chunk_len = bytestream2_get_bytes_left(&gb);\n\n            av_log(s->avctx, AV_LOG_WARNING, \"LBR chunk %#x was truncated\\n\", chunk_id);\n\n            if (s->avctx->err_recognition & AV_EF_EXPLODE)\n\n                return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        switch (chunk_id) {\n\n        case LBR_CHUNK_LFE:\n\n            chunk.lfe.len  = chunk_len;\n\n            chunk.lfe.data = gb.buffer;\n\n            break;\n\n\n\n        case LBR_CHUNK_SCF:\n\n        case LBR_CHUNK_TONAL:\n\n        case LBR_CHUNK_TONAL_SCF:\n\n            chunk.tonal.id   = chunk_id;\n\n            chunk.tonal.len  = chunk_len;\n\n            chunk.tonal.data = gb.buffer;\n\n            break;\n\n\n\n        case LBR_CHUNK_TONAL_GRP_1:\n\n        case LBR_CHUNK_TONAL_GRP_2:\n\n        case LBR_CHUNK_TONAL_GRP_3:\n\n        case LBR_CHUNK_TONAL_GRP_4:\n\n        case LBR_CHUNK_TONAL_GRP_5:\n\n            i = LBR_CHUNK_TONAL_GRP_5 - chunk_id;\n\n            chunk.tonal_grp[i].id   = i;\n\n            chunk.tonal_grp[i].len  = chunk_len;\n\n            chunk.tonal_grp[i].data = gb.buffer;\n\n            break;\n\n\n\n        case LBR_CHUNK_TONAL_SCF_GRP_1:\n\n        case LBR_CHUNK_TONAL_SCF_GRP_2:\n\n        case LBR_CHUNK_TONAL_SCF_GRP_3:\n\n        case LBR_CHUNK_TONAL_SCF_GRP_4:\n\n        case LBR_CHUNK_TONAL_SCF_GRP_5:\n\n            i = LBR_CHUNK_TONAL_SCF_GRP_5 - chunk_id;\n\n            chunk.tonal_grp[i].id   = i;\n\n            chunk.tonal_grp[i].len  = chunk_len;\n\n            chunk.tonal_grp[i].data = gb.buffer;\n\n            break;\n\n\n\n        case LBR_CHUNK_RES_GRID_LR:\n\n        case LBR_CHUNK_RES_GRID_LR + 1:\n\n        case LBR_CHUNK_RES_GRID_LR + 2:\n\n            i = chunk_id - LBR_CHUNK_RES_GRID_LR;\n\n            chunk.grid1[i].len  = chunk_len;\n\n            chunk.grid1[i].data = gb.buffer;\n\n            break;\n\n\n\n        case LBR_CHUNK_RES_GRID_HR:\n\n        case LBR_CHUNK_RES_GRID_HR + 1:\n\n        case LBR_CHUNK_RES_GRID_HR + 2:\n\n            i = chunk_id - LBR_CHUNK_RES_GRID_HR;\n\n            chunk.hr_grid[i].len  = chunk_len;\n\n            chunk.hr_grid[i].data = gb.buffer;\n\n            break;\n\n\n\n        case LBR_CHUNK_RES_TS_1:\n\n        case LBR_CHUNK_RES_TS_1 + 1:\n\n        case LBR_CHUNK_RES_TS_1 + 2:\n\n            i = chunk_id - LBR_CHUNK_RES_TS_1;\n\n            chunk.ts1[i].len  = chunk_len;\n\n            chunk.ts1[i].data = gb.buffer;\n\n            break;\n\n\n\n        case LBR_CHUNK_RES_TS_2:\n\n        case LBR_CHUNK_RES_TS_2 + 1:\n\n        case LBR_CHUNK_RES_TS_2 + 2:\n\n            i = chunk_id - LBR_CHUNK_RES_TS_2;\n\n            chunk.ts2[i].len  = chunk_len;\n\n            chunk.ts2[i].data = gb.buffer;\n\n            break;\n\n        }\n\n\n\n        bytestream2_skip(&gb, chunk_len);\n\n    }\n\n\n\n    // Parse the chunks\n\n    ret = parse_lfe_chunk(s, &chunk.lfe);\n\n\n\n    ret |= parse_tonal_chunk(s, &chunk.tonal);\n\n\n\n    for (i = 0; i < 5; i++)\n\n        ret |= parse_tonal_group(s, &chunk.tonal_grp[i]);\n\n\n\n    for (i = 0; i < (s->nchannels + 1) / 2; i++) {\n\n        int ch1 = i * 2;\n\n        int ch2 = FFMIN(ch1 + 1, s->nchannels - 1);\n\n\n\n        if (parse_grid_1_chunk (s, &chunk.grid1  [i], ch1, ch2) < 0 ||\n\n            parse_high_res_grid(s, &chunk.hr_grid[i], ch1, ch2) < 0) {\n\n            ret = -1;\n\n            continue;\n\n        }\n\n\n\n        // TS chunks depend on both grids. TS_2 depends on TS_1.\n\n        if (!chunk.grid1[i].len || !chunk.hr_grid[i].len || !chunk.ts1[i].len)\n\n            continue;\n\n\n\n        if (parse_ts1_chunk(s, &chunk.ts1[i], ch1, ch2) < 0 ||\n\n            parse_ts2_chunk(s, &chunk.ts2[i], ch1, ch2) < 0) {\n\n            ret = -1;\n\n            continue;\n\n        }\n\n    }\n\n\n\n    if (ret < 0 && (s->avctx->err_recognition & AV_EF_EXPLODE))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    return 0;\n\n}\n", "idx": 24431}
{"project": "FFmpeg", "commit_id": "1eaae7abb8f208fefb4e8b9e983e61b2499206a3", "target": 0, "func": "static av_cold int wmv2_decode_init(AVCodecContext *avctx)\n\n{\n\n    Wmv2Context *const w = avctx->priv_data;\n\n    int ret;\n\n\n\n    if ((ret = ff_msmpeg4_decode_init(avctx)) < 0)\n\n        return ret;\n\n\n\n    ff_wmv2_common_init(w);\n\n\n\n    return ff_intrax8_common_init(&w->x8, &w->s.idsp, &w->s);\n\n}\n", "idx": 24432}
{"project": "FFmpeg", "commit_id": "2bb62455c899cdccbdc2a6ad33f9582008ed9f05", "target": 0, "func": "static char *check_nan_suffix(char *s)\n\n{\n\n    char *start = s;\n\n\n\n    if (*s++ != '(')\n\n        return start;\n\n\n\n    while ((*s >= 'a' && *s <= 'z') || (*s >= 'A' && *s <= 'Z') ||\n\n           (*s >= '0' && *s <= '9') ||  *s == '_')\n\n        s++;\n\n\n\n    return *s == ')' ? s + 1 : start;\n\n}\n", "idx": 24433}
{"project": "FFmpeg", "commit_id": "ac726a4f0cd2fb8619b478af51312a4282215f0e", "target": 0, "func": "static int amovie_get_samples(AVFilterLink *outlink)\n\n{\n\n    MovieContext *movie = outlink->src->priv;\n\n    AVPacket pkt;\n\n    int ret, got_frame = 0;\n\n\n\n    if (!movie->pkt.size && movie->is_done == 1)\n\n        return AVERROR_EOF;\n\n\n\n    /* check for another frame, in case the previous one was completely consumed */\n\n    if (!movie->pkt.size) {\n\n        while ((ret = av_read_frame(movie->format_ctx, &pkt)) >= 0) {\n\n            // Is this a packet from the selected stream?\n\n            if (pkt.stream_index != movie->stream_index) {\n\n                av_free_packet(&pkt);\n\n                continue;\n\n            } else {\n\n                movie->pkt0 = movie->pkt = pkt;\n\n                break;\n\n            }\n\n        }\n\n\n\n        if (ret == AVERROR_EOF) {\n\n            movie->is_done = 1;\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    /* decode and update the movie pkt */\n\n    avcodec_get_frame_defaults(movie->frame);\n\n    ret = avcodec_decode_audio4(movie->codec_ctx, movie->frame, &got_frame, &movie->pkt);\n\n    if (ret < 0) {\n\n        movie->pkt.size = 0;\n\n        return ret;\n\n    }\n\n    movie->pkt.data += ret;\n\n    movie->pkt.size -= ret;\n\n\n\n    /* wrap the decoded data in a samplesref */\n\n    if (got_frame) {\n\n        int nb_samples = movie->frame->nb_samples;\n\n        int data_size =\n\n            av_samples_get_buffer_size(NULL, movie->codec_ctx->channels,\n\n                                       nb_samples, movie->codec_ctx->sample_fmt, 1);\n\n        if (data_size < 0)\n\n            return data_size;\n\n        movie->samplesref =\n\n            ff_get_audio_buffer(outlink, AV_PERM_WRITE, nb_samples);\n\n        memcpy(movie->samplesref->data[0], movie->frame->data[0], data_size);\n\n        movie->samplesref->pts = movie->pkt.pts;\n\n        movie->samplesref->pos = movie->pkt.pos;\n\n        movie->samplesref->audio->sample_rate = movie->codec_ctx->sample_rate;\n\n    }\n\n\n\n    // We got it. Free the packet since we are returning\n\n    if (movie->pkt.size <= 0)\n\n        av_free_packet(&movie->pkt0);\n\n\n\n    return 0;\n\n}\n", "idx": 24434}
{"project": "FFmpeg", "commit_id": "c8dcff0cdb17d0aa03ac729eba12d1a20f1f59c8", "target": 0, "func": "static int h264_init_context(AVCodecContext *avctx, H264Context *h)\n\n{\n\n    int i;\n\n\n\n    h->avctx                 = avctx;\n\n\n\n    h->picture_structure     = PICT_FRAME;\n\n    h->slice_context_count   = 1;\n\n    h->workaround_bugs       = avctx->workaround_bugs;\n\n    h->flags                 = avctx->flags;\n\n    h->prev_poc_msb          = 1 << 16;\n\n    h->x264_build            = -1;\n\n    h->recovery_frame        = -1;\n\n    h->frame_recovered       = 0;\n\n\n\n    h->next_outputed_poc = INT_MIN;\n\n    for (i = 0; i < MAX_DELAYED_PIC_COUNT; i++)\n\n        h->last_pocs[i] = INT_MIN;\n\n\n\n    ff_h264_reset_sei(h);\n\n\n\n    avctx->chroma_sample_location = AVCHROMA_LOC_LEFT;\n\n\n\n    h->nb_slice_ctx = (avctx->active_thread_type & FF_THREAD_SLICE) ?  H264_MAX_THREADS : 1;\n\n    h->slice_ctx = av_mallocz_array(h->nb_slice_ctx, sizeof(*h->slice_ctx));\n\n    if (!h->slice_ctx) {\n\n        h->nb_slice_ctx = 0;\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    for (i = 0; i < H264_MAX_PICTURE_COUNT; i++) {\n\n        h->DPB[i].f = av_frame_alloc();\n\n        if (!h->DPB[i].f)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    h->cur_pic.f = av_frame_alloc();\n\n    if (!h->cur_pic.f)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for (i = 0; i < h->nb_slice_ctx; i++)\n\n        h->slice_ctx[i].h264 = h;\n\n\n\n    return 0;\n\n}\n", "idx": 24435}
{"project": "FFmpeg", "commit_id": "9d602a0b0e955ac8553b16fc1b98731d66fdde2b", "target": 0, "func": "static int dnxhd_encode_init(AVCodecContext *avctx)\n\n{\n\n    DNXHDEncContext *ctx = avctx->priv_data;\n\n    int i, index, bit_depth;\n\n\n\n    switch (avctx->pix_fmt) {\n\n    case AV_PIX_FMT_YUV422P:\n\n        bit_depth = 8;\n\n        break;\n\n    case AV_PIX_FMT_YUV422P10:\n\n        bit_depth = 10;\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"pixel format is incompatible with DNxHD\\n\");\n\n        return -1;\n\n    }\n\n\n\n    ctx->cid = ff_dnxhd_find_cid(avctx, bit_depth);\n\n    if (!ctx->cid) {\n\n        av_log(avctx, AV_LOG_ERROR, \"video parameters incompatible with DNxHD\\n\");\n\n        return -1;\n\n    }\n\n    av_log(avctx, AV_LOG_DEBUG, \"cid %d\\n\", ctx->cid);\n\n\n\n    index = ff_dnxhd_get_cid_table(ctx->cid);\n\n    av_assert0(index >= 0);\n\n    ctx->cid_table = &ff_dnxhd_cid_table[index];\n\n\n\n    ctx->m.avctx = avctx;\n\n    ctx->m.mb_intra = 1;\n\n    ctx->m.h263_aic = 1;\n\n\n\n    avctx->bits_per_raw_sample = ctx->cid_table->bit_depth;\n\n\n\n    ff_dct_common_init(&ctx->m);\n\n    ff_dct_encode_init(&ctx->m);\n\n\n\n    if (!ctx->m.dct_quantize)\n\n        ctx->m.dct_quantize = ff_dct_quantize_c;\n\n\n\n    if (ctx->cid_table->bit_depth == 10) {\n\n       ctx->m.dct_quantize = dnxhd_10bit_dct_quantize;\n\n       ctx->get_pixels_8x4_sym = dnxhd_10bit_get_pixels_8x4_sym;\n\n       ctx->block_width_l2 = 4;\n\n    } else {\n\n       ctx->get_pixels_8x4_sym = dnxhd_8bit_get_pixels_8x4_sym;\n\n       ctx->block_width_l2 = 3;\n\n    }\n\n\n\n    if (ARCH_X86)\n\n        ff_dnxhdenc_init_x86(ctx);\n\n\n\n    ctx->m.mb_height = (avctx->height + 15) / 16;\n\n    ctx->m.mb_width  = (avctx->width  + 15) / 16;\n\n\n\n    if (avctx->flags & CODEC_FLAG_INTERLACED_DCT) {\n\n        ctx->interlaced = 1;\n\n        ctx->m.mb_height /= 2;\n\n    }\n\n\n\n    ctx->m.mb_num = ctx->m.mb_height * ctx->m.mb_width;\n\n\n\n    if (avctx->intra_quant_bias != FF_DEFAULT_QUANT_BIAS)\n\n        ctx->m.intra_quant_bias = avctx->intra_quant_bias;\n\n    if (dnxhd_init_qmat(ctx, ctx->m.intra_quant_bias, 0) < 0) // XXX tune lbias/cbias\n\n        return -1;\n\n\n\n    // Avid Nitris hardware decoder requires a minimum amount of padding in the coding unit payload\n\n    if (ctx->nitris_compat)\n\n        ctx->min_padding = 1600;\n\n\n\n    if (dnxhd_init_vlc(ctx) < 0)\n\n        return -1;\n\n    if (dnxhd_init_rc(ctx) < 0)\n\n        return -1;\n\n\n\n    FF_ALLOCZ_OR_GOTO(ctx->m.avctx, ctx->slice_size, ctx->m.mb_height*sizeof(uint32_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(ctx->m.avctx, ctx->slice_offs, ctx->m.mb_height*sizeof(uint32_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(ctx->m.avctx, ctx->mb_bits,    ctx->m.mb_num   *sizeof(uint16_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(ctx->m.avctx, ctx->mb_qscale,  ctx->m.mb_num   *sizeof(uint8_t),  fail);\n\n\n\n    ctx->frame.key_frame = 1;\n\n    ctx->frame.pict_type = AV_PICTURE_TYPE_I;\n\n    ctx->m.avctx->coded_frame = &ctx->frame;\n\n\n\n    if (avctx->thread_count > MAX_THREADS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"too many threads\\n\");\n\n        return -1;\n\n    }\n\n\n\n    ctx->thread[0] = ctx;\n\n    for (i = 1; i < avctx->thread_count; i++) {\n\n        ctx->thread[i] =  av_malloc(sizeof(DNXHDEncContext));\n\n        memcpy(ctx->thread[i], ctx, sizeof(DNXHDEncContext));\n\n    }\n\n\n\n    return 0;\n\n fail: //for FF_ALLOCZ_OR_GOTO\n\n    return -1;\n\n}\n", "idx": 24442}
{"project": "FFmpeg", "commit_id": "c96bd21227e594856f8fd0610fd213b002056383", "target": 0, "func": "static int mpegaudio_parse(AVCodecParserContext *s1,\n\n                           AVCodecContext *avctx,\n\n                           const uint8_t **poutbuf, int *poutbuf_size,\n\n                           const uint8_t *buf, int buf_size)\n\n{\n\n    MpegAudioParseContext *s = s1->priv_data;\n\n    int len, ret, sr;\n\n    uint32_t header;\n\n    const uint8_t *buf_ptr;\n\n\n\n    *poutbuf = NULL;\n\n    *poutbuf_size = 0;\n\n    buf_ptr = buf;\n\n    while (buf_size > 0) {\n\n        len = s->inbuf_ptr - s->inbuf;\n\n        if (s->frame_size == 0) {\n\n            /* special case for next header for first frame in free\n\n               format case (XXX: find a simpler method) */\n\n            if (s->free_format_next_header != 0) {\n\n                AV_WB32(s->inbuf, s->free_format_next_header);\n\n                s->inbuf_ptr = s->inbuf + 4;\n\n                s->free_format_next_header = 0;\n\n                goto got_header;\n\n            }\n\n            /* no header seen : find one. We need at least MPA_HEADER_SIZE\n\n               bytes to parse it */\n\n            len = FFMIN(MPA_HEADER_SIZE - len, buf_size);\n\n            if (len > 0) {\n\n                memcpy(s->inbuf_ptr, buf_ptr, len);\n\n                buf_ptr += len;\n\n                buf_size -= len;\n\n                s->inbuf_ptr += len;\n\n            }\n\n            if ((s->inbuf_ptr - s->inbuf) >= MPA_HEADER_SIZE) {\n\n            got_header:\n\n                header = AV_RB32(s->inbuf);\n\n\n\n                ret = ff_mpa_decode_header(avctx, header, &sr);\n\n                if (ret < 0) {\n\n                    s->header_count= -2;\n\n                    /* no sync found : move by one byte (inefficient, but simple!) */\n\n                    memmove(s->inbuf, s->inbuf + 1, s->inbuf_ptr - s->inbuf - 1);\n\n                    s->inbuf_ptr--;\n\n                    dprintf(avctx, \"skip %x\\n\", header);\n\n                    /* reset free format frame size to give a chance\n\n                       to get a new bitrate */\n\n                    s->free_format_frame_size = 0;\n\n                } else {\n\n                    if((header&SAME_HEADER_MASK) != (s->header&SAME_HEADER_MASK) && s->header)\n\n                        s->header_count= -3;\n\n                    s->header= header;\n\n                    s->header_count++;\n\n                    s->frame_size = ret;\n\n\n\n#if 0\n\n                    /* free format: prepare to compute frame size */\n\n                    if (ff_mpegaudio_decode_header(s, header) == 1) {\n\n                        s->frame_size = -1;\n\n                    }\n\n#endif\n\n                    if(s->header_count > 1)\n\n                        avctx->sample_rate= sr;\n\n                }\n\n            }\n\n        } else\n\n#if 0\n\n        if (s->frame_size == -1) {\n\n            /* free format : find next sync to compute frame size */\n\n            len = MPA_MAX_CODED_FRAME_SIZE - len;\n\n            if (len > buf_size)\n\n                len = buf_size;\n\n            if (len == 0) {\n\n                /* frame too long: resync */\n\n                s->frame_size = 0;\n\n                memmove(s->inbuf, s->inbuf + 1, s->inbuf_ptr - s->inbuf - 1);\n\n                s->inbuf_ptr--;\n\n            } else {\n\n                uint8_t *p, *pend;\n\n                uint32_t header1;\n\n                int padding;\n\n\n\n                memcpy(s->inbuf_ptr, buf_ptr, len);\n\n                /* check for header */\n\n                p = s->inbuf_ptr - 3;\n\n                pend = s->inbuf_ptr + len - 4;\n\n                while (p <= pend) {\n\n                    header = AV_RB32(p);\n\n                    header1 = AV_RB32(s->inbuf);\n\n                    /* check with high probability that we have a\n\n                       valid header */\n\n                    if ((header & SAME_HEADER_MASK) ==\n\n                        (header1 & SAME_HEADER_MASK)) {\n\n                        /* header found: update pointers */\n\n                        len = (p + 4) - s->inbuf_ptr;\n\n                        buf_ptr += len;\n\n                        buf_size -= len;\n\n                        s->inbuf_ptr = p;\n\n                        /* compute frame size */\n\n                        s->free_format_next_header = header;\n\n                        s->free_format_frame_size = s->inbuf_ptr - s->inbuf;\n\n                        padding = (header1 >> 9) & 1;\n\n                        if (s->layer == 1)\n\n                            s->free_format_frame_size -= padding * 4;\n\n                        else\n\n                            s->free_format_frame_size -= padding;\n\n                        dprintf(avctx, \"free frame size=%d padding=%d\\n\",\n\n                                s->free_format_frame_size, padding);\n\n                        ff_mpegaudio_decode_header(s, header1);\n\n                        goto next_data;\n\n                    }\n\n                    p++;\n\n                }\n\n                /* not found: simply increase pointers */\n\n                buf_ptr += len;\n\n                s->inbuf_ptr += len;\n\n                buf_size -= len;\n\n            }\n\n        } else\n\n#endif\n\n        if (len < s->frame_size) {\n\n            if (s->frame_size > MPA_MAX_CODED_FRAME_SIZE)\n\n                s->frame_size = MPA_MAX_CODED_FRAME_SIZE;\n\n            len = FFMIN(s->frame_size - len, buf_size);\n\n            memcpy(s->inbuf_ptr, buf_ptr, len);\n\n            buf_ptr += len;\n\n            s->inbuf_ptr += len;\n\n            buf_size -= len;\n\n        }\n\n\n\n        if(s->frame_size > 0 && buf_ptr - buf == s->inbuf_ptr - s->inbuf\n\n           && buf_size + buf_ptr - buf >= s->frame_size){\n\n            if(s->header_count > 0){\n\n                *poutbuf = buf;\n\n                *poutbuf_size = s->frame_size;\n\n            }\n\n            buf_ptr = buf + s->frame_size;\n\n            s->inbuf_ptr = s->inbuf;\n\n            s->frame_size = 0;\n\n            break;\n\n        }\n\n\n\n        //    next_data:\n\n        if (s->frame_size > 0 &&\n\n            (s->inbuf_ptr - s->inbuf) >= s->frame_size) {\n\n            if(s->header_count > 0){\n\n                *poutbuf = s->inbuf;\n\n                *poutbuf_size = s->inbuf_ptr - s->inbuf;\n\n            }\n\n            s->inbuf_ptr = s->inbuf;\n\n            s->frame_size = 0;\n\n            break;\n\n        }\n\n    }\n\n    return buf_ptr - buf;\n\n}\n", "idx": 24453}
{"project": "FFmpeg", "commit_id": "7f4ec4364bc4a73036660c1c6a3c4801db524e9e", "target": 0, "func": "int ff_replaygain_export_raw(AVStream *st, int32_t tg, uint32_t tp,\n\n                             int32_t ag, uint32_t ap)\n\n{\n\n    AVReplayGain *replaygain;\n\n\n\n    if (tg == INT32_MIN && ag == INT32_MIN)\n\n        return 0;\n\n\n\n    replaygain = (AVReplayGain*)ff_stream_new_side_data(st, AV_PKT_DATA_REPLAYGAIN,\n\n                                                        sizeof(*replaygain));\n\n    if (!replaygain)\n\n        return AVERROR(ENOMEM);\n\n\n\n    replaygain->track_gain = tg;\n\n    replaygain->track_peak = tp;\n\n    replaygain->album_gain = ag;\n\n    replaygain->album_peak = ap;\n\n\n\n    return 0;\n\n}\n", "idx": 24454}
{"project": "FFmpeg", "commit_id": "c4b2017ba66e1623da9f527704c61c86a6e74844", "target": 1, "func": "static int decode_nal_units(H264Context *h, const uint8_t *buf, int buf_size,\n\n                            int parse_extradata)\n\n{\n\n    AVCodecContext *const avctx = h->avctx;\n\n    H264SliceContext *sl;\n\n    int buf_index;\n\n    unsigned context_count;\n\n    int next_avc;\n\n    int nals_needed = 0; ///< number of NALs that need decoding before the next frame thread starts\n\n    int nal_index;\n\n    int idr_cleared=0;\n\n    int ret = 0;\n\n\n\n    h->nal_unit_type= 0;\n\n\n\n    if(!h->slice_context_count)\n\n         h->slice_context_count= 1;\n\n    h->max_contexts = h->slice_context_count;\n\n    if (!(avctx->flags2 & CODEC_FLAG2_CHUNKS)) {\n\n        h->current_slice = 0;\n\n        if (!h->first_field)\n\n            h->cur_pic_ptr = NULL;\n\n        ff_h264_reset_sei(h);\n\n\n\n\n    if (h->nal_length_size == 4) {\n\n        if (buf_size > 8 && AV_RB32(buf) == 1 && AV_RB32(buf+5) > (unsigned)buf_size) {\n\n            h->is_avc = 0;\n\n        }else if(buf_size > 3 && AV_RB32(buf) > 1 && AV_RB32(buf) <= (unsigned)buf_size)\n\n            h->is_avc = 1;\n\n\n\n\n    if (avctx->active_thread_type & FF_THREAD_FRAME)\n\n        nals_needed = get_last_needed_nal(h, buf, buf_size);\n\n\n\n    {\n\n        buf_index     = 0;\n\n\n        next_avc      = h->is_avc ? 0 : buf_size;\n\n        nal_index     = 0;\n\n        for (;;) {\n\n            int consumed;\n\n            int dst_length;\n\n            int bit_length;\n\n            const uint8_t *ptr;\n\n            int nalsize = 0;\n\n            int err;\n\n\n\n            if (buf_index >= next_avc) {\n\n                nalsize = get_avc_nalsize(h, buf, buf_size, &buf_index);\n\n                if (nalsize < 0)\n\n                    break;\n\n                next_avc = buf_index + nalsize;\n\n            } else {\n\n                buf_index = find_start_code(buf, buf_size, buf_index, next_avc);\n\n                if (buf_index >= buf_size)\n\n                    break;\n\n                if (buf_index >= next_avc)\n\n                    continue;\n\n\n\n\n            sl = &h->slice_ctx[context_count];\n\n\n\n            ptr = ff_h264_decode_nal(h, sl, buf + buf_index, &dst_length,\n\n                                     &consumed, next_avc - buf_index);\n\n            if (!ptr || dst_length < 0) {\n\n                ret = -1;\n\n\n\n\n\n            bit_length = get_bit_length(h, buf, ptr, dst_length,\n\n                                        buf_index + consumed, next_avc);\n\n\n\n            if (h->avctx->debug & FF_DEBUG_STARTCODE)\n\n                av_log(h->avctx, AV_LOG_DEBUG,\n\n                       \"NAL %d/%d at %d/%d length %d\\n\",\n\n                       h->nal_unit_type, h->nal_ref_idc, buf_index, buf_size, dst_length);\n\n\n\n            if (h->is_avc && (nalsize != consumed) && nalsize)\n\n                av_log(h->avctx, AV_LOG_DEBUG,\n\n                       \"AVC: Consumed only %d bytes instead of %d\\n\",\n\n                       consumed, nalsize);\n\n\n\n            buf_index += consumed;\n\n            nal_index++;\n\n\n\n            if (avctx->skip_frame >= AVDISCARD_NONREF &&\n\n                h->nal_ref_idc == 0 &&\n\n                h->nal_unit_type != NAL_SEI)\n\n                continue;\n\n\n\nagain:\n\n            if (   (!(avctx->active_thread_type & FF_THREAD_FRAME) || nals_needed >= nal_index)\n\n                && !h->current_slice)\n\n                h->au_pps_id = -1;\n\n            /* Ignore per frame NAL unit type during extradata\n\n             * parsing. Decoding slices is not possible in codec init\n\n             * with frame-mt */\n\n            if (parse_extradata) {\n\n                switch (h->nal_unit_type) {\n\n                case NAL_IDR_SLICE:\n\n                case NAL_SLICE:\n\n                case NAL_DPA:\n\n                case NAL_DPB:\n\n                case NAL_DPC:\n\n                    av_log(h->avctx, AV_LOG_WARNING,\n\n                           \"Ignoring NAL %d in global header/extradata\\n\",\n\n                           h->nal_unit_type);\n\n                    // fall through to next case\n\n                case NAL_AUXILIARY_SLICE:\n\n                    h->nal_unit_type = NAL_FF_IGNORE;\n\n\n\n\n\n            err = 0;\n\n\n\n            switch (h->nal_unit_type) {\n\n            case NAL_IDR_SLICE:\n\n                if ((ptr[0] & 0xFC) == 0x98) {\n\n                    av_log(h->avctx, AV_LOG_ERROR, \"Invalid inter IDR frame\\n\");\n\n                    h->next_outputed_poc = INT_MIN;\n\n                    ret = -1;\n\n\n\n                if (h->nal_unit_type != NAL_IDR_SLICE) {\n\n                    av_log(h->avctx, AV_LOG_ERROR,\n\n                           \"Invalid mix of idr and non-idr slices\\n\");\n\n                    ret = -1;\n\n\n\n                if(!idr_cleared) {\n\n                    if (h->current_slice && (avctx->active_thread_type & FF_THREAD_SLICE)) {\n\n                        av_log(h, AV_LOG_ERROR, \"invalid mixed IDR / non IDR frames cannot be decoded in slice multithreading mode\\n\");\n\n                        ret = AVERROR_INVALIDDATA;\n\n\n\n                    idr(h); // FIXME ensure we don't lose some frames if there is reordering\n\n\n                idr_cleared = 1;\n\n                h->has_recovery_point = 1;\n\n            case NAL_SLICE:\n\n                init_get_bits(&sl->gb, ptr, bit_length);\n\n\n\n                if ((err = ff_h264_decode_slice_header(h, sl)))\n\n                    break;\n\n\n\n                if (h->sei_recovery_frame_cnt >= 0) {\n\n                    if (h->frame_num != h->sei_recovery_frame_cnt || sl->slice_type_nos != AV_PICTURE_TYPE_I)\n\n                        h->valid_recovery_point = 1;\n\n\n\n                    if (   h->recovery_frame < 0\n\n                        || ((h->recovery_frame - h->frame_num) & ((1 << h->sps.log2_max_frame_num)-1)) > h->sei_recovery_frame_cnt) {\n\n                        h->recovery_frame = (h->frame_num + h->sei_recovery_frame_cnt) &\n\n                                            ((1 << h->sps.log2_max_frame_num) - 1);\n\n\n\n                        if (!h->valid_recovery_point)\n\n                            h->recovery_frame = h->frame_num;\n\n\n\n\n\n                h->cur_pic_ptr->f.key_frame |=\n\n                    (h->nal_unit_type == NAL_IDR_SLICE);\n\n\n\n                if (h->nal_unit_type == NAL_IDR_SLICE ||\n\n                    h->recovery_frame == h->frame_num) {\n\n                    h->recovery_frame         = -1;\n\n                    h->cur_pic_ptr->recovered = 1;\n\n\n                // If we have an IDR, all frames after it in decoded order are\n\n                // \"recovered\".\n\n                if (h->nal_unit_type == NAL_IDR_SLICE)\n\n                    h->frame_recovered |= FRAME_RECOVERED_IDR;\n\n                h->frame_recovered |= 3*!!(avctx->flags2 & CODEC_FLAG2_SHOW_ALL);\n\n                h->frame_recovered |= 3*!!(avctx->flags & CODEC_FLAG_OUTPUT_CORRUPT);\n\n#if 1\n\n                h->cur_pic_ptr->recovered |= h->frame_recovered;\n\n#else\n\n                h->cur_pic_ptr->recovered |= !!(h->frame_recovered & FRAME_RECOVERED_IDR);\n\n#endif\n\n\n\n                if (h->current_slice == 1) {\n\n                    if (!(avctx->flags2 & CODEC_FLAG2_CHUNKS))\n\n                        decode_postinit(h, nal_index >= nals_needed);\n\n\n\n                    if (h->avctx->hwaccel &&\n\n                        (ret = h->avctx->hwaccel->start_frame(h->avctx, buf, buf_size)) < 0)\n\n\n                    if (CONFIG_H264_VDPAU_DECODER &&\n\n                        h->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU)\n\n                        ff_vdpau_h264_picture_start(h);\n\n\n\n\n                if (sl->redundant_pic_count == 0) {\n\n                    if (avctx->hwaccel) {\n\n                        ret = avctx->hwaccel->decode_slice(avctx,\n\n                                                           &buf[buf_index - consumed],\n\n                                                           consumed);\n\n                        if (ret < 0)\n\n\n                    } else if (CONFIG_H264_VDPAU_DECODER &&\n\n                               h->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU) {\n\n                        ff_vdpau_add_data_chunk(h->cur_pic_ptr->f.data[0],\n\n                                                start_code,\n\n                                                sizeof(start_code));\n\n                        ff_vdpau_add_data_chunk(h->cur_pic_ptr->f.data[0],\n\n                                                &buf[buf_index - consumed],\n\n                                                consumed);\n\n                    } else\n\n                        context_count++;\n\n\n                break;\n\n            case NAL_DPA:\n\n            case NAL_DPB:\n\n            case NAL_DPC:\n\n                avpriv_request_sample(avctx, \"data partitioning\");\n\n                ret = AVERROR(ENOSYS);\n\n\n                break;\n\n            case NAL_SEI:\n\n                init_get_bits(&h->gb, ptr, bit_length);\n\n                ret = ff_h264_decode_sei(h);\n\n\n\n                break;\n\n            case NAL_SPS:\n\n                init_get_bits(&h->gb, ptr, bit_length);\n\n                if (ff_h264_decode_seq_parameter_set(h) < 0 && (h->is_avc ? nalsize : 1)) {\n\n                    av_log(h->avctx, AV_LOG_DEBUG,\n\n                           \"SPS decoding failure, trying again with the complete NAL\\n\");\n\n                    if (h->is_avc)\n\n                        av_assert0(next_avc - buf_index + consumed == nalsize);\n\n                    if ((next_avc - buf_index + consumed - 1) >= INT_MAX/8)\n\n                        break;\n\n                    init_get_bits(&h->gb, &buf[buf_index + 1 - consumed],\n\n                                  8*(next_avc - buf_index + consumed - 1));\n\n                    ff_h264_decode_seq_parameter_set(h);\n\n\n\n\n                break;\n\n            case NAL_PPS:\n\n                init_get_bits(&h->gb, ptr, bit_length);\n\n                ret = ff_h264_decode_picture_parameter_set(h, bit_length);\n\n\n\n                break;\n\n            case NAL_AUD:\n\n            case NAL_END_SEQUENCE:\n\n            case NAL_END_STREAM:\n\n            case NAL_FILLER_DATA:\n\n            case NAL_SPS_EXT:\n\n            case NAL_AUXILIARY_SLICE:\n\n                break;\n\n            case NAL_FF_IGNORE:\n\n                break;\n\n            default:\n\n                av_log(avctx, AV_LOG_DEBUG, \"Unknown NAL code: %d (%d bits)\\n\",\n\n                       h->nal_unit_type, bit_length);\n\n\n\n\n            if (context_count == h->max_contexts) {\n\n                ret = ff_h264_execute_decode_slices(h, context_count);\n\n\n\n\n\n\n\n            if (err < 0 || err == SLICE_SKIPED) {\n\n                if (err < 0)\n\n                    av_log(h->avctx, AV_LOG_ERROR, \"decode_slice_header error\\n\");\n\n                sl->ref_count[0] = sl->ref_count[1] = sl->list_count = 0;\n\n            } else if (err == SLICE_SINGLETHREAD) {\n\n\n\n\n\n\n\n                /* Slice could not be decoded in parallel mode, restart. Note\n\n                 * that rbsp_buffer is not transferred, but since we no longer\n\n                 * run in parallel mode this should not be an issue. */\n\n                sl               = &h->slice_ctx[0];\n\n                goto again;\n\n\n\n\n    if (context_count) {\n\n        ret = ff_h264_execute_decode_slices(h, context_count);\n\n\n\n\n\n\n    ret = 0;\n\nend:\n\n    /* clean up */\n\n    if (h->cur_pic_ptr && !h->droppable) {\n\n        ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n\n                                  h->picture_structure == PICT_BOTTOM_FIELD);\n\n\n\n\n    return (ret < 0) ? ret : buf_index;\n", "idx": 24459}
{"project": "FFmpeg", "commit_id": "0382c94f13b4b20456b7259e90b170dc020419b8", "target": 1, "func": "static int check_tag(AVIOContext *s, int offset, unsigned int len)\n\n{\n\n    char tag[4];\n\n\n\n    if (len > 4 ||\n\n        avio_seek(s, offset, SEEK_SET) < 0 ||\n\n        avio_read(s, tag, len) < len)\n\n        return -1;\n\n    else if (!AV_RB32(tag) || is_tag(tag, len))\n\n        return 1;\n\n\n\n    return 0;\n\n}\n", "idx": 24460}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int rm_probe(AVProbeData *p)\n\n{\n\n    /* check file header */\n\n    if (p->buf_size <= 32)\n\n        return 0;\n\n    if ((p->buf[0] == '.' && p->buf[1] == 'R' &&\n\n         p->buf[2] == 'M' && p->buf[3] == 'F' &&\n\n         p->buf[4] == 0 && p->buf[5] == 0) ||\n\n        (p->buf[0] == '.' && p->buf[1] == 'r' &&\n\n         p->buf[2] == 'a' && p->buf[3] == 0xfd))\n\n        return AVPROBE_SCORE_MAX;\n\n    else\n\n        return 0;\n\n}\n", "idx": 24464}
{"project": "FFmpeg", "commit_id": "bb23a15df507440deb0dcf25099d321d0f73dc28", "target": 0, "func": "static int read_sm_data(AVFormatContext *s, AVIOContext *bc, AVPacket *pkt, int is_meta, int64_t maxpos)\n\n{\n\n    int count = ffio_read_varlen(bc);\n\n    int skip_start = 0;\n\n    int skip_end = 0;\n\n    int channels = 0;\n\n    int64_t channel_layout = 0;\n\n    int sample_rate = 0;\n\n    int width = 0;\n\n    int height = 0;\n\n    int i;\n\n\n\n    for (i=0; i<count; i++) {\n\n        uint8_t name[256], str_value[256], type_str[256];\n\n        int value;\n\n        if (avio_tell(bc) >= maxpos)\n\n            return AVERROR_INVALIDDATA;\n\n        get_str(bc, name, sizeof(name));\n\n        value = get_s(bc);\n\n\n\n        if (value == -1) {\n\n            get_str(bc, str_value, sizeof(str_value));\n\n            av_log(s, AV_LOG_WARNING, \"Unknown string %s / %s\\n\", name, str_value);\n\n        } else if (value == -2) {\n\n            uint8_t *dst = NULL;\n\n            int64_t v64, value_len;\n\n\n\n            get_str(bc, type_str, sizeof(type_str));\n\n            value_len = ffio_read_varlen(bc);\n\n            if (avio_tell(bc) + value_len >= maxpos)\n\n                return AVERROR_INVALIDDATA;\n\n            if (!strcmp(name, \"Palette\")) {\n\n                dst = av_packet_new_side_data(pkt, AV_PKT_DATA_PALETTE, value_len);\n\n            } else if (!strcmp(name, \"Extradata\")) {\n\n                dst = av_packet_new_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA, value_len);\n\n            } else if (sscanf(name, \"CodecSpecificSide%\"SCNd64\"\", &v64) == 1) {\n\n                dst = av_packet_new_side_data(pkt, AV_PKT_DATA_MATROSKA_BLOCKADDITIONAL, value_len + 8);\n\n                if(!dst)\n\n                    return AVERROR(ENOMEM);\n\n                AV_WB64(dst, v64);\n\n                dst += 8;\n\n            } else if (!strcmp(name, \"ChannelLayout\") && value_len == 8) {\n\n                channel_layout = avio_rl64(bc);\n\n                continue;\n\n            } else {\n\n                av_log(s, AV_LOG_WARNING, \"Unknown data %s / %s\\n\", name, type_str);\n\n                avio_skip(bc, value_len);\n\n                continue;\n\n            }\n\n            if(!dst)\n\n                return AVERROR(ENOMEM);\n\n            avio_read(bc, dst, value_len);\n\n        } else if (value == -3) {\n\n            value = get_s(bc);\n\n        } else if (value == -4) {\n\n            value = ffio_read_varlen(bc);\n\n        } else if (value < -4) {\n\n            get_s(bc);\n\n        } else {\n\n            if (!strcmp(name, \"SkipStart\")) {\n\n                skip_start = value;\n\n            } else if (!strcmp(name, \"SkipEnd\")) {\n\n                skip_end = value;\n\n            } else if (!strcmp(name, \"Channels\")) {\n\n                channels = value;\n\n            } else if (!strcmp(name, \"SampleRate\")) {\n\n                sample_rate = value;\n\n            } else if (!strcmp(name, \"Width\")) {\n\n                width = value;\n\n            } else if (!strcmp(name, \"Height\")) {\n\n                height = value;\n\n            } else {\n\n                av_log(s, AV_LOG_WARNING, \"Unknown integer %s\\n\", name);\n\n            }\n\n        }\n\n    }\n\n\n\n    if (channels || channel_layout || sample_rate || width || height) {\n\n        uint8_t *dst = av_packet_new_side_data(pkt, AV_PKT_DATA_PARAM_CHANGE, 28);\n\n        if (!dst)\n\n            return AVERROR(ENOMEM);\n\n        bytestream_put_le32(&dst,\n\n                            AV_SIDE_DATA_PARAM_CHANGE_CHANNEL_COUNT*(!!channels) +\n\n                            AV_SIDE_DATA_PARAM_CHANGE_CHANNEL_LAYOUT*(!!channel_layout) +\n\n                            AV_SIDE_DATA_PARAM_CHANGE_SAMPLE_RATE*(!!sample_rate) +\n\n                            AV_SIDE_DATA_PARAM_CHANGE_DIMENSIONS*(!!(width|height))\n\n                           );\n\n        if (channels)\n\n            bytestream_put_le32(&dst, channels);\n\n        if (channel_layout)\n\n            bytestream_put_le64(&dst, channel_layout);\n\n        if (sample_rate)\n\n            bytestream_put_le32(&dst, sample_rate);\n\n        if (width || height){\n\n            bytestream_put_le32(&dst, width);\n\n            bytestream_put_le32(&dst, height);\n\n        }\n\n    }\n\n\n\n    if (skip_start || skip_end) {\n\n        uint8_t *dst = av_packet_new_side_data(pkt, AV_PKT_DATA_SKIP_SAMPLES, 10);\n\n        if (!dst)\n\n            return AVERROR(ENOMEM);\n\n        AV_WL32(dst, skip_start);\n\n        AV_WL32(dst+4, skip_end);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24465}
{"project": "FFmpeg", "commit_id": "8005b6de4f88c9e3739a3a4ceda4288804788df9", "target": 0, "func": "static FFPsyWindowInfo psy_lame_window(FFPsyContext *ctx, const float *audio,\n\n                                       const float *la, int channel, int prev_type)\n\n{\n\n    AacPsyContext *pctx = (AacPsyContext*) ctx->model_priv_data;\n\n    AacPsyChannel *pch  = &pctx->ch[channel];\n\n    int grouping     = 0;\n\n    int uselongblock = 1;\n\n    int attacks[AAC_NUM_BLOCKS_SHORT + 1] = { 0 };\n\n    float clippings[AAC_NUM_BLOCKS_SHORT];\n\n    int i;\n\n    FFPsyWindowInfo wi = { { 0 } };\n\n\n\n    if (la) {\n\n        float hpfsmpl[AAC_BLOCK_SIZE_LONG];\n\n        float const *pf = hpfsmpl;\n\n        float attack_intensity[(AAC_NUM_BLOCKS_SHORT + 1) * PSY_LAME_NUM_SUBBLOCKS];\n\n        float energy_subshort[(AAC_NUM_BLOCKS_SHORT + 1) * PSY_LAME_NUM_SUBBLOCKS];\n\n        float energy_short[AAC_NUM_BLOCKS_SHORT + 1] = { 0 };\n\n        const float *firbuf = la + (AAC_BLOCK_SIZE_SHORT/4 - PSY_LAME_FIR_LEN);\n\n        int att_sum = 0;\n\n\n\n        /* LAME comment: apply high pass filter of fs/4 */\n\n        psy_hp_filter(firbuf, hpfsmpl, psy_fir_coeffs);\n\n\n\n        /* Calculate the energies of each sub-shortblock */\n\n        for (i = 0; i < PSY_LAME_NUM_SUBBLOCKS; i++) {\n\n            energy_subshort[i] = pch->prev_energy_subshort[i + ((AAC_NUM_BLOCKS_SHORT - 1) * PSY_LAME_NUM_SUBBLOCKS)];\n\n            assert(pch->prev_energy_subshort[i + ((AAC_NUM_BLOCKS_SHORT - 2) * PSY_LAME_NUM_SUBBLOCKS + 1)] > 0);\n\n            attack_intensity[i] = energy_subshort[i] / pch->prev_energy_subshort[i + ((AAC_NUM_BLOCKS_SHORT - 2) * PSY_LAME_NUM_SUBBLOCKS + 1)];\n\n            energy_short[0] += energy_subshort[i];\n\n        }\n\n\n\n        for (i = 0; i < AAC_NUM_BLOCKS_SHORT * PSY_LAME_NUM_SUBBLOCKS; i++) {\n\n            float const *const pfe = pf + AAC_BLOCK_SIZE_LONG / (AAC_NUM_BLOCKS_SHORT * PSY_LAME_NUM_SUBBLOCKS);\n\n            float p = 1.0f;\n\n            for (; pf < pfe; pf++)\n\n                p = FFMAX(p, fabsf(*pf));\n\n            pch->prev_energy_subshort[i] = energy_subshort[i + PSY_LAME_NUM_SUBBLOCKS] = p;\n\n            energy_short[1 + i / PSY_LAME_NUM_SUBBLOCKS] += p;\n\n            /* NOTE: The indexes below are [i + 3 - 2] in the LAME source.\n\n             *       Obviously the 3 and 2 have some significance, or this would be just [i + 1]\n\n             *       (which is what we use here). What the 3 stands for is ambiguous, as it is both\n\n             *       number of short blocks, and the number of sub-short blocks.\n\n             *       It seems that LAME is comparing each sub-block to sub-block + 1 in the\n\n             *       previous block.\n\n             */\n\n            if (p > energy_subshort[i + 1])\n\n                p = p / energy_subshort[i + 1];\n\n            else if (energy_subshort[i + 1] > p * 10.0f)\n\n                p = energy_subshort[i + 1] / (p * 10.0f);\n\n            else\n\n                p = 0.0;\n\n            attack_intensity[i + PSY_LAME_NUM_SUBBLOCKS] = p;\n\n        }\n\n\n\n        /* compare energy between sub-short blocks */\n\n        for (i = 0; i < (AAC_NUM_BLOCKS_SHORT + 1) * PSY_LAME_NUM_SUBBLOCKS; i++)\n\n            if (!attacks[i / PSY_LAME_NUM_SUBBLOCKS])\n\n                if (attack_intensity[i] > pch->attack_threshold)\n\n                    attacks[i / PSY_LAME_NUM_SUBBLOCKS] = (i % PSY_LAME_NUM_SUBBLOCKS) + 1;\n\n\n\n        /* should have energy change between short blocks, in order to avoid periodic signals */\n\n        /* Good samples to show the effect are Trumpet test songs */\n\n        /* GB: tuned (1) to avoid too many short blocks for test sample TRUMPET */\n\n        /* RH: tuned (2) to let enough short blocks through for test sample FSOL and SNAPS */\n\n        for (i = 1; i < AAC_NUM_BLOCKS_SHORT + 1; i++) {\n\n            float const u = energy_short[i - 1];\n\n            float const v = energy_short[i];\n\n            float const m = FFMAX(u, v);\n\n            if (m < 40000) {                          /* (2) */\n\n                if (u < 1.7f * v && v < 1.7f * u) {   /* (1) */\n\n                    if (i == 1 && attacks[0] < attacks[i])\n\n                        attacks[0] = 0;\n\n                    attacks[i] = 0;\n\n                }\n\n            }\n\n            att_sum += attacks[i];\n\n        }\n\n\n\n        if (attacks[0] <= pch->prev_attack)\n\n            attacks[0] = 0;\n\n\n\n        att_sum += attacks[0];\n\n        /* 3 below indicates the previous attack happened in the last sub-block of the previous sequence */\n\n        if (pch->prev_attack == 3 || att_sum) {\n\n            uselongblock = 0;\n\n\n\n            for (i = 1; i < AAC_NUM_BLOCKS_SHORT + 1; i++)\n\n                if (attacks[i] && attacks[i-1])\n\n                    attacks[i] = 0;\n\n        }\n\n    } else {\n\n        /* We have no lookahead info, so just use same type as the previous sequence. */\n\n        uselongblock = !(prev_type == EIGHT_SHORT_SEQUENCE);\n\n    }\n\n\n\n    lame_apply_block_type(pch, &wi, uselongblock);\n\n\n\n    /* Calculate input sample maximums and evaluate clipping risk */\n\n    if (audio) {\n\n        for (i = 0; i < AAC_NUM_BLOCKS_SHORT; i++) {\n\n            const float *wbuf = audio + i * AAC_BLOCK_SIZE_SHORT;\n\n            float max = 0;\n\n            int j;\n\n            for (j = 0; j < AAC_BLOCK_SIZE_SHORT; j++)\n\n                max = FFMAX(max, fabsf(wbuf[j]));\n\n            clippings[i] = max;\n\n        }\n\n    } else {\n\n        for (i = 0; i < 8; i++)\n\n            clippings[i] = 0;\n\n    }\n\n\n\n    wi.window_type[1] = prev_type;\n\n    if (wi.window_type[0] != EIGHT_SHORT_SEQUENCE) {\n\n        float clipping = 0.0f;\n\n\n\n        wi.num_windows  = 1;\n\n        wi.grouping[0]  = 1;\n\n        if (wi.window_type[0] == LONG_START_SEQUENCE)\n\n            wi.window_shape = 0;\n\n        else\n\n            wi.window_shape = 1;\n\n\n\n        for (i = 0; i < 8; i++)\n\n            clipping = FFMAX(clipping, clippings[i]);\n\n        wi.clipping[0] = clipping;\n\n    } else {\n\n        int lastgrp = 0;\n\n\n\n        wi.num_windows = 8;\n\n        wi.window_shape = 0;\n\n        for (i = 0; i < 8; i++) {\n\n            if (!((pch->next_grouping >> i) & 1))\n\n                lastgrp = i;\n\n            wi.grouping[lastgrp]++;\n\n        }\n\n\n\n        for (i = 0; i < 8; i += wi.grouping[i]) {\n\n            int w;\n\n            float clipping = 0.0f;\n\n            for (w = 0; w < wi.grouping[i]; w++)\n\n                clipping = FFMAX(clipping, clippings[i+w]);\n\n            for (w = 0; w < wi.grouping[i]; w++)\n\n                wi.clipping[i+w] = clipping;\n\n        }\n\n    }\n\n\n\n    /* Determine grouping, based on the location of the first attack, and save for\n\n     * the next frame.\n\n     * FIXME: Move this to analysis.\n\n     * TODO: Tune groupings depending on attack location\n\n     * TODO: Handle more than one attack in a group\n\n     */\n\n    for (i = 0; i < 9; i++) {\n\n        if (attacks[i]) {\n\n            grouping = i;\n\n            break;\n\n        }\n\n    }\n\n    pch->next_grouping = window_grouping[grouping];\n\n\n\n    pch->prev_attack = attacks[8];\n\n\n\n    return wi;\n\n}\n", "idx": 24466}
{"project": "FFmpeg", "commit_id": "4bff9ef9d0781c4de228bf1f85634d2706fc589b", "target": 0, "func": "static inline void RENAME(yuvPlanartoyuy2)(const uint8_t *ysrc, const uint8_t *usrc, const uint8_t *vsrc, uint8_t *dst,\n\n\tlong width, long height,\n\n\tlong lumStride, long chromStride, long dstStride, long vertLumPerChroma)\n\n{\n\n\tlong y;\n\n\tconst long chromWidth= width>>1;\n\n\tfor(y=0; y<height; y++)\n\n\t{\n\n#ifdef HAVE_MMX\n\n//FIXME handle 2 lines a once (fewer prefetch, reuse some chrom, but very likely limited by mem anyway)\n\n\t\tasm volatile(\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\"\n\n\t\t\tASMALIGN16\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%1, %%\"REG_a\", 2)\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%2, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%3, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\t\"movq (%2, %%\"REG_a\"), %%mm0\t\\n\\t\" // U(0)\n\n\t\t\t\"movq %%mm0, %%mm2\t\t\\n\\t\" // U(0)\n\n\t\t\t\"movq (%3, %%\"REG_a\"), %%mm1\t\\n\\t\" // V(0)\n\n\t\t\t\"punpcklbw %%mm1, %%mm0\t\t\\n\\t\" // UVUV UVUV(0)\n\n\t\t\t\"punpckhbw %%mm1, %%mm2\t\t\\n\\t\" // UVUV UVUV(8)\n\n\n\n\t\t\t\"movq (%1, %%\"REG_a\",2), %%mm3\t\\n\\t\" // Y(0)\n\n\t\t\t\"movq 8(%1, %%\"REG_a\",2), %%mm5\t\\n\\t\" // Y(8)\n\n\t\t\t\"movq %%mm3, %%mm4\t\t\\n\\t\" // Y(0)\n\n\t\t\t\"movq %%mm5, %%mm6\t\t\\n\\t\" // Y(8)\n\n\t\t\t\"punpcklbw %%mm0, %%mm3\t\t\\n\\t\" // YUYV YUYV(0)\n\n\t\t\t\"punpckhbw %%mm0, %%mm4\t\t\\n\\t\" // YUYV YUYV(4)\n\n\t\t\t\"punpcklbw %%mm2, %%mm5\t\t\\n\\t\" // YUYV YUYV(8)\n\n\t\t\t\"punpckhbw %%mm2, %%mm6\t\t\\n\\t\" // YUYV YUYV(12)\n\n\n\n\t\t\tMOVNTQ\" %%mm3, (%0, %%\"REG_a\", 4)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm4, 8(%0, %%\"REG_a\", 4)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm5, 16(%0, %%\"REG_a\", 4)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm6, 24(%0, %%\"REG_a\", 4)\\n\\t\"\n\n\n\n\t\t\t\"add $8, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\"cmp %4, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\t\t\t::\"r\"(dst), \"r\"(ysrc), \"r\"(usrc), \"r\"(vsrc), \"g\" (chromWidth)\n\n\t\t\t: \"%\"REG_a\n\n\t\t);\n\n#else\n\n\n\n#if defined ARCH_ALPHA && defined HAVE_MVI\n\n#define pl2yuy2(n)\t\t\t\t\t\\\n\n\ty1 = yc[n];\t\t\t\t\t\\\n\n\ty2 = yc2[n];\t\t\t\t\t\\\n\n\tu = uc[n];\t\t\t\t\t\\\n\n\tv = vc[n];\t\t\t\t\t\\\n\n\tasm(\"unpkbw %1, %0\" : \"=r\"(y1) : \"r\"(y1));\t\\\n\n\tasm(\"unpkbw %1, %0\" : \"=r\"(y2) : \"r\"(y2));\t\\\n\n\tasm(\"unpkbl %1, %0\" : \"=r\"(u) : \"r\"(u));\t\\\n\n\tasm(\"unpkbl %1, %0\" : \"=r\"(v) : \"r\"(v));\t\\\n\n\tyuv1 = (u << 8) + (v << 24);\t\t\t\\\n\n\tyuv2 = yuv1 + y2;\t\t\t\t\\\n\n\tyuv1 += y1;\t\t\t\t\t\\\n\n\tqdst[n] = yuv1;\t\t\t\t\t\\\n\n\tqdst2[n] = yuv2;\n\n\n\n\t\tint i;\n\n\t\tuint64_t *qdst = (uint64_t *) dst;\n\n\t\tuint64_t *qdst2 = (uint64_t *) (dst + dstStride);\n\n\t\tconst uint32_t *yc = (uint32_t *) ysrc;\n\n\t\tconst uint32_t *yc2 = (uint32_t *) (ysrc + lumStride);\n\n\t\tconst uint16_t *uc = (uint16_t*) usrc, *vc = (uint16_t*) vsrc;\n\n\t\tfor(i = 0; i < chromWidth; i += 8){\n\n\t\t\tuint64_t y1, y2, yuv1, yuv2;\n\n\t\t\tuint64_t u, v;\n\n\t\t\t/* Prefetch */\n\n\t\t\tasm(\"ldq $31,64(%0)\" :: \"r\"(yc));\n\n\t\t\tasm(\"ldq $31,64(%0)\" :: \"r\"(yc2));\n\n\t\t\tasm(\"ldq $31,64(%0)\" :: \"r\"(uc));\n\n\t\t\tasm(\"ldq $31,64(%0)\" :: \"r\"(vc));\n\n\n\n\t\t\tpl2yuy2(0);\n\n\t\t\tpl2yuy2(1);\n\n\t\t\tpl2yuy2(2);\n\n\t\t\tpl2yuy2(3);\n\n\n\n\t\t\tyc += 4;\n\n\t\t\tyc2 += 4;\n\n\t\t\tuc += 4;\n\n\t\t\tvc += 4;\n\n\t\t\tqdst += 4;\n\n\t\t\tqdst2 += 4;\n\n\t\t}\n\n\t\ty++;\n\n\t\tysrc += lumStride;\n\n\t\tdst += dstStride;\n\n\n\n#elif __WORDSIZE >= 64\n\n\t\tint i;\n\n\t\tuint64_t *ldst = (uint64_t *) dst;\n\n\t\tconst uint8_t *yc = ysrc, *uc = usrc, *vc = vsrc;\n\n\t\tfor(i = 0; i < chromWidth; i += 2){\n\n\t\t\tuint64_t k, l;\n\n\t\t\tk = yc[0] + (uc[0] << 8) +\n\n\t\t\t    (yc[1] << 16) + (vc[0] << 24);\n\n\t\t\tl = yc[2] + (uc[1] << 8) +\n\n\t\t\t    (yc[3] << 16) + (vc[1] << 24);\n\n\t\t\t*ldst++ = k + (l << 32);\n\n\t\t\tyc += 4;\n\n\t\t\tuc += 2;\n\n\t\t\tvc += 2;\n\n\t\t}\n\n\n\n#else\n\n\t\tint i, *idst = (int32_t *) dst;\n\n\t\tconst uint8_t *yc = ysrc, *uc = usrc, *vc = vsrc;\n\n\t\tfor(i = 0; i < chromWidth; i++){\n\n#ifdef WORDS_BIGENDIAN\n\n\t\t\t*idst++ = (yc[0] << 24)+ (uc[0] << 16) +\n\n\t\t\t    (yc[1] << 8) + (vc[0] << 0);\n\n#else\n\n\t\t\t*idst++ = yc[0] + (uc[0] << 8) +\n\n\t\t\t    (yc[1] << 16) + (vc[0] << 24);\n\n#endif\n\n\t\t\tyc += 2;\n\n\t\t\tuc++;\n\n\t\t\tvc++;\n\n\t\t}\n\n#endif\n\n#endif\n\n\t\tif((y&(vertLumPerChroma-1))==(vertLumPerChroma-1) )\n\n\t\t{\n\n\t\t\tusrc += chromStride;\n\n\t\t\tvsrc += chromStride;\n\n\t\t}\n\n\t\tysrc += lumStride;\n\n\t\tdst += dstStride;\n\n\t}\n\n#ifdef HAVE_MMX\n\nasm(    EMMS\" \\n\\t\"\n\n        SFENCE\" \\n\\t\"\n\n        :::\"memory\");\n\n#endif\n\n}\n", "idx": 24467}
{"project": "FFmpeg", "commit_id": "69c1fe7c9c9bc85eebfc02c6a19caf7e88cd74ff", "target": 0, "func": "static int ass_get_duration(const uint8_t *p)\n\n{\n\n    int sh, sm, ss, sc, eh, em, es, ec;\n\n    uint64_t start, end;\n\n\n\n    if (sscanf(p, \"%*[^,],%d:%d:%d%*c%d,%d:%d:%d%*c%d\",\n\n               &sh, &sm, &ss, &sc, &eh, &em, &es, &ec) != 8)\n\n        return 0;\n\n    start = 3600000 * sh + 60000 * sm + 1000 * ss + 10 * sc;\n\n    end   = 3600000 * eh + 60000 * em + 1000 * es + 10 * ec;\n\n    return end - start;\n\n}\n", "idx": 24468}
{"project": "FFmpeg", "commit_id": "44273f19512f96a6e7bd1a4cbcec6c75c93ab488", "target": 0, "func": "static inline int msmpeg4_decode_block(MpegEncContext * s, DCTELEM * block,\n\n                              int n, int coded)\n\n{\n\n    int level, i, last, run, run_diff;\n\n    int dc_pred_dir;\n\n    RLTable *rl;\n\n    RL_VLC_ELEM *rl_vlc;\n\n    const UINT8 *scan_table;\n\n    int qmul, qadd;\n\n\n\n    if (s->mb_intra) {\n\n        qmul=1;\n\n        qadd=0;\n\n\n\n\t/* DC coef */\n\n        set_stat(ST_DC);\n\n        level = msmpeg4_decode_dc(s, n, &dc_pred_dir);\n\n#ifdef PRINT_MB\n\n{\n\n    static int c;\n\n    if(n==0) c=0;\n\n    if(n==4) printf(\"%X\", c);\n\n    c+= c +dc_pred_dir;\n\n}\n\n#endif\n\n        if (level < 0){\n\n            fprintf(stderr, \"dc overflow- block: %d qscale: %d//\\n\", n, s->qscale);\n\n            if(s->inter_intra_pred) level=0;\n\n            else                    return -1;\n\n        }\n\n        if (n < 4) {\n\n            rl = &rl_table[s->rl_table_index];\n\n            if(level > 256*s->y_dc_scale){\n\n                fprintf(stderr, \"dc overflow+ L qscale: %d//\\n\", s->qscale);\n\n                if(!s->inter_intra_pred) return -1;\n\n            }\n\n        } else {\n\n            rl = &rl_table[3 + s->rl_chroma_table_index];\n\n            if(level > 256*s->c_dc_scale){\n\n                fprintf(stderr, \"dc overflow+ C qscale: %d//\\n\", s->qscale);\n\n                if(!s->inter_intra_pred) return -1;\n\n            }\n\n        }\n\n        block[0] = level;\n\n\n\n        run_diff = 0;\n\n        i = 0;\n\n        if (!coded) {\n\n            goto not_coded;\n\n        }\n\n        if (s->ac_pred) {\n\n            if (dc_pred_dir == 0) \n\n                scan_table = s->intra_v_scantable; /* left */\n\n            else\n\n                scan_table = s->intra_h_scantable; /* top */\n\n        } else {\n\n            scan_table = s->intra_scantable;\n\n        }\n\n        set_stat(ST_INTRA_AC);\n\n        rl_vlc= rl->rl_vlc[0];\n\n    } else {\n\n        qmul = s->qscale << 1;\n\n        qadd = (s->qscale - 1) | 1;\n\n        i = -1;\n\n        rl = &rl_table[3 + s->rl_table_index];\n\n\n\n        if(s->msmpeg4_version==2)\n\n            run_diff = 0;\n\n        else\n\n            run_diff = 1;\n\n\n\n        if (!coded) {\n\n            s->block_last_index[n] = i;\n\n            return 0;\n\n        }\n\n        scan_table = s->inter_scantable;\n\n        set_stat(ST_INTER_AC);\n\n        rl_vlc= rl->rl_vlc[s->qscale];\n\n    }\n\n  {\n\n    OPEN_READER(re, &s->gb);\n\n    for(;;) {\n\n        UPDATE_CACHE(re, &s->gb);\n\n        GET_RL_VLC(level, run, re, &s->gb, rl_vlc, TEX_VLC_BITS, 2);\n\n        if (level==0) {\n\n            int cache;\n\n            cache= GET_CACHE(re, &s->gb);\n\n            /* escape */\n\n            if (s->msmpeg4_version==1 || (cache&0x80000000)==0) {\n\n                if (s->msmpeg4_version==1 || (cache&0x40000000)==0) {\n\n                    /* third escape */\n\n                    if(s->msmpeg4_version!=1) LAST_SKIP_BITS(re, &s->gb, 2);\n\n                    UPDATE_CACHE(re, &s->gb);\n\n                    if(s->msmpeg4_version<=3){\n\n                        last=  SHOW_UBITS(re, &s->gb, 1); SKIP_CACHE(re, &s->gb, 1);\n\n                        run=   SHOW_UBITS(re, &s->gb, 6); SKIP_CACHE(re, &s->gb, 6);\n\n                        level= SHOW_SBITS(re, &s->gb, 8); LAST_SKIP_CACHE(re, &s->gb, 8);\n\n                        SKIP_COUNTER(re, &s->gb, 1+6+8);\n\n                    }else{                        \n\n                        int sign;\n\n                        last=  SHOW_UBITS(re, &s->gb, 1); SKIP_BITS(re, &s->gb, 1);\n\n                        if(!s->esc3_level_length){\n\n                            int ll;\n\n                            //printf(\"ESC-3 %X at %d %d\\n\", show_bits(&s->gb, 24), s->mb_x, s->mb_y);\n\n                            if(s->qscale<8){\n\n                                ll= SHOW_UBITS(re, &s->gb, 3); SKIP_BITS(re, &s->gb, 3);\n\n                                if(ll==0){\n\n                                    if(SHOW_UBITS(re, &s->gb, 1)) printf(\"cool a new vlc code ,contact the ffmpeg developers and upload the file\\n\");\n\n                                    SKIP_BITS(re, &s->gb, 1);\n\n                                    ll=8;\n\n                                }\n\n                            }else{\n\n                                ll=2;\n\n                                while(ll<8 && SHOW_UBITS(re, &s->gb, 1)==0){\n\n                                    ll++;\n\n                                    SKIP_BITS(re, &s->gb, 1);\n\n                                }\n\n                                if(ll<8) SKIP_BITS(re, &s->gb, 1);\n\n                            }\n\n\n\n                            s->esc3_level_length= ll;\n\n                            s->esc3_run_length= SHOW_UBITS(re, &s->gb, 2) + 3; SKIP_BITS(re, &s->gb, 2);\n\n//printf(\"level length:%d, run length: %d\\n\", ll, s->esc3_run_length);\n\n                            UPDATE_CACHE(re, &s->gb);\n\n                        }\n\n                        run=   SHOW_UBITS(re, &s->gb, s->esc3_run_length); \n\n                        SKIP_BITS(re, &s->gb, s->esc3_run_length);\n\n                        \n\n                        sign=  SHOW_UBITS(re, &s->gb, 1); \n\n                        SKIP_BITS(re, &s->gb, 1);\n\n                        \n\n                        level= SHOW_UBITS(re, &s->gb, s->esc3_level_length); \n\n                        SKIP_BITS(re, &s->gb, s->esc3_level_length);\n\n                        if(sign) level= -level;\n\n                    }\n\n//printf(\"level: %d, run: %d at %d %d\\n\", level, run, s->mb_x, s->mb_y);\n\n#if 0 // waste of time / this will detect very few errors\n\n                    {\n\n                        const int abs_level= ABS(level);\n\n                        const int run1= run - rl->max_run[last][abs_level] - run_diff;\n\n                        if(abs_level<=MAX_LEVEL && run<=MAX_RUN){\n\n                            if(abs_level <= rl->max_level[last][run]){\n\n                                fprintf(stderr, \"illegal 3. esc, vlc encoding possible\\n\");\n\n                                return DECODING_AC_LOST;\n\n                            }\n\n                            if(abs_level <= rl->max_level[last][run]*2){\n\n                                fprintf(stderr, \"illegal 3. esc, esc 1 encoding possible\\n\");\n\n                                return DECODING_AC_LOST;\n\n                            }\n\n                            if(run1>=0 && abs_level <= rl->max_level[last][run1]){\n\n                                fprintf(stderr, \"illegal 3. esc, esc 2 encoding possible\\n\");\n\n                                return DECODING_AC_LOST;\n\n                            }\n\n                        }\n\n                    }\n\n#endif\n\n\t\t    //level = level * qmul + (level>0) * qadd - (level<=0) * qadd ;\n\n\t\t    if (level>0) level= level * qmul + qadd;\n\n                    else         level= level * qmul - qadd;\n\n#if 0 // waste of time too :(\n\n                    if(level>2048 || level<-2048){\n\n                        fprintf(stderr, \"|level| overflow in 3. esc\\n\");\n\n                        return DECODING_AC_LOST;\n\n                    }\n\n#endif\n\n                    i+= run + 1;\n\n                    if(last) i+=192;\n\n#ifdef ERROR_DETAILS\n\n                if(run==66)\n\n                    fprintf(stderr, \"illegal vlc code in ESC3 level=%d\\n\", level);\n\n                else if((i>62 && i<192) || i>192+63)\n\n                    fprintf(stderr, \"run overflow in ESC3 i=%d run=%d level=%d\\n\", i, run, level);\n\n#endif\n\n                } else {\n\n                    /* second escape */\n\n#if MIN_CACHE_BITS < 23\n\n                    LAST_SKIP_BITS(re, &s->gb, 2);\n\n                    UPDATE_CACHE(re, &s->gb);\n\n#else\n\n                    SKIP_BITS(re, &s->gb, 2);\n\n#endif\n\n                    GET_RL_VLC(level, run, re, &s->gb, rl_vlc, TEX_VLC_BITS, 2);\n\n                    i+= run + rl->max_run[run>>7][level/qmul] + run_diff; //FIXME opt indexing\n\n                    level = (level ^ SHOW_SBITS(re, &s->gb, 1)) - SHOW_SBITS(re, &s->gb, 1);\n\n                    LAST_SKIP_BITS(re, &s->gb, 1);\n\n#ifdef ERROR_DETAILS\n\n                if(run==66)\n\n                    fprintf(stderr, \"illegal vlc code in ESC2 level=%d\\n\", level);\n\n                else if((i>62 && i<192) || i>192+63)\n\n                    fprintf(stderr, \"run overflow in ESC2 i=%d run=%d level=%d\\n\", i, run, level);\n\n#endif\n\n                }\n\n            } else {\n\n                /* first escape */\n\n#if MIN_CACHE_BITS < 22\n\n                LAST_SKIP_BITS(re, &s->gb, 1);\n\n                UPDATE_CACHE(re, &s->gb);\n\n#else\n\n                SKIP_BITS(re, &s->gb, 1);\n\n#endif\n\n                GET_RL_VLC(level, run, re, &s->gb, rl_vlc, TEX_VLC_BITS, 2);\n\n                i+= run;\n\n                level = level + rl->max_level[run>>7][(run-1)&63] * qmul;//FIXME opt indexing\n\n                level = (level ^ SHOW_SBITS(re, &s->gb, 1)) - SHOW_SBITS(re, &s->gb, 1);\n\n                LAST_SKIP_BITS(re, &s->gb, 1);\n\n#ifdef ERROR_DETAILS\n\n                if(run==66)\n\n                    fprintf(stderr, \"illegal vlc code in ESC1 level=%d\\n\", level);\n\n                else if((i>62 && i<192) || i>192+63)\n\n                    fprintf(stderr, \"run overflow in ESC1 i=%d run=%d level=%d\\n\", i, run, level);\n\n#endif\n\n            }\n\n        } else {\n\n            i+= run;\n\n            level = (level ^ SHOW_SBITS(re, &s->gb, 1)) - SHOW_SBITS(re, &s->gb, 1);\n\n            LAST_SKIP_BITS(re, &s->gb, 1);\n\n#ifdef ERROR_DETAILS\n\n                if(run==66)\n\n                    fprintf(stderr, \"illegal vlc code level=%d\\n\", level);\n\n                else if((i>62 && i<192) || i>192+63)\n\n                    fprintf(stderr, \"run overflow i=%d run=%d level=%d\\n\", i, run, level);\n\n#endif\n\n        }\n\n        if (i > 62){\n\n            i-= 192;\n\n            if(i&(~63)){\n\n                if(i+192 == 64 && level/qmul==-1){\n\n                    fprintf(stderr, \"ignoring overflow at %d %d\\n\", s->mb_x, s->mb_y);\n\n                    break;\n\n                }else{\n\n                    fprintf(stderr, \"ac-tex damaged at %d %d\\n\", s->mb_x, s->mb_y);\n\n                    return -1;\n\n                }\n\n            }\n\n\n\n            block[scan_table[i]] = level;\n\n            break;\n\n        }\n\n\n\n        block[scan_table[i]] = level;\n\n    }\n\n    CLOSE_READER(re, &s->gb);\n\n  }\n\n not_coded:\n\n    if (s->mb_intra) {\n\n        mpeg4_pred_ac(s, block, n, dc_pred_dir);\n\n        if (s->ac_pred) {\n\n            i = 63; /* XXX: not optimal */\n\n        }\n\n    }\n\n    if(s->msmpeg4_version==4 && i>0) i=63; //FIXME/XXX optimize\n\n    s->block_last_index[n] = i;\n\n    \n\n    return 0;\n\n}\n", "idx": 24469}
{"project": "FFmpeg", "commit_id": "bacc4b6e8173fa944c24f297435dc507a60efb10", "target": 1, "func": "static void revert_acfilter(WmallDecodeCtx *s, int tile_size)\n\n{\n\n    int ich, pred, i, j;\n\n    int16_t *filter_coeffs = s->acfilter_coeffs;\n\n    int scaling            = s->acfilter_scaling;\n\n    int order              = s->acfilter_order;\n\n\n\n    for (ich = 0; ich < s->num_channels; ich++) {\n\n        int *prevvalues = s->acfilter_prevvalues[ich];\n\n        for (i = 0; i < order; i++) {\n\n            pred = 0;\n\n            for (j = 0; j < order; j++) {\n\n                if (i <= j)\n\n                    pred += filter_coeffs[j] * prevvalues[j - i];\n\n                else\n\n                    pred += s->channel_residues[ich][i - j - 1] * filter_coeffs[j];\n\n            }\n\n            pred >>= scaling;\n\n            s->channel_residues[ich][i] += pred;\n\n        }\n\n        for (i = order; i < tile_size; i++) {\n\n            pred = 0;\n\n            for (j = 0; j < order; j++)\n\n                pred += s->channel_residues[ich][i - j - 1] * filter_coeffs[j];\n\n            pred >>= scaling;\n\n            s->channel_residues[ich][i] += pred;\n\n        }\n\n        for (j = 0; j < order; j++)\n\n            prevvalues[j] = s->channel_residues[ich][tile_size - j - 1];\n\n    }\n\n}\n", "idx": 24471}
{"project": "FFmpeg", "commit_id": "d1916d13e28b87f4b1b214231149e12e1d536b4b", "target": 1, "func": "static void diff_bytes_c(uint8_t *dst, uint8_t *src1, uint8_t *src2, int w){\n\n    long i;\n\n#if !HAVE_FAST_UNALIGNED\n\n    if((long)src2 & (sizeof(long)-1)){\n\n        for(i=0; i+7<w; i+=8){\n\n            dst[i+0] = src1[i+0]-src2[i+0];\n\n            dst[i+1] = src1[i+1]-src2[i+1];\n\n            dst[i+2] = src1[i+2]-src2[i+2];\n\n            dst[i+3] = src1[i+3]-src2[i+3];\n\n            dst[i+4] = src1[i+4]-src2[i+4];\n\n            dst[i+5] = src1[i+5]-src2[i+5];\n\n            dst[i+6] = src1[i+6]-src2[i+6];\n\n            dst[i+7] = src1[i+7]-src2[i+7];\n\n        }\n\n    }else\n\n#endif\n\n    for(i=0; i<=w-sizeof(long); i+=sizeof(long)){\n\n        long a = *(long*)(src1+i);\n\n        long b = *(long*)(src2+i);\n\n        *(long*)(dst+i) = ((a|pb_80) - (b&pb_7f)) ^ ((a^b^pb_80)&pb_80);\n\n    }\n\n    for(; i<w; i++)\n\n        dst[i+0] = src1[i+0]-src2[i+0];\n\n}\n", "idx": 24472}
{"project": "FFmpeg", "commit_id": "07728a111583be6865b7ce2adea705af9d207588", "target": 1, "func": "static int decode_frame(AVCodecContext *avctx, void *data,\n\n                        int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    BinkAudioContext *s = avctx->priv_data;\n\n    AVFrame *frame      = data;\n\n    GetBitContext *gb = &s->gb;\n\n    int ret, consumed = 0;\n\n\n\n    if (!get_bits_left(gb)) {\n\n        uint8_t *buf;\n\n        /* handle end-of-stream */\n\n        if (!avpkt->size) {\n\n            *got_frame_ptr = 0;\n\n            return 0;\n\n        }\n\n        if (avpkt->size < 4) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        buf = av_realloc(s->packet_buffer, avpkt->size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!buf)\n\n            return AVERROR(ENOMEM);\n\n\n        s->packet_buffer = buf;\n\n        memcpy(s->packet_buffer, avpkt->data, avpkt->size);\n\n        if ((ret = init_get_bits8(gb, s->packet_buffer, avpkt->size)) < 0)\n\n            return ret;\n\n        consumed = avpkt->size;\n\n\n\n        /* skip reported size */\n\n        skip_bits_long(gb, 32);\n\n    }\n\n\n\n    /* get output buffer */\n\n    frame->nb_samples = s->frame_len;\n\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n\n        return ret;\n\n\n\n    if (decode_block(s, (float **)frame->extended_data,\n\n                     avctx->codec->id == AV_CODEC_ID_BINKAUDIO_DCT)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Incomplete packet\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    get_bits_align32(gb);\n\n\n\n    frame->nb_samples = s->block_size / avctx->channels;\n\n    *got_frame_ptr    = 1;\n\n\n\n    return consumed;\n\n}", "idx": 24475}
{"project": "FFmpeg", "commit_id": "5806e8cd1f60c67d936fa44dd4421428489503f5", "target": 0, "func": "static int decode_cabac_intra_mb_type(H264Context *h, int ctx_base, int intra_slice) {\n\n    uint8_t *state= &h->cabac_state[ctx_base];\n\n    int mb_type;\n\n\n\n    if(intra_slice){\n\n        MpegEncContext * const s = &h->s;\n\n        const int mba_xy = h->left_mb_xy[0];\n\n        const int mbb_xy = h->top_mb_xy;\n\n        int ctx=0;\n\n        if( h->slice_table[mba_xy] == h->slice_num && !IS_INTRA4x4( s->current_picture.mb_type[mba_xy] ) )\n\n            ctx++;\n\n        if( h->slice_table[mbb_xy] == h->slice_num && !IS_INTRA4x4( s->current_picture.mb_type[mbb_xy] ) )\n\n            ctx++;\n\n        if( get_cabac_noinline( &h->cabac, &state[ctx] ) == 0 )\n\n            return 0;   /* I4x4 */\n\n        state += 2;\n\n    }else{\n\n        if( get_cabac_noinline( &h->cabac, state ) == 0 )\n\n            return 0;   /* I4x4 */\n\n    }\n\n\n\n    if( get_cabac_terminate( &h->cabac ) )\n\n        return 25;  /* PCM */\n\n\n\n    mb_type = 1; /* I16x16 */\n\n    mb_type += 12 * get_cabac_noinline( &h->cabac, &state[1] ); /* cbp_luma != 0 */\n\n    if( get_cabac_noinline( &h->cabac, &state[2] ) ) /* cbp_chroma */\n\n        mb_type += 4 + 4 * get_cabac_noinline( &h->cabac, &state[2+intra_slice] );\n\n    mb_type += 2 * get_cabac_noinline( &h->cabac, &state[3+intra_slice] );\n\n    mb_type += 1 * get_cabac_noinline( &h->cabac, &state[3+2*intra_slice] );\n\n    return mb_type;\n\n}\n", "idx": 24476}
{"project": "FFmpeg", "commit_id": "e5540b3fd30367ce3cc33b2f34a04b660dbc4b38", "target": 0, "func": "static int decode_p_picture_header(VC9Context *v)\n\n{\n\n    /* INTERFRM, FRMCNT, RANGEREDFRM read in caller */\n\n    int lowquant, pqindex;\n\n\n\n    pqindex = get_bits(&v->gb, 5);\n\n    if (v->quantizer_mode == QUANT_FRAME_IMPLICIT)\n\n        v->pq = pquant_table[0][pqindex];\n\n    else\n\n    {\n\n        v->pq = pquant_table[v->quantizer_mode-1][pqindex];\n\n    }\n\n    if (pqindex < 9) v->halfpq = get_bits(&v->gb, 1);\n\n    if (v->quantizer_mode == QUANT_FRAME_EXPLICIT)\n\n        v->pquantizer = get_bits(&v->gb, 1);\n\n    av_log(v->avctx, AV_LOG_DEBUG, \"P Frame: QP=%i (+%i/2)\\n\",\n\n           v->pq, v->halfpq);\n\n    if (v->extended_mv == 1) v->mvrange = get_prefix(&v->gb, 0, 3);\n\n#if HAS_ADVANCED_PROFILE\n\n    if (v->profile > PROFILE_MAIN)\n\n    {\n\n        if (v->postprocflag) v->postproc = get_bits(&v->gb, 1);\n\n    }\n\n    else\n\n#endif\n\n        if (v->multires) v->respic = get_bits(&v->gb, 2);\n\n    lowquant = (v->pquantizer>12) ? 0 : 1;\n\n    v->mv_mode = mv_pmode_table[lowquant][get_prefix(&v->gb, 1, 4)];\n\n    if (v->mv_mode == MV_PMODE_INTENSITY_COMP)\n\n    {\n\n        v->mv_mode2 = mv_pmode_table[lowquant][get_prefix(&v->gb, 1, 3)];\n\n        v->lumscale = get_bits(&v->gb, 6);\n\n        v->lumshift = get_bits(&v->gb, 6);\n\n    }\n\n\n\n    if ((v->mv_mode == MV_PMODE_INTENSITY_COMP &&\n\n         v->mv_mode2 == MV_PMODE_MIXED_MV)\n\n        || v->mv_mode == MV_PMODE_MIXED_MV)\n\n    {\n\n        if (bitplane_decoding(v->mv_type_mb_plane, v->width_mb,\n\n                                  v->height_mb, v) < 0)\n\n            return -1;\n\n    }\n\n\n\n    if (bitplane_decoding(v->skip_mb_plane, v->width_mb,\n\n                              v->height_mb, v) < 0)\n\n        return -1;\n\n\n\n    /* Hopefully this is correct for P frames */\n\n    v->mv_diff_vlc = &vc9_mv_diff_vlc[get_bits(&v->gb, 2)];\n\n    v->cbpcy_vlc = &vc9_cbpcy_p_vlc[get_bits(&v->gb, 2)];\n\n\n\n    if (v->dquant)\n\n    {\n\n        av_log(v->avctx, AV_LOG_INFO, \"VOP DQuant info\\n\");\n\n        vop_dquant_decoding(v);\n\n    }\n\n\n\n    if (v->vstransform)\n\n    {\n\n        v->ttmbf = get_bits(&v->gb, 1);\n\n        if (v->ttmbf)\n\n        {\n\n            v->ttfrm = get_bits(&v->gb, 2);\n\n            av_log(v->avctx, AV_LOG_INFO, \"Transform used: %ix%i\\n\",\n\n                   (v->ttfrm & 2) ? 4 : 8, (v->ttfrm & 1) ? 4 : 8);\n\n        }\n\n    }\n\n    /* Epilog should be done in caller */\n\n    return 0;\n\n}\n", "idx": 24477}
{"project": "FFmpeg", "commit_id": "cb85779d459c6486acbbf060b3f169779424583e", "target": 0, "func": "static int decode_frame(AVCodecContext *avctx,\n\n                        void *data,\n\n                        int *got_frame,\n\n                        AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    DPXContext *const s = avctx->priv_data;\n\n    AVFrame *picture  = data;\n\n    AVFrame *const p = &s->picture;\n\n    uint8_t *ptr[AV_NUM_DATA_POINTERS];\n\n\n\n    unsigned int offset;\n\n    int magic_num, endian;\n\n    int x, y, i, ret;\n\n    int w, h, bits_per_color, descriptor, elements, packing, total_size;\n\n\n\n    unsigned int rgbBuffer = 0;\n\n    int n_datum = 0;\n\n\n\n    if (avpkt->size <= 1634) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Packet too small for DPX header\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    magic_num = AV_RB32(buf);\n\n    buf += 4;\n\n\n\n    /* Check if the files \"magic number\" is \"SDPX\" which means it uses\n\n     * big-endian or XPDS which is for little-endian files */\n\n    if (magic_num == AV_RL32(\"SDPX\")) {\n\n        endian = 0;\n\n    } else if (magic_num == AV_RB32(\"SDPX\")) {\n\n        endian = 1;\n\n    } else {\n\n        av_log(avctx, AV_LOG_ERROR, \"DPX marker not found\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    offset = read32(&buf, endian);\n\n    if (avpkt->size <= offset) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid data start offset\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    // Need to end in 0x304 offset from start of file\n\n    buf = avpkt->data + 0x304;\n\n    w = read32(&buf, endian);\n\n    h = read32(&buf, endian);\n\n    if ((ret = av_image_check_size(w, h, 0, avctx)) < 0)\n\n        return ret;\n\n\n\n    if (w != avctx->width || h != avctx->height)\n\n        avcodec_set_dimensions(avctx, w, h);\n\n\n\n    // Need to end in 0x320 to read the descriptor\n\n    buf += 20;\n\n    descriptor = buf[0];\n\n\n\n    // Need to end in 0x323 to read the bits per color\n\n    buf += 3;\n\n    avctx->bits_per_raw_sample =\n\n    bits_per_color = buf[0];\n\n    buf++;\n\n    packing = *((uint16_t*)buf);\n\n\n\n    buf += 824;\n\n    avctx->sample_aspect_ratio.num = read32(&buf, endian);\n\n    avctx->sample_aspect_ratio.den = read32(&buf, endian);\n\n    if (avctx->sample_aspect_ratio.num > 0 && avctx->sample_aspect_ratio.den > 0)\n\n        av_reduce(&avctx->sample_aspect_ratio.num, &avctx->sample_aspect_ratio.den,\n\n                   avctx->sample_aspect_ratio.num,  avctx->sample_aspect_ratio.den,\n\n                  0x10000);\n\n    else\n\n        avctx->sample_aspect_ratio = (AVRational){ 0, 1 };\n\n\n\n    switch (descriptor) {\n\n        case 51: // RGBA\n\n            elements = 4;\n\n            break;\n\n        case 50: // RGB\n\n            elements = 3;\n\n            break;\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unsupported descriptor %d\\n\", descriptor);\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    switch (bits_per_color) {\n\n        case 8:\n\n            if (elements == 4) {\n\n                avctx->pix_fmt = AV_PIX_FMT_RGBA;\n\n            } else {\n\n                avctx->pix_fmt = AV_PIX_FMT_RGB24;\n\n            }\n\n            total_size = avctx->width * avctx->height * elements;\n\n            break;\n\n        case 10:\n\n            if (!packing) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Packing to 32bit required\\n\");\n\n                return -1;\n\n            }\n\n            avctx->pix_fmt = AV_PIX_FMT_GBRP10;\n\n            total_size = (avctx->width * avctx->height * elements + 2) / 3 * 4;\n\n            break;\n\n        case 12:\n\n            if (!packing) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Packing to 16bit required\\n\");\n\n                return -1;\n\n            }\n\n            if (endian) {\n\n                avctx->pix_fmt = AV_PIX_FMT_GBRP12BE;\n\n            } else {\n\n                avctx->pix_fmt = AV_PIX_FMT_GBRP12LE;\n\n            }\n\n            total_size = 2 * avctx->width * avctx->height * elements;\n\n            break;\n\n        case 16:\n\n            if (endian) {\n\n                avctx->pix_fmt = elements == 4 ? AV_PIX_FMT_RGBA64BE : AV_PIX_FMT_RGB48BE;\n\n            } else {\n\n                avctx->pix_fmt = elements == 4 ? AV_PIX_FMT_RGBA64LE : AV_PIX_FMT_RGB48LE;\n\n            }\n\n            total_size = 2 * avctx->width * avctx->height * elements;\n\n            break;\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unsupported color depth : %d\\n\", bits_per_color);\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->picture.data[0])\n\n        avctx->release_buffer(avctx, &s->picture);\n\n    if ((ret = ff_get_buffer(avctx, p)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n\n\n    // Move pointer to offset from start of file\n\n    buf =  avpkt->data + offset;\n\n\n\n    for (i=0; i<AV_NUM_DATA_POINTERS; i++)\n\n        ptr[i] = p->data[i];\n\n\n\n    if (total_size > avpkt->size) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Overread buffer. Invalid header?\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    switch (bits_per_color) {\n\n    case 10:\n\n        for (x = 0; x < avctx->height; x++) {\n\n            uint16_t *dst[3] = {(uint16_t*)ptr[0],\n\n                                (uint16_t*)ptr[1],\n\n                                (uint16_t*)ptr[2]};\n\n            for (y = 0; y < avctx->width; y++) {\n\n                *dst[2]++ = read10in32(&buf, &rgbBuffer,\n\n                                       &n_datum, endian);\n\n                *dst[0]++ = read10in32(&buf, &rgbBuffer,\n\n                                       &n_datum, endian);\n\n                *dst[1]++ = read10in32(&buf, &rgbBuffer,\n\n                                       &n_datum, endian);\n\n                // For 10 bit, ignore alpha\n\n                if (elements == 4)\n\n                    read10in32(&buf, &rgbBuffer,\n\n                               &n_datum, endian);\n\n            }\n\n            for (i = 0; i < 3; i++)\n\n                ptr[i] += p->linesize[i];\n\n        }\n\n        break;\n\n    case 12:\n\n        for (x = 0; x < avctx->height; x++) {\n\n            uint16_t *dst[3] = {(uint16_t*)ptr[0],\n\n                                (uint16_t*)ptr[1],\n\n                                (uint16_t*)ptr[2]};\n\n            for (y = 0; y < avctx->width; y++) {\n\n                *dst[2] = *((uint16_t*)buf);\n\n                *dst[2] = (*dst[2] >> 4) | (*dst[2] << 12);\n\n                dst[2]++;\n\n                buf += 2;\n\n                *dst[0] = *((uint16_t*)buf);\n\n                *dst[0] = (*dst[0] >> 4) | (*dst[0] << 12);\n\n                dst[0]++;\n\n                buf += 2;\n\n                *dst[1] = *((uint16_t*)buf);\n\n                *dst[1] = (*dst[1] >> 4) | (*dst[1] << 12);\n\n                dst[1]++;\n\n                buf += 2;\n\n                // For 12 bit, ignore alpha\n\n                if (elements == 4)\n\n                    buf += 2;\n\n            }\n\n            for (i = 0; i < 3; i++)\n\n                ptr[i] += p->linesize[i];\n\n        }\n\n        break;\n\n    case 16:\n\n        elements *= 2;\n\n    case 8:\n\n        for (x = 0; x < avctx->height; x++) {\n\n            memcpy(ptr[0], buf, elements*avctx->width);\n\n            ptr[0] += p->linesize[0];\n\n            buf += elements*avctx->width;\n\n        }\n\n        break;\n\n    }\n\n\n\n    *picture   = s->picture;\n\n    *got_frame = 1;\n\n\n\n    return buf_size;\n\n}\n", "idx": 24478}
{"project": "FFmpeg", "commit_id": "72dbc610be3272ba36603f78a39cc2d2d8fe0cc3", "target": 0, "func": "void ff_avg_h264_qpel8_mc12_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_midh_qrt_and_aver_dst_8w_msa(src - (2 * stride) - 2,\n\n                                          stride, dst, stride, 8, 0);\n\n}\n", "idx": 24479}
{"project": "FFmpeg", "commit_id": "aac46e088d67a390489af686b846dea4987d8ffb", "target": 0, "func": "static void sbr_hf_assemble(float Y[2][38][64][2], const float X_high[64][40][2],\n\n                            SpectralBandReplication *sbr, SBRData *ch_data,\n\n                            const int e_a[2])\n\n{\n\n    int e, i, j, m;\n\n    const int h_SL = 4 * !sbr->bs_smoothing_mode;\n\n    const int kx = sbr->kx[1];\n\n    const int m_max = sbr->m[1];\n\n    static const float h_smooth[5] = {\n\n        0.33333333333333,\n\n        0.30150283239582,\n\n        0.21816949906249,\n\n        0.11516383427084,\n\n        0.03183050093751,\n\n    };\n\n    static const int8_t phi[2][4] = {\n\n        {  1,  0, -1,  0}, // real\n\n        {  0,  1,  0, -1}, // imaginary\n\n    };\n\n    float (*g_temp)[48] = ch_data->g_temp, (*q_temp)[48] = ch_data->q_temp;\n\n    int indexnoise = ch_data->f_indexnoise;\n\n    int indexsine  = ch_data->f_indexsine;\n\n    memcpy(Y[0], Y[1], sizeof(Y[0]));\n\n\n\n    if (sbr->reset) {\n\n        for (i = 0; i < h_SL; i++) {\n\n            memcpy(g_temp[i + 2*ch_data->t_env[0]], sbr->gain[0], m_max * sizeof(sbr->gain[0][0]));\n\n            memcpy(q_temp[i + 2*ch_data->t_env[0]], sbr->q_m[0],  m_max * sizeof(sbr->q_m[0][0]));\n\n        }\n\n    } else if (h_SL) {\n\n        memcpy(g_temp[2*ch_data->t_env[0]], g_temp[2*ch_data->t_env_num_env_old], 4*sizeof(g_temp[0]));\n\n        memcpy(q_temp[2*ch_data->t_env[0]], q_temp[2*ch_data->t_env_num_env_old], 4*sizeof(q_temp[0]));\n\n    }\n\n\n\n    for (e = 0; e < ch_data->bs_num_env; e++) {\n\n        for (i = 2 * ch_data->t_env[e]; i < 2 * ch_data->t_env[e + 1]; i++) {\n\n            memcpy(g_temp[h_SL + i], sbr->gain[e], m_max * sizeof(sbr->gain[0][0]));\n\n            memcpy(q_temp[h_SL + i], sbr->q_m[e],  m_max * sizeof(sbr->q_m[0][0]));\n\n        }\n\n    }\n\n\n\n    for (e = 0; e < ch_data->bs_num_env; e++) {\n\n        for (i = 2 * ch_data->t_env[e]; i < 2 * ch_data->t_env[e + 1]; i++) {\n\n            int phi_sign = (1 - 2*(kx & 1));\n\n\n\n            if (h_SL && e != e_a[0] && e != e_a[1]) {\n\n                for (m = 0; m < m_max; m++) {\n\n                    const int idx1 = i + h_SL;\n\n                    float g_filt = 0.0f;\n\n                    for (j = 0; j <= h_SL; j++)\n\n                        g_filt += g_temp[idx1 - j][m] * h_smooth[j];\n\n                    Y[1][i][m + kx][0] =\n\n                        X_high[m + kx][i + ENVELOPE_ADJUSTMENT_OFFSET][0] * g_filt;\n\n                    Y[1][i][m + kx][1] =\n\n                        X_high[m + kx][i + ENVELOPE_ADJUSTMENT_OFFSET][1] * g_filt;\n\n                }\n\n            } else {\n\n                for (m = 0; m < m_max; m++) {\n\n                    const float g_filt = g_temp[i + h_SL][m];\n\n                    Y[1][i][m + kx][0] =\n\n                        X_high[m + kx][i + ENVELOPE_ADJUSTMENT_OFFSET][0] * g_filt;\n\n                    Y[1][i][m + kx][1] =\n\n                        X_high[m + kx][i + ENVELOPE_ADJUSTMENT_OFFSET][1] * g_filt;\n\n                }\n\n            }\n\n\n\n            if (e != e_a[0] && e != e_a[1]) {\n\n                for (m = 0; m < m_max; m++) {\n\n                    indexnoise = (indexnoise + 1) & 0x1ff;\n\n                    if (sbr->s_m[e][m]) {\n\n                        Y[1][i][m + kx][0] +=\n\n                            sbr->s_m[e][m] * phi[0][indexsine];\n\n                        Y[1][i][m + kx][1] +=\n\n                            sbr->s_m[e][m] * (phi[1][indexsine] * phi_sign);\n\n                    } else {\n\n                        float q_filt;\n\n                        if (h_SL) {\n\n                            const int idx1 = i + h_SL;\n\n                            q_filt = 0.0f;\n\n                            for (j = 0; j <= h_SL; j++)\n\n                                q_filt += q_temp[idx1 - j][m] * h_smooth[j];\n\n                        } else {\n\n                            q_filt = q_temp[i][m];\n\n                        }\n\n                        Y[1][i][m + kx][0] +=\n\n                            q_filt * sbr_noise_table[indexnoise][0];\n\n                        Y[1][i][m + kx][1] +=\n\n                            q_filt * sbr_noise_table[indexnoise][1];\n\n                    }\n\n                    phi_sign = -phi_sign;\n\n                }\n\n            } else {\n\n                indexnoise = (indexnoise + m_max) & 0x1ff;\n\n                for (m = 0; m < m_max; m++) {\n\n                    Y[1][i][m + kx][0] +=\n\n                        sbr->s_m[e][m] * phi[0][indexsine];\n\n                    Y[1][i][m + kx][1] +=\n\n                        sbr->s_m[e][m] * (phi[1][indexsine] * phi_sign);\n\n                    phi_sign = -phi_sign;\n\n                }\n\n            }\n\n            indexsine = (indexsine + 1) & 3;\n\n        }\n\n    }\n\n    ch_data->f_indexnoise = indexnoise;\n\n    ch_data->f_indexsine  = indexsine;\n\n}\n", "idx": 24480}
{"project": "FFmpeg", "commit_id": "c8dcff0cdb17d0aa03ac729eba12d1a20f1f59c8", "target": 0, "func": "int ff_init_poc(H264Context *h, int pic_field_poc[2], int *pic_poc)\n\n{\n\n    const SPS *sps = h->ps.sps;\n\n    const int max_frame_num = 1 << sps->log2_max_frame_num;\n\n    int field_poc[2];\n\n\n\n    h->frame_num_offset = h->prev_frame_num_offset;\n\n    if (h->frame_num < h->prev_frame_num)\n\n        h->frame_num_offset += max_frame_num;\n\n\n\n    if (sps->poc_type == 0) {\n\n        const int max_poc_lsb = 1 << sps->log2_max_poc_lsb;\n\n\n\n        if (h->poc_lsb < h->prev_poc_lsb &&\n\n            h->prev_poc_lsb - h->poc_lsb >= max_poc_lsb / 2)\n\n            h->poc_msb = h->prev_poc_msb + max_poc_lsb;\n\n        else if (h->poc_lsb > h->prev_poc_lsb &&\n\n                 h->prev_poc_lsb - h->poc_lsb < -max_poc_lsb / 2)\n\n            h->poc_msb = h->prev_poc_msb - max_poc_lsb;\n\n        else\n\n            h->poc_msb = h->prev_poc_msb;\n\n        field_poc[0] =\n\n        field_poc[1] = h->poc_msb + h->poc_lsb;\n\n        if (h->picture_structure == PICT_FRAME)\n\n            field_poc[1] += h->delta_poc_bottom;\n\n    } else if (sps->poc_type == 1) {\n\n        int abs_frame_num, expected_delta_per_poc_cycle, expectedpoc;\n\n        int i;\n\n\n\n        if (sps->poc_cycle_length != 0)\n\n            abs_frame_num = h->frame_num_offset + h->frame_num;\n\n        else\n\n            abs_frame_num = 0;\n\n\n\n        if (h->nal_ref_idc == 0 && abs_frame_num > 0)\n\n            abs_frame_num--;\n\n\n\n        expected_delta_per_poc_cycle = 0;\n\n        for (i = 0; i < sps->poc_cycle_length; i++)\n\n            // FIXME integrate during sps parse\n\n            expected_delta_per_poc_cycle += sps->offset_for_ref_frame[i];\n\n\n\n        if (abs_frame_num > 0) {\n\n            int poc_cycle_cnt          = (abs_frame_num - 1) / sps->poc_cycle_length;\n\n            int frame_num_in_poc_cycle = (abs_frame_num - 1) % sps->poc_cycle_length;\n\n\n\n            expectedpoc = poc_cycle_cnt * expected_delta_per_poc_cycle;\n\n            for (i = 0; i <= frame_num_in_poc_cycle; i++)\n\n                expectedpoc = expectedpoc + sps->offset_for_ref_frame[i];\n\n        } else\n\n            expectedpoc = 0;\n\n\n\n        if (h->nal_ref_idc == 0)\n\n            expectedpoc = expectedpoc + sps->offset_for_non_ref_pic;\n\n\n\n        field_poc[0] = expectedpoc + h->delta_poc[0];\n\n        field_poc[1] = field_poc[0] + sps->offset_for_top_to_bottom_field;\n\n\n\n        if (h->picture_structure == PICT_FRAME)\n\n            field_poc[1] += h->delta_poc[1];\n\n    } else {\n\n        int poc = 2 * (h->frame_num_offset + h->frame_num);\n\n\n\n        if (!h->nal_ref_idc)\n\n            poc--;\n\n\n\n        field_poc[0] = poc;\n\n        field_poc[1] = poc;\n\n    }\n\n\n\n    if (h->picture_structure != PICT_BOTTOM_FIELD)\n\n        pic_field_poc[0] = field_poc[0];\n\n    if (h->picture_structure != PICT_TOP_FIELD)\n\n        pic_field_poc[1] = field_poc[1];\n\n    *pic_poc = FFMIN(pic_field_poc[0], pic_field_poc[1]);\n\n\n\n    return 0;\n\n}\n", "idx": 24481}
{"project": "FFmpeg", "commit_id": "abb5e37f64c48bba8bd0fde2bada0f7544defa24", "target": 1, "func": "int ff_filter_frame(AVFilterLink *link, AVFrame *frame)\n\n{\n\n    int (*filter_frame)(AVFilterLink *, AVFrame *);\n\n    AVFilterPad *dst = link->dstpad;\n\n    AVFrame *out;\n\n\n\n    FF_DPRINTF_START(NULL, filter_frame);\n\n    ff_dlog_link(NULL, link, 1);\n\n\n\n    if (!(filter_frame = dst->filter_frame))\n\n        filter_frame = default_filter_frame;\n\n\n\n    /* copy the frame if needed */\n\n    if (dst->needs_writable && !av_frame_is_writable(frame)) {\n\n        av_log(link->dst, AV_LOG_DEBUG, \"Copying data in avfilter.\\n\");\n\n\n\n        switch (link->type) {\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            out = ff_get_video_buffer(link, link->w, link->h);\n\n            break;\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            out = ff_get_audio_buffer(link, frame->nb_samples);\n\n            break;\n\n        default: return AVERROR(EINVAL);\n\n        }\n\n        if (!out) {\n\n            av_frame_free(&frame);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        av_frame_copy_props(out, frame);\n\n\n\n        switch (link->type) {\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            av_image_copy(out->data, out->linesize, frame->data, frame->linesize,\n\n                          frame->format, frame->width, frame->height);\n\n            break;\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            av_samples_copy(out->extended_data, frame->extended_data,\n\n                            0, 0, frame->nb_samples,\n\n                            av_get_channel_layout_nb_channels(frame->channel_layout),\n\n                            frame->format);\n\n            break;\n\n        default: return AVERROR(EINVAL);\n\n        }\n\n\n\n        av_frame_free(&frame);\n\n    } else\n\n        out = frame;\n\n\n\n    return filter_frame(link, out);\n\n}\n", "idx": 24484}
{"project": "FFmpeg", "commit_id": "078d43e23a7a3d64aafee8a58b380d3e139b3020", "target": 1, "func": "static int sdp_parse_rtpmap(AVFormatContext *s,\n\n                            AVStream *st, RTSPStream *rtsp_st,\n\n                            int payload_type, const char *p)\n\n{\n\n    AVCodecContext *codec = st->codec;\n\n    char buf[256];\n\n    int i;\n\n    AVCodec *c;\n\n    const char *c_name;\n\n\n\n    /* See if we can handle this kind of payload.\n\n     * The space should normally not be there but some Real streams or\n\n     * particular servers (\"RealServer Version 6.1.3.970\", see issue 1658)\n\n     * have a trailing space. */\n\n    get_word_sep(buf, sizeof(buf), \"/ \", &p);\n\n    if (payload_type < RTP_PT_PRIVATE) {\n\n        /* We are in a standard case\n\n         * (from http://www.iana.org/assignments/rtp-parameters). */\n\n        codec->codec_id = ff_rtp_codec_id(buf, codec->codec_type);\n\n    }\n\n\n\n    if (codec->codec_id == AV_CODEC_ID_NONE) {\n\n        RTPDynamicProtocolHandler *handler =\n\n            ff_rtp_handler_find_by_name(buf, codec->codec_type);\n\n        init_rtp_handler(handler, rtsp_st, st);\n\n        /* If no dynamic handler was found, check with the list of standard\n\n         * allocated types, if such a stream for some reason happens to\n\n         * use a private payload type. This isn't handled in rtpdec.c, since\n\n         * the format name from the rtpmap line never is passed into rtpdec. */\n\n        if (!rtsp_st->dynamic_handler)\n\n            codec->codec_id = ff_rtp_codec_id(buf, codec->codec_type);\n\n    }\n\n\n\n    c = avcodec_find_decoder(codec->codec_id);\n\n    if (c && c->name)\n\n        c_name = c->name;\n\n    else\n\n        c_name = \"(null)\";\n\n\n\n    get_word_sep(buf, sizeof(buf), \"/\", &p);\n\n    i = atoi(buf);\n\n    switch (codec->codec_type) {\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        av_log(s, AV_LOG_DEBUG, \"audio codec set to: %s\\n\", c_name);\n\n        codec->sample_rate = RTSP_DEFAULT_AUDIO_SAMPLERATE;\n\n        codec->channels = RTSP_DEFAULT_NB_AUDIO_CHANNELS;\n\n        if (i > 0) {\n\n            codec->sample_rate = i;\n\n            avpriv_set_pts_info(st, 32, 1, codec->sample_rate);\n\n            get_word_sep(buf, sizeof(buf), \"/\", &p);\n\n            i = atoi(buf);\n\n            if (i > 0)\n\n                codec->channels = i;\n\n        }\n\n        av_log(s, AV_LOG_DEBUG, \"audio samplerate set to: %i\\n\",\n\n               codec->sample_rate);\n\n        av_log(s, AV_LOG_DEBUG, \"audio channels set to: %i\\n\",\n\n               codec->channels);\n\n        break;\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        av_log(s, AV_LOG_DEBUG, \"video codec set to: %s\\n\", c_name);\n\n        if (i > 0)\n\n            avpriv_set_pts_info(st, 32, 1, i);\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n    if (rtsp_st->dynamic_handler && rtsp_st->dynamic_handler->init)\n\n        rtsp_st->dynamic_handler->init(s, st->index,\n\n                                       rtsp_st->dynamic_protocol_context);\n\n    return 0;\n\n}\n", "idx": 24487}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "void ff_h264_filter_mb_fast(const H264Context *h, H264SliceContext *sl,\n\n                            int mb_x, int mb_y, uint8_t *img_y,\n\n                            uint8_t *img_cb, uint8_t *img_cr,\n\n                            unsigned int linesize, unsigned int uvlinesize)\n\n{\n\n    assert(!FRAME_MBAFF(h));\n\n    if(!h->h264dsp.h264_loop_filter_strength || h->pps.chroma_qp_diff) {\n\n        ff_h264_filter_mb(h, sl, mb_x, mb_y, img_y, img_cb, img_cr, linesize, uvlinesize);\n\n        return;\n\n    }\n\n\n\n#if CONFIG_SMALL\n\n    h264_filter_mb_fast_internal(h, sl, mb_x, mb_y, img_y, img_cb, img_cr, linesize, uvlinesize, h->pixel_shift);\n\n#else\n\n    if(h->pixel_shift){\n\n        h264_filter_mb_fast_internal(h, sl, mb_x, mb_y, img_y, img_cb, img_cr, linesize, uvlinesize, 1);\n\n    }else{\n\n        h264_filter_mb_fast_internal(h, sl, mb_x, mb_y, img_y, img_cb, img_cr, linesize, uvlinesize, 0);\n\n    }\n\n#endif\n\n}\n", "idx": 24488}
{"project": "FFmpeg", "commit_id": "28f9ab7029bd1a02f659995919f899f84ee7361b", "target": 0, "func": "void ff_dsputil_init_ppc(DSPContext* c, AVCodecContext *avctx)\n\n{\n\n    const int high_bit_depth = avctx->bits_per_raw_sample > 8;\n\n\n\n    // Common optimizations whether AltiVec is available or not\n\n    c->prefetch = prefetch_ppc;\n\n    if (!high_bit_depth) {\n\n    switch (check_dcbzl_effect()) {\n\n        case 32:\n\n            c->clear_blocks = clear_blocks_dcbz32_ppc;\n\n            break;\n\n        case 128:\n\n            c->clear_blocks = clear_blocks_dcbz128_ppc;\n\n            break;\n\n        default:\n\n            break;\n\n    }\n\n    }\n\n\n\n#if HAVE_ALTIVEC\n\n    if(CONFIG_H264_DECODER) ff_dsputil_h264_init_ppc(c, avctx);\n\n\n\n    if (av_get_cpu_flags() & AV_CPU_FLAG_ALTIVEC) {\n\n        ff_dsputil_init_altivec(c, avctx);\n\n        ff_float_init_altivec(c, avctx);\n\n        ff_int_init_altivec(c, avctx);\n\n        c->gmc1 = ff_gmc1_altivec;\n\n\n\n#if CONFIG_ENCODERS\n\n        if (avctx->bits_per_raw_sample <= 8 &&\n\n            (avctx->dct_algo == FF_DCT_AUTO ||\n\n             avctx->dct_algo == FF_DCT_ALTIVEC)) {\n\n            c->fdct = ff_fdct_altivec;\n\n        }\n\n#endif //CONFIG_ENCODERS\n\n\n\n        if (avctx->bits_per_raw_sample <= 8) {\n\n            if ((avctx->idct_algo == FF_IDCT_AUTO) ||\n\n                (avctx->idct_algo == FF_IDCT_ALTIVEC)) {\n\n                c->idct_put = ff_idct_put_altivec;\n\n                c->idct_add = ff_idct_add_altivec;\n\n                c->idct_permutation_type = FF_TRANSPOSE_IDCT_PERM;\n\n            }else if((CONFIG_VP3_DECODER || CONFIG_VP5_DECODER || CONFIG_VP6_DECODER) &&\n\n                     avctx->idct_algo==FF_IDCT_VP3){\n\n                c->idct_put = ff_vp3_idct_put_altivec;\n\n                c->idct_add = ff_vp3_idct_add_altivec;\n\n                c->idct     = ff_vp3_idct_altivec;\n\n                c->idct_permutation_type = FF_TRANSPOSE_IDCT_PERM;\n\n            }\n\n        }\n\n\n\n    }\n\n#endif /* HAVE_ALTIVEC */\n\n}\n", "idx": 24489}
{"project": "FFmpeg", "commit_id": "f6e1c96730ebbcebbd0341329d51d3d3a36b4fa1", "target": 1, "func": "static int ffm_is_avail_data(AVFormatContext *s, int size)\n\n{\n\n    FFMContext *ffm = s->priv_data;\n\n    int64_t pos, avail_size;\n\n    int len;\n\n\n\n    len = ffm->packet_end - ffm->packet_ptr;\n\n    if (size <= len)\n\n        return 1;\n\n    pos = avio_tell(s->pb);\n\n    if (!ffm->write_index) {\n\n        if (pos == ffm->file_size)\n\n            return AVERROR_EOF;\n\n        avail_size = ffm->file_size - pos;\n\n    } else {\n\n    if (pos == ffm->write_index) {\n\n        /* exactly at the end of stream */\n\n        if (ffm->server_attached)\n\n            return AVERROR(EAGAIN);\n\n        else\n\n            return AVERROR_INVALIDDATA;\n\n    } else if (pos < ffm->write_index) {\n\n        avail_size = ffm->write_index - pos;\n\n    } else {\n\n        avail_size = (ffm->file_size - pos) + (ffm->write_index - FFM_PACKET_SIZE);\n\n    }\n\n    }\n\n    avail_size = (avail_size / ffm->packet_size) * (ffm->packet_size - FFM_HEADER_SIZE) + len;\n\n    if (size <= avail_size)\n\n        return 1;\n\n    else if (ffm->server_attached)\n\n        return AVERROR(EAGAIN);\n\n    else\n\n        return AVERROR_INVALIDDATA;\n\n}\n", "idx": 24491}
{"project": "FFmpeg", "commit_id": "aeb59e839f97e88dd0b5f0b2a4422a9ee75321e5", "target": 1, "func": "static int execute_ref_pic_marking(H264Context *h, MMCO *mmco, int mmco_count){\n    MpegEncContext * const s = &h->s;\n    int i, j;\n    int current_ref_assigned=0;\n    Picture *pic;\n    if((s->avctx->debug&FF_DEBUG_MMCO) && mmco_count==0)\n        av_log(h->s.avctx, AV_LOG_DEBUG, \"no mmco here\\n\");\n    for(i=0; i<mmco_count; i++){\n        int structure, frame_num, unref_pic;\n        if(s->avctx->debug&FF_DEBUG_MMCO)\n            av_log(h->s.avctx, AV_LOG_DEBUG, \"mmco:%d %d %d\\n\", h->mmco[i].opcode, h->mmco[i].short_pic_num, h->mmco[i].long_arg);\n        switch(mmco[i].opcode){\n        case MMCO_SHORT2UNUSED:\n            if(s->avctx->debug&FF_DEBUG_MMCO)\n                av_log(h->s.avctx, AV_LOG_DEBUG, \"mmco: unref short %d count %d\\n\", h->mmco[i].short_pic_num, h->short_ref_count);\n            frame_num = pic_num_extract(h, mmco[i].short_pic_num, &structure);\n            pic = find_short(h, frame_num, &j);\n            if (pic) {\n                if (unreference_pic(h, pic, structure ^ PICT_FRAME))\n                    remove_short_at_index(h, j);\n            } else if(s->avctx->debug&FF_DEBUG_MMCO)\n                av_log(h->s.avctx, AV_LOG_DEBUG, \"mmco: unref short failure\\n\");\n        case MMCO_SHORT2LONG:\n            if (FIELD_PICTURE && mmco[i].long_arg < h->long_ref_count &&\n                    h->long_ref[mmco[i].long_arg]->frame_num ==\n                                              mmco[i].short_pic_num / 2) {\n                /* do nothing, we've already moved this field pair. */\n                int frame_num = mmco[i].short_pic_num >> FIELD_PICTURE;\n                pic= remove_long(h, mmco[i].long_arg);\n                if(pic) unreference_pic(h, pic, 0);\n                h->long_ref[ mmco[i].long_arg ]= remove_short(h, frame_num);\n                if (h->long_ref[ mmco[i].long_arg ]){\n                    h->long_ref[ mmco[i].long_arg ]->long_ref=1;\n                    h->long_ref_count++;\n        case MMCO_LONG2UNUSED:\n            j = pic_num_extract(h, mmco[i].long_arg, &structure);\n            pic = h->long_ref[j];\n            if (pic) {\n                if (unreference_pic(h, pic, structure ^ PICT_FRAME))\n                    remove_long_at_index(h, j);\n            } else if(s->avctx->debug&FF_DEBUG_MMCO)\n                av_log(h->s.avctx, AV_LOG_DEBUG, \"mmco: unref long failure\\n\");\n        case MMCO_LONG:\n            unref_pic = 1;\n            if (FIELD_PICTURE && !s->first_field) {\n                if (h->long_ref[mmco[i].long_arg] == s->current_picture_ptr) {\n                    /* Just mark second field as referenced */\n                    unref_pic = 0;\n                } else if (s->current_picture_ptr->reference) {\n                    /* First field in pair is in short term list or\n                     * at a different long term index.\n                     * This is not allowed; see 7.4.3, notes 2 and 3.\n                     * Report the problem and keep the pair where it is,\n                     * and mark this field valid.\n                        \"illegal long term reference assignment for second \"\n                        \"field in complementary field pair (first field is \"\n                        \"short term or has non-matching long index)\\n\");\n                    unref_pic = 0;\n            if (unref_pic) {\n                pic= remove_long(h, mmco[i].long_arg);\n                if(pic) unreference_pic(h, pic, 0);\n                h->long_ref[ mmco[i].long_arg ]= s->current_picture_ptr;\n                h->long_ref[ mmco[i].long_arg ]->long_ref=1;\n                h->long_ref_count++;\n            s->current_picture_ptr->reference |= s->picture_structure;\n            current_ref_assigned=1;\n        case MMCO_SET_MAX_LONG:\n            assert(mmco[i].long_arg <= 16);\n            // just remove the long term which index is greater than new max\n            for(j = mmco[i].long_arg; j<16; j++){\n                pic = remove_long(h, j);\n                if (pic) unreference_pic(h, pic, 0);\n        case MMCO_RESET:\n            while(h->short_ref_count){\n                pic= remove_short(h, h->short_ref[0]->frame_num);\n                if(pic) unreference_pic(h, pic, 0);\n            for(j = 0; j < 16; j++) {\n                pic= remove_long(h, j);\n                if(pic) unreference_pic(h, pic, 0);\n        default: assert(0);\n    if (!current_ref_assigned && FIELD_PICTURE &&\n            !s->first_field && s->current_picture_ptr->reference) {\n        /* Second field of complementary field pair; the first field of\n         * which is already referenced. If short referenced, it\n         * should be first entry in short_ref. If not, it must exist\n         * in long_ref; trying to put it on the short list here is an\n         * error in the encoded bit stream (ref: 7.4.3, NOTE 2 and 3).\n        if (h->short_ref_count && h->short_ref[0] == s->current_picture_ptr) {\n            /* Just mark the second field valid */\n            s->current_picture_ptr->reference = PICT_FRAME;\n        } else if (s->current_picture_ptr->long_ref) {\n            av_log(h->s.avctx, AV_LOG_ERROR, \"illegal short term reference \"\n                                             \"assignment for second field \"\n                                             \"in complementary field pair \"\n                                             \"(first field is long term)\\n\");\n            /*\n             * First field in reference, but not in any sensible place on our\n             * reference lists. This shouldn't happen unless reference\n             * handling somewhere else is wrong.\n            assert(0);\n        current_ref_assigned = 1;\n    if(!current_ref_assigned){\n        pic= remove_short(h, s->current_picture_ptr->frame_num);\n        if(pic){\n            unreference_pic(h, pic, 0);\n            av_log(h->s.avctx, AV_LOG_ERROR, \"illegal short term buffer state detected\\n\");\n        if(h->short_ref_count)\n            memmove(&h->short_ref[1], &h->short_ref[0], h->short_ref_count*sizeof(Picture*));\n        h->short_ref[0]= s->current_picture_ptr;\n        h->short_ref[0]->long_ref=0;\n        h->short_ref_count++;\n        s->current_picture_ptr->reference |= s->picture_structure;\n    print_short_term(h);\n    print_long_term(h);\n    return 0;", "idx": 24495}
{"project": "FFmpeg", "commit_id": "cc6b8c4b612d239bef31a8115402b03453c2b4bc", "target": 0, "func": "static void filter_samples(AVFilterLink *inlink, AVFilterBufferRef *samplesref)\n\n{\n\n    AVFilterContext *ctx = inlink->dst;\n\n    ShowInfoContext *showinfo = ctx->priv;\n\n    uint32_t plane_checksum[8] = {0}, checksum = 0;\n\n    char chlayout_str[128];\n\n    int plane;\n\n\n\n    for (plane = 0; samplesref->data[plane] && plane < 8; plane++) {\n\n        uint8_t *data = samplesref->data[plane];\n\n        int linesize = samplesref->linesize[plane];\n\n\n\n        plane_checksum[plane] = av_adler32_update(plane_checksum[plane],\n\n                                                  data, linesize);\n\n        checksum = av_adler32_update(checksum, data, linesize);\n\n    }\n\n\n\n    av_get_channel_layout_string(chlayout_str, sizeof(chlayout_str), -1,\n\n                                 samplesref->audio->channel_layout);\n\n\n\n    av_log(ctx, AV_LOG_INFO,\n\n           \"n:%d pts:%\"PRId64\" pts_time:%f pos:%\"PRId64\" \"\n\n           \"fmt:%s chlayout:%s nb_samples:%d rate:%d planar:%d \"\n\n           \"checksum:%u plane_checksum[%u %u %u %u %u %u %u %u]\\n\",\n\n           showinfo->frame,\n\n           samplesref->pts, samplesref->pts * av_q2d(inlink->time_base),\n\n           samplesref->pos,\n\n           av_get_sample_fmt_name(samplesref->format),\n\n           chlayout_str,\n\n           samplesref->audio->nb_samples,\n\n           samplesref->audio->sample_rate,\n\n           samplesref->audio->planar,\n\n           checksum,\n\n           plane_checksum[0], plane_checksum[1], plane_checksum[2], plane_checksum[3],\n\n           plane_checksum[4], plane_checksum[5], plane_checksum[6], plane_checksum[7]);\n\n\n\n    showinfo->frame++;\n\n\n\n    avfilter_filter_samples(inlink->dst->outputs[0], samplesref);\n\n}\n", "idx": 24496}
{"project": "FFmpeg", "commit_id": "f033ba470fbab1ff6838666d4d86411effa97b27", "target": 0, "func": "static av_cold int vaapi_encode_init_rate_control(AVCodecContext *avctx)\n\n{\n\n    VAAPIEncodeContext *ctx = avctx->priv_data;\n\n    int hrd_buffer_size;\n\n    int hrd_initial_buffer_fullness;\n\n\n\n    if (avctx->rc_buffer_size)\n\n        hrd_buffer_size = avctx->rc_buffer_size;\n\n    else\n\n        hrd_buffer_size = avctx->bit_rate;\n\n    if (avctx->rc_initial_buffer_occupancy)\n\n        hrd_initial_buffer_fullness = avctx->rc_initial_buffer_occupancy;\n\n    else\n\n        hrd_initial_buffer_fullness = hrd_buffer_size * 3 / 4;\n\n\n\n    ctx->rc_params.misc.type = VAEncMiscParameterTypeRateControl;\n\n    ctx->rc_params.rc = (VAEncMiscParameterRateControl) {\n\n        .bits_per_second   = avctx->bit_rate,\n\n        .target_percentage = 66,\n\n        .window_size       = 1000,\n\n        .initial_qp        = (avctx->qmax >= 0 ? avctx->qmax : 40),\n\n        .min_qp            = (avctx->qmin >= 0 ? avctx->qmin : 18),\n\n        .basic_unit_size   = 0,\n\n    };\n\n    ctx->global_params[ctx->nb_global_params] =\n\n        &ctx->rc_params.misc;\n\n    ctx->global_params_size[ctx->nb_global_params++] =\n\n        sizeof(ctx->rc_params);\n\n\n\n    ctx->hrd_params.misc.type = VAEncMiscParameterTypeHRD;\n\n    ctx->hrd_params.hrd = (VAEncMiscParameterHRD) {\n\n        .initial_buffer_fullness = hrd_initial_buffer_fullness,\n\n        .buffer_size             = hrd_buffer_size,\n\n    };\n\n    ctx->global_params[ctx->nb_global_params] =\n\n        &ctx->hrd_params.misc;\n\n    ctx->global_params_size[ctx->nb_global_params++] =\n\n        sizeof(ctx->hrd_params);\n\n\n\n    return 0;\n\n}\n", "idx": 24497}
{"project": "FFmpeg", "commit_id": "2272ab0e84de6ef29548e0c89bb041a5c2e55a18", "target": 0, "func": "static int mp3_write_xing(AVFormatContext *s)\n\n{\n\n    MP3Context       *mp3 = s->priv_data;\n\n    AVCodecContext *codec = s->streams[mp3->audio_stream_idx]->codec;\n\n    AVDictionaryEntry *enc = av_dict_get(s->streams[mp3->audio_stream_idx]->metadata, \"encoder\", NULL, 0);\n\n    AVIOContext *dyn_ctx;\n\n    int32_t        header;\n\n    MPADecodeHeader  mpah;\n\n    int srate_idx, i, channels;\n\n    int bitrate_idx;\n\n    int best_bitrate_idx = -1;\n\n    int best_bitrate_error = INT_MAX;\n\n    int ret;\n\n    int ver = 0;\n\n    int bytes_needed;\n\n\n\n    if (!s->pb->seekable || !mp3->write_xing)\n\n        return 0;\n\n\n\n    for (i = 0; i < FF_ARRAY_ELEMS(avpriv_mpa_freq_tab); i++) {\n\n        const uint16_t base_freq = avpriv_mpa_freq_tab[i];\n\n\n\n        if      (codec->sample_rate == base_freq)     ver = 0x3; // MPEG 1\n\n        else if (codec->sample_rate == base_freq / 2) ver = 0x2; // MPEG 2\n\n        else if (codec->sample_rate == base_freq / 4) ver = 0x0; // MPEG 2.5\n\n        else continue;\n\n\n\n        srate_idx = i;\n\n        break;\n\n    }\n\n    if (i == FF_ARRAY_ELEMS(avpriv_mpa_freq_tab)) {\n\n        av_log(s, AV_LOG_WARNING, \"Unsupported sample rate, not writing Xing header.\\n\");\n\n        return -1;\n\n    }\n\n\n\n    switch (codec->channels) {\n\n    case 1:  channels = MPA_MONO;                                          break;\n\n    case 2:  channels = MPA_STEREO;                                        break;\n\n    default: av_log(s, AV_LOG_WARNING, \"Unsupported number of channels, \"\n\n                    \"not writing Xing header.\\n\");\n\n             return -1;\n\n    }\n\n\n\n    /* dummy MPEG audio header */\n\n    header  =  0xffU                                 << 24; // sync\n\n    header |= (0x7 << 5 | ver << 3 | 0x1 << 1 | 0x1) << 16; // sync/audio-version/layer 3/no crc*/\n\n    header |= (srate_idx << 2) << 8;\n\n    header |= channels << 6;\n\n\n\n    for (bitrate_idx = 1; bitrate_idx < 15; bitrate_idx++) {\n\n        int bit_rate = 1000 * avpriv_mpa_bitrate_tab[ver != 3][3 - 1][bitrate_idx];\n\n        int error    = FFABS(bit_rate - codec->bit_rate);\n\n\n\n        if (error < best_bitrate_error) {\n\n            best_bitrate_error = error;\n\n            best_bitrate_idx   = bitrate_idx;\n\n        }\n\n    }\n\n    av_assert0(best_bitrate_idx >= 0);\n\n\n\n    for (bitrate_idx = best_bitrate_idx; ; bitrate_idx++) {\n\n        int32_t mask = bitrate_idx << (4 + 8);\n\n        if (15 == bitrate_idx)\n\n            return -1;\n\n        header |= mask;\n\n\n\n        avpriv_mpegaudio_decode_header(&mpah, header);\n\n        mp3->xing_offset = xing_offtbl[mpah.lsf == 1][mpah.nb_channels == 1] + 4;\n\n        bytes_needed     = mp3->xing_offset + XING_SIZE;\n\n\n\n        if (bytes_needed <= mpah.frame_size)\n\n            break;\n\n\n\n        header &= ~mask;\n\n    }\n\n\n\n    ret = avio_open_dyn_buf(&dyn_ctx);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    avio_wb32(dyn_ctx, header);\n\n\n\n    ffio_fill(dyn_ctx, 0, mp3->xing_offset - 4);\n\n    ffio_wfourcc(dyn_ctx, \"Xing\");\n\n    avio_wb32(dyn_ctx, 0x01 | 0x02 | 0x04 | 0x08);  // frames / size / TOC / vbr scale\n\n\n\n    mp3->size = mpah.frame_size;\n\n    mp3->want=1;\n\n    mp3->seen=0;\n\n    mp3->pos=0;\n\n\n\n    avio_wb32(dyn_ctx, 0);  // frames\n\n    avio_wb32(dyn_ctx, 0);  // size\n\n\n\n    // TOC\n\n    for (i = 0; i < XING_TOC_SIZE; i++)\n\n        avio_w8(dyn_ctx, (uint8_t)(255 * i / XING_TOC_SIZE));\n\n\n\n    // vbr quality\n\n    // we write it, because some (broken) tools always expect it to be present\n\n    avio_wb32(dyn_ctx, 0);\n\n\n\n    // encoder short version string\n\n    if (enc) {\n\n        uint8_t encoder_str[9] = { 0 };\n\n        if (   strlen(enc->value) > sizeof(encoder_str)\n\n            && !strcmp(\"Lavc libmp3lame\", enc->value)) {\n\n            memcpy(encoder_str, \"Lavf lame\", 9);\n\n        } else\n\n            memcpy(encoder_str, enc->value, FFMIN(strlen(enc->value), sizeof(encoder_str)));\n\n\n\n        avio_write(dyn_ctx, encoder_str, sizeof(encoder_str));\n\n    } else\n\n        avio_write(dyn_ctx, \"Lavf\\0\\0\\0\\0\\0\", 9);\n\n\n\n    avio_w8(dyn_ctx, 0);      // tag revision 0 / unknown vbr method\n\n    avio_w8(dyn_ctx, 0);      // unknown lowpass filter value\n\n    ffio_fill(dyn_ctx, 0, 8); // empty replaygain fields\n\n    avio_w8(dyn_ctx, 0);      // unknown encoding flags\n\n    avio_w8(dyn_ctx, 0);      // unknown abr/minimal bitrate\n\n\n\n    // encoder delay\n\n    if (codec->initial_padding - 528 - 1 >= 1 << 12) {\n\n        av_log(s, AV_LOG_WARNING, \"Too many samples of initial padding.\\n\");\n\n    }\n\n    avio_wb24(dyn_ctx, FFMAX(codec->initial_padding - 528 - 1, 0)<<12);\n\n\n\n    avio_w8(dyn_ctx,   0); // misc\n\n    avio_w8(dyn_ctx,   0); // mp3gain\n\n    avio_wb16(dyn_ctx, 0); // preset\n\n\n\n    // audio length and CRCs (will be updated later)\n\n    avio_wb32(dyn_ctx, 0); // music length\n\n    avio_wb16(dyn_ctx, 0); // music crc\n\n    avio_wb16(dyn_ctx, 0); // tag crc\n\n\n\n    ffio_fill(dyn_ctx, 0, mpah.frame_size - bytes_needed);\n\n\n\n    mp3->xing_frame_size   = avio_close_dyn_buf(dyn_ctx, &mp3->xing_frame);\n\n    mp3->xing_frame_offset = avio_tell(s->pb);\n\n    avio_write(s->pb, mp3->xing_frame, mp3->xing_frame_size);\n\n\n\n    mp3->audio_size = mp3->xing_frame_size;\n\n\n\n    return 0;\n\n}\n", "idx": 24506}
{"project": "FFmpeg", "commit_id": "3c895fc098f7637f6d5ec3a9d6766e724a8b9e41", "target": 0, "func": "static void compute_pkt_fields(AVFormatContext *s, AVStream *st, \n\n                               AVCodecParserContext *pc, AVPacket *pkt)\n\n{\n\n    int num, den, presentation_delayed;\n\n\n\n    /* handle wrapping */\n\n    if(st->cur_dts != AV_NOPTS_VALUE){\n\n        if(pkt->pts != AV_NOPTS_VALUE)\n\n            pkt->pts= lsb2full(pkt->pts, st->cur_dts, st->pts_wrap_bits);\n\n        if(pkt->dts != AV_NOPTS_VALUE)\n\n            pkt->dts= lsb2full(pkt->dts, st->cur_dts, st->pts_wrap_bits);\n\n    }\n\n    \n\n    if (pkt->duration == 0) {\n\n        compute_frame_duration(&num, &den, s, st, pc, pkt);\n\n        if (den && num) {\n\n            pkt->duration = av_rescale(1, num * (int64_t)st->time_base.den, den * (int64_t)st->time_base.num);\n\n        }\n\n    }\n\n\n\n    /* do we have a video B frame ? */\n\n    presentation_delayed = 0;\n\n    if (st->codec.codec_type == CODEC_TYPE_VIDEO) {\n\n        /* XXX: need has_b_frame, but cannot get it if the codec is\n\n           not initialized */\n\n        if ((st->codec.codec_id == CODEC_ID_MPEG1VIDEO ||\n\n             st->codec.codec_id == CODEC_ID_MPEG2VIDEO ||\n\n             st->codec.codec_id == CODEC_ID_MPEG4 ||\n\n             st->codec.codec_id == CODEC_ID_H264) && \n\n            pc && pc->pict_type != FF_B_TYPE)\n\n            presentation_delayed = 1;\n\n        /* this may be redundant, but it shouldnt hurt */\n\n        if(pkt->dts != AV_NOPTS_VALUE && pkt->pts != AV_NOPTS_VALUE && pkt->pts > pkt->dts)\n\n            presentation_delayed = 1;\n\n    }\n\n    \n\n    if(st->cur_dts == AV_NOPTS_VALUE){\n\n        if(presentation_delayed) st->cur_dts = -pkt->duration;\n\n        else                     st->cur_dts = 0;\n\n    }\n\n\n\n//    av_log(NULL, AV_LOG_DEBUG, \"IN delayed:%d pts:%lld, dts:%lld cur_dts:%lld\\n\", presentation_delayed, pkt->pts, pkt->dts, st->cur_dts);\n\n    /* interpolate PTS and DTS if they are not present */\n\n    if (presentation_delayed) {\n\n        /* DTS = decompression time stamp */\n\n        /* PTS = presentation time stamp */\n\n        if (pkt->dts == AV_NOPTS_VALUE) {\n\n            /* if we know the last pts, use it */\n\n            if(st->last_IP_pts != AV_NOPTS_VALUE)\n\n                st->cur_dts = pkt->dts = st->last_IP_pts;\n\n            else\n\n                pkt->dts = st->cur_dts;\n\n        } else {\n\n            st->cur_dts = pkt->dts;\n\n        }\n\n        /* this is tricky: the dts must be incremented by the duration\n\n           of the frame we are displaying, i.e. the last I or P frame */\n\n        if (st->last_IP_duration == 0)\n\n            st->cur_dts += pkt->duration;\n\n        else\n\n            st->cur_dts += st->last_IP_duration;\n\n        st->last_IP_duration  = pkt->duration;\n\n        st->last_IP_pts= pkt->pts;\n\n        /* cannot compute PTS if not present (we can compute it only\n\n           by knowing the futur */\n\n    } else {\n\n        /* presentation is not delayed : PTS and DTS are the same */\n\n        if (pkt->pts == AV_NOPTS_VALUE) {\n\n            if (pkt->dts == AV_NOPTS_VALUE) {\n\n                pkt->pts = st->cur_dts;\n\n                pkt->dts = st->cur_dts;\n\n            }\n\n            else {\n\n                st->cur_dts = pkt->dts;\n\n                pkt->pts = pkt->dts;\n\n            }\n\n        } else {\n\n            st->cur_dts = pkt->pts;\n\n            pkt->dts = pkt->pts;\n\n        }\n\n        st->cur_dts += pkt->duration;\n\n    }\n\n//    av_log(NULL, AV_LOG_DEBUG, \"OUTdelayed:%d pts:%lld, dts:%lld cur_dts:%lld\\n\", presentation_delayed, pkt->pts, pkt->dts, st->cur_dts);\n\n    \n\n    /* update flags */\n\n    if (pc) {\n\n        pkt->flags = 0;\n\n        /* key frame computation */\n\n        switch(st->codec.codec_type) {\n\n        case CODEC_TYPE_VIDEO:\n\n            if (pc->pict_type == FF_I_TYPE)\n\n                pkt->flags |= PKT_FLAG_KEY;\n\n            break;\n\n        case CODEC_TYPE_AUDIO:\n\n            pkt->flags |= PKT_FLAG_KEY;\n\n            break;\n\n        default:\n\n            break;\n\n        }\n\n    }\n\n\n\n    /* convert the packet time stamp units */\n\n    if(pkt->pts != AV_NOPTS_VALUE)\n\n        pkt->pts = av_rescale(pkt->pts, AV_TIME_BASE * (int64_t)st->time_base.num, st->time_base.den);\n\n    if(pkt->dts != AV_NOPTS_VALUE)\n\n        pkt->dts = av_rescale(pkt->dts, AV_TIME_BASE * (int64_t)st->time_base.num, st->time_base.den);\n\n\n\n    /* duration field */\n\n    pkt->duration = av_rescale(pkt->duration, AV_TIME_BASE * (int64_t)st->time_base.num, st->time_base.den);\n\n}\n", "idx": 24517}
{"project": "FFmpeg", "commit_id": "f03c0f6afcb1360c95e92cf9278a8f43ca5cdb9f", "target": 0, "func": "static int ffm_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    int size;\n\n    FFMContext *ffm = s->priv_data;\n\n    int duration, ret;\n\n\n\n    switch(ffm->read_state) {\n\n    case READ_HEADER:\n\n        if ((ret = ffm_is_avail_data(s, FRAME_HEADER_SIZE+4)) < 0)\n\n            return ret;\n\n\n\n        av_dlog(s, \"pos=%08\"PRIx64\" spos=%\"PRIx64\", write_index=%\"PRIx64\" size=%\"PRIx64\"\\n\",\n\n               avio_tell(s->pb), s->pb->pos, ffm->write_index, ffm->file_size);\n\n        if (ffm_read_data(s, ffm->header, FRAME_HEADER_SIZE, 1) !=\n\n            FRAME_HEADER_SIZE)\n\n            return -1;\n\n        if (ffm->header[1] & FLAG_DTS)\n\n            if (ffm_read_data(s, ffm->header+16, 4, 1) != 4)\n\n                return -1;\n\n        ffm->read_state = READ_DATA;\n\n        /* fall thru */\n\n    case READ_DATA:\n\n        size = AV_RB24(ffm->header + 2);\n\n        if ((ret = ffm_is_avail_data(s, size)) < 0)\n\n            return ret;\n\n\n\n        duration = AV_RB24(ffm->header + 5);\n\n\n\n        av_new_packet(pkt, size);\n\n        pkt->stream_index = ffm->header[0];\n\n        if ((unsigned)pkt->stream_index >= s->nb_streams) {\n\n            av_log(s, AV_LOG_ERROR, \"invalid stream index %d\\n\", pkt->stream_index);\n\n            av_free_packet(pkt);\n\n            ffm->read_state = READ_HEADER;\n\n            return -1;\n\n        }\n\n        pkt->pos = avio_tell(s->pb);\n\n        if (ffm->header[1] & FLAG_KEY_FRAME)\n\n            pkt->flags |= AV_PKT_FLAG_KEY;\n\n\n\n        ffm->read_state = READ_HEADER;\n\n        if (ffm_read_data(s, pkt->data, size, 0) != size) {\n\n            /* bad case: desynchronized packet. we cancel all the packet loading */\n\n            av_free_packet(pkt);\n\n            return -1;\n\n        }\n\n        pkt->pts = AV_RB64(ffm->header+8);\n\n        if (ffm->header[1] & FLAG_DTS)\n\n            pkt->dts = pkt->pts - AV_RB32(ffm->header+16);\n\n        else\n\n            pkt->dts = pkt->pts;\n\n        pkt->duration = duration;\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 24518}
{"project": "FFmpeg", "commit_id": "67afcefb35932b420998f6f3fda46c7c85848a3f", "target": 0, "func": "static int vda_h264_start_frame(AVCodecContext *avctx,\n\n                                av_unused const uint8_t *buffer,\n\n                                av_unused uint32_t size)\n\n{\n\n    VDAContext *vda = avctx->internal->hwaccel_priv_data;\n\n    struct vda_context *vda_ctx         = avctx->hwaccel_context;\n\n\n\n    if (!vda_ctx->decoder)\n\n        return -1;\n\n\n\n    vda->bitstream_size = 0;\n\n\n\n    return 0;\n\n}\n", "idx": 24519}
{"project": "FFmpeg", "commit_id": "7ac2f7e413051aa6ff735a8b9c47ca06dc4607d9", "target": 0, "func": "static void colored_fputs(int level, int tint, const char *str)\n\n{\n\n    if (!*str)\n\n        return;\n\n\n\n    if (use_color < 0)\n\n        check_color_terminal();\n\n\n\n#if defined(_WIN32) && !defined(__MINGW32CE__) && HAVE_SETCONSOLETEXTATTRIBUTE\n\n    if (use_color && level != AV_LOG_INFO/8)\n\n        SetConsoleTextAttribute(con, background | color[level]);\n\n    fputs(str, stderr);\n\n    if (use_color && level != AV_LOG_INFO/8)\n\n        SetConsoleTextAttribute(con, attr_orig);\n\n#else\n\n    if (use_color == 1 && level != AV_LOG_INFO/8) {\n\n        fprintf(stderr,\n\n                \"\\033[%d;3%dm%s\\033[0m\",\n\n                (color[level] >> 4) & 15,\n\n                color[level] & 15,\n\n                str);\n\n    } else if (tint && use_color == 256) {\n\n        fprintf(stderr,\n\n                \"\\033[48;5;%dm\\033[38;5;%dm%s\\033[0m\",\n\n                (color[level] >> 16) & 0xff,\n\n                tint,\n\n                str);\n\n    } else if (use_color == 256 && level != AV_LOG_INFO/8) {\n\n        fprintf(stderr,\n\n                \"\\033[48;5;%dm\\033[38;5;%dm%s\\033[0m\",\n\n                (color[level] >> 16) & 0xff,\n\n                (color[level] >> 8) & 0xff,\n\n                str);\n\n    } else\n\n        fputs(str, stderr);\n\n#endif\n\n\n\n}\n", "idx": 24520}
{"project": "FFmpeg", "commit_id": "da7baaaae79b4d7d715d35ea6bcfbdd149edc177", "target": 0, "func": "static int aasc_decode_frame(AVCodecContext *avctx,\n\n                              void *data, int *got_frame,\n\n                              AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    AascContext *s     = avctx->priv_data;\n\n    int compr, i, stride, ret;\n\n\n\n    s->frame.reference = 1;\n\n    s->frame.buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE;\n\n    if ((ret = avctx->reget_buffer(avctx, &s->frame)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n\n\n    compr     = AV_RL32(buf);\n\n    buf      += 4;\n\n    buf_size -= 4;\n\n    switch (compr) {\n\n    case 0:\n\n        stride = (avctx->width * 3 + 3) & ~3;\n\n        for (i = avctx->height - 1; i >= 0; i--) {\n\n            memcpy(s->frame.data[0] + i * s->frame.linesize[0], buf, avctx->width * 3);\n\n            buf += stride;\n\n        }\n\n        break;\n\n    case 1:\n\n        bytestream2_init(&s->gb, buf - 4, buf_size + 4);\n\n        ff_msrle_decode(avctx, (AVPicture*)&s->frame, 8, &s->gb);\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown compression type %d\\n\", compr);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    *got_frame = 1;\n\n    *(AVFrame*)data = s->frame;\n\n\n\n    /* report that the buffer was completely consumed */\n\n    return buf_size;\n\n}\n", "idx": 24521}
{"project": "FFmpeg", "commit_id": "bed1707c9c274831173902542aaef1f8428e6331", "target": 1, "func": "static int rv10_decode_packet(AVCodecContext *avctx, \n\n                             uint8_t *buf, int buf_size)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int i, mb_count, mb_pos, left;\n\n\n\n    init_get_bits(&s->gb, buf, buf_size*8);\n\n#if 0\n\n    for(i=0; i<buf_size*8 && i<200; i++)\n\n        printf(\"%d\", get_bits1(&s->gb));\n\n    printf(\"\\n\");\n\n    return 0;\n\n#endif\n\n    if(s->codec_id ==CODEC_ID_RV10)\n\n        mb_count = rv10_decode_picture_header(s);\n\n    else\n\n        mb_count = rv20_decode_picture_header(s);\n\n    if (mb_count < 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"HEADER ERROR\\n\");\n\n        return -1;\n\n    }\n\n    \n\n    if (s->mb_x >= s->mb_width ||\n\n        s->mb_y >= s->mb_height) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"POS ERROR %d %d\\n\", s->mb_x, s->mb_y);\n\n        return -1;\n\n    }\n\n    mb_pos = s->mb_y * s->mb_width + s->mb_x;\n\n    left = s->mb_width * s->mb_height - mb_pos;\n\n    if (mb_count > left) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"COUNT ERROR\\n\");\n\n        return -1;\n\n    }\n\n//if(s->pict_type == P_TYPE) return 0;\n\n\n\n    if (s->mb_x == 0 && s->mb_y == 0) {\n\n        if(MPV_frame_start(s, avctx) < 0)\n\n            return -1;\n\n    }\n\n\n\n#ifdef DEBUG\n\n    printf(\"qscale=%d\\n\", s->qscale);\n\n#endif\n\n\n\n    /* default quantization values */\n\n    if(s->codec_id== CODEC_ID_RV10){\n\n        if(s->mb_y==0) s->first_slice_line=1;\n\n    }else{\n\n        s->first_slice_line=1;    \n\n        s->resync_mb_x= s->mb_x;\n\n        s->resync_mb_y= s->mb_y;\n\n    }\n\n    if(s->h263_aic){\n\n        s->y_dc_scale_table= \n\n        s->c_dc_scale_table= ff_aic_dc_scale_table;\n\n    }else{\n\n        s->y_dc_scale_table=\n\n        s->c_dc_scale_table= ff_mpeg1_dc_scale_table;\n\n    }\n\n\n\n    if(s->modified_quant)\n\n        s->chroma_qscale_table= ff_h263_chroma_qscale_table;\n\n        \n\n    ff_set_qscale(s, s->qscale);\n\n\n\n    s->rv10_first_dc_coded[0] = 0;\n\n    s->rv10_first_dc_coded[1] = 0;\n\n    s->rv10_first_dc_coded[2] = 0;\n\n\n\n    s->block_wrap[0]=\n\n    s->block_wrap[1]=\n\n    s->block_wrap[2]=\n\n    s->block_wrap[3]= s->mb_width*2 + 2;\n\n    s->block_wrap[4]=\n\n    s->block_wrap[5]= s->mb_width + 2;\n\n    ff_init_block_index(s);\n\n    /* decode each macroblock */\n\n    for(i=0;i<mb_count;i++) {\n\n        int ret;\n\n        ff_update_block_index(s);\n\n#ifdef DEBUG\n\n        printf(\"**mb x=%d y=%d\\n\", s->mb_x, s->mb_y);\n\n#endif\n\n        \n\n\ts->dsp.clear_blocks(s->block[0]);\n\n        s->mv_dir = MV_DIR_FORWARD;\n\n        s->mv_type = MV_TYPE_16X16; \n\n        ret=ff_h263_decode_mb(s, s->block);\n\n\n\n        if (ret == SLICE_ERROR) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"ERROR at MB %d %d\\n\", s->mb_x, s->mb_y);\n\n            return -1;\n\n        }\n\n        ff_h263_update_motion_val(s);\n\n        MPV_decode_mb(s, s->block);\n\n        if(s->loop_filter)\n\n            ff_h263_loop_filter(s);\n\n\n\n        if (++s->mb_x == s->mb_width) {\n\n            s->mb_x = 0;\n\n            s->mb_y++;\n\n            ff_init_block_index(s);\n\n        }\n\n        if(s->mb_x == s->resync_mb_x)\n\n            s->first_slice_line=0;\n\n        if(ret == SLICE_END) break;\n\n    }\n\n\n\n    return buf_size;\n\n}\n", "idx": 24522}
{"project": "FFmpeg", "commit_id": "ea5366670e26b2c6c396e6a5f49827a2b71e6dd6", "target": 1, "func": "static void dwt_decode97_int(DWTContext *s, int32_t *t)\n\n{\n\n    int lev;\n\n    int w       = s->linelen[s->ndeclevels - 1][0];\n\n    int h       = s->linelen[s->ndeclevels - 1][1];\n\n    int i;\n\n    int32_t *line = s->i_linebuf;\n\n    int32_t *data = t;\n\n    /* position at index O of line range [0-5,w+5] cf. extend function */\n\n    line += 5;\n\n\n\n    for (i = 0; i < w * h; i++)\n\n        data[i] *= 1 << I_PRESHIFT;\n\n\n\n    for (lev = 0; lev < s->ndeclevels; lev++) {\n\n        int lh = s->linelen[lev][0],\n\n            lv = s->linelen[lev][1],\n\n            mh = s->mod[lev][0],\n\n            mv = s->mod[lev][1],\n\n            lp;\n\n        int32_t *l;\n\n        // HOR_SD\n\n        l = line + mh;\n\n        for (lp = 0; lp < lv; lp++) {\n\n            int i, j = 0;\n\n            // rescale with interleaving\n\n            for (i = mh; i < lh; i += 2, j++)\n\n                l[i] = ((data[w * lp + j] * I_LFTG_K) + (1 << 15)) >> 16;\n\n            for (i = 1 - mh; i < lh; i += 2, j++)\n\n                l[i] = data[w * lp + j];\n\n\n\n            sr_1d97_int(line, mh, mh + lh);\n\n\n\n            for (i = 0; i < lh; i++)\n\n                data[w * lp + i] = l[i];\n\n        }\n\n\n\n        // VER_SD\n\n        l = line + mv;\n\n        for (lp = 0; lp < lh; lp++) {\n\n            int i, j = 0;\n\n            // rescale with interleaving\n\n            for (i = mv; i < lv; i += 2, j++)\n\n                l[i] = ((data[w * j + lp] * I_LFTG_K) + (1 << 15)) >> 16;\n\n            for (i = 1 - mv; i < lv; i += 2, j++)\n\n                l[i] = data[w * j + lp];\n\n\n\n            sr_1d97_int(line, mv, mv + lv);\n\n\n\n            for (i = 0; i < lv; i++)\n\n                data[w * i + lp] = l[i];\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < w * h; i++)\n\n        data[i] = (data[i] + ((1<<I_PRESHIFT)>>1)) >> I_PRESHIFT;\n\n}\n", "idx": 24524}
{"project": "FFmpeg", "commit_id": "cd7a2e1502f174c725c0de82711d2c7649057574", "target": 1, "func": "static int asf_read_simple_index(AVFormatContext *s, const GUIDParseTable *g)\n\n{\n\n    ASFContext *asf = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st    = NULL;\n\n    uint64_t interval; // index entry time interval in 100 ns units, usually it's 1s\n\n    uint32_t pkt_num, nb_entries;\n\n    int32_t prev_pkt_num = -1;\n\n    int i, ret;\n\n    uint64_t size = avio_rl64(pb);\n\n\n\n    // simple index objects should be ordered by stream number, this loop tries to find\n\n    // the first not indexed video stream\n\n    for (i = 0; i < asf->nb_streams; i++) {\n\n        if ((asf->asf_st[i]->type == AVMEDIA_TYPE_VIDEO) && !asf->asf_st[i]->indexed) {\n\n            asf->asf_st[i]->indexed = 1;\n\n            st = s->streams[asf->asf_st[i]->index];\n\n            break;\n\n        }\n\n    }\n\n    if (!st) {\n\n        avio_skip(pb, size - 24); // if there's no video stream, skip index object\n\n        return 0;\n\n    }\n\n    avio_skip(pb, 16); // skip File ID\n\n    interval = avio_rl64(pb);\n\n    avio_skip(pb, 4);\n\n    nb_entries = avio_rl32(pb);\n\n    for (i = 0; i < nb_entries; i++) {\n\n        pkt_num = avio_rl32(pb);\n\n        ret = avio_skip(pb, 2);\n\n        if (ret < 0) {\n\n            av_log(s, AV_LOG_ERROR, \"Skipping failed in asf_read_simple_index.\\n\");\n\n            return ret;\n\n        }\n\n        if (prev_pkt_num != pkt_num) {\n\n            av_add_index_entry(st, asf->first_packet_offset + asf->packet_size *\n\n                               pkt_num, av_rescale(interval, i, 10000),\n\n                               asf->packet_size, 0, AVINDEX_KEYFRAME);\n\n            prev_pkt_num = pkt_num;\n\n        }\n\n    }\n\n    asf->is_simple_index = 1;\n\n    align_position(pb, asf->offset, size);\n\n\n\n    return 0;\n\n}\n", "idx": 24529}
{"project": "FFmpeg", "commit_id": "f19af812a32c1398d48c3550d11dbc6aafbb2bfc", "target": 1, "func": "static uint32_t read_long(const unsigned char *p)\n\n{\n\n\treturn (p[0]<<24)|(p[1]<<16)|(p[2]<<8)|p[3];\n\n}\n", "idx": 24531}
{"project": "FFmpeg", "commit_id": "fd4c87fa3becaf8a6c480db915daf51e297b76c5", "target": 1, "func": "static void do_video_out(AVFormatContext *s,\n\n                         OutputStream *ost,\n\n                         AVFrame *next_picture,\n\n                         double sync_ipts)\n\n{\n\n    int ret, format_video_sync;\n\n    AVPacket pkt;\n\n    AVCodecContext *enc = ost->enc_ctx;\n\n    AVCodecContext *mux_enc = ost->st->codec;\n\n    int nb_frames, nb0_frames, i;\n\n    double delta, delta0;\n\n    double duration = 0;\n\n    int frame_size = 0;\n\n    InputStream *ist = NULL;\n\n    AVFilterContext *filter = ost->filter->filter;\n\n\n\n    if (ost->source_index >= 0)\n\n        ist = input_streams[ost->source_index];\n\n\n\n    if (filter->inputs[0]->frame_rate.num > 0 &&\n\n        filter->inputs[0]->frame_rate.den > 0)\n\n        duration = 1/(av_q2d(filter->inputs[0]->frame_rate) * av_q2d(enc->time_base));\n\n\n\n    if(ist && ist->st->start_time != AV_NOPTS_VALUE && ist->st->first_dts != AV_NOPTS_VALUE && ost->frame_rate.num)\n\n        duration = FFMIN(duration, 1/(av_q2d(ost->frame_rate) * av_q2d(enc->time_base)));\n\n\n\n    if (!ost->filters_script &&\n\n        !ost->filters &&\n\n        next_picture &&\n\n        ist &&\n\n        lrintf(av_frame_get_pkt_duration(next_picture) * av_q2d(ist->st->time_base) / av_q2d(enc->time_base)) > 0) {\n\n        duration = lrintf(av_frame_get_pkt_duration(next_picture) * av_q2d(ist->st->time_base) / av_q2d(enc->time_base));\n\n    }\n\n\n\n    if (!next_picture) {\n\n        //end, flushing\n\n        nb0_frames = nb_frames = mid_pred(ost->last_nb0_frames[0],\n\n                                          ost->last_nb0_frames[1],\n\n                                          ost->last_nb0_frames[2]);\n\n    } else {\n\n        delta0 = sync_ipts - ost->sync_opts;\n\n        delta  = delta0 + duration;\n\n\n\n        /* by default, we output a single frame */\n\n        nb0_frames = 0;\n\n        nb_frames = 1;\n\n\n\n        format_video_sync = video_sync_method;\n\n        if (format_video_sync == VSYNC_AUTO) {\n\n            if(!strcmp(s->oformat->name, \"avi\")) {\n\n                format_video_sync = VSYNC_VFR;\n\n            } else\n\n                format_video_sync = (s->oformat->flags & AVFMT_VARIABLE_FPS) ? ((s->oformat->flags & AVFMT_NOTIMESTAMPS) ? VSYNC_PASSTHROUGH : VSYNC_VFR) : VSYNC_CFR;\n\n            if (   ist\n\n                && format_video_sync == VSYNC_CFR\n\n                && input_files[ist->file_index]->ctx->nb_streams == 1\n\n                && input_files[ist->file_index]->input_ts_offset == 0) {\n\n                format_video_sync = VSYNC_VSCFR;\n\n            }\n\n            if (format_video_sync == VSYNC_CFR && copy_ts) {\n\n                format_video_sync = VSYNC_VSCFR;\n\n            }\n\n        }\n\n\n\n        if (delta0 < 0 &&\n\n            delta > 0 &&\n\n            format_video_sync != VSYNC_PASSTHROUGH &&\n\n            format_video_sync != VSYNC_DROP) {\n\n            double cor = FFMIN(-delta0, duration);\n\n            if (delta0 < -0.6) {\n\n                av_log(NULL, AV_LOG_WARNING, \"Past duration %f too large\\n\", -delta0);\n\n            } else\n\n                av_log(NULL, AV_LOG_DEBUG, \"Cliping frame in rate conversion by %f\\n\", -delta0);\n\n            sync_ipts += cor;\n\n            duration -= cor;\n\n            delta0 += cor;\n\n        }\n\n\n\n        switch (format_video_sync) {\n\n        case VSYNC_VSCFR:\n\n            if (ost->frame_number == 0 && delta - duration >= 0.5) {\n\n                av_log(NULL, AV_LOG_DEBUG, \"Not duplicating %d initial frames\\n\", (int)lrintf(delta - duration));\n\n                delta = duration;\n\n                delta0 = 0;\n\n                ost->sync_opts = lrint(sync_ipts);\n\n            }\n\n        case VSYNC_CFR:\n\n            // FIXME set to 0.5 after we fix some dts/pts bugs like in avidec.c\n\n            if (frame_drop_threshold && delta < frame_drop_threshold && ost->frame_number) {\n\n                nb_frames = 0;\n\n            } else if (delta < -1.1)\n\n                nb_frames = 0;\n\n            else if (delta > 1.1) {\n\n                nb_frames = lrintf(delta);\n\n                if (delta0 > 1.1)\n\n                    nb0_frames = lrintf(delta0 - 0.6);\n\n            }\n\n            break;\n\n        case VSYNC_VFR:\n\n            if (delta <= -0.6)\n\n                nb_frames = 0;\n\n            else if (delta > 0.6)\n\n                ost->sync_opts = lrint(sync_ipts);\n\n            break;\n\n        case VSYNC_DROP:\n\n        case VSYNC_PASSTHROUGH:\n\n            ost->sync_opts = lrint(sync_ipts);\n\n            break;\n\n        default:\n\n            av_assert0(0);\n\n        }\n\n    }\n\n\n\n    nb_frames = FFMIN(nb_frames, ost->max_frames - ost->frame_number);\n\n    nb0_frames = FFMIN(nb0_frames, nb_frames);\n\n\n\n    memmove(ost->last_nb0_frames + 1,\n\n            ost->last_nb0_frames,\n\n            sizeof(ost->last_nb0_frames[0]) * (FF_ARRAY_ELEMS(ost->last_nb0_frames) - 1));\n\n    ost->last_nb0_frames[0] = nb0_frames;\n\n\n\n    if (nb0_frames == 0 && ost->last_droped) {\n\n        nb_frames_drop++;\n\n        av_log(NULL, AV_LOG_VERBOSE,\n\n               \"*** dropping frame %d from stream %d at ts %\"PRId64\"\\n\",\n\n               ost->frame_number, ost->st->index, ost->last_frame->pts);\n\n    }\n\n    if (nb_frames > (nb0_frames && ost->last_droped) + (nb_frames > nb0_frames)) {\n\n        if (nb_frames > dts_error_threshold * 30) {\n\n            av_log(NULL, AV_LOG_ERROR, \"%d frame duplication too large, skipping\\n\", nb_frames - 1);\n\n            nb_frames_drop++;\n\n            return;\n\n        }\n\n        nb_frames_dup += nb_frames - (nb0_frames && ost->last_droped) - (nb_frames > nb0_frames);\n\n        av_log(NULL, AV_LOG_VERBOSE, \"*** %d dup!\\n\", nb_frames - 1);\n\n    }\n\n    ost->last_droped = nb_frames == nb0_frames && next_picture;\n\n\n\n  /* duplicates frame if needed */\n\n  for (i = 0; i < nb_frames; i++) {\n\n    AVFrame *in_picture;\n\n    av_init_packet(&pkt);\n\n    pkt.data = NULL;\n\n    pkt.size = 0;\n\n\n\n    if (i < nb0_frames && ost->last_frame) {\n\n        in_picture = ost->last_frame;\n\n    } else\n\n        in_picture = next_picture;\n\n\n\n    if (!in_picture)\n\n        return;\n\n\n\n    in_picture->pts = ost->sync_opts;\n\n\n\n#if 1\n\n    if (!check_recording_time(ost))\n\n#else\n\n    if (ost->frame_number >= ost->max_frames)\n\n#endif\n\n        return;\n\n\n\n    if (s->oformat->flags & AVFMT_RAWPICTURE &&\n\n        enc->codec->id == AV_CODEC_ID_RAWVIDEO) {\n\n        /* raw pictures are written as AVPicture structure to\n\n           avoid any copies. We support temporarily the older\n\n           method. */\n\n        if (in_picture->interlaced_frame)\n\n            mux_enc->field_order = in_picture->top_field_first ? AV_FIELD_TB:AV_FIELD_BT;\n\n        else\n\n            mux_enc->field_order = AV_FIELD_PROGRESSIVE;\n\n        pkt.data   = (uint8_t *)in_picture;\n\n        pkt.size   =  sizeof(AVPicture);\n\n        pkt.pts    = av_rescale_q(in_picture->pts, enc->time_base, ost->st->time_base);\n\n        pkt.flags |= AV_PKT_FLAG_KEY;\n\n\n\n        write_frame(s, &pkt, ost);\n\n    } else {\n\n        int got_packet, forced_keyframe = 0;\n\n        double pts_time;\n\n\n\n        if (enc->flags & (CODEC_FLAG_INTERLACED_DCT|CODEC_FLAG_INTERLACED_ME) &&\n\n            ost->top_field_first >= 0)\n\n            in_picture->top_field_first = !!ost->top_field_first;\n\n\n\n        if (in_picture->interlaced_frame) {\n\n            if (enc->codec->id == AV_CODEC_ID_MJPEG)\n\n                mux_enc->field_order = in_picture->top_field_first ? AV_FIELD_TT:AV_FIELD_BB;\n\n            else\n\n                mux_enc->field_order = in_picture->top_field_first ? AV_FIELD_TB:AV_FIELD_BT;\n\n        } else\n\n            mux_enc->field_order = AV_FIELD_PROGRESSIVE;\n\n\n\n        in_picture->quality = enc->global_quality;\n\n        in_picture->pict_type = 0;\n\n\n\n        pts_time = in_picture->pts != AV_NOPTS_VALUE ?\n\n            in_picture->pts * av_q2d(enc->time_base) : NAN;\n\n        if (ost->forced_kf_index < ost->forced_kf_count &&\n\n            in_picture->pts >= ost->forced_kf_pts[ost->forced_kf_index]) {\n\n            ost->forced_kf_index++;\n\n            forced_keyframe = 1;\n\n        } else if (ost->forced_keyframes_pexpr) {\n\n            double res;\n\n            ost->forced_keyframes_expr_const_values[FKF_T] = pts_time;\n\n            res = av_expr_eval(ost->forced_keyframes_pexpr,\n\n                               ost->forced_keyframes_expr_const_values, NULL);\n\n            av_dlog(NULL, \"force_key_frame: n:%f n_forced:%f prev_forced_n:%f t:%f prev_forced_t:%f -> res:%f\\n\",\n\n                    ost->forced_keyframes_expr_const_values[FKF_N],\n\n                    ost->forced_keyframes_expr_const_values[FKF_N_FORCED],\n\n                    ost->forced_keyframes_expr_const_values[FKF_PREV_FORCED_N],\n\n                    ost->forced_keyframes_expr_const_values[FKF_T],\n\n                    ost->forced_keyframes_expr_const_values[FKF_PREV_FORCED_T],\n\n                    res);\n\n            if (res) {\n\n                forced_keyframe = 1;\n\n                ost->forced_keyframes_expr_const_values[FKF_PREV_FORCED_N] =\n\n                    ost->forced_keyframes_expr_const_values[FKF_N];\n\n                ost->forced_keyframes_expr_const_values[FKF_PREV_FORCED_T] =\n\n                    ost->forced_keyframes_expr_const_values[FKF_T];\n\n                ost->forced_keyframes_expr_const_values[FKF_N_FORCED] += 1;\n\n            }\n\n\n\n            ost->forced_keyframes_expr_const_values[FKF_N] += 1;\n\n        } else if (   ost->forced_keyframes\n\n                   && !strncmp(ost->forced_keyframes, \"source\", 6)\n\n                   && in_picture->key_frame==1) {\n\n            forced_keyframe = 1;\n\n        }\n\n\n\n        if (forced_keyframe) {\n\n            in_picture->pict_type = AV_PICTURE_TYPE_I;\n\n            av_log(NULL, AV_LOG_DEBUG, \"Forced keyframe at time %f\\n\", pts_time);\n\n        }\n\n\n\n        update_benchmark(NULL);\n\n        if (debug_ts) {\n\n            av_log(NULL, AV_LOG_INFO, \"encoder <- type:video \"\n\n                   \"frame_pts:%s frame_pts_time:%s time_base:%d/%d\\n\",\n\n                   av_ts2str(in_picture->pts), av_ts2timestr(in_picture->pts, &enc->time_base),\n\n                   enc->time_base.num, enc->time_base.den);\n\n        }\n\n\n\n        ost->frames_encoded++;\n\n\n\n        ret = avcodec_encode_video2(enc, &pkt, in_picture, &got_packet);\n\n        update_benchmark(\"encode_video %d.%d\", ost->file_index, ost->index);\n\n        if (ret < 0) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Video encoding failed\\n\");\n\n            exit_program(1);\n\n        }\n\n\n\n        if (got_packet) {\n\n            if (debug_ts) {\n\n                av_log(NULL, AV_LOG_INFO, \"encoder -> type:video \"\n\n                       \"pkt_pts:%s pkt_pts_time:%s pkt_dts:%s pkt_dts_time:%s\\n\",\n\n                       av_ts2str(pkt.pts), av_ts2timestr(pkt.pts, &enc->time_base),\n\n                       av_ts2str(pkt.dts), av_ts2timestr(pkt.dts, &enc->time_base));\n\n            }\n\n\n\n            if (pkt.pts == AV_NOPTS_VALUE && !(enc->codec->capabilities & CODEC_CAP_DELAY))\n\n                pkt.pts = ost->sync_opts;\n\n\n\n            av_packet_rescale_ts(&pkt, enc->time_base, ost->st->time_base);\n\n\n\n            if (debug_ts) {\n\n                av_log(NULL, AV_LOG_INFO, \"encoder -> type:video \"\n\n                    \"pkt_pts:%s pkt_pts_time:%s pkt_dts:%s pkt_dts_time:%s\\n\",\n\n                    av_ts2str(pkt.pts), av_ts2timestr(pkt.pts, &ost->st->time_base),\n\n                    av_ts2str(pkt.dts), av_ts2timestr(pkt.dts, &ost->st->time_base));\n\n            }\n\n\n\n            frame_size = pkt.size;\n\n            write_frame(s, &pkt, ost);\n\n\n\n            /* if two pass, output log */\n\n            if (ost->logfile && enc->stats_out) {\n\n                fprintf(ost->logfile, \"%s\", enc->stats_out);\n\n            }\n\n        }\n\n    }\n\n    ost->sync_opts++;\n\n    /*\n\n     * For video, number of frames in == number of packets out.\n\n     * But there may be reordering, so we can't throw away frames on encoder\n\n     * flush, we need to limit them here, before they go into encoder.\n\n     */\n\n    ost->frame_number++;\n\n\n\n    if (vstats_filename && frame_size)\n\n        do_video_stats(ost, frame_size);\n\n  }\n\n\n\n    if (!ost->last_frame)\n\n        ost->last_frame = av_frame_alloc();\n\n    av_frame_unref(ost->last_frame);\n\n    if (next_picture)\n\n        av_frame_ref(ost->last_frame, next_picture);\n\n    else\n\n        av_frame_free(&ost->last_frame);\n\n}\n", "idx": 24536}
{"project": "FFmpeg", "commit_id": "7b67fe20f6c5ce21ed1cac01fdb1906e515bc87e", "target": 1, "func": "static int read_header(AVFormatContext *s)\n\n{\n\n    BRSTMDemuxContext *b = s->priv_data;\n\n    int bom, major, minor, codec, chunk;\n\n    int64_t h1offset, pos, toffset;\n\n    uint32_t size, asize, start = 0;\n\n    AVStream *st;\n\n    int ret = AVERROR_EOF;\n\n    int loop = 0;\n\n    int bfstm = !strcmp(\"bfstm\", s->iformat->name);\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n    st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n\n\n    avio_skip(s->pb, 4);\n\n\n\n    bom = avio_rb16(s->pb);\n\n    if (bom != 0xFEFF && bom != 0xFFFE) {\n\n        av_log(s, AV_LOG_ERROR, \"invalid byte order: %X\\n\", bom);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (bom == 0xFFFE)\n\n        b->little_endian = 1;\n\n\n\n    if (!bfstm) {\n\n        major = avio_r8(s->pb);\n\n        minor = avio_r8(s->pb);\n\n        avio_skip(s->pb, 4); // size of file\n\n        size = read16(s);\n\n        if (size < 14)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        avio_skip(s->pb, size - 14);\n\n        pos = avio_tell(s->pb);\n\n        if (avio_rl32(s->pb) != MKTAG('H','E','A','D'))\n\n            return AVERROR_INVALIDDATA;\n\n    } else {\n\n        uint32_t info_offset = 0;\n\n        uint16_t section_count, header_size, i;\n\n\n\n        header_size = read16(s); // 6\n\n\n\n        avio_skip(s->pb, 4); // Unknown constant 0x00030000\n\n        avio_skip(s->pb, 4); // size of file\n\n        section_count = read16(s);\n\n        avio_skip(s->pb, 2); // padding\n\n        for (i = 0; avio_tell(s->pb) < header_size\n\n                    && !(start && info_offset)\n\n                    && i < section_count; i++) {\n\n            uint16_t flag = read16(s);\n\n            avio_skip(s->pb, 2);\n\n            switch (flag) {\n\n            case 0x4000:\n\n                info_offset = read32(s);\n\n                /*info_size =*/ read32(s);\n\n                break;\n\n            case 0x4001:\n\n                avio_skip(s->pb, 4); // seek offset\n\n                avio_skip(s->pb, 4); // seek size\n\n                break;\n\n            case 0x4002:\n\n                start = read32(s) + 8;\n\n                avio_skip(s->pb, 4); //data_size = read32(s);\n\n                break;\n\n            case 0x4003:\n\n                avio_skip(s->pb, 4); // REGN offset\n\n                avio_skip(s->pb, 4); // REGN size\n\n                break;\n\n            }\n\n        }\n\n\n\n        if (!info_offset || !start)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        avio_skip(s->pb, info_offset - avio_tell(s->pb));\n\n        pos = avio_tell(s->pb);\n\n        if (avio_rl32(s->pb) != MKTAG('I','N','F','O'))\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    size = read32(s);\n\n    if (size < 192)\n\n        return AVERROR_INVALIDDATA;\n\n    avio_skip(s->pb, 4); // unknown\n\n    h1offset = read32(s);\n\n    if (h1offset > size)\n\n        return AVERROR_INVALIDDATA;\n\n    avio_skip(s->pb, 12);\n\n    toffset = read32(s) + 16LL;\n\n    if (toffset > size)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    avio_skip(s->pb, pos + h1offset + 8 - avio_tell(s->pb));\n\n    codec = avio_r8(s->pb);\n\n\n\n    switch (codec) {\n\n    case 0: codec = AV_CODEC_ID_PCM_S8_PLANAR;    break;\n\n    case 1: codec = b->little_endian ?\n\n                    AV_CODEC_ID_PCM_S16LE_PLANAR :\n\n                    AV_CODEC_ID_PCM_S16BE_PLANAR; break;\n\n    case 2: codec = b->little_endian ?\n\n                    AV_CODEC_ID_ADPCM_THP_LE :\n\n                    AV_CODEC_ID_ADPCM_THP;        break;\n\n    default:\n\n        avpriv_request_sample(s, \"codec %d\", codec);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    loop = avio_r8(s->pb); // loop flag\n\n    st->codec->codec_id = codec;\n\n    st->codec->channels = avio_r8(s->pb);\n\n    if (!st->codec->channels)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    avio_skip(s->pb, 1); // padding\n\n\n\n    st->codec->sample_rate = bfstm ? read32(s) : read16(s);\n\n    if (!st->codec->sample_rate)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (!bfstm)\n\n        avio_skip(s->pb, 2); // padding\n\n\n\n    if (loop) {\n\n        if (av_dict_set_int(&s->metadata, \"loop_start\",\n\n                            av_rescale(read32(s), AV_TIME_BASE,\n\n                                       st->codec->sample_rate),\n\n                            0) < 0)\n\n            return AVERROR(ENOMEM);\n\n    } else {\n\n        avio_skip(s->pb, 4);\n\n    }\n\n\n\n    st->start_time = 0;\n\n    st->duration = read32(s);\n\n    avpriv_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n\n\n    if (!bfstm)\n\n        start = read32(s);\n\n    b->current_block = 0;\n\n    b->block_count = read32(s);\n\n    if (b->block_count > UINT16_MAX) {\n\n        av_log(s, AV_LOG_WARNING, \"too many blocks: %u\\n\", b->block_count);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    b->block_size = read32(s);\n\n    if (b->block_size > UINT32_MAX / st->codec->channels)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    b->samples_per_block = read32(s);\n\n    b->last_block_used_bytes = read32(s);\n\n    b->last_block_samples = read32(s);\n\n    b->last_block_size = read32(s);\n\n    if (b->last_block_size > UINT32_MAX / st->codec->channels)\n\n        return AVERROR_INVALIDDATA;\n\n    if (b->last_block_used_bytes > b->last_block_size)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n\n\n    if (codec == AV_CODEC_ID_ADPCM_THP || codec == AV_CODEC_ID_ADPCM_THP_LE) {\n\n        int ch;\n\n\n\n        avio_skip(s->pb, pos + toffset - avio_tell(s->pb));\n\n        if (!bfstm)\n\n            toffset = read32(s) + 16LL;\n\n        else\n\n            toffset = toffset + read32(s) + st->codec->channels * 8 - 8;\n\n        if (toffset > size)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        avio_skip(s->pb, pos + toffset - avio_tell(s->pb));\n\n        b->table = av_mallocz(32 * st->codec->channels);\n\n        if (!b->table)\n\n            return AVERROR(ENOMEM);\n\n\n\n        for (ch = 0; ch < st->codec->channels; ch++) {\n\n            if (avio_read(s->pb, b->table + ch * 32, 32) != 32) {\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            avio_skip(s->pb, bfstm ? 14 : 24);\n\n        }\n\n    }\n\n\n\n    if (size < (avio_tell(s->pb) - pos)) {\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto fail;\n\n    }\n\n\n\n    avio_skip(s->pb, size - (avio_tell(s->pb) - pos));\n\n\n\n    while (!avio_feof(s->pb)) {\n\n        chunk = avio_rl32(s->pb);\n\n        size  = read32(s);\n\n        if (size < 8) {\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n        size -= 8;\n\n        switch (chunk) {\n\n        case MKTAG('S','E','E','K'):\n\n        case MKTAG('A','D','P','C'):\n\n            if (codec != AV_CODEC_ID_ADPCM_THP &&\n\n                codec != AV_CODEC_ID_ADPCM_THP_LE)\n\n                goto skip;\n\n\n\n            asize = b->block_count * st->codec->channels * 4;\n\n            if (size < asize) {\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            if (b->adpc) {\n\n                av_log(s, AV_LOG_WARNING, \"skipping additional ADPC chunk\\n\");\n\n                goto skip;\n\n            } else {\n\n                b->adpc = av_mallocz(asize);\n\n                if (!b->adpc) {\n\n                    ret = AVERROR(ENOMEM);\n\n                    goto fail;\n\n                }\n\n                if (bfstm && codec != AV_CODEC_ID_ADPCM_THP_LE) {\n\n                    // Big-endian BFSTMs have little-endian SEEK tables\n\n                    // for some strange reason.\n\n                    int i;\n\n                    for (i = 0; i < asize; i += 2) {\n\n                        b->adpc[i+1] = avio_r8(s->pb);\n\n                        b->adpc[i]   = avio_r8(s->pb);\n\n                    }\n\n                } else {\n\n                    avio_read(s->pb, b->adpc, asize);\n\n                }\n\n                avio_skip(s->pb, size - asize);\n\n            }\n\n            break;\n\n        case MKTAG('D','A','T','A'):\n\n            if ((start < avio_tell(s->pb)) ||\n\n                (!b->adpc && (codec == AV_CODEC_ID_ADPCM_THP ||\n\n                              codec == AV_CODEC_ID_ADPCM_THP_LE))) {\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            avio_skip(s->pb, start - avio_tell(s->pb));\n\n\n\n            if (bfstm && (codec == AV_CODEC_ID_ADPCM_THP ||\n\n                          codec == AV_CODEC_ID_ADPCM_THP_LE))\n\n                avio_skip(s->pb, 24);\n\n\n\n            b->data_start = avio_tell(s->pb);\n\n\n\n            if (!bfstm && (major != 1 || minor))\n\n                avpriv_request_sample(s, \"Version %d.%d\", major, minor);\n\n\n\n            return 0;\n\n        default:\n\n            av_log(s, AV_LOG_WARNING, \"skipping unknown chunk: %X\\n\", chunk);\n\nskip:\n\n            avio_skip(s->pb, size);\n\n        }\n\n    }\n\n\n\nfail:\n\n    read_close(s);\n\n\n\n    return ret;\n\n}\n", "idx": 24537}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(rgb15to16)(const uint8_t *src,uint8_t *dst,unsigned src_size)\n\n{\n\n  register const uint8_t* s=src;\n\n  register uint8_t* d=dst;\n\n  register const uint8_t *end;\n\n  const uint8_t *mm_end;\n\n  end = s + src_size;\n\n#ifdef HAVE_MMX\n\n  __asm __volatile(PREFETCH\"\t%0\"::\"m\"(*s));\n\n  __asm __volatile(\"movq\t%0, %%mm4\"::\"m\"(mask15s));\n\n  mm_end = end - 15;\n\n  while(s<mm_end)\n\n  {\n\n\t__asm __volatile(\n\n\t\tPREFETCH\"\t32%1\\n\\t\"\n\n\t\t\"movq\t%1, %%mm0\\n\\t\"\n\n\t\t\"movq\t8%1, %%mm2\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm1\\n\\t\"\n\n\t\t\"movq\t%%mm2, %%mm3\\n\\t\"\n\n\t\t\"pand\t%%mm4, %%mm0\\n\\t\"\n\n\t\t\"pand\t%%mm4, %%mm2\\n\\t\"\n\n\t\t\"paddw\t%%mm1, %%mm0\\n\\t\"\n\n\t\t\"paddw\t%%mm3, %%mm2\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm2, 8%0\"\n\n\t\t:\"=m\"(*d)\n\n\t\t:\"m\"(*s)\n\n\t\t);\n\n\td+=16;\n\n\ts+=16;\n\n  }\n\n  __asm __volatile(SFENCE:::\"memory\");\n\n  __asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n    mm_end = end - 3;\n\n    while(s < mm_end)\n\n    {\n\n\tregister unsigned x= *((uint32_t *)s);\n\n\t*((uint32_t *)d) = (x&0x7FFF7FFF) + (x&0x7FE07FE0);\n\n\td+=4;\n\n\ts+=4;\n\n    }\n\n    if(s < end)\n\n    {\n\n\tregister unsigned short x= *((uint16_t *)s);\n\n\t*((uint16_t *)d) = (x&0x7FFF) + (x&0x7FE0);\n\n    }\n\n}\n", "idx": 24538}
{"project": "FFmpeg", "commit_id": "5d22ac488b4a424fa8e71f01152b43070f3ef1be", "target": 1, "func": "static int X264_frame(AVCodecContext *ctx, AVPacket *pkt, const AVFrame *frame,\n\n                      int *got_packet)\n\n{\n\n    X264Context *x4 = ctx->priv_data;\n\n    x264_nal_t *nal;\n\n    int nnal, i, ret;\n\n    x264_picture_t pic_out;\n\n\n\n    x264_picture_init( &x4->pic );\n\n    x4->pic.img.i_csp   = x4->params.i_csp;\n\n    if (x264_bit_depth > 8)\n\n        x4->pic.img.i_csp |= X264_CSP_HIGH_DEPTH;\n\n    x4->pic.img.i_plane = avfmt2_num_planes(ctx->pix_fmt);\n\n\n\n    if (frame) {\n\n        for (i = 0; i < x4->pic.img.i_plane; i++) {\n\n            x4->pic.img.plane[i]    = frame->data[i];\n\n            x4->pic.img.i_stride[i] = frame->linesize[i];\n\n        }\n\n\n\n        x4->pic.i_pts  = frame->pts;\n\n        x4->pic.i_type =\n\n            frame->pict_type == AV_PICTURE_TYPE_I ? X264_TYPE_KEYFRAME :\n\n            frame->pict_type == AV_PICTURE_TYPE_P ? X264_TYPE_P :\n\n            frame->pict_type == AV_PICTURE_TYPE_B ? X264_TYPE_B :\n\n                                            X264_TYPE_AUTO;\n\n        if (x4->params.b_interlaced && x4->params.b_tff != frame->top_field_first) {\n\n            x4->params.b_tff = frame->top_field_first;\n\n            x264_encoder_reconfig(x4->enc, &x4->params);\n\n        }\n\n        if (x4->params.vui.i_sar_height != ctx->sample_aspect_ratio.den ||\n\n            x4->params.vui.i_sar_width  != ctx->sample_aspect_ratio.num) {\n\n            x4->params.vui.i_sar_height = ctx->sample_aspect_ratio.den;\n\n            x4->params.vui.i_sar_width  = ctx->sample_aspect_ratio.num;\n\n            x264_encoder_reconfig(x4->enc, &x4->params);\n\n        }\n\n    }\n\n\n\n    do {\n\n        if (x264_encoder_encode(x4->enc, &nal, &nnal, frame? &x4->pic: NULL, &pic_out) < 0)\n\n            return -1;\n\n\n\n        ret = encode_nals(ctx, pkt, nal, nnal);\n\n        if (ret < 0)\n\n            return -1;\n\n    } while (!ret && !frame && x264_encoder_delayed_frames(x4->enc));\n\n\n\n    pkt->pts = pic_out.i_pts;\n\n    pkt->dts = pic_out.i_dts;\n\n\n\n    switch (pic_out.i_type) {\n\n    case X264_TYPE_IDR:\n\n    case X264_TYPE_I:\n\n        x4->out_pic.pict_type = AV_PICTURE_TYPE_I;\n\n        break;\n\n    case X264_TYPE_P:\n\n        x4->out_pic.pict_type = AV_PICTURE_TYPE_P;\n\n        break;\n\n    case X264_TYPE_B:\n\n    case X264_TYPE_BREF:\n\n        x4->out_pic.pict_type = AV_PICTURE_TYPE_B;\n\n        break;\n\n    }\n\n\n\n    pkt->flags |= AV_PKT_FLAG_KEY*pic_out.b_keyframe;\n\n    if (ret)\n\n        x4->out_pic.quality = (pic_out.i_qpplus1 - 1) * FF_QP2LAMBDA;\n\n\n\n    *got_packet = ret;\n\n    return 0;\n\n}\n", "idx": 24541}
{"project": "FFmpeg", "commit_id": "8bc80f8b24cb6f03ad209ce546ae594904c8b353", "target": 1, "func": "static int http_server(void)\n\n{\n\n    int server_fd, ret, rtsp_server_fd, delay, delay1;\n\n    struct pollfd poll_table[HTTP_MAX_CONNECTIONS + 2], *poll_entry;\n\n    HTTPContext *c, *c_next;\n\n\n\n    server_fd = socket_open_listen(&my_http_addr);\n\n    if (server_fd < 0)\n\n        return -1;\n\n\n\n    rtsp_server_fd = socket_open_listen(&my_rtsp_addr);\n\n    if (rtsp_server_fd < 0)\n\n        return -1;\n\n    \n\n    http_log(\"ffserver started.\\n\");\n\n\n\n    start_children(first_feed);\n\n\n\n    first_http_ctx = NULL;\n\n    nb_connections = 0;\n\n    first_http_ctx = NULL;\n\n\n\n    start_multicast();\n\n\n\n    for(;;) {\n\n        poll_entry = poll_table;\n\n        poll_entry->fd = server_fd;\n\n        poll_entry->events = POLLIN;\n\n        poll_entry++;\n\n\n\n        poll_entry->fd = rtsp_server_fd;\n\n        poll_entry->events = POLLIN;\n\n        poll_entry++;\n\n\n\n        /* wait for events on each HTTP handle */\n\n        c = first_http_ctx;\n\n        delay = 1000;\n\n        while (c != NULL) {\n\n            int fd;\n\n            fd = c->fd;\n\n            switch(c->state) {\n\n            case HTTPSTATE_SEND_HEADER:\n\n            case RTSPSTATE_SEND_REPLY:\n\n            case RTSPSTATE_SEND_PACKET:\n\n                c->poll_entry = poll_entry;\n\n                poll_entry->fd = fd;\n\n                poll_entry->events = POLLOUT;\n\n                poll_entry++;\n\n                break;\n\n            case HTTPSTATE_SEND_DATA_HEADER:\n\n            case HTTPSTATE_SEND_DATA:\n\n            case HTTPSTATE_SEND_DATA_TRAILER:\n\n                if (!c->is_packetized) {\n\n                    /* for TCP, we output as much as we can (may need to put a limit) */\n\n                    c->poll_entry = poll_entry;\n\n                    poll_entry->fd = fd;\n\n                    poll_entry->events = POLLOUT;\n\n                    poll_entry++;\n\n                } else {\n\n                    /* not strictly correct, but currently cannot add\n\n                       more than one fd in poll entry */\n\n                    delay = 0;\n\n                }\n\n                break;\n\n            case HTTPSTATE_WAIT_REQUEST:\n\n            case HTTPSTATE_RECEIVE_DATA:\n\n            case HTTPSTATE_WAIT_FEED:\n\n            case RTSPSTATE_WAIT_REQUEST:\n\n                /* need to catch errors */\n\n                c->poll_entry = poll_entry;\n\n                poll_entry->fd = fd;\n\n                poll_entry->events = POLLIN;/* Maybe this will work */\n\n                poll_entry++;\n\n                break;\n\n            case HTTPSTATE_WAIT:\n\n                c->poll_entry = NULL;\n\n                delay1 = compute_send_delay(c);\n\n                if (delay1 < delay)\n\n                    delay = delay1;\n\n                break;\n\n            case HTTPSTATE_WAIT_SHORT:\n\n                c->poll_entry = NULL;\n\n                delay1 = 10; /* one tick wait XXX: 10 ms assumed */\n\n                if (delay1 < delay)\n\n                    delay = delay1;\n\n                break;\n\n            default:\n\n                c->poll_entry = NULL;\n\n                break;\n\n            }\n\n            c = c->next;\n\n        }\n\n\n\n        /* wait for an event on one connection. We poll at least every\n\n           second to handle timeouts */\n\n        do {\n\n            ret = poll(poll_table, poll_entry - poll_table, delay);\n\n        } while (ret == -1);\n\n        \n\n        cur_time = gettime_ms();\n\n\n\n        if (need_to_start_children) {\n\n            need_to_start_children = 0;\n\n            start_children(first_feed);\n\n        }\n\n\n\n        /* now handle the events */\n\n        for(c = first_http_ctx; c != NULL; c = c_next) {\n\n            c_next = c->next;\n\n            if (handle_connection(c) < 0) {\n\n                /* close and free the connection */\n\n                log_connection(c);\n\n                close_connection(c);\n\n            }\n\n        }\n\n\n\n        poll_entry = poll_table;\n\n        /* new HTTP connection request ? */\n\n        if (poll_entry->revents & POLLIN) {\n\n            new_connection(server_fd, 0);\n\n        }\n\n        poll_entry++;\n\n        /* new RTSP connection request ? */\n\n        if (poll_entry->revents & POLLIN) {\n\n            new_connection(rtsp_server_fd, 1);\n\n        }\n\n    }\n\n}\n", "idx": 24542}
{"project": "FFmpeg", "commit_id": "add41decd94b2d3581a3715ba10f27168b8cdb1b", "target": 0, "func": "static int get_http_header_data(MMSHContext *mmsh)\n\n{\n\n    MMSContext *mms = &mmsh->mms;\n\n    int res, len;\n\n    ChunkType chunk_type;\n\n\n\n    for (;;) {\n\n        len = 0;\n\n        res = chunk_type = get_chunk_header(mmsh, &len);\n\n        if (res < 0) {\n\n            return res;\n\n        } else if (chunk_type == CHUNK_TYPE_ASF_HEADER){\n\n            // get asf header and stored it\n\n            if (!mms->header_parsed) {\n\n                if (mms->asf_header) {\n\n                    if (len != mms->asf_header_size) {\n\n                        mms->asf_header_size = len;\n\n                        av_dlog(NULL, \"Header len changed from %d to %d\\n\",\n\n                                mms->asf_header_size, len);\n\n                        av_freep(&mms->asf_header);\n\n                    }\n\n                }\n\n                mms->asf_header = av_mallocz(len);\n\n                if (!mms->asf_header) {\n\n                    return AVERROR(ENOMEM);\n\n                }\n\n                mms->asf_header_size = len;\n\n            }\n\n            if (len > mms->asf_header_size) {\n\n                av_log(NULL, AV_LOG_ERROR,\n\n                       \"Asf header packet len = %d exceed the asf header buf size %d\\n\",\n\n                       len, mms->asf_header_size);\n\n                return AVERROR(EIO);\n\n            }\n\n            res = ffurl_read_complete(mms->mms_hd, mms->asf_header, len);\n\n            if (res != len) {\n\n                av_log(NULL, AV_LOG_ERROR,\n\n                       \"Recv asf header data len %d != expected len %d\\n\", res, len);\n\n                return AVERROR(EIO);\n\n            }\n\n            mms->asf_header_size = len;\n\n            if (!mms->header_parsed) {\n\n                res = ff_mms_asf_header_parser(mms);\n\n                mms->header_parsed = 1;\n\n                return res;\n\n            }\n\n        } else if (chunk_type == CHUNK_TYPE_DATA) {\n\n            // read data packet and do padding\n\n            return read_data_packet(mmsh, len);\n\n        } else {\n\n            if (len) {\n\n                if (len > sizeof(mms->in_buffer)) {\n\n                    av_log(NULL, AV_LOG_ERROR,\n\n                           \"Other packet len = %d exceed the in_buffer size %zu\\n\",\n\n                           len, sizeof(mms->in_buffer));\n\n                    return AVERROR(EIO);\n\n                }\n\n                res = ffurl_read_complete(mms->mms_hd, mms->in_buffer, len);\n\n                if (res != len) {\n\n                    av_log(NULL, AV_LOG_ERROR, \"Read other chunk type data failed!\\n\");\n\n                    return AVERROR(EIO);\n\n                } else {\n\n                    av_dlog(NULL, \"Skip chunk type %d \\n\", chunk_type);\n\n                    continue;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 24545}
{"project": "FFmpeg", "commit_id": "ac9d159015a88aa2721b271875d18482f713f354", "target": 1, "func": "static void unpack_alpha(GetBitContext *gb, uint16_t *dst, int num_coeffs,\n\n                         const int num_bits)\n\n{\n\n    const int mask = (1 << num_bits) - 1;\n\n    int i, idx, val, alpha_val;\n\n\n\n    idx       = 0;\n\n    alpha_val = mask;\n\n    do {\n\n        do {\n\n            if (get_bits1(gb))\n\n                val = get_bits(gb, num_bits);\n\n            else {\n\n                int sign;\n\n                val  = get_bits(gb, num_bits == 16 ? 7 : 4);\n\n                sign = val & 1;\n\n                val  = (val + 2) >> 1;\n\n                if (sign)\n\n                    val = -val;\n\n            }\n\n            alpha_val = (alpha_val + val) & mask;\n\n            if (num_bits == 16)\n\n                dst[idx++] = alpha_val >> 6;\n\n            else\n\n                dst[idx++] = (alpha_val << 2) | (alpha_val >> 6);\n\n            if (idx == num_coeffs - 1)\n\n                break;\n\n        } while (get_bits1(gb));\n\n        val = get_bits(gb, 4);\n\n        if (!val)\n\n            val = get_bits(gb, 11);\n\n        if (idx + val > num_coeffs)\n\n            val = num_coeffs - idx;\n\n        if (num_bits == 16)\n\n            for (i = 0; i < val; i++)\n\n                dst[idx++] = alpha_val >> 6;\n\n        else\n\n            for (i = 0; i < val; i++)\n\n                dst[idx++] = (alpha_val << 2) | (alpha_val >> 6);\n\n    } while (idx < num_coeffs);\n\n}\n", "idx": 24550}
{"project": "FFmpeg", "commit_id": "f3c0e0bf6f53df0977f3878d4f5cec99dff8de9e", "target": 0, "func": "static int dnxhd_decode_header(DNXHDContext *ctx, AVFrame *frame,\n\n                               const uint8_t *buf, int buf_size,\n\n                               int first_field)\n\n{\n\n    static const uint8_t header_prefix[]    = { 0x00, 0x00, 0x02, 0x80, 0x01 };\n\n    static const uint8_t header_prefix444[] = { 0x00, 0x00, 0x02, 0x80, 0x02 };\n\n    int i, cid, ret;\n\n\n\n    if (buf_size < 0x280)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (memcmp(buf, header_prefix, 5) && memcmp(buf, header_prefix444, 5)) {\n\n        av_log(ctx->avctx, AV_LOG_ERROR, \"error in header\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (buf[5] & 2) { /* interlaced */\n\n        ctx->cur_field = buf[5] & 1;\n\n        frame->interlaced_frame = 1;\n\n        frame->top_field_first  = first_field ^ ctx->cur_field;\n\n        av_log(ctx->avctx, AV_LOG_DEBUG,\n\n               \"interlaced %d, cur field %d\\n\", buf[5] & 3, ctx->cur_field);\n\n    }\n\n\n\n    ctx->height = AV_RB16(buf + 0x18);\n\n    ctx->width  = AV_RB16(buf + 0x1a);\n\n\n\n    av_dlog(ctx->avctx, \"width %d, height %d\\n\", ctx->width, ctx->height);\n\n\n\n    ctx->is_444 = 0;\n\n    if (buf[0x4] == 0x2) {\n\n        ctx->avctx->pix_fmt = AV_PIX_FMT_YUV444P10;\n\n        ctx->avctx->bits_per_raw_sample = 10;\n\n        if (ctx->bit_depth != 10) {\n\n            ff_blockdsp_init(&ctx->bdsp, ctx->avctx);\n\n            ff_idctdsp_init(&ctx->idsp, ctx->avctx);\n\n            ctx->bit_depth = 10;\n\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n\n        }\n\n        ctx->is_444 = 1;\n\n    } else if (buf[0x21] & 0x40) {\n\n        ctx->avctx->pix_fmt = AV_PIX_FMT_YUV422P10;\n\n        ctx->avctx->bits_per_raw_sample = 10;\n\n        if (ctx->bit_depth != 10) {\n\n            ff_blockdsp_init(&ctx->bdsp, ctx->avctx);\n\n            ff_idctdsp_init(&ctx->idsp, ctx->avctx);\n\n            ctx->bit_depth = 10;\n\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10;\n\n        }\n\n    } else {\n\n        ctx->avctx->pix_fmt = AV_PIX_FMT_YUV422P;\n\n        ctx->avctx->bits_per_raw_sample = 8;\n\n        if (ctx->bit_depth != 8) {\n\n            ff_blockdsp_init(&ctx->bdsp, ctx->avctx);\n\n            ff_idctdsp_init(&ctx->idsp, ctx->avctx);\n\n            ctx->bit_depth = 8;\n\n            ctx->decode_dct_block = dnxhd_decode_dct_block_8;\n\n        }\n\n    }\n\n\n\n    cid = AV_RB32(buf + 0x28);\n\n    av_dlog(ctx->avctx, \"compression id %d\\n\", cid);\n\n\n\n    if ((ret = dnxhd_init_vlc(ctx, cid)) < 0)\n\n        return ret;\n\n\n\n    if (buf_size < ctx->cid_table->coding_unit_size) {\n\n        av_log(ctx->avctx, AV_LOG_ERROR, \"incorrect frame size\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    ctx->mb_width  = ctx->width >> 4;\n\n    ctx->mb_height = buf[0x16d];\n\n\n\n    av_dlog(ctx->avctx,\n\n            \"mb width %d, mb height %d\\n\", ctx->mb_width, ctx->mb_height);\n\n\n\n    if ((ctx->height + 15) >> 4 == ctx->mb_height && frame->interlaced_frame)\n\n        ctx->height <<= 1;\n\n\n\n    if (ctx->mb_height > 68 ||\n\n        (ctx->mb_height << frame->interlaced_frame) > (ctx->height + 15) >> 4) {\n\n        av_log(ctx->avctx, AV_LOG_ERROR,\n\n               \"mb height too big: %d\\n\", ctx->mb_height);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    for (i = 0; i < ctx->mb_height; i++) {\n\n        ctx->mb_scan_index[i] = AV_RB32(buf + 0x170 + (i << 2));\n\n        av_dlog(ctx->avctx, \"mb scan index %d\\n\", ctx->mb_scan_index[i]);\n\n        if (buf_size < ctx->mb_scan_index[i] + 0x280LL) {\n\n            av_log(ctx->avctx, AV_LOG_ERROR, \"invalid mb scan index\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24555}
{"project": "FFmpeg", "commit_id": "66dd21d50be14a355e296b769d9d99090c0207f7", "target": 1, "func": "int attribute_align_arg avcodec_send_packet(AVCodecContext *avctx, const AVPacket *avpkt)\n\n{\n\n    int ret;\n\n\n\n    if (!avcodec_is_open(avctx) || !av_codec_is_decoder(avctx->codec))\n\n        return AVERROR(EINVAL);\n\n\n\n    if (avctx->internal->draining)\n\n        return AVERROR_EOF;\n\n\n\n    if (!avpkt || !avpkt->size) {\n\n        avctx->internal->draining = 1;\n\n        avpkt = NULL;\n\n\n\n        if (!(avctx->codec->capabilities & AV_CODEC_CAP_DELAY))\n\n            return 0;\n\n    }\n\n\n\n    if (avctx->codec->send_packet) {\n\n        if (avpkt) {\n\n            ret = apply_param_change(avctx, (AVPacket *)avpkt);\n\n            if (ret < 0)\n\n                return ret;\n\n        }\n\n        return avctx->codec->send_packet(avctx, avpkt);\n\n    }\n\n\n\n    // Emulation via old API. Assume avpkt is likely not refcounted, while\n\n    // decoder output is always refcounted, and avoid copying.\n\n\n\n    if (avctx->internal->buffer_pkt->size || avctx->internal->buffer_frame->buf[0])\n\n        return AVERROR(EAGAIN);\n\n\n\n    // The goal is decoding the first frame of the packet without using memcpy,\n\n    // because the common case is having only 1 frame per packet (especially\n\n    // with video, but audio too). In other cases, it can't be avoided, unless\n\n    // the user is feeding refcounted packets.\n\n    return do_decode(avctx, (AVPacket *)avpkt);\n\n}\n", "idx": 24556}
{"project": "FFmpeg", "commit_id": "aed7715b8fa295980c221f1cd095d42cd3bd74a6", "target": 1, "func": "static int asf_read_stream_properties(AVFormatContext *s, const GUIDParseTable *g)\n\n{\n\n    ASFContext *asf = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    uint64_t size;\n\n    uint32_t err_data_len, ts_data_len; // type specific data length\n\n    uint16_t flags;\n\n    ff_asf_guid stream_type;\n\n    enum AVMediaType type;\n\n    int i, ret;\n\n    uint8_t stream_index;\n\n    AVStream *st;\n\n    ASFStream *asf_st;\n\n\n\n    // ASF file must not contain more than 128 streams according to the specification\n\n    if (asf->nb_streams >= ASF_MAX_STREAMS)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    size = avio_rl64(pb);\n\n    ff_get_guid(pb, &stream_type);\n\n    if (!ff_guidcmp(&stream_type, &ff_asf_audio_stream))\n\n        type = AVMEDIA_TYPE_AUDIO;\n\n    else if (!ff_guidcmp(&stream_type, &ff_asf_video_stream))\n\n        type = AVMEDIA_TYPE_VIDEO;\n\n    else if (!ff_guidcmp(&stream_type, &ff_asf_jfif_media))\n\n        type = AVMEDIA_TYPE_VIDEO;\n\n    else if (!ff_guidcmp(&stream_type, &ff_asf_command_stream))\n\n        type = AVMEDIA_TYPE_DATA;\n\n    else if (!ff_guidcmp(&stream_type,\n\n                         &ff_asf_ext_stream_embed_stream_header))\n\n        type = AVMEDIA_TYPE_UNKNOWN;\n\n    else\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    ff_get_guid(pb, &stream_type); // error correction type\n\n    avio_skip(pb, 8); // skip the time offset\n\n    ts_data_len      = avio_rl32(pb);\n\n    err_data_len     = avio_rl32(pb);\n\n    flags            = avio_rl16(pb); // bit 15 - Encrypted Content\n\n\n\n    stream_index = flags & ASF_STREAM_NUM;\n\n    for (i = 0; i < asf->nb_streams; i++)\n\n        if (stream_index == asf->asf_st[i]->stream_index) {\n\n            av_log(s, AV_LOG_WARNING,\n\n                   \"Duplicate stream found, this stream will be ignored.\\n\");\n\n            align_position(pb, asf->offset, size);\n\n            return 0;\n\n        }\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n    avpriv_set_pts_info(st, 32, 1, 1000); // pts should be dword, in milliseconds\n\n    st->codec->codec_type = type;\n\n    asf->asf_st[asf->nb_streams] = av_mallocz(sizeof(*asf_st));\n\n    if (!asf->asf_st[asf->nb_streams])\n\n        return AVERROR(ENOMEM);\n\n    asf_st                       = asf->asf_st[asf->nb_streams];\n\n    asf_st->stream_index         = stream_index;\n\n    asf_st->index                = st->index;\n\n    asf_st->indexed              = 0;\n\n    st->id                       = flags & ASF_STREAM_NUM;\n\n    av_init_packet(&asf_st->pkt.avpkt);\n\n    asf_st->pkt.data_size        = 0;\n\n    avio_skip(pb, 4); // skip reserved field\n\n\n\n    switch (type) {\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        asf_st->type = AVMEDIA_TYPE_AUDIO;\n\n        if ((ret = ff_get_wav_header(s, pb, st->codec, ts_data_len)) < 0)\n\n            return ret;\n\n        break;\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        asf_st->type = AVMEDIA_TYPE_VIDEO;\n\n        if ((ret = parse_video_info(pb, st)) < 0)\n\n            return ret;\n\n        break;\n\n    default:\n\n        avio_skip(pb, ts_data_len);\n\n        break;\n\n    }\n\n\n\n    if (err_data_len) {\n\n        if (type == AVMEDIA_TYPE_AUDIO) {\n\n            uint8_t span = avio_r8(pb);\n\n            if (span > 1) {\n\n                asf_st->span              = span;\n\n                asf_st->virtual_pkt_len   = avio_rl16(pb);\n\n                asf_st->virtual_chunk_len = avio_rl16(pb);\n\n                if (!asf_st->virtual_chunk_len || !asf_st->virtual_pkt_len)\n\n                    return AVERROR_INVALIDDATA;\n\n                avio_skip(pb, err_data_len - 5);\n\n            } else\n\n                avio_skip(pb, err_data_len - 1);\n\n        } else\n\n            avio_skip(pb, err_data_len);\n\n    }\n\n\n\n    asf->nb_streams++;\n\n    align_position(pb, asf->offset, size);\n\n\n\n    return 0;\n\n}\n", "idx": 24557}
{"project": "FFmpeg", "commit_id": "4a745b41770893116405c22f832192510f9bcc9b", "target": 1, "func": "static int pnm_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *data_size, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf   = avpkt->data;\n\n    int buf_size         = avpkt->size;\n\n    PNMContext * const s = avctx->priv_data;\n\n    AVFrame *picture     = data;\n\n    AVFrame * const p    = (AVFrame*)&s->picture;\n\n    int i, j, n, linesize, h, upgrade = 0;\n\n    unsigned char *ptr;\n\n    int components, sample_len;\n\n\n\n    s->bytestream_start =\n\n    s->bytestream       = buf;\n\n    s->bytestream_end   = buf + buf_size;\n\n\n\n    if (ff_pnm_decode_header(avctx, s) < 0)\n\n        return -1;\n\n\n\n    if (p->data[0])\n\n        avctx->release_buffer(avctx, p);\n\n\n\n    p->reference = 0;\n\n    if (avctx->get_buffer(avctx, p) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n    p->pict_type = AV_PICTURE_TYPE_I;\n\n    p->key_frame = 1;\n\n\n\n    switch (avctx->pix_fmt) {\n\n    default:\n\n        return -1;\n\n    case PIX_FMT_RGB48BE:\n\n        n = avctx->width * 6;\n\n        components=3;\n\n        sample_len=16;\n\n        goto do_read;\n\n    case PIX_FMT_RGB24:\n\n        n = avctx->width * 3;\n\n        components=3;\n\n        sample_len=8;\n\n        goto do_read;\n\n    case PIX_FMT_GRAY8:\n\n        n = avctx->width;\n\n        components=1;\n\n        sample_len=8;\n\n        if (s->maxval < 255)\n\n            upgrade = 1;\n\n        goto do_read;\n\n    case PIX_FMT_GRAY16BE:\n\n    case PIX_FMT_GRAY16LE:\n\n        n = avctx->width * 2;\n\n        components=1;\n\n        sample_len=16;\n\n        if (s->maxval < 65535)\n\n            upgrade = 2;\n\n        goto do_read;\n\n    case PIX_FMT_MONOWHITE:\n\n    case PIX_FMT_MONOBLACK:\n\n        n = (avctx->width + 7) >> 3;\n\n        components=1;\n\n        sample_len=1;\n\n    do_read:\n\n        ptr      = p->data[0];\n\n        linesize = p->linesize[0];\n\n        if (s->bytestream + n * avctx->height > s->bytestream_end)\n\n            return -1;\n\n        if(s->type < 4){\n\n            for (i=0; i<avctx->height; i++) {\n\n                PutBitContext pb;\n\n                init_put_bits(&pb, ptr, linesize);\n\n                for(j=0; j<avctx->width * components; j++){\n\n                    unsigned int c=0;\n\n                    int v=0;\n\n                    while(s->bytestream < s->bytestream_end && (*s->bytestream < '0' || *s->bytestream > '9' ))\n\n                        s->bytestream++;\n\n                    if(s->bytestream >= s->bytestream_end)\n\n                        return -1;\n\n                    do{\n\n                        v= 10*v + c;\n\n                        c= (*s->bytestream++) - '0';\n\n                    }while(c <= 9);\n\n                    put_bits(&pb, sample_len, (((1<<sample_len)-1)*v + (s->maxval>>1))/s->maxval);\n\n                }\n\n                flush_put_bits(&pb);\n\n                ptr+= linesize;\n\n            }\n\n        }else{\n\n        for (i = 0; i < avctx->height; i++) {\n\n            if (!upgrade)\n\n                memcpy(ptr, s->bytestream, n);\n\n            else if (upgrade == 1) {\n\n                unsigned int j, f = (255 * 128 + s->maxval / 2) / s->maxval;\n\n                for (j = 0; j < n; j++)\n\n                    ptr[j] = (s->bytestream[j] * f + 64) >> 7;\n\n            } else if (upgrade == 2) {\n\n                unsigned int j, v, f = (65535 * 32768 + s->maxval / 2) / s->maxval;\n\n                for (j = 0; j < n / 2; j++) {\n\n                    v = av_be2ne16(((uint16_t *)s->bytestream)[j]);\n\n                    ((uint16_t *)ptr)[j] = (v * f + 16384) >> 15;\n\n                }\n\n            }\n\n            s->bytestream += n;\n\n            ptr           += linesize;\n\n        }\n\n        }\n\n        break;\n\n    case PIX_FMT_YUV420P:\n\n        {\n\n            unsigned char *ptr1, *ptr2;\n\n\n\n            n        = avctx->width;\n\n            ptr      = p->data[0];\n\n            linesize = p->linesize[0];\n\n            if (s->bytestream + n * avctx->height * 3 / 2 > s->bytestream_end)\n\n                return -1;\n\n            for (i = 0; i < avctx->height; i++) {\n\n                memcpy(ptr, s->bytestream, n);\n\n                s->bytestream += n;\n\n                ptr           += linesize;\n\n            }\n\n            ptr1 = p->data[1];\n\n            ptr2 = p->data[2];\n\n            n >>= 1;\n\n            h = avctx->height >> 1;\n\n            for (i = 0; i < h; i++) {\n\n                memcpy(ptr1, s->bytestream, n);\n\n                s->bytestream += n;\n\n                memcpy(ptr2, s->bytestream, n);\n\n                s->bytestream += n;\n\n                ptr1 += p->linesize[1];\n\n                ptr2 += p->linesize[2];\n\n            }\n\n        }\n\n        break;\n\n    case PIX_FMT_RGB32:\n\n        ptr      = p->data[0];\n\n        linesize = p->linesize[0];\n\n        if (s->bytestream + avctx->width * avctx->height * 4 > s->bytestream_end)\n\n            return -1;\n\n        for (i = 0; i < avctx->height; i++) {\n\n            int j, r, g, b, a;\n\n\n\n            for (j = 0; j < avctx->width; j++) {\n\n                r = *s->bytestream++;\n\n                g = *s->bytestream++;\n\n                b = *s->bytestream++;\n\n                a = *s->bytestream++;\n\n                ((uint32_t *)ptr)[j] = (a << 24) | (r << 16) | (g << 8) | b;\n\n            }\n\n            ptr += linesize;\n\n        }\n\n        break;\n\n    }\n\n    *picture   = *(AVFrame*)&s->picture;\n\n    *data_size = sizeof(AVPicture);\n\n\n\n    return s->bytestream - s->bytestream_start;\n\n}\n", "idx": 24558}
{"project": "FFmpeg", "commit_id": "ac4b32df71bd932838043a4838b86d11e169707f", "target": 1, "func": "int check_tm_pred8x8_mode(int mode, int mb_x, int mb_y)\n\n{\n\n    if (!mb_x)\n\n        return mb_y ? VERT_PRED8x8 : DC_129_PRED8x8;\n\n    else\n\n        return mb_y ? mode : HOR_PRED8x8;\n\n}\n", "idx": 24561}
{"project": "FFmpeg", "commit_id": "584c2f1db82fbb8024ba2b6b4c48397efedcc125", "target": 1, "func": "double parse_number_or_die(const char *context, const char *numstr, int type, double min, double max)\n\n{\n\n    char *tail;\n\n    const char *error;\n\n    double d = av_strtod(numstr, &tail);\n\n    if (*tail)\n\n        error= \"Expected number for %s but found: %s\\n\";\n\n    else if (d < min || d > max)\n\n        error= \"The value for %s was %s which is not within %f - %f\\n\";\n\n    else if(type == OPT_INT64 && (int64_t)d != d)\n\n        error= \"Expected int64 for %s but found %s\\n\";\n\n\n\n    else\n\n        return d;\n\n    fprintf(stderr, error, context, numstr, min, max);\n\n    exit(1);\n\n}", "idx": 24563}
{"project": "FFmpeg", "commit_id": "b83ccbffe9b109fcd18dbd178d6b4f300e6d6799", "target": 1, "func": "static void do_video_out(AVFormatContext *s,\n\n                         AVOutputStream *ost,\n\n                         AVInputStream *ist,\n\n                         AVFrame *in_picture,\n\n                         int *frame_size)\n\n{\n\n    int nb_frames, i, ret;\n\n    int64_t topBand, bottomBand, leftBand, rightBand;\n\n    AVFrame *final_picture, *formatted_picture, *resampling_dst, *padding_src;\n\n    AVFrame picture_crop_temp, picture_pad_temp;\n\n    AVCodecContext *enc, *dec;\n\n\n\n    avcodec_get_frame_defaults(&picture_crop_temp);\n\n    avcodec_get_frame_defaults(&picture_pad_temp);\n\n\n\n    enc = ost->st->codec;\n\n    dec = ist->st->codec;\n\n\n\n    /* by default, we output a single frame */\n\n    nb_frames = 1;\n\n\n\n    *frame_size = 0;\n\n\n\n    if(video_sync_method){\n\n        double vdelta;\n\n        vdelta = get_sync_ipts(ost) / av_q2d(enc->time_base) - ost->sync_opts;\n\n        //FIXME set to 0.5 after we fix some dts/pts bugs like in avidec.c\n\n        if (vdelta < -1.1)\n\n            nb_frames = 0;\n\n        else if (video_sync_method == 2 || (video_sync_method<0 && (s->oformat->flags & AVFMT_VARIABLE_FPS))){\n\n            if(vdelta<=-0.6){\n\n                nb_frames=0;\n\n            }else if(vdelta>0.6)\n\n            ost->sync_opts= lrintf(get_sync_ipts(ost) / av_q2d(enc->time_base));\n\n        }else if (vdelta > 1.1)\n\n            nb_frames = lrintf(vdelta);\n\n//fprintf(stderr, \"vdelta:%f, ost->sync_opts:%\"PRId64\", ost->sync_ipts:%f nb_frames:%d\\n\", vdelta, ost->sync_opts, get_sync_ipts(ost), nb_frames);\n\n        if (nb_frames == 0){\n\n            ++nb_frames_drop;\n\n            if (verbose>2)\n\n                fprintf(stderr, \"*** drop!\\n\");\n\n        }else if (nb_frames > 1) {\n\n            nb_frames_dup += nb_frames;\n\n            if (verbose>2)\n\n                fprintf(stderr, \"*** %d dup!\\n\", nb_frames-1);\n\n        }\n\n    }else\n\n        ost->sync_opts= lrintf(get_sync_ipts(ost) / av_q2d(enc->time_base));\n\n\n\n    nb_frames= FFMIN(nb_frames, max_frames[CODEC_TYPE_VIDEO] - ost->frame_number);\n\n    if (nb_frames <= 0)\n\n        return;\n\n\n\n    if (ost->video_crop) {\n\n        if (av_picture_crop((AVPicture *)&picture_crop_temp, (AVPicture *)in_picture, dec->pix_fmt, ost->topBand, ost->leftBand) < 0) {\n\n            fprintf(stderr, \"error cropping picture\\n\");\n\n            if (exit_on_error)\n\n                av_exit(1);\n\n            return;\n\n        }\n\n        formatted_picture = &picture_crop_temp;\n\n    } else {\n\n        formatted_picture = in_picture;\n\n    }\n\n\n\n    final_picture = formatted_picture;\n\n    padding_src = formatted_picture;\n\n    resampling_dst = &ost->pict_tmp;\n\n    if (ost->video_pad) {\n\n        final_picture = &ost->pict_tmp;\n\n        if (ost->video_resample) {\n\n            if (av_picture_crop((AVPicture *)&picture_pad_temp, (AVPicture *)final_picture, enc->pix_fmt, ost->padtop, ost->padleft) < 0) {\n\n                fprintf(stderr, \"error padding picture\\n\");\n\n                if (exit_on_error)\n\n                    av_exit(1);\n\n                return;\n\n            }\n\n            resampling_dst = &picture_pad_temp;\n\n        }\n\n    }\n\n\n\n    if (ost->video_resample) {\n\n        padding_src = NULL;\n\n        final_picture = &ost->pict_tmp;\n\n        if(  (ost->resample_height != (ist->st->codec->height - (ost->topBand  + ost->bottomBand)))\n\n          || (ost->resample_width  != (ist->st->codec->width  - (ost->leftBand + ost->rightBand)))\n\n          || (ost->resample_pix_fmt!= ist->st->codec->pix_fmt) ) {\n\n\n\n            fprintf(stderr,\"Input Stream #%d.%d frame size changed to %dx%d, %s\\n\", ist->file_index, ist->index, ist->st->codec->width, ist->st->codec->height,avcodec_get_pix_fmt_name(ist->st->codec->pix_fmt));\n\n            /* keep bands proportional to the frame size */\n\n            topBand    = ((int64_t)ist->st->codec->height * ost->original_topBand    / ost->original_height) & ~1;\n\n            bottomBand = ((int64_t)ist->st->codec->height * ost->original_bottomBand / ost->original_height) & ~1;\n\n            leftBand   = ((int64_t)ist->st->codec->width  * ost->original_leftBand   / ost->original_width)  & ~1;\n\n            rightBand  = ((int64_t)ist->st->codec->width  * ost->original_rightBand  / ost->original_width)  & ~1;\n\n\n\n            /* sanity check to ensure no bad band sizes sneak in */\n\n            assert(topBand    <= INT_MAX && topBand    >= 0);\n\n            assert(bottomBand <= INT_MAX && bottomBand >= 0);\n\n            assert(leftBand   <= INT_MAX && leftBand   >= 0);\n\n            assert(rightBand  <= INT_MAX && rightBand  >= 0);\n\n\n\n            ost->topBand    = topBand;\n\n            ost->bottomBand = bottomBand;\n\n            ost->leftBand   = leftBand;\n\n            ost->rightBand  = rightBand;\n\n\n\n            ost->resample_height = ist->st->codec->height - (ost->topBand  + ost->bottomBand);\n\n            ost->resample_width  = ist->st->codec->width  - (ost->leftBand + ost->rightBand);\n\n            ost->resample_pix_fmt= ist->st->codec->pix_fmt;\n\n\n\n            /* initialize a new scaler context */\n\n            sws_freeContext(ost->img_resample_ctx);\n\n            sws_flags = av_get_int(sws_opts, \"sws_flags\", NULL);\n\n            ost->img_resample_ctx = sws_getContext(\n\n                ist->st->codec->width  - (ost->leftBand + ost->rightBand),\n\n                ist->st->codec->height - (ost->topBand  + ost->bottomBand),\n\n                ist->st->codec->pix_fmt,\n\n                ost->st->codec->width  - (ost->padleft  + ost->padright),\n\n                ost->st->codec->height - (ost->padtop   + ost->padbottom),\n\n                ost->st->codec->pix_fmt,\n\n                sws_flags, NULL, NULL, NULL);\n\n            if (ost->img_resample_ctx == NULL) {\n\n                fprintf(stderr, \"Cannot get resampling context\\n\");\n\n                av_exit(1);\n\n            }\n\n        }\n\n        sws_scale(ost->img_resample_ctx, formatted_picture->data, formatted_picture->linesize,\n\n              0, ost->resample_height, resampling_dst->data, resampling_dst->linesize);\n\n    }\n\n\n\n    if (ost->video_pad) {\n\n        av_picture_pad((AVPicture*)final_picture, (AVPicture *)padding_src,\n\n                enc->height, enc->width, enc->pix_fmt,\n\n                ost->padtop, ost->padbottom, ost->padleft, ost->padright, padcolor);\n\n    }\n\n\n\n    /* duplicates frame if needed */\n\n    for(i=0;i<nb_frames;i++) {\n\n        AVPacket pkt;\n\n        av_init_packet(&pkt);\n\n        pkt.stream_index= ost->index;\n\n\n\n        if (s->oformat->flags & AVFMT_RAWPICTURE) {\n\n            /* raw pictures are written as AVPicture structure to\n\n               avoid any copies. We support temorarily the older\n\n               method. */\n\n            AVFrame* old_frame = enc->coded_frame;\n\n            enc->coded_frame = dec->coded_frame; //FIXME/XXX remove this hack\n\n            pkt.data= (uint8_t *)final_picture;\n\n            pkt.size=  sizeof(AVPicture);\n\n            pkt.pts= av_rescale_q(ost->sync_opts, enc->time_base, ost->st->time_base);\n\n            pkt.flags |= PKT_FLAG_KEY;\n\n\n\n            write_frame(s, &pkt, ost->st->codec, bitstream_filters[ost->file_index][pkt.stream_index]);\n\n            enc->coded_frame = old_frame;\n\n        } else {\n\n            AVFrame big_picture;\n\n\n\n            big_picture= *final_picture;\n\n            /* better than nothing: use input picture interlaced\n\n               settings */\n\n            big_picture.interlaced_frame = in_picture->interlaced_frame;\n\n            if(avcodec_opts[CODEC_TYPE_VIDEO]->flags & (CODEC_FLAG_INTERLACED_DCT|CODEC_FLAG_INTERLACED_ME)){\n\n                if(top_field_first == -1)\n\n                    big_picture.top_field_first = in_picture->top_field_first;\n\n                else\n\n                    big_picture.top_field_first = top_field_first;\n\n            }\n\n\n\n            /* handles sameq here. This is not correct because it may\n\n               not be a global option */\n\n            if (same_quality) {\n\n                big_picture.quality = ist->st->quality;\n\n            }else\n\n                big_picture.quality = ost->st->quality;\n\n            if(!me_threshold)\n\n                big_picture.pict_type = 0;\n\n//            big_picture.pts = AV_NOPTS_VALUE;\n\n            big_picture.pts= ost->sync_opts;\n\n//            big_picture.pts= av_rescale(ost->sync_opts, AV_TIME_BASE*(int64_t)enc->time_base.num, enc->time_base.den);\n\n//av_log(NULL, AV_LOG_DEBUG, \"%\"PRId64\" -> encoder\\n\", ost->sync_opts);\n\n            ret = avcodec_encode_video(enc,\n\n                                       bit_buffer, bit_buffer_size,\n\n                                       &big_picture);\n\n            if (ret < 0) {\n\n                fprintf(stderr, \"Video encoding failed\\n\");\n\n                av_exit(1);\n\n            }\n\n\n\n            if(ret>0){\n\n                pkt.data= bit_buffer;\n\n                pkt.size= ret;\n\n                if(enc->coded_frame->pts != AV_NOPTS_VALUE)\n\n                    pkt.pts= av_rescale_q(enc->coded_frame->pts, enc->time_base, ost->st->time_base);\n\n/*av_log(NULL, AV_LOG_DEBUG, \"encoder -> %\"PRId64\"/%\"PRId64\"\\n\",\n\n   pkt.pts != AV_NOPTS_VALUE ? av_rescale(pkt.pts, enc->time_base.den, AV_TIME_BASE*(int64_t)enc->time_base.num) : -1,\n\n   pkt.dts != AV_NOPTS_VALUE ? av_rescale(pkt.dts, enc->time_base.den, AV_TIME_BASE*(int64_t)enc->time_base.num) : -1);*/\n\n\n\n                if(enc->coded_frame->key_frame)\n\n                    pkt.flags |= PKT_FLAG_KEY;\n\n                write_frame(s, &pkt, ost->st->codec, bitstream_filters[ost->file_index][pkt.stream_index]);\n\n                *frame_size = ret;\n\n                video_size += ret;\n\n                //fprintf(stderr,\"\\nFrame: %3d size: %5d type: %d\",\n\n                //        enc->frame_number-1, ret, enc->pict_type);\n\n                /* if two pass, output log */\n\n                if (ost->logfile && enc->stats_out) {\n\n                    fprintf(ost->logfile, \"%s\", enc->stats_out);\n\n                }\n\n            }\n\n        }\n\n        ost->sync_opts++;\n\n        ost->frame_number++;\n\n    }\n\n}\n", "idx": 24564}
{"project": "FFmpeg", "commit_id": "220b24c7c97dc033ceab1510549f66d0e7b52ef1", "target": 1, "func": "static void libschroedinger_decode_frame_free(void *frame)\n\n{\n\n    schro_frame_unref(frame);\n\n}\n", "idx": 24566}
{"project": "FFmpeg", "commit_id": "5ef19590802f000299e418143fc2301e3f43affe", "target": 1, "func": "static OutputStream *new_output_stream(OptionsContext *o, AVFormatContext *oc, enum AVMediaType type, int source_index)\n\n{\n\n    OutputStream *ost;\n\n    AVStream *st = avformat_new_stream(oc, NULL);\n\n    int idx      = oc->nb_streams - 1, ret = 0;\n\n    char *bsf = NULL, *next, *codec_tag = NULL;\n\n    AVBitStreamFilterContext *bsfc, *bsfc_prev = NULL;\n\n    double qscale = -1;\n\n    int i;\n\n\n\n    if (!st) {\n\n        av_log(NULL, AV_LOG_FATAL, \"Could not alloc stream.\\n\");\n\n        exit_program(1);\n\n    }\n\n\n\n    if (oc->nb_streams - 1 < o->nb_streamid_map)\n\n        st->id = o->streamid_map[oc->nb_streams - 1];\n\n\n\n    GROW_ARRAY(output_streams, nb_output_streams);\n\n    if (!(ost = av_mallocz(sizeof(*ost))))\n\n        exit_program(1);\n\n    output_streams[nb_output_streams - 1] = ost;\n\n\n\n    ost->file_index = nb_output_files - 1;\n\n    ost->index      = idx;\n\n    ost->st         = st;\n\n    st->codecpar->codec_type = type;\n\n\n\n    ret = choose_encoder(o, oc, ost);\n\n    if (ret < 0) {\n\n        av_log(NULL, AV_LOG_FATAL, \"Error selecting an encoder for stream \"\n\n               \"%d:%d\\n\", ost->file_index, ost->index);\n\n        exit_program(1);\n\n    }\n\n\n\n    ost->enc_ctx = avcodec_alloc_context3(ost->enc);\n\n    if (!ost->enc_ctx) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Error allocating the encoding context.\\n\");\n\n        exit_program(1);\n\n    }\n\n    ost->enc_ctx->codec_type = type;\n\n\n\n    ost->ref_par = avcodec_parameters_alloc();\n\n    if (!ost->ref_par) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Error allocating the encoding parameters.\\n\");\n\n        exit_program(1);\n\n    }\n\n\n\n    if (ost->enc) {\n\n        AVIOContext *s = NULL;\n\n        char *buf = NULL, *arg = NULL, *preset = NULL;\n\n\n\n        ost->encoder_opts  = filter_codec_opts(o->g->codec_opts, ost->enc->id, oc, st, ost->enc);\n\n\n\n        MATCH_PER_STREAM_OPT(presets, str, preset, oc, st);\n\n        if (preset && (!(ret = get_preset_file_2(preset, ost->enc->name, &s)))) {\n\n            do  {\n\n                buf = get_line(s);\n\n                if (!buf[0] || buf[0] == '#') {\n\n                    av_free(buf);\n\n                    continue;\n\n                }\n\n                if (!(arg = strchr(buf, '='))) {\n\n                    av_log(NULL, AV_LOG_FATAL, \"Invalid line found in the preset file.\\n\");\n\n                    exit_program(1);\n\n                }\n\n                *arg++ = 0;\n\n                av_dict_set(&ost->encoder_opts, buf, arg, AV_DICT_DONT_OVERWRITE);\n\n                av_free(buf);\n\n            } while (!s->eof_reached);\n\n            avio_closep(&s);\n\n        }\n\n        if (ret) {\n\n            av_log(NULL, AV_LOG_FATAL,\n\n                   \"Preset %s specified for stream %d:%d, but could not be opened.\\n\",\n\n                   preset, ost->file_index, ost->index);\n\n            exit_program(1);\n\n        }\n\n    } else {\n\n        ost->encoder_opts = filter_codec_opts(o->g->codec_opts, AV_CODEC_ID_NONE, oc, st, NULL);\n\n    }\n\n\n\n    ost->max_frames = INT64_MAX;\n\n    MATCH_PER_STREAM_OPT(max_frames, i64, ost->max_frames, oc, st);\n\n    for (i = 0; i<o->nb_max_frames; i++) {\n\n        char *p = o->max_frames[i].specifier;\n\n        if (!*p && type != AVMEDIA_TYPE_VIDEO) {\n\n            av_log(NULL, AV_LOG_WARNING, \"Applying unspecific -frames to non video streams, maybe you meant -vframes ?\\n\");\n\n            break;\n\n        }\n\n    }\n\n\n\n    ost->copy_prior_start = -1;\n\n    MATCH_PER_STREAM_OPT(copy_prior_start, i, ost->copy_prior_start, oc ,st);\n\n\n\n    MATCH_PER_STREAM_OPT(bitstream_filters, str, bsf, oc, st);\n\n    while (bsf) {\n\n        char *arg = NULL;\n\n        if (next = strchr(bsf, ','))\n\n            *next++ = 0;\n\n        if (arg = strchr(bsf, '='))\n\n            *arg++ = 0;\n\n        if (!(bsfc = av_bitstream_filter_init(bsf))) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Unknown bitstream filter %s\\n\", bsf);\n\n            exit_program(1);\n\n        }\n\n        if (bsfc_prev)\n\n            bsfc_prev->next = bsfc;\n\n        else\n\n            ost->bitstream_filters = bsfc;\n\n        if (arg)\n\n            if (!(bsfc->args = av_strdup(arg))) {\n\n                av_log(NULL, AV_LOG_FATAL, \"Bitstream filter memory allocation failed\\n\");\n\n                exit_program(1);\n\n            }\n\n\n\n        bsfc_prev = bsfc;\n\n        bsf       = next;\n\n    }\n\n\n\n    MATCH_PER_STREAM_OPT(codec_tags, str, codec_tag, oc, st);\n\n    if (codec_tag) {\n\n        uint32_t tag = strtol(codec_tag, &next, 0);\n\n        if (*next)\n\n            tag = AV_RL32(codec_tag);\n\n        ost->st->codecpar->codec_tag =\n\n        ost->enc_ctx->codec_tag = tag;\n\n    }\n\n\n\n    MATCH_PER_STREAM_OPT(qscale, dbl, qscale, oc, st);\n\n    if (qscale >= 0) {\n\n        ost->enc_ctx->flags |= AV_CODEC_FLAG_QSCALE;\n\n        ost->enc_ctx->global_quality = FF_QP2LAMBDA * qscale;\n\n    }\n\n\n\n    MATCH_PER_STREAM_OPT(disposition, str, ost->disposition, oc, st);\n\n    ost->disposition = av_strdup(ost->disposition);\n\n\n\n    if (oc->oformat->flags & AVFMT_GLOBALHEADER)\n\n        ost->enc_ctx->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;\n\n\n\n    av_dict_copy(&ost->sws_dict, o->g->sws_dict, 0);\n\n\n\n    av_dict_copy(&ost->swr_opts, o->g->swr_opts, 0);\n\n    if (ost->enc && av_get_exact_bits_per_sample(ost->enc->id) == 24)\n\n        av_dict_set(&ost->swr_opts, \"output_sample_bits\", \"24\", 0);\n\n\n\n    av_dict_copy(&ost->resample_opts, o->g->resample_opts, 0);\n\n\n\n    ost->source_index = source_index;\n\n    if (source_index >= 0) {\n\n        ost->sync_ist = input_streams[source_index];\n\n        input_streams[source_index]->discard = 0;\n\n        input_streams[source_index]->st->discard = input_streams[source_index]->user_set_discard;\n\n    }\n\n    ost->last_mux_dts = AV_NOPTS_VALUE;\n\n\n\n    return ost;\n\n}\n", "idx": 24568}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int estimate_best_b_count(MpegEncContext *s)\n\n{\n\n    AVCodec *codec    = avcodec_find_encoder(s->avctx->codec_id);\n\n    AVCodecContext *c = avcodec_alloc_context3(NULL);\n\n    const int scale = s->avctx->brd_scale;\n\n    int i, j, out_size, p_lambda, b_lambda, lambda2;\n\n    int64_t best_rd  = INT64_MAX;\n\n    int best_b_count = -1;\n\n\n\n    assert(scale >= 0 && scale <= 3);\n\n\n\n    //emms_c();\n\n    //s->next_picture_ptr->quality;\n\n    p_lambda = s->last_lambda_for[AV_PICTURE_TYPE_P];\n\n    //p_lambda * FFABS(s->avctx->b_quant_factor) + s->avctx->b_quant_offset;\n\n    b_lambda = s->last_lambda_for[AV_PICTURE_TYPE_B];\n\n    if (!b_lambda) // FIXME we should do this somewhere else\n\n        b_lambda = p_lambda;\n\n    lambda2  = (b_lambda * b_lambda + (1 << FF_LAMBDA_SHIFT) / 2) >>\n\n               FF_LAMBDA_SHIFT;\n\n\n\n    c->width        = s->width  >> scale;\n\n    c->height       = s->height >> scale;\n\n    c->flags        = CODEC_FLAG_QSCALE | CODEC_FLAG_PSNR |\n\n                      CODEC_FLAG_INPUT_PRESERVED;\n\n    c->flags       |= s->avctx->flags & CODEC_FLAG_QPEL;\n\n    c->mb_decision  = s->avctx->mb_decision;\n\n    c->me_cmp       = s->avctx->me_cmp;\n\n    c->mb_cmp       = s->avctx->mb_cmp;\n\n    c->me_sub_cmp   = s->avctx->me_sub_cmp;\n\n    c->pix_fmt      = AV_PIX_FMT_YUV420P;\n\n    c->time_base    = s->avctx->time_base;\n\n    c->max_b_frames = s->max_b_frames;\n\n\n\n    if (avcodec_open2(c, codec, NULL) < 0)\n\n        return -1;\n\n\n\n    for (i = 0; i < s->max_b_frames + 2; i++) {\n\n        Picture pre_input, *pre_input_ptr = i ? s->input_picture[i - 1] :\n\n                                                s->next_picture_ptr;\n\n\n\n        if (pre_input_ptr && (!i || s->input_picture[i - 1])) {\n\n            pre_input = *pre_input_ptr;\n\n\n\n            if (!pre_input.shared && i) {\n\n                pre_input.f.data[0] += INPLACE_OFFSET;\n\n                pre_input.f.data[1] += INPLACE_OFFSET;\n\n                pre_input.f.data[2] += INPLACE_OFFSET;\n\n            }\n\n\n\n            s->dsp.shrink[scale](s->tmp_frames[i]->data[0], s->tmp_frames[i]->linesize[0],\n\n                                 pre_input.f.data[0], pre_input.f.linesize[0],\n\n                                 c->width,      c->height);\n\n            s->dsp.shrink[scale](s->tmp_frames[i]->data[1], s->tmp_frames[i]->linesize[1],\n\n                                 pre_input.f.data[1], pre_input.f.linesize[1],\n\n                                 c->width >> 1, c->height >> 1);\n\n            s->dsp.shrink[scale](s->tmp_frames[i]->data[2], s->tmp_frames[i]->linesize[2],\n\n                                 pre_input.f.data[2], pre_input.f.linesize[2],\n\n                                 c->width >> 1, c->height >> 1);\n\n        }\n\n    }\n\n\n\n    for (j = 0; j < s->max_b_frames + 1; j++) {\n\n        int64_t rd = 0;\n\n\n\n        if (!s->input_picture[j])\n\n            break;\n\n\n\n        c->error[0] = c->error[1] = c->error[2] = 0;\n\n\n\n        s->tmp_frames[0]->pict_type = AV_PICTURE_TYPE_I;\n\n        s->tmp_frames[0]->quality   = 1 * FF_QP2LAMBDA;\n\n\n\n        out_size = encode_frame(c, s->tmp_frames[0]);\n\n\n\n        //rd += (out_size * lambda2) >> FF_LAMBDA_SHIFT;\n\n\n\n        for (i = 0; i < s->max_b_frames + 1; i++) {\n\n            int is_p = i % (j + 1) == j || i == s->max_b_frames;\n\n\n\n            s->tmp_frames[i + 1]->pict_type = is_p ?\n\n                                     AV_PICTURE_TYPE_P : AV_PICTURE_TYPE_B;\n\n            s->tmp_frames[i + 1]->quality   = is_p ? p_lambda : b_lambda;\n\n\n\n            out_size = encode_frame(c, s->tmp_frames[i + 1]);\n\n\n\n            rd += (out_size * lambda2) >> (FF_LAMBDA_SHIFT - 3);\n\n        }\n\n\n\n        /* get the delayed frames */\n\n        while (out_size) {\n\n            out_size = encode_frame(c, NULL);\n\n            rd += (out_size * lambda2) >> (FF_LAMBDA_SHIFT - 3);\n\n        }\n\n\n\n        rd += c->error[0] + c->error[1] + c->error[2];\n\n\n\n        if (rd < best_rd) {\n\n            best_rd = rd;\n\n            best_b_count = j;\n\n        }\n\n    }\n\n\n\n    avcodec_close(c);\n\n    av_freep(&c);\n\n\n\n    return best_b_count;\n\n}\n", "idx": 24570}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static int get_transform_coeffs(AC3DecodeContext * ctx)\n\n{\n\n    int i;\n\n    ac3_audio_block *ab = &ctx->audio_block;\n\n    float *samples = ctx->samples;\n\n    int got_cplchan = 0;\n\n    int dithflag = 0;\n\n\n\n    samples += (ctx->bsi.flags & AC3_BSI_LFEON) ? 256 : 0;\n\n    for (i = 0; i < ctx->bsi.nfchans; i++) {\n\n        if ((ab->flags & AC3_AB_CPLINU) && (ab->chincpl & (1 << i)))\n\n            dithflag = 0; /* don't generate dither until channels are decoupled */\n\n        else\n\n            dithflag = ab->dithflag & (1 << i);\n\n        /* transform coefficients for individual channel */\n\n        if (_get_transform_coeffs(ab->dexps[i], ab->bap[i], ab->chcoeffs[i], samples + (i * 256),\n\n                    0, ab->endmant[i], dithflag, &ctx->gb, &ctx->state))\n\n            return -1;\n\n        /* tranform coefficients for coupling channels */\n\n        if ((ab->flags & AC3_AB_CPLINU) && (ab->chincpl & (1 << i)) && !got_cplchan) {\n\n            if (_get_transform_coeffs(ab->dcplexps, ab->cplbap, 1.0f, ab->cplcoeffs,\n\n                        ab->cplstrtmant, ab->cplendmant, 0, &ctx->gb, &ctx->state))\n\n                return -1;\n\n            got_cplchan = 1;\n\n        }\n\n    }\n\n    if (ctx->bsi.flags & AC3_BSI_LFEON)\n\n        if (_get_transform_coeffs(ab->lfeexps, ab->lfebap, 1.0f, samples - 256, 0, 7, 0, &ctx->gb, &ctx->state))\n\n                return -1;\n\n\n\n    /* uncouple the channels from the coupling channel */\n\n    if (ab->flags & AC3_AB_CPLINU)\n\n        if (uncouple_channels(ctx))\n\n            return -1;\n\n\n\n    return 0;\n\n}\n", "idx": 24571}
{"project": "FFmpeg", "commit_id": "f5fbbbc022f723d3ccf99afd5d658a977b51c08a", "target": 0, "func": "static int mxf_add_metadata_set(MXFContext *mxf, void *metadata_set)\n\n{\n\n    int err;\n\n\n\n    if (mxf->metadata_sets_count+1 >= UINT_MAX / sizeof(*mxf->metadata_sets))\n\n        return AVERROR(ENOMEM);\n\n    if ((err = av_reallocp_array(&mxf->metadata_sets, mxf->metadata_sets_count + 1,\n\n                                 sizeof(*mxf->metadata_sets))) < 0) {\n\n        mxf->metadata_sets_count = 0;\n\n        return err;\n\n    }\n\n    mxf->metadata_sets[mxf->metadata_sets_count] = metadata_set;\n\n    mxf->metadata_sets_count++;\n\n    return 0;\n\n}\n", "idx": 24572}
{"project": "FFmpeg", "commit_id": "778111592bf5f38630858ee6dfcfd097cd6c6da9", "target": 0, "func": "static int dvvideo_encode_frame(AVCodecContext *c, AVPacket *pkt,\n\n                                const AVFrame *frame, int *got_packet)\n\n{\n\n    DVVideoContext *s = c->priv_data;\n\n    int ret;\n\n\n\n    s->sys = avpriv_dv_codec_profile(c);\n\n    if (!s->sys || ff_dv_init_dynamic_tables(s->sys))\n\n        return -1;\n\n    if ((ret = ff_alloc_packet(pkt, s->sys->frame_size)) < 0) {\n\n        av_log(c, AV_LOG_ERROR, \"Error getting output packet.\\n\");\n\n        return ret;\n\n    }\n\n\n\n    c->pix_fmt                = s->sys->pix_fmt;\n\n    s->frame                  = frame;\n\n    c->coded_frame->key_frame = 1;\n\n    c->coded_frame->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    s->buf = pkt->data;\n\n    c->execute(c, dv_encode_video_segment, s->sys->work_chunks, NULL,\n\n               dv_work_pool_size(s->sys), sizeof(DVwork_chunk));\n\n\n\n    emms_c();\n\n\n\n    dv_format_frame(s, pkt->data);\n\n\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n\n    *got_packet = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 24573}
{"project": "FFmpeg", "commit_id": "cfa3caf81cd64485b80def8bb2552c2dafac5eb4", "target": 0, "func": "static void mxf_write_partition(AVFormatContext *s, int bodysid,\n\n                                int indexsid,\n\n                                const uint8_t *key, int write_metadata)\n\n{\n\n    MXFContext *mxf = s->priv_data;\n\n    ByteIOContext *pb = s->pb;\n\n    int64_t header_byte_count_offset;\n\n    unsigned index_byte_count = 0;\n\n    uint64_t partition_offset = url_ftell(pb);\n\n\n\n    if (mxf->edit_units_count) {\n\n        index_byte_count = 109 + (s->nb_streams+1)*6 +\n\n            mxf->edit_units_count*(11+mxf->slice_count*4);\n\n        // add encoded ber length\n\n        index_byte_count += 16 + klv_ber_length(index_byte_count);\n\n        index_byte_count += klv_fill_size(index_byte_count);\n\n    }\n\n\n\n    if (!memcmp(key, body_partition_key, 16)) {\n\n        mxf->body_partition_offset =\n\n            av_realloc(mxf->body_partition_offset,\n\n                       (mxf->body_partitions_count+1)*\n\n                       sizeof(*mxf->body_partition_offset));\n\n        mxf->body_partition_offset[mxf->body_partitions_count++] = partition_offset;\n\n    }\n\n\n\n    // write klv\n\n    put_buffer(pb, key, 16);\n\n\n\n    klv_encode_ber_length(pb, 88 + 16 * mxf->essence_container_count);\n\n\n\n    // write partition value\n\n    put_be16(pb, 1); // majorVersion\n\n    put_be16(pb, 2); // minorVersion\n\n    put_be32(pb, KAG_SIZE); // KAGSize\n\n\n\n    put_be64(pb, partition_offset); // ThisPartition\n\n\n\n    if (!memcmp(key, body_partition_key, 16) && mxf->body_partitions_count > 1)\n\n        put_be64(pb, mxf->body_partition_offset[mxf->body_partitions_count-2]); // PreviousPartition\n\n    else if (!memcmp(key, footer_partition_key, 16))\n\n        put_be64(pb, mxf->body_partition_offset[mxf->body_partitions_count-1]); // PreviousPartition\n\n    else\n\n        put_be64(pb, 0);\n\n\n\n    put_be64(pb, mxf->footer_partition_offset); // footerPartition\n\n\n\n    // set offset\n\n    header_byte_count_offset = url_ftell(pb);\n\n    put_be64(pb, 0); // headerByteCount, update later\n\n\n\n    // indexTable\n\n    put_be64(pb, index_byte_count); // indexByteCount\n\n    put_be32(pb, index_byte_count ? indexsid : 0); // indexSID\n\n\n\n    // BodyOffset\n\n    if (bodysid && mxf->edit_units_count) {\n\n        uint64_t partition_end = url_ftell(pb) + 8 + 4 + 16 + 8 +\n\n            16*mxf->essence_container_count;\n\n        put_be64(pb, partition_end + klv_fill_size(partition_end) +\n\n                 index_byte_count - mxf->first_edit_unit_offset);\n\n    } else\n\n        put_be64(pb, 0);\n\n\n\n    put_be32(pb, bodysid); // bodySID\n\n\n\n    // operational pattern\n\n    if (s->nb_streams > 1) {\n\n        put_buffer(pb, op1a_ul, 14);\n\n        put_be16(pb, 0x0900); // multi track\n\n    } else {\n\n        put_buffer(pb, op1a_ul, 16);\n\n    }\n\n\n\n    // essence container\n\n    mxf_write_essence_container_refs(s);\n\n\n\n    if (write_metadata) {\n\n        // mark the start of the headermetadata and calculate metadata size\n\n        int64_t pos, start;\n\n        unsigned header_byte_count;\n\n\n\n        mxf_write_klv_fill(s);\n\n        start = url_ftell(s->pb);\n\n        mxf_write_primer_pack(s);\n\n        mxf_write_header_metadata_sets(s);\n\n        pos = url_ftell(s->pb);\n\n        header_byte_count = pos - start + klv_fill_size(pos);\n\n\n\n        // update header_byte_count\n\n        url_fseek(pb, header_byte_count_offset, SEEK_SET);\n\n        put_be64(pb, header_byte_count);\n\n        url_fseek(pb, pos, SEEK_SET);\n\n    }\n\n\n\n    put_flush_packet(pb);\n\n}\n", "idx": 24574}
{"project": "FFmpeg", "commit_id": "435a6082f9e368196e0d8347858c63de1126af2c", "target": 0, "func": "static int str_read_packet(AVFormatContext *s,\n\n                           AVPacket *ret_pkt)\n\n{\n\n    ByteIOContext *pb = s->pb;\n\n    StrDemuxContext *str = s->priv_data;\n\n    unsigned char sector[RAW_CD_SECTOR_SIZE];\n\n    int channel;\n\n    AVPacket *pkt;\n\n    AVStream *st;\n\n\n\n    while (1) {\n\n\n\n        if (get_buffer(pb, sector, RAW_CD_SECTOR_SIZE) != RAW_CD_SECTOR_SIZE)\n\n            return AVERROR(EIO);\n\n\n\n        channel = sector[0x11];\n\n        if (channel >= 32)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        switch (sector[0x12] & CDXA_TYPE_MASK) {\n\n\n\n        case CDXA_TYPE_DATA:\n\n        case CDXA_TYPE_VIDEO:\n\n            {\n\n\n\n                int current_sector = AV_RL16(&sector[0x1C]);\n\n                int sector_count   = AV_RL16(&sector[0x1E]);\n\n                int frame_size = AV_RL32(&sector[0x24]);\n\n\n\n                if(!(   frame_size>=0\n\n                     && current_sector < sector_count\n\n                     && sector_count*VIDEO_DATA_CHUNK_SIZE >=frame_size)){\n\n                    av_log(s, AV_LOG_ERROR, \"Invalid parameters %d %d %d\\n\", current_sector, sector_count, frame_size);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                if(str->channels[channel].video_stream_index < 0){\n\n                    /* allocate a new AVStream */\n\n                    st = av_new_stream(s, 0);\n\n                    if (!st)\n\n                        return AVERROR(ENOMEM);\n\n                    av_set_pts_info(st, 64, 1, 15);\n\n\n\n                    str->channels[channel].video_stream_index = st->index;\n\n\n\n                    st->codec->codec_type = CODEC_TYPE_VIDEO;\n\n                    st->codec->codec_id   = CODEC_ID_MDEC;\n\n                    st->codec->codec_tag  = 0;  /* no fourcc */\n\n                    st->codec->width      = AV_RL16(&sector[0x28]);\n\n                    st->codec->height     = AV_RL16(&sector[0x2A]);\n\n                }\n\n\n\n                /* if this is the first sector of the frame, allocate a pkt */\n\n                pkt = &str->channels[channel].tmp_pkt;\n\n\n\n                if(pkt->size != sector_count*VIDEO_DATA_CHUNK_SIZE){\n\n                    if(pkt->data)\n\n                        av_log(s, AV_LOG_ERROR, \"missmatching sector_count\\n\");\n\n                    av_free_packet(pkt);\n\n                    if (av_new_packet(pkt, sector_count*VIDEO_DATA_CHUNK_SIZE))\n\n                        return AVERROR(EIO);\n\n\n\n                    pkt->pos= url_ftell(pb) - RAW_CD_SECTOR_SIZE;\n\n                    pkt->stream_index =\n\n                        str->channels[channel].video_stream_index;\n\n                }\n\n\n\n                memcpy(pkt->data + current_sector*VIDEO_DATA_CHUNK_SIZE,\n\n                       sector + VIDEO_DATA_HEADER_SIZE,\n\n                       VIDEO_DATA_CHUNK_SIZE);\n\n\n\n                if (current_sector == sector_count-1) {\n\n                    pkt->size= frame_size;\n\n                    *ret_pkt = *pkt;\n\n                    pkt->data= NULL;\n\n                    pkt->size= -1;\n\n                    return 0;\n\n                }\n\n\n\n            }\n\n            break;\n\n\n\n        case CDXA_TYPE_AUDIO:\n\n            if(str->channels[channel].audio_stream_index < 0){\n\n                int fmt = sector[0x13];\n\n                /* allocate a new AVStream */\n\n                st = av_new_stream(s, 0);\n\n                if (!st)\n\n                    return AVERROR(ENOMEM);\n\n\n\n                str->channels[channel].audio_stream_index = st->index;\n\n\n\n                st->codec->codec_type  = CODEC_TYPE_AUDIO;\n\n                st->codec->codec_id    = CODEC_ID_ADPCM_XA;\n\n                st->codec->codec_tag   = 0;  /* no fourcc */\n\n                st->codec->channels    = (fmt&1)?2:1;\n\n                st->codec->sample_rate = (fmt&4)?18900:37800;\n\n            //    st->codec->bit_rate = 0; //FIXME;\n\n                st->codec->block_align = 128;\n\n\n\n                av_set_pts_info(st, 64, 128, st->codec->sample_rate);\n\n            }\n\n                pkt = ret_pkt;\n\n                if (av_new_packet(pkt, 2304))\n\n                    return AVERROR(EIO);\n\n                memcpy(pkt->data,sector+24,2304);\n\n\n\n                pkt->stream_index =\n\n                    str->channels[channel].audio_stream_index;\n\n                return 0;\n\n            break;\n\n        default:\n\n            /* drop the sector and move on */\n\n            break;\n\n        }\n\n\n\n        if (url_feof(pb))\n\n            return AVERROR(EIO);\n\n    }\n\n}\n", "idx": 24575}
{"project": "FFmpeg", "commit_id": "7f938dd32bed373560e06a6f884f5d73415ed788", "target": 1, "func": "static void av_update_stream_timings(AVFormatContext *ic)\n\n{\n\n    int64_t start_time, start_time1, end_time, end_time1;\n\n    int64_t duration, duration1;\n\n    int i;\n\n    AVStream *st;\n\n\n\n    start_time = INT64_MAX;\n\n    end_time = INT64_MIN;\n\n    duration = INT64_MIN;\n\n    for(i = 0;i < ic->nb_streams; i++) {\n\n        st = ic->streams[i];\n\n        if (st->start_time != AV_NOPTS_VALUE) {\n\n            start_time1= av_rescale_q(st->start_time, st->time_base, AV_TIME_BASE_Q);\n\n            if (start_time1 < start_time)\n\n                start_time = start_time1;\n\n            if (st->duration != AV_NOPTS_VALUE) {\n\n                end_time1 = start_time1\n\n                          + av_rescale_q(st->duration, st->time_base, AV_TIME_BASE_Q);\n\n                if (end_time1 > end_time)\n\n                    end_time = end_time1;\n\n            }\n\n        }\n\n        if (st->duration != AV_NOPTS_VALUE) {\n\n            duration1 = av_rescale_q(st->duration, st->time_base, AV_TIME_BASE_Q);\n\n            if (duration1 > duration)\n\n                duration = duration1;\n\n        }\n\n    }\n\n    if (start_time != INT64_MAX) {\n\n        ic->start_time = start_time;\n\n        if (end_time != INT64_MIN) {\n\n            if (end_time - start_time > duration)\n\n                duration = end_time - start_time;\n\n        }\n\n    }\n\n    if (duration != INT64_MIN) {\n\n        ic->duration = duration;\n\n        if (ic->file_size > 0) {\n\n            /* compute the bitrate */\n\n            ic->bit_rate = (double)ic->file_size * 8.0 * AV_TIME_BASE /\n\n                (double)ic->duration;\n\n        }\n\n    }\n\n}\n", "idx": 24581}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(rgb32tobgr24)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n    uint8_t *dest = dst;\n\n    const uint8_t *s = src;\n\n    const uint8_t *end;\n\n#if COMPILE_TEMPLATE_MMX\n\n    const uint8_t *mm_end;\n\n#endif\n\n    end = s + src_size;\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*s):\"memory\");\n\n    mm_end = end - 31;\n\n    while (s < mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"    32%1           \\n\\t\"\n\n            \"movq          %1, %%mm0    \\n\\t\"\n\n            \"movq         8%1, %%mm1    \\n\\t\"\n\n            \"movq        16%1, %%mm4    \\n\\t\"\n\n            \"movq        24%1, %%mm5    \\n\\t\"\n\n            \"movq       %%mm0, %%mm2    \\n\\t\"\n\n            \"movq       %%mm1, %%mm3    \\n\\t\"\n\n            \"movq       %%mm4, %%mm6    \\n\\t\"\n\n            \"movq       %%mm5, %%mm7    \\n\\t\"\n\n            STORE_BGR24_MMX\n\n            :\"=m\"(*dest)\n\n            :\"m\"(*s)\n\n            :\"memory\");\n\n        dest += 24;\n\n        s += 32;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n#endif\n\n    while (s < end) {\n\n#if HAVE_BIGENDIAN\n\n        /* RGB32 (= A,B,G,R) -> RGB24 (= R,G,B) */\n\n        s++;\n\n        dest[2] = *s++;\n\n        dest[1] = *s++;\n\n        dest[0] = *s++;\n\n        dest += 3;\n\n#else\n\n        *dest++ = *s++;\n\n        *dest++ = *s++;\n\n        *dest++ = *s++;\n\n        s++;\n\n#endif\n\n    }\n\n}\n", "idx": 24587}
{"project": "FFmpeg", "commit_id": "dcc39ee10e82833ce24aa57926c00ffeb1948198", "target": 0, "func": "av_cold int ff_intrax8_common_init(AVCodecContext *avctx,\n\n                                   IntraX8Context *w, IDCTDSPContext *idsp,\n\n                                   int16_t (*block)[64],\n\n                                   int block_last_index[12],\n\n                                   int mb_width, int mb_height)\n\n{\n\n    int ret = x8_vlc_init();\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    w->avctx = avctx;\n\n    w->idsp = *idsp;\n\n    w->mb_width  = mb_width;\n\n    w->mb_height = mb_height;\n\n    w->block = block;\n\n    w->block_last_index = block_last_index;\n\n\n\n    // two rows, 2 blocks per cannon mb\n\n    w->prediction_table = av_mallocz(w->mb_width * 2 * 2);\n\n    if (!w->prediction_table)\n\n        return AVERROR(ENOMEM);\n\n\n\n    ff_init_scantable(w->idsp.idct_permutation, &w->scantable[0],\n\n                      ff_wmv1_scantable[0]);\n\n    ff_init_scantable(w->idsp.idct_permutation, &w->scantable[1],\n\n                      ff_wmv1_scantable[2]);\n\n    ff_init_scantable(w->idsp.idct_permutation, &w->scantable[2],\n\n                      ff_wmv1_scantable[3]);\n\n\n\n    ff_intrax8dsp_init(&w->dsp);\n\n    ff_blockdsp_init(&w->bdsp, avctx);\n\n\n\n    return 0;\n\n}\n", "idx": 24598}
{"project": "FFmpeg", "commit_id": "150ddbc1482c65b9aac803f011d7fcd734f776ec", "target": 0, "func": "static void do_video_out(AVFormatContext *s,\n\n                         OutputStream *ost,\n\n                         InputStream *ist,\n\n                         AVFrame *in_picture,\n\n                         int *frame_size, float quality)\n\n{\n\n    int nb_frames, i, ret, format_video_sync;\n\n    AVFrame *final_picture;\n\n    AVCodecContext *enc;\n\n    double sync_ipts;\n\n\n\n    enc = ost->st->codec;\n\n\n\n    sync_ipts = get_sync_ipts(ost) / av_q2d(enc->time_base);\n\n\n\n    /* by default, we output a single frame */\n\n    nb_frames = 1;\n\n\n\n    *frame_size = 0;\n\n\n\n    format_video_sync = video_sync_method;\n\n    if (format_video_sync < 0)\n\n        format_video_sync = (s->oformat->flags & AVFMT_NOTIMESTAMPS) ? 0 :\n\n                            (s->oformat->flags & AVFMT_VARIABLE_FPS) ? 2 : 1;\n\n\n\n    if (format_video_sync) {\n\n        double vdelta = sync_ipts - ost->sync_opts;\n\n        //FIXME set to 0.5 after we fix some dts/pts bugs like in avidec.c\n\n        if (vdelta < -1.1)\n\n            nb_frames = 0;\n\n        else if (format_video_sync == 2) {\n\n            if(vdelta<=-0.6){\n\n                nb_frames=0;\n\n            }else if(vdelta>0.6)\n\n                ost->sync_opts= lrintf(sync_ipts);\n\n        }else if (vdelta > 1.1)\n\n            nb_frames = lrintf(vdelta);\n\n//fprintf(stderr, \"vdelta:%f, ost->sync_opts:%\"PRId64\", ost->sync_ipts:%f nb_frames:%d\\n\", vdelta, ost->sync_opts, get_sync_ipts(ost), nb_frames);\n\n        if (nb_frames == 0){\n\n            ++nb_frames_drop;\n\n            av_log(NULL, AV_LOG_VERBOSE, \"*** drop!\\n\");\n\n        }else if (nb_frames > 1) {\n\n            nb_frames_dup += nb_frames - 1;\n\n            av_log(NULL, AV_LOG_VERBOSE, \"*** %d dup!\\n\", nb_frames-1);\n\n        }\n\n    }else\n\n        ost->sync_opts= lrintf(sync_ipts);\n\n\n\n    nb_frames = FFMIN(nb_frames, ost->max_frames - ost->frame_number);\n\n    if (nb_frames <= 0)\n\n        return;\n\n\n\n    do_video_resample(ost, ist, in_picture, &final_picture);\n\n\n\n    /* duplicates frame if needed */\n\n    for(i=0;i<nb_frames;i++) {\n\n        AVPacket pkt;\n\n        av_init_packet(&pkt);\n\n        pkt.stream_index= ost->index;\n\n\n\n        if (s->oformat->flags & AVFMT_RAWPICTURE) {\n\n            /* raw pictures are written as AVPicture structure to\n\n               avoid any copies. We support temporarily the older\n\n               method. */\n\n            enc->coded_frame->interlaced_frame = in_picture->interlaced_frame;\n\n            enc->coded_frame->top_field_first  = in_picture->top_field_first;\n\n            pkt.data= (uint8_t *)final_picture;\n\n            pkt.size=  sizeof(AVPicture);\n\n            pkt.pts= av_rescale_q(ost->sync_opts, enc->time_base, ost->st->time_base);\n\n            pkt.flags |= AV_PKT_FLAG_KEY;\n\n\n\n            write_frame(s, &pkt, ost->st->codec, ost->bitstream_filters);\n\n        } else {\n\n            AVFrame big_picture;\n\n\n\n            big_picture= *final_picture;\n\n            /* better than nothing: use input picture interlaced\n\n               settings */\n\n            big_picture.interlaced_frame = in_picture->interlaced_frame;\n\n            if (ost->st->codec->flags & (CODEC_FLAG_INTERLACED_DCT|CODEC_FLAG_INTERLACED_ME)) {\n\n                if (ost->top_field_first == -1)\n\n                    big_picture.top_field_first = in_picture->top_field_first;\n\n                else\n\n                    big_picture.top_field_first = !!ost->top_field_first;\n\n            }\n\n\n\n            /* handles same_quant here. This is not correct because it may\n\n               not be a global option */\n\n            big_picture.quality = quality;\n\n            if (!enc->me_threshold)\n\n                big_picture.pict_type = 0;\n\n//            big_picture.pts = AV_NOPTS_VALUE;\n\n            big_picture.pts= ost->sync_opts;\n\n//            big_picture.pts= av_rescale(ost->sync_opts, AV_TIME_BASE*(int64_t)enc->time_base.num, enc->time_base.den);\n\n//av_log(NULL, AV_LOG_DEBUG, \"%\"PRId64\" -> encoder\\n\", ost->sync_opts);\n\n            if (ost->forced_kf_index < ost->forced_kf_count &&\n\n                big_picture.pts >= ost->forced_kf_pts[ost->forced_kf_index]) {\n\n                big_picture.pict_type = AV_PICTURE_TYPE_I;\n\n                ost->forced_kf_index++;\n\n            }\n\n            ret = avcodec_encode_video(enc,\n\n                                       bit_buffer, bit_buffer_size,\n\n                                       &big_picture);\n\n            if (ret < 0) {\n\n                av_log(NULL, AV_LOG_FATAL, \"Video encoding failed\\n\");\n\n                exit_program(1);\n\n            }\n\n\n\n            if(ret>0){\n\n                pkt.data= bit_buffer;\n\n                pkt.size= ret;\n\n                if(enc->coded_frame->pts != AV_NOPTS_VALUE)\n\n                    pkt.pts= av_rescale_q(enc->coded_frame->pts, enc->time_base, ost->st->time_base);\n\n/*av_log(NULL, AV_LOG_DEBUG, \"encoder -> %\"PRId64\"/%\"PRId64\"\\n\",\n\n   pkt.pts != AV_NOPTS_VALUE ? av_rescale(pkt.pts, enc->time_base.den, AV_TIME_BASE*(int64_t)enc->time_base.num) : -1,\n\n   pkt.dts != AV_NOPTS_VALUE ? av_rescale(pkt.dts, enc->time_base.den, AV_TIME_BASE*(int64_t)enc->time_base.num) : -1);*/\n\n\n\n                if(enc->coded_frame->key_frame)\n\n                    pkt.flags |= AV_PKT_FLAG_KEY;\n\n                write_frame(s, &pkt, ost->st->codec, ost->bitstream_filters);\n\n                *frame_size = ret;\n\n                video_size += ret;\n\n                //fprintf(stderr,\"\\nFrame: %3d size: %5d type: %d\",\n\n                //        enc->frame_number-1, ret, enc->pict_type);\n\n                /* if two pass, output log */\n\n                if (ost->logfile && enc->stats_out) {\n\n                    fprintf(ost->logfile, \"%s\", enc->stats_out);\n\n                }\n\n            }\n\n        }\n\n        ost->sync_opts++;\n\n        ost->frame_number++;\n\n    }\n\n}\n", "idx": 24607}
{"project": "FFmpeg", "commit_id": "b8ce8f15a036780bd5ee655bcac881a8cd62f85a", "target": 0, "func": "static void vc1_decode_i_blocks_adv(VC1Context *v)\n\n{\n\n    int k, j;\n\n    MpegEncContext *s = &v->s;\n\n    int cbp, val;\n\n    uint8_t *coded_val;\n\n    int mb_pos;\n\n    int mquant = v->pq;\n\n    int mqdiff;\n\n    int overlap;\n\n    GetBitContext *gb = &s->gb;\n\n\n\n    /* select codingmode used for VLC tables selection */\n\n    switch(v->y_ac_table_index){\n\n    case 0:\n\n        v->codingset = (v->pqindex <= 8) ? CS_HIGH_RATE_INTRA : CS_LOW_MOT_INTRA;\n\n        break;\n\n    case 1:\n\n        v->codingset = CS_HIGH_MOT_INTRA;\n\n        break;\n\n    case 2:\n\n        v->codingset = CS_MID_RATE_INTRA;\n\n        break;\n\n    }\n\n\n\n    switch(v->c_ac_table_index){\n\n    case 0:\n\n        v->codingset2 = (v->pqindex <= 8) ? CS_HIGH_RATE_INTER : CS_LOW_MOT_INTER;\n\n        break;\n\n    case 1:\n\n        v->codingset2 = CS_HIGH_MOT_INTER;\n\n        break;\n\n    case 2:\n\n        v->codingset2 = CS_MID_RATE_INTER;\n\n        break;\n\n    }\n\n\n\n    /* Set DC scale - y and c use the same */\n\n    s->y_dc_scale = s->y_dc_scale_table[v->pq];\n\n    s->c_dc_scale = s->c_dc_scale_table[v->pq];\n\n\n\n    //do frame decode\n\n    s->mb_x = s->mb_y = 0;\n\n    s->mb_intra = 1;\n\n    s->first_slice_line = 1;\n\n    ff_er_add_slice(s, 0, 0, s->mb_width - 1, s->mb_height - 1, (AC_END|DC_END|MV_END));\n\n    for(s->mb_y = 0; s->mb_y < s->mb_height; s->mb_y++) {\n\n        for(s->mb_x = 0; s->mb_x < s->mb_width; s->mb_x++) {\n\n            ff_init_block_index(s);\n\n            ff_update_block_index(s);\n\n            s->dsp.clear_blocks(s->block[0]);\n\n            mb_pos = s->mb_x + s->mb_y * s->mb_stride;\n\n            s->current_picture.mb_type[mb_pos] = MB_TYPE_INTRA;\n\n            s->current_picture.motion_val[1][s->block_index[0]][0] = 0;\n\n            s->current_picture.motion_val[1][s->block_index[0]][1] = 0;\n\n\n\n            // do actual MB decoding and displaying\n\n            cbp = get_vlc2(&v->s.gb, ff_msmp4_mb_i_vlc.table, MB_INTRA_VLC_BITS, 2);\n\n            if(v->acpred_is_raw)\n\n                v->s.ac_pred = get_bits(&v->s.gb, 1);\n\n            else\n\n                v->s.ac_pred = v->acpred_plane[mb_pos];\n\n\n\n            if(v->condover == CONDOVER_SELECT) {\n\n                if(v->overflg_is_raw)\n\n                    overlap = get_bits(&v->s.gb, 1);\n\n                else\n\n                    overlap = v->over_flags_plane[mb_pos];\n\n            } else\n\n                overlap = (v->condover == CONDOVER_ALL);\n\n\n\n            GET_MQUANT();\n\n\n\n            s->current_picture.qscale_table[mb_pos] = mquant;\n\n\n\n            for(k = 0; k < 6; k++) {\n\n                val = ((cbp >> (5 - k)) & 1);\n\n\n\n                if (k < 4) {\n\n                    int pred = vc1_coded_block_pred(&v->s, k, &coded_val);\n\n                    val = val ^ pred;\n\n                    *coded_val = val;\n\n                }\n\n                cbp |= val << (5 - k);\n\n\n\n                v->a_avail = !s->first_slice_line || (k==2 || k==3);\n\n                v->c_avail = !!s->mb_x || (k==1 || k==3);\n\n\n\n                vc1_decode_i_block_adv(v, s->block[k], k, val, (k<4)? v->codingset : v->codingset2, mquant);\n\n\n\n                s->dsp.vc1_inv_trans_8x8(s->block[k]);\n\n                for(j = 0; j < 64; j++) s->block[k][j] += 128;\n\n            }\n\n\n\n            vc1_put_block(v, s->block);\n\n            if(overlap) {\n\n                if(s->mb_x) {\n\n                    s->dsp.vc1_h_overlap(s->dest[0], s->linesize, 0);\n\n                    s->dsp.vc1_h_overlap(s->dest[0] + 8 * s->linesize, s->linesize, 0);\n\n                    if(!(s->flags & CODEC_FLAG_GRAY)) {\n\n                        s->dsp.vc1_h_overlap(s->dest[1], s->uvlinesize, s->mb_x&1);\n\n                        s->dsp.vc1_h_overlap(s->dest[2], s->uvlinesize, s->mb_x&1);\n\n                    }\n\n                }\n\n                s->dsp.vc1_h_overlap(s->dest[0] + 8, s->linesize, 1);\n\n                s->dsp.vc1_h_overlap(s->dest[0] + 8 * s->linesize + 8, s->linesize, 1);\n\n                if(!s->first_slice_line) {\n\n                    s->dsp.vc1_v_overlap(s->dest[0], s->linesize, 0);\n\n                    s->dsp.vc1_v_overlap(s->dest[0] + 8, s->linesize, 0);\n\n                    if(!(s->flags & CODEC_FLAG_GRAY)) {\n\n                        s->dsp.vc1_v_overlap(s->dest[1], s->uvlinesize, s->mb_y&1);\n\n                        s->dsp.vc1_v_overlap(s->dest[2], s->uvlinesize, s->mb_y&1);\n\n                    }\n\n                }\n\n                s->dsp.vc1_v_overlap(s->dest[0] + 8 * s->linesize, s->linesize, 1);\n\n                s->dsp.vc1_v_overlap(s->dest[0] + 8 * s->linesize + 8, s->linesize, 1);\n\n            }\n\n\n\n            if(get_bits_count(&s->gb) > v->bits) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"Bits overconsumption: %i > %i\\n\", get_bits_count(&s->gb), v->bits);\n\n                return;\n\n            }\n\n        }\n\n        ff_draw_horiz_band(s, s->mb_y * 16, 16);\n\n        s->first_slice_line = 0;\n\n    }\n\n}\n", "idx": 24608}
{"project": "FFmpeg", "commit_id": "e3a1eb9edf65edda301f3a727f11e0224b9f5ae2", "target": 1, "func": "static int parse_channel_name(char **arg, int *rchannel, int *rnamed)\n\n{\n\n    char buf[8];\n\n    int len, i, channel_id = 0;\n\n    int64_t layout, layout0;\n\n\n\n    /* try to parse a channel name, e.g. \"FL\" */\n\n    if (sscanf(*arg, \" %7[A-Z] %n\", buf, &len)) {\n\n        layout0 = layout = av_get_channel_layout(buf);\n\n        /* channel_id <- first set bit in layout */\n\n        for (i = 32; i > 0; i >>= 1) {\n\n            if (layout >= (int64_t)1 << i) {\n\n                channel_id += i;\n\n                layout >>= i;\n\n            }\n\n        }\n\n        /* reject layouts that are not a single channel */\n\n        if (channel_id >= MAX_CHANNELS || layout0 != (int64_t)1 << channel_id)\n\n            return AVERROR(EINVAL);\n\n        *rchannel = channel_id;\n\n        *rnamed = 1;\n\n        *arg += len;\n\n        return 0;\n\n    }\n\n    /* try to parse a channel number, e.g. \"c2\" */\n\n    if (sscanf(*arg, \" c%d %n\", &channel_id, &len) &&\n\n        channel_id >= 0 && channel_id < MAX_CHANNELS) {\n\n        *rchannel = channel_id;\n\n        *rnamed = 0;\n\n        *arg += len;\n\n        return 0;\n\n    }\n\n    return AVERROR(EINVAL);\n\n}\n", "idx": 24609}
{"project": "FFmpeg", "commit_id": "ca203e9985cd2dcf42a0c0853940850d3a8edf3a", "target": 1, "func": "static void search_for_ms_mips(AACEncContext *s, ChannelElement *cpe)\n\n{\n\n    int start = 0, i, w, w2, g;\n\n    float M[128], S[128];\n\n    float *L34 = s->scoefs, *R34 = s->scoefs + 128, *M34 = s->scoefs + 128*2, *S34 = s->scoefs + 128*3;\n\n    const float lambda = s->lambda;\n\n    SingleChannelElement *sce0 = &cpe->ch[0];\n\n    SingleChannelElement *sce1 = &cpe->ch[1];\n\n    if (!cpe->common_window)\n\n        return;\n\n    for (w = 0; w < sce0->ics.num_windows; w += sce0->ics.group_len[w]) {\n\n        start = 0;\n\n        for (g = 0;  g < sce0->ics.num_swb; g++) {\n\n            if (!cpe->ch[0].zeroes[w*16+g] && !cpe->ch[1].zeroes[w*16+g]) {\n\n                float dist1 = 0.0f, dist2 = 0.0f;\n\n                for (w2 = 0; w2 < sce0->ics.group_len[w]; w2++) {\n\n                    FFPsyBand *band0 = &s->psy.ch[s->cur_channel+0].psy_bands[(w+w2)*16+g];\n\n                    FFPsyBand *band1 = &s->psy.ch[s->cur_channel+1].psy_bands[(w+w2)*16+g];\n\n                    float minthr = FFMIN(band0->threshold, band1->threshold);\n\n                    float maxthr = FFMAX(band0->threshold, band1->threshold);\n\n                    for (i = 0; i < sce0->ics.swb_sizes[g]; i+=4) {\n\n                        M[i  ] = (sce0->coeffs[start+w2*128+i  ]\n\n                                + sce1->coeffs[start+w2*128+i  ]) * 0.5;\n\n                        M[i+1] = (sce0->coeffs[start+w2*128+i+1]\n\n                                + sce1->coeffs[start+w2*128+i+1]) * 0.5;\n\n                        M[i+2] = (sce0->coeffs[start+w2*128+i+2]\n\n                                + sce1->coeffs[start+w2*128+i+2]) * 0.5;\n\n                        M[i+3] = (sce0->coeffs[start+w2*128+i+3]\n\n                                + sce1->coeffs[start+w2*128+i+3]) * 0.5;\n\n\n\n                        S[i  ] =  M[i  ]\n\n                                - sce1->coeffs[start+w2*128+i  ];\n\n                        S[i+1] =  M[i+1]\n\n                                - sce1->coeffs[start+w2*128+i+1];\n\n                        S[i+2] =  M[i+2]\n\n                                - sce1->coeffs[start+w2*128+i+2];\n\n                        S[i+3] =  M[i+3]\n\n                                - sce1->coeffs[start+w2*128+i+3];\n\n                   }\n\n                    abs_pow34_v(L34, sce0->coeffs+start+(w+w2)*128, sce0->ics.swb_sizes[g]);\n\n                    abs_pow34_v(R34, sce1->coeffs+start+(w+w2)*128, sce0->ics.swb_sizes[g]);\n\n                    abs_pow34_v(M34, M,                         sce0->ics.swb_sizes[g]);\n\n                    abs_pow34_v(S34, S,                         sce0->ics.swb_sizes[g]);\n\n                    dist1 += quantize_band_cost(s, &sce0->coeffs[start + (w+w2)*128],\n\n                                                L34,\n\n                                                sce0->ics.swb_sizes[g],\n\n                                                sce0->sf_idx[(w+w2)*16+g],\n\n                                                sce0->band_type[(w+w2)*16+g],\n\n                                                lambda / band0->threshold, INFINITY, NULL, NULL, 0);\n\n                    dist1 += quantize_band_cost(s, &sce1->coeffs[start + (w+w2)*128],\n\n                                                R34,\n\n                                                sce1->ics.swb_sizes[g],\n\n                                                sce1->sf_idx[(w+w2)*16+g],\n\n                                                sce1->band_type[(w+w2)*16+g],\n\n                                                lambda / band1->threshold, INFINITY, NULL, NULL, 0);\n\n                    dist2 += quantize_band_cost(s, M,\n\n                                                M34,\n\n                                                sce0->ics.swb_sizes[g],\n\n                                                sce0->sf_idx[(w+w2)*16+g],\n\n                                                sce0->band_type[(w+w2)*16+g],\n\n                                                lambda / maxthr, INFINITY, NULL, NULL, 0);\n\n                    dist2 += quantize_band_cost(s, S,\n\n                                                S34,\n\n                                                sce1->ics.swb_sizes[g],\n\n                                                sce1->sf_idx[(w+w2)*16+g],\n\n                                                sce1->band_type[(w+w2)*16+g],\n\n                                                lambda / minthr, INFINITY, NULL, NULL, 0);\n\n                }\n\n                cpe->ms_mask[w*16+g] = dist2 < dist1;\n\n            }\n\n            start += sce0->ics.swb_sizes[g];\n\n        }\n\n    }\n\n}\n", "idx": 24612}
{"project": "FFmpeg", "commit_id": "f5e646a00ac21e500dae4bcceded790a0fbc5246", "target": 1, "func": "static void get_attachment(AVFormatContext *s, AVIOContext *pb, int length)\n\n{\n\n    char mime[1024];\n\n    char description[1024];\n\n    unsigned int filesize;\n\n    AVStream *st;\n\n    int64_t pos = avio_tell(pb);\n\n\n\n    avio_get_str16le(pb, INT_MAX, mime, sizeof(mime));\n\n    if (strcmp(mime, \"image/jpeg\"))\n\n        goto done;\n\n\n\n    avio_r8(pb);\n\n    avio_get_str16le(pb, INT_MAX, description, sizeof(description));\n\n    filesize = avio_rl32(pb);\n\n    if (!filesize)\n\n        goto done;\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        goto done;\n\n    av_dict_set(&st->metadata, \"title\", description, 0);\n\n    st->codec->codec_id   = AV_CODEC_ID_MJPEG;\n\n    st->codec->codec_type = AVMEDIA_TYPE_ATTACHMENT;\n\n    st->codec->extradata  = av_mallocz(filesize);\n\n\n    if (!st->codec->extradata)\n\n        goto done;\n\n    st->codec->extradata_size = filesize;\n\n    avio_read(pb, st->codec->extradata, filesize);\n\ndone:\n\n    avio_seek(pb, pos + length, SEEK_SET);\n\n}", "idx": 24616}
{"project": "FFmpeg", "commit_id": "1c37848f9029985d1271da9a0d161c2ebf0aca81", "target": 1, "func": "static int parse_filename(char *filename, char **representation_id,\n\n                          char **initialization_pattern, char **media_pattern) {\n\n    char *underscore_pos = NULL;\n\n    char *period_pos = NULL;\n\n    char *temp_pos = NULL;\n\n    char *filename_str = av_strdup(filename);\n\n    if (!filename_str) return AVERROR(ENOMEM);\n\n    temp_pos = av_stristr(filename_str, \"_\");\n\n    while (temp_pos) {\n\n        underscore_pos = temp_pos + 1;\n\n        temp_pos = av_stristr(temp_pos + 1, \"_\");\n\n    }\n\n    if (!underscore_pos) return -1;\n\n    period_pos = av_stristr(underscore_pos, \".\");\n\n    if (!period_pos) return -1;\n\n    *(underscore_pos - 1) = 0;\n\n    if (representation_id) {\n\n        *representation_id = av_malloc(period_pos - underscore_pos + 1);\n\n        if (!(*representation_id)) return AVERROR(ENOMEM);\n\n        av_strlcpy(*representation_id, underscore_pos, period_pos - underscore_pos + 1);\n\n    }\n\n    if (initialization_pattern) {\n\n        *initialization_pattern = av_asprintf(\"%s_$RepresentationID$.hdr\",\n\n                                              filename_str);\n\n        if (!(*initialization_pattern)) return AVERROR(ENOMEM);\n\n    }\n\n    if (media_pattern) {\n\n        *media_pattern = av_asprintf(\"%s_$RepresentationID$_$Number$.chk\",\n\n                                     filename_str);\n\n        if (!(*media_pattern)) return AVERROR(ENOMEM);\n\n    }\n\n    av_free(filename_str);\n\n    return 0;\n\n}\n", "idx": 24617}
{"project": "FFmpeg", "commit_id": "2caf19e90f270abe1e80a3e85acaf0eb5c9d0aac", "target": 1, "func": "static void FUNCC(pred8x8_left_dc)(uint8_t *_src, int stride){\n\n    int i;\n\n    int dc0, dc2;\n\n    pixel4 dc0splat, dc2splat;\n\n    pixel *src = (pixel*)_src;\n\n    stride /= sizeof(pixel);\n\n\n\n    dc0=dc2=0;\n\n    for(i=0;i<4; i++){\n\n        dc0+= src[-1+i*stride];\n\n        dc2+= src[-1+(i+4)*stride];\n\n    }\n\n    dc0splat = PIXEL_SPLAT_X4((dc0 + 2)>>2);\n\n    dc2splat = PIXEL_SPLAT_X4((dc2 + 2)>>2);\n\n\n\n    for(i=0; i<4; i++){\n\n        ((pixel4*)(src+i*stride))[0]=\n\n        ((pixel4*)(src+i*stride))[1]= dc0splat;\n\n    }\n\n    for(i=4; i<8; i++){\n\n        ((pixel4*)(src+i*stride))[0]=\n\n        ((pixel4*)(src+i*stride))[1]= dc2splat;\n\n    }\n\n}\n", "idx": 24621}
{"project": "FFmpeg", "commit_id": "de052ea454e06f2c1aab4e06cca0012cf80f2630", "target": 1, "func": "static void celt_denormalize(CeltFrame *f, CeltBlock *block, float *data)\n\n{\n\n    int i, j;\n\n\n\n    for (i = f->start_band; i < f->end_band; i++) {\n\n        float *dst = data + (ff_celt_freq_bands[i] << f->size);\n\n        float norm = exp2f(block->energy[i] + ff_celt_mean_energy[i]);\n\n\n\n        for (j = 0; j < ff_celt_freq_range[i] << f->size; j++)\n\n            dst[j] *= norm;\n\n    }\n\n}\n", "idx": 24622}
{"project": "FFmpeg", "commit_id": "5ff998a233d759d0de83ea6f95c383d03d25d88e", "target": 1, "func": "static int flac_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n\n                             const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    FlacEncodeContext *s;\n\n    const int16_t *samples;\n\n    int frame_bytes, out_bytes, ret;\n\n\n\n    s = avctx->priv_data;\n\n\n\n    /* when the last block is reached, update the header in extradata */\n\n    if (!frame) {\n\n        s->max_framesize = s->max_encoded_framesize;\n\n        av_md5_final(s->md5ctx, s->md5sum);\n\n        write_streaminfo(s, avctx->extradata);\n\n        return 0;\n\n    }\n\n    samples = (const int16_t *)frame->data[0];\n\n\n\n    /* change max_framesize for small final frame */\n\n    if (frame->nb_samples < s->frame.blocksize) {\n\n        s->max_framesize = ff_flac_get_max_frame_size(frame->nb_samples,\n\n                                                      s->channels, 16);\n\n    }\n\n\n\n    init_frame(s, frame->nb_samples);\n\n\n\n    copy_samples(s, samples);\n\n\n\n    channel_decorrelation(s);\n\n\n\n    remove_wasted_bits(s);\n\n\n\n    frame_bytes = encode_frame(s);\n\n\n\n    /* fallback to verbatim mode if the compressed frame is larger than it\n\n       would be if encoded uncompressed. */\n\n    if (frame_bytes > s->max_framesize) {\n\n        s->frame.verbatim_only = 1;\n\n        frame_bytes = encode_frame(s);\n\n    }\n\n\n\n    if ((ret = ff_alloc_packet(avpkt, frame_bytes))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n\n        return ret;\n\n    }\n\n\n\n    out_bytes = write_frame(s, avpkt);\n\n\n\n    s->frame_count++;\n\n    s->sample_count += frame->nb_samples;\n\n    if ((ret = update_md5_sum(s, samples)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error updating MD5 checksum\\n\");\n\n        return ret;\n\n    }\n\n    if (out_bytes > s->max_encoded_framesize)\n\n        s->max_encoded_framesize = out_bytes;\n\n    if (out_bytes < s->min_framesize)\n\n        s->min_framesize = out_bytes;\n\n\n\n    avpkt->pts      = frame->pts;\n\n    avpkt->duration = ff_samples_to_time_base(avctx, frame->nb_samples);\n\n    avpkt->size     = out_bytes;\n\n    *got_packet_ptr = 1;\n\n    return 0;\n\n}\n", "idx": 24623}
{"project": "FFmpeg", "commit_id": "48aecf5a7dd8e914d44cb4210a09172dbd8d5d86", "target": 1, "func": "static void alloc_and_copy(uint8_t **poutbuf,          int *poutbuf_size,\n\n                           const uint8_t *sps_pps, uint32_t sps_pps_size,\n\n                           const uint8_t *in,      uint32_t in_size) {\n\n    uint32_t offset = *poutbuf_size;\n\n    uint8_t nal_header_size = offset ? 3 : 4;\n\n\n\n    *poutbuf_size += sps_pps_size+in_size+nal_header_size;\n\n    *poutbuf = av_realloc(*poutbuf, *poutbuf_size);\n\n    if (sps_pps)\n\n        memcpy(*poutbuf+offset, sps_pps, sps_pps_size);\n\n    memcpy(*poutbuf+sps_pps_size+nal_header_size+offset, in, in_size);\n\n    if (!offset)\n\n        AV_WB32(*poutbuf+sps_pps_size, 1);\n\n    else {\n\n        (*poutbuf+offset)[0] = (*poutbuf+offset)[1] = 0;\n\n        (*poutbuf+offset)[2] = 1;\n\n    }\n\n}\n", "idx": 24625}
{"project": "FFmpeg", "commit_id": "c7d9b473e28238d4a4ef1b7e8b42c1cca256da36", "target": 0, "func": "static int cdg_decode_frame(AVCodecContext *avctx,\n\n                            void *data, int *got_frame, AVPacket *avpkt)\n\n{\n\n    GetByteContext gb;\n\n    int buf_size       = avpkt->size;\n\n    int ret;\n\n    uint8_t command, inst;\n\n    uint8_t cdg_data[CDG_DATA_SIZE];\n\n    AVFrame *frame = data;\n\n    CDGraphicsContext *cc = avctx->priv_data;\n\n\n\n    bytestream2_init(&gb, avpkt->data, avpkt->size);\n\n\n\n\n\n    ret = ff_reget_buffer(avctx, cc->frame);\n\n    if (ret) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n    if (!avctx->frame_number)\n\n        memset(cc->frame->data[0], 0, cc->frame->linesize[0] * avctx->height);\n\n\n\n    command = bytestream2_get_byte(&gb);\n\n    inst    = bytestream2_get_byte(&gb);\n\n    inst    &= CDG_MASK;\n\n    bytestream2_skip(&gb, 2);\n\n    bytestream2_get_buffer(&gb, cdg_data, sizeof(cdg_data));\n\n\n\n    if ((command & CDG_MASK) == CDG_COMMAND) {\n\n        switch (inst) {\n\n        case CDG_INST_MEMORY_PRESET:\n\n            if (!(cdg_data[1] & 0x0F))\n\n                memset(cc->frame->data[0], cdg_data[0] & 0x0F,\n\n                       cc->frame->linesize[0] * CDG_FULL_HEIGHT);\n\n            break;\n\n        case CDG_INST_LOAD_PAL_LO:\n\n        case CDG_INST_LOAD_PAL_HIGH:\n\n            if (buf_size - CDG_HEADER_SIZE < CDG_DATA_SIZE) {\n\n                av_log(avctx, AV_LOG_ERROR, \"buffer too small for loading palette\\n\");\n\n                return AVERROR(EINVAL);\n\n            }\n\n\n\n            cdg_load_palette(cc, cdg_data, inst == CDG_INST_LOAD_PAL_LO);\n\n            break;\n\n        case CDG_INST_BORDER_PRESET:\n\n            cdg_border_preset(cc, cdg_data);\n\n            break;\n\n        case CDG_INST_TILE_BLOCK_XOR:\n\n        case CDG_INST_TILE_BLOCK:\n\n            if (buf_size - CDG_HEADER_SIZE < CDG_DATA_SIZE) {\n\n                av_log(avctx, AV_LOG_ERROR, \"buffer too small for drawing tile\\n\");\n\n                return AVERROR(EINVAL);\n\n            }\n\n\n\n            ret = cdg_tile_block(cc, cdg_data, inst == CDG_INST_TILE_BLOCK_XOR);\n\n            if (ret) {\n\n                av_log(avctx, AV_LOG_ERROR, \"tile is out of range\\n\");\n\n                return ret;\n\n            }\n\n            break;\n\n        case CDG_INST_SCROLL_PRESET:\n\n        case CDG_INST_SCROLL_COPY:\n\n            if (buf_size - CDG_HEADER_SIZE < CDG_MINIMUM_SCROLL_SIZE) {\n\n                av_log(avctx, AV_LOG_ERROR, \"buffer too small for scrolling\\n\");\n\n                return AVERROR(EINVAL);\n\n            }\n\n\n\n            ret = ff_get_buffer(avctx, frame, AV_GET_BUFFER_FLAG_REF);\n\n            if (ret) {\n\n                av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n                return ret;\n\n            }\n\n\n\n            cdg_scroll(cc, cdg_data, frame, inst == CDG_INST_SCROLL_COPY);\n\n            av_frame_unref(cc->frame);\n\n            ret = av_frame_ref(cc->frame, frame);\n\n            if (ret < 0)\n\n                return ret;\n\n            break;\n\n        default:\n\n            break;\n\n        }\n\n\n\n        if (!frame->data[0]) {\n\n            ret = av_frame_ref(frame, cc->frame);\n\n            if (ret < 0)\n\n                return ret;\n\n        }\n\n        *got_frame = 1;\n\n    } else {\n\n        *got_frame = 0;\n\n        buf_size   = 0;\n\n    }\n\n\n\n    return buf_size;\n\n}\n", "idx": 24627}
